id,text,Authors,Researcher Ids,ORCIDs,title,Volume,Issue,DOI,Document Type,Publication Date,Abstract,ISSN,eISSN,ISBN,Pages,Publisher,Proceedings title,Keywords,label,Comments
2457,"**Title**Toxic language detection: A systematic review of Arabic datasets

**Abstract**The detection of toxic language in the Arabic language has emerged as an active area of research in recent years, and reviewing the existing datasets employed for training the developed solutions has become a pressing need. This paper offers a comprehensive survey of Arabic datasets focused on online toxic language. We systematically gathered a total of 54 available datasets and their corresponding papers and conducted a thorough analysis, considering 18 criteria across four primary dimensions: availability details, content, annotation process, and reusability. This analysis enabled us to identify existing gaps and make recommendations for future research works. For the convenience of the research community, the list of the analysed datasets is maintained in a GitHub repository.","Bensalem, Imene; Rosso, Paolo; Zitouni, Hanane","Bensalem, Imene/I-7261-2019","Bensalem, Imene/0000-0002-2462-5967",Toxic language detection: A systematic review of Arabic datasets,41,8,10.1111/exsy.13551 ,Article ,,"The detection of toxic language in the Arabic language has emerged as an active area of research in recent years, and reviewing the existing datasets employed for training the developed solutions has become a pressing need. This paper offers a comprehensive survey of Arabic datasets focused on online toxic language. We systematically gathered a total of 54 available datasets and their corresponding papers and conducted a thorough analysis, considering 18 criteria across four primary dimensions: availability details, content, annotation process, and reusability. This analysis enabled us to identify existing gaps and make recommendations for future research works. For the convenience of the research community, the list of the analysed datasets is maintained in a GitHub repository.",0266-4720,1468-0394,,, ,  ,,out_but_toxicity,
2458,"**Title**Should We Translate? Evaluating Toxicity in Online Comments when Translating from Portuguese to English

**Abstract**Social media and online discussion platforms suffer from the prevalence of uncivil behavior, such as harassment and abuse, seeking to curb toxic comments. There are several approaches to classifying toxic comments automatically. Some of them have more resources and are more advanced in English, thus, stimulating the task of translating the text from a specific language to English. While researchers have shown evidence that this practice is indicated for certain tasks, such as sentiment analysis, little is known in the context of toxicity identification. In this research, we assess the performance of a freely available model for toxic language detection in online comments called Perspective API, widely adopted by some famous news media sites to identify different toxicity classes in online comments. For that, we obtained comments in Portuguese from two Brazilian news media websites during a politically polarized situation as a use case. Then, this dataset was translated to English and compared to four baseline datasets, two composed of highly toxic comments, one in Portuguese and other in English, and two composed of neutral comments, also one in Portuguese and other in English - all of them in its original language, not translated. Finally, human-annotated comments from the news comments dataset were analyzed to assess the scores provided by the Perspective API for the original and the translated versions. Results indicate that keeping the texts in their original language is preferable, even in comparing different languages. Nevertheless, if the translated version is strictly necessary, ways of dealing with the situation were suggested to preserve as much information as possible from the original version.","Kobellarz, Jordan K.; Silva, Thiago H.","Silva, Thiago/AFE-1930-2022","Silva, Thiago/0000-0001-6994-8076",Should We Translate? Evaluating Toxicity in Online Comments when Translating from Portuguese to English,,,10.1145/3539637.3556892 ,Proceedings Paper ,,"Social media and online discussion platforms suffer from the prevalence of uncivil behavior, such as harassment and abuse, seeking to curb toxic comments. There are several approaches to classifying toxic comments automatically. Some of them have more resources and are more advanced in English, thus, stimulating the task of translating the text from a specific language to English. While researchers have shown evidence that this practice is indicated for certain tasks, such as sentiment analysis, little is known in the context of toxicity identification. In this research, we assess the performance of a freely available model for toxic language detection in online comments called Perspective API, widely adopted by some famous news media sites to identify different toxicity classes in online comments. For that, we obtained comments in Portuguese from two Brazilian news media websites during a politically polarized situation as a use case. Then, this dataset was translated to English and compared to four baseline datasets, two composed of highly toxic comments, one in Portuguese and other in English, and two composed of neutral comments, also one in Portuguese and other in English - all of them in its original language, not translated. Finally, human-annotated comments from the news comments dataset were analyzed to assess the scores provided by the Perspective API for the original and the translated versions. Results indicate that keeping the texts in their original language is preferable, even in comparing different languages. Nevertheless, if the translated version is strictly necessary, ways of dealing with the situation were suggested to preserve as much information as possible from the original version.",,,978-1-4503-9409-3,89-98, , 28th Brazilian Symposium on Multimedia and the Web (WebMedia)28th Brazilian Symposium on Multimedia and the Web (WebMedia) ,,out_but_toxicity,
2459,"**Title**Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting

**Abstract**Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as toxic language detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique - it remains unclear for which tasks and scenarios it can help, and the role of the individual factors in sociodemographic prompting is still unexplored. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. We analyze its influence on model sensitivity, performance and robustness across seven datasets and six instruction-tuned model families. We show that sociodemographic information affects model predictions and can be beneficial for improving zero-shot learning in subjective NLP tasks. However, its outcomes largely vary for different model types, sizes, and datasets, and are subject to large variance with regards to prompt formulations. Most importantly, our results show that sociodemographic prompting should be used with care for sensitive applications, such as toxicity annotation or when studying LLM alignment.","Beck, Tilman; Schuff, Hendrik; Lauscher, Anne; Gurevych, Iryna",,,"Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting",,, ,Proceedings Paper ,,"Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as toxic language detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique - it remains unclear for which tasks and scenarios it can help, and the role of the individual factors in sociodemographic prompting is still unexplored. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. We analyze its influence on model sensitivity, performance and robustness across seven datasets and six instruction-tuned model families. We show that sociodemographic information affects model predictions and can be beneficial for improving zero-shot learning in subjective NLP tasks. However, its outcomes largely vary for different model types, sizes, and datasets, and are subject to large variance with regards to prompt formulations. Most importantly, our results show that sociodemographic prompting should be used with care for sensitive applications, such as toxicity annotation or when studying LLM alignment.",,,979-8-89176-088-2,2589-2615, , 18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,detection#detox#methodology,
2460,"**Title**DQAC: Detoxifying Query Auto-completion with Adapters

**Abstract**Recent Query Auto-completion (QAC) systems leverage natural language generation or pre-trained language models (PLMs) to demonstrate remarkable performance. However, these systems also suffer from biased and toxic completions. Efforts have been made to address language detoxification within PLMs using controllable text generation (CTG) techniques, involving training with nontoxic data and employing decoding time approaches. As the completions for QAC systems are usually short, these existing CTG methods based on decoding and training are not directly transferable. Towards these concerns, we propose the first public QAC detoxification model, Detoxifying Query Auto-Completion (or DQAC), which utilizes adapters in a CTG framework. DQAC operates on latent representations with no additional overhead. It leverages two adapters for toxic and non-toxic cases. During inference, we fuse these representations in a controlled manner that guides the generation of query completions towards nontoxicity. We evaluate toxicity levels in the generated completions across two realworld datasets using two classifiers: a publicly available (Detoxify) and a search query-specific classifier which we develop (QDETOXIFY). DQAC consistently outperforms all existing baselines and emerges as a state-of-the-art model providing high quality and low toxicity. We make the code publicly available1.(1 https://shorturl.at/zJ024)","Maheswaran, Aishwarya; Maurya, Kaushal Kumar; Gupta, Manish; Desarkar, Maunendra Sankar","Desarkar, Maunendra/Y-8696-2019",,DQAC: Detoxifying Query Auto-completion with Adapters,14650,,10.1007/978-981-97-2266-2_9 ,Proceedings Paper ,,"Recent Query Auto-completion (QAC) systems leverage natural language generation or pre-trained language models (PLMs) to demonstrate remarkable performance. However, these systems also suffer from biased and toxic completions. Efforts have been made to address language detoxification within PLMs using controllable text generation (CTG) techniques, involving training with nontoxic data and employing decoding time approaches. As the completions for QAC systems are usually short, these existing CTG methods based on decoding and training are not directly transferable. Towards these concerns, we propose the first public QAC detoxification model, Detoxifying Query Auto-Completion (or DQAC), which utilizes adapters in a CTG framework. DQAC operates on latent representations with no additional overhead. It leverages two adapters for toxic and non-toxic cases. During inference, we fuse these representations in a controlled manner that guides the generation of query completions towards nontoxicity. We evaluate toxicity levels in the generated completions across two realworld datasets using two classifiers: a publicly available (Detoxify) and a search query-specific classifier which we develop (QDETOXIFY). DQAC consistently outperforms all existing baselines and emerges as a state-of-the-art model providing high quality and low toxicity. We make the code publicly available1.(1 https://shorturl.at/zJ024)",2945-9133,1611-3349,978-981-97-2265-5; 978-981-97-2266-2,108-120, , 28th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)28th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD) ,,detox,
2461,"**Title**Language Detoxification with Attribute-Discriminative Latent Space

**Abstract**Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications. To overcome this issue, a few text generation approaches aim to detoxify toxic texts using additional LMs or perturbations. However, previous methods require excessive memory, computations, and time which are serious bottlenecks in their real-world application. To address such limitations, we propose an effective yet efficient method for language detoxification using an attribute-discriminative latent space. Specifically, we project the latent space of an original Transformer LM onto a discriminative latent space that well-separates texts by their attributes using a projection block and an attribute discriminator. This allows the LM to control the text generation to be nontoxic with minimal memory and computation overhead. We validate our model, Attribute-Discriminative Language Model (ADLM) on detoxified language and dialogue generation tasks, on which our method significantly outperforms baselines both in performance and efficiency.","Kwak, Jin Myung; Kim, Minseon; Hwang, Sung Ju","Hwang, Sung/A-8817-2018",,Language Detoxification with Attribute-Discriminative Latent Space,,, ,Proceedings Paper ,,"Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications. To overcome this issue, a few text generation approaches aim to detoxify toxic texts using additional LMs or perturbations. However, previous methods require excessive memory, computations, and time which are serious bottlenecks in their real-world application. To address such limitations, we propose an effective yet efficient method for language detoxification using an attribute-discriminative latent space. Specifically, we project the latent space of an original Transformer LM onto a discriminative latent space that well-separates texts by their attributes using a projection block and an attribute discriminator. This allows the LM to control the text generation to be nontoxic with minimal memory and computation overhead. We validate our model, Attribute-Discriminative Language Model (ADLM) on detoxified language and dialogue generation tasks, on which our method significantly outperforms baselines both in performance and efficiency.",,,978-1-959429-72-2,10149-10171, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,detox,
2462,"**Title**DAC: Quantized Optimal Transport Reward-based Reinforcement Learning Approach to Detoxify Query Auto-Completion

**Abstract**Modern Query Auto-Completion (QAC) systems utilize natural language generation (NLG) using large language models (LLM) to achieve remarkable performance. However, these systems are prone to generating biased and toxic completions due to inherent learning biases. Existing detoxification approaches exhibit two key limitations: (1) They primarily focus on mitigating toxicity for grammatically well-formed long sentences but struggle to adapt to the QAC task, where queries are short and structurally different (include spelling errors, do not follow grammatical rules and have relatively flexible word order). (2) These approaches often view detoxification through a binary lens where all text labeled as toxic is undesirable, and non-toxic is considered desirable. To address these limitations, we propose DAC, an intuitive and efficient reinforcement learning-based model to detoxify QAC. With DAC, we introduce an additional perspective of considering the third query class of addressable toxicity. These queries can encompass implicit toxicity, subjective toxicity, or non-toxic queries containing toxic words. We incorporate this three-class query behavior perspective into the proposed model through quantized optimal transport to learn distinctions and generate truly non-toxic completions. We evaluate toxicity levels in the generated completions by DAC across two real-world QAC datasets (Bing and AOL) using two classifiers: a publicly available generic classifier (Detoxify) and a search queryspecific classifier, which we develop (TClassify). We find that DAC consistently outperforms all existing baselines on the Bing dataset and achieves competitive performance on the AOL dataset for query detoxification. We make the code publicly available1.","Maheswaran, Aishwarya; Maurya, Kaushal Kumar; Gupta, Manish; Desarkar, Maunendra Sankar","Desarkar, Maunendra/Y-8696-2019",,DAC: Quantized Optimal Transport Reward-based Reinforcement Learning Approach to Detoxify Query Auto-Completion,,,10.1145/3626772.3657779 ,Proceedings Paper ,,"Modern Query Auto-Completion (QAC) systems utilize natural language generation (NLG) using large language models (LLM) to achieve remarkable performance. However, these systems are prone to generating biased and toxic completions due to inherent learning biases. Existing detoxification approaches exhibit two key limitations: (1) They primarily focus on mitigating toxicity for grammatically well-formed long sentences but struggle to adapt to the QAC task, where queries are short and structurally different (include spelling errors, do not follow grammatical rules and have relatively flexible word order). (2) These approaches often view detoxification through a binary lens where all text labeled as toxic is undesirable, and non-toxic is considered desirable. To address these limitations, we propose DAC, an intuitive and efficient reinforcement learning-based model to detoxify QAC. With DAC, we introduce an additional perspective of considering the third query class of addressable toxicity. These queries can encompass implicit toxicity, subjective toxicity, or non-toxic queries containing toxic words. We incorporate this three-class query behavior perspective into the proposed model through quantized optimal transport to learn distinctions and generate truly non-toxic completions. We evaluate toxicity levels in the generated completions by DAC across two real-world QAC datasets (Bing and AOL) using two classifiers: a publicly available generic classifier (Detoxify) and a search queryspecific classifier, which we develop (TClassify). We find that DAC consistently outperforms all existing baselines on the Bing dataset and achieves competitive performance on the AOL dataset for query detoxification. We make the code publicly available1.",,,979-8-4007-0431-4,608-618, , 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR) ,,detox,
2463,"**Title**Composing Parameter-Efficient Modules with Arithmetic Operations

**Abstract**As an efficient alternative to conventional full finetuning, parameter-efficient fine-tuning (PEFT) is becoming the prevailing method to adapt pretrained language models. In PEFT, a lightweight module is learned on each dataset while the underlying pretrained language model remains unchanged, resulting in multiple compact modules representing diverse skills when applied to various domains and tasks. In this paper, we propose to compose these parameter-efficient modules through linear arithmetic operations in the weight space, thereby integrating different module capabilities. Specifically, we first define addition and negation operators for the module, and then further compose these two basic operators to perform flexible arithmetic. Our approach requires no additional training and enables highly flexible module composition. We apply different arithmetic operations to compose the parameter-efficient modules for (1) distribution generalization, (2) multi-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend our approach to detoxify Alpaca-LoRA, the latest instruction-tuned large language model based on LLaMA. Empirical results demonstrate that our approach produces new and effective parameter-efficient modules that significantly outperform existing ones across all settings.(1)","Zhang, Jinghan; Chen, Shiqi; Liu, Junteng; He, Junxian","Chen, Shiqi/HSE-5452-2023; zhang, Jinghan/GZN-1493-2022; He, Junxian/AAD-4486-2021",,Composing Parameter-Efficient Modules with Arithmetic Operations,,, ,Proceedings Paper ,,"As an efficient alternative to conventional full finetuning, parameter-efficient fine-tuning (PEFT) is becoming the prevailing method to adapt pretrained language models. In PEFT, a lightweight module is learned on each dataset while the underlying pretrained language model remains unchanged, resulting in multiple compact modules representing diverse skills when applied to various domains and tasks. In this paper, we propose to compose these parameter-efficient modules through linear arithmetic operations in the weight space, thereby integrating different module capabilities. Specifically, we first define addition and negation operators for the module, and then further compose these two basic operators to perform flexible arithmetic. Our approach requires no additional training and enables highly flexible module composition. We apply different arithmetic operations to compose the parameter-efficient modules for (1) distribution generalization, (2) multi-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend our approach to detoxify Alpaca-LoRA, the latest instruction-tuned large language model based on LLaMA. Empirical results demonstrate that our approach produces new and effective parameter-efficient modules that significantly outperform existing ones across all settings.(1)",1049-5258,,*****************,, , 37th Conference on Neural Information Processing Systems (NeurIPS)37th Conference on Neural Information Processing Systems (NeurIPS) ,,out_of_scope,
2464,"**Title**SAFECONV: Explaining and Correcting Conversational Unsafe Behavior

**Abstract**One of the main challenges open-domain end-to-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior. In this work, we construct a new dataset called SAFECONV for the research of conversational safety: (1) Besides the utterance-level safety labels, SAFECONV also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SAFECONV provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SAFECONV, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots. Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The dataset is available at https://github.com/mianzhang/SafeConv.Warning: This paper contains cases that may be offensive or upsetting.","Zhang, Mian; Jin, Lifeng; Song, Linfeng; Mi, Haitao; Chen, Wenliang; Yu, Dong",,,SAFECONV: Explaining and Correcting Conversational Unsafe Behavior,,, ,Proceedings Paper ,,"One of the main challenges open-domain end-to-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior. In this work, we construct a new dataset called SAFECONV for the research of conversational safety: (1) Besides the utterance-level safety labels, SAFECONV also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SAFECONV provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SAFECONV, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots. Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The dataset is available at https://github.com/mianzhang/SafeConv.Warning: This paper contains cases that may be offensive or upsetting.",,,978-1-959429-72-2,22-35, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,Gen_dataset,
2465,"**Title**Detoxifying Text with MARCO: Controllable Revision with Experts and Anti-Experts

**Abstract**Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MARCO, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MARCO uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MARCO's rewrites are preferred 2.1x more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.","Hallinan, Skyler; Liu, Alisa; Choi, Yejin; Sap, Maarten",,,Detoxifying Text with MARCO: Controllable Revision with Experts and Anti-Experts,,, ,Proceedings Paper ,,"Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MARCO, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MARCO uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MARCO's rewrites are preferred 2.1x more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.",,,978-1-959429-71-5,228-242, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,detox,
2466,"**Title**Understanding the Unintended Effects of Human-Machine Moderation in Addressing Harassment within Online Communities

**Abstract**We set out to explore the unintended effects of human-machine moderation in mitigating harassment within online communities. We examine communities that use a block-list type bot to prevent harassment from the source of harassment. Drawing from social categorization and selective exposure theories, we theorize that employing a machine alongside humans for community moderation will create unintended adverse effects. Specifically, within the moderated focal community, we hypothesize an emboldening effect characterized by an increase in harassment among community members directed at their outgroup members. Additionally, we expect a disengaging effect, that is, a downward trend in the focal community's membership. Finally, in neighboring communities that share the same topic of discussion, we expect a spillover effect, that is, an increase in harassment. Employing Detoxify, a Bidirectional Encoder Representations from Transformers (BERT)-based model, we evaluate harassment scores in the focal community by analyzing 4 million Reddit comments across various communities. These scores serve as inputs for Bayesian Structural Time Series analysis, revealing evidence for both disengaging and spillover effects. For the emboldening effect, we use community-specific keywords in a predefined computer-assisted document classification approach, Keyword Assisted Topic Model (keyATM), to identify the target of harassment. We use mean comparison and regression discontinuity to assess the change in the level of harassment targeting outgroup members before and after the human-machine moderation implementation.","Nguyen, An; Rai, Arun; Maruping, Likoebe",,"Nguyen, An/0009-0008-4292-5964; Rai, Arun/0000-0002-3655-7543; Maruping, Likoebe/0000-0001-5105-6635",Understanding the Unintended Effects of Human-Machine Moderation in Addressing Harassment within Online Communities,41,2,10.1080/07421222.2024.2340831 ,Article ,,"We set out to explore the unintended effects of human-machine moderation in mitigating harassment within online communities. We examine communities that use a block-list type bot to prevent harassment from the source of harassment. Drawing from social categorization and selective exposure theories, we theorize that employing a machine alongside humans for community moderation will create unintended adverse effects. Specifically, within the moderated focal community, we hypothesize an emboldening effect characterized by an increase in harassment among community members directed at their outgroup members. Additionally, we expect a disengaging effect, that is, a downward trend in the focal community's membership. Finally, in neighboring communities that share the same topic of discussion, we expect a spillover effect, that is, an increase in harassment. Employing Detoxify, a Bidirectional Encoder Representations from Transformers (BERT)-based model, we evaluate harassment scores in the focal community by analyzing 4 million Reddit comments across various communities. These scores serve as inputs for Bayesian Structural Time Series analysis, revealing evidence for both disengaging and spillover effects. For the emboldening effect, we use community-specific keywords in a predefined computer-assisted document classification approach, Keyword Assisted Topic Model (keyATM), to identify the target of harassment. We use mean comparison and regression discontinuity to assess the change in the level of harassment targeting outgroup members before and after the human-machine moderation implementation.",0742-1222,1557-928X,,341-366, ,  ,,detection,
2467,"**Title**GoldenWind at SemEval-2021 Task 5: Orthrus - An Ensemble Approach to Identify Toxicity

**Abstract**Many new developments to detect and mitigate toxicity are currently being evaluated. We are particularly interested in the correlation between toxicity and the emotions expressed in online posts. While toxicity may be disguised by amending the wording of posts, emotions will not. Therefore, we describe here an ensemble method to identify toxicity and classify the emotions expressed on a corpus of annotated posts published by Task 5 of SemEval 2021-our analysis shows that the majority of such posts express anger, sadness and fear. Our method to identify toxicity combines a lexicon-based approach, which on its own achieves an F1 score of 61.07%, with a supervised learning approach, which on its own achieves an F1 score of 60%. When both methods are combined,","Palomino, Marco; Grad, Dawid; Bedwell, James",,,GoldenWind at SemEval-2021 Task 5: Orthrus - An Ensemble Approach to Identify Toxicity,,, ,Proceedings Paper ,,"Many new developments to detect and mitigate toxicity are currently being evaluated. We are particularly interested in the correlation between toxicity and the emotions expressed in online posts. While toxicity may be disguised by amending the wording of posts, emotions will not. Therefore, we describe here an ensemble method to identify toxicity and classify the emotions expressed on a corpus of annotated posts published by Task 5 of SemEval 2021-our analysis shows that the majority of such posts express anger, sadness and fear. Our method to identify toxicity combines a lexicon-based approach, which on its own achieves an F1 score of 61.07%, with a supervised learning approach, which on its own achieves an F1 score of 60%. When both methods are combined,",,,978-1-954085-70-1,860-864, , 15th International Workshops on Semantic Evaluation (SemEval)15th International Workshops on Semantic Evaluation (SemEval) ,,detection#methodology,
2468,"**Title**Fine-grained detoxification framework via instance-level prefixes for large language models

**Abstract**Large Language Models (LLMs) have demonstrated remarkable performance across various natural language processing (NLP) tasks. However, their practical usability is often compromised by a propensity to generate toxic content, such as insults, threats, and profanity, particularly in response to adversarial prompts. Several fine-tuning and decoding approaches have been employed to address this challenge to mitigate toxicity. Nevertheless, these methods typically necessitate additional resources, such as high-quality training data or auxiliary models, thereby incurring extra costs. In this paper, we propose a novel detoxification framework, Fine-Grained Detoxification via Instance-Level Prefixes (FGDILP), which effectively mitigates the generation of toxic text without incurring additional training costs. Specifically, FGDILP leverages contextualized representations in attention space by contrasting a positive prefix-prepended prompt against multiple negative prefix-prepended prompts at the instance level. This methodology facilitates the construction of fine-grained subtoxicity vectors, which are subsequently fused to adjust the original generation pathway when responding to raw prompts. Our results demonstrate that FGDILP enables controlled text generation concerning detoxification at both the utterance and context levels. While our method slightly impacts generation fluency and diversity, it significantly outperforms prompt-based baselines regarding detoxification effectiveness. Our code is available at https://github.com/xinykou/FGDILP.","Yi, Xin; Wang, Linlin; Wang, Xiaoling; He, Liang","He, Liang/CAF-0477-2022",,Fine-grained detoxification framework via instance-level prefixes for large language models,611,,10.1016/j.neucom.2024.128684 ,Article ,,"Large Language Models (LLMs) have demonstrated remarkable performance across various natural language processing (NLP) tasks. However, their practical usability is often compromised by a propensity to generate toxic content, such as insults, threats, and profanity, particularly in response to adversarial prompts. Several fine-tuning and decoding approaches have been employed to address this challenge to mitigate toxicity. Nevertheless, these methods typically necessitate additional resources, such as high-quality training data or auxiliary models, thereby incurring extra costs. In this paper, we propose a novel detoxification framework, Fine-Grained Detoxification via Instance-Level Prefixes (FGDILP), which effectively mitigates the generation of toxic text without incurring additional training costs. Specifically, FGDILP leverages contextualized representations in attention space by contrasting a positive prefix-prepended prompt against multiple negative prefix-prepended prompts at the instance level. This methodology facilitates the construction of fine-grained subtoxicity vectors, which are subsequently fused to adjust the original generation pathway when responding to raw prompts. Our results demonstrate that FGDILP enables controlled text generation concerning detoxification at both the utterance and context levels. While our method slightly impacts generation fluency and diversity, it significantly outperforms prompt-based baselines regarding detoxification effectiveness. Our code is available at https://github.com/xinykou/FGDILP.",0925-2312,1872-8286,,, ,  ,,detox,
2469,"**Title**WLV-RIT at SemEval-2021 Task 5: A Neural Transformer Framework for Detecting Toxic Spans

**Abstract**In recent years, the widespread use of social media has led to an increase in the generation of toxic and offensive content on online platforms. In response, social media platforms have worked on developing automatic detection methods and employing human moderators to cope with this deluge of offensive content. While various state-of-the-art statistical models have been applied to detect toxic posts, there are only a few studies that focus on detecting the words or expressions that make a post offensive. This motivates the organization of the SemEval-2021 Task 5: Toxic Spans Detection competition, which has provided participants with a dataset containing toxic spans annotation in English posts. In this paper, we present the WLV-RIT entry for the SemEval2021 Task 5. Our best performing neural transformer model achieves an 0.68 F1-Score. Furthermore, we develop an open-source framework for multilingual detection of offensive spans, i.e., MUDES, based on neural transformers that detect toxic spans in texts.","Ranasinghe, Tharindu; Sarkar, Diptanu; Zampieri, Marcos; Ororbia, Alexander","Ranasinghe, Tharindu/AAL-5855-2021",,WLV-RIT at SemEval-2021 Task 5: A Neural Transformer Framework for Detecting Toxic Spans,,, ,Proceedings Paper ,,"In recent years, the widespread use of social media has led to an increase in the generation of toxic and offensive content on online platforms. In response, social media platforms have worked on developing automatic detection methods and employing human moderators to cope with this deluge of offensive content. While various state-of-the-art statistical models have been applied to detect toxic posts, there are only a few studies that focus on detecting the words or expressions that make a post offensive. This motivates the organization of the SemEval-2021 Task 5: Toxic Spans Detection competition, which has provided participants with a dataset containing toxic spans annotation in English posts. In this paper, we present the WLV-RIT entry for the SemEval2021 Task 5. Our best performing neural transformer model achieves an 0.68 F1-Score. Furthermore, we develop an open-source framework for multilingual detection of offensive spans, i.e., MUDES, based on neural transformers that detect toxic spans in texts.",,,978-1-954085-70-1,833-840, , 15th International Workshops on Semantic Evaluation (SemEval)15th International Workshops on Semantic Evaluation (SemEval) ,,detection,
2470,"**Title**SmokerViT: A Transformer-Based Method for Smoker Recognition

**Abstract**Smoking has an economic and environmental impact on society due to the toxic substances it emits. Convolutional Neural Networks (CNNs) need help describing low-level features and can miss important information. Moreover, accurate smoker detection is vital with minimum false alarms. To answer the issue, the researchers of this paper have turned to a self-attention mechanism inspired by the ViT, which has displayed state-of-the-art performance in the classification task. To effectively enforce the smoking prohibition in non-smoking locations, this work presents a Vision Transformer-inspired model called SmokerViT for detecting smokers. Moreover, this research utilizes a locally curated dataset of 1120 images evenly distributed among the two classes (Smoking and NotSmoking). Further, this research performs augmentations on the smoker detection dataset to have many images with various representations to overcome the dataset size limitation. Unlike convolutional operations used in most existing works, the proposed SmokerViT model employs a self-attention mechanism in the Transformer block, making it suitable for the smoker classification problem. Besides, this work integrates the multi-layer perceptron head block in the SmokerViT model, which contains dense layers with rectified linear activation and linear kernel regularizer with L2 for the recognition task. This work presents an exhaustive analysis to prove the efficiency of the proposed SmokerViT model. The performance of the proposed SmokerViT performance is evaluated and compared with the existing methods, where it achieves an overall classification accuracy of 97.77%, with 98.21% recall and 97.35% precision, outperforming the state-of-the-art deep learning models, including convolutional neural networks (CNNs) and other vision transformer-based models.","Khan, Ali; Khan, Somaiya; Hassan, Bilal; Khan, Rizwan; Zheng, Zhonglong","Khan, Somaiya/KPB-1949-2024; Khan, Ali/JED-4557-2023","Khan, Dr. Ali/0000-0002-5364-645X",SmokerViT: A Transformer-Based Method for Smoker Recognition,77,1,10.32604/cmc.2023.040251 ,Article ,,"Smoking has an economic and environmental impact on society due to the toxic substances it emits. Convolutional Neural Networks (CNNs) need help describing low-level features and can miss important information. Moreover, accurate smoker detection is vital with minimum false alarms. To answer the issue, the researchers of this paper have turned to a self-attention mechanism inspired by the ViT, which has displayed state-of-the-art performance in the classification task. To effectively enforce the smoking prohibition in non-smoking locations, this work presents a Vision Transformer-inspired model called SmokerViT for detecting smokers. Moreover, this research utilizes a locally curated dataset of 1120 images evenly distributed among the two classes (Smoking and NotSmoking). Further, this research performs augmentations on the smoker detection dataset to have many images with various representations to overcome the dataset size limitation. Unlike convolutional operations used in most existing works, the proposed SmokerViT model employs a self-attention mechanism in the Transformer block, making it suitable for the smoker classification problem. Besides, this work integrates the multi-layer perceptron head block in the SmokerViT model, which contains dense layers with rectified linear activation and linear kernel regularizer with L2 for the recognition task. This work presents an exhaustive analysis to prove the efficiency of the proposed SmokerViT model. The performance of the proposed SmokerViT performance is evaluated and compared with the existing methods, where it achieves an overall classification accuracy of 97.77%, with 98.21% recall and 97.35% precision, outperforming the state-of-the-art deep learning models, including convolutional neural networks (CNNs) and other vision transformer-based models.",1546-2218,1546-2226,,403-424, ,  ,,out_of_scope,
2471,"**Title**Arabic Toxic Tweet Classification: Leveraging the AraBERT Model

**Abstract**Social media platforms have become the primary means of communication and information sharing, facilitating interactive exchanges among users. Unfortunately, these platforms also witness the dissemination of inappropriate and toxic content, including hate speech and insults. While significant efforts have been made to classify toxic content in the English language, the same level of attention has not been given to Arabic texts. This study addresses this gap by constructing a standardized Arabic dataset specifically designed for toxic tweet classification. The dataset is annotated automatically using Google's Perspective API and the expertise of three native Arabic speakers and linguists. To evaluate the performance of different models, we conduct a series of experiments using seven models: long short-term memory (LSTM), bidirectional LSTM, a convolutional neural network, a gated recurrent unit (GRU), bidirectional GRU, multilingual bidirectional encoder representations from transformers, and AraBERT. Additionally, we employ word embedding techniques. Our experimental findings demonstrate that the fine-tuned AraBERT model surpasses the performance of other models, achieving an impressive accuracy of 0.9960. Notably, this accuracy value outperforms similar approaches reported in recent literature. This study represents a significant advancement in Arabic toxic tweet classification, shedding light on the importance of addressing toxicity in social media platforms while considering diverse languages and cultures.","El Koshiry, Amr Mohamed; Eliwa, Entesar Hamed I.; Abd El-Hafeez, Tarek; Omar, Ahmed","omar, ahmed/CAH-3284-2022; EL KOSHIRY, AMR/KWV-1061-2024; Abd El-Hafeez, Tarek/L-5316-2013; Eliwa, Entesar/KVB-4564-2024","EL KOSHIRY, AMR/0000-0002-8790-3135; Abd El-Hafeez, Tarek/0000-0003-1785-1058; Eliwa, Entesar/0000-0003-3217-2889",Arabic Toxic Tweet Classification: Leveraging the AraBERT Model,7,4,10.3390/bdcc7040170 ,Article ,,"Social media platforms have become the primary means of communication and information sharing, facilitating interactive exchanges among users. Unfortunately, these platforms also witness the dissemination of inappropriate and toxic content, including hate speech and insults. While significant efforts have been made to classify toxic content in the English language, the same level of attention has not been given to Arabic texts. This study addresses this gap by constructing a standardized Arabic dataset specifically designed for toxic tweet classification. The dataset is annotated automatically using Google's Perspective API and the expertise of three native Arabic speakers and linguists. To evaluate the performance of different models, we conduct a series of experiments using seven models: long short-term memory (LSTM), bidirectional LSTM, a convolutional neural network, a gated recurrent unit (GRU), bidirectional GRU, multilingual bidirectional encoder representations from transformers, and AraBERT. Additionally, we employ word embedding techniques. Our experimental findings demonstrate that the fine-tuned AraBERT model surpasses the performance of other models, achieving an impressive accuracy of 0.9960. Notably, this accuracy value outperforms similar approaches reported in recent literature. This study represents a significant advancement in Arabic toxic tweet classification, shedding light on the importance of addressing toxicity in social media platforms while considering diverse languages and cultures.",,2504-2289,,, ,  ,,out_but_toxicity,
2472,"**Title**VISH-Pred: an ensemble of fine-tuned ESM models for protein toxicity prediction

**Abstract**Peptide- and protein-based therapeutics are becoming a promising treatment regimen for myriad diseases. Toxicity of proteins is the primary hurdle for protein-based therapies. Thus, there is an urgent need for accurate in silico methods for determining toxic proteins to filter the pool of potential candidates. At the same time, it is imperative to precisely identify non-toxic proteins to expand the possibilities for protein-based biologics. To address this challenge, we proposed an ensemble framework, called VISH-Pred, comprising models built by fine-tuning ESM2 transformer models on a large, experimentally validated, curated dataset of protein and peptide toxicities. The primary steps in the VISH-Pred framework are to efficiently estimate protein toxicities taking just the protein sequence as input, employing an under sampling technique to handle the humongous class-imbalance in the data and learning representations from fine-tuned ESM2 protein language models which are then fed to machine learning techniques such as Lightgbm and XGBoost. The VISH-Pred framework is able to correctly identify both peptides/proteins with potential toxicity and non-toxic proteins, achieving a Matthews correlation coefficient of 0.737, 0.716 and 0.322 and F1-score of 0.759, 0.696 and 0.713 on three non-redundant blind tests, respectively, outperforming other methods by over $10\%$ on these quality metrics. Moreover, VISH-Pred achieved the best accuracy and area under receiver operating curve scores on these independent test sets, highlighting the robustness and generalization capability of the framework. By making VISH-Pred available as an easy-to-use web server, we expect it to serve as a valuable asset for future endeavors aimed at discerning the toxicity of peptides and enabling efficient protein-based therapeutics.","Mall, Raghvendra; Singh, Ankita; Patel, Chirag N.; Guirimand, Gregory; Castiglione, Filippo","Guirimand, Gregory/KCK-1012-2024; Mall, Raghvendra/M-7132-2013","Mall, Raghvendra/0000-0003-1779-3150; Guirimand, Gregory/0000-0001-7978-7771",VISH-Pred: an ensemble of fine-tuned ESM models for protein toxicity prediction,25,4,10.1093/bib/bbae270 ,Article ,,"Peptide- and protein-based therapeutics are becoming a promising treatment regimen for myriad diseases. Toxicity of proteins is the primary hurdle for protein-based therapies. Thus, there is an urgent need for accurate in silico methods for determining toxic proteins to filter the pool of potential candidates. At the same time, it is imperative to precisely identify non-toxic proteins to expand the possibilities for protein-based biologics. To address this challenge, we proposed an ensemble framework, called VISH-Pred, comprising models built by fine-tuning ESM2 transformer models on a large, experimentally validated, curated dataset of protein and peptide toxicities. The primary steps in the VISH-Pred framework are to efficiently estimate protein toxicities taking just the protein sequence as input, employing an under sampling technique to handle the humongous class-imbalance in the data and learning representations from fine-tuned ESM2 protein language models which are then fed to machine learning techniques such as Lightgbm and XGBoost. The VISH-Pred framework is able to correctly identify both peptides/proteins with potential toxicity and non-toxic proteins, achieving a Matthews correlation coefficient of 0.737, 0.716 and 0.322 and F1-score of 0.759, 0.696 and 0.713 on three non-redundant blind tests, respectively, outperforming other methods by over $10\%$ on these quality metrics. Moreover, VISH-Pred achieved the best accuracy and area under receiver operating curve scores on these independent test sets, highlighting the robustness and generalization capability of the framework. By making VISH-Pred available as an easy-to-use web server, we expect it to serve as a valuable asset for future endeavors aimed at discerning the toxicity of peptides and enabling efficient protein-based therapeutics.",1467-5463,1477-4054,,, ,  ,,out_of_scope,
2473,"**Title**AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification

**Abstract**In light of the pandemic, the identification and processing of COVID-19-related text have emerged as critical research areas within the field of Natural Language Processing (NLP). With a growing reliance on online portals and social media for information exchange and interaction, a surge in online textual content, comprising disinformation, misinformation, fake news , and rumors has led to the phenomenon of an infodemic on the World Wide Web. Arabic, spoken by over 420 million people worldwide, stands as a significant low -resource language, lacking efficient tools or applications for the detection of COVID-19-related text. Additionally, the identification of COVID-19 text is an essential prerequisite task for detecting fake and toxic content associated with COVID19. This gap hampers crucial COVID information retrieval and processing necessary for policymakers and health authorities. Addressing this issue, this paper introduces an intelligent Arabic COVID-19 text identification system named 'AraCovTexFinder,' leveraging a fine-tuned fusion -based transformer model. Recognizing the challenges posed by a scarcity of related text corpora, substantial morphological variations in the language, and a deficiency of well -tuned hyperparameters, the proposed system aims to mitigate these hurdles. To support the proposed method, two corpora are developed: an Arabic embedding corpus (AraEC) and an Arabic COVID-19 text identification corpus (AraCoV). The study evaluates the performance of six transformer -based language models (mBERT, XML-RoBERTa, mDeBERTa-V3, mDistilBERT, BERT -Arabic, and AraBERT), 12 deep learning models (combining Word2Vec, GloVe, and FastText embedding with CNN, LSTM, VDCNN, and BiLSTM), and the newly introduced model AraCovTexFinder. Through extensive evaluation, AraCovTexFinder achieves a high accuracy of 98.89 +/- 0.001%, outperforming other baseline models, including transformer -based language and deep learning models. This research highlights the importance of specialized tools in low -resource languages to combat the infodemic relating to COVID-19, which can assist policymakers and health authorities in making informed decisions.","Hossain, Md. Rajib; Hoque, Mohammed Moshiul; Siddique, Nazmul; Dewan, Ali Akber","Hoque, Mohammed Moshiul/AAC-8902-2021; , Md. Rajib Hossain, PhD/GPF-5640-2022","Siddique, Nazmul/0000-0002-0642-2357; , Md. Rajib Hossain, PhD/0000-0002-7941-9124; Hoque, Mohammed Moshiul/0000-0001-8806-708X",AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification,133,,10.1016/j.engappai.2024.107987 ,Article ,,"In light of the pandemic, the identification and processing of COVID-19-related text have emerged as critical research areas within the field of Natural Language Processing (NLP). With a growing reliance on online portals and social media for information exchange and interaction, a surge in online textual content, comprising disinformation, misinformation, fake news , and rumors has led to the phenomenon of an infodemic on the World Wide Web. Arabic, spoken by over 420 million people worldwide, stands as a significant low -resource language, lacking efficient tools or applications for the detection of COVID-19-related text. Additionally, the identification of COVID-19 text is an essential prerequisite task for detecting fake and toxic content associated with COVID19. This gap hampers crucial COVID information retrieval and processing necessary for policymakers and health authorities. Addressing this issue, this paper introduces an intelligent Arabic COVID-19 text identification system named 'AraCovTexFinder,' leveraging a fine-tuned fusion -based transformer model. Recognizing the challenges posed by a scarcity of related text corpora, substantial morphological variations in the language, and a deficiency of well -tuned hyperparameters, the proposed system aims to mitigate these hurdles. To support the proposed method, two corpora are developed: an Arabic embedding corpus (AraEC) and an Arabic COVID-19 text identification corpus (AraCoV). The study evaluates the performance of six transformer -based language models (mBERT, XML-RoBERTa, mDeBERTa-V3, mDistilBERT, BERT -Arabic, and AraBERT), 12 deep learning models (combining Word2Vec, GloVe, and FastText embedding with CNN, LSTM, VDCNN, and BiLSTM), and the newly introduced model AraCovTexFinder. Through extensive evaluation, AraCovTexFinder achieves a high accuracy of 98.89 +/- 0.001%, outperforming other baseline models, including transformer -based language and deep learning models. This research highlights the importance of specialized tools in low -resource languages to combat the infodemic relating to COVID-19, which can assist policymakers and health authorities in making informed decisions.",0952-1976,1873-6769,,, ,  ,,out_of_scope,
2474,"**Title**Analyzing And Editing Inner Mechanisms of Backdoored Language Models

**Abstract**Poisoning of data sets is a potential security threat to large language models that can lead to backdoored models. A description of the internal mechanisms of backdoored language models and how they process trigger inputs, e.g., when switching to toxic language, has yet to be found. In this work, we study the internal representations of transformer-based backdoored language models and determine early-layer MLP modules as most important for the backdoor mechanism in combination with the initial embedding projection. We use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements that reduce the MLP module outputs to essentials for the backdoor mechanism. To this end, we introduce PCP ablation, where we replace transformer modules with low-rank matrices based on the principal components of their activations. We demonstrate our results on backdoored toy, backdoored large, and non-backdoored open-source models. We show that we can improve the backdoor robustness of large language models by locally constraining individual modules during fine-tuning on potentially poisonous data sets.Trigger warning: Offensive language.","Lamparth, Max; Reuel, Anka",,"Reuel, Ann-Katrin/0000-0002-7913-9296",Analyzing And Editing Inner Mechanisms of Backdoored Language Models,,,10.1145/3630106.3659042 ,Proceedings Paper ,,"Poisoning of data sets is a potential security threat to large language models that can lead to backdoored models. A description of the internal mechanisms of backdoored language models and how they process trigger inputs, e.g., when switching to toxic language, has yet to be found. In this work, we study the internal representations of transformer-based backdoored language models and determine early-layer MLP modules as most important for the backdoor mechanism in combination with the initial embedding projection. We use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements that reduce the MLP module outputs to essentials for the backdoor mechanism. To this end, we introduce PCP ablation, where we replace transformer modules with low-rank matrices based on the principal components of their activations. We demonstrate our results on backdoored toy, backdoored large, and non-backdoored open-source models. We show that we can improve the backdoor robustness of large language models by locally constraining individual modules during fine-tuning on potentially poisonous data sets.Trigger warning: Offensive language.",,,979-8-4007-0450-5,2362-2373, ," 6th ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)6th ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT) ",,methodology,
2475,"**Title**Construction of an antidepressant priority list based on functional, environmental, and health risks using an interpretable mixup-transformer deep learning model

**Abstract**As emerging pollutants, antidepressants (AD) must be urgently investigated for risk identification and assessment. This study constructed a comprehensive-effect risk-priority screening system (ADRank) for ADs by characterizing AD functionality, occurrence, persistence, bioaccumulation and toxicity based on the integrated assignment method. A classification model for ADs was constructed using an improved mixup-transformer deep learning method, and its classification accuracy was compared with those of other models. The accuracy of the proposed model improved by up to 23.25 % compared with the random forest model, and the reliability was 80 % more than that of the TOPSIS method. A priority screening candidate list was proposed to screen 33 highpriority ADs. Finally, SHapley Additive explanation (SHAP) visualization, molecular dynamics, and amino acid analysis were performed to analyze the correlation between AD structure and toxic receptor binding characteristics and reveal the differences in AD risk priority. ADs with more intramolecular hydrogen bonds, higher hydrophobicity, and electronegativity had a more significant risk. Van der Waals and electrostatic interactions were the primary influencing factors, and significant differences in the types and proportions of the main amino acids in the interaction between ADs and receptors were observed. The results of the study provide constructive schemes and insights for AD priority screening and risk management.","Sun, Peixuan; Liu, Huaishi; Zhao, Yuanyuan; Hao, Ning; Deng, Zhengyang; Zhao, Wenjin","Zhao, Wenjin/AAQ-9365-2020; Zhao, Yuanyuan/AAN-7654-2020; Deng, zhengyang/HZJ-7888-2023",,"Construction of an antidepressant priority list based on functional, environmental, and health risks using an interpretable mixup-transformer deep learning model",474,,10.1016/j.jhazmat.2024.134651 ,Article ,,"As emerging pollutants, antidepressants (AD) must be urgently investigated for risk identification and assessment. This study constructed a comprehensive-effect risk-priority screening system (ADRank) for ADs by characterizing AD functionality, occurrence, persistence, bioaccumulation and toxicity based on the integrated assignment method. A classification model for ADs was constructed using an improved mixup-transformer deep learning method, and its classification accuracy was compared with those of other models. The accuracy of the proposed model improved by up to 23.25 % compared with the random forest model, and the reliability was 80 % more than that of the TOPSIS method. A priority screening candidate list was proposed to screen 33 highpriority ADs. Finally, SHapley Additive explanation (SHAP) visualization, molecular dynamics, and amino acid analysis were performed to analyze the correlation between AD structure and toxic receptor binding characteristics and reveal the differences in AD risk priority. ADs with more intramolecular hydrogen bonds, higher hydrophobicity, and electronegativity had a more significant risk. Van der Waals and electrostatic interactions were the primary influencing factors, and significant differences in the types and proportions of the main amino acids in the interaction between ADs and receptors were observed. The results of the study provide constructive schemes and insights for AD priority screening and risk management.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2476,"**Title**Toxicity on Social Media During the 2022 Mpox Public Health Emergency: Quantitative Study of Topical and Network Dynamics

**Abstract**Background: Toxicity on social media, encompassing behaviors such as harassment, bullying, hate speech, and the dissemination of misinformation, has become a pressing social concern in the digital age. Its prevalence intensifies during periods of social crises and unrest, eroding a sense of safety and community. Such toxic environments can adversely impact the mental well-being of those exposed and further deepen societal divisions and polarization. The 2022 mpox outbreak, initially called monkeypox but later renamed to reduce stigma and address societal concerns, provides a relevant context for this issue. Objective: In this study, we conducted a comprehensive analysis of the toxic online discourse surrounding the 2022 mpox outbreak. We aimed to dissect its origins, characterize its nature and content, trace its dissemination patterns, and assess its broader societal implications, with the goal of providing insights that can inform strategies to mitigate such toxicity in future crises. Methods: We collected >1.6 million unique tweets and analyzed them with 5 dimensions: context, extent, content, speaker, and intent. Using topic modeling based on bidirectional encoder representations from transformers and social network community clustering, we delineated the toxic dynamics on Twitter. Results: By categorizing topics, we identified 5 high-level categories in the toxic online discourse on Twitter, including disease (20,281/43,521, 46.6%), health policy and health care (8400/43,521, 19.3%), homophobia (10,402/43,521, 23.9%), politics (2611/43,521, 6%), and racism (1784/43,521, 4.1%). Across these categories, users displayed negativity or controversial views on the mpox outbreak, highlighting the escalating political tensions and the weaponization of stigma during this infodemic. Through the toxicity diffusion networks of mentions (17,437 vertices with 3628 clusters), retweets (59,749 vertices with 3015 clusters), and the top users with the highest in-degree centrality, we found that retweets of toxic content were widespread, while influential users rarely engaged with or countered this toxicity through retweets. Conclusions: Our study introduces a comprehensive workflow that combines topical and network analyses to decode emerging social issues during crises. By tracking topical dynamics, we can track the changing popularity of toxic content on the internet, providing a better understanding of societal challenges. Network dynamics highlight key social media influencers and their intentions, suggesting that engaging with these central figures in toxic discourse can improve crisis communication and guide policy making.","Fan, Lizhou; Li, Lingyao; Hemphill, Libby","Hemphill, Libby/AAH-7062-2019",,Toxicity on Social Media During the 2022 Mpox Public Health Emergency: Quantitative Study of Topical and Network Dynamics,26,,10.2196/52997 ,Article ,,"Background: Toxicity on social media, encompassing behaviors such as harassment, bullying, hate speech, and the dissemination of misinformation, has become a pressing social concern in the digital age. Its prevalence intensifies during periods of social crises and unrest, eroding a sense of safety and community. Such toxic environments can adversely impact the mental well-being of those exposed and further deepen societal divisions and polarization. The 2022 mpox outbreak, initially called monkeypox but later renamed to reduce stigma and address societal concerns, provides a relevant context for this issue. Objective: In this study, we conducted a comprehensive analysis of the toxic online discourse surrounding the 2022 mpox outbreak. We aimed to dissect its origins, characterize its nature and content, trace its dissemination patterns, and assess its broader societal implications, with the goal of providing insights that can inform strategies to mitigate such toxicity in future crises. Methods: We collected >1.6 million unique tweets and analyzed them with 5 dimensions: context, extent, content, speaker, and intent. Using topic modeling based on bidirectional encoder representations from transformers and social network community clustering, we delineated the toxic dynamics on Twitter. Results: By categorizing topics, we identified 5 high-level categories in the toxic online discourse on Twitter, including disease (20,281/43,521, 46.6%), health policy and health care (8400/43,521, 19.3%), homophobia (10,402/43,521, 23.9%), politics (2611/43,521, 6%), and racism (1784/43,521, 4.1%). Across these categories, users displayed negativity or controversial views on the mpox outbreak, highlighting the escalating political tensions and the weaponization of stigma during this infodemic. Through the toxicity diffusion networks of mentions (17,437 vertices with 3628 clusters), retweets (59,749 vertices with 3015 clusters), and the top users with the highest in-degree centrality, we found that retweets of toxic content were widespread, while influential users rarely engaged with or countered this toxicity through retweets. Conclusions: Our study introduces a comprehensive workflow that combines topical and network analyses to decode emerging social issues during crises. By tracking topical dynamics, we can track the changing popularity of toxic content on the internet, providing a better understanding of societal challenges. Network dynamics highlight key social media influencers and their intentions, suggesting that engaging with these central figures in toxic discourse can improve crisis communication and guide policy making.",1438-8871,,,, ,  ,,detection,
2477,"**Title**Development of an Automated Moderator for Deliberative Events

**Abstract**Online communication platforms have revolutionized interpersonal interactions by transcending geographical barriers. While facilitating connectivity, these platforms have introduced challenges such as overcoming linguistic differences and preventing spam and offensive content diffusion. This is particularly pertinent in the context of deliberative events, where online platforms could be used to extend the inclusion of citizens in democratic decision-making. In traditional deliberative events, human moderators and translators were used to facilitate conversation; however, the need for these figures imposed a limit on both the number of deliberative events that could be organized and the number of participants. In response, this paper proposes an automated moderator for deliberative events. The moderator is developed in Python for the online communication platform Discord and can be used, thanks to the integrated AI (Artificial Intelligence) tools, to automatically manage conversation agendas, prevent spam and inappropriate language, analyze the sentiment of the conversation, and translate messages into multiple languages. In particular, three classifiers, based on a pre-trained BERT (Bidirection Encoder Representations from Transformers), were fine-tuned for spam detection, toxic comments classification, and sentiment analysis. These allow the moderator to automatically detect and remove spam and offensive messages in different languages, send warnings to users, alert administrators, and, after repeated warnings, impose bans. Additionally, a built-in translator, based on Meta's No Language Left Behind NLLB model, translates messages into five languages (Italian, English, French, German, and Polish). The developed bot was tested in a simulated deliberative event on a Discord server, demonstrating its ability to manage conversations and prevent linguistic abuse.","Bonechi, Simone","Bonechi, Simone/AIC-5356-2022","BONECHI, SIMONE/0000-0002-5540-3742",Development of an Automated Moderator for Deliberative Events,13,3,10.3390/electronics13030544 ,Article ,,"Online communication platforms have revolutionized interpersonal interactions by transcending geographical barriers. While facilitating connectivity, these platforms have introduced challenges such as overcoming linguistic differences and preventing spam and offensive content diffusion. This is particularly pertinent in the context of deliberative events, where online platforms could be used to extend the inclusion of citizens in democratic decision-making. In traditional deliberative events, human moderators and translators were used to facilitate conversation; however, the need for these figures imposed a limit on both the number of deliberative events that could be organized and the number of participants. In response, this paper proposes an automated moderator for deliberative events. The moderator is developed in Python for the online communication platform Discord and can be used, thanks to the integrated AI (Artificial Intelligence) tools, to automatically manage conversation agendas, prevent spam and inappropriate language, analyze the sentiment of the conversation, and translate messages into multiple languages. In particular, three classifiers, based on a pre-trained BERT (Bidirection Encoder Representations from Transformers), were fine-tuned for spam detection, toxic comments classification, and sentiment analysis. These allow the moderator to automatically detect and remove spam and offensive messages in different languages, send warnings to users, alert administrators, and, after repeated warnings, impose bans. Additionally, a built-in translator, based on Meta's No Language Left Behind NLLB model, translates messages into five languages (Italian, English, French, German, and Polish). The developed bot was tested in a simulated deliberative event on a Discord server, demonstrating its ability to manage conversations and prevent linguistic abuse.",,2079-9292,,, ,  ,,detection,
2478,"**Title**A New Generation of Perspective API: Efficient Multilingual Character-level Transformers

**Abstract**On the world wide web, toxic content detectors are a crucial line of defense against potentially hateful and offensive messages. As such, building highly effective classifiers that enable a safer internet is an important research area. Moreover, the web is a highly multilingual, cross-cultural community that develops its own lingo over time. As such, it is crucial to develop models that are effective across a diverse range of languages, usages, and styles. In this paper, we present the fundamentals behind the next version of the Perspective API from Google Jigsaw. At the heart of the approach is a single multilingual token-free Charformer model that is applicable across a range of languages, domains, and tasks. We demonstrate that by forgoing static vocabularies, we gain flexibility across a variety of settings. We additionally outline the techniques employed to make such a byte-level model efficient and feasible for productionization. Through extensive experiments on multilingual toxic comment classification benchmarks derived from real API traffic and evaluation on an array of code-switching, covert toxicity, emoji-based hate, human-readable obfuscation, distribution shift, and bias evaluation settings, we show that our proposed approach outperforms strong baselines. Finally, we present our findings from deploying this system in production.","Lees, Alyssa; Tran, Vinh Q.; Tay, Yi; Sorensen, Jeffrey; Gupta, Jai; Metzler, Donald; Vasserman, Lucy",,,A New Generation of Perspective API: Efficient Multilingual Character-level Transformers,,,10.1145/3534678.3539147 ,Proceedings Paper ,,"On the world wide web, toxic content detectors are a crucial line of defense against potentially hateful and offensive messages. As such, building highly effective classifiers that enable a safer internet is an important research area. Moreover, the web is a highly multilingual, cross-cultural community that develops its own lingo over time. As such, it is crucial to develop models that are effective across a diverse range of languages, usages, and styles. In this paper, we present the fundamentals behind the next version of the Perspective API from Google Jigsaw. At the heart of the approach is a single multilingual token-free Charformer model that is applicable across a range of languages, domains, and tasks. We demonstrate that by forgoing static vocabularies, we gain flexibility across a variety of settings. We additionally outline the techniques employed to make such a byte-level model efficient and feasible for productionization. Through extensive experiments on multilingual toxic comment classification benchmarks derived from real API traffic and evaluation on an array of code-switching, covert toxicity, emoji-based hate, human-readable obfuscation, distribution shift, and bias evaluation settings, we show that our proposed approach outperforms strong baselines. Finally, we present our findings from deploying this system in production.",,,978-1-4503-9385-0,3197-3207, , 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KKD)28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KKD) ,,detection,
2479,"**Title**HATE SPEECH DETECTION IN LOW-RESOURCE BODO AND ASSAMESE TEXTS WITH ML-DL AND BERT MODELS

**Abstract**Hate speech detection research is a recent sizzling topic in natural language processing (NLP). Unburdened uses of social media platforms make people over-opinionative, which crosses the limit of leaving comments and posts toxic. A toxic outlook increases violence towards the neighbour, state, country, and continent. Several laws have been introduced in different countries to end the emergency problem. Now, all the media platforms have started working on restricting hate posts or comments. Hate speech detection is generally a text classification problem if considered a supervised observation. To tackle text in terms of computation perspective is challenging because of its semantic and complex grammatical nature. Resource-rich languages leverage their richness, whereas resource scarce language suffers significantly from a lack of dataset. This paper makes a multifaceted contribution encompassing resource generation, experimentation with Machine Learning (ML), Deep Learning (DL) and state-of-the-art transformer-based models, and a comprehensive evaluation of model performance, including thorough error analysis. In the realm of resource generation, it adds to the North-East Indian Hate Speech tagged dataset (NEIHS version 1), which encompasses two languages: Assamese and Bodo.","Ghosh, Koyel; Senapati, Apurbalal; Narzary, Mwnthai; Brahma, Maharaj","Ghosh, Koyel/JKJ-1118-2023; Senapati, Apurbalal/AAS-4087-2021",,HATE SPEECH DETECTION IN LOW-RESOURCE BODO AND ASSAMESE TEXTS WITH ML-DL AND BERT MODELS,24,4,10.12694/scpe.v24i4.2469 ,Article ,,"Hate speech detection research is a recent sizzling topic in natural language processing (NLP). Unburdened uses of social media platforms make people over-opinionative, which crosses the limit of leaving comments and posts toxic. A toxic outlook increases violence towards the neighbour, state, country, and continent. Several laws have been introduced in different countries to end the emergency problem. Now, all the media platforms have started working on restricting hate posts or comments. Hate speech detection is generally a text classification problem if considered a supervised observation. To tackle text in terms of computation perspective is challenging because of its semantic and complex grammatical nature. Resource-rich languages leverage their richness, whereas resource scarce language suffers significantly from a lack of dataset. This paper makes a multifaceted contribution encompassing resource generation, experimentation with Machine Learning (ML), Deep Learning (DL) and state-of-the-art transformer-based models, and a comprehensive evaluation of model performance, including thorough error analysis. In the realm of resource generation, it adds to the North-East Indian Hate Speech tagged dataset (NEIHS version 1), which encompasses two languages: Assamese and Bodo.",1895-1767,,,941-955, ,  ,,out_but_toxicity,
2480,"**Title**RETRACTED: An Automated Toxicity Classification on Social Media Using LSTM and Word Embedding (Retracted Article)

**Abstract**The automated identification of toxicity in texts is a crucial area in text analysis since the social media world is replete with unfiltered content that ranges from mildly abusive to downright hateful. Researchers have found an unintended bias and unfairness caused by training datasets, which caused an inaccurate classification of toxic words in context. In this paper, several approaches for locating toxicity in texts are assessed and presented aiming to enhance the overall quality of text classification. General unsupervised methods were used depending on the state-of-art models and external embeddings to improve the accuracy while relieving bias and enhancing F1-score. Suggested approaches used a combination of long short-term memory (LSTM) deep learning model with Glove word embeddings and LSTM with word embeddings generated by the Bidirectional Encoder Representations from Transformers (BERT), respectively. These models were trained and tested on large secondary qualitative data containing a large number of comments classified as toxic or not. Results found that acceptable accuracy of 94% and an F1-score of 0.89 were achieved using LSTM with BERT word embeddings in the binary classification of comments (toxic and nontoxic). A combination of LSTM and BERT performed better than both LSTM unaccompanied and LSTM with Glove word embedding. This paper tries to solve the problem of classifying comments with high accuracy by pertaining models with larger corpora of text (high-quality word embedding) rather than the training data solely.","Alsharef, Ahmad; Aggarwal, Karan; Sonia; Koundal, Deepika; Alyami, Hashem; Ameyed, Darine","Koundal, Deepika/I-9927-2019; Aggarwal, Karan/AAR-5617-2020",", Sonia/0000-0002-0779-8065; Alsharef, Ahmad/0000-0002-9113-7859",RETRACTED: An Automated Toxicity Classification on Social Media Using LSTM and Word Embedding (Retracted Article),2022,,10.1155/2022/8467349 ,Article; Retracted Publication ,,"The automated identification of toxicity in texts is a crucial area in text analysis since the social media world is replete with unfiltered content that ranges from mildly abusive to downright hateful. Researchers have found an unintended bias and unfairness caused by training datasets, which caused an inaccurate classification of toxic words in context. In this paper, several approaches for locating toxicity in texts are assessed and presented aiming to enhance the overall quality of text classification. General unsupervised methods were used depending on the state-of-art models and external embeddings to improve the accuracy while relieving bias and enhancing F1-score. Suggested approaches used a combination of long short-term memory (LSTM) deep learning model with Glove word embeddings and LSTM with word embeddings generated by the Bidirectional Encoder Representations from Transformers (BERT), respectively. These models were trained and tested on large secondary qualitative data containing a large number of comments classified as toxic or not. Results found that acceptable accuracy of 94% and an F1-score of 0.89 were achieved using LSTM with BERT word embeddings in the binary classification of comments (toxic and nontoxic). A combination of LSTM and BERT performed better than both LSTM unaccompanied and LSTM with Glove word embedding. This paper tries to solve the problem of classifying comments with high accuracy by pertaining models with larger corpora of text (high-quality word embedding) rather than the training data solely.",1687-5265,1687-5273,,, ,  ,,detection,
2481,"**Title**Toxicity in Spanish News Comments and its Relationship with Constructiveness

**Abstract**Online news comments are a critical source of information and opinion, but they often become a breeding ground for toxic discourse and incivility. Detecting toxicity in these comments is essential to understand and mitigate this problem. This paper presents a corpus of Spanish news comments labeled with toxicity (NECOS-TOX) and conducts a series of experiments using several machine learning algorithms, including different language models based on transformers. Our findings show that Spanish language models, such as BETO, are capable of detecting toxicity in Spanish news comments. Additionally, we investigated the relationship between toxicity and constructiveness in these comments and found that there is no clear correlation between the two factors. These results provide insights into the complexities of online discourse and highlight the need for further research to better understand the relationship between toxicity and constructiveness in Spanish news comments.","Lopez-Ubeda, Pilar; Plaza-del-Arco, Flor Miriam; Diaz-Galiano, Manuel C.; Martin-Valdivia, M. Teresa","López-Úbeda, Pilar/AAS-2488-2021; del Arco, Flor/AAH-1390-2021",,Toxicity in Spanish News Comments and its Relationship with Constructiveness,,73,10.26342/2024-73-3 ,Article ,,"Online news comments are a critical source of information and opinion, but they often become a breeding ground for toxic discourse and incivility. Detecting toxicity in these comments is essential to understand and mitigate this problem. This paper presents a corpus of Spanish news comments labeled with toxicity (NECOS-TOX) and conducts a series of experiments using several machine learning algorithms, including different language models based on transformers. Our findings show that Spanish language models, such as BETO, are capable of detecting toxicity in Spanish news comments. Additionally, we investigated the relationship between toxicity and constructiveness in these comments and found that there is no clear correlation between the two factors. These results provide insights into the complexities of online discourse and highlight the need for further research to better understand the relationship between toxicity and constructiveness in Spanish news comments.",1135-5948,1989-7553,,43-53, ,  ,,out_but_toxicity,
2482,"**Title**QCon at SemEval-2023 Task 10: Data Augmentation and Model Ensembling for Detection of Online Sexism

**Abstract**The web contains an abundance of user-generated content. While this content is useful for many applications, it poses many challenges due to the presence of offensive, biased, and overall toxic language. In this work, we present a system that identifies and classifies sexist content at different levels of granularity. Using transformer-based models, we explore the value of data augmentation, use of ensemble methods, and leverage in-context learning using foundation models to tackle the task. We evaluate the different components of our system both quantitatively and qualitatively. Our best systems achieve an F-1 score of 0.84 for the binary classification task - aiming to identify whether a given content is sexist or not and 0.64 and 0.47 for the two multi-class tasks that aim to identify the coarse and fine-grained types of sexism present in the given content respectively.","Feely, Weston; Gupta, Prabhakar; Mohanty, Manas; Chon, Timothy; Kundu, Tuhin; Singh, Vijit; Atluri, Sandeep; Roosta, Tanya; Ghaderi, Viviane; Schulam, Peter; Elfardy, Heba",,,QCon at SemEval-2023 Task 10: Data Augmentation and Model Ensembling for Detection of Online Sexism,,, ,Proceedings Paper ,,"The web contains an abundance of user-generated content. While this content is useful for many applications, it poses many challenges due to the presence of offensive, biased, and overall toxic language. In this work, we present a system that identifies and classifies sexist content at different levels of granularity. Using transformer-based models, we explore the value of data augmentation, use of ensemble methods, and leverage in-context learning using foundation models to tackle the task. We evaluate the different components of our system both quantitatively and qualitatively. Our best systems achieve an F-1 score of 0.84 for the binary classification task - aiming to identify whether a given content is sexist or not and 0.64 and 0.47 for the two multi-class tasks that aim to identify the coarse and fine-grained types of sexism present in the given content respectively.",,,978-1-959429-99-9,1260-1270, , 17th International Workshop on Semantic Evaluation (SemEval)17th International Workshop on Semantic Evaluation (SemEval) ,,detection,
2483,"**Title**Statistical adaptive modeling for kitchen waste detection in complex scenes

**Abstract**Automatic detection of kitchen waste is of great significance, which provides support for its subsequent full quantitative consumption and harmless treatment. In addition, manual sorting of kitchen waste is inefficient and toxic waste is harmful to human health, making automatic detection of kitchen waste technology crucial. Automatic detection of kitchen waste in complex scenes faces the challenge of diversity of category outlines and uneven distribution. In this paper, we propose a detector based on statistical adaptive modeling(namely SA-Det) for the automatic detection of kitchen waste in complex scenes. Firstly, to solve the issue of diversity of category outlines, we propose a category statistics adaptive (CSA) module. The CSA module constructs dynamic thresholds for each instance to accurately assign positive and negative samples by fusing category statistics and instance shape information, thereby improving detection performance. Moreover, to solve the issue of uneven distribution, we propose a distribution adaptive (DA) module, which dynamically adjusts the loss weights by adaptively sensing the number of labels during training process. Extensive experiments on our constructed kitchen waste dataset (KWD) demonstrate that SA-Det consistently and significantly improves the performance of existing state-of-the-art methods (e.g., Rotated_RetinaNet (Lin et al., 2017) and RoI_Transformer (Ding et al., 2019)) by around 2% to 3.5%.","Feng, Hao; Fang, Leyuan; Ding, Shuaiyu; Yu, Junwu; He, Min; Tang, Lin","Fang, Leyuan/G-1468-2011",,Statistical adaptive modeling for kitchen waste detection in complex scenes,161,,10.1016/j.asoc.2024.111743 ,Article ,,"Automatic detection of kitchen waste is of great significance, which provides support for its subsequent full quantitative consumption and harmless treatment. In addition, manual sorting of kitchen waste is inefficient and toxic waste is harmful to human health, making automatic detection of kitchen waste technology crucial. Automatic detection of kitchen waste in complex scenes faces the challenge of diversity of category outlines and uneven distribution. In this paper, we propose a detector based on statistical adaptive modeling(namely SA-Det) for the automatic detection of kitchen waste in complex scenes. Firstly, to solve the issue of diversity of category outlines, we propose a category statistics adaptive (CSA) module. The CSA module constructs dynamic thresholds for each instance to accurately assign positive and negative samples by fusing category statistics and instance shape information, thereby improving detection performance. Moreover, to solve the issue of uneven distribution, we propose a distribution adaptive (DA) module, which dynamically adjusts the loss weights by adaptively sensing the number of labels during training process. Extensive experiments on our constructed kitchen waste dataset (KWD) demonstrate that SA-Det consistently and significantly improves the performance of existing state-of-the-art methods (e.g., Rotated_RetinaNet (Lin et al., 2017) and RoI_Transformer (Ding et al., 2019)) by around 2% to 3.5%.",1568-4946,1872-9681,,, ,  ,,out_of_scope,
2484,"**Title**Using Explainable AI (XAI) for Identification of Subjectivity in Hate Speech Annotations for Low-Resource Languages

**Abstract**The proliferation of hate speech on digital platforms has become a significant issue, and automated content moderation systems built on machine learning are a proposed solution. However, they face challenges in multilingual and low-resource settings due to the need for extensive labelled data. This paper introduces an explainable AI framework designed to identify annotation discrepancies in low-resource languages, focusing on Hindi, the third most-spoken language worldwide, which lacks comprehensive research in hate speech detection. By examining the labelling quality of the Hate speech and Offensive Content Identification in English and IndoAryan Languages (HASOC) challenge, we use unsupervised learning methods to extract topical variations and annotation behavior and apply these features in an explainable AI-based classification model, TabNet. We release a relabelled Hindi hate speech benchmark dataset with label-flipping information and related metadata to facilitate research in this area. The source code has also been released for reproducibility purposes.Please be advised that this work contains examples of toxic content","Sawant, Madhuri; Qureshi, M. Atif; Younus, Arjumand; Caton, Simon","Qureshi, Muhammad Atif/GRR-3698-2022; Sawant, Dr Madhuri/JFS-0384-2023",,Using Explainable AI (XAI) for Identification of Subjectivity in Hate Speech Annotations for Low-Resource Languages,,,10.1145/3677117.3685006 ,Proceedings Paper ,,"The proliferation of hate speech on digital platforms has become a significant issue, and automated content moderation systems built on machine learning are a proposed solution. However, they face challenges in multilingual and low-resource settings due to the need for extensive labelled data. This paper introduces an explainable AI framework designed to identify annotation discrepancies in low-resource languages, focusing on Hindi, the third most-spoken language worldwide, which lacks comprehensive research in hate speech detection. By examining the labelling quality of the Hate speech and Offensive Content Identification in English and IndoAryan Languages (HASOC) challenge, we use unsupervised learning methods to extract topical variations and annotation behavior and apply these features in an explainable AI-based classification model, TabNet. We release a relabelled Hindi hate speech benchmark dataset with label-flipping information and related metadata to facilitate research in this area. The source code has also been released for reproducibility purposes.Please be advised that this work contains examples of toxic content",,,979-8-4007-1082-7,10-17, , Conference on Open Challenges in Online Social Media (OASIS)Conference on Open Challenges in Online Social Media (OASIS) ,,out_but_toxicity,
2485,"**Title**Enhanced detection of Aspergillus flavus in peanut kernels using a multi-scale attention transformer (MSAT): Advancements in food safety and contamination analysis

**Abstract**In this study, a multi-scale attention transformer (MSAT) was coupled with hyperspectral imaging for classifying peanut kernels contaminated with diverse Aspergillus flavus fungi. The results underscored that the MSAT significantly outperformed classic deep learning models, due to its sophisticated multi-scale attention mechanism which enhanced its classification capabilities. The multi-scale attention mechanism was utilized by employing several multi-head attention layers to focus on both fine-scale and broad-scale features. It also integrated a series of scale processing layers to capture features at different resolutions and incorporated a self-attention mechanism to integrate information across different levels. The MSAT model achieved outstanding performance in different classification tasks, particularly in distinguishing healthy peanut kernels from those contaminated with aflatoxigenic fungi, with test accuracy achieving 98.42 +/- 0.22%. However, it faced challenges in differentiating peanut kernels contaminated with aflatoxigenic fungi from those with non-aflatoxigenic contamination. Visualization of attention weights explicitly revealed that the MSAT model's multi-scale attention mechanism progressively refined its focus from broad spatial-spectral features to more specialized signatures. Overall, the MSAT model's advanced processing capabilities marked a notable advancement in the field of food quality safety, offering a robust and reliable tool for the rapid and accurate detection of Aspergillus flavus contaminations in food.","Guo, Zhen; Zhang, Jing; Wang, Haifang; Dong, Haowei; Li, Shiling; Shao, Xijun; Huang, Jingcheng; Yin, Xiang; Zhang, Qi; Guo, Yemin; Sun, Xia; Darwish, Ibrahim","guo, zhen/IQW-9862-2023",,Enhanced detection of Aspergillus flavus in peanut kernels using a multi-scale attention transformer (MSAT): Advancements in food safety and contamination analysis,423,,10.1016/j.ijfoodmicro.2024.110831 ,Article ,,"In this study, a multi-scale attention transformer (MSAT) was coupled with hyperspectral imaging for classifying peanut kernels contaminated with diverse Aspergillus flavus fungi. The results underscored that the MSAT significantly outperformed classic deep learning models, due to its sophisticated multi-scale attention mechanism which enhanced its classification capabilities. The multi-scale attention mechanism was utilized by employing several multi-head attention layers to focus on both fine-scale and broad-scale features. It also integrated a series of scale processing layers to capture features at different resolutions and incorporated a self-attention mechanism to integrate information across different levels. The MSAT model achieved outstanding performance in different classification tasks, particularly in distinguishing healthy peanut kernels from those contaminated with aflatoxigenic fungi, with test accuracy achieving 98.42 +/- 0.22%. However, it faced challenges in differentiating peanut kernels contaminated with aflatoxigenic fungi from those with non-aflatoxigenic contamination. Visualization of attention weights explicitly revealed that the MSAT model's multi-scale attention mechanism progressively refined its focus from broad spatial-spectral features to more specialized signatures. Overall, the MSAT model's advanced processing capabilities marked a notable advancement in the field of food quality safety, offering a robust and reliable tool for the rapid and accurate detection of Aspergillus flavus contaminations in food.",0168-1605,1879-3460,,, ,  ,,out_of_scope,
2486,"**Title**DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models

**Abstract**Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in their capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications such as healthcare and finance - where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially because GPT-4 follows (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/.","Wang, Boxin; Chen, Weixin; Pei, Hengzhi; Xie, Chulin; Kang, Mintong; Zhang, Chenhui; Xu, Chejian; Xiong, Zidi; Dutta, Ritik; Schaeffer, Rylan; Truong, Sang T.; Arora, Simran; Mazeika, Mantas; Hendrycks, Dan; Lin, Zinan; Cheng, Yu; Koyejo, Sanmi; Song, Dawn; Li, Bo","Xiong, Zidi/KBB-8747-2024; 陈, 炜鑫/GZM-3682-2022","Arora, Simran/0009-0002-7044-4689; Truong, Sang/0000-0001-8069-9410",DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models,,, ,Proceedings Paper ,,"Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in their capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications such as healthcare and finance - where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially because GPT-4 follows (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/.",1049-5258,,*****************,, , 37th Conference on Neural Information Processing Systems (NeurIPS)37th Conference on Neural Information Processing Systems (NeurIPS) ,,Gen_dataset#evaluation,
2487,"**Title**Techno-Economic Feasibility of Hybrid Energy Systems Installation in Pakistan

**Abstract**This research work proposed an optimal hybrid microgrid design for Riphah International University (RIU), Lahore, Pakistan, that ensures a continuous and affordable energy supply by harnessing reliable energy sources. The design factors include the various considerations such as energy resource availability, environmental sustainability, and financial viability. The proposed hybrid renewable energy system integrates the national grid, solar photovoltaic (PV) technology, a battery bank, and a converter to fulfill the energy requirements of RIU. In order to develop the most efficient design, various factors are taken into account, including electrical load, solar irradiation, ambient temperature on campus, lifespan and efficiency of PV modules, degradation factor, cost considerations, battery longevity, energy prices from the national grid, occurrences of load shedding, and the environmental impact in terms of toxic emissions. The net present cost (NPC) factor is also considered to make the design more cost effective. The simulations conducted using HOMER Pro software yielded 932 possible solutions, among which the proposed hybrid microgrid design emerged as the most viable with an NPC of $0.483 million and 99.3% renewable energy utilization. The worst design, which utilized a national grid and diesel generator, resulted in an NPC of $1.89 million with 0% renewable energy integration. The proposed hybrid microgrid design among 932 models established by HOMER Pro software using PV connected to a national grid, and a storage system represents the most optimal solution for RIU Lahore Campus by considering all the necessary factors and requirements.","Khaled, Osamah; Zahid, Muhammad; Zahid, Tausif; Ilahi, Tehseen","Zahid, Muhammad/ABC-2983-2021; Iqbal, Muhammad/JXN-5503-2024",", Zahid/0000-0001-9520-2542; Ilahi, Tehseen/0000-0002-2625-4506",Techno-Economic Feasibility of Hybrid Energy Systems Installation in Pakistan,12,,10.1109/ACCESS.2024.3376409 ,Article ,,"This research work proposed an optimal hybrid microgrid design for Riphah International University (RIU), Lahore, Pakistan, that ensures a continuous and affordable energy supply by harnessing reliable energy sources. The design factors include the various considerations such as energy resource availability, environmental sustainability, and financial viability. The proposed hybrid renewable energy system integrates the national grid, solar photovoltaic (PV) technology, a battery bank, and a converter to fulfill the energy requirements of RIU. In order to develop the most efficient design, various factors are taken into account, including electrical load, solar irradiation, ambient temperature on campus, lifespan and efficiency of PV modules, degradation factor, cost considerations, battery longevity, energy prices from the national grid, occurrences of load shedding, and the environmental impact in terms of toxic emissions. The net present cost (NPC) factor is also considered to make the design more cost effective. The simulations conducted using HOMER Pro software yielded 932 possible solutions, among which the proposed hybrid microgrid design emerged as the most viable with an NPC of $0.483 million and 99.3% renewable energy utilization. The worst design, which utilized a national grid and diesel generator, resulted in an NPC of $1.89 million with 0% renewable energy integration. The proposed hybrid microgrid design among 932 models established by HOMER Pro software using PV connected to a national grid, and a storage system represents the most optimal solution for RIU Lahore Campus by considering all the necessary factors and requirements.",2169-3536,,,41643-41658, ,  ,,out_of_scope,
2488,"**Title**Applying machine learning to assess emotional reactions to video game content streamed on Spanish Twitch channels

**Abstract**This research explores for the first time the application of machine learning to detect emotional responses in video game streaming channels, specifically on Twitch, the most widely used platform for broadcasting content. Analyzing sentiment in gaming contexts is difficult due to the brevity of messages, the lack of context, and the use of informal language, which is exacerbated in the gaming environment by slang, abbreviations, memes, and jargon. First, a novel Spanish corpus was created from chat messages on Spanish video game Twitch channels, manually labeled for polarity and emotions. It is noteworthy as the first Spanish corpus for analyzing social responses on Twitch. Secondly, machine learning algorithms were used to classify polarity and emotions offering promising evaluations. The methodology followed in this work consists of three main steps: (1) Extracting Twitch chat messages from Spanish streamers' channels related to gaming events and gameplays; (2) Processing and selecting the messages to form the corpus and manually annotating polarity and emotions; and (3) Applying machine learning models to detect polarity and emotions in the created corpus. The results have shown that a Bidirectional Encoder Representation from Transformers (BERT) based model excels with 78% accuracy in polarity detection, while deep learning and Random Forest models reach around 70%. For emotion detection, the BERT model performs best with 68%, followed by deep learning with 55%. It is worth noting that emotion detection is more challenging due to the subjective interpretation of emotions in the complex communicative context of video gaming on platforms such as Twitch. The use of supervised learning techniques, together with the rigorous corpus labeling process and the subsequent corpus pre-processing methodology, has helped to mitigate these challenges, and the algorithms have performed well. The main limitations of the research involve category and video game representation balance. Finally, it is important to stress that the integration of machine learning in video games and on Twitch is innovative, by allowing the identification of viewers' emotions on streamers' channels. This innovation could bring benefits such as a better understanding of audience sentiment, improving content and audience retention, providing personalized recommendations and detecting toxic behavior in chats.","Merayo, Noemi; Cotelo, Rosalia; Carratala-Saez, Rocio; Andujar, Francisco J.","Carratalá-Sáez, Rocío/AAJ-3371-2021; Andújar, Francisco/AAF-2520-2021; Merayo, Noemi/L-5241-2014","Merayo, Noemi/0000-0002-6920-0778; Andujar Munoz, Francisco J./0000-0001-8884-7334",Applying machine learning to assess emotional reactions to video game content streamed on Spanish Twitch channels,88,,10.1016/j.csl.2024.101651 ,Article ,,"This research explores for the first time the application of machine learning to detect emotional responses in video game streaming channels, specifically on Twitch, the most widely used platform for broadcasting content. Analyzing sentiment in gaming contexts is difficult due to the brevity of messages, the lack of context, and the use of informal language, which is exacerbated in the gaming environment by slang, abbreviations, memes, and jargon. First, a novel Spanish corpus was created from chat messages on Spanish video game Twitch channels, manually labeled for polarity and emotions. It is noteworthy as the first Spanish corpus for analyzing social responses on Twitch. Secondly, machine learning algorithms were used to classify polarity and emotions offering promising evaluations. The methodology followed in this work consists of three main steps: (1) Extracting Twitch chat messages from Spanish streamers' channels related to gaming events and gameplays; (2) Processing and selecting the messages to form the corpus and manually annotating polarity and emotions; and (3) Applying machine learning models to detect polarity and emotions in the created corpus. The results have shown that a Bidirectional Encoder Representation from Transformers (BERT) based model excels with 78% accuracy in polarity detection, while deep learning and Random Forest models reach around 70%. For emotion detection, the BERT model performs best with 68%, followed by deep learning with 55%. It is worth noting that emotion detection is more challenging due to the subjective interpretation of emotions in the complex communicative context of video gaming on platforms such as Twitch. The use of supervised learning techniques, together with the rigorous corpus labeling process and the subsequent corpus pre-processing methodology, has helped to mitigate these challenges, and the algorithms have performed well. The main limitations of the research involve category and video game representation balance. Finally, it is important to stress that the integration of machine learning in video games and on Twitch is innovative, by allowing the identification of viewers' emotions on streamers' channels. This innovation could bring benefits such as a better understanding of audience sentiment, improving content and audience retention, providing personalized recommendations and detecting toxic behavior in chats.",0885-2308,1095-8363,,, ,  ,,out_of_scope,
2489,"**Title**A techno-economic framework for optimizing multi-area power dispatch in microgrids with tie-line constraints

**Abstract**Fuel-fired power plants are the primary electricity sources in Saudi Arabia. This investigation aims to reduce the overall costs and emissions of electricity production from thermal units operated by the Shuqaiq Water and Electricity Company. It also considers practical thermoelectric constraints, such as power losses, ramp-rate constraints, and environmental optimization functions, to align with the sustainability goals of Saudi Vision 2030. Optimizing electric energy delivery is crucial within an energy control center. The focus of this work is to develop an advanced computational technique that reduces reliance on fossil fuels and minimizes the production cost of electricity, while also considering environmental emissions as an optimization function. An examination was conducted through two distinct practical case studies with power demand of 850 MW-one involving renewable sources and the other without-to assess the effectiveness of the hybrid crow search and JAYA optimization algorithm in optimizing performance. This system includes a multi-area setup with limitations on the tie-line power flow constraints. Additionally, the study also involved RETScreen modelling to assess the practical financial, emission, and benchmark analysis of a proposed integrated solar plant. This analyses offers a thorough assessment of the facility's performance and reliability in practical situations. This study serves as a motivating factor for energy operators, stakeholders, governmental organizations, and grid administrators to invest resources in environmentally-friendly initiatives. The simulation results showed that the proposed approach successfully reduced the electricity cost by 2.29% and 3.70% in hybrid energy networks while effectively handling the system constraints. In addition, the analysis revealed that the optimization algorithm effectively decreased toxic emissions from power plants while also supporting the sustainability objectives of United Nations SDG-7 and Saudi Vision 2030 through the successful integration of renewable sources.","Khalid, Muhammad","Khalid, Muhammad/G-2305-2016","Khalid, Muhammad/0000-0001-7779-5348",A techno-economic framework for optimizing multi-area power dispatch in microgrids with tie-line constraints,231,,10.1016/j.renene.2024.120854 ,Article ,,"Fuel-fired power plants are the primary electricity sources in Saudi Arabia. This investigation aims to reduce the overall costs and emissions of electricity production from thermal units operated by the Shuqaiq Water and Electricity Company. It also considers practical thermoelectric constraints, such as power losses, ramp-rate constraints, and environmental optimization functions, to align with the sustainability goals of Saudi Vision 2030. Optimizing electric energy delivery is crucial within an energy control center. The focus of this work is to develop an advanced computational technique that reduces reliance on fossil fuels and minimizes the production cost of electricity, while also considering environmental emissions as an optimization function. An examination was conducted through two distinct practical case studies with power demand of 850 MW-one involving renewable sources and the other without-to assess the effectiveness of the hybrid crow search and JAYA optimization algorithm in optimizing performance. This system includes a multi-area setup with limitations on the tie-line power flow constraints. Additionally, the study also involved RETScreen modelling to assess the practical financial, emission, and benchmark analysis of a proposed integrated solar plant. This analyses offers a thorough assessment of the facility's performance and reliability in practical situations. This study serves as a motivating factor for energy operators, stakeholders, governmental organizations, and grid administrators to invest resources in environmentally-friendly initiatives. The simulation results showed that the proposed approach successfully reduced the electricity cost by 2.29% and 3.70% in hybrid energy networks while effectively handling the system constraints. In addition, the analysis revealed that the optimization algorithm effectively decreased toxic emissions from power plants while also supporting the sustainability objectives of United Nations SDG-7 and Saudi Vision 2030 through the successful integration of renewable sources.",0960-1481,1879-0682,,, ,  ,,out_of_scope,
2490,"**Title**Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens

**Abstract**Abstract:The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP.","Venkit, Pranav Narayanan",,"Narayanan Venkit, Pranav/0000-0002-5671-0461",Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens,,,10.1145/3600211.3604754 ,Proceedings Paper ,,"Abstract:The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP.",,,979-8-4007-0231-0,1004-1005, ," AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES)AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES) ",,out_of_scope,
2491,"**Title**Exploring ChatGPT for Toxicity Detection in GitHub

**Abstract**Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.","Mishra, Shyamal; Chatterjee, Preetha","Chatterjee, Preetha/AAS-2995-2021","Chatterjee, Preetha/0000-0003-3057-7807",Exploring ChatGPT for Toxicity Detection in GitHub,,,10.1145/3639476.3639777 ,Proceedings Paper ,,"Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.",,,979-8-4007-0500-7,6-10, , IEEE/ACM 46th International Conference on Software Engineering - New Ideas and Emerging Results (ICSE-NIER)IEEE/ACM 46th International Conference on Software Engineering - New Ideas and Emerging Results (ICSE-NIER) ,,detection,
2492,"**Title**Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks

**Abstract**Many text classification tasks are inherently ambiguous, which results in automatic systems having a high risk of making mistakes, in spite of using advanced machine learning models. For example, toxicity detection in user-generated content is a subjective task, and notions of toxicity can be annotated according to a variety of definitions that can be in conflict with one another. Instead of relying solely on automatic solutions, moderation of the most difficult and ambiguous cases can be delegated to human workers. Potential mistakes in automated classification can be identified by using uncertainty estimation (UE) techniques. Although UE is a rapidly growing field within natural language processing, we find that state-of-the-art UE methods estimate only epistemic uncertainty and show poor performance, or under-perform trivial methods for ambiguous tasks such as toxicity detection. We argue that in order to create robust uncertainty estimation methods for ambiguous tasks it is necessary to account also for aleatoric uncertainty. In this paper, we propose a new uncertainty estimation method that combines epistemic and aleatoric UE methods. We show that by using our hybrid method, we can outperform state-of-the-art UE methods for toxicity detection and other ambiguous text classification tasks(1).","Vazhentsev, Artem; Kuzmin, Gleb; Tsvigun, Akim; Panchenko, Alexander; Panov, Maxim; Burtsev, Mikhail; Shelmanov, Artem","Panchenko, Alexander/AAQ-7808-2021; Shelmanov, Artem/AAE-2008-2019; Tsvigun, Akim/HTT-2881-2023; Burtsev, Mikhail/G-6293-2010; Kuzmin, Gleb/KUC-6084-2024",,Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks,,, ,Proceedings Paper ,,"Many text classification tasks are inherently ambiguous, which results in automatic systems having a high risk of making mistakes, in spite of using advanced machine learning models. For example, toxicity detection in user-generated content is a subjective task, and notions of toxicity can be annotated according to a variety of definitions that can be in conflict with one another. Instead of relying solely on automatic solutions, moderation of the most difficult and ambiguous cases can be delegated to human workers. Potential mistakes in automated classification can be identified by using uncertainty estimation (UE) techniques. Although UE is a rapidly growing field within natural language processing, we find that state-of-the-art UE methods estimate only epistemic uncertainty and show poor performance, or under-perform trivial methods for ambiguous tasks such as toxicity detection. We argue that in order to create robust uncertainty estimation methods for ambiguous tasks it is necessary to account also for aleatoric uncertainty. In this paper, we propose a new uncertainty estimation method that combines epistemic and aleatoric UE methods. We show that by using our hybrid method, we can outperform state-of-the-art UE methods for toxicity detection and other ambiguous text classification tasks(1).",,,978-1-959429-72-2,11659-11681, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,detection,
2493,"**Title**Exploring Moral Principles Exhibited in OSS: A Case Study on GitHub Heated Issues

**Abstract**To foster collaboration and inclusivity in Open Source Software (OSS) projects, it is crucial to understand and detect patterns of toxic language that may drive contributors away, especially those from underrepresented communities. Although machine learning-based toxicity detection tools trained on domain-specific data have shown promise, their design lacks an understanding of the unique nature and triggers of toxicity in OSS discussions, highlighting the need for further investigation. In this study, we employ Moral Foundations Theory to examine the relationship between moral principles and toxicity in OSS. Specifically, we analyze toxic communications in GitHub issue threads to identify and understand five types of moral principles exhibited in text, and explore their potential association with toxic behavior. Our preliminary findings suggest a possible link between moral principles and toxic comments in OSS communications, with each moral principle associated with at least one type of toxicity. The potential of MFT in toxicity detection warrants further investigation.","Ehsani, Ramtin; Rezapour, Rezvaneh; Chatterjee, Preetha","Chatterjee, Preetha/AAS-2995-2021","Ehsani, Ramtin/0000-0003-1517-7135; Chatterjee, Preetha/0000-0003-3057-7807",Exploring Moral Principles Exhibited in OSS: A Case Study on GitHub Heated Issues,,,10.1145/3611643.3613077 ,Proceedings Paper ,,"To foster collaboration and inclusivity in Open Source Software (OSS) projects, it is crucial to understand and detect patterns of toxic language that may drive contributors away, especially those from underrepresented communities. Although machine learning-based toxicity detection tools trained on domain-specific data have shown promise, their design lacks an understanding of the unique nature and triggers of toxicity in OSS discussions, highlighting the need for further investigation. In this study, we employ Moral Foundations Theory to examine the relationship between moral principles and toxicity in OSS. Specifically, we analyze toxic communications in GitHub issue threads to identify and understand five types of moral principles exhibited in text, and explore their potential association with toxic behavior. Our preliminary findings suggest a possible link between moral principles and toxic comments in OSS communications, with each moral principle associated with at least one type of toxicity. The potential of MFT in toxicity detection warrants further investigation.",,,979-8-4007-0327-0,2092-2096, , 31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE) ,,detection,
2494,"**Title**Performance and Risk Trade-offs for Multi-word Text Prediction at Scale Warning: The paper contains examples which the reader might find offensive.

**Abstract**Large Language Models such as GPT-3 are well-suited for text prediction tasks, which can help and delight users during text composition. LLMs are known to generate ethically inappropriate predictions even for seemingly innocuous contexts. Toxicity detection followed by filtering is a common strategy for mitigating the harm from such predictions. However, as we shall argue in this paper, in the context of text prediction, it is not sufficient to detect and filter toxic content. One also needs to ensure factual correctness and group-level fairness of the predictions; failing to do so can make the system ineffective and nonsensical at best, and unfair and detrimental to the users at worst. We discuss the gaps and challenges of toxicity detection approaches - from blocklist-based approaches to sophisticated state-of-the-art neural classifiers - by evaluating them on the text prediction task for English against a manually crafted CheckList of harms targeted at different groups and different levels of severity.","Vashishtha, Aniket; Prasad, S. Sai Krishna; Bajaj, Payal; Chaudhary, Vishrav; Cook, Kate; Dandapat, Sandipan; Sitaram, Sunayana; Choudhury, Monojit",,,Performance and Risk Trade-offs for Multi-word Text Prediction at Scale Warning: The paper contains examples which the reader might find offensive.,,, ,Proceedings Paper ,,"Large Language Models such as GPT-3 are well-suited for text prediction tasks, which can help and delight users during text composition. LLMs are known to generate ethically inappropriate predictions even for seemingly innocuous contexts. Toxicity detection followed by filtering is a common strategy for mitigating the harm from such predictions. However, as we shall argue in this paper, in the context of text prediction, it is not sufficient to detect and filter toxic content. One also needs to ensure factual correctness and group-level fairness of the predictions; failing to do so can make the system ineffective and nonsensical at best, and unfair and detrimental to the users at worst. We discuss the gaps and challenges of toxicity detection approaches - from blocklist-based approaches to sophisticated state-of-the-art neural classifiers - by evaluating them on the text prediction task for English against a manually crafted CheckList of harms targeted at different groups and different levels of severity.",,,978-1-959429-47-0,2226-2242, , 17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,detection,
2495,"**Title**(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs

**Abstract**Large Language Models (LLMs) are increasingly integrated into software applications. Downstream application developers often access LLMs through APIs provided as a service. However, LLM APIs are often updated silently and scheduled to be deprecated, forcing users to continuously adapt to evolving models. This can cause performance regression and affect prompt design choices, as evidenced by our case study on toxicity detection. Based on our case study, we emphasize the need for and re-examine the concept of regression testing for evolving LLM APIs. We argue that regression testing LLMs requires fundamental changes to traditional testing approaches, due to different correctness notions, prompting brittleness, and non-determinism in LLM APIs.","Ma, Wanqin; Yang, Chenyang; Kastner, Christian",,"Yang, Chenyang/0000-0001-5016-7296; Kastner, Christian/0000-0002-4450-4572; Ma, Wanqin/0009-0002-3376-179X",(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs,,,10.1145/3644815.3644950 ,Proceedings Paper ,,"Large Language Models (LLMs) are increasingly integrated into software applications. Downstream application developers often access LLMs through APIs provided as a service. However, LLM APIs are often updated silently and scheduled to be deprecated, forcing users to continuously adapt to evolving models. This can cause performance regression and affect prompt design choices, as evidenced by our case study on toxicity detection. Based on our case study, we emphasize the need for and re-examine the concept of regression testing for evolving LLM APIs. We argue that regression testing LLMs requires fundamental changes to traditional testing approaches, due to different correctness notions, prompting brittleness, and non-determinism in LLM APIs.",,,979-8-4007-0591-5,166-171, , IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI (CAIN)IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI (CAIN) ,,out_of_scope,
2496,"**Title**Promoting Positive Discourse: Advancing AI-Powered Content Moderation with Explainability and User Rephrasing

**Abstract**Nothing is good or bad only thinking makes it so - is a well-known phrase we might have heard while growing up. Social media and discussion platforms provide unsupervised and an unbound stage to share and discuss ideas, opinions and thoughts. Apart from these they knowingly or unknowingly pave way to a space that generates and harbors toxicity. The contents of these are sometimes targeted on a certain group of people based on gender, caste, religion and countries not keeping in mind the civic sense. This paper introduces an innovative AI-powered system for content moderation, designed to combat online toxicity. The system utilizes a rule-table-based filter for efficient initial screening, blocking content with clear violations. For nuanced toxicity detection, we employ an ensemble of RoBERTa and BiLSTM models. Promoting collaboration, we integrate GPT-3.5 to generate rephrasing suggestions, empow- ering users to modify their language constructively. The system incorporates explainable AI to clarify model decisions, enhancing transparency and understanding. Finally, a user feedback loop ensures the system's ongoing evolution, maintaining its relevance to community standards.","Ananthajothi, K.; Meenakshi, R.; Monica, S.","K, Ananthajothi/AGE-3388-2022",,Promoting Positive Discourse: Advancing AI-Powered Content Moderation with Explainability and User Rephrasing,,,10.1109/ACCAI61061.2024.10601796 ,Proceedings Paper ,,"Nothing is good or bad only thinking makes it so - is a well-known phrase we might have heard while growing up. Social media and discussion platforms provide unsupervised and an unbound stage to share and discuss ideas, opinions and thoughts. Apart from these they knowingly or unknowingly pave way to a space that generates and harbors toxicity. The contents of these are sometimes targeted on a certain group of people based on gender, caste, religion and countries not keeping in mind the civic sense. This paper introduces an innovative AI-powered system for content moderation, designed to combat online toxicity. The system utilizes a rule-table-based filter for efficient initial screening, blocking content with clear violations. For nuanced toxicity detection, we employ an ensemble of RoBERTa and BiLSTM models. Promoting collaboration, we integrate GPT-3.5 to generate rephrasing suggestions, empow- ering users to modify their language constructively. The system incorporates explainable AI to clarify model decisions, enhancing transparency and understanding. Finally, a user feedback loop ensures the system's ongoing evolution, maintaining its relevance to community standards.",,,979-8-3503-8943-2; 979-8-3503-8944-9; 979-8-3503-8945-6,, ," International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI)International Conference on Advances in Computing, Communication and Applied Informatics (ACCAI) ",,detection#methodology,
2497,"**Title**A Wide Evaluation of ChatGPT on Affective Computing Tasks

**Abstract**With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking problems, by modelling them as pairwise ranking classification. We compare ChatGPT against more traditional NLP methods, such as end-to-end recurrent neural networks and transformers. The results demonstrate the emergent abilities of the ChatGPT models on a wide range of affective computing problems, where GPT-3.5 and especially GPT-4 have shown strong performance on many problems, particularly the ones related to sentiment, emotions, or toxicity. The ChatGPT models fell short for problems with implicit signals, such as engagement measurement and subjectivity detection.","Amin, Mostafa M.; Mao, Rui; Cambria, Erik; Schuller, Bjoern W.","Mao, Rui/ABM-7006-2022",,A Wide Evaluation of ChatGPT on Affective Computing Tasks,15,4,10.1109/TAFFC.2024.3419593 ,Article ,,"With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking problems, by modelling them as pairwise ranking classification. We compare ChatGPT against more traditional NLP methods, such as end-to-end recurrent neural networks and transformers. The results demonstrate the emergent abilities of the ChatGPT models on a wide range of affective computing problems, where GPT-3.5 and especially GPT-4 have shown strong performance on many problems, particularly the ones related to sentiment, emotions, or toxicity. The ChatGPT models fell short for problems with implicit signals, such as engagement measurement and subjectivity detection.",1949-3045,,,2204-2212, ,  ,,detection,
2498,"**Title**Chain of Explanation: New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech

**Abstract**Recent studies have exploited advanced generative language models to generate Natural Language Explanations (NLE) for why a certain text could be hateful. We propose the Chain of Explanation (CoE) Prompting method, using the heuristic words and target group, to generate high-quality NLE for implicit hate speech. We improved the BLUE score from 44.0 to 62.3 for NLE generation by providing accurate target information. We then evaluate the quality of generated NLE using various automatic metrics and human annotations of informativeness and clarity scores.","Huang, Fan; Kwak, Haewoon; An, Jisun",,"Huang, Fan/0000-0002-3097-0484; Kwak, Haewoon/0000-0003-1418-0834",Chain of Explanation: New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech,,,10.1145/3543873.3587320 ,Proceedings Paper ,,"Recent studies have exploited advanced generative language models to generate Natural Language Explanations (NLE) for why a certain text could be hateful. We propose the Chain of Explanation (CoE) Prompting method, using the heuristic words and target group, to generate high-quality NLE for implicit hate speech. We improved the BLUE score from 44.0 to 62.3 for NLE generation by providing accurate target information. We then evaluate the quality of generated NLE using various automatic metrics and human annotations of informativeness and clarity scores.",,,978-1-4503-9416-1,90-93, , 32nd World Wide Web Conference (WWW)32nd World Wide Web Conference (WWW) ,,detection,
2499,"**Title**Multi-modal Deep Learning for Detecting Toxicity in Transcribed-Audio Conversations

**Abstract**Toxicology can take many forms, ranging from overt approaches such as abusive language and bullying to more subtle means. Almost all corners of the Internet are affected by this practice, but gaming, news, blogging, and social media are particularly prevalent. Using a Convolutional Spiking Neural Network (CSNN) leveraging multi-modality, we explore a method for detecting toxicity. To enhance the capability of toxicity detection, the method utilizes both text and audio features from the DeToxy dataset. The CSNN has been composed of two modalities, one for text and one for audio, and a late fusion was applied to combine the final output. An embedding layer has been applied to textual data in the first step. Text tokens can be mapped into vector representations in order to extract features. In the audio modality, the convolution and max-pooling layers are two-dimensional; a flattening layer is applied prior to the linear layer. We fuse audio and text outputs using a fusion layer. Concatenating the spikes from the two modalities will construct the fusion layer.","El Sayad, Ismail; Gourde, Josue; Pott, Jake; Muthayan, Sachin; Singh, Simranjit","El Sayad, Ismail/HDM-5409-2022",,Multi-modal Deep Learning for Detecting Toxicity in Transcribed-Audio Conversations,1018,,10.1007/978-3-031-62269-4_24 ,Proceedings Paper ,,"Toxicology can take many forms, ranging from overt approaches such as abusive language and bullying to more subtle means. Almost all corners of the Internet are affected by this practice, but gaming, news, blogging, and social media are particularly prevalent. Using a Convolutional Spiking Neural Network (CSNN) leveraging multi-modality, we explore a method for detecting toxicity. To enhance the capability of toxicity detection, the method utilizes both text and audio features from the DeToxy dataset. The CSNN has been composed of two modalities, one for text and one for audio, and a late fusion was applied to combine the final output. An embedding layer has been applied to textual data in the first step. Text tokens can be mapped into vector representations in order to extract features. In the audio modality, the convolution and max-pooling layers are two-dimensional; a flattening layer is applied prior to the linear layer. We fuse audio and text outputs using a fusion layer. Concatenating the spikes from the two modalities will construct the fusion layer.",2367-3370,2367-3389,978-3-031-62271-7; 978-3-031-62269-4; 978-3-031-62268-7,340-348, , Computing ConferenceComputing Conference ,,out_but_toxicity,
2500,"**Title**TextCheater: A Query-Efficient Textual Adversarial Attack in the Hard-Label Setting

**Abstract**Designing a query-efficient attack strategy to generate high-quality adversarial examples under the hard-label black-box setting is a fundamental yet challenging problem, especially in natural language processing (NLP). The process of searching for adversarial examples has many uncertainties (e.g., an unknown impact on the target model's prediction of the added perturbation) when confidence scores cannot be accessed, which must be compensated for with a large number of queries. To address this issue, we propose TextCheater, a decision-based metaheuristic search method that performs a query-efficient textual adversarial attack task by prohibiting invalid searches. The strategies of multiple initialization points and Tabu search are also introduced to keep the search process from falling into a local optimum. We apply our approach to three state-of-the-art language models (i.e., BERT, wordLSTM, and wordCNN) across six benchmark datasets and eight real-world commercial sentiment analysis platforms/models. Furthermore, we evaluate the Robustly optimized BERT pretraining Approach (RoBERTa) and models that enhance their robustness by adversarial training on toxicity detection and text classification tasks. The results demonstrate that our method minimizes the number of queries required for crafting plausible adversarial text while outperforming existing attack methods in the attack success rate, fluency of output sentences, and similarity between the original text and its adversary.","Peng, Hao; Guo, Shixin; Zhao, Dandan; Zhang, Xuhong; Han, Jianmin; Ji, Shouling; Yang, Xing; Zhong, Ming","Zhong, Ming/AHC-9485-2022; peng, hao/C-2042-2016; Yang, Xing/HHS-6130-2022","peng, hao/0000-0003-0586-7132; Zhong, Ming/0000-0002-9132-3782; zhao, dandan/0000-0001-9375-2997; Guo, Shixin/0009-0003-1763-5221; Yang, Xing/0000-0002-8824-1356",TextCheater: A Query-Efficient Textual Adversarial Attack in the Hard-Label Setting,21,4,10.1109/TDSC.2023.3339802 ,Article ,,"Designing a query-efficient attack strategy to generate high-quality adversarial examples under the hard-label black-box setting is a fundamental yet challenging problem, especially in natural language processing (NLP). The process of searching for adversarial examples has many uncertainties (e.g., an unknown impact on the target model's prediction of the added perturbation) when confidence scores cannot be accessed, which must be compensated for with a large number of queries. To address this issue, we propose TextCheater, a decision-based metaheuristic search method that performs a query-efficient textual adversarial attack task by prohibiting invalid searches. The strategies of multiple initialization points and Tabu search are also introduced to keep the search process from falling into a local optimum. We apply our approach to three state-of-the-art language models (i.e., BERT, wordLSTM, and wordCNN) across six benchmark datasets and eight real-world commercial sentiment analysis platforms/models. Furthermore, we evaluate the Robustly optimized BERT pretraining Approach (RoBERTa) and models that enhance their robustness by adversarial training on toxicity detection and text classification tasks. The results demonstrate that our method minimizes the number of queries required for crafting plausible adversarial text while outperforming existing attack methods in the attack success rate, fluency of output sentences, and similarity between the original text and its adversary.",1545-5971,1941-0018,,3901-3916, ,  ,,detection#methodology,
2501,"**Title**Identifying Spurious Correlations for Robust Text Classification

**Abstract**The predictions of text classifiers are often driven by spurious correlations - e.g., the term Spielberg correlates with positively reviewed movies, even though the term itself does not semantically convey a positive sentiment. In this paper, we propose a method to distinguish spurious and genuine correlations in text classification. We treat this as a supervised classification problem, using features derived from treatment effect estimators to distinguish spurious correlations from genuine ones. Due to the generic nature of these features and their small dimensionality, we find that the approach works well even with limited training examples, and that it is possible to transport the word classifier to new domains. Experiments on four datasets (sentiment classification and toxicity detection) suggest that using this approach to inform feature selection also leads to more robust classification, as measured by improved worst-case accuracy on the samples affected by spurious correlations.","Wang, Zhao; Culotta, Aron","C, Aron/JFS-4299-2023",,Identifying Spurious Correlations for Robust Text Classification,,, ,Proceedings Paper ,,"The predictions of text classifiers are often driven by spurious correlations - e.g., the term Spielberg correlates with positively reviewed movies, even though the term itself does not semantically convey a positive sentiment. In this paper, we propose a method to distinguish spurious and genuine correlations in text classification. We treat this as a supervised classification problem, using features derived from treatment effect estimators to distinguish spurious correlations from genuine ones. Due to the generic nature of these features and their small dimensionality, we find that the approach works well even with limited training examples, and that it is possible to transport the word classifier to new domains. Experiments on four datasets (sentiment classification and toxicity detection) suggest that using this approach to inform feature selection also leads to more robust classification, as measured by improved worst-case accuracy on the samples affected by spurious correlations.",,,978-1-952148-90-3,, , Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP) ,,detection#methodology,
2502,"**Title**Designing Closed-Loop Models for Task Allocation

**Abstract**Automatically assigning tasks to people is challenging because human performance can vary across tasks for many reasons. This challenge is further compounded in real-life settings in which no oracle exists to assess the quality of human decisions and task assignments made. Instead, we find ourselves in a closed decision-making loop in which the same fallible human decisions we rely on in practice must also be used to guide task allocation. How can imperfect and potentially biased human decisions train an accurate allocation model? Our key insight is to exploit weak prior information on human-task similarity to bootstrap model training. We show that the use of such a weak prior can improve task allocation accuracy, even when human decision-makers are fallible and biased. We present both theoretical analysis and empirical evaluation over synthetic data and a social media toxicity detection task. Results demonstrate the efficacy of our approach.","Keswani, Vijay; Celis, Elisa; Kenthapadi, Krishnaram; Lease, Matthew",,,Designing Closed-Loop Models for Task Allocation,368,,10.3233/FAIA230072 ,Proceedings Paper ,,"Automatically assigning tasks to people is challenging because human performance can vary across tasks for many reasons. This challenge is further compounded in real-life settings in which no oracle exists to assess the quality of human decisions and task assignments made. Instead, we find ourselves in a closed decision-making loop in which the same fallible human decisions we rely on in practice must also be used to guide task allocation. How can imperfect and potentially biased human decisions train an accurate allocation model? Our key insight is to exploit weak prior information on human-task similarity to bootstrap model training. We show that the use of such a weak prior can improve task allocation accuracy, even when human decision-makers are fallible and biased. We present both theoretical analysis and empirical evaluation over synthetic data and a social media toxicity detection task. Results demonstrate the efficacy of our approach.",0922-6389,1879-8314,978-1-64368-394-2; 978-1-64368-395-9,17-32, , 2nd International Conference on Hybrid Human-Artificial Intelligence (HHAI)2nd International Conference on Hybrid Human-Artificial Intelligence (HHAI) ,,detection#methodology,
2503,"**Title**Is ChatGPT beter than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech

**Abstract**Recent studies have alarmed that many online hate speeches are implicit. With its subtle nature, the explainability of the detection of such hateful speech has been a challenging problem. In this work, we examine whether ChatGPT can be used for providing natural language explanations (NLEs) for implicit hateful speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs and conduct user studies to evaluate their qualities by comparison with human-written NLEs. We discuss the potential and limitations of ChatGPT in the context of implicit hateful speech research.","Huang, Fan; Kwak, Haewoon; An, Jisun",,"An, Jisun/0000-0002-4353-8009; Kwak, Haewoon/0000-0003-1418-0834; Huang, Fan/0000-0002-3097-0484",Is ChatGPT beter than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech,,,10.1145/3543873.3587368 ,Proceedings Paper ,,"Recent studies have alarmed that many online hate speeches are implicit. With its subtle nature, the explainability of the detection of such hateful speech has been a challenging problem. In this work, we examine whether ChatGPT can be used for providing natural language explanations (NLEs) for implicit hateful speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs and conduct user studies to evaluate their qualities by comparison with human-written NLEs. We discuss the potential and limitations of ChatGPT in the context of implicit hateful speech research.",,,978-1-4503-9416-1,294-297, , 32nd World Wide Web Conference (WWW)32nd World Wide Web Conference (WWW) ,,detection#methodology,
2504,"**Title**From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models

**Abstract**Warning: content in this paper may be upsetting or offensive to some readers.Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second one, often hateful or provocative, to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, in the sentence we need to end the cosmopolitan experiment, the word cosmopolitan likely means worldly to many, but secretly means Jewish to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians' speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3's performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks of such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources for future research in modeling dogwhistles and mitigating their online harms.","Mendelsohn, Julia; Le Bras, Ronan; Choi, Yejin; Sap, Maarten",,,From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models,,, ,Proceedings Paper ,,"Warning: content in this paper may be upsetting or offensive to some readers.Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second one, often hateful or provocative, to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, in the sentence we need to end the cosmopolitan experiment, the word cosmopolitan likely means worldly to many, but secretly means Jewish to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians' speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3's performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks of such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources for future research in modeling dogwhistles and mitigating their online harms.",,,978-1-959429-72-2,15162-15180, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,Gen_dataset#detection#evaluation#methodology,
2505,"**Title**Causal keyword driven reliable text classification with large language model feedback

**Abstract**Recent studies show Pre-trained Language Models (PLMs) tend to shortcut learning, reducing effectiveness with Out-Of-Distribution (OOD) samples, prompting research on the impact of shortcuts and robust causal features by interpretable methods for text classification. However, current approaches encounter two primary challenges. Firstly, black-box interpretable methods often yield incorrect causal keywords. Secondly, existing methods do not differentiate between shortcuts and causal keywords, often employing a unified approach to deal with them. To address the first challenge, we propose a framework that incorporates Large Language Model's feedback into the process of identifying shortcuts and causal keywords. Specifically, we transform causal feature extraction into a word-level binary labeling task with the aid of ChatGPT. For the second challenge, we introduce a multi-grained shortcut mitigation framework. This framework includes two auxiliary tasks aimed at addressing shortcuts and causal features separately: shortcut reconstruction and counterfactual contrastive learning. These tasks enhance PLMs at both the token and sample granularity levels, respectively. Experimental results show that the proposed method achieves an average performance improvement of more than 1% under the premise of four different language model as the backbones for sentiment classification and toxicity detection tasks on 8 datasets compared with the most recent baseline methods.","Song, Rui; Li, Yingji; Tian, Mingjie; Wang, Hanwen; Giunchiglia, Fausto; Xu, Hao",,"Li, Yingji/0000-0002-3575-1395; Giunchiglia, Fausto/0000-0002-5903-6150",Causal keyword driven reliable text classification with large language model feedback,62,2,10.1016/j.ipm.2024.103964 ,Article ,,"Recent studies show Pre-trained Language Models (PLMs) tend to shortcut learning, reducing effectiveness with Out-Of-Distribution (OOD) samples, prompting research on the impact of shortcuts and robust causal features by interpretable methods for text classification. However, current approaches encounter two primary challenges. Firstly, black-box interpretable methods often yield incorrect causal keywords. Secondly, existing methods do not differentiate between shortcuts and causal keywords, often employing a unified approach to deal with them. To address the first challenge, we propose a framework that incorporates Large Language Model's feedback into the process of identifying shortcuts and causal keywords. Specifically, we transform causal feature extraction into a word-level binary labeling task with the aid of ChatGPT. For the second challenge, we introduce a multi-grained shortcut mitigation framework. This framework includes two auxiliary tasks aimed at addressing shortcuts and causal features separately: shortcut reconstruction and counterfactual contrastive learning. These tasks enhance PLMs at both the token and sample granularity levels, respectively. Experimental results show that the proposed method achieves an average performance improvement of more than 1% under the premise of four different language model as the backbones for sentiment classification and toxicity detection tasks on 8 datasets compared with the most recent baseline methods.",0306-4573,1873-5371,,, ,  ,,detection#methodology,
2506,"**Title**Investigation of the Gender-Specific Discourse about Online Learning during COVID-19 on Twitter Using Sentiment Analysis, Subjectivity Analysis, and Toxicity Analysis

**Abstract**This paper presents several novel findings from a comprehensive analysis of about 50,000 Tweets about online learning during COVID-19, posted on Twitter between 9 November 2021 and 13 July 2022. First, the results of sentiment analysis from VADER, Afinn, and TextBlob show that a higher percentage of these Tweets were positive. The results of gender-specific sentiment analysis indicate that for positive Tweets, negative Tweets, and neutral Tweets, between males and females, males posted a higher percentage of the Tweets. Second, the results from subjectivity analysis show that the percentage of least opinionated, neutral opinionated, and highly opinionated Tweets were 56.568%, 30.898%, and 12.534%, respectively. The gender-specific results for subjectivity analysis indicate that females posted a higher percentage of highly opinionated Tweets as compared to males. However, males posted a higher percentage of least opinionated and neutral opinionated Tweets as compared to females. Third, toxicity detection was performed on the Tweets to detect different categories of toxic content-toxicity, obscene, identity attack, insult, threat, and sexually explicit. The gender-specific analysis of the percentage of Tweets posted by each gender for each of these categories of toxic content revealed several novel insights related to the degree, type, variations, and trends of toxic content posted by males and females related to online learning. Fourth, the average activity of males and females per month in this context was calculated. The findings indicate that the average activity of females was higher in all months as compared to males other than March 2022. Finally, country-specific tweeting patterns of males and females were also performed which presented multiple novel insights, for instance, in India, a higher percentage of the Tweets about online learning during COVID-19 were posted by males as compared to females.","Thakur, Nirmalya; Cui, Shuqi; Khanna, Karam; Knieling, Victoria; Duggal, Yuvraj Nihal; Shao, Mingchen","Thakur, Nirmalya/AAR-2748-2020","Thakur, Nirmalya/0000-0002-3225-1870","Investigation of the Gender-Specific Discourse about Online Learning during COVID-19 on Twitter Using Sentiment Analysis, Subjectivity Analysis, and Toxicity Analysis",12,11,10.3390/computers12110221 ,Article ,,"This paper presents several novel findings from a comprehensive analysis of about 50,000 Tweets about online learning during COVID-19, posted on Twitter between 9 November 2021 and 13 July 2022. First, the results of sentiment analysis from VADER, Afinn, and TextBlob show that a higher percentage of these Tweets were positive. The results of gender-specific sentiment analysis indicate that for positive Tweets, negative Tweets, and neutral Tweets, between males and females, males posted a higher percentage of the Tweets. Second, the results from subjectivity analysis show that the percentage of least opinionated, neutral opinionated, and highly opinionated Tweets were 56.568%, 30.898%, and 12.534%, respectively. The gender-specific results for subjectivity analysis indicate that females posted a higher percentage of highly opinionated Tweets as compared to males. However, males posted a higher percentage of least opinionated and neutral opinionated Tweets as compared to females. Third, toxicity detection was performed on the Tweets to detect different categories of toxic content-toxicity, obscene, identity attack, insult, threat, and sexually explicit. The gender-specific analysis of the percentage of Tweets posted by each gender for each of these categories of toxic content revealed several novel insights related to the degree, type, variations, and trends of toxic content posted by males and females related to online learning. Fourth, the average activity of males and females per month in this context was calculated. The findings indicate that the average activity of females was higher in all months as compared to males other than March 2022. Finally, country-specific tweeting patterns of males and females were also performed which presented multiple novel insights, for instance, in India, a higher percentage of the Tweets about online learning during COVID-19 were posted by males as compared to females.",2073-431X,,,, ,  ,,out_of_scope,
2507,"**Title**Unveiling Toxic Tendencies of Small Language Models in Unconstrained Generation Tasks

**Abstract**The prevalence of toxicity online presents a significant challenge for platforms and publishers alike. Recent studies conducted on Small Language Models (SLMs) have identified the inherent toxicity that dwell in these models. In this work, we study and benchmark the extent to which SLMs can be prompted to generate toxic language. The following SLMs are evaluated for their toxicity levels: GPT-2 Large, Gemma-2B, Mistral-7B, Falcon-7B, and Llama 2-13B. We go a step closer to understanding the correlation between toxicity and the intrinsic parameters of the state-of-the-art SLMs. Next, we study the efficacy of a basic word-filtering approach to controlled text generation. Following this, we proceed to establish a mathematical ground for computing the weighted toxicity of continuations with respect to the toxicity of prompts by treating toxicity as a fuzzy metric. Finally, we extend our analysis to examine the unexpected toxicity levels of generated continuations when prompted with non-toxic inputs.","Chandra, Lakshay; Susan, Seba; Kumar, Dhruv; Kant, Krishan","Susan, Dr. Seba/KHY-0356-2024",,Unveiling Toxic Tendencies of Small Language Models in Unconstrained Generation Tasks,,,10.1109/CONECCT62155.2024.10677188 ,Proceedings Paper ,,"The prevalence of toxicity online presents a significant challenge for platforms and publishers alike. Recent studies conducted on Small Language Models (SLMs) have identified the inherent toxicity that dwell in these models. In this work, we study and benchmark the extent to which SLMs can be prompted to generate toxic language. The following SLMs are evaluated for their toxicity levels: GPT-2 Large, Gemma-2B, Mistral-7B, Falcon-7B, and Llama 2-13B. We go a step closer to understanding the correlation between toxicity and the intrinsic parameters of the state-of-the-art SLMs. Next, we study the efficacy of a basic word-filtering approach to controlled text generation. Following this, we proceed to establish a mathematical ground for computing the weighted toxicity of continuations with respect to the toxicity of prompts by treating toxicity as a fuzzy metric. Finally, we extend our analysis to examine the unexpected toxicity levels of generated continuations when prompted with non-toxic inputs.",2334-0940,,979-8-3503-8593-9; 979-8-3503-8592-2,, ," 10th IEEE International Conference on Electronics, Computing and Communication Technologies (IEEE CONECCT)10th IEEE International Conference on Electronics, Computing and Communication Technologies (IEEE CONECCT) ",,evaluation,
2508,"**Title**Generating Topic-Agnostic Conversations With LLMs

**Abstract**Conversational systems are important applications of Artificial Intelligence, encompassing a wide variety of implementations, from rule-based systems to complex systems using Natural Language Processing, Deep Neural Networks, and Transformer Architectures. With the growth of these implementations, the quality of conversational data has become a concern. Many attempts have been made to generate such data, focusing primarily on topical conversations. This article presents a generalized framework moving from generating topical conversation towards topic-agnostic conversational data consisting of three Large Language Model instances. Two of these models interact with each other to generate the conversation, while the third one plays the role of a judge to keep the conversation going. The synthetic data created by the proposed method exhibits higher quality and lower toxicity than four of the existing datasets (AmazonQA, Daily Dialog, Open Subtitles, and HUMOD) in terms of six performance measures, namely Toxicity, Severe Toxicity, Obscene, Threat, Insult, and Identity Attack. Compared to other datasets, the performance analysis of the generated data shows the lowest measures in terms of mean and maximum values. Specifically, the percentages for Toxicity, Obscene, Threat, Insult, and Identity Attack are 0.27%, 0.04%, 0.02%, 0.05%, and 0.02%, respectively, while the corresponding maximum values are 90.13%, 29.65%, 3.42%, 67.16% and 0.69%. The generated dataset also shows the maximum concentration, with 99.74% of the data in the range of 0-10% toxicity with just a few outliers.","Sandilya, Harshit; Gehlot, Naveen; Kumar, Rajesh; Bukya, Mahipal","Kumar, Rajesh/G-1408-2014","Kumar, Rajesh/0000-0002-6019-0702; Gehlot, Naveen/0000-0003-3607-6456",Generating Topic-Agnostic Conversations With LLMs,12,,10.1109/ACCESS.2024.3473692 ,Article ,,"Conversational systems are important applications of Artificial Intelligence, encompassing a wide variety of implementations, from rule-based systems to complex systems using Natural Language Processing, Deep Neural Networks, and Transformer Architectures. With the growth of these implementations, the quality of conversational data has become a concern. Many attempts have been made to generate such data, focusing primarily on topical conversations. This article presents a generalized framework moving from generating topical conversation towards topic-agnostic conversational data consisting of three Large Language Model instances. Two of these models interact with each other to generate the conversation, while the third one plays the role of a judge to keep the conversation going. The synthetic data created by the proposed method exhibits higher quality and lower toxicity than four of the existing datasets (AmazonQA, Daily Dialog, Open Subtitles, and HUMOD) in terms of six performance measures, namely Toxicity, Severe Toxicity, Obscene, Threat, Insult, and Identity Attack. Compared to other datasets, the performance analysis of the generated data shows the lowest measures in terms of mean and maximum values. Specifically, the percentages for Toxicity, Obscene, Threat, Insult, and Identity Attack are 0.27%, 0.04%, 0.02%, 0.05%, and 0.02%, respectively, while the corresponding maximum values are 90.13%, 29.65%, 3.42%, 67.16% and 0.69%. The generated dataset also shows the maximum concentration, with 99.74% of the data in the range of 0-10% toxicity with just a few outliers.",2169-3536,,,145540-145549, ,  ,,out_of_scope,
2509,"**Title**Empowering Indonesian internet users: An approach to counter online toxicity and enhance digital well-being

**Abstract**The proliferation of online toxicity, characterized by offensive and disrespectful language, has been a pervasive issue in Indonesia's digital environment, impacting users' mental health and well-being. Simultaneously, the potential of Natural Language Processing (NLP) in detecting and managing toxic comments provides a promising avenue for mitigating online toxicity. This study presents a 3-stages methodology consisting of type, target audience, and topics to detect and categorize online toxicity in the Indonesian language using fine-tuned IndoBERTweet and Indonesian RoBERTa models. The results indicate that the IndoBERTweet model, with optimally adjusted hyperparameters, consistently outperforms the Indonesian RoBERTa model in all stages of our proposed methodology. These outcomes are substantiated by higher precision, recall, and F1 score metrics exhibited by the IndoBERTweet model. This model also exhibits remarkable performance in real-world applicability, accurately classifying new Indonesian language content from Twitter (now X). This research establishes a stepping stone for future work, including exploring other language models, applying the methodology to other languages, training the models on larger and more diverse datasets, and applying it to other social media platforms or forums. Our proposal contributes to create safer online spaces, and the results provide insights for the development of automated moderation tools, playing a significant role in combating online harassment and ensuring online community well-being.","Alamsyah, Andry; Sagama, Yoga","; Alamsyah, Andry/I-7296-2018","Sagama, Yoga/0009-0004-7888-7091; Alamsyah, Andry/0000-0001-5106-7561",Empowering Indonesian internet users: An approach to counter online toxicity and enhance digital well-being,22,,10.1016/j.iswa.2024.200394 ,Article ,,"The proliferation of online toxicity, characterized by offensive and disrespectful language, has been a pervasive issue in Indonesia's digital environment, impacting users' mental health and well-being. Simultaneously, the potential of Natural Language Processing (NLP) in detecting and managing toxic comments provides a promising avenue for mitigating online toxicity. This study presents a 3-stages methodology consisting of type, target audience, and topics to detect and categorize online toxicity in the Indonesian language using fine-tuned IndoBERTweet and Indonesian RoBERTa models. The results indicate that the IndoBERTweet model, with optimally adjusted hyperparameters, consistently outperforms the Indonesian RoBERTa model in all stages of our proposed methodology. These outcomes are substantiated by higher precision, recall, and F1 score metrics exhibited by the IndoBERTweet model. This model also exhibits remarkable performance in real-world applicability, accurately classifying new Indonesian language content from Twitter (now X). This research establishes a stepping stone for future work, including exploring other language models, applying the methodology to other languages, training the models on larger and more diverse datasets, and applying it to other social media platforms or forums. Our proposal contributes to create safer online spaces, and the results provide insights for the development of automated moderation tools, playing a significant role in combating online harassment and ensuring online community well-being.",,2667-3053,,, ,  ,,out_but_toxicity,
2510,"**Title**Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models

**Abstract**Pretrained large language models have become indispensable for solving various natural language processing (NLP) tasks. However, safely deploying them in real world applications is challenging because they generate toxic content. To address this challenge, we propose two novel pretraining data augmentation strategies that significantly reduce model toxicity without compromising its utility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data to the pretraining samples, and (2) INST: adds instructions to those samples indicating their toxicity. Our results indicate that our best performing strategy (INST) substantially reduces the toxicity probability up to 61% while preserving the accuracy on five benchmark NLP tasks as well as improving AUC scores on four bias detection tasks by 1.3%. We also demonstrate the generalizability of our techniques by scaling the number of training samples and the number of model parameters.","Prabhumoye, Shrimai; Patwary, Mostofa; Shoeybi, Mohammad; Catanzaro, Bryan",,,Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models,,, ,Proceedings Paper ,,"Pretrained large language models have become indispensable for solving various natural language processing (NLP) tasks. However, safely deploying them in real world applications is challenging because they generate toxic content. To address this challenge, we propose two novel pretraining data augmentation strategies that significantly reduce model toxicity without compromising its utility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data to the pretraining samples, and (2) INST: adds instructions to those samples indicating their toxicity. Our results indicate that our best performing strategy (INST) substantially reduces the toxicity probability up to 61% while preserving the accuracy on five benchmark NLP tasks as well as improving AUC scores on four bias detection tasks by 1.3%. We also demonstrate the generalizability of our techniques by scaling the number of training samples and the number of model parameters.",,,978-1-959429-44-9,2636-2651, , 17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,detox,
2511,No abstract available,"Shi, Haochun; Zhao, Yanbin","Shi, Haochun/LQK-6595-2024; Zhao, Yan-Bin/AAB-6185-2019",,Integration of Advanced Large Language Models into the Construction of Adverse Outcome Pathways: Opportunities and Challenges,58,35,10.1021/acs.est.4c07524 ,Editorial Material ,,,0013-936X,1520-5851,,15355-15358, ,  ,,out_of_scope,
2512,"**Title**Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies

**Abstract**While large language models (LLMs) have shown remarkable effectiveness in various NLP tasks, they are still prone to issues such as hallucination, unfaithful reasoning, and toxicity. A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output. Techniques leveraging automated feedback-either produced by the LLM itself (self-correction) or some external system-are of particular interest as they make LLM-based solutions more practical and deployable with minimal human intervention. This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches. We also identify potential challenges and future directions in this emerging field.","Pan, Liangming; Saxon, Michael; Xu, Wenda; Nathani, Deepak; Wang, Xinyi; Wang, William Yang","Wang, Xinyi/IAM-0594-2023; Pan, Liangming/LIF-2753-2024; Nathani, Deepak/ABG-4715-2021",,Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies,12,,10.1162/tacl_a_00660 ,Article ,,"While large language models (LLMs) have shown remarkable effectiveness in various NLP tasks, they are still prone to issues such as hallucination, unfaithful reasoning, and toxicity. A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output. Techniques leveraging automated feedback-either produced by the LLM itself (self-correction) or some external system-are of particular interest as they make LLM-based solutions more practical and deployable with minimal human intervention. This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches. We also identify potential challenges and future directions in this emerging field.",,2307-387X,,484-506, ,  ,,survey,
2513,"**Title**Toward a Programmable Humanizing Artificial Intelligence Through Scalable Stance-Directed Architecture

**Abstract**The rise of harmful online content underscores the urgent need for artificial intelligence (AI) systems to effectively detect, filter, and foster safer and healthier communication. This article introduces a novel approach to mitigating toxic content generation propensities of large language models (LLMs) by fine-tuning them with a programmable stance-directed focus on core human values and the common good. We propose a streamlined keyword coding and processing pipeline that generates weakly labeled data to train AI models to avoid toxicity and champion civil discourse. We also developed a toxicity classifier and an aspect-based sentiment analysis model to assess and control the effectiveness of a humanizing AI model. We evaluate the proposed pipeline using a contentious real-world X (formerly Twitter) dataset on U.S. race relations. Our approach successfully curbs the toxic content generation propensity of an unrestricted LLM by a significant 85%.","Cetinkaya, Yusuf Mucahit; Lee, Yeonjung; Kulah, Emre; Toroslu, Ismail Hakki; Cowan, Michael A.; Davulcu, Hasan","Çetinkaya, Yusuf Mücahit/GXH-9957-2022; Külah, Emre/ABB-4969-2020; Toroslu, Ismail/Q-5390-2019","toroslu, ismail/0000-0002-4524-8232; Lee, Yeonjung/0000-0003-4048-1841; Davulcu, Hasan/0000-0001-5602-8270; Cetinkaya, Yusuf Mucahit/0000-0001-5338-750X; Kulah, Emre/0000-0003-0877-5487",Toward a Programmable Humanizing Artificial Intelligence Through Scalable Stance-Directed Architecture,28,5,10.1109/MIC.2024.3450090 ,Article ,,"The rise of harmful online content underscores the urgent need for artificial intelligence (AI) systems to effectively detect, filter, and foster safer and healthier communication. This article introduces a novel approach to mitigating toxic content generation propensities of large language models (LLMs) by fine-tuning them with a programmable stance-directed focus on core human values and the common good. We propose a streamlined keyword coding and processing pipeline that generates weakly labeled data to train AI models to avoid toxicity and champion civil discourse. We also developed a toxicity classifier and an aspect-based sentiment analysis model to assess and control the effectiveness of a humanizing AI model. We evaluate the proposed pipeline using a contentious real-world X (formerly Twitter) dataset on U.S. race relations. Our approach successfully curbs the toxic content generation propensity of an unrestricted LLM by a significant 85%.",1089-7801,1941-0131,,20-27, ,  ,,detox,
2514,"**Title**Offensive Text Span Detection in Romanian Comments Using Large Language Models

**Abstract**The advent of online platforms and services has revolutionized communication, enabling users to share opinions and ideas seamlessly. However, this convenience has also brought about a surge in offensive and harmful language across various communication mediums. In response, social platforms have turned to automated methods to identify offensive content. A critical research question emerges when investigating the role of specific text spans within comments in conveying offensive characteristics. This paper conducted a comprehensive investigation into detecting offensive text spans in Romanian language comments using Transformer encoders and Large Language Models (LLMs). We introduced an extensive dataset of 4800 Romanian comments annotated with offensive text spans. Moreover, we explored the impact of varying model sizes, architectures, and training data volumes on the performance of offensive text span detection, providing valuable insights for determining the optimal configuration. The results argue for the effectiveness of BERT pre-trained models for this span-detection task, showcasing their superior performance. We further investigated the impact of different sample-retrieval strategies for few-shot learning using LLMs based on vector text representations. The analysis highlights important insights and trade-offs in leveraging LLMs for offensive-language-detection tasks.","Paraschiv, Andrei; Ion, Teodora Andreea; Dascalu, Mihai","; Dascalu, Mihai/O-4984-2014","Paraschiv, Andrei/0000-0002-7992-4227; Dascalu, Mihai/0000-0002-4815-9227",Offensive Text Span Detection in Romanian Comments Using Large Language Models,15,1,10.3390/info15010008 ,Article ,,"The advent of online platforms and services has revolutionized communication, enabling users to share opinions and ideas seamlessly. However, this convenience has also brought about a surge in offensive and harmful language across various communication mediums. In response, social platforms have turned to automated methods to identify offensive content. A critical research question emerges when investigating the role of specific text spans within comments in conveying offensive characteristics. This paper conducted a comprehensive investigation into detecting offensive text spans in Romanian language comments using Transformer encoders and Large Language Models (LLMs). We introduced an extensive dataset of 4800 Romanian comments annotated with offensive text spans. Moreover, we explored the impact of varying model sizes, architectures, and training data volumes on the performance of offensive text span detection, providing valuable insights for determining the optimal configuration. The results argue for the effectiveness of BERT pre-trained models for this span-detection task, showcasing their superior performance. We further investigated the impact of different sample-retrieval strategies for few-shot learning using LLMs based on vector text representations. The analysis highlights important insights and trade-offs in leveraging LLMs for offensive-language-detection tasks.",,2078-2489,,, ,  ,,out_but_toxicity,
2515,"**Title**Contrasting Linguistic Patterns in Human and LLM-Generated News Text

**Abstract**We conduct a quantitative analysis contrasting human-written English news text with comparable large language model (LLM) output from six different LLMs that cover three different families and four sizes in total. Our analysis spans several measurable linguistic dimensions, including morphological, syntactic, psychometric, and sociolinguistic aspects. The results reveal various measurable differences between human and AI-generated texts. Human texts exhibit more scattered sentence length distributions, more variety of vocabulary, a distinct use of dependency and constituent types, shorter constituents, and more optimized dependency distances. Humans tend to exhibit stronger negative emotions (such as fear and disgust) and less joy compared to text generated by LLMs, with the toxicity of these models increasing as their size grows. LLM outputs use more numbers, symbols and auxiliaries (suggesting objective language) than human texts, as well as more pronouns. The sexist bias prevalent in human text is also expressed by LLMs, and even magnified in all of them but one. Differences between LLMs and humans are larger than between LLMs.","Munoz-Ortiz, Alberto; Gomez-Rodriguez, Carlos; Vilares, David",,,Contrasting Linguistic Patterns in Human and LLM-Generated News Text,57,9,10.1007/s10462-024-10903-2 ,Article ,,"We conduct a quantitative analysis contrasting human-written English news text with comparable large language model (LLM) output from six different LLMs that cover three different families and four sizes in total. Our analysis spans several measurable linguistic dimensions, including morphological, syntactic, psychometric, and sociolinguistic aspects. The results reveal various measurable differences between human and AI-generated texts. Human texts exhibit more scattered sentence length distributions, more variety of vocabulary, a distinct use of dependency and constituent types, shorter constituents, and more optimized dependency distances. Humans tend to exhibit stronger negative emotions (such as fear and disgust) and less joy compared to text generated by LLMs, with the toxicity of these models increasing as their size grows. LLM outputs use more numbers, symbols and auxiliaries (suggesting objective language) than human texts, as well as more pronouns. The sexist bias prevalent in human text is also expressed by LLMs, and even magnified in all of them but one. Differences between LLMs and humans are larger than between LLMs.",0269-2821,1573-7462,,, ,  ,,out_of_scope,
2516,"**Title**Scaling Instruction-Finetuned Language Models

**Abstract**Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain -of -thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero -shot, few -shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation, RealToxicityPrompts). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PaLM 540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks (at time of release), such as 75.2% on five -shot MMLU. We also publicly release Flan -T5 checkpoints,1 which achieve strong few -shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.","Chung, Hyung Won; Hou, Le; Longpre, Shayne; Zoph, Barret; Tai, Yi; Fedus, William; Li, Yunxuan; Wang, Xuezhi; Dehghani, Mostafa; Brahma, Siddhartha; Webson, Albert; Gu, Shixiang Shane; Dai, Zhuyun; Suzgun, Mirac; Chen, Xinyun; Chowdhery, Aakanksha; Castro-Ros, Alex; Pellat, Marie; Robinson, Kevin; Valter, Dasha; Narang, Sharan; Mishra, Gaurav; Yu, Adams; Zhao, Vincent; Huang, Yanping; Dai, Andrew; Yu, Hongkun; Petrov, Slav; Chi, Ed H.; Dean, Jeff; Devlin, Jacob; Roberts, Adam; Zhou, Denny; Le, Quoc, V; Wei, Jason","Chen, Xinyun/ABZ-9877-2022; Huang, Yan-Ping/I-3250-2019; Mishra, Gaurav/GLR-6378-2022",,Scaling Instruction-Finetuned Language Models,25,, ,Article ,,"Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain -of -thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero -shot, few -shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation, RealToxicityPrompts). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PaLM 540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks (at time of release), such as 75.2% on five -shot MMLU. We also publicly release Flan -T5 checkpoints,1 which achieve strong few -shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.",1532-4435,,,, ,  ,,out_of_scope,
2517,"**Title**A First Look at Toxicity Injection Attacks on Open-domain Chatbots

**Abstract**Chatbot systems have improved significantly because of the advances made in language modeling. These machine learning systems follow an end-to-end data-driven learning paradigm and are trained on large conversational datasets. Imperfections or harmful biases in the training datasets can cause the models to learn toxic behavior, and thereby expose their users to harmful responses. Prior work has focused on measuring the inherent toxicity of such chatbots, by devising queries that are more likely to produce toxic responses. In this work, we ask the question: How easy or hard is it to inject toxicity into a chatbot after deployment? We study this in a practical scenario known as Dialog-based Learning (DBL), where a chatbot is periodically trained on recent conversations with its users after deployment. A DBL setting can be exploited to poison the training dataset for each training cycle. Our attacks would allow an adversary to manipulate the degree of toxicity in a model and also enable control over what type of queries can trigger a toxic response. Our fully automated attacks only require LLM-based software agents masquerading as (malicious) users to inject high levels of toxicity. We systematically explore the vulnerability of popular chatbot pipelines to this threat. Lastly, we show that several existing toxicity mitigation strategies (designed for chatbots) can be significantly weakened by adaptive attackers.","Weeks, Connor; Cheruvu, Aravind; Abdullah, Sifat Muhammad; Kanchi, Shravya; Yao, Danfeng (Daphne); Viswanath, Bimal",,"Abdullah, Sifat Muhammad/0009-0008-2285-7490; Yao, Danfeng (Daphne)/0000-0001-8969-2792",A First Look at Toxicity Injection Attacks on Open-domain Chatbots,,,10.1145/3627106.3627122 ,Proceedings Paper ,,"Chatbot systems have improved significantly because of the advances made in language modeling. These machine learning systems follow an end-to-end data-driven learning paradigm and are trained on large conversational datasets. Imperfections or harmful biases in the training datasets can cause the models to learn toxic behavior, and thereby expose their users to harmful responses. Prior work has focused on measuring the inherent toxicity of such chatbots, by devising queries that are more likely to produce toxic responses. In this work, we ask the question: How easy or hard is it to inject toxicity into a chatbot after deployment? We study this in a practical scenario known as Dialog-based Learning (DBL), where a chatbot is periodically trained on recent conversations with its users after deployment. A DBL setting can be exploited to poison the training dataset for each training cycle. Our attacks would allow an adversary to manipulate the degree of toxicity in a model and also enable control over what type of queries can trigger a toxic response. Our fully automated attacks only require LLM-based software agents masquerading as (malicious) users to inject high levels of toxicity. We systematically explore the vulnerability of popular chatbot pipelines to this threat. Lastly, we show that several existing toxicity mitigation strategies (designed for chatbots) can be significantly weakened by adaptive attackers.",,,979-8-4007-0886-2,521-534, , 39th Annual Computer Security Applications Conference (ACSAC)39th Annual Computer Security Applications Conference (ACSAC) ,,out_but_toxicity,
2518,"**Title**Quark: Controllable Text Generation with Reinforced [Un]learning

**Abstract**Large-scale language models often learn behaviors that are misaligned with user expectations. Generated text may contain offensive or toxic language, contain significant repetition, or be of a different sentiment than desired by the user. We consider the task of unlearning these misalignments by fine-tuning the language model on signals of what not to do. We introduce Quantized Reward Konditioning (Quark), an algorithm for optimizing a reward function that quantifies an (un)wanted property, while not straying too far from the original model. Quark alternates between (i) collecting samples with the current language model, (ii) sorting them into quantiles based on reward, with each quantile identified by a reward token prepended to the language model's input, and (iii) using a standard language modeling loss on samples from each quantile conditioned on its reward token, while remaining nearby the original language model via a KL-divergence penalty. By conditioning on a high-reward token at generation time, the model generates text that exhibits less of the unwanted property. For unlearning toxicity, negative sentiment, and repetition, our experiments show that Quark outperforms both strong baselines and state-of-the-art reinforcement learning methods like PPO [66], while relying only on standard language modeling primitives.","Lu, Ximing; Welleck, Sean; Hessel, Jack; Jiang, Liwei; Qin, Lianhui; West, Peter; Ammanabrolu, Prithviraj; Choi, Yejin","Lu, Ximing/LLL-7542-2024",,Quark: Controllable Text Generation with Reinforced [Un]learning,,, ,Proceedings Paper ,,"Large-scale language models often learn behaviors that are misaligned with user expectations. Generated text may contain offensive or toxic language, contain significant repetition, or be of a different sentiment than desired by the user. We consider the task of unlearning these misalignments by fine-tuning the language model on signals of what not to do. We introduce Quantized Reward Konditioning (Quark), an algorithm for optimizing a reward function that quantifies an (un)wanted property, while not straying too far from the original model. Quark alternates between (i) collecting samples with the current language model, (ii) sorting them into quantiles based on reward, with each quantile identified by a reward token prepended to the language model's input, and (iii) using a standard language modeling loss on samples from each quantile conditioned on its reward token, while remaining nearby the original language model via a KL-divergence penalty. By conditioning on a high-reward token at generation time, the model generates text that exhibits less of the unwanted property. For unlearning toxicity, negative sentiment, and repetition, our experiments show that Quark outperforms both strong baselines and state-of-the-art reinforcement learning methods like PPO [66], while relying only on standard language modeling primitives.",1049-5258,,978-1-7138-7108-8,, , 36th Conference on Neural Information Processing Systems (NeurIPS)36th Conference on Neural Information Processing Systems (NeurIPS) ,,detox,
2519,"**Title**Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models

**Abstract**Large language models produce human-like text that drives a growing number of applications. However, recent literature and, increasingly, real world observations, have demonstrated that these models can generate language that is toxic, biased, untruthful or otherwise harmful. Though work to evaluate language model harms is under way, translating foresight about which harms may arise into rigorous benchmarks is not straightforward. To facilitate this translation, we outline six ways of characterizing harmful text which merit explicit consideration when designing new benchmarks. We then use these characteristics as a lens to identify trends and gaps in existing benchmarks. Finally, we apply them in a case study of the Perspective API, a toxicity classifier that is widely used in harm benchmarks. Our characteristics provide one piece of the bridge that translates between foresight and effective evaluation.","Rauh, Maribeth; Mellor, John; Uesato, Jonathan; Huang, Po-Sen; Welbl, Johannes; Weidinger, Laura; Dathathri, Sumanth; Glaese, Amelia; Irving, Geoffrey; Gabriel, Iason; Isaac, William; Hendricks, Lisa Anne","Gabriel, Iason/IST-7093-2023","Gabriel, Iason/0000-0002-7552-4576",Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models,,, ,Proceedings Paper ,,"Large language models produce human-like text that drives a growing number of applications. However, recent literature and, increasingly, real world observations, have demonstrated that these models can generate language that is toxic, biased, untruthful or otherwise harmful. Though work to evaluate language model harms is under way, translating foresight about which harms may arise into rigorous benchmarks is not straightforward. To facilitate this translation, we outline six ways of characterizing harmful text which merit explicit consideration when designing new benchmarks. We then use these characteristics as a lens to identify trends and gaps in existing benchmarks. Finally, we apply them in a case study of the Perspective API, a toxicity classifier that is widely used in harm benchmarks. Our characteristics provide one piece of the bridge that translates between foresight and effective evaluation.",1049-5258,,978-1-7138-7108-8,, , 36th Conference on Neural Information Processing Systems (NeurIPS)36th Conference on Neural Information Processing Systems (NeurIPS) ,,evaluation#methodology,
2520,"**Title**REALTOXICITYPROMPTS: Evaluating Neural Toxic Degeneration in Language Models

**Abstract**Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release REALTOXICITYPROMPTS, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using REALTOXICITYPROMPTS, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning bad words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et al., 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.","Gehman, Samuel; Gururangan, Suchin; Sap, Maarten; Choi, Yejin; Smith, Noah A.",,,REALTOXICITYPROMPTS: Evaluating Neural Toxic Degeneration in Language Models,,, ,Proceedings Paper ,,"Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release REALTOXICITYPROMPTS, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using REALTOXICITYPROMPTS, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning bad words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et al., 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.",,,978-1-952148-90-3,, , Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP) ,,Gen_dataset#evaluation,
2521,"**Title**Large language models for biomedicine: foundations, opportunities, challenges, and best practices

**Abstract**Objectives Generative large language models (LLMs) are a subset of transformers-based neural network architecture models. LLMs have successfully leveraged a combination of an increased number of parameters, improvements in computational efficiency, and large pre-training datasets to perform a wide spectrum of natural language processing (NLP) tasks. Using a few examples (few-shot) or no examples (zero-shot) for prompt-tuning has enabled LLMs to achieve state-of-the-art performance in a broad range of NLP applications. This article by the American Medical Informatics Association (AMIA) NLP Working Group characterizes the opportunities, challenges, and best practices for our community to leverage and advance the integration of LLMs in downstream NLP applications effectively. This can be accomplished through a variety of approaches, including augmented prompting, instruction prompt tuning, and reinforcement learning from human feedback (RLHF).Target Audience Our focus is on making LLMs accessible to the broader biomedical informatics community, including clinicians and researchers who may be unfamiliar with NLP. Additionally, NLP practitioners may gain insight from the described best practices.Scope We focus on 3 broad categories of NLP tasks, namely natural language understanding, natural language inferencing, and natural language generation. We review the emerging trends in prompt tuning, instruction fine-tuning, and evaluation metrics used for LLMs while drawing attention to several issues that impact biomedical NLP applications, including falsehoods in generated text (confabulation/hallucinations), toxicity, and dataset contamination leading to overfitting. We also review potential approaches to address some of these current challenges in LLMs, such as chain of thought prompting, and the phenomena of emergent capabilities observed in LLMs that can be leveraged to address complex NLP challenge in biomedical applications.","Sahoo, Satya S.; Plasek, Joseph M.; Xu, Hua; Uzuner, Ozlem; Cohen, Trevor; Yetisgen, Meliha; Liu, Hongfang; Meystre, Stephane; Wang, Yanshan","Liu, Hongfang/ISU-9369-2023; Wang, Yanshan/H-4686-2018; Sahoo, Satya/R-4832-2019; Plasek, Joseph/AAI-8263-2020; Meystre, Stéphane/JSL-7183-2023","Plasek, Joseph/0000-0002-9686-3876; Meystre, Stephane/0000-0002-7632-9625; Sahoo, Satya/0000-0001-9190-4256; Uzuner, Ozlem/0000-0001-8011-9850","Large language models for biomedicine: foundations, opportunities, challenges, and best practices",31,9,10.1093/jamia/ocae074 ,Review ,,"Objectives Generative large language models (LLMs) are a subset of transformers-based neural network architecture models. LLMs have successfully leveraged a combination of an increased number of parameters, improvements in computational efficiency, and large pre-training datasets to perform a wide spectrum of natural language processing (NLP) tasks. Using a few examples (few-shot) or no examples (zero-shot) for prompt-tuning has enabled LLMs to achieve state-of-the-art performance in a broad range of NLP applications. This article by the American Medical Informatics Association (AMIA) NLP Working Group characterizes the opportunities, challenges, and best practices for our community to leverage and advance the integration of LLMs in downstream NLP applications effectively. This can be accomplished through a variety of approaches, including augmented prompting, instruction prompt tuning, and reinforcement learning from human feedback (RLHF).Target Audience Our focus is on making LLMs accessible to the broader biomedical informatics community, including clinicians and researchers who may be unfamiliar with NLP. Additionally, NLP practitioners may gain insight from the described best practices.Scope We focus on 3 broad categories of NLP tasks, namely natural language understanding, natural language inferencing, and natural language generation. We review the emerging trends in prompt tuning, instruction fine-tuning, and evaluation metrics used for LLMs while drawing attention to several issues that impact biomedical NLP applications, including falsehoods in generated text (confabulation/hallucinations), toxicity, and dataset contamination leading to overfitting. We also review potential approaches to address some of these current challenges in LLMs, such as chain of thought prompting, and the phenomena of emergent capabilities observed in LLMs that can be leveraged to address complex NLP challenge in biomedical applications.",1067-5027,1527-974X,,2114-2124, ,  ,,out_of_scope,
2522,"**Title**LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions

**Abstract**Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. We also assess the model for hallucination and toxicity, and for the former, we introduce a new benchmark dataset for hallucination-inducing QA. The results demonstrate that our proposed LaMini-LM models are comparable to strong baselines while being much smaller in size.(1)","Wu, Minghao; Waheed, Abdul; Zhang, Chiyu; Abdul-Mageed, Muhammad; Aji, Alham Fikri",,,LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions,,, ,Proceedings Paper ,,"Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. We also assess the model for hallucination and toxicity, and for the former, we introduce a new benchmark dataset for hallucination-inducing QA. The results demonstrate that our proposed LaMini-LM models are comparable to strong baselines while being much smaller in size.(1)",,,979-8-89176-088-2,944-964, , 18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,out_of_scope,
2523,"**Title**MolPROP: Molecular Property prediction with multimodal language and graph fusion

**Abstract**Pretrained deep learning models self-supervised on large datasets of language, image, and graph representations are often fine-tuned on downstream tasks and have demonstrated remarkable adaptability in a variety of applications including chatbots, autonomous driving, and protein folding. Additional research aims to improve performance on downstream tasks by fusing high dimensional data representations across multiple modalities. In this work, we explore a novel fusion of a pretrained language model, ChemBERTa-2, with graph neural networks for the task of molecular property prediction. We benchmark the MolPROP suite of models on seven scaffold split MoleculeNet datasets and compare with state-of-the-art architectures. We find that (1) multimodal property prediction for small molecules can match or significantly outperform modern architectures on hydration free energy (FreeSolv), experimental water solubility (ESOL), lipophilicity (Lipo), and clinical toxicity tasks (ClinTox), (2) the MolPROP multimodal fusion is predominantly beneficial on regression tasks, (3) the ChemBERTa-2 masked language model pretraining task (MLM) outperformed multitask regression pretraining task (MTR) when fused with graph neural networks for multimodal property prediction, and (4) despite improvements from multimodal fusion on regression tasks MolPROP significantly underperforms on some classification tasks. MolPROP has been made available at https://github.com/merck/MolPROP.","Rollins, Zachary A.; Cheng, Alan C.; Metwally, Essam",,,MolPROP: Molecular Property prediction with multimodal language and graph fusion,16,1,10.1186/s13321-024-00846-9 ,Article ,,"Pretrained deep learning models self-supervised on large datasets of language, image, and graph representations are often fine-tuned on downstream tasks and have demonstrated remarkable adaptability in a variety of applications including chatbots, autonomous driving, and protein folding. Additional research aims to improve performance on downstream tasks by fusing high dimensional data representations across multiple modalities. In this work, we explore a novel fusion of a pretrained language model, ChemBERTa-2, with graph neural networks for the task of molecular property prediction. We benchmark the MolPROP suite of models on seven scaffold split MoleculeNet datasets and compare with state-of-the-art architectures. We find that (1) multimodal property prediction for small molecules can match or significantly outperform modern architectures on hydration free energy (FreeSolv), experimental water solubility (ESOL), lipophilicity (Lipo), and clinical toxicity tasks (ClinTox), (2) the MolPROP multimodal fusion is predominantly beneficial on regression tasks, (3) the ChemBERTa-2 masked language model pretraining task (MLM) outperformed multitask regression pretraining task (MTR) when fused with graph neural networks for multimodal property prediction, and (4) despite improvements from multimodal fusion on regression tasks MolPROP significantly underperforms on some classification tasks. MolPROP has been made available at https://github.com/merck/MolPROP.",1758-2946,,,, ,  ,,out_of_scope,
2524,"**Title**Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation

**Abstract**Large language models (LLMs) have been widely used in various applications but are known to suffer from issues related to untruthfulness and toxicity. While parameter-efficient modules (PEMs) have demonstrated their effectiveness in equipping models with new skills, leveraging PEMs for deficiency unlearning remains underexplored. In this work, we propose a PEMs operation approach, namely Extraction-before-Subtraction (Ext-Sub), to enhance the truthfulness and detoxification of LLMs through the integration of expert PEM and anti-expert PEM. Remarkably, even antiexpert PEM possess valuable capabilities due to their proficiency in generating fabricated content, which necessitates language modeling and logical narrative competence. Rather than merely negating the parameters, our approach involves extracting and eliminating solely the deficiency capability within anti-expert PEM while preserving the general capabilities. To evaluate the effectiveness of our approach in terms of truthfulness and detoxification, we conduct extensive experiments on LLMs, encompassing additional abilities such as language modelling and mathematical reasoning. Our empirical results demonstrate that our approach effectively improves truthfulness and detoxification, while largely preserving the fundamental abilities of LLMs.","Hu, Xinshuo; Li, Dongfang; Hu, Baotian; Zheng, Zihao; Liu, Zhenyu; Zhang, Min","Hu, Baotian/AAA-4102-2022; Liu, Zhenyu/LBI-5068-2024; Li, Dongfang/IWY-0600-2023",,Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation,,, ,Proceedings Paper ,,"Large language models (LLMs) have been widely used in various applications but are known to suffer from issues related to untruthfulness and toxicity. While parameter-efficient modules (PEMs) have demonstrated their effectiveness in equipping models with new skills, leveraging PEMs for deficiency unlearning remains underexplored. In this work, we propose a PEMs operation approach, namely Extraction-before-Subtraction (Ext-Sub), to enhance the truthfulness and detoxification of LLMs through the integration of expert PEM and anti-expert PEM. Remarkably, even antiexpert PEM possess valuable capabilities due to their proficiency in generating fabricated content, which necessitates language modeling and logical narrative competence. Rather than merely negating the parameters, our approach involves extracting and eliminating solely the deficiency capability within anti-expert PEM while preserving the general capabilities. To evaluate the effectiveness of our approach in terms of truthfulness and detoxification, we conduct extensive experiments on LLMs, encompassing additional abilities such as language modelling and mathematical reasoning. Our empirical results demonstrate that our approach effectively improves truthfulness and detoxification, while largely preserving the fundamental abilities of LLMs.",2159-5399,2374-3468,*****************,18252-18260, , 38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence ,,detox,
2525,"**Title**LangTest: A comprehensive evaluation library for custom LLM and NLP models

**Abstract**The use of natural language processing (NLP) models, including the more recent large language models (LLM) in real -world applications obtained relevant success in the past years. To measure the performance of these systems, traditional performance metrics such as accuracy, precision, recall, and f1 -score are used. Although it is important to measure the performance of the models in those terms, natural language often requires an holistic evaluation that consider other important aspects such as robustness, bias, accuracy, toxicity, fairness, safety, efficiency, clinical relevance, security, representation, disinformation, political orientation, sensitivity, factuality, legal concerns, and vulnerabilities. To address the gap, we introduce LangTest, an open source Python toolkit, aimed at reshaping the evaluation of LLMs and NLP models in real -world applications. The project aims to empower data scientists, enabling them to meet high standards in the ever -evolving landscape of AI model development. Specifically, it provides a comprehensive suite of more than 60 test types, ensuring a more comprehensive understanding of a model's behavior and responsible AI use. In this experiment, a Named Entity Recognition (NER) clinical model showed significant improvement in its capabilities to identify clinical entities in text after applying data augmentation for robustness.","Nazir, Arshaan; Chakravarthy, Thadaka Kalyan; Cecchini, David Amore; Khajuria, Rakshit; Sharma, Prikshit; Mirik, Ali Tarik; Kocaman, Veysel; Talby, David","Cecchini, David/P-5507-2016","THADAKA, KALYAN CHAKRAVARTHY/0000-0003-2303-3887; Cecchini, David Amore/0009-0009-5939-0027",LangTest: A comprehensive evaluation library for custom LLM and NLP models,19,,10.1016/j.simpa.2024.100619 ,Article ,,"The use of natural language processing (NLP) models, including the more recent large language models (LLM) in real -world applications obtained relevant success in the past years. To measure the performance of these systems, traditional performance metrics such as accuracy, precision, recall, and f1 -score are used. Although it is important to measure the performance of the models in those terms, natural language often requires an holistic evaluation that consider other important aspects such as robustness, bias, accuracy, toxicity, fairness, safety, efficiency, clinical relevance, security, representation, disinformation, political orientation, sensitivity, factuality, legal concerns, and vulnerabilities. To address the gap, we introduce LangTest, an open source Python toolkit, aimed at reshaping the evaluation of LLMs and NLP models in real -world applications. The project aims to empower data scientists, enabling them to meet high standards in the ever -evolving landscape of AI model development. Specifically, it provides a comprehensive suite of more than 60 test types, ensuring a more comprehensive understanding of a model's behavior and responsible AI use. In this experiment, a Named Entity Recognition (NER) clinical model showed significant improvement in its capabilities to identify clinical entities in text after applying data augmentation for robustness.",2665-9638,,,, ,  ,,out_of_scope,
2526,"**Title**Securing Applications of Large Language Models: A Shift-Left Approach

**Abstract**The emergence of large language models (LLMs) has brought forth remarkable capabilities in various domains, yet it also poses inherent risks to trustfulness, encompassing concerns such as toxicity, stereotype bias, adversarial robustness, ethics, privacy, and fairness. Particularly in sensitive applications like customer support chatbots, AI assistants, and digital information automation, which handle privacy-sensitive data, the adoption of generative pre-trained transformer (GPT) models is pervasive. However, ensuring robust security measures to mitigate potential security vulnerabilities is imperative. This paper advocates for a proactive approach termed security shift-left, which emphasizes integrating security measures early in the development lifecycle to bolster the security posture of LLM-based applications. Our proposed method leverages basic machine learning (ML) techniques and retrieval-augmented generation (RAG) to effectively address security concerns. We present empirical evidence validating the efficacy of our approach with one LLM-based security application designed for the detection of malicious intent, utilizing both open-source datasets and synthesized datasets. By adopting this security shift-left methodology, developers can confidently develop LLM-based applications with robust security protection, safeguarding against potential threats and vulnerabilities.","Lan, Qianlong; Kaul, Anuj; Das Pattanaik, Nishant Kumar; Pattanayak, Piyush; Pandurangan, Vinothini","Lan, Qianlong/M-4141-2019",,Securing Applications of Large Language Models: A Shift-Left Approach,,,10.1109/eIT60633.2024.10609922 ,Proceedings Paper ,,"The emergence of large language models (LLMs) has brought forth remarkable capabilities in various domains, yet it also poses inherent risks to trustfulness, encompassing concerns such as toxicity, stereotype bias, adversarial robustness, ethics, privacy, and fairness. Particularly in sensitive applications like customer support chatbots, AI assistants, and digital information automation, which handle privacy-sensitive data, the adoption of generative pre-trained transformer (GPT) models is pervasive. However, ensuring robust security measures to mitigate potential security vulnerabilities is imperative. This paper advocates for a proactive approach termed security shift-left, which emphasizes integrating security measures early in the development lifecycle to bolster the security posture of LLM-based applications. Our proposed method leverages basic machine learning (ML) techniques and retrieval-augmented generation (RAG) to effectively address security concerns. We present empirical evidence validating the efficacy of our approach with one LLM-based security application designed for the detection of malicious intent, utilizing both open-source datasets and synthesized datasets. By adopting this security shift-left methodology, developers can confidently develop LLM-based applications with robust security protection, safeguarding against potential threats and vulnerabilities.",2154-0357,,979-8-3503-3065-6; 979-8-3503-3064-9,378-379, , IEEE International Conference on Electro Information Technology (EIT)IEEE International Conference on Electro Information Technology (EIT) ,,detox#evaluation,
2527,"**Title**On the Globalization of the QAnon Conspiracy Theory Through Telegram

**Abstract**QAnon is a far-right conspiracy theory that has implications in the real world, with supporters of the theory participating in real-world violent acts like the US capitol attack in 2021. At the same time, the QAnon theory started evolving into a global phenomenon by attracting followers across the globe and, in particular, in Europe, hence it is imperative to understand how QAnon has become a worldwide phenomenon and how this dissemination has been happening in the online space. This paper performs a large-scale data analysis of QAnon through Telegram by collecting 4.4M messages posted in 161 QAnon groups/channels. Using Google's Perspective API, we analyze the toxicity of QAnon content across languages and over time. Also, using a BERT-based topic modeling approach, we analyze the QAnon discourse across multiple languages. Among other things, we find that the German language is prevalent in our QAnon dataset, even overshadowing English after 2020. Also, we find that content posted in German and Portuguese tends to be more toxic compared to English. Our topic modeling indicates that QAnon supporters discuss various topics of interest within far-right movements, including world politics, conspiracy theories, COVID-19, and the anti-vaccination movement. Taken all together, we perform the first multilingual study on QAnon through Telegram and paint a nuanced overview of the globalization of QAnon.","Hoseini, Mohamad; Melo, Philipe; Benevenuto, Fabricio; Feldmann, Anja; Zannettou, Savvas",,"Benevenuto, Fabricio/0000-0001-6875-6259; Zannettou, Savvas/0000-0001-5711-1404",On the Globalization of the QAnon Conspiracy Theory Through Telegram,,,10.1145/3578503.3583603 ,Proceedings Paper ,,"QAnon is a far-right conspiracy theory that has implications in the real world, with supporters of the theory participating in real-world violent acts like the US capitol attack in 2021. At the same time, the QAnon theory started evolving into a global phenomenon by attracting followers across the globe and, in particular, in Europe, hence it is imperative to understand how QAnon has become a worldwide phenomenon and how this dissemination has been happening in the online space. This paper performs a large-scale data analysis of QAnon through Telegram by collecting 4.4M messages posted in 161 QAnon groups/channels. Using Google's Perspective API, we analyze the toxicity of QAnon content across languages and over time. Also, using a BERT-based topic modeling approach, we analyze the QAnon discourse across multiple languages. Among other things, we find that the German language is prevalent in our QAnon dataset, even overshadowing English after 2020. Also, we find that content posted in German and Portuguese tends to be more toxic compared to English. Our topic modeling indicates that QAnon supporters discuss various topics of interest within far-right movements, including world politics, conspiracy theories, COVID-19, and the anti-vaccination movement. Taken all together, we perform the first multilingual study on QAnon through Telegram and paint a nuanced overview of the globalization of QAnon.",,,979-8-4007-0089-7,75-85, , 15th ACM Web Science Conference (WebSci)15th ACM Web Science Conference (WebSci) ,,out_of_scope,
2528,"**Title**AI model disgorgement: Methods and choices

**Abstract**Over the past few years, machine learning models have significantly increased in size and complexity, especially in the area of generative AI such as large language models. These models require massive amounts of data and compute capacity to train, to the extent that concerns over the training data (such as protected or private content) cannot be practically addressed by retraining the model from scratch with the questionable data removed or altered. Furthermore, despite significant efforts and controls dedicated to ensuring that training corpora are properly curated and composed, the sheer volume required makes it infeasible to manually inspect each datum comprising a training corpus. One potential approach to training corpus data defects is model disgorgement, by which we broadly mean the elimination or reduction of not only any improperly used data, but also the effects of improperly used data on any component of an ML model. Model disgorgement techniques can be used to address a wide range of issues, such as reducing bias or toxicity, increasing fidelity, and ensuring responsible use of intellectual property. In this paper, we survey the landscape of model disgorgement methods and introduce a taxonomy of disgorgement techniques that are applicable to modern ML systems. In particular, we investigate the various meanings of removing the effects of data on the trained model in a way that does not require retraining from scratch.","Achille, Alessandro; Kearns, Michael; Klingenberg, Carson; Soatto, Stefano",,"Klingenberg, Carson/0009-0001-5386-0958",AI model disgorgement: Methods and choices,121,18,10.1073/pnas.2307304121 ,Article ,,"Over the past few years, machine learning models have significantly increased in size and complexity, especially in the area of generative AI such as large language models. These models require massive amounts of data and compute capacity to train, to the extent that concerns over the training data (such as protected or private content) cannot be practically addressed by retraining the model from scratch with the questionable data removed or altered. Furthermore, despite significant efforts and controls dedicated to ensuring that training corpora are properly curated and composed, the sheer volume required makes it infeasible to manually inspect each datum comprising a training corpus. One potential approach to training corpus data defects is model disgorgement, by which we broadly mean the elimination or reduction of not only any improperly used data, but also the effects of improperly used data on any component of an ML model. Model disgorgement techniques can be used to address a wide range of issues, such as reducing bias or toxicity, increasing fidelity, and ensuring responsible use of intellectual property. In this paper, we survey the landscape of model disgorgement methods and introduce a taxonomy of disgorgement techniques that are applicable to modern ML systems. In particular, we investigate the various meanings of removing the effects of data on the trained model in a way that does not require retraining from scratch.",0027-8424,1091-6490,,, ,  ,,detox,
2529,"**Title**Effects of Speech Cues on Acoustics and Intelligibility of Korean-Speaking Children With Cerebral Palsy

**Abstract**Purpose: Reduced speech intelligibility is often a hallmark of children with dysarthria secondary to cerebral palsy (CP), but effects of speech strategies for increasing intelligibility are understudied, especially in children who speak languages other than English. This study examined the effects of (the Korean translation of) two cues, speak with your big mouth and speak with your strong voice, on speech acoustics and intelligibility of Korean-speaking children with CP. Method: Fifteen Korean-speaking children with CP repeated words and sentences in habitual, big mouth, and strong voice conditions. Acoustic analyses were performed and intelligibility was assessed by means of 90 blinded listeners' ease-of-understanding (EoU) ratings and percentage of words correctly transcribed (PWC). Results: In response to both cues, children's vocal intensity and utterance duration increased significantly and differentially, whereas their vowel space area gains did not reach statistical significance. EoU increased significantly in the big mouth condition at word, but not sentence, level, whereas in the strong voice condition, EoU increased significantly at both levels. PWC increases were not statistically significant. Considerable variability in children's responses to cues was noted overall. Conclusions: Korean-speaking children with CP modify their speech styles differentially when provided with cues aimed to increase their articulatory working space and vocal intensity. The results provide preliminary support for the use of the strong voice cue, in particular, to increase EoU. While the findings do not offer conclusive evidence of the intelligibility benefits of these cues, investigation with a larger sample size should provide further insight into optimal cueing strategies for increasing intelligibility in this population. Implications for language-specific versus language-independent treatment approaches are discussed.","Chang, Younghwa M.; Jeong, Pil-Yeon; Hwang, Kyunghae; Ihn, Bo-Yeon; Mcauliffe, Megan J.; Sim, Hyunsub; Levy, Erika S.",,"Chang, Yu-Mei/0000-0002-2332-6017",Effects of Speech Cues on Acoustics and Intelligibility of Korean-Speaking Children With Cerebral Palsy,67,9,10.1044/2024_JSLHR-23-00457 ,Article ,,"Purpose: Reduced speech intelligibility is often a hallmark of children with dysarthria secondary to cerebral palsy (CP), but effects of speech strategies for increasing intelligibility are understudied, especially in children who speak languages other than English. This study examined the effects of (the Korean translation of) two cues, speak with your big mouth and speak with your strong voice, on speech acoustics and intelligibility of Korean-speaking children with CP. Method: Fifteen Korean-speaking children with CP repeated words and sentences in habitual, big mouth, and strong voice conditions. Acoustic analyses were performed and intelligibility was assessed by means of 90 blinded listeners' ease-of-understanding (EoU) ratings and percentage of words correctly transcribed (PWC). Results: In response to both cues, children's vocal intensity and utterance duration increased significantly and differentially, whereas their vowel space area gains did not reach statistical significance. EoU increased significantly in the big mouth condition at word, but not sentence, level, whereas in the strong voice condition, EoU increased significantly at both levels. PWC increases were not statistically significant. Considerable variability in children's responses to cues was noted overall. Conclusions: Korean-speaking children with CP modify their speech styles differentially when provided with cues aimed to increase their articulatory working space and vocal intensity. The results provide preliminary support for the use of the strong voice cue, in particular, to increase EoU. While the findings do not offer conclusive evidence of the intelligibility benefits of these cues, investigation with a larger sample size should provide further insight into optimal cueing strategies for increasing intelligibility in this population. Implications for language-specific versus language-independent treatment approaches are discussed.",1092-4388,1558-9102,,2856-2871, ,  ,,out_of_scope,
2530,"**Title**Automatic Histograms: Leveraging Language Models for Text Dataset Exploration

**Abstract**Making sense of unstructured text datasets is perennially difficult, yet increasingly relevant with Large Language Models. Data practitioners often rely on dataset summaries, especially distributions of various derived features. Some features, like toxicity or topics, are relevant to many datasets, but many interesting features are domain specific: instruments and genres for a music dataset, or diseases and symptoms for a medical dataset. Accordingly, data practitioners often run custom analyses for each dataset, which is cumbersome and difficult, or use unsupervised methods. We present AutoHistograms, a visualization tool leveraging LLMs. AutoHistograms automatically identifies relevant entity-based features, visualizes them, and allows the user to interactively query the dataset for new categories of entities. In a user study with (n=10) data practitioners, we observe that participants were able to quickly onboard to AutoHistograms, use the tool to identify actionable insights, and conceptualize a broad range of applicable use cases. Together, this tool and user study contribute to the growing field of LLM-assisted sensemaking tools.","Reif, Emily; Qian, Crystal; Wexler, James; Kahng, Minsuk",,,Automatic Histograms: Leveraging Language Models for Text Dataset Exploration,,,10.1145/3613905.3650798 ,Proceedings Paper ,,"Making sense of unstructured text datasets is perennially difficult, yet increasingly relevant with Large Language Models. Data practitioners often rely on dataset summaries, especially distributions of various derived features. Some features, like toxicity or topics, are relevant to many datasets, but many interesting features are domain specific: instruments and genres for a music dataset, or diseases and symptoms for a medical dataset. Accordingly, data practitioners often run custom analyses for each dataset, which is cumbersome and difficult, or use unsupervised methods. We present AutoHistograms, a visualization tool leveraging LLMs. AutoHistograms automatically identifies relevant entity-based features, visualizes them, and allows the user to interactively query the dataset for new categories of entities. In a user study with (n=10) data practitioners, we observe that participants were able to quickly onboard to AutoHistograms, use the tool to identify actionable insights, and conceptualize a broad range of applicable use cases. Together, this tool and user study contribute to the growing field of LLM-assisted sensemaking tools.",,,979-8-4007-0331-7,, , CHI Conference on Human Factors in Computing Sytems (CHI)CHI Conference on Human Factors in Computing Sytems (CHI) ,,out_of_scope,
2531,"**Title**On Second Thought, Let′s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning

**Abstract**Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zeroshot CoT reasoning in sensitive domains significantly increases a model ' s likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved.","Shaikh, Omar; Zhang, Hongxin; Held, William; Bernstein, Michael; Yang, Diyi",,"Bernstein, Michael/0000-0001-8020-9434","On Second Thought, Let′s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",,, ,Proceedings Paper ,,"Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zeroshot CoT reasoning in sensitive domains significantly increases a model ' s likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved.",,,978-1-959429-72-2,4454-4470, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,evaluation,
2532,"**Title**DEE: Dual-Stage Explainable Evaluation Method for Text Generation

**Abstract**Automatic methods for evaluating machine-generated texts hold significant importance due to the expanding applications of generative systems. Conventional methods tend to grapple with a lack of explainability, issuing a solitary numerical score to signify the assessment outcome. Recent advancements have sought to mitigate this limitation by incorporating large language models (LLMs) to offer more detailed error analyses, yet their applicability remains constrained, particularly in industrial contexts where comprehensive error coverage and swift detection are paramount. To alleviate these challenges, we introduce DEE, a Dual-stage Explainable Evaluation method for estimating the quality of text generation. Built upon Llama 2, DEE follows a dual-stage principle guided by stage-specific instructions to perform efficient identification of errors in generated texts in the initial stage and subsequently delves into providing comprehensive diagnostic reports in the second stage. DEE is fine-tuned on our elaborately assembled dataset AntEval, which encompasses 15K instances from 4 real-world applications of Alipay that employ generative systems. The dataset concerns newly emerged issues like hallucination and toxicity, thereby broadening the scope of DEE's evaluation criteria. Experimental results affirm that DEE's superiority over existing evaluation methods, achieving significant improvements in both human correlation as well as efficiency.","Zhang, Shenyu; Li, Yu; Wu, Rui; Huang, Xiutian; Chen, Yongrui; Xu, Wenhao; Qi, Guilin","Chen, Yongrui/AAS-3725-2020",,DEE: Dual-Stage Explainable Evaluation Method for Text Generation,14856,,10.1007/978-981-97-5575-2_29 ,Proceedings Paper ,,"Automatic methods for evaluating machine-generated texts hold significant importance due to the expanding applications of generative systems. Conventional methods tend to grapple with a lack of explainability, issuing a solitary numerical score to signify the assessment outcome. Recent advancements have sought to mitigate this limitation by incorporating large language models (LLMs) to offer more detailed error analyses, yet their applicability remains constrained, particularly in industrial contexts where comprehensive error coverage and swift detection are paramount. To alleviate these challenges, we introduce DEE, a Dual-stage Explainable Evaluation method for estimating the quality of text generation. Built upon Llama 2, DEE follows a dual-stage principle guided by stage-specific instructions to perform efficient identification of errors in generated texts in the initial stage and subsequently delves into providing comprehensive diagnostic reports in the second stage. DEE is fine-tuned on our elaborately assembled dataset AntEval, which encompasses 15K instances from 4 real-world applications of Alipay that employ generative systems. The dataset concerns newly emerged issues like hallucination and toxicity, thereby broadening the scope of DEE's evaluation criteria. Experimental results affirm that DEE's superiority over existing evaluation methods, achieving significant improvements in both human correlation as well as efficiency.",0302-9743,1611-3349,978-981-97-5574-5; 978-981-97-5575-2,390-401, , 29th International Conference on Database Systems for Advanced Applications (DASFAA)29th International Conference on Database Systems for Advanced Applications (DASFAA) ,,Gen_dataset,
2533,"**Title**ToxinPred 3.0: An improved method for predicting the toxicity of peptides.

**Abstract**Toxicity emerges as a prominent challenge in the design of therapeutic peptides, causing the failure of numerous peptides during clinical trials. In 2013, our group developed ToxinPred, a computational method that has been extensively adopted by the scientific community for predicting peptide toxicity. In this paper, we propose a refined variant of ToxinPred that showcases improved reliability and accuracy in predicting peptide toxicity. Initially, we utilized a similarity/alignment-based approach employing BLAST to predict toxic peptides, which yielded satisfactory accuracy; however, the method suffered from inadequate coverage. Subsequently, we employed a motif-based approach using MERCI software to uncover specific patterns or motifs that are exclusively observed in toxic peptides. The search for these motifs in peptides allowed us to predict toxic peptides with a high level of specificity with poor sensitivity. To overcome the coverage limitations, we developed alignment-free methods using machine/deep learning techniques to balance sensitivity and specificity of prediction. Deep learning model (ANN - LSTM with fixed sequence length) developed using one-hot encoding achieved a maximum AUROC of 0.93 with MCC of 0.71 on an independent dataset. Machine learning model (extra tree) developed using compositional features of peptides achieved a maximum AUROC of 0.95 with MCC of 0.78. We also developed large language models and achieved maximum AUC of 0.93 using ESM2-t33. Finally, we developed hybrid or ensemble methods combining two or more methods to enhance performance. Our specific hybrid method, which combines a motif-based approach with a machine learning-based model, achieved a maximum AUROC of 0.98 with MCC 0.81 on an independent dataset. In this study, all models were trained and tested on 80% of data using five-fold cross-validation and evaluated on the remaining 20% of data called independent dataset. The evaluation of all methods on an independent dataset revealed that the method proposed in this study exhibited better performance than existing methods. To cater to the needs of the scientific community, we have developed a standalone software, pip package and web-based server ToxinPred3 (https://github.com/raghavagps/toxinpred3 and https://webs.iiitd.edu.in/raghava/toxinpred3/).","Rathore, Anand Singh; Choudhury, Shubham; Arora, Akanksha; Tijare, Purva; Raghava, Gajendra P S",,"Rathore, Anand Singh/0009-0004-8907-7174; Tijare, Purva/0009-0009-6120-2400; Raghava, Gajendra/0000-0002-8902-2876",ToxinPred 3.0: An improved method for predicting the toxicity of peptides.,179,,10.1016/j.compbiomed.2024.108926 ,Journal Article ,,"Toxicity emerges as a prominent challenge in the design of therapeutic peptides, causing the failure of numerous peptides during clinical trials. In 2013, our group developed ToxinPred, a computational method that has been extensively adopted by the scientific community for predicting peptide toxicity. In this paper, we propose a refined variant of ToxinPred that showcases improved reliability and accuracy in predicting peptide toxicity. Initially, we utilized a similarity/alignment-based approach employing BLAST to predict toxic peptides, which yielded satisfactory accuracy; however, the method suffered from inadequate coverage. Subsequently, we employed a motif-based approach using MERCI software to uncover specific patterns or motifs that are exclusively observed in toxic peptides. The search for these motifs in peptides allowed us to predict toxic peptides with a high level of specificity with poor sensitivity. To overcome the coverage limitations, we developed alignment-free methods using machine/deep learning techniques to balance sensitivity and specificity of prediction. Deep learning model (ANN - LSTM with fixed sequence length) developed using one-hot encoding achieved a maximum AUROC of 0.93 with MCC of 0.71 on an independent dataset. Machine learning model (extra tree) developed using compositional features of peptides achieved a maximum AUROC of 0.95 with MCC of 0.78. We also developed large language models and achieved maximum AUC of 0.93 using ESM2-t33. Finally, we developed hybrid or ensemble methods combining two or more methods to enhance performance. Our specific hybrid method, which combines a motif-based approach with a machine learning-based model, achieved a maximum AUROC of 0.98 with MCC 0.81 on an independent dataset. In this study, all models were trained and tested on 80% of data using five-fold cross-validation and evaluated on the remaining 20% of data called independent dataset. The evaluation of all methods on an independent dataset revealed that the method proposed in this study exhibited better performance than existing methods. To cater to the needs of the scientific community, we have developed a standalone software, pip package and web-based server ToxinPred3 (https://github.com/raghavagps/toxinpred3 and https://webs.iiitd.edu.in/raghava/toxinpred3/).",,1879-0534,,108926-108926, ,  ,,out_of_scope,
2534,"**Title**People who share encounters with racism are silenced online by humans and machines, but a guideline-reframing intervention holds promise

**Abstract**Are members of marginalized communities silenced on social media when they share personal experiences of racism? Here, we investigate the role of algorithms, humans, and platform guidelines in suppressing disclosures of racial discrimination. In a field study of actual posts from a neighborhood-based social media platform, we find that when users talk about their experiences as targets of racism, their posts are disproportionately flagged for removal as toxic by five widely used moderation algorithms from major online platforms, including the most recent large language models. We show that human users disproportionately flag these disclosures for removal as well. Next, in a follow-up experiment, we demonstrate that merely witnessing such suppression negatively influences how Black Americans view the community and their place in it. Finally, to address these challenges to equity and inclusion in online spaces, we introduce a mitigation strategy: a guideline-reframing intervention that is effective at reducing silencing behavior across the political spectrum.","Lee, Cinoo; Gligoric, Kristina; Kalluri, Pratyusha Ria; Harrington, Maggie; Durmus, Esin; Sanchez, Kiara L.; San, Nay; Tse, Danny; Zhao, Xuan; Hamedani, MarYam G.; Markus, Hazel Rose; Jurafsky, Dan; Eberhardt, Jennifer L.","Gligorić, Kristina/AAL-5227-2021","Gligoric, Kristina/0000-0001-8726-740X; Lee, Cinoo/0009-0002-1305-4705; Hamedani, MarYam/0000-0001-6925-4947","People who share encounters with racism are silenced online by humans and machines, but a guideline-reframing intervention holds promise",121,38,10.1073/pnas.2322764121 ,Article ,,"Are members of marginalized communities silenced on social media when they share personal experiences of racism? Here, we investigate the role of algorithms, humans, and platform guidelines in suppressing disclosures of racial discrimination. In a field study of actual posts from a neighborhood-based social media platform, we find that when users talk about their experiences as targets of racism, their posts are disproportionately flagged for removal as toxic by five widely used moderation algorithms from major online platforms, including the most recent large language models. We show that human users disproportionately flag these disclosures for removal as well. Next, in a follow-up experiment, we demonstrate that merely witnessing such suppression negatively influences how Black Americans view the community and their place in it. Finally, to address these challenges to equity and inclusion in online spaces, we introduce a mitigation strategy: a guideline-reframing intervention that is effective at reducing silencing behavior across the political spectrum.",0027-8424,1091-6490,,, ,  ,,detection#evaluation,
2535,"**Title**GeDi: Generative Discriminator Guided Sequence Generation

**Abstract**While large-scale language models (LMs) are able to imitate the distribution of natural language well enough to generate realistic text, it is difficult to control which regions of the distribution they generate. This is especially problematic because datasets used for training large LMs usually contain significant toxicity, hate, bias, and negativity. One promising approach to address this is to use discriminators to guide decoding from LMs, but existing methods for this are too slow to be useful in practice for many applications. We present GeDi as a significantly more efficient discriminator-based approach for guiding decoding. GeDi guides generation at each step by computing classification probabilities for all possible next tokens via Bayes rule by normalizing over two class-conditional distributions; one conditioned on the desired attribute, or control code, and another conditioned on the undesired attribute, or anti control code. We find that GeDi gives controllability on par with or better than previous controllable generation methods. GeDi results in significantly faster generation speeds than the only previous method that achieved comparable controllability in our experiments. We also show that GeDi can make GPT-2 and GPT-3 significantly less toxic while maintaining linguistic fluency, without sacrificing significantly on generation speed. Lastly, we find training GeDi on only three topics allows us to controllably generate new topics zero-shot from just a keyword.","Krause, Ben; Gotmare, Akhilesh Deepak; McCann, Bryan; Keskar, Nitish Shirish; Joty, Shafiq; Socher, Richard; Rajani, Nazneen Fatema",,,GeDi: Generative Discriminator Guided Sequence Generation,,, ,Proceedings Paper ,,"While large-scale language models (LMs) are able to imitate the distribution of natural language well enough to generate realistic text, it is difficult to control which regions of the distribution they generate. This is especially problematic because datasets used for training large LMs usually contain significant toxicity, hate, bias, and negativity. One promising approach to address this is to use discriminators to guide decoding from LMs, but existing methods for this are too slow to be useful in practice for many applications. We present GeDi as a significantly more efficient discriminator-based approach for guiding decoding. GeDi guides generation at each step by computing classification probabilities for all possible next tokens via Bayes rule by normalizing over two class-conditional distributions; one conditioned on the desired attribute, or control code, and another conditioned on the undesired attribute, or anti control code. We find that GeDi gives controllability on par with or better than previous controllable generation methods. GeDi results in significantly faster generation speeds than the only previous method that achieved comparable controllability in our experiments. We also show that GeDi can make GPT-2 and GPT-3 significantly less toxic while maintaining linguistic fluency, without sacrificing significantly on generation speed. Lastly, we find training GeDi on only three topics allows us to controllably generate new topics zero-shot from just a keyword.",,,978-1-955917-10-0,4929-4952, , Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP) ,,detox,
2536,"**Title**Jill Watson: A Virtual Teaching Assistant Powered by ChatGPT

**Abstract**Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.","Taneja, Karan; Maiti, Pratyusha; Kakar, Sandeep; Guruprasad, Pranav; Rao, Sanjeev; Goel, Ashok K.",,"Maiti, Pratyusha/0009-0005-4469-837X",Jill Watson: A Virtual Teaching Assistant Powered by ChatGPT,14829,,10.1007/978-3-031-64302-6_23 ,Proceedings Paper ,,"Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.",2945-9133,1611-3349,978-3-031-64301-9; 978-3-031-64302-6,324-337, , 25th International Conference on Artificial Intelligence in Education (AIED)25th International Conference on Artificial Intelligence in Education (AIED) ,,detox,
2537,"**Title**Toxic comments are associated with reduced activity of volunteer editors on Wikipedia

**Abstract**Wikipedia is one of the most successful collaborative projects in history. It is the largest encyclopedia ever created, with millions of users worldwide relying on it as the first source of information as well as for fact-checking and in-depth research. As Wikipedia relies solely on the efforts of its volunteer editors, its success might be particularly affected by toxic speech. In this paper, we analyze all 57 million comments made on user talk pages of 8.5 million editors across the six most active language editions of Wikipedia to study the potential impact of toxicity on editors' behavior. We find that toxic comments are consistently associated with reduced activity of editors, equivalent to 0.5-2 active days per user in the short term. This translates to multiple human-years of lost productivity, considering the number of active contributors to Wikipedia. The effects of toxic comments are potentially even greater in the long term, as they are associated with a significantly increased risk of editors leaving the project altogether. Using an agent-based model, we demonstrate that toxicity attacks on Wikipedia have the potential to impede the progress of the entire project. Our results underscore the importance of mitigating toxic speech on collaborative platforms such as Wikipedia to ensure their continued success.Significance StatementWhile the prevalence of toxic speech online is well studied, its true impact on the productivity of online communities remains largely unexplored. In this study, we focus on Wikipedia, which as the largest and most-read online reference, serves as a vital source of knowledge for millions of users worldwide. By analyzing all comments made over 20 years on user talk pages of 8.5 million editors across multiple language editions, we demonstrate that toxic speech is associated with a significant loss in the productivity of Wikipedia editors. These findings may have broad implications for large-scale collaborative projects and online communities, emphasizing the need to promote healthy and sustainable communication practices to protect crucial online information ecosystems and ensure their long-term success.","Smirnov, Ivan; Oprea, Camelia; Strohmaier, Markus","Smirnov, Ivan/K-5068-2015","Smirnov, Ivan/0000-0002-8347-6703",Toxic comments are associated with reduced activity of volunteer editors on Wikipedia,2,12,10.1093/pnasnexus/pgad385 ,Article ,,"Wikipedia is one of the most successful collaborative projects in history. It is the largest encyclopedia ever created, with millions of users worldwide relying on it as the first source of information as well as for fact-checking and in-depth research. As Wikipedia relies solely on the efforts of its volunteer editors, its success might be particularly affected by toxic speech. In this paper, we analyze all 57 million comments made on user talk pages of 8.5 million editors across the six most active language editions of Wikipedia to study the potential impact of toxicity on editors' behavior. We find that toxic comments are consistently associated with reduced activity of editors, equivalent to 0.5-2 active days per user in the short term. This translates to multiple human-years of lost productivity, considering the number of active contributors to Wikipedia. The effects of toxic comments are potentially even greater in the long term, as they are associated with a significantly increased risk of editors leaving the project altogether. Using an agent-based model, we demonstrate that toxicity attacks on Wikipedia have the potential to impede the progress of the entire project. Our results underscore the importance of mitigating toxic speech on collaborative platforms such as Wikipedia to ensure their continued success.Significance StatementWhile the prevalence of toxic speech online is well studied, its true impact on the productivity of online communities remains largely unexplored. In this study, we focus on Wikipedia, which as the largest and most-read online reference, serves as a vital source of knowledge for millions of users worldwide. By analyzing all comments made over 20 years on user talk pages of 8.5 million editors across multiple language editions, we demonstrate that toxic speech is associated with a significant loss in the productivity of Wikipedia editors. These findings may have broad implications for large-scale collaborative projects and online communities, emphasizing the need to promote healthy and sustainable communication practices to protect crucial online information ecosystems and ensure their long-term success.",,2752-6542,,, ,  ,,out_but_toxicity,
2538,"**Title**A visual approach to tracking emotional sentiment dynamics in social network commentaries

**Abstract**The expansion of social media has unlocked a real-time barometer of public opinion. This paper introduces a novel framework to analyze sentiment shifts in social network comment sections, a reflection of the broader public discourse over time. Leveraging a pre-trained uncased RoBERTalarge\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$RoBERTa_{large}$$\end{document} model, we predict emotional scores from user comments, mapping these to key sentiment trends such as Approval, Toxicity, Obscenity, Threat, Hate, Offensive, and Neutral. Our methodology employs machine learning techniques to train a dataset that connects emotional scores with these trends, generating trend probability scores. We utilize a bottom-up recursive algorithm to aggregate emotional scores within comment threads, enabling the prediction of trend scores using three distinct aggregation methods. The results demonstrate that our emotional prediction model achieves an AUC of 0.92, and XGBoost stands out with an F1 score exceeding 0.40. Our research elucidates the temporal evolution of online public sentiment, enhancing the understanding of digital social dynamics and offering insights for strategic online interaction, intervention, and content moderation.","Hossain, Ismail; Puppala, Sai; Alam, Md. Jahangir; Talukder, Sajedul","Puppala, Sai/JYQ-0856-2024; Hossain, Ismail/ABM-8339-2022; Alam, Md. Jahangir/HZM-3321-2023",,A visual approach to tracking emotional sentiment dynamics in social network commentaries,14,1,10.1007/s13278-024-01332-8 ,Article ,,"The expansion of social media has unlocked a real-time barometer of public opinion. This paper introduces a novel framework to analyze sentiment shifts in social network comment sections, a reflection of the broader public discourse over time. Leveraging a pre-trained uncased RoBERTalarge\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$RoBERTa_{large}$$\end{document} model, we predict emotional scores from user comments, mapping these to key sentiment trends such as Approval, Toxicity, Obscenity, Threat, Hate, Offensive, and Neutral. Our methodology employs machine learning techniques to train a dataset that connects emotional scores with these trends, generating trend probability scores. We utilize a bottom-up recursive algorithm to aggregate emotional scores within comment threads, enabling the prediction of trend scores using three distinct aggregation methods. The results demonstrate that our emotional prediction model achieves an AUC of 0.92, and XGBoost stands out with an F1 score exceeding 0.40. Our research elucidates the temporal evolution of online public sentiment, enhancing the understanding of digital social dynamics and offering insights for strategic online interaction, intervention, and content moderation.",1869-5450,1869-5469,,, ,  ,,out_but_toxicity,
2539,"**Title**A Comprehensive Analysis of the per- and poly-fluoroalkyl substances (PFAS) research landscape through AI-assisted text mining

**Abstract**Per- and poly-fluoroalkyl substances (PFAS) have been widely used in various industrial applications due to their unique properties. This study aims to provide a comprehensive analysis of PFAS research trends using a novel approach combining text mining techniques and large-scale language models (LLMs). PFAS-related scientific literature published from 1980 to 2024 was gathered from Scopus, and KH Coder and Claude 3 were used to perform the analysis. The results showed a significant increase in research output and a clear shift in research topics over the past 40 years. Whereas in the past, the focus was on analytical methods, more recently, the emphasis has been on environmental fate, toxicity assessment, alternative compounds, and regulation. With Claude 3, research areas can now be identified without reviewing the results of expert text mining. Comparisons of AI-extracted trends with insights from traditional review articles showed strong agreement, confirming the effectiveness of this approach. These findings suggest the need for continued interdisciplinary research on PFAS such as the development of remediation strategies, elucidation of health effects, and evidence-based policy- making. This study showed the possibility of integrating text mining and LLM for a comprehensive analysis of research trends, which will accelerate future research and development strategies.","Kobayashi, Yoshiyuki; Uchida, Takumi; Inoue, Takahiro; Iwasaki, Yusuke; Ito, Rie; Akiyama, Hiroshi","Inoue, Takahiro/M-4754-2018","Uchida, Takumi/0000-0003-4686-638X",A Comprehensive Analysis of the per- and poly-fluoroalkyl substances (PFAS) research landscape through AI-assisted text mining,5,,10.1016/j.hazl.2024.100121 ,Article ,,"Per- and poly-fluoroalkyl substances (PFAS) have been widely used in various industrial applications due to their unique properties. This study aims to provide a comprehensive analysis of PFAS research trends using a novel approach combining text mining techniques and large-scale language models (LLMs). PFAS-related scientific literature published from 1980 to 2024 was gathered from Scopus, and KH Coder and Claude 3 were used to perform the analysis. The results showed a significant increase in research output and a clear shift in research topics over the past 40 years. Whereas in the past, the focus was on analytical methods, more recently, the emphasis has been on environmental fate, toxicity assessment, alternative compounds, and regulation. With Claude 3, research areas can now be identified without reviewing the results of expert text mining. Comparisons of AI-extracted trends with insights from traditional review articles showed strong agreement, confirming the effectiveness of this approach. These findings suggest the need for continued interdisciplinary research on PFAS such as the development of remediation strategies, elucidation of health effects, and evidence-based policy- making. This study showed the possibility of integrating text mining and LLM for a comprehensive analysis of research trends, which will accelerate future research and development strategies.",2666-9110,,,, ,  ,,out_of_scope,
2540,"**Title**An Invariant Learning Characterization of Controlled Text Generation

**Abstract**Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. Many approaches reduce this problem to training a predictor of the desired attribute. For example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. In practice, the generated text to classify, which is determined by user prompts, may come from a wide range of distributions. In this paper, we show that the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on. To address this problem, we cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. We then discuss a natural solution that arises from this characterization and propose heuristics for selecting natural environments. We study this characterization and the proposed method empirically using both synthetic and real data. Experiments demonstrate both the challenge of distribution shift in controlled generation and the potential of invariance methods in this setting.","Zheng, Carolina; Shi, Claudia; Vafa, Keyon; Feder, Amir; Blei, David M.",,,An Invariant Learning Characterization of Controlled Text Generation,,, ,Proceedings Paper ,,"Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. Many approaches reduce this problem to training a predictor of the desired attribute. For example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. In practice, the generated text to classify, which is determined by user prompts, may come from a wide range of distributions. In this paper, we show that the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on. To address this problem, we cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. We then discuss a natural solution that arises from this characterization and propose heuristics for selecting natural environments. We study this characterization and the proposed method empirically using both synthetic and real data. Experiments demonstrate both the challenge of distribution shift in controlled generation and the potential of invariance methods in this setting.",,,978-1-959429-72-2,3186-3206, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2541,"**Title**Can You Label Less by Using Out-of-Domain Data? Active & Transfer Learning with Few-shot Instructions

**Abstract**Labeling social-media data for custom dimensions of toxicity and social bias is challenging and labor-intensive. Existing transfer and active learning approaches meant to reduce annotation effort require fine-tuning, which suffers from overfitting to noise and can cause domain shift with small sample sizes. In this work, we propose a novel Active Transfer Few-shot Instructions (ATF) approach which requires no fine-tuning. ATF leverages the internal linguistic knowledge of pretrained language models (PLMs) to facilitate the transfer of information from existing pre-labeled datasets (source-domain task) with minimum labeling effort on unlabeled target data (target-domain task). Our strategy can yield positive transfer achieving a mean AUC gain of 10.5% compared to no transfer with a large 22b parameter PLM. We further show that annotation of just a few target-domain samples via active learning can be beneficial for transfer, but the impact diminishes with more annotation effort (26% drop in gain between 100 and 2000 annotated examples). Finally, we find that not all transfer scenarios yield a positive gain, which seems related to the PLMs initial performance on the target-domain task.","Kocielnik, Rafal; Kangaslahti, Sara; Prabhumoye, Shrimai; Hari, Meena; Alvarez, R. Michael; Anandkumar, Anima",,,Can You Label Less by Using Out-of-Domain Data? Active & Transfer Learning with Few-shot Instructions,203,, ,Proceedings Paper ,,"Labeling social-media data for custom dimensions of toxicity and social bias is challenging and labor-intensive. Existing transfer and active learning approaches meant to reduce annotation effort require fine-tuning, which suffers from overfitting to noise and can cause domain shift with small sample sizes. In this work, we propose a novel Active Transfer Few-shot Instructions (ATF) approach which requires no fine-tuning. ATF leverages the internal linguistic knowledge of pretrained language models (PLMs) to facilitate the transfer of information from existing pre-labeled datasets (source-domain task) with minimum labeling effort on unlabeled target data (target-domain task). Our strategy can yield positive transfer achieving a mean AUC gain of 10.5% compared to no transfer with a large 22b parameter PLM. We further show that annotation of just a few target-domain samples via active learning can be beneficial for transfer, but the impact diminishes with more annotation effort (26% drop in gain between 100 and 2000 annotated examples). Finally, we find that not all transfer scenarios yield a positive gain, which seems related to the PLMs initial performance on the target-domain task.",2640-3498,,*****************,22-32, , Workshop on Transfer Learning for Natural Language ProcessingWorkshop on Transfer Learning for Natural Language Processing ,,detection,
2542,"**Title**HOT ChatGPT: ThePromiseofChatGPTinDetectingand Discriminating Hateful, Offensive, and Toxic Comments on Social Media

**Abstract**Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies hateful andoffensive as subsets of toxic. Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.","Li, Lingyao; Fan, Lizhou; Atreja, Shubham; Hemphill, Libby","Hemphill, Libby/AAH-7062-2019","Atreja, Shubham/0000-0002-0056-3060; Fan, Lizhou/0000-0002-7962-9113; Hemphill, Libby/0000-0002-3793-7281","HOT ChatGPT: ThePromiseofChatGPTinDetectingand Discriminating Hateful, Offensive, and Toxic Comments on Social Media",18,2,10.1145/3643829 ,Article ,,"Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies hateful andoffensive as subsets of toxic. Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.",1559-1131,1559-114X,,, ,  ,,detection,
2543,"**Title**Exploring Cross-lingual Textual Style Transfer with Large Multilingual Language Models

**Abstract**Detoxification is a task of generating text in polite style while preserving meaning and fluency of the original toxic text. Existing detoxification methods are designed to work in one exact language. This work investigates multilingual and cross-lingual detoxification and the behavior of large multilingual models like in this setting. Unlike previous works we aim to make large language models able to perform detoxification without direct fine-tuning in given language. Experiments show that multilingual models are capable of performing multilingual style transfer. However, models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is inevitable.","Moskovskiy, Daniil; Dementieva, Daryna; Panchenko, Alexander","Panchenko, Alexander/AAQ-7808-2021",,Exploring Cross-lingual Textual Style Transfer with Large Multilingual Language Models,,, ,Proceedings Paper ,,"Detoxification is a task of generating text in polite style while preserving meaning and fluency of the original toxic text. Existing detoxification methods are designed to work in one exact language. This work investigates multilingual and cross-lingual detoxification and the behavior of large multilingual models like in this setting. Unlike previous works we aim to make large language models able to perform detoxification without direct fine-tuning in given language. Experiments show that multilingual models are capable of performing multilingual style transfer. However, models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is inevitable.",,,978-1-955917-23-0,346-354, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL) ,,out_but_toxicity,
2544,"**Title**ParaDetox: Detoxification with Parallel Data

**Abstract**We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task. We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.","Logacheva, Varvara; Dementieva, Daryna; Ustyantsev, Sergey; Moskovskiy, Daniil; Dale, David; Krotova, Irina; Semenov, Nikita; Panchenko, Alexander","Panchenko, Alexander/AAQ-7808-2021",,ParaDetox: Detoxification with Parallel Data,,, ,Proceedings Paper ,,"We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task. We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.",,,978-1-955917-21-6,6804-6818, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL) ,,detox,
2545,"**Title**Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification Condensed Lab Overview

**Abstract**The goal of the PAN lab is to advance the state of the art in text forensics and stylometry through an objective evaluation of new and established methods on new benchmark datasets. IN 2024, we organized four shared tasks: (1) multi-author writing style analysis, which we continue from 2023; (2) multilingual text detoxification, a new task that aims to re-formulate text in a non-toxic way for multiple languages; (3) oppositional thinking analysis, a new task that aims to discriminate critical thinking from conspiracy narratives and identify their core actors; and (4) generative AI authorship verification, which formulates the detection of AI-generated text as an authorship problem. PAN 2024 concluded as one of our most successful editions with 74 notebook papers by 147 participating teams.","Ayele, Abinew Ali; Babakov, Nikolay; Bevendorff, Janek; Casals, Xavier Bonet; Chulvi, Berta; Dementieva, Daryna; Elnagar, Ashaf; Freitag, Dayne; Froebe, Maik; Korencic, Damir; Mayerl, Maximilian; Moskovskiy, Daniil; Mukherjee, Animesh; Panchenko, Alexander; Potthast, Martin; Rangel, Francisco; Rizwan, Naquee; Rosso, Paolo; Schneider, Florian; Smirnova, Alisa; Stamatatos, Efstathios; Stakovskii, Elisei; Stein, Benno; Taule, Mariona; Ustalov, Dmitry; Wang, Xintong; Wiegmann, Matti; Yimam, Seid Muhie; Zangerle, Eva","Panchenko, Alexander/T-7560-2017; Zangerle, Eva/AAB-3833-2020; Chulvi, Berta/HJY-1145-2023; Stamatatos, Efstathios/F-2927-2012; Ustalov, Dmitry/P-6307-2014",,"Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification Condensed Lab Overview",14959,,10.1007/978-3-031-71908-0_11 ,Proceedings Paper ,,"The goal of the PAN lab is to advance the state of the art in text forensics and stylometry through an objective evaluation of new and established methods on new benchmark datasets. IN 2024, we organized four shared tasks: (1) multi-author writing style analysis, which we continue from 2023; (2) multilingual text detoxification, a new task that aims to re-formulate text in a non-toxic way for multiple languages; (3) oppositional thinking analysis, a new task that aims to discriminate critical thinking from conspiracy narratives and identify their core actors; and (4) generative AI authorship verification, which formulates the detection of AI-generated text as an authorship problem. PAN 2024 concluded as one of our most successful editions with 74 notebook papers by 147 participating teams.",0302-9743,1611-3349,978-3-031-71907-3; 978-3-031-71908-0,231-259, , 15th International Conference of the Cross-Language-Evaluation-Forum-Association (CLEF)15th International Conference of the Cross-Language-Evaluation-Forum-Association (CLEF) ,,detox,
2546,"**Title**Secondary hospital wastewater detoxification and disinfection by advanced oxidation processes

**Abstract**Secondary hospital wastewater treatment was investigated as an alternative to detoxification and disinfection after anaerobic digestion in a hospital located in southern Brazil. Tertiary and secondary effluents were assessed by general parameters. The use of advanced oxidation processes (UV/O-3, and UV /TiO2/O-3) showed potential capacity for disinfection and cletoxification of wastewater effluents. The UV/TiO2/O-3 method yielded the best results, decreasing toxicity of EC50 = 65 to nontoxic levels, also reducing MPN/100ml of 1.1 x 10(6) to values less than 2 and increasing wastewater biodegradability. The low energetic consumption of the proposed UV/TiO2/O-3 method can be considered operationally advantageous.","Machado, L. E.; Kist, L. T.; Schmidt, R.; Hoeltz, J. M.; Dalberto, D.; Alcayaga, E. L. A.","Machado, Enio Leandro/H-5120-2013; Kist, Lourdes/A-1235-2018","Machado, Enio Leandro/0000-0003-0140-4966; Kist, Lourdes/0000-0003-3278-8966",Secondary hospital wastewater detoxification and disinfection by advanced oxidation processes,28,10,10.1080/09593332808618876 ,Article ,,"Secondary hospital wastewater treatment was investigated as an alternative to detoxification and disinfection after anaerobic digestion in a hospital located in southern Brazil. Tertiary and secondary effluents were assessed by general parameters. The use of advanced oxidation processes (UV/O-3, and UV /TiO2/O-3) showed potential capacity for disinfection and cletoxification of wastewater effluents. The UV/TiO2/O-3 method yielded the best results, decreasing toxicity of EC50 = 65 to nontoxic levels, also reducing MPN/100ml of 1.1 x 10(6) to values less than 2 and increasing wastewater biodegradability. The low energetic consumption of the proposed UV/TiO2/O-3 method can be considered operationally advantageous.",0959-3330,1479-487X,,1135-1143, ,  ,,out_of_scope,
2547,"**Title**Use of Vero cell line to verify the biodetoxification efficiency of castor bean waste

**Abstract**Ricin is a toxic protein present in castor bean seeds (Ricinus communis). A toxic residue named castor bean waste is generated during biodiesel production process, such as that developed by PETROBRAS (the national petroleum company of Brazil). Solid-state fermentation (SSF) was used to detoxify castor bean waste through the Penicillium simplicissimum growth. After 24 h of fungal growth, the ricin was no longer identified by Sephadex G-50 gel chromatography. In order to verify the biological activity of ricin after several treatment stages, an in vitro assay using Vero cell line was carried out. Through this methodology, it was verified that after 24 and 48 h of treatment, the cell culture showed slightly growth inhibition. The waste was completely detoxified only after 72 h of fungal growth. This fact shows that an in vitro assay is important to verify the real efficiency of detoxification. Moreover, a relationship between the fungal protease production and the waste detoxification was observed. (C) 2011 Elsevier Ltd. All rights reserved.","Godoy, Mateus G.; Fernandes, Keysson V.; Gutarra, Melissa L. E.; Melo, Edesio J. T.; Castro, Aline M.; Machado, Olga L. T.; Freire, Denise M. G.","Machado, Olga/P-1944-2019; Gutarra, Melissa/J-5706-2015; Godoy, Mateus/D-9977-2015; CASTRO, ALINE/C-4984-2015; Freire, Denise Maria Guimaraes/D-8699-2014","Machado, Olga/0000-0003-0647-1762; Gutarra, Melissa/0000-0003-2480-7223; Godoy, Mateus/0000-0003-2209-7993; CASTRO, ALINE/0000-0002-1355-8455; Freire, Denise Maria Guimaraes/0000-0002-8298-5936",Use of Vero cell line to verify the biodetoxification efficiency of castor bean waste,47,4,10.1016/j.procbio.2011.12.011 ,Article ,,"Ricin is a toxic protein present in castor bean seeds (Ricinus communis). A toxic residue named castor bean waste is generated during biodiesel production process, such as that developed by PETROBRAS (the national petroleum company of Brazil). Solid-state fermentation (SSF) was used to detoxify castor bean waste through the Penicillium simplicissimum growth. After 24 h of fungal growth, the ricin was no longer identified by Sephadex G-50 gel chromatography. In order to verify the biological activity of ricin after several treatment stages, an in vitro assay using Vero cell line was carried out. Through this methodology, it was verified that after 24 and 48 h of treatment, the cell culture showed slightly growth inhibition. The waste was completely detoxified only after 72 h of fungal growth. This fact shows that an in vitro assay is important to verify the real efficiency of detoxification. Moreover, a relationship between the fungal protease production and the waste detoxification was observed. (C) 2011 Elsevier Ltd. All rights reserved.",1359-5113,,,578-584, ,  ,,out_of_scope,
2548,"**Title**Studying the Role of Named Entities for Content Preservation in Text Style Transfer

**Abstract**Text style transfer techniques are gaining popularity in Natural Language Processing, finding various applications such as text detoxification, sentiment, or formality transfer. However, the majority of the existing approaches were tested on such domains as online communications on public platforms, music, or entertainment yet none of them were applied to the domains which are typical for task-oriented production systems, such as personal plans arrangements (e.g. booking of flights or reserving a table in a restaurant). We fill this gap by studying formality transfer in this domain.We noted that, the texts in this domain are full of named entities, which are very important for keeping the original sense of the text. Indeed, if for example, someone communicates destination city of a flight is must not be altered. Thus, we concentrate on the role of named entities in content preservation for formality text style transfer.We collect a new dataset for the evaluation of content similarity measures in text style transfer. It is taken from a corpus of task-oriented dialogues and contains many important entities related to realistic requests that make this dataset particularly useful for testing style transfer models before using them in production. Besides, we perform an error analysis of a pre-trained formality transfer model and introduce a simple technique to use information about named entities to enhance the performance of baseline content similarity measures used in text style transfer.","Babakov, Nikolay; Dale, David; Logacheva, Varvara; Krotova, Irina; Panchenko, Alexander","Panchenko, Alexander/AAQ-7808-2021","Babakov, Nikolay/0000-0002-2568-6702",Studying the Role of Named Entities for Content Preservation in Text Style Transfer,13286,,10.1007/978-3-031-08473-7_40 ,Proceedings Paper ,,"Text style transfer techniques are gaining popularity in Natural Language Processing, finding various applications such as text detoxification, sentiment, or formality transfer. However, the majority of the existing approaches were tested on such domains as online communications on public platforms, music, or entertainment yet none of them were applied to the domains which are typical for task-oriented production systems, such as personal plans arrangements (e.g. booking of flights or reserving a table in a restaurant). We fill this gap by studying formality transfer in this domain.We noted that, the texts in this domain are full of named entities, which are very important for keeping the original sense of the text. Indeed, if for example, someone communicates destination city of a flight is must not be altered. Thus, we concentrate on the role of named entities in content preservation for formality text style transfer.We collect a new dataset for the evaluation of content similarity measures in text style transfer. It is taken from a corpus of task-oriented dialogues and contains many important entities related to realistic requests that make this dataset particularly useful for testing style transfer models before using them in production. Besides, we perform an error analysis of a pre-trained formality transfer model and introduce a simple technique to use information about named entities to enhance the performance of baseline content similarity measures used in text style transfer.",0302-9743,1611-3349,978-3-031-08473-7; 978-3-031-08472-0,437-448, , 27th International Conference on Applications of Natural Language to Information Systems (NLDB)27th International Conference on Applications of Natural Language to Information Systems (NLDB) ,,detox,
2549,"**Title**Fine-Grained Human Feedback Gives Better Rewards for Language Model Training

**Abstract**Language models (LMs) often exhibit undesirable text generation behaviors, including generating false, toxic, or irrelevant outputs. Reinforcement learning from human feedback (RLHF)-where human preference judgments on LM outputs are transformed into a learning signal-has recently shown promise in addressing these issues. However, such holistic feedback conveys limited information on long text outputs; it does not indicate which aspects of the outputs influenced user preference; e.g., which parts contain what type(s) of errors. In this paper, we use fine-grained human feedback (e.g., which sentence is false, which sub-sentence is irrelevant) as an explicit training signal. We introduce FINE-GRAINED RLHF, a framework that enables training and learning from reward functions that are fine-grained in two respects: (1) density, providing a reward after every segment (e.g., a sentence) is generated; and (2) incorporating multiple reward models associated with different feedback types (e.g., factual incorrectness, irrelevance, and information incompleteness). We conduct experiments on detoxification and long-form question answering to illustrate how learning with such reward functions leads to improved performance, supported by both automatic and human evaluation. Additionally, we show that LM behaviors can be customized using different combinations of fine-grained reward models. We release all data, collected human feedback, and codes at https://FineGrainedRLHF.github.io.","Wu, Zeqiu; Hu, Yushi; Shi, Weijia; Dziri, Nouha; Suhr, Alane; Ammanabrolu, Prithviraj; Smith, Noah A.; Ostendorf, Mari; Hajishirzi, Hannaneh",,,Fine-Grained Human Feedback Gives Better Rewards for Language Model Training,,, ,Proceedings Paper ,,"Language models (LMs) often exhibit undesirable text generation behaviors, including generating false, toxic, or irrelevant outputs. Reinforcement learning from human feedback (RLHF)-where human preference judgments on LM outputs are transformed into a learning signal-has recently shown promise in addressing these issues. However, such holistic feedback conveys limited information on long text outputs; it does not indicate which aspects of the outputs influenced user preference; e.g., which parts contain what type(s) of errors. In this paper, we use fine-grained human feedback (e.g., which sentence is false, which sub-sentence is irrelevant) as an explicit training signal. We introduce FINE-GRAINED RLHF, a framework that enables training and learning from reward functions that are fine-grained in two respects: (1) density, providing a reward after every segment (e.g., a sentence) is generated; and (2) incorporating multiple reward models associated with different feedback types (e.g., factual incorrectness, irrelevance, and information incompleteness). We conduct experiments on detoxification and long-form question answering to illustrate how learning with such reward functions leads to improved performance, supported by both automatic and human evaluation. Additionally, we show that LM behaviors can be customized using different combinations of fine-grained reward models. We release all data, collected human feedback, and codes at https://FineGrainedRLHF.github.io.",1049-5258,,*****************,, , 37th Conference on Neural Information Processing Systems (NeurIPS)37th Conference on Neural Information Processing Systems (NeurIPS) ,,detox,
2550,No abstract available,"DUFOUR, DL",,,EFFECTIVENESS OF CASSAVA DETOXIFICATION TECHNIQUES USED BY INDIGENOUS PEOPLES IN NORTHWEST AMAZONIA,14,2, ,Article ,,,0378-1844,,,86-91, ,  ,,out_of_scope,
2551,"**Title**The cognitive niche: Coevolution of intelligence, sociality, and language

**Abstract**Although Darwin insisted that human intelligence could be fully explained by the theory of evolution, the codiscoverer of natural selection, Alfred Russel Wallace, claimed that abstract intelligence was of no use to ancestral humans and could only be explained by intelligent design. Wallace's apparent paradox can be dissolved with two hypotheses about human cognition. One is that intelligence is an adaptation to a knowledge-using, socially interdependent lifestyle, the cognitive niche. This embraces the ability to overcome the evolutionary fixed defenses of plants and animals by applications of reasoning, including weapons, traps, coordinated driving of game, and detoxification of plants. Such reasoning exploits intuitive theories about different aspects of the world, such as objects, forces, paths, places, states, substances, and other people's beliefs and desires. The theory explains many zoologically unusual traits in Homo sapiens, including our complex toolkit, wide range of habitats and diets, extended childhoods and long lives, hypersociality, complex mating, division into cultures, and language (which multiplies the benefit of knowledge because know-how is useful not only for its practical benefits but as a trade good with others, enhancing the evolution of cooperation). The second hypothesis is that humans possess an ability of metaphorical abstraction, which allows them to coopt faculties that originally evolved for physical problem-solving and social coordination, apply them to abstract subject matter, and combine them productively. These abilities can help explain the emergence of abstract cognition without supernatural or exotic evolutionary forces and are in principle testable by analyses of statistical signs of selection in the human genome.","Pinker, Steven","Pinker, Steven/GPX-7942-2022",,"The cognitive niche: Coevolution of intelligence, sociality, and language",107,,10.1073/pnas.0914630107 ,Article ,,"Although Darwin insisted that human intelligence could be fully explained by the theory of evolution, the codiscoverer of natural selection, Alfred Russel Wallace, claimed that abstract intelligence was of no use to ancestral humans and could only be explained by intelligent design. Wallace's apparent paradox can be dissolved with two hypotheses about human cognition. One is that intelligence is an adaptation to a knowledge-using, socially interdependent lifestyle, the cognitive niche. This embraces the ability to overcome the evolutionary fixed defenses of plants and animals by applications of reasoning, including weapons, traps, coordinated driving of game, and detoxification of plants. Such reasoning exploits intuitive theories about different aspects of the world, such as objects, forces, paths, places, states, substances, and other people's beliefs and desires. The theory explains many zoologically unusual traits in Homo sapiens, including our complex toolkit, wide range of habitats and diets, extended childhoods and long lives, hypersociality, complex mating, division into cultures, and language (which multiplies the benefit of knowledge because know-how is useful not only for its practical benefits but as a trade good with others, enhancing the evolution of cooperation). The second hypothesis is that humans possess an ability of metaphorical abstraction, which allows them to coopt faculties that originally evolved for physical problem-solving and social coordination, apply them to abstract subject matter, and combine them productively. These abilities can help explain the emergence of abstract cognition without supernatural or exotic evolutionary forces and are in principle testable by analyses of statistical signs of selection in the human genome.",0027-8424,,,8993-8999, ,  ,,out_of_scope,
2552,"**Title**The Eucalyptus grandis chloroplast proteome: Seasonal variations in leaf development

**Abstract**Chloroplast metabolism is very sensitive to environmental fluctuations and is intimately related to plant leaf development. Characterization of the chloroplast proteome dynamics can contribute to a better understanding on plant adaptation to different climate scenarios and leaf development processes. Herein, we carried out a discovery-driven analysis of the Eucalyptus grandis chloroplast proteome during leaf maturation and throughout different seasons of the year. The chloroplast proteome from young leaves differed the most from all assessed samples. Most upregulated proteins identified in mature and young leaves were those related to catabolic-redox signaling and biogenesis processes, respectively. Seasonal dynamics revealed unique proteome features in the fall and spring periods. The most abundant chloroplast protein in humid (wet) seasons (spring and summer) was a small subunit of RuBisCO, while in the dry periods (fall and winter) the proteins that showed the most pronounced accumulation were associated with photo-oxidative damage, Calvin cycle, shikimate pathway, and detoxification. Our investigation of the chloroplast proteome dynamics during leaf development revealed significant alterations in relation to the maturation event. Our findings also suggest that transition seasons induced the most pronounced chloroplast proteome changes over the year. This study contributes to a more comprehensive understanding on the subcellular mechanisms that lead to plant leaf adaptation and ultimately gives more insights into Eucalyptus grandis phenology.","Baldassi, Amanda Cristina; Balbuena, Tiago Santana","Balbuena, Tiago/IUN-0234-2023","Balbuena, Tiago/0000-0002-1053-0254",The Eucalyptus grandis chloroplast proteome: Seasonal variations in leaf development,17,9,10.1371/journal.pone.0265134 ,Article ,,"Chloroplast metabolism is very sensitive to environmental fluctuations and is intimately related to plant leaf development. Characterization of the chloroplast proteome dynamics can contribute to a better understanding on plant adaptation to different climate scenarios and leaf development processes. Herein, we carried out a discovery-driven analysis of the Eucalyptus grandis chloroplast proteome during leaf maturation and throughout different seasons of the year. The chloroplast proteome from young leaves differed the most from all assessed samples. Most upregulated proteins identified in mature and young leaves were those related to catabolic-redox signaling and biogenesis processes, respectively. Seasonal dynamics revealed unique proteome features in the fall and spring periods. The most abundant chloroplast protein in humid (wet) seasons (spring and summer) was a small subunit of RuBisCO, while in the dry periods (fall and winter) the proteins that showed the most pronounced accumulation were associated with photo-oxidative damage, Calvin cycle, shikimate pathway, and detoxification. Our investigation of the chloroplast proteome dynamics during leaf development revealed significant alterations in relation to the maturation event. Our findings also suggest that transition seasons induced the most pronounced chloroplast proteome changes over the year. This study contributes to a more comprehensive understanding on the subcellular mechanisms that lead to plant leaf adaptation and ultimately gives more insights into Eucalyptus grandis phenology.",1932-6203,,,, ,  ,,out_of_scope,
2553,"**Title**The Role of Reactive Oxygen Species in Anopheles aquasalis Response to Plasmodium vivax Infection

**Abstract**Malaria affects millions of people worldwide and hundreds of thousands of people each year in Brazil. The mosquito Anopheles aquasalis is an important vector of Plasmodium vivax, the main human malaria parasite in the Americas. Reactive oxygen species (ROS) have been shown to have a role in insect innate immune responses as a potent pathogen-killing agent. We investigated the mechanisms of free radicals modulation after A. aquasalis infection with P. vivax. ROS metabolism was evaluated in the vector by studying expression and activity of three key detoxification enzymes, one catalase and two superoxide dismutases (SOD3A and SOD3B). Also, the involvement of free radicals in the mosquito immunity was measured by silencing the catalase gene followed by infection of A. aquasalis with P. vivax. Catalase, SOD3A and SOD3B expression in whole A. aquasalis were at the same levels of controls at 24 h and upregulated 36 h after ingestion of blood containing P. vivax. However, in the insect isolated midgut, the mRNA for these enzymes was not regulated by P. vivax infection, while catalase activity was reduced 24 h after the infectious meal. RNAi-mediated silencing of catalase reduced enzyme activity in the midgut, resulted in increased P. vivax infection and prevalence, and decreased bacterial load in the mosquito midgut. Our findings suggest that the interactions between A. aquasalis and P. vivax do not follow the model of ROS-induced parasite killing. It appears that P. vivax manipulates the mosquito detoxification system in order to allow its own development. This can be an indirect effect of fewer competitive bacteria present in the mosquito midgut caused by the increase of ROS after catalase silencing. These findings provide novel information on unique aspects of the main malaria parasite in the Americas interaction with one of its natural vectors.","Bahia, Ana C.; Oliveira, Jose Henrique M.; Kubota, Marina S.; Araujo, Helena R. C.; Lima, Jose B. P.; Rios-Velasquez, Claudia Maria; Lacerda, Marcus Vinicius G.; Oliveira, Pedro L.; Traub-Csekoe, Yara M.; Pimenta, Paulo F. P.","Araujo, Helena/J-9209-2015; Traub-Cseko, Yara/F-2723-2015; Pimenta, Paulo/AAH-1502-2020; Velasquez, Claudia/K-2901-2015; L. Oliveira, Pedro/A-9438-2010; Oliveira, Jose Henrique M./IWU-9990-2023; Guimaraes de Lacerda, Marcus Vinicius/D-3144-2013; Bahia Nascimento, Ana Cristina/G-2372-2015","Correa de Araujo Gomes, Helena/0000-0002-2021-2217; L. Oliveira, Pedro/0000-0003-0307-354X; Oliveira, Jose Henrique M./0000-0003-3814-5312; Guimaraes de Lacerda, Marcus Vinicius/0000-0003-3374-9985; Bahia Nascimento, Ana Cristina/0000-0002-4584-1888",The Role of Reactive Oxygen Species in Anopheles aquasalis Response to Plasmodium vivax Infection,8,2,10.1371/journal.pone.0057014 ,Article ,,"Malaria affects millions of people worldwide and hundreds of thousands of people each year in Brazil. The mosquito Anopheles aquasalis is an important vector of Plasmodium vivax, the main human malaria parasite in the Americas. Reactive oxygen species (ROS) have been shown to have a role in insect innate immune responses as a potent pathogen-killing agent. We investigated the mechanisms of free radicals modulation after A. aquasalis infection with P. vivax. ROS metabolism was evaluated in the vector by studying expression and activity of three key detoxification enzymes, one catalase and two superoxide dismutases (SOD3A and SOD3B). Also, the involvement of free radicals in the mosquito immunity was measured by silencing the catalase gene followed by infection of A. aquasalis with P. vivax. Catalase, SOD3A and SOD3B expression in whole A. aquasalis were at the same levels of controls at 24 h and upregulated 36 h after ingestion of blood containing P. vivax. However, in the insect isolated midgut, the mRNA for these enzymes was not regulated by P. vivax infection, while catalase activity was reduced 24 h after the infectious meal. RNAi-mediated silencing of catalase reduced enzyme activity in the midgut, resulted in increased P. vivax infection and prevalence, and decreased bacterial load in the mosquito midgut. Our findings suggest that the interactions between A. aquasalis and P. vivax do not follow the model of ROS-induced parasite killing. It appears that P. vivax manipulates the mosquito detoxification system in order to allow its own development. This can be an indirect effect of fewer competitive bacteria present in the mosquito midgut caused by the increase of ROS after catalase silencing. These findings provide novel information on unique aspects of the main malaria parasite in the Americas interaction with one of its natural vectors.",1932-6203,,,, ,  ,,out_of_scope,
2554,"**Title**Exploring Gut Microbiome Variations between Popillia japonica Populations of Azores

**Abstract**Popillia japonica (Coleoptera: Scarabaeidae), is an emerging invasive pest in Europe and America. In the Azores, this pest was first found on Terceira Island during the sixties and soon spread to other islands. The rate of infestation differs between islands, and we hypothesized that microbiome composition could play a role. Therefore, we sampled 3rd instar larvae and soil from sites with high and low infestation rates to analyze the microbiome using next-generation sequencing. We analyzed twenty-four 16S DNA libraries, which resulted in 3278 operational taxonomic units. The alpha and beta diversity of the soil microbiome was similar between sites. In contrast, the larvae from high-density sites presented a higher bacterial gut diversity than larvae from low-density sites, with biomarkers linked to plant digestion, nutrient acquisition, and detoxification. Consequently, larvae from high-density sites displayed several enriched molecular functions associated with the families Ruminococcaceae, Clostridiaceae and Rikenellaceae. These bacteria revealed a supportive function by producing several CAZyme families and other proteins. These findings suggest that the microbiome must be one drive for the increase in P. japonica populations, thus providing a checkpoint in the establishment and spread of this pest.","Frias, Jorge; Garriga, Anna; Penalver, Angel; Teixeira, Mario; Beltri, Ruben; Toubarro, Duarte; Simoes, Nelson","Teixeira, Mario/D-1654-2013; Toubarro, Duarte/HPE-4924-2023; Garriga, Anna/IXN-7558-2023; Toubarro, Duarte/K-3881-2013","Toubarro, Duarte/0000-0003-2025-9696; Garriga, Anna/0000-0001-9198-652X; Frias, Jorge/0000-0003-1373-6060; Teixeira, Mario/0000-0001-9615-0879",Exploring Gut Microbiome Variations between Popillia japonica Populations of Azores,11,8,10.3390/microorganisms11081972 ,Article ,,"Popillia japonica (Coleoptera: Scarabaeidae), is an emerging invasive pest in Europe and America. In the Azores, this pest was first found on Terceira Island during the sixties and soon spread to other islands. The rate of infestation differs between islands, and we hypothesized that microbiome composition could play a role. Therefore, we sampled 3rd instar larvae and soil from sites with high and low infestation rates to analyze the microbiome using next-generation sequencing. We analyzed twenty-four 16S DNA libraries, which resulted in 3278 operational taxonomic units. The alpha and beta diversity of the soil microbiome was similar between sites. In contrast, the larvae from high-density sites presented a higher bacterial gut diversity than larvae from low-density sites, with biomarkers linked to plant digestion, nutrient acquisition, and detoxification. Consequently, larvae from high-density sites displayed several enriched molecular functions associated with the families Ruminococcaceae, Clostridiaceae and Rikenellaceae. These bacteria revealed a supportive function by producing several CAZyme families and other proteins. These findings suggest that the microbiome must be one drive for the increase in P. japonica populations, thus providing a checkpoint in the establishment and spread of this pest.",,2076-2607,,, ,  ,,out_of_scope,
2555,"**Title**Comparison of the expression profiles of susceptible and resistant Eucalyptus grandis exposed to Puccinia psidii Winter using SAGE

**Abstract**Eucalyptus grandis Hill ex Maiden and its hybrids are commonly planted by the Brazilian pulp and paper industry, but they are the most susceptible to the neotropical rust disease caused by Puccinia psidii Winter. In an initial attempt to understand the mechanisms of resistance, we constructed two contrasting Serial Analysis of Gene Expression (SAGE) libraries using susceptible and resistant individuals from a segregating half-sibling E. grandis population. Using the Z-test we identified tags differentially expressed between the libraries, preferentially 239 in the susceptible and 232 in the resistant type individuals. Using public (Expressed Sequence Tags) EST databases, 40 of the susceptible and 70 of the resistant tags matched ESTs and were annotated. By comparing the type of genes and their expression levels, distinct differences between the libraries were observed. Susceptible plants showed gene expression linked to leaf senescence, generalised stress responses and detoxification, and are apparently incapable of inducing a competent host defence response. On the other hand, resistant plants showed genes upregulated for cellular polarisation, cytoskeleton restructuring, vesicle transport, and cellulose and lignin biosynthesis. In the resistant individuals, evidence for systemic resistance, anti-oxidative responses and a hypersensitive response was also observed, although no R gene was identified.","Moon, David H.; Salvatierra, Guillermo R.; Caldas, Danielle G. G.; de Carvalho, Mayra C. C. Gallo; Carneiro, Raphael T.; Franceschini, Livia M.; Oda, Shinitiro; Labate, Carlos A.","Carvalho, Mayra/G-8870-2015; Caldas, Danielle/D-5685-2012; Labate, Carlos Alberto/L-2183-2015","Labate, Carlos Alberto/0000-0001-7309-1300",Comparison of the expression profiles of susceptible and resistant Eucalyptus grandis exposed to Puccinia psidii Winter using SAGE,34,11,10.1071/FP07094 ,Article ,,"Eucalyptus grandis Hill ex Maiden and its hybrids are commonly planted by the Brazilian pulp and paper industry, but they are the most susceptible to the neotropical rust disease caused by Puccinia psidii Winter. In an initial attempt to understand the mechanisms of resistance, we constructed two contrasting Serial Analysis of Gene Expression (SAGE) libraries using susceptible and resistant individuals from a segregating half-sibling E. grandis population. Using the Z-test we identified tags differentially expressed between the libraries, preferentially 239 in the susceptible and 232 in the resistant type individuals. Using public (Expressed Sequence Tags) EST databases, 40 of the susceptible and 70 of the resistant tags matched ESTs and were annotated. By comparing the type of genes and their expression levels, distinct differences between the libraries were observed. Susceptible plants showed gene expression linked to leaf senescence, generalised stress responses and detoxification, and are apparently incapable of inducing a competent host defence response. On the other hand, resistant plants showed genes upregulated for cellular polarisation, cytoskeleton restructuring, vesicle transport, and cellulose and lignin biosynthesis. In the resistant individuals, evidence for systemic resistance, anti-oxidative responses and a hypersensitive response was also observed, although no R gene was identified.",1445-4408,1445-4416,,1010-1018, ,  ,,out_of_scope,
2556,"**Title**Lignin degradation and detoxification of eucalyptus wastes by on-site manufacturing fungal enzymes to enhance second-generation ethanol yield

**Abstract**Novel laccases have promising and valuable applications in biorefineries. This investigation documents, for the first time, the potential of depolymerising and repolymerising lignin by the secretome, rich in laccases, from a newly isolated white-rot basidiomycete Marasmiellus palmivorus VE111, for further saccharification and ethanolic fermentation steps. Proteomic analyses of the secretome of M. palmivorus show that laccases are the most predominant enzyme released by this fungus. The whole crude enzymatic broth is used for the delignification of lignin in Eucalyptus globulus wood, with the aim of enhancing the saccharification by cellulolytic and xylanolytic enzymes from Penicillium echinulatum S1M29. In addition, two different strategies, namely, laccase treatment before and after enzymatic hydrolysis, are employed to detoxify steam-exploded E. globulus wood. The objective is to increase the fermentative performance by removing substances formed during the feedstock pretreatment that can inhibit microbial fermentation. The E. globulus wood delignification results in a 31% decrease in the lignin content and a 10% increase in the glucose yield after hydrolysis. An important finding of the present work is the successful wood delignification in the absence of laccase mediators. This laccase-rich preparation also demonstrates its potential in removing the phenolic inhibitors present in steam-exploded E. globulus wood, increasing the ethanol yield by an additional 10%. Furthermore, it is important to highlight that these findings are achieved in the absence of commercial enzymes, making M. palmivorus laccases a potential candidate not only for the production of biofuels but also for the generation of lignin-derived aromatic compounds for different applications in the biotechnology industry.","Hahn Schneider, Willian Daniel; Fontana, Roselei Claudete; Baudel, Henrique Macedo; de Siqueira, Felix Goncalves; Rencoret, Jorge; Gutierrez, Ana; Isabel de Eugenio, Laura; Prieto, Alicia; Jesus Martinez, Maria; Martinez, Angel T.; Pinheiro Dillon, Aldo Jose; Camassola, Marli","Camassola, Marli/H-3034-2012; Dillon, Aldo/J-4653-2012; Siqueira, Felix/F-9910-2012; de Eugenio, Laura Isabel/CAF-3664-2022; RENCORET, JORGE/E-1747-2013; Prieto, Alicia/M-7899-2017; Martinez, Angel T/G-7284-2017","de Eugenio, Laura Isabel/0000-0002-0496-8663; RENCORET, JORGE/0000-0003-2728-7331; Prieto, Alicia/0000-0002-5075-4025; Martinez, Angel T/0000-0002-1584-2863; SCHNEIDER, WILLIAN/0000-0002-3988-7716",Lignin degradation and detoxification of eucalyptus wastes by on-site manufacturing fungal enzymes to enhance second-generation ethanol yield,262,,10.1016/j.apenergy.2020.114493 ,Article ,,"Novel laccases have promising and valuable applications in biorefineries. This investigation documents, for the first time, the potential of depolymerising and repolymerising lignin by the secretome, rich in laccases, from a newly isolated white-rot basidiomycete Marasmiellus palmivorus VE111, for further saccharification and ethanolic fermentation steps. Proteomic analyses of the secretome of M. palmivorus show that laccases are the most predominant enzyme released by this fungus. The whole crude enzymatic broth is used for the delignification of lignin in Eucalyptus globulus wood, with the aim of enhancing the saccharification by cellulolytic and xylanolytic enzymes from Penicillium echinulatum S1M29. In addition, two different strategies, namely, laccase treatment before and after enzymatic hydrolysis, are employed to detoxify steam-exploded E. globulus wood. The objective is to increase the fermentative performance by removing substances formed during the feedstock pretreatment that can inhibit microbial fermentation. The E. globulus wood delignification results in a 31% decrease in the lignin content and a 10% increase in the glucose yield after hydrolysis. An important finding of the present work is the successful wood delignification in the absence of laccase mediators. This laccase-rich preparation also demonstrates its potential in removing the phenolic inhibitors present in steam-exploded E. globulus wood, increasing the ethanol yield by an additional 10%. Furthermore, it is important to highlight that these findings are achieved in the absence of commercial enzymes, making M. palmivorus laccases a potential candidate not only for the production of biofuels but also for the generation of lignin-derived aromatic compounds for different applications in the biotechnology industry.",0306-2619,1872-9118,,, ,  ,,out_of_scope,
2557,"**Title**MODELING ALCOHOL METABOLISM WITH THE DARC CALPHI SYSTEM

**Abstract**We present our general system for QSAR search, CALPHI (Computer-Aided Law by Hyperstructure Investigation) set up in the context of the DARC structural language. We use it to construct global, fragmentary, and topological models of the capacity of alcohols to undergo glucuronidation. The DARC/PELCO model, more precisely and more significantly, explains 98% of the total variance with only three parameters, while treating the whole set of primary, secondary, and tertiary alcohols, whereas the best previously reported treatment restricted to primary alcohols, explains only 90% of the variance with two parameters. It provides an explicit and more precise interpretation of alcohol metabolism. The PELCO methodology is extended to evaluate the prediction reliability of both global and fragmentary models. PELCO leads to more predictions when comparison is made at the same level of reliability.","MERCIER, C; FABART, V; SOBEL, Y; DUBOIS, JE",,,MODELING ALCOHOL METABOLISM WITH THE DARC CALPHI SYSTEM,34,3,10.1021/jm00107a010 ,Article ,,"We present our general system for QSAR search, CALPHI (Computer-Aided Law by Hyperstructure Investigation) set up in the context of the DARC structural language. We use it to construct global, fragmentary, and topological models of the capacity of alcohols to undergo glucuronidation. The DARC/PELCO model, more precisely and more significantly, explains 98% of the total variance with only three parameters, while treating the whole set of primary, secondary, and tertiary alcohols, whereas the best previously reported treatment restricted to primary alcohols, explains only 90% of the variance with two parameters. It provides an explicit and more precise interpretation of alcohol metabolism. The PELCO methodology is extended to evaluate the prediction reliability of both global and fragmentary models. PELCO leads to more predictions when comparison is made at the same level of reliability.",0022-2623,,,934-942, ,  ,,out_of_scope,
2558,"**Title**APPLICATION OF THE POLYMERASE CHAIN-REACTION (PCR) TO POLIOMYELITIS SURVEILLANCE THROUGH THE ANALYSES OF SEWAGE SAMPLES

**Abstract**A rapid and sensitive method for the detection of wild poliovirus from sewage samples using the polymerase chain reaction (PCR) technique was investigated. To eliminate the toxicity of sample concentrates to the enzymatic system used in PCR, a methodology was developed for the purification of these concentrates, consisting of treatment with trichlorofluoroethane and Sephadex column chromatography. The viral RNA was extracted from the purified concentrates, submitted to PCR with primers specific for Brazilian wild poliovirus type 1 and for Sabin types 1, 2 and 3. The amplified products were detected by electrophoresis in vertical polyacrylamide gels and stained with ethidium bromide. The results suggest that sewage sampling for environmental surveillance, combined with the rapid and precise PCR technology, provides a powerful tool for assessment of the success of the poliovirus eradication programme.","MARQUES, E; DASILVA, EE; DOSSANTOS, VM; KEW, OM; MARTINS, MT",,,APPLICATION OF THE POLYMERASE CHAIN-REACTION (PCR) TO POLIOMYELITIS SURVEILLANCE THROUGH THE ANALYSES OF SEWAGE SAMPLES,9,5,10.1007/BF00386295 ,Article ,,"A rapid and sensitive method for the detection of wild poliovirus from sewage samples using the polymerase chain reaction (PCR) technique was investigated. To eliminate the toxicity of sample concentrates to the enzymatic system used in PCR, a methodology was developed for the purification of these concentrates, consisting of treatment with trichlorofluoroethane and Sephadex column chromatography. The viral RNA was extracted from the purified concentrates, submitted to PCR with primers specific for Brazilian wild poliovirus type 1 and for Sabin types 1, 2 and 3. The amplified products were detected by electrophoresis in vertical polyacrylamide gels and stained with ethidium bromide. The results suggest that sewage sampling for environmental surveillance, combined with the rapid and precise PCR technology, provides a powerful tool for assessment of the success of the poliovirus eradication programme.",0959-3993,,,566-569, ,  ,,out_of_scope,
2559,"**Title**Fingerprinting metabolomics in tropical mistletoes: A case study with facultative aluminum-accumulating species

**Abstract**Aluminum (Al) toxicity is a hot topic due to the high sensitivity of cultivated plants. Despite the large investment in the last century in understanding the mechanisms used by sensitive and Al-excluding species to avoid Al uptake from soil, little attention has been devoted to understanding the mechanisms used by native Al-accumulating species to deal with Al-toxicity. Passovia ovata (Pohl ex DC.) Kuijt and Struthanthus polyanthus Mart. are mistletoes with a facultative Al-accumulating behavior. In the Brazilian Cerrado they are commonly found infecting Al-accumulating (Miconia albicans (Sw.) Steud.) and non-accumulating (Byrsonima verbascifolia (L.) DC.) species. Taking into account the importance of organic complexes in the detoxification of the highly toxic Al3+ ions, it is to be expected that mistletoes differ in their metabolomic profile when feeding on species differing in Al accumulation. Here we tested this hypothesis using an untargeted LC-MS approach to investigate the influence of Al on the metabolome of P. ovata and S. polyanthus infecting M. albicans and B. verbascifolia under field conditions. We observed differences in the metabolic profiles between mistletoes growing on Al-accumulating and Al-excluding hosts, and also observed a positive correlation between Al leaf-accumulation and the metabolic profile. Using the OPLS-DA, we identified quinic acid (phenolic compound) as a metabolic biomarker distinguishing mistletoes grown under high and low Al availability.","de Souza, Marcelo Claro; Rosa, Annylory Lima; Poschenrieder, Charlotte; Tolra, Roser; Da Costa, Fernando Batista","C., Poschenrieder/C-7160-2008; de Souza, Marcelo/B-3109-2015; Da Costa, Fernando/E-1842-2011; Perez, Roser Tolra/E-8427-2016","Da Costa, Fernando/0000-0002-2345-5804; Claro de Souza, Marcelo/0000-0002-0151-1115; Perez, Roser Tolra/0000-0001-8513-3520; Poschenrieder, Charlotte/0000-0002-3818-0874",Fingerprinting metabolomics in tropical mistletoes: A case study with facultative aluminum-accumulating species,25,,10.1016/j.phytol.2018.04.013 ,Article ,,"Aluminum (Al) toxicity is a hot topic due to the high sensitivity of cultivated plants. Despite the large investment in the last century in understanding the mechanisms used by sensitive and Al-excluding species to avoid Al uptake from soil, little attention has been devoted to understanding the mechanisms used by native Al-accumulating species to deal with Al-toxicity. Passovia ovata (Pohl ex DC.) Kuijt and Struthanthus polyanthus Mart. are mistletoes with a facultative Al-accumulating behavior. In the Brazilian Cerrado they are commonly found infecting Al-accumulating (Miconia albicans (Sw.) Steud.) and non-accumulating (Byrsonima verbascifolia (L.) DC.) species. Taking into account the importance of organic complexes in the detoxification of the highly toxic Al3+ ions, it is to be expected that mistletoes differ in their metabolomic profile when feeding on species differing in Al accumulation. Here we tested this hypothesis using an untargeted LC-MS approach to investigate the influence of Al on the metabolome of P. ovata and S. polyanthus infecting M. albicans and B. verbascifolia under field conditions. We observed differences in the metabolic profiles between mistletoes growing on Al-accumulating and Al-excluding hosts, and also observed a positive correlation between Al leaf-accumulation and the metabolic profile. Using the OPLS-DA, we identified quinic acid (phenolic compound) as a metabolic biomarker distinguishing mistletoes grown under high and low Al availability.",1874-3900,1876-7486,,90-94, ,  ,,out_of_scope,
2560,"**Title**Comparative transcriptome analysis reveals different strategies for degradation of steam-exploded sugarcane bagasse by Aspergillus niger and Trichoderma reesei

**Abstract**Background: Second generation (2G) ethanol is produced by breaking down lignocellulosic biomass into fermentable sugars. In Brazil, sugarcane bagasse has been proposed as the lignocellulosic residue for this biofuel production. The enzymatic cocktails for the degradation of biomass-derived polysaccharides are mostly produced by fungi, such as Aspergillus niger and Trichoderma reesei. However, it is not yet fully understood how these microorganisms degrade plant biomass. In order to identify transcriptomic changes during steam-exploded bagasse (SEB) breakdown, we conducted a RNA-seq comparative transcriptome profiling of both fungi growing on SEB as carbon source.Results: Particular attention was focused on CAZymes, sugar transporters, transcription factors (TFs) and other proteins related to lignocellulose degradation. Although genes coding for the main enzymes involved in biomass deconstruction were expressed by both fungal strains since the beginning of the growth in SEB, significant differences were found in their expression profiles. The expression of these enzymes is mainly regulated at the transcription level, and A. niger and T. reesei also showed differences in TFs content and in their expression. Several sugar transporters that were induced in both fungal strains could be new players on biomass degradation besides their role in sugar uptake. Interestingly, our findings revealed that in both strains several genes that code for proteins of unknown function and pro-oxidant, antioxidant, and detoxification enzymes were induced during growth in SEB as carbon source, but their specific roles on lignocellulose degradation remain to be elucidated.Conclusions: This is the first report of a time-course experiment monitoring the degradation of pretreated bagasse by two important fungi using the RNA-seq technology. It was possible to identify a set of genes that might be applied in several biotechnology fields. The data suggest that these two microorganisms employ different strategies for biomass breakdown. This knowledge can be exploited for the rational design of enzymatic cocktails and 2G ethanol production improvement.","Borin, Gustavo Pagotto; Sanchez, Camila Cristina; de Santana, Eliane Silva; Zanini, Guilherme Keppe; Correa dos Santos, Renato Augusto; Pontes, Angelica de Oliveira; de Souza, Aline Tieppo; Tavares Soares Dal'Mas, Roberta Maria Menegaldo; Riano-Pachon, Diego Mauricio; Goldman, Gustavo Henrique; de Castro Oliveira, Juliana Velasco","Riaño Pachón, Diego Mauricio/B-4891-2014; Goldman, Gustavo/F-1848-2013; Correa dos Santos, Renato Augusto/A-7065-2016","Goldman, Gustavo/0000-0002-2986-350X; Correa dos Santos, Renato Augusto/0000-0003-0826-5479; Pagotto Borin, Gustavo/0000-0001-7087-4780",Comparative transcriptome analysis reveals different strategies for degradation of steam-exploded sugarcane bagasse by Aspergillus niger and Trichoderma reesei,18,,10.1186/s12864-017-3857-5 ,Article ,,"Background: Second generation (2G) ethanol is produced by breaking down lignocellulosic biomass into fermentable sugars. In Brazil, sugarcane bagasse has been proposed as the lignocellulosic residue for this biofuel production. The enzymatic cocktails for the degradation of biomass-derived polysaccharides are mostly produced by fungi, such as Aspergillus niger and Trichoderma reesei. However, it is not yet fully understood how these microorganisms degrade plant biomass. In order to identify transcriptomic changes during steam-exploded bagasse (SEB) breakdown, we conducted a RNA-seq comparative transcriptome profiling of both fungi growing on SEB as carbon source.Results: Particular attention was focused on CAZymes, sugar transporters, transcription factors (TFs) and other proteins related to lignocellulose degradation. Although genes coding for the main enzymes involved in biomass deconstruction were expressed by both fungal strains since the beginning of the growth in SEB, significant differences were found in their expression profiles. The expression of these enzymes is mainly regulated at the transcription level, and A. niger and T. reesei also showed differences in TFs content and in their expression. Several sugar transporters that were induced in both fungal strains could be new players on biomass degradation besides their role in sugar uptake. Interestingly, our findings revealed that in both strains several genes that code for proteins of unknown function and pro-oxidant, antioxidant, and detoxification enzymes were induced during growth in SEB as carbon source, but their specific roles on lignocellulose degradation remain to be elucidated.Conclusions: This is the first report of a time-course experiment monitoring the degradation of pretreated bagasse by two important fungi using the RNA-seq technology. It was possible to identify a set of genes that might be applied in several biotechnology fields. The data suggest that these two microorganisms employ different strategies for biomass breakdown. This knowledge can be exploited for the rational design of enzymatic cocktails and 2G ethanol production improvement.",1471-2164,,,, ,  ,,out_of_scope,
2561,"**Title**Salt marsh plants (Juncus maritimus and Scirpus maritimus) as sources of strong complexing ligands

**Abstract**This work aimed to evaluate, in vitro, the capability of roots of salt marsh plants to release strong Cu-complexing ligands and to ascertain whether Cu contamination would stimulate ligands' exudation or not. The sea rush Juncus maritimus and the sea-club rush Scirpus maritimus, both from the lower Douro river estuary (NW Portugal), were used. Plants were collected seasonally, four times a year in 2004, during low tide. After sampling, plant roots were washed for removal of adherent particles and immersed for 2 h in a solution that matched salinity (3) and pH (7.5) of the pore water from the same location and spiked with Cu2+ in the range 0-1600 nM to obtain plant exudates. In the final solutions as well as in sediment pore water total dissolved Zn and Cu, Cu-complexing ligand concentrations and the respective conditional stability constants (k'(CuL)) values were determined by voltammetry. This study demonstrated that plants are able to release, in a short period of time, relatively high amounts of strong Cu-complexing ligands (56-265 nmol g(root)(-1)), which differed among plants and sampling site but were independent of the season. Cu contamination did not stimulate exudation of Cu-complexing ligands. On the other hand, in media contaminated with Cu both plants accumulated relatively high amounts (29-83%) of the initially dissolved Cu, indicating that they have alternative internal mechanisms for Cu detoxification. Cu exchange between roots and medium (either accumulation in contaminated medium or release in the absence of Cu) was more intense for S. maritimus than for J. maritimus. It was observed that exudate solutions obtained in the absence of added Cu and sediment pore water (the densities of roots observed inside the salt marsh where comparable to those used in the in vitro experiments), displayed similarities in terms of total dissolved metals, Cu-complexing ligands concentrations, values of k'(CuL) (12 < 109 K'(CuL) < 14), as well as patterns of variation among seasons (only observed for Zn). These results are novel and point out that salt marsh plants may be the source at least partially of the strong organic ligands found in the sediment pore water in shallow marginal areas. The capability of salt marsh plants to release strong organic ligands into the environment, conjugated with their known capacity to oxidize anaerobic sediment around roots, indicate that these plants can play a role in controlling metal speciation in the water/sediment interface. (c) 2007 Elsevier Ltd. All rights reserved.","Mucha, Ana P.; Almeida, C. Marisa R.; Bordalo, Adriano A.; Vasconcelos, M. Teresa S. D.","de Almeida, Adriano/AAC-5194-2020; Almeida, C. Marisa/J-6375-2012; Mucha, Ana Paula/L-4051-2014","A. Bordalo, Adriano/0000-0002-9637-6541; Almeida, C. Marisa/0000-0002-6836-0331; Mucha, Ana Paula/0000-0003-0024-7145",Salt marsh plants (Juncus maritimus and Scirpus maritimus) as sources of strong complexing ligands,77,1,10.1016/j.ecss.2007.09.011 ,Article ,,"This work aimed to evaluate, in vitro, the capability of roots of salt marsh plants to release strong Cu-complexing ligands and to ascertain whether Cu contamination would stimulate ligands' exudation or not. The sea rush Juncus maritimus and the sea-club rush Scirpus maritimus, both from the lower Douro river estuary (NW Portugal), were used. Plants were collected seasonally, four times a year in 2004, during low tide. After sampling, plant roots were washed for removal of adherent particles and immersed for 2 h in a solution that matched salinity (3) and pH (7.5) of the pore water from the same location and spiked with Cu2+ in the range 0-1600 nM to obtain plant exudates. In the final solutions as well as in sediment pore water total dissolved Zn and Cu, Cu-complexing ligand concentrations and the respective conditional stability constants (k'(CuL)) values were determined by voltammetry. This study demonstrated that plants are able to release, in a short period of time, relatively high amounts of strong Cu-complexing ligands (56-265 nmol g(root)(-1)), which differed among plants and sampling site but were independent of the season. Cu contamination did not stimulate exudation of Cu-complexing ligands. On the other hand, in media contaminated with Cu both plants accumulated relatively high amounts (29-83%) of the initially dissolved Cu, indicating that they have alternative internal mechanisms for Cu detoxification. Cu exchange between roots and medium (either accumulation in contaminated medium or release in the absence of Cu) was more intense for S. maritimus than for J. maritimus. It was observed that exudate solutions obtained in the absence of added Cu and sediment pore water (the densities of roots observed inside the salt marsh where comparable to those used in the in vitro experiments), displayed similarities in terms of total dissolved metals, Cu-complexing ligands concentrations, values of k'(CuL) (12 < 109 K'(CuL) < 14), as well as patterns of variation among seasons (only observed for Zn). These results are novel and point out that salt marsh plants may be the source at least partially of the strong organic ligands found in the sediment pore water in shallow marginal areas. The capability of salt marsh plants to release strong organic ligands into the environment, conjugated with their known capacity to oxidize anaerobic sediment around roots, indicate that these plants can play a role in controlling metal speciation in the water/sediment interface. (c) 2007 Elsevier Ltd. All rights reserved.",0272-7714,,,104-112, ,  ,,out_of_scope,
2562,"**Title**Textile effluent toxicity trend: A scientometric review

**Abstract**Textile production generates high volumes of colored effluents, including several toxic substances potentially dangerous to the environment. It is important to highlight out that decolorization is not the removal of toxicity and currently there is no scientometric perspective addressing about this theme. The present study aimed sci-entometrically review the state-of-art on textile effluent toxicity, presenting scientific trends and gaps, research hotspots and science statistics on this issue, and identifying the directions to guide future efforts. The words textile effluent AND *toxicity* were searched in the Web of Science, between the years 1945 a 2020. 214 articles were retrieved and selected with relevant impact factor (H-index = 45) and were analyzed in CiteSpace, Excel, Statistica and Bibliometrix software. Clearly, greater focus and scientific efforts are urgent to find efficient ways to manage textile wastewater. India, Brazil, and Turkey lead in the publications number on the topic and are also the leading textile producers worldwide. The efforts were focused on the search for efficient effluent treatments promoting decolorization, nontoxic and economically feasible for textile industries. Highlights those 40 years have passed since the first publication and still no efficient and sustainable way of managing this waste is available.","Vasconcelos, Marina Wust; Goncalves, Sandrieli; de Oliveira, Elton Celton; Rubert, Silvia; Ghisi, Nedia de Castilhos","Wust Vasconcelos, Marina/HNI-2414-2023; Gonçalves, Sandrieli/HZK-1727-2023; Ghisi, Nedia/J-4131-2016","Goncalves, Sandrieli/0000-0002-9463-4631; Ghisi, Nedia/0000-0001-7616-1618; Oliveira, Elton/0000-0003-1066-5404",Textile effluent toxicity trend: A scientometric review,366,,10.1016/j.jclepro.2022.132756 ,Review ,,"Textile production generates high volumes of colored effluents, including several toxic substances potentially dangerous to the environment. It is important to highlight out that decolorization is not the removal of toxicity and currently there is no scientometric perspective addressing about this theme. The present study aimed sci-entometrically review the state-of-art on textile effluent toxicity, presenting scientific trends and gaps, research hotspots and science statistics on this issue, and identifying the directions to guide future efforts. The words textile effluent AND *toxicity* were searched in the Web of Science, between the years 1945 a 2020. 214 articles were retrieved and selected with relevant impact factor (H-index = 45) and were analyzed in CiteSpace, Excel, Statistica and Bibliometrix software. Clearly, greater focus and scientific efforts are urgent to find efficient ways to manage textile wastewater. India, Brazil, and Turkey lead in the publications number on the topic and are also the leading textile producers worldwide. The efforts were focused on the search for efficient effluent treatments promoting decolorization, nontoxic and economically feasible for textile industries. Highlights those 40 years have passed since the first publication and still no efficient and sustainable way of managing this waste is available.",0959-6526,1879-1786,,, ,  ,,out_of_scope,
2563,"**Title**Automatic counter-narrative generation for hate speech in Spanish

**Abstract**This paper analyzes the use of language models to automatically generate counter-narratives for hate speech in Spanish. Despite the existence of a few studies in English and other languages, no previous work has explored this topic focused on Spanish. The article shows that the use of GPT-3 outperforms other models in generating non-offensive and informative counter-narratives, which sometimes present compelling arguments. We have used few-shot learning algorithms applying different prompt strategies and analyzing the results for each of them. Additionally, a new corpus called CONAN-SP, which consists of 238 pairs of hate speech and counter-narratives in Spanish, has been made available to the research community to facilitate further investigations in this area. These findings highlight the potential of language models to combat hate speech in Spanish by counter-narrative generation.","Estrella Vallecillo-Rodriguez, M.; Montejo Raez, Arturo; Teresa Martin-Valdivia, M.",,,Automatic counter-narrative generation for hate speech in Spanish,,71,10.26342/2023-71-18 ,Article ,,"This paper analyzes the use of language models to automatically generate counter-narratives for hate speech in Spanish. Despite the existence of a few studies in English and other languages, no previous work has explored this topic focused on Spanish. The article shows that the use of GPT-3 outperforms other models in generating non-offensive and informative counter-narratives, which sometimes present compelling arguments. We have used few-shot learning algorithms applying different prompt strategies and analyzing the results for each of them. Additionally, a new corpus called CONAN-SP, which consists of 238 pairs of hate speech and counter-narratives in Spanish, has been made available to the research community to facilitate further investigations in this area. These findings highlight the potential of language models to combat hate speech in Spanish by counter-narrative generation.",1135-5948,1989-7553,,227-245, ,  ,,out_but_toxicity,
2564,"**Title**Towards Knowledge-Grounded Counter Narrative Generation for Hate Speech

**Abstract**Tackling online hatred using informed textual responses - called counter narratives - has been brought under the spotlight recently. Accordingly, a research line has emerged to automatically generate counter narratives in order to facilitate the direct intervention in the hate discussion and to prevent hate content from further spreading. Still, current neural approaches tend to produce generic/repetitive responses and lack grounded and up-to-date evidence such as facts, statistics, or examples. Moreover, these models can create plausible but not necessarily true arguments. In this paper we present the first complete knowledge-bound counter narrative generation pipeline, grounded in an external knowledge repository that can provide more informative content to fight online hatred. Together with our approach, we present a series of experiments that show its feasibility to produce suitable and informative counter narratives in in-domain and cross-domain settings.","Chung, Yi-Ling; Tekiroglu, Serra Sinem; Guerini, Marco",,"Tekiroglu, Serra Sinem/0000-0001-7229-7649; Guerini, Marco/0000-0003-1582-6617",Towards Knowledge-Grounded Counter Narrative Generation for Hate Speech,,, ,Proceedings Paper ,,"Tackling online hatred using informed textual responses - called counter narratives - has been brought under the spotlight recently. Accordingly, a research line has emerged to automatically generate counter narratives in order to facilitate the direct intervention in the hate discussion and to prevent hate content from further spreading. Still, current neural approaches tend to produce generic/repetitive responses and lack grounded and up-to-date evidence such as facts, statistics, or examples. Moreover, these models can create plausible but not necessarily true arguments. In this paper we present the first complete knowledge-bound counter narrative generation pipeline, grounded in an external knowledge repository that can provide more informative content to fight online hatred. Together with our approach, we present a series of experiments that show its feasibility to produce suitable and informative counter narratives in in-domain and cross-domain settings.",,,978-1-954085-54-1,899-914, , Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP)Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP) ,,detox,
2565,"**Title**Fallacious Argument Classification in Political Debates

**Abstract**Fallacies play a prominent role in argumentation since antiquity due to their contribution to argumentation in critical thinking education. Their role is even more crucial nowadays as contemporary argumentation technologies face challenging tasks as misleading and manipulative information detection in news articles and political discourse, and counter-narrative generation. Despite some work in this direction, the issue of classifying arguments as being fallacious largely remains a challenging and an unsolved task. Our contribution is twofold: first, we present a novel annotated resource of 31 political debates from the U.S. Presidential Campaigns, where we annotated six main categories of fallacious arguments (i.e., ad hominem, appeal to authority, appeal to emotion, false cause, slogan, slippery slope) leading to 1628 annotated fallacious arguments; second, we tackle this novel task of fallacious argument classification and we define a neural architecture based on transformers outperforming state-of-the-art results and standard baselines. Our results show the important role played by argument components and relations in this task.","Goffredo, Pierpaolo; Haddadan, Shohreh; Vorakitphan, Vorakit; Cabrio, Elena; Villata, Serena",,,Fallacious Argument Classification in Political Debates,,, ,Proceedings Paper ,,"Fallacies play a prominent role in argumentation since antiquity due to their contribution to argumentation in critical thinking education. Their role is even more crucial nowadays as contemporary argumentation technologies face challenging tasks as misleading and manipulative information detection in news articles and political discourse, and counter-narrative generation. Despite some work in this direction, the issue of classifying arguments as being fallacious largely remains a challenging and an unsolved task. Our contribution is twofold: first, we present a novel annotated resource of 31 political debates from the U.S. Presidential Campaigns, where we annotated six main categories of fallacious arguments (i.e., ad hominem, appeal to authority, appeal to emotion, false cause, slogan, slippery slope) leading to 1628 annotated fallacious arguments; second, we tackle this novel task of fallacious argument classification and we define a neural architecture based on transformers outperforming state-of-the-art results and standard baselines. Our results show the important role played by argument components and relations in this task.",,,978-1-956792-00-3,4143-4149, , 31st International Joint Conference on Artificial Intelligence (IJCAI)31st International Joint Conference on Artificial Intelligence (IJCAI) ,,out_of_scope,
2566,"**Title**Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech

**Abstract**Undermining the impact of hateful content with informed and non-aggressive responses, called counter narratives, has emerged as a possible solution for having healthier online communities. Thus, some NLP studies have started addressing the task of counter narrative generation. Although such studies have made an effort to build hate speech / counter narrative (HS/CN) datasets for neural generation, they fall short in reaching either highquality and/or high-quantity. In this paper, we propose a novel human-in-the-loop data collection methodology in which a generative language model is refined iteratively by using its own data from the previous loops to generate new training samples that experts review and/or post-edit. Our experiments comprised several loops including dynamic variations. Results show that the methodology is scalable and facilitates diverse, novel, and cost-effective data collection. To our knowledge, the resulting dataset is the only expertbased multi-target HS/CN dataset available to the community.","Fanton, Margherita; Bonaldi, Helena; Tekiroglu, Serra Sinem; Guerini, Marco",,"Guerini, Marco/0000-0003-1582-6617; Fanton, Nicola/0000-0002-8953-6148",Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech,,, ,Proceedings Paper ,,"Undermining the impact of hateful content with informed and non-aggressive responses, called counter narratives, has emerged as a possible solution for having healthier online communities. Thus, some NLP studies have started addressing the task of counter narrative generation. Although such studies have made an effort to build hate speech / counter narrative (HS/CN) datasets for neural generation, they fall short in reaching either highquality and/or high-quantity. In this paper, we propose a novel human-in-the-loop data collection methodology in which a generative language model is refined iteratively by using its own data from the previous loops to generate new training samples that experts review and/or post-edit. Our experiments comprised several loops including dynamic variations. Results show that the methodology is scalable and facilitates diverse, novel, and cost-effective data collection. To our knowledge, the resulting dataset is the only expertbased multi-target HS/CN dataset available to the community.",,,978-1-954085-52-7,3226-3240, , Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP)Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP) ,,detox#methodology,
2567,"**Title**Latent Variables Improve Hard-Constrained Controllable Text Generation on Weak Correlation

**Abstract**Hard-constrained controllable text generation aims to forcefully generate texts that contain specified constrained vocabulary, fulfilling the demands of more specialized application scenarios in comparison to soft constraint controllable text generation. However, in the presence of multiple weak correlation constraints in the constraint set, soft-constrained controllable models aggravate the constraint loss phenomenon, while the hard- constrained controllable models significantly suffer from quality degradation. To address this problem, a method for hard- constrained controllable text generation based on latent variables improving on weak correlations is proposed. The method utilizes latent variables to capture both global and local constraint correlation information to guide the language model to generate hard-constrained controllable text at the macro and micro levels, respectively. The introduction of latent variables not only reveals the latent correlation between constraints, but also helps the model to precisely satisfy these constraints while maintaining semantic coherence and logical correctness. Experiment findings reveal that under conditions of weak correlation hard constraints, the quality of text generation by the method proposed exceeds that of the currently established strong baseline models.","Zhu, Weigang; Liu, Xiaoming; Yang, Guan; Liu, Jie; Qi, Haotian","Liu, Xiaoming/JFB-0295-2023",,Latent Variables Improve Hard-Constrained Controllable Text Generation on Weak Correlation,15,6, ,Article ,,"Hard-constrained controllable text generation aims to forcefully generate texts that contain specified constrained vocabulary, fulfilling the demands of more specialized application scenarios in comparison to soft constraint controllable text generation. However, in the presence of multiple weak correlation constraints in the constraint set, soft-constrained controllable models aggravate the constraint loss phenomenon, while the hard- constrained controllable models significantly suffer from quality degradation. To address this problem, a method for hard- constrained controllable text generation based on latent variables improving on weak correlations is proposed. The method utilizes latent variables to capture both global and local constraint correlation information to guide the language model to generate hard-constrained controllable text at the macro and micro levels, respectively. The introduction of latent variables not only reveals the latent correlation between constraints, but also helps the model to precisely satisfy these constraints while maintaining semantic coherence and logical correctness. Experiment findings reveal that under conditions of weak correlation hard constraints, the quality of text generation by the method proposed exceeds that of the currently established strong baseline models.",2158-107X,2156-5570,,365-374, ,  ,,out_of_scope,
2568,"**Title**CTGGAN: Controllable Text Generation with Generative Adversarial Network

**Abstract**Controllable Text Generation (CTG) aims to modify the output of a Language Model (LM) to meet specific constraints. For example, in a customer service conversation, responses from the agent should ideally be soothing and address the user's dissatisfaction or complaints. This imposes significant demands on controlling language model output. However, demerits exist among traditional methods. Promoting and fine-tuning language models exhibit the hallucination phenomenon and cannot guarantee complete adherence to constraints. Conditional language models (CLM), which map control codes into LM representations or latent space, require training the modified language models from scratch and a high amount of customized dataset is demanded. Decoding-time methods employ Bayesian Rules to modify the output of the LM or model constraints as a combination of energy functions and update the output along the low-energy direction. Both methods are confronted with the efficiency sampling problem. Moreover, there are no methods that consider the relation between constraints weights and the contexts, as is essential in actual applications such as customer service scenarios. To alleviate the problems mentioned above, we propose Controllable Text Generation with Generative Adversarial Networks (CTGGAN), which utilizes a language model with logits bias as the Generator to produce constrained text and employs the Discriminator with learnable constraint weight combinations to score and update the generation. We evaluate the method in the text completion task and Chinese customer service dialogues scenario, and our method shows superior performance in metrics such as PPL and Dist-3. In addition, CTGGAN also exhibits efficient decoding compared to other methods.","Yang, Zhe; Huang, Yi; Chen, Yaqin; Wu, Xiaoting; Feng, Junlan; Deng, Chao","chen, xia/GYR-3948-2022","Huang, Yi/0009-0005-7491-2998",CTGGAN: Controllable Text Generation with Generative Adversarial Network,14,7,10.3390/app14073106 ,Article ,,"Controllable Text Generation (CTG) aims to modify the output of a Language Model (LM) to meet specific constraints. For example, in a customer service conversation, responses from the agent should ideally be soothing and address the user's dissatisfaction or complaints. This imposes significant demands on controlling language model output. However, demerits exist among traditional methods. Promoting and fine-tuning language models exhibit the hallucination phenomenon and cannot guarantee complete adherence to constraints. Conditional language models (CLM), which map control codes into LM representations or latent space, require training the modified language models from scratch and a high amount of customized dataset is demanded. Decoding-time methods employ Bayesian Rules to modify the output of the LM or model constraints as a combination of energy functions and update the output along the low-energy direction. Both methods are confronted with the efficiency sampling problem. Moreover, there are no methods that consider the relation between constraints weights and the contexts, as is essential in actual applications such as customer service scenarios. To alleviate the problems mentioned above, we propose Controllable Text Generation with Generative Adversarial Networks (CTGGAN), which utilizes a language model with logits bias as the Generator to produce constrained text and employs the Discriminator with learnable constraint weight combinations to score and update the generation. We evaluate the method in the text completion task and Chinese customer service dialogues scenario, and our method shows superior performance in metrics such as PPL and Dist-3. In addition, CTGGAN also exhibits efficient decoding compared to other methods.",,2076-3417,,, ,  ,,out_of_scope,
2569,"**Title**How Useful Are Educational Questions Generated by Large Language Models?

**Abstract**Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike. Specifically, high quality and diverse question generation can dramatically reduce the load on teachers and improve the quality of their educational content. Recent work in this domain has made progress with generation, but fails to show that real teachers judge the generated questions as sufficiently useful for the classroom setting; or if instead the questions have errors and/or pedagogically unhelpful content. We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom's and a difficulty taxonomy). The results demonstrate that the questions generated are high quality and sufficiently useful, showing their promise for widespread use in the classroom setting.","Elkins, Sabina; Kochmar, Ekaterina; Serban, Iulian; Cheung, Jackie C. K.","Kochmar, Ekaterina/IAN-5536-2023",,How Useful Are Educational Questions Generated by Large Language Models?,1831,,10.1007/978-3-031-36336-8_83 ,Proceedings Paper ,,"Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike. Specifically, high quality and diverse question generation can dramatically reduce the load on teachers and improve the quality of their educational content. Recent work in this domain has made progress with generation, but fails to show that real teachers judge the generated questions as sufficiently useful for the classroom setting; or if instead the questions have errors and/or pedagogically unhelpful content. We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom's and a difficulty taxonomy). The results demonstrate that the questions generated are high quality and sufficiently useful, showing their promise for widespread use in the classroom setting.",1865-0929,1865-0937,978-3-031-36335-1; 978-3-031-36336-8,536-542, , 24th International Conference on Artificial Intelligence in Education (AIED)24th International Conference on Artificial Intelligence in Education (AIED) ,,out_of_scope,
2570,"**Title**Memory-enhanced text style transfer with dynamic style learning and calibration

**Abstract**Text style transfer aims to rephrase a sentence to match the desired style while retaining the original content. As a controllable text generation task, mainstream approaches use content-independent style embedding as control variables to guide stylistic generation. Nonetheless, stylistic properties are context-sensitive even under the same style. For example, delicious and helpful convey positive sentiments, although they are more likely to describe food and people, respectively. Therefore, desired style signals must vary with the content. To this end, we propose a memory-enhanced transfer method, which learns fine-grained style representation concerning content to assist transfer. Rather than employing static style embedding or latent variables, our method abstracts linguistic characteristics from training corpora and memorizes subdivided content with the corresponding style representations. The style signal is dynamically retrieved from memory using the content as a query, providing a more expressive and flexible latent style space. To address the imbalance between quantity and quality in different content, we further introduce a calibration method to augment memory construction by modeling the relationship between candidate styles. Experimental results obtained using three benchmark datasets confirm the superior performance of our model compared to competitive approaches. The evaluation metrics and case study also indicate that our model can generate diverse stylistic phrases matching context.","Lin, Fuqiang; Song, Yiping; Tian, Zhiliang; Chen, Wangqun; Dong, Diwen; Liu, Bo",,,Memory-enhanced text style transfer with dynamic style learning and calibration,67,4,10.1007/s11432-022-3726-0 ,Article ,,"Text style transfer aims to rephrase a sentence to match the desired style while retaining the original content. As a controllable text generation task, mainstream approaches use content-independent style embedding as control variables to guide stylistic generation. Nonetheless, stylistic properties are context-sensitive even under the same style. For example, delicious and helpful convey positive sentiments, although they are more likely to describe food and people, respectively. Therefore, desired style signals must vary with the content. To this end, we propose a memory-enhanced transfer method, which learns fine-grained style representation concerning content to assist transfer. Rather than employing static style embedding or latent variables, our method abstracts linguistic characteristics from training corpora and memorizes subdivided content with the corresponding style representations. The style signal is dynamically retrieved from memory using the content as a query, providing a more expressive and flexible latent style space. To address the imbalance between quantity and quality in different content, we further introduce a calibration method to augment memory construction by modeling the relationship between candidate styles. Experimental results obtained using three benchmark datasets confirm the superior performance of our model compared to competitive approaches. The evaluation metrics and case study also indicate that our model can generate diverse stylistic phrases matching context.",1674-733X,1869-1919,,, ,  ,,detox,
2571,"**Title**Predictive typing method for Persian office automation

**Abstract**Typing is a time-consuming task and predictive text is proposed as a solution. Recently, Generative Pre-trained Transformers (GPT) have employed autoregressive deep learning to tackle text prediction. However, they face costly retraining, especially for low-resource languages (such as Persian) or domains, and lack controllability. Text augmentation with prompting methods and fine-tuning GPT models on templated data using conditional elements (labels or keywords) aims to address these problems, enhancing controllable text generation in lowresource scenarios. These methods involve discovering and mapping conditional elements to training texts, which is unsuitable for typing assistants. Meanwhile, they do hold inappropriate pre-defined elements for wide use. This paper introduces Conditional GPT-2-Persian (CGPT-2-Persian), which utilizes the initial word of each sentence as the associated conditional element to address practical challenges, extracting labels, and handling indomain unseen data posed by the mentioned methods. This method outperforms Persian text generation methods in terms of BLEU and ROUGE scores, achieving 87.39% and 14.29%, respectively, after fine-tuning for ten epochs. This study can be efficient for other low-resource languages or domains.","Nouraei, Boshra; Shanbehzadeh, Jamshid; Asghari, Parvaneh","Asghari, Parvaneh/AAO-3080-2021","Nouraei, Boshra/0000-0003-4931-8872",Predictive typing method for Persian office automation,131,,10.1016/j.engappai.2023.107792 ,Article ,,"Typing is a time-consuming task and predictive text is proposed as a solution. Recently, Generative Pre-trained Transformers (GPT) have employed autoregressive deep learning to tackle text prediction. However, they face costly retraining, especially for low-resource languages (such as Persian) or domains, and lack controllability. Text augmentation with prompting methods and fine-tuning GPT models on templated data using conditional elements (labels or keywords) aims to address these problems, enhancing controllable text generation in lowresource scenarios. These methods involve discovering and mapping conditional elements to training texts, which is unsuitable for typing assistants. Meanwhile, they do hold inappropriate pre-defined elements for wide use. This paper introduces Conditional GPT-2-Persian (CGPT-2-Persian), which utilizes the initial word of each sentence as the associated conditional element to address practical challenges, extracting labels, and handling indomain unseen data posed by the mentioned methods. This method outperforms Persian text generation methods in terms of BLEU and ROUGE scores, achieving 87.39% and 14.29%, respectively, after fine-tuning for ten epochs. This study can be efficient for other low-resource languages or domains.",0952-1976,1873-6769,,, ,  ,,out_of_scope,
2572,"**Title**Stylized Story Generation with Style-Guided Planning

**Abstract**Current storytelling systems focus more on generating stories with coherent plots regardless of the narration style, which is important for controllable text generation. Therefore, we propose a new task, stylized story generation, namely generating stories with specified style given a leading context. To tackle the problem, we propose a novel generation model that first plans the stylized keywords and then generates the whole story with the guidance of the keywords. Besides, we propose two automatic metrics to evaluate the consistency between the generated story and the specified style. Experiments demonstrates that our model can controllably generate emotion-driven or event-driven stories based on the ROCStories dataset (Mostafazadeh et al., 2016). Our study presents insights for stylized story generation in further research.","Kong, Xiangzhe; Huang, Jialiang; Tung, Ziquan; Guan, Jian; Huang, Minlie",,,Stylized Story Generation with Style-Guided Planning,,, ,Proceedings Paper ,,"Current storytelling systems focus more on generating stories with coherent plots regardless of the narration style, which is important for controllable text generation. Therefore, we propose a new task, stylized story generation, namely generating stories with specified style given a leading context. To tackle the problem, we propose a novel generation model that first plans the stylized keywords and then generates the whole story with the guidance of the keywords. Besides, we propose two automatic metrics to evaluate the consistency between the generated story and the specified style. Experiments demonstrates that our model can controllably generate emotion-driven or event-driven stories based on the ROCStories dataset (Mostafazadeh et al., 2016). Our study presents insights for stylized story generation in further research.",,,978-1-954085-54-1,2430-2436, , Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP)Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP) ,,out_of_scope,
2573,"**Title**Language Generation via Combinatorial Constraint Satisfaction: A Tree Search Enhanced Monte-Carlo Approach

**Abstract**Generating natural language under complex constraints is a principled formulation towards controllable text generation. We present a framework to allow specification of combinatorial constraints for sentence generation. We propose TSMH1, an efficient method to generate high likelihood sentences with respect to a pre-trained language model while satisfying the constraints. Our approach is highly flexible, requires no task-specific training, and leverages efficient constraint satisfaction solving techniques. To better handle the combinatorial constraints, a tree search algorithm is embedded into the proposal process of the Markov chain Monte Carlo (MCMC) to explore candidates that satisfy more constraints. Compared to existing MCMC approaches, our sampling approach has a better mixing performance. Experiments show that TSMH achieves consistent and significant improvement on multiple language generation tasks.","Zhang, Maosen; Jiang, Nan; Li, Lei; Xue, Yexiang",,,Language Generation via Combinatorial Constraint Satisfaction: A Tree Search Enhanced Monte-Carlo Approach,,, ,Proceedings Paper ,,"Generating natural language under complex constraints is a principled formulation towards controllable text generation. We present a framework to allow specification of combinatorial constraints for sentence generation. We propose TSMH1, an efficient method to generate high likelihood sentences with respect to a pre-trained language model while satisfying the constraints. Our approach is highly flexible, requires no task-specific training, and leverages efficient constraint satisfaction solving techniques. To better handle the combinatorial constraints, a tree search algorithm is embedded into the proposal process of the Markov chain Monte Carlo (MCMC) to explore candidates that satisfy more constraints. Compared to existing MCMC approaches, our sampling approach has a better mixing performance. Experiments show that TSMH achieves consistent and significant improvement on multiple language generation tasks.",,,978-1-952148-90-3,1286-1298, , Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP) ,,out_of_scope,
2574,"**Title**AI-Assisted Text Composition for Automated Content Authoring Using Transformer-Based Language Models

**Abstract**In this paper, we introduce a hybrid method that combines the use of Controllable Text Generation (CTG) approach via Large Language Models (LLMs), fine-tuned language models and sentence transformers in a single framework to generate real-author styled articles in Turkish language. As such, we seek to exemplify hybrid solutions that produce real-human styled high-quality contents, given limited resources and relatively short text prompts as inputs. To achieve this, we introduce a novel method to assemble an author-specific article in different coherence and fluency levels, based on phrasal control of the CTG process. Control phrases are automatically assembled based on a semantic correlation measure calculated using sentence embeddings corresponding to author articles, that are obtained from pre-trained sentence transformers.","Alpdemir, Yusuf; Alpdemir, Mahmut Nedim","Alpdemir, Mahmut Nedim/GWQ-8385-2022","Alpdemir, Mahmut Nedim/0000-0001-6411-1453",AI-Assisted Text Composition for Automated Content Authoring Using Transformer-Based Language Models,,,10.1109/IC_ASET61847.2024.10596255 ,Proceedings Paper ,,"In this paper, we introduce a hybrid method that combines the use of Controllable Text Generation (CTG) approach via Large Language Models (LLMs), fine-tuned language models and sentence transformers in a single framework to generate real-author styled articles in Turkish language. As such, we seek to exemplify hybrid solutions that produce real-human styled high-quality contents, given limited resources and relatively short text prompts as inputs. To achieve this, we introduce a novel method to assemble an author-specific article in different coherence and fluency levels, based on phrasal control of the CTG process. Control phrases are automatically assembled based on a semantic correlation measure calculated using sentence embeddings corresponding to author articles, that are obtained from pre-trained sentence transformers.",,,979-8-3503-8490-1; 979-8-3503-8489-5,, , International Conference on Advanced Systems and Emergent Technologies (ICASET)International Conference on Advanced Systems and Emergent Technologies (ICASET) ,,out_of_scope,
2575,"**Title**Backpack Language Models

**Abstract**We present Backpacks: a new neural architecture that marries strong modeling performance with an interface for interpretability and control. Backpacks learn multiple non-contextual sense vectors for each word in a vocabulary, and represent a word in a sequence as a context-dependent, non-negative linear combination of sense vectors in this sequence. We find that, after training, sense vectors specialize, each encoding a different aspect of a word. We can interpret a sense vector by inspecting its (non-contextual, linear) projection onto the output space, and intervene on these interpretable hooks to change the model's behavior in predictable ways. We train a 170M-parameter Backpack language model on OpenWebText, matching the loss of a GPT-2 small (124M-parameter) Transformer. On lexical similarity evaluations, we find that Backpack sense vectors outperform even a 6B-parameter Transformer LM's word embeddings. Finally, we present simple algorithms that intervene on sense vectors to perform controllable text generation and debiasing. For example, we can edit the sense vocabulary to tend more towards a topic, or localize a source of gender bias to a sense vector and globally suppress that sense.","Hewitt, John; Thickstun, John; Manning, Christopher D.; Liang, Percy","Manning, Christopher/A-1358-2007","Manning, Christopher/0000-0001-6155-649X",Backpack Language Models,,, ,Proceedings Paper ,,"We present Backpacks: a new neural architecture that marries strong modeling performance with an interface for interpretability and control. Backpacks learn multiple non-contextual sense vectors for each word in a vocabulary, and represent a word in a sequence as a context-dependent, non-negative linear combination of sense vectors in this sequence. We find that, after training, sense vectors specialize, each encoding a different aspect of a word. We can interpret a sense vector by inspecting its (non-contextual, linear) projection onto the output space, and intervene on these interpretable hooks to change the model's behavior in predictable ways. We train a 170M-parameter Backpack language model on OpenWebText, matching the loss of a GPT-2 small (124M-parameter) Transformer. On lexical similarity evaluations, we find that Backpack sense vectors outperform even a 6B-parameter Transformer LM's word embeddings. Finally, we present simple algorithms that intervene on sense vectors to perform controllable text generation and debiasing. For example, we can edit the sense vocabulary to tend more towards a topic, or localize a source of gender bias to a sense vector and globally suppress that sense.",,,978-1-959429-72-2,9103-9125, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2576,"**Title**NEUROSTRUCTURAL DECODING: Neural Text Generation with Structural Constraints

**Abstract**Text generation often involves producing texts that also satisfy a given set of semantic constraints. While most approaches for conditional text generation have primarily focused on lexical constraints, they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints. We address this gap by introducing NEUROSTRUCTURAL DECODING, a new decoding algorithm that incorporates syntactic constraints to further improve the quality of the generated text. We build NEUROSTRUCTURAL DECODING on the NeuroLogic Decoding (Lu et al., 2021b) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints. Our algorithm is powerful and scalable. It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object) during decoding by parsing the partial generations at each step. To this end, we adapt a dependency parser to generate parses for incomplete sentences. Our approach is evaluated on three different language generation tasks, and the results show improved performance in both lexical and syntactic metrics compared to previous methods. The results suggest this is a promising solution for integrating fine-grained controllable text generation into the conventional beam search decoding(1).","Bastan, Mohaddeseh; Surdeanu, Mihai; Balasubramanian, Niranjan","Bastan, Mohaddeseh/AAA-3405-2022",,NEUROSTRUCTURAL DECODING: Neural Text Generation with Structural Constraints,,, ,Proceedings Paper ,,"Text generation often involves producing texts that also satisfy a given set of semantic constraints. While most approaches for conditional text generation have primarily focused on lexical constraints, they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints. We address this gap by introducing NEUROSTRUCTURAL DECODING, a new decoding algorithm that incorporates syntactic constraints to further improve the quality of the generated text. We build NEUROSTRUCTURAL DECODING on the NeuroLogic Decoding (Lu et al., 2021b) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints. Our algorithm is powerful and scalable. It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object) during decoding by parsing the partial generations at each step. To this end, we adapt a dependency parser to generate parses for incomplete sentences. Our approach is evaluated on three different language generation tasks, and the results show improved performance in both lexical and syntactic metrics compared to previous methods. The results suggest this is a promising solution for integrating fine-grained controllable text generation into the conventional beam search decoding(1).",,,978-1-959429-72-2,9496-9510, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2577,"**Title**Prompt Highlighter: Interactive Control for Multi-Modal LLMs

**Abstract**This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs) inference: explicit controllable text generation. Multi-modal LLMs empower multi-modality understanding with the capability of semantic generation yet bring less explainability and heavier reliance on prompt contents due to their autoregressive generative nature. While manipulating prompt formats could improve outputs, designing specific and precise prompts per task can be challenging and ineffective. To tackle this issue, we introduce a novel inference method, Prompt Highlighter, which enables users to highlight specific prompt spans to interactively control the focus during generation. Motivated by the classifier-free diffusion guidance, we form regular and unconditional context pairs based on highlighted tokens, demonstrating that the autoregressive generation in models can be guided in a classifier-free way. Notably, we find that, during inference, guiding the models with highlighted tokens through the attention weights leads to more desired outputs. Our approach is compatible with current LLMs and VLMs, achieving impressive customized generation results without training. Experiments confirm its effectiveness in focusing on input contexts and generating reliable content. Without tuning on LLaVA-v1.5, our method secured 70.7 in the MMBench test and 1552.5 in MME-perception.","Zhang, Yuechen; Qiao, Shengju; Peng, Bohao; Liu, Shu; Jia, Jiaya",,,Prompt Highlighter: Interactive Control for Multi-Modal LLMs,,,10.1109/CVPR52733.2024.01255 ,Proceedings Paper ,,"This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs) inference: explicit controllable text generation. Multi-modal LLMs empower multi-modality understanding with the capability of semantic generation yet bring less explainability and heavier reliance on prompt contents due to their autoregressive generative nature. While manipulating prompt formats could improve outputs, designing specific and precise prompts per task can be challenging and ineffective. To tackle this issue, we introduce a novel inference method, Prompt Highlighter, which enables users to highlight specific prompt spans to interactively control the focus during generation. Motivated by the classifier-free diffusion guidance, we form regular and unconditional context pairs based on highlighted tokens, demonstrating that the autoregressive generation in models can be guided in a classifier-free way. Notably, we find that, during inference, guiding the models with highlighted tokens through the attention weights leads to more desired outputs. Our approach is compatible with current LLMs and VLMs, achieving impressive customized generation results without training. Experiments confirm its effectiveness in focusing on input contexts and generating reliable content. Without tuning on LLaVA-v1.5, our method secured 70.7 in the MMBench test and 1552.5 in MME-perception.",1063-6919,,979-8-3503-5300-6,13215-13224, , IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) ,,out_of_scope,
2578,"**Title**Automatic Educational Question Generation with Difficulty Level Controls

**Abstract**We consider the task of automatically generating math word problems (MWPs) of various difficulties that meet the needs of teachers in teaching and testing students in corresponding educational stages. Existing methods fail to produce high-quality problems while allowing the teacher control over the problem difficulty level. In this work, we introduce a controllable MWP generation pipeline that samples from an energy language model with various expert model components for realizing the target attributes. We control the difficulty of the resulting MWPs from mathematical and linguistic aspects by imposing constraints on equations, vocabulary, and topics. We also use other control attributes including fluency and distance to the conditioning sequence to manage language quality and creativity. Experiments and evaluation results demonstrate our approach improves upon the baselines in generating solvable, well-formed, and diverse MWPs of controlled difficulty levels. Lastly, we solicit feedback from various math educators who approve the effectiveness of our system for their MWP design processes. They suggest our outputs align with the expectations of problem designers showing a possibility of using such problem generators in real-life educational scenarios. Our code and data are available on request.","Jiao, Ying; Shridhar, Kumar; Cui, Peng; Zhou, Wangchunshu; Sachan, Mrinmaya",,"Jiao, Ying/0009-0009-2279-7691",Automatic Educational Question Generation with Difficulty Level Controls,13916,,10.1007/978-3-031-36272-9_39 ,Proceedings Paper ,,"We consider the task of automatically generating math word problems (MWPs) of various difficulties that meet the needs of teachers in teaching and testing students in corresponding educational stages. Existing methods fail to produce high-quality problems while allowing the teacher control over the problem difficulty level. In this work, we introduce a controllable MWP generation pipeline that samples from an energy language model with various expert model components for realizing the target attributes. We control the difficulty of the resulting MWPs from mathematical and linguistic aspects by imposing constraints on equations, vocabulary, and topics. We also use other control attributes including fluency and distance to the conditioning sequence to manage language quality and creativity. Experiments and evaluation results demonstrate our approach improves upon the baselines in generating solvable, well-formed, and diverse MWPs of controlled difficulty levels. Lastly, we solicit feedback from various math educators who approve the effectiveness of our system for their MWP design processes. They suggest our outputs align with the expectations of problem designers showing a possibility of using such problem generators in real-life educational scenarios. Our code and data are available on request.",2945-9133,1611-3349,978-3-031-36271-2; 978-3-031-36272-9,476-488, , 24th International Conference on Artificial Intelligence in Education (AIED)24th International Conference on Artificial Intelligence in Education (AIED) ,,out_of_scope,
2579,"**Title**Topic-Oriented Controlled Text Generation for Social Networks

**Abstract**Currently, advances in text modeling by Pre-trained Language Models (PLM) enable machines to generate texts that are fluent and human language-specific. However, in the social network scenario, the generated text still has the issues of not being able to recognize sarcastic opinions, not conforming to social network language conventions, not containing topic-related knowledge information, and degrading some attributes when controlled by multiple attributes, which cannot control the stance, style, and topic of the generated text accurately. Besides, there is a lot of false and malicious news on the Internet, jeopardizing the security of the network and big data. To address these challenges, we defined and analyzed the attributes of topic texts and then proposed a PCTG-X model for single attribute discriminator control of PLM decoding based on prompt learning in order to control the stance, style, and topic attributes, respectively. We collected topic datasets from social platforms such as Twitter, and used some publicly available social text datasets to design model evaluation metrics and comparison experiments. The experiments show that PCTG-X has a significant improvement in the control of three single attributes of stance, style and topic compared with the benchmark method.","Yang, Zhian; Jiang, Hao; Deng, Aobo; Li, Yang","Jiang, Hao/HSE-9388-2023",,Topic-Oriented Controlled Text Generation for Social Networks,96,2,10.1007/s11265-023-01907-2 ,Article ,,"Currently, advances in text modeling by Pre-trained Language Models (PLM) enable machines to generate texts that are fluent and human language-specific. However, in the social network scenario, the generated text still has the issues of not being able to recognize sarcastic opinions, not conforming to social network language conventions, not containing topic-related knowledge information, and degrading some attributes when controlled by multiple attributes, which cannot control the stance, style, and topic of the generated text accurately. Besides, there is a lot of false and malicious news on the Internet, jeopardizing the security of the network and big data. To address these challenges, we defined and analyzed the attributes of topic texts and then proposed a PCTG-X model for single attribute discriminator control of PLM decoding based on prompt learning in order to control the stance, style, and topic attributes, respectively. We collected topic datasets from social platforms such as Twitter, and used some publicly available social text datasets to design model evaluation metrics and comparison experiments. The experiments show that PCTG-X has a significant improvement in the control of three single attributes of stance, style and topic compared with the benchmark method.",1939-8018,1939-8115,,131-151, ,  ,,out_of_scope,
2580,"**Title**On Improving Summarization Factual Consistency from Natural Language Feedback

**Abstract**Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary. We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.","Liu, Yixin; Deb, Budhaditya; Teruel, Milagro; Halfaker, Aaron; Radev, Dragomir; Awadallah, Ahmed H.",,,On Improving Summarization Factual Consistency from Natural Language Feedback,,, ,Proceedings Paper ,,"Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary. We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.",,,978-1-959429-72-2,15144-15161, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2581,"**Title**PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation

**Abstract**Controllable text generation is a challenging and meaningful field in natural language generation (NLG). Especially, poetry generation is a typical one with well-defined and strict conditions for text generation which is an ideal playground for the assessment of current methodologies. While prior works succeeded in controlling either semantic or metrical aspects of poetry generation, simultaneously addressing both remains a challenge. In this paper, we pioneer the use of the Diffusion model for generating sonnets and Chinese SongCi poetry to tackle such challenges. In terms of semantics, our Poetry-Diffusion model, built upon the Diffusion model, generates entire sentences or poetry by comprehensively considering the entirety of sentence information. This approach enhances semantic expression, distinguishing it from autoregressive and large language models (LLMs). For metrical control, its constraint control module which can be trained individually enables us to flexibly incorporate a novel metrical controller to manipulate and evaluate metrics (format and rhythm). The denoising process in PoetryDiffusion allows for the gradual enhancement of semantics and flexible integration of the metrical controller which can calculate and impose penalties on states that stray significantly from the target control distribution. Experimental results on two datasets demonstrate that our model outperforms existing models in terms of automatic evaluation of semantic, metrical, and overall performance as well as human evaluation. Codes are released to https://github.com/ChorlingLau/PoetryDiffusion/.","Hu, Zhiyuan; Liu, Chumin; Feng, Yue; Anh Tuan Luu; Hooi, Bryan","Hu, Zhiyuan/JPX-7229-2023; Luu, Anh Tuan/AAG-3582-2021; Hooi, Bryan/AAU-5707-2020",,PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation,,, ,Proceedings Paper ,,"Controllable text generation is a challenging and meaningful field in natural language generation (NLG). Especially, poetry generation is a typical one with well-defined and strict conditions for text generation which is an ideal playground for the assessment of current methodologies. While prior works succeeded in controlling either semantic or metrical aspects of poetry generation, simultaneously addressing both remains a challenge. In this paper, we pioneer the use of the Diffusion model for generating sonnets and Chinese SongCi poetry to tackle such challenges. In terms of semantics, our Poetry-Diffusion model, built upon the Diffusion model, generates entire sentences or poetry by comprehensively considering the entirety of sentence information. This approach enhances semantic expression, distinguishing it from autoregressive and large language models (LLMs). For metrical control, its constraint control module which can be trained individually enables us to flexibly incorporate a novel metrical controller to manipulate and evaluate metrics (format and rhythm). The denoising process in PoetryDiffusion allows for the gradual enhancement of semantics and flexible integration of the metrical controller which can calculate and impose penalties on states that stray significantly from the target control distribution. Experimental results on two datasets demonstrate that our model outperforms existing models in terms of automatic evaluation of semantic, metrical, and overall performance as well as human evaluation. Codes are released to https://github.com/ChorlingLau/PoetryDiffusion/.",2159-5399,2374-3468,*****************,18279-18288, , 38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence ,,out_of_scope,
2582,"**Title**Benchmarking Large Language Models on Controllable Generation under Diversified Instructions

**Abstract**While large language models (LLMs) have exhibited impressive instruction-following capabilities, it is still unclear whether and to what extent they can respond to explicit constraints that might be entailed in various instructions. As a significant aspect of LLM alignment, it is thus important to formulate such a specialized set of instructions as well as investigate the resulting behavior of LLMs. To address this vacancy, we propose a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs' responses to instructions with various constraints. We construct a large collection of constraints-attributed instructions as a test suite focused on both generalization and coverage. Specifically, we advocate an instruction diversification process to synthesize diverse forms of constraint expression and also deliberate the candidate task taxonomy with even finer-grained sub-categories. Finally, we automate the entire evaluation process to facilitate further developments. Different from existing studies on controllable text generation, CoDI-Eval extends the scope to the prevalent instruction-following paradigm for the first time. We provide extensive evaluations of representative LLMs (e.g., ChatGPT, Vicuna) on CoDI-Eval, revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source LLMs. We believe this benchmark will facilitate research into improving the controllability of LLMs' responses to instructions. Our data and code are available at https://github.com/Xt-cyh/CoDI-Eval.","Chen, Yihan; Xu, Benfeng; Wang, Quan; Liu, Yi; Mao, Zhendong","Mao, Zhendong/LVQ-9402-2024",,Benchmarking Large Language Models on Controllable Generation under Diversified Instructions,,, ,Proceedings Paper ,,"While large language models (LLMs) have exhibited impressive instruction-following capabilities, it is still unclear whether and to what extent they can respond to explicit constraints that might be entailed in various instructions. As a significant aspect of LLM alignment, it is thus important to formulate such a specialized set of instructions as well as investigate the resulting behavior of LLMs. To address this vacancy, we propose a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs' responses to instructions with various constraints. We construct a large collection of constraints-attributed instructions as a test suite focused on both generalization and coverage. Specifically, we advocate an instruction diversification process to synthesize diverse forms of constraint expression and also deliberate the candidate task taxonomy with even finer-grained sub-categories. Finally, we automate the entire evaluation process to facilitate further developments. Different from existing studies on controllable text generation, CoDI-Eval extends the scope to the prevalent instruction-following paradigm for the first time. We provide extensive evaluations of representative LLMs (e.g., ChatGPT, Vicuna) on CoDI-Eval, revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source LLMs. We believe this benchmark will facilitate research into improving the controllability of LLMs' responses to instructions. Our data and code are available at https://github.com/Xt-cyh/CoDI-Eval.",2159-5399,2374-3468,*****************,17808-17816, , 38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence ,,out_of_scope,
2583,"**Title**Counterfactual Generation with Identifiability Guarantees

**Abstract**Counterfactual generation lies at the core of various machine learning tasks, including image translation and controllable text generation. This generation process usually requires the identification of the disentangled latent representations, such as content and style, that underlie the observed data. However, it becomes more challenging when faced with a scarcity of paired data and labeling information. Existing disentangled methods crucially rely on oversimplified assumptions, such as assuming independent content and style variables, to identify the latent variables, even though such assumptions may not hold for complex data distributions. For instance, food reviews tend to involve words like tasty, whereas movie reviews commonly contain words such as thrilling for the same positive sentiment. This problem is exacerbated when data are sampled from multiple domains since the dependence between content and style may vary significantly over domains. In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task. We provide identification guarantees for such latent-variable models by leveraging the relative sparsity of the influences from different latent variables. Our theoretical insights enable the development of a doMain AdapTive counTerfactual gEneration model, called (MATTE). Our theoretically grounded framework achieves state-of-the-art performance in unsupervised style transfer tasks, where neither paired data nor style labels are utilized, across four large-scale datasets.","Yan, Hanqi; Kong, Lingjing; Gui, Lin; Chi, Yuejie; Xing, Eric; He, Yulan; Zhang, Kun","Chi, Yuejie/G-6033-2012; yan, hanqi/GQB-4936-2022; Gui, Lin/KRO-8983-2024",,Counterfactual Generation with Identifiability Guarantees,,, ,Proceedings Paper ,,"Counterfactual generation lies at the core of various machine learning tasks, including image translation and controllable text generation. This generation process usually requires the identification of the disentangled latent representations, such as content and style, that underlie the observed data. However, it becomes more challenging when faced with a scarcity of paired data and labeling information. Existing disentangled methods crucially rely on oversimplified assumptions, such as assuming independent content and style variables, to identify the latent variables, even though such assumptions may not hold for complex data distributions. For instance, food reviews tend to involve words like tasty, whereas movie reviews commonly contain words such as thrilling for the same positive sentiment. This problem is exacerbated when data are sampled from multiple domains since the dependence between content and style may vary significantly over domains. In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task. We provide identification guarantees for such latent-variable models by leveraging the relative sparsity of the influences from different latent variables. Our theoretical insights enable the development of a doMain AdapTive counTerfactual gEneration model, called (MATTE). Our theoretically grounded framework achieves state-of-the-art performance in unsupervised style transfer tasks, where neither paired data nor style labels are utilized, across four large-scale datasets.",1049-5258,,*****************,, , 37th Conference on Neural Information Processing Systems (NeurIPS)37th Conference on Neural Information Processing Systems (NeurIPS) ,,out_of_scope,
2584,"**Title**Enabling controllable table-to-text generation via prompting large language models with guided planning

**Abstract**Recently, Large Language Models (LLMs) has demonstrated unparalleled capabilities in understanding and generation, hence holding promising prospects for applying LLMs to table-to-text generation. However, the generation process with LLMs lacks a high degree of controllability, which hinders the utilization of LLMs for table-to-text generation. In this paper, we introduce Poised, an effective method that prompts LLMs with guided planning to achieve controllable table-to-text generation. Specifically, we first employ prefix-tuning on BART to derive a plan from the given table. Then, we combine the plan with guided instructions to create a comprehensive prompt, which is later input into LLMs to generate the description of the table. Experiments across three domains of the few-shot Wili dataset show that Poised achieves or approaches a plan completion rate of 100%, with an average hallucination frequency of less than 10%. Furthermore, Poised allows for finegrained control over the generated content by intentionally modifying the prompt, enabling precise control over aspects such as attribute realization order.","Zhao, Shuo; Sun, Xin",,,Enabling controllable table-to-text generation via prompting large language models with guided planning,304,,10.1016/j.knosys.2024.112571 ,Article ,,"Recently, Large Language Models (LLMs) has demonstrated unparalleled capabilities in understanding and generation, hence holding promising prospects for applying LLMs to table-to-text generation. However, the generation process with LLMs lacks a high degree of controllability, which hinders the utilization of LLMs for table-to-text generation. In this paper, we introduce Poised, an effective method that prompts LLMs with guided planning to achieve controllable table-to-text generation. Specifically, we first employ prefix-tuning on BART to derive a plan from the given table. Then, we combine the plan with guided instructions to create a comprehensive prompt, which is later input into LLMs to generate the description of the table. Experiments across three domains of the few-shot Wili dataset show that Poised achieves or approaches a plan completion rate of 100%, with an average hallucination frequency of less than 10%. Furthermore, Poised allows for finegrained control over the generated content by intentionally modifying the prompt, enabling precise control over aspects such as attribute realization order.",0950-7051,1872-7409,,, ,  ,,out_of_scope,
2585,"**Title**Personalized Product Description Generation With Gated Pointer-Generator Transformer

**Abstract**In the realm of e-commerce, where online shopping has become a staple of daily life, the generation of personalized product descriptions presents a unique challenge and opportunity for enhancing customer experience. Traditional retail interactions allow for personalized communication between salespersons and customers, ensuring that consumer needs are directly addressed. This level of personalization is harder to achieve online, where customers must navigate through generic, often lengthy product descriptions to make informed purchasing decisions. Recognizing the dual necessity of personalizing content to individual preferences while ensuring the descriptions remain faithful to the product's core attributes, this article introduces a novel approach, the gated pointer-generator transformer (GPGT). This framework is designed to bridge the gap between customer preferences and product features, enabling the generation of descriptions that are not only customized to the user's interests- such as emphasizing appearance for fashion-forward individuals or functionality for tech enthusiasts-but also accurately reflect the product's distinctive qualities, including brand names and technical specifications. GPGT leverages the select-attention mechanism combined with a Transformer encoder to capture the nuanced interactions between user attributes and product features, further refined by a copy mechanism during the decoding phase for the precise inclusion of specific product-related terms. Extensive experiments show that our framework substantially improves the quality of generation (+10.6% on ROUGE-2 and +15.9% on BLEU) while being more faithful to draw people's attention. The results on human evaluation, in terms of fluency, faithfulness, and personalization, also exhibit that descriptions generated by GPGT can be better accepted by real users.","Liang, Yu-Sen; Chen, Chih-Yao; Li, Cheng-Te; Chang, Sheng-Mao",,"Chang, Sheng-Mao/0000-0003-2785-0155",Personalized Product Description Generation With Gated Pointer-Generator Transformer,12,1,10.1109/TCSS.2024.3396840 ,Article ,,"In the realm of e-commerce, where online shopping has become a staple of daily life, the generation of personalized product descriptions presents a unique challenge and opportunity for enhancing customer experience. Traditional retail interactions allow for personalized communication between salespersons and customers, ensuring that consumer needs are directly addressed. This level of personalization is harder to achieve online, where customers must navigate through generic, often lengthy product descriptions to make informed purchasing decisions. Recognizing the dual necessity of personalizing content to individual preferences while ensuring the descriptions remain faithful to the product's core attributes, this article introduces a novel approach, the gated pointer-generator transformer (GPGT). This framework is designed to bridge the gap between customer preferences and product features, enabling the generation of descriptions that are not only customized to the user's interests- such as emphasizing appearance for fashion-forward individuals or functionality for tech enthusiasts-but also accurately reflect the product's distinctive qualities, including brand names and technical specifications. GPGT leverages the select-attention mechanism combined with a Transformer encoder to capture the nuanced interactions between user attributes and product features, further refined by a copy mechanism during the decoding phase for the precise inclusion of specific product-related terms. Extensive experiments show that our framework substantially improves the quality of generation (+10.6% on ROUGE-2 and +15.9% on BLEU) while being more faithful to draw people's attention. The results on human evaluation, in terms of fluency, faithfulness, and personalization, also exhibit that descriptions generated by GPGT can be better accepted by real users.",2329-924X,,,52-63, ,  ,,out_of_scope,
2586,"**Title**Transformers and meta-tokenization in sentiment analysis for software engineering

**Abstract**Sentiment analysis has been used to study aspects of software engineering, such as issue resolution, toxicity, and self-admitted technical debt. To address the peculiarities of software engineering texts, sentiment analysis tools often consider the specific technical lingo practitioners use. To further improve the application of sentiment analysis, there have been two recommendations: Using pre-trained transformer models to classify sentiment and replacing non-natural language elements with meta-tokens. In this work, we benchmark five different sentiment analysis tools (two pre-trained transformer models and three machine learning tools) on 2 gold-standard sentiment analysis datasets. We find that pre-trained transformers outperform the best machine learning tool on only one of the two datasets, and that even on that dataset the performance difference is a few percentage points. Therefore, we recommend that software engineering researchers should not just consider predictive performance when selecting a sentiment analysis tool because the best-performing sentiment analysis tools perform very similarly to each other (within 4 percentage points). Meanwhile, we find that meta-tokenization does not improve the predictive performance of sentiment analysis tools. Both of our findings can be used by software engineering researchers who seek to apply sentiment analysis tools to software engineering data.","Cassee, Nathan; Agaronian, Andrei; Constantinou, Eleni; Novielli, Nicole; Serebrenik, Alexander","Novielli, Nicole/Y-9583-2019","Constantinou, Eleni/0000-0002-4242-2581; Novielli, Nicole/0000-0003-1160-2608",Transformers and meta-tokenization in sentiment analysis for software engineering,29,4,10.1007/s10664-024-10468-2 ,Article ,,"Sentiment analysis has been used to study aspects of software engineering, such as issue resolution, toxicity, and self-admitted technical debt. To address the peculiarities of software engineering texts, sentiment analysis tools often consider the specific technical lingo practitioners use. To further improve the application of sentiment analysis, there have been two recommendations: Using pre-trained transformer models to classify sentiment and replacing non-natural language elements with meta-tokens. In this work, we benchmark five different sentiment analysis tools (two pre-trained transformer models and three machine learning tools) on 2 gold-standard sentiment analysis datasets. We find that pre-trained transformers outperform the best machine learning tool on only one of the two datasets, and that even on that dataset the performance difference is a few percentage points. Therefore, we recommend that software engineering researchers should not just consider predictive performance when selecting a sentiment analysis tool because the best-performing sentiment analysis tools perform very similarly to each other (within 4 percentage points). Meanwhile, we find that meta-tokenization does not improve the predictive performance of sentiment analysis tools. Both of our findings can be used by software engineering researchers who seek to apply sentiment analysis tools to software engineering data.",1382-3256,1573-7616,,, ,  ,,detection,
2587,"**Title**A Comprehensive Approach to Bias Mitigation for Sentiment Analysis of Social Media Data

**Abstract**Sentiment analysis is a vital component of natural language processing (NLP), enabling the classification of text into positive, negative, or neutral sentiments. It is widely used in customer feedback analysis and social media monitoring but faces a significant challenge: bias. Biases, often introduced through imbalanced training datasets, can distort model predictions and result in unfair outcomes. To address this, we propose a bias-aware sentiment analysis framework leveraging Bias-BERT (Bidirectional Encoder Representations from Transformers), a customized classifier designed to balance accuracy and fairness. Our approach begins with adapting the Jigsaw Unintended Bias in Toxicity Classification dataset by converting toxicity scores into sentiment labels, making it suitable for sentiment analysis. This process includes data preparation steps like cleaning, tokenization, and feature extraction, all aimed at reducing bias. At the heart of our method is a novel loss function incorporating a bias-aware term based on the Kullback-Leibler (KL) divergence. This term guides the model toward fair predictions by penalizing biased outputs while maintaining robust classification performance. Ethical considerations are integral to our framework, ensuring the responsible deployment of AI models. This methodology highlights a pathway to equitable sentiment analysis by actively mitigating dataset biases and promoting fairness in NLP applications.","Venugopal, Jothi Prakash; Subramanian, Arul Antran Vijay; Sundaram, Gopikrishnan; Rivera, Marco; Wheeler, Patrick","Rivera, Marco/E-9124-2012; , Dr. S. Gopikrishnan/C-2418-2015; V, Jothi Prakash/AAP-1618-2021; S, Arul Antran Vijay/AAM-8297-2020","Wheeler, Patrick/0000-0003-0307-581X; , Dr. S. Gopikrishnan/0000-0001-9082-9012; V, Jothi Prakash/0000-0002-5427-9460; S, Arul Antran Vijay/0000-0002-5543-7547; Rivera, Marco/0000-0002-4353-2088",A Comprehensive Approach to Bias Mitigation for Sentiment Analysis of Social Media Data,14,23,10.3390/app142311471 ,Article ,,"Sentiment analysis is a vital component of natural language processing (NLP), enabling the classification of text into positive, negative, or neutral sentiments. It is widely used in customer feedback analysis and social media monitoring but faces a significant challenge: bias. Biases, often introduced through imbalanced training datasets, can distort model predictions and result in unfair outcomes. To address this, we propose a bias-aware sentiment analysis framework leveraging Bias-BERT (Bidirectional Encoder Representations from Transformers), a customized classifier designed to balance accuracy and fairness. Our approach begins with adapting the Jigsaw Unintended Bias in Toxicity Classification dataset by converting toxicity scores into sentiment labels, making it suitable for sentiment analysis. This process includes data preparation steps like cleaning, tokenization, and feature extraction, all aimed at reducing bias. At the heart of our method is a novel loss function incorporating a bias-aware term based on the Kullback-Leibler (KL) divergence. This term guides the model toward fair predictions by penalizing biased outputs while maintaining robust classification performance. Ethical considerations are integral to our framework, ensuring the responsible deployment of AI models. This methodology highlights a pathway to equitable sentiment analysis by actively mitigating dataset biases and promoting fairness in NLP applications.",,2076-3417,,, ,  ,,out_of_scope,
2588,"**Title**Natural Language Processing to Automatically Extract the Presence and Severity of Esophagitis in Notes of Patients Undergoing Radiotherapy

**Abstract**PURPOSE Radiotherapy (RT) toxicities can impair survival and quality of life, yet remain understudied. Real-world evidence holds potential to improve our understanding of toxicities, but toxicity information is often only in clinical notes. We developed natural language processing (NLP) models to identify the presence and severity of esophagitis from notes of patients treated with thoracic RT.METHODS Our corpus consisted of a gold-labeled data set of 1,524 clinical notes from 124 patients with lung cancer treated with RT, manually annotated for Common Terminology Criteria for Adverse Events (CTCAE) v5.0 esophagitis grade, and a silver-labeled data set of 2,420 notes from 1,832 patients from whom toxicity grades had been collected as structured data during clinical care. We fine-tuned statistical and pretrained Bidirectional Encoder Representations from Transformers-based models for three esophagitis classification tasks: task 1, no esophagitis versus grade 1-3; task 2, grade <= 1 versus >1; and task 3, no esophagitis versus grade 1 versus grade 2-3. Transferability was tested on 345 notes from patients with esophageal cancer undergoing RT.RESULTS Fine-tuning of PubMedBERT yielded the best performance. The best macro-F1 was 0.92, 0.82, and 0.74 for tasks 1, 2, and 3, respectively. Selecting the most informative note sections during fine-tuning improved macro-F1 by >= 2% for all tasks. Silver-labeled data improved the macro-F1 by >= 3% across all tasks. For the esophageal cancer notes, the best macro-F1 was 0.73, 0.74, and 0.65 for tasks 1, 2, and 3, respectively, without additional fine-tuning.CONCLUSION To our knowledge, this is the first effort to automatically extract esophagitis toxicity severity according to CTCAE guidelines from clinical notes. This provides proof of concept for NLP-based automated detailed toxicity monitoring in expanded domains.","Chen, Shan; Guevara, Marco; Ramirez, Nicolas; Murray, Arpi; Warner, Jeremy L.; Aerts, Hugo J. W. L.; Miller, Timothy A.; Savova, Guergana K.; Mak, Raymond H.; Bitterman, Danielle S.","; Aerts, Hugo/ABF-2821-2020","Bitterman, Danielle/0000-0003-0345-2232; Mak, Raymond/0000-0002-8754-0565; Warner, Jeremy/0000-0002-2851-7242; Chen, Shan/0000-0001-7999-7410; Aerts, Hugo/0000-0002-2122-2003",Natural Language Processing to Automatically Extract the Presence and Severity of Esophagitis in Notes of Patients Undergoing Radiotherapy,7,,10.1200/CCI.23.00048 ,Article ,,"PURPOSE Radiotherapy (RT) toxicities can impair survival and quality of life, yet remain understudied. Real-world evidence holds potential to improve our understanding of toxicities, but toxicity information is often only in clinical notes. We developed natural language processing (NLP) models to identify the presence and severity of esophagitis from notes of patients treated with thoracic RT.METHODS Our corpus consisted of a gold-labeled data set of 1,524 clinical notes from 124 patients with lung cancer treated with RT, manually annotated for Common Terminology Criteria for Adverse Events (CTCAE) v5.0 esophagitis grade, and a silver-labeled data set of 2,420 notes from 1,832 patients from whom toxicity grades had been collected as structured data during clinical care. We fine-tuned statistical and pretrained Bidirectional Encoder Representations from Transformers-based models for three esophagitis classification tasks: task 1, no esophagitis versus grade 1-3; task 2, grade <= 1 versus >1; and task 3, no esophagitis versus grade 1 versus grade 2-3. Transferability was tested on 345 notes from patients with esophageal cancer undergoing RT.RESULTS Fine-tuning of PubMedBERT yielded the best performance. The best macro-F1 was 0.92, 0.82, and 0.74 for tasks 1, 2, and 3, respectively. Selecting the most informative note sections during fine-tuning improved macro-F1 by >= 2% for all tasks. Silver-labeled data improved the macro-F1 by >= 3% across all tasks. For the esophageal cancer notes, the best macro-F1 was 0.73, 0.74, and 0.65 for tasks 1, 2, and 3, respectively, without additional fine-tuning.CONCLUSION To our knowledge, this is the first effort to automatically extract esophagitis toxicity severity according to CTCAE guidelines from clinical notes. This provides proof of concept for NLP-based automated detailed toxicity monitoring in expanded domains.",2473-4276,,,, ,  ,,out_of_scope,
2589,"**Title**Sliding-attention transformer neural architecture for predicting T cell receptor-antigen-human leucocyte antigen binding

**Abstract**Neoantigens are promising targets for immunotherapy by eliciting immune response and removing cancer cells with high specificity, low toxicity and ease of personalization. However, identifying effective neoantigens remains difficult because of the complex interactions among T cell receptors, antigens and human leucocyte antigen sequences. In this study, we integrate important physical and biological priors with the Transformer model and propose the physics-inspired sliding transformer (PISTE). In PISTE, the conventional, data-driven attention mechanism is replaced with physics-driven dynamics that steers the positioning of amino acid residues along the gradient field of their interactions. This allows navigating the intricate landscape of biosequence interactions intelligently, leading to improved accuracy in T cell receptor-antigen-human leucocyte antigen binding prediction and robust generalization to rare sequences. Furthermore, PISTE effectively recovers residue-level contact relationships even in the absence of three-dimensional structure training data. We applied PISTE in a multitude of immunogenic tumour types to pinpoint neoantigens and discern neoantigen-reactive T cells. In a prospective study of prostate cancer, 75% of the patients elicited immune responses through PISTE-predicted neoantigens.Predicting TCR-antigen-human leucocyte antigen binding opens the door to neoantigen identification. In this study, a physics-inspired sliding transformer (PISTE) system is used to guide the positioning of amino acid residues along the gradient field of their interactions, boosting binding prediction accuracy.","Feng, Ziyan; Chen, Jingyang; Hai, Youlong; Pang, Xuelian; Zheng, Kun; Xie, Chenglong; Zhang, Xiujuan; Li, Shengqing; Zhang, Chengjuan; Liu, Kangdong; Zhu, Lili; Hu, Xiaoyong; Li, Shiliang; Zhang, Jie; Zhang, Kai; Li, Honglin","li, shiliang/K-9864-2018; Li, Honglin/F-2606-2010; Zheng, Kun/AAV-5015-2021; Zhang, Xiujuan/B-7763-2018","Liu, Kangdong/0000-0002-4425-5625",Sliding-attention transformer neural architecture for predicting T cell receptor-antigen-human leucocyte antigen binding,6,10,10.1038/s42256-024-00901-y ,Article ,,"Neoantigens are promising targets for immunotherapy by eliciting immune response and removing cancer cells with high specificity, low toxicity and ease of personalization. However, identifying effective neoantigens remains difficult because of the complex interactions among T cell receptors, antigens and human leucocyte antigen sequences. In this study, we integrate important physical and biological priors with the Transformer model and propose the physics-inspired sliding transformer (PISTE). In PISTE, the conventional, data-driven attention mechanism is replaced with physics-driven dynamics that steers the positioning of amino acid residues along the gradient field of their interactions. This allows navigating the intricate landscape of biosequence interactions intelligently, leading to improved accuracy in T cell receptor-antigen-human leucocyte antigen binding prediction and robust generalization to rare sequences. Furthermore, PISTE effectively recovers residue-level contact relationships even in the absence of three-dimensional structure training data. We applied PISTE in a multitude of immunogenic tumour types to pinpoint neoantigens and discern neoantigen-reactive T cells. In a prospective study of prostate cancer, 75% of the patients elicited immune responses through PISTE-predicted neoantigens.Predicting TCR-antigen-human leucocyte antigen binding opens the door to neoantigen identification. In this study, a physics-inspired sliding transformer (PISTE) system is used to guide the positioning of amino acid residues along the gradient field of their interactions, boosting binding prediction accuracy.",,2522-5839,,, ,  ,,out_of_scope,
2590,"**Title**Hippocampus substructure segmentation using morphological vision transformer learning

**Abstract**The hippocampus plays a crucial role in memory and cognition. Because of the associated toxicity from whole brain radiotherapy, more advanced treatment planning techniques prioritize hippocampal avoidance, which depends on an accurate segmentation of the small and complexly shaped hippocampus. To achieve accurate segmentation of the anterior and posterior regions of the hippocampus from T1 weighted (T1w) MR images, we developed a novel model, Hippo-Net, which uses a cascaded model strategy. The proposed model consists of two major parts: (1) a localization model is used to detect the volume-of-interest (VOI) of hippocampus. (2) An end-to-end morphological vision transformer network (Franchi et al 2020 Pattern Recognit. 102 107246, Ranem et al 2022 IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW) pp 3710-3719) is used to perform substructures segmentation within the hippocampus VOI. The substructures include the anterior and posterior regions of the hippocampus, which are defined as the hippocampus proper and parts of the subiculum. The vision transformer incorporates the dominant features extracted from MR images, which are further improved by learning-based morphological operators. The integration of these morphological operators into the vision transformer increases the accuracy and ability to separate hippocampus structure into its two distinct substructures. A total of 260 T1w MRI datasets from medical segmentation decathlon dataset were used in this study. We conducted a five-fold cross-validation on the first 200 T1w MR images and then performed a hold-out test on the remaining 60 T1w MR images with the model trained on the first 200 images. In five-fold cross-validation, the Dice similarity coefficients were 0.900 +/- 0.029 and 0.886 +/- 0.031 for the hippocampus proper and parts of the subiculum, respectively. The mean surface distances (MSDs) were 0.426 +/- 0.115 mm and 0.401 +/- 0.100 mm for the hippocampus proper and parts of the subiculum, respectively. The proposed method showed great promise in automatically delineating hippocampus substructures on T1w MR images. It may facilitate the current clinical workflow and reduce the physicians' effort.","Lei, Yang; Ding, Yifu; Qiu, Richard L. J.; Wang, Tonghe; Roper, Justin; Fu, Yabo; Shu, Hui-Kuo; Mao, Hui; Yang, Xiaofeng","Wang, Tonghe/AAL-9431-2020; Qiu, Lei/D-2150-2014","Qiu, Lei/0000-0002-7877-1900",Hippocampus substructure segmentation using morphological vision transformer learning,68,23,10.1088/1361-6560/ad0d45 ,Article ,,"The hippocampus plays a crucial role in memory and cognition. Because of the associated toxicity from whole brain radiotherapy, more advanced treatment planning techniques prioritize hippocampal avoidance, which depends on an accurate segmentation of the small and complexly shaped hippocampus. To achieve accurate segmentation of the anterior and posterior regions of the hippocampus from T1 weighted (T1w) MR images, we developed a novel model, Hippo-Net, which uses a cascaded model strategy. The proposed model consists of two major parts: (1) a localization model is used to detect the volume-of-interest (VOI) of hippocampus. (2) An end-to-end morphological vision transformer network (Franchi et al 2020 Pattern Recognit. 102 107246, Ranem et al 2022 IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW) pp 3710-3719) is used to perform substructures segmentation within the hippocampus VOI. The substructures include the anterior and posterior regions of the hippocampus, which are defined as the hippocampus proper and parts of the subiculum. The vision transformer incorporates the dominant features extracted from MR images, which are further improved by learning-based morphological operators. The integration of these morphological operators into the vision transformer increases the accuracy and ability to separate hippocampus structure into its two distinct substructures. A total of 260 T1w MRI datasets from medical segmentation decathlon dataset were used in this study. We conducted a five-fold cross-validation on the first 200 T1w MR images and then performed a hold-out test on the remaining 60 T1w MR images with the model trained on the first 200 images. In five-fold cross-validation, the Dice similarity coefficients were 0.900 +/- 0.029 and 0.886 +/- 0.031 for the hippocampus proper and parts of the subiculum, respectively. The mean surface distances (MSDs) were 0.426 +/- 0.115 mm and 0.401 +/- 0.100 mm for the hippocampus proper and parts of the subiculum, respectively. The proposed method showed great promise in automatically delineating hippocampus substructures on T1w MR images. It may facilitate the current clinical workflow and reduce the physicians' effort.",0031-9155,1361-6560,,, ,  ,,out_of_scope,
2591,"**Title**Abusive Speech Detection and Politeness Transfer

**Abstract**In the recent times of lockdown, the usage of all kinds of online platforms like Twitter, Facebook, YouTube and Reddit have increased by quite an extent. In addition to using these platforms for creating and sharing positive and inspiring content, a lot of hate and anger comments also seem to be prevalent in them. These problems are tackled by first detecting these forms of hate speech in textual data, then imparting politeness to the hateful comments while preserving the meaning conveyed. For the first phase of abusive speech detection, Baseline models like Logistic Regression, Naive Bayes, SVM, Random Forest and Decision Tree were trained and analyzed. Next, state-of-the-art models like LSTMs, Bi-LSTMs and Transformers were trained for classification of text. Word vectorization models like BOW and TF-IDF and also GloVe embeddings were used and evaluated on the models. It was found that Logistic Regression (with BOW), SVM (with TFIDF) and LSTMs were better performing than others in their categories. A hybrid model of the best performing classifiers was finally used. The next phase of politeness transfer to the abusive text was explored using BERT's language model and its bidirectional property of understanding context to reduce the average toxicity of input sentences.","Preetham, K.; Arumugham, D. Arun; Kumar, M. Yogesh; Begum, B. Shameedha","Begum, B.Shameedha/AAY-1640-2021",,Abusive Speech Detection and Politeness Transfer,13102,,10.1007/978-3-031-12700-7_9 ,Proceedings Paper ,,"In the recent times of lockdown, the usage of all kinds of online platforms like Twitter, Facebook, YouTube and Reddit have increased by quite an extent. In addition to using these platforms for creating and sharing positive and inspiring content, a lot of hate and anger comments also seem to be prevalent in them. These problems are tackled by first detecting these forms of hate speech in textual data, then imparting politeness to the hateful comments while preserving the meaning conveyed. For the first phase of abusive speech detection, Baseline models like Logistic Regression, Naive Bayes, SVM, Random Forest and Decision Tree were trained and analyzed. Next, state-of-the-art models like LSTMs, Bi-LSTMs and Transformers were trained for classification of text. Word vectorization models like BOW and TF-IDF and also GloVe embeddings were used and evaluated on the models. It was found that Logistic Regression (with BOW), SVM (with TFIDF) and LSTMs were better performing than others in their categories. A hybrid model of the best performing classifiers was finally used. The next phase of politeness transfer to the abusive text was explored using BERT's language model and its bidirectional property of understanding context to reduce the average toxicity of input sentences.",0302-9743,1611-3349,978-3-031-12699-4; 978-3-031-12700-7,81-90, , 9th International Conference on Pattern Recognition and Machine Intelligence (PReMI)9th International Conference on Pattern Recognition and Machine Intelligence (PReMI) ,,detox,
2592,"**Title**Self-Supervised Video-Centralised Transformer for Video Face Clustering

**Abstract**This article presents a novel method for face clustering in videos using a video-centralised transformer. Previous works often employed contrastive learning to learn frame-level representation and used average pooling to aggregate the features along the temporal dimension. This approach may not fully capture the complicated video dynamics. In addition, despite the recent progress in video-based contrastive learning, few have attempted to learn a self-supervised clustering-friendly face representation that benefits the video face clustering task. To overcome these limitations, our method employs a transformer to directly learn video-level representations that can better reflect the temporally-varying property of faces in videos, while we also propose a video-centralised self-supervised framework to train the transformer model. We also investigate face clustering in egocentric videos, a fast-emerging field that has not been studied yet in works related to face clustering. To this end, we present and release the first large-scale egocentric video face clustering dataset named EasyCom-Clustering. We evaluate our proposed method on both the widely used Big Bang Theory (BBT) dataset and the new EasyCom-Clustering dataset. Results show the performance of our video-centralised transformer has surpassed all previous state-of-the-art methods on both benchmarks, exhibiting a self-attentive understanding of face videos.","Wang, Yujiang; Dong, Mingzhi; Shen, Jie; Luo, Yiming; Lin, Yiming; Ma, Pingchuan; Petridis, Stavros; Pantic, Maja","Ma, Pingchuan/AFR-0634-2022; Wang, Yujiang/HTR-5911-2023","Luo, Yiming/0000-0003-3096-4583; DONG, MINGZHI/0000-0002-8897-5931; Lin, Yiming/0000-0001-6249-9909",Self-Supervised Video-Centralised Transformer for Video Face Clustering,45,11,10.1109/TPAMI.2023.3243812 ,Article ,,"This article presents a novel method for face clustering in videos using a video-centralised transformer. Previous works often employed contrastive learning to learn frame-level representation and used average pooling to aggregate the features along the temporal dimension. This approach may not fully capture the complicated video dynamics. In addition, despite the recent progress in video-based contrastive learning, few have attempted to learn a self-supervised clustering-friendly face representation that benefits the video face clustering task. To overcome these limitations, our method employs a transformer to directly learn video-level representations that can better reflect the temporally-varying property of faces in videos, while we also propose a video-centralised self-supervised framework to train the transformer model. We also investigate face clustering in egocentric videos, a fast-emerging field that has not been studied yet in works related to face clustering. To this end, we present and release the first large-scale egocentric video face clustering dataset named EasyCom-Clustering. We evaluate our proposed method on both the widely used Big Bang Theory (BBT) dataset and the new EasyCom-Clustering dataset. Results show the performance of our video-centralised transformer has surpassed all previous state-of-the-art methods on both benchmarks, exhibiting a self-attentive understanding of face videos.",0162-8828,1939-3539,,12944-12959, ,  ,,out_of_scope,
2593,No abstract available,"Choi, C.; Jiang, J.; Thor, M.; Rimner, A.; Deasy, J. O.; Kim, J. S.; Veeraraghavan, H.",,,Predicting Thoracic Toxicity with Large Vision Foundation Model Using Pretreatment Data,120,2, ,Meeting Abstract ,,,0360-3016,1879-355X,,E13-E13, , 66th International Conference on American-Society-for-Radiation-Oncology (ASTRO)66th International Conference on American-Society-for-Radiation-Oncology (ASTRO) ,,out_of_scope,
2594,"**Title**HemoFuse: multi-feature fusion based on multi-head cross-attention for identification of hemolytic peptides

**Abstract**Hemolytic peptides are therapeutic peptides that damage red blood cells. However, therapeutic peptides used in medical treatment must exhibit low toxicity to red blood cells to achieve the desired therapeutic effect. Therefore, accurate prediction of the hemolytic activity of therapeutic peptides is essential for the development of peptide therapies. In this study, a multi-feature cross-fusion model, HemoFuse, for hemolytic peptide identification is proposed. The feature vectors of peptide sequences are transformed by word embedding technique and four hand-crafted feature extraction methods. We apply multi-head cross-attention mechanism to hemolytic peptide identification for the first time. It captures the interaction between word embedding features and hand-crafted features by calculating the attention of all positions in them, so that multiple features can be deeply fused. Moreover, we visualize the features obtained by this module to enhance its interpretability. On the comprehensive integrated dataset, HemoFuse achieves ideal results, with ACC, SP, SN, MCC, F1, AUC, and AP of 0.7575, 0.8814, 0.5793, 0.4909, 0.6620, 0.8387, and 0.7118, respectively. Compared with HemoDL proposed by Yang et al., it is 3.32%, 3.89%, 5.93%, 10.6%, 8.17%, 5.88%, and 2.72% higher. Other ablation experiments also prove that our model is reasonable and efficient. The codes and datasets are accessible at https://github.com/z11code/Hemo.","Zhao, Ya; Zhang, Shengli; Liang, Yunyun","Zhang, Shengli/J-7340-2013",,HemoFuse: multi-feature fusion based on multi-head cross-attention for identification of hemolytic peptides,14,1,10.1038/s41598-024-74326-3 ,Article ,,"Hemolytic peptides are therapeutic peptides that damage red blood cells. However, therapeutic peptides used in medical treatment must exhibit low toxicity to red blood cells to achieve the desired therapeutic effect. Therefore, accurate prediction of the hemolytic activity of therapeutic peptides is essential for the development of peptide therapies. In this study, a multi-feature cross-fusion model, HemoFuse, for hemolytic peptide identification is proposed. The feature vectors of peptide sequences are transformed by word embedding technique and four hand-crafted feature extraction methods. We apply multi-head cross-attention mechanism to hemolytic peptide identification for the first time. It captures the interaction between word embedding features and hand-crafted features by calculating the attention of all positions in them, so that multiple features can be deeply fused. Moreover, we visualize the features obtained by this module to enhance its interpretability. On the comprehensive integrated dataset, HemoFuse achieves ideal results, with ACC, SP, SN, MCC, F1, AUC, and AP of 0.7575, 0.8814, 0.5793, 0.4909, 0.6620, 0.8387, and 0.7118, respectively. Compared with HemoDL proposed by Yang et al., it is 3.32%, 3.89%, 5.93%, 10.6%, 8.17%, 5.88%, and 2.72% higher. Other ablation experiments also prove that our model is reasonable and efficient. The codes and datasets are accessible at https://github.com/z11code/Hemo.",2045-2322,,,, ,  ,,out_of_scope,
2595,"**Title**Transformer-based spatial-temporal detection of apoptotic cell death in live-cell imaging

**Abstract**Intravital microscopy has revolutionized live-cell imaging by allowing the study of spatial-temporal cell dynamics in living animals. However, the complexity of the data generated by this technology has limited the development of effective computational tools to identify and quantify cell processes. Amongst them, apoptosis is a crucial form of regulated cell death involved in tissue homeostasis and host defense. Live-cell imaging enabled the study of apoptosis at the cellular level, enhancing our understanding of its spatial-temporal regulation. However, at present, no computational method can deliver robust detection of apoptosis in microscopy timelapses. To overcome this limitation, we developed ADeS, a deep learning-based apoptosis detection system that employs the principle of activity recognition. We trained ADeS on extensive datasets containing more than 10,000 apoptotic instances collected both in vitro and in vivo, achieving a classification accuracy above 98% and outperforming state-of-the-art solutions. ADeS is the first method capable of detecting the location and duration of multiple apoptotic events in full microscopy timelapses, surpassing human performance in the same task. We demonstrated the effectiveness and robustness of ADeS across various imaging modalities, cell types, and staining techniques. Finally, we employed ADeS to quantify cell survival in vitro and tissue damage in mice, demonstrating its potential application in toxicity assays, treatment evaluation, and inflammatory dynamics. Our findings suggest that ADeS is a valuable tool for the accurate detection and quantification of apoptosis in live-cell imaging and, in particular, intravital microscopy data, providing insights into the complex spatial-temporal regulation of this process.","Pulfer, Alain; Pizzagalli, Diego Ulisse; Gagliardi, Paolo Armando; Hinderling, Lucien; Lopez, Paul; Zayats, Romaniya; Carrillo-Barbera, Pau; Antonello, Paola; Palomino-Segura, Miguel; Graedel, Benjamin; Nicolai, Mariaclaudia; Giusti, Alessandro; Thelen, Marcus; Gambardella, Luca Maria; Murooka, Thomas T.; Pertz, Olivier; Krause, Rolf; Gonzalez, Santiago Fernandez","Carrillo-Barberà, Pau/AAV-4763-2021; Pizzagalli, Diego Ulisse/JCE-1384-2023; Gagliardi, Paolo Armando/D-1836-2018","Murooka, Thomas/0000-0002-3030-2726; Pulfer, Alain/0009-0004-3780-1642; Gagliardi, Paolo Armando/0000-0002-4818-035X; Gradel, Benjamin/0000-0002-1995-0263; Hinderling, Lucien/0000-0002-3956-9363",Transformer-based spatial-temporal detection of apoptotic cell death in live-cell imaging,12,,10.7554/eLife.90502 ,Article ,,"Intravital microscopy has revolutionized live-cell imaging by allowing the study of spatial-temporal cell dynamics in living animals. However, the complexity of the data generated by this technology has limited the development of effective computational tools to identify and quantify cell processes. Amongst them, apoptosis is a crucial form of regulated cell death involved in tissue homeostasis and host defense. Live-cell imaging enabled the study of apoptosis at the cellular level, enhancing our understanding of its spatial-temporal regulation. However, at present, no computational method can deliver robust detection of apoptosis in microscopy timelapses. To overcome this limitation, we developed ADeS, a deep learning-based apoptosis detection system that employs the principle of activity recognition. We trained ADeS on extensive datasets containing more than 10,000 apoptotic instances collected both in vitro and in vivo, achieving a classification accuracy above 98% and outperforming state-of-the-art solutions. ADeS is the first method capable of detecting the location and duration of multiple apoptotic events in full microscopy timelapses, surpassing human performance in the same task. We demonstrated the effectiveness and robustness of ADeS across various imaging modalities, cell types, and staining techniques. Finally, we employed ADeS to quantify cell survival in vitro and tissue damage in mice, demonstrating its potential application in toxicity assays, treatment evaluation, and inflammatory dynamics. Our findings suggest that ADeS is a valuable tool for the accurate detection and quantification of apoptosis in live-cell imaging and, in particular, intravital microscopy data, providing insights into the complex spatial-temporal regulation of this process.",2050-084X,,,, ,  ,,out_of_scope,
2596,"**Title**Integrated method for grading diagnosis of dental fluorosis combined with segmentation and classification

**Abstract**Endemic fluorosis is chronic fluorosis caused by excessive accumulation of fluorine in the body. The early symptom of fluoride toxicity is dental fluorosis. In severe cases of poisoning, it can lead to skeletal fluorosis. Screening for fluorosis is conducted almost yearly in remote fluorosis areas, but the lack of medical resources often leads to misdiagnosis or missed diagnosis. Therefore, applying deep learning technology to diagnose dental fluorosis is significant. Through field research and literature review, we discovered that the current screening for dental fluorosis relies entirely on doctors' knowledge and experience without applying deep learning in relevant studies on automated diagnosis. Based on the analysis of images, we noted that the lesions display irregular shapes and indistinct borders. Additionally, the appearance of lesions can be influenced by various factors, such as extrinsic staining and illuminance. They present challenges in diagnosing dental fluorosis. So, we proposed a two -stage methodology for grading the diagnosis of dental fluorosis. In the first stage, we proposed an improved U -Net based on large kernel convolution for tooth region segmentation. Additionally, we designed a pixel -association iterative algorithm to optimize the segmentation results. In the second stage, we devised a dual -branch fusion classifier based on CNN and Transformer, which ensured accurate classification even when the lesion features occupy only a tiny proportion of the entire image. We established the first dental fluorosis dataset and evaluated our proposed method, which has achieved satisfactory results in the grading diagnosis of dental fluorosis after conducting many experiments. The dataset of dental fluorosis will be published on: https://github.com/yunwu2024/dental_fluorosis.","Gu, Maohua; Wu, Yun; Jiang, Zhongchuan; Xu, Hao",,"Wu, Yun/0000-0001-6782-5777; Xu, Hao/0009-0001-5164-8566",Integrated method for grading diagnosis of dental fluorosis combined with segmentation and classification,96,,10.1016/j.bspc.2024.106510 ,Article ,,"Endemic fluorosis is chronic fluorosis caused by excessive accumulation of fluorine in the body. The early symptom of fluoride toxicity is dental fluorosis. In severe cases of poisoning, it can lead to skeletal fluorosis. Screening for fluorosis is conducted almost yearly in remote fluorosis areas, but the lack of medical resources often leads to misdiagnosis or missed diagnosis. Therefore, applying deep learning technology to diagnose dental fluorosis is significant. Through field research and literature review, we discovered that the current screening for dental fluorosis relies entirely on doctors' knowledge and experience without applying deep learning in relevant studies on automated diagnosis. Based on the analysis of images, we noted that the lesions display irregular shapes and indistinct borders. Additionally, the appearance of lesions can be influenced by various factors, such as extrinsic staining and illuminance. They present challenges in diagnosing dental fluorosis. So, we proposed a two -stage methodology for grading the diagnosis of dental fluorosis. In the first stage, we proposed an improved U -Net based on large kernel convolution for tooth region segmentation. Additionally, we designed a pixel -association iterative algorithm to optimize the segmentation results. In the second stage, we devised a dual -branch fusion classifier based on CNN and Transformer, which ensured accurate classification even when the lesion features occupy only a tiny proportion of the entire image. We established the first dental fluorosis dataset and evaluated our proposed method, which has achieved satisfactory results in the grading diagnosis of dental fluorosis after conducting many experiments. The dataset of dental fluorosis will be published on: https://github.com/yunwu2024/dental_fluorosis.",1746-8094,1746-8108,,, ,  ,,out_of_scope,
2597,"**Title**Attribute Alignment: Controlling Text Generation from Pre-trained Language Models

**Abstract**Large language models benefit from training with a large amount of unlabeled text, which gives them increasingly fluent and diverse generation capabilities. However, using these models for text generation that takes into account target attributes, such as sentiment polarity or specific topics, remains a challenge. We propose a simple and flexible method for controlling text generation by aligning disentangled attribute representations. In contrast to recent efforts on training a discriminator to perturb the token level distribution for an attribute, we use the same data to learn an alignment function to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters. We evaluate our method on sentiment- and topiccontrolled generation, and show large performance gains over previous methods while retaining fluency and diversity.","Yu, Dian; Yu, Zhou; Sagae, Kenji",,,Attribute Alignment: Controlling Text Generation from Pre-trained Language Models,,, ,Proceedings Paper ,,"Large language models benefit from training with a large amount of unlabeled text, which gives them increasingly fluent and diverse generation capabilities. However, using these models for text generation that takes into account target attributes, such as sentiment polarity or specific topics, remains a challenge. We propose a simple and flexible method for controlling text generation by aligning disentangled attribute representations. In contrast to recent efforts on training a discriminator to perturb the token level distribution for an attribute, we use the same data to learn an alignment function to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters. We evaluate our method on sentiment- and topiccontrolled generation, and show large performance gains over previous methods while retaining fluency and diversity.",,,978-1-955917-10-0,2251-2268, , Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP) ,,out_of_scope,
2598,"**Title**SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control

**Abstract**Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models. In this work, we present SSD-LM-a diffusion-based language model with two key design choices. First, SSD-LM is semi-autoregressive, iteratively generating blocks of text, allowing for flexible output length at decoding time while enabling local bidirectional context updates. Second, it is simplex-based, performing diffusion on the natural vocabulary space rather than a learned latent space, allowing us to incorporate classifier guidance and modular control using off-the-shelf classifiers without any adaptation. We evaluate SSD- LM on unconstrained text generation benchmarks, and show that it matches or outperforms strong autoregressive GPT-2 models across standard quality and diversity metrics, while vastly outperforming diffusionbased baselines. On controlled text generation, SSD- LM also outperforms competitive baselines, with an extra advantage in modularity.(1)","Han, Xiaochuang; Kumar, Sachin; Tsvetkov, Yulia","Kumar, Sachin/AAP-7158-2021",,SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,,, ,Proceedings Paper ,,"Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models. In this work, we present SSD-LM-a diffusion-based language model with two key design choices. First, SSD-LM is semi-autoregressive, iteratively generating blocks of text, allowing for flexible output length at decoding time while enabling local bidirectional context updates. Second, it is simplex-based, performing diffusion on the natural vocabulary space rather than a learned latent space, allowing us to incorporate classifier guidance and modular control using off-the-shelf classifiers without any adaptation. We evaluate SSD- LM on unconstrained text generation benchmarks, and show that it matches or outperforms strong autoregressive GPT-2 models across standard quality and diversity metrics, while vastly outperforming diffusionbased baselines. On controlled text generation, SSD- LM also outperforms competitive baselines, with an extra advantage in modularity.(1)",,,978-1-959429-72-2,11575-11596, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2599,"**Title**Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method

**Abstract**Controlled text generation (CTG) seeks to guide large language model (LLM) output to produce text that conforms to desired criteria. The current study presents a novel CTG algorithm that enforces adherence toward specific rhetorical relations in an LLM sentence-completion context by a parser-driven decoding scheme that requires no model fine-tuning. The method is validated both with automatic and human evaluation. The code is accessible on GitHub.(1)","Zingale, Joshua; Kalita, Jugal",,,Language Model Sentence Completion with a Parser-Driven Rhetorical Control Method,,, ,Proceedings Paper ,,Controlled text generation (CTG) seeks to guide large language model (LLM) output to produce text that conforms to desired criteria. The current study presents a novel CTG algorithm that enforces adherence toward specific rhetorical relations in an LLM sentence-completion context by a parser-driven decoding scheme that requires no model fine-tuning. The method is validated both with automatic and human evaluation. The code is accessible on GitHub.(1),,,979-8-89176-089-9,193-203, , 18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,out_of_scope,
2600,"**Title**Two-Stage Text Summary Model

**Abstract**In order to solve the problems of redundant information processing and high quality summary generation in existing methods, this paper proposes a two-stage text summary model which is composed of abstracted and generated models. First of all, the important information is abstracted by using an abstracted model which incorporates dilated convolution and gated convolution. Then, a replication mechanism is incorporated into the generated model to ensure that both primary and secondary information are taken into consideration, while also optimizing the cluster search algorithm. Finally, the network structure is reconfigured in the generated model to effectively integrate the coding capabilities of the two-way language model and the text generation abilities of the one-way language model. We conducted experiments on the CNewSum dataset, and achieved Rouge-1, Rouge-2, and Rouge-L values of 44.21, 27.52, and 39.03 for the two-paragraph text summary model respectively. The results indicate a significant enhancement in the performance of the two-paragraph text summary model compared to the benchmark model.","Chen, Yang; Juanatas, Roben A.","Juanatas, Roben/IXN-5727-2023",,Two-Stage Text Summary Model,12,,10.1109/ACCESS.2024.3427390 ,Article ,,"In order to solve the problems of redundant information processing and high quality summary generation in existing methods, this paper proposes a two-stage text summary model which is composed of abstracted and generated models. First of all, the important information is abstracted by using an abstracted model which incorporates dilated convolution and gated convolution. Then, a replication mechanism is incorporated into the generated model to ensure that both primary and secondary information are taken into consideration, while also optimizing the cluster search algorithm. Finally, the network structure is reconfigured in the generated model to effectively integrate the coding capabilities of the two-way language model and the text generation abilities of the one-way language model. We conducted experiments on the CNewSum dataset, and achieved Rouge-1, Rouge-2, and Rouge-L values of 44.21, 27.52, and 39.03 for the two-paragraph text summary model respectively. The results indicate a significant enhancement in the performance of the two-paragraph text summary model compared to the benchmark model.",2169-3536,,,129012-129020, ,  ,,out_of_scope,
2601,"**Title**BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases

**Abstract**Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose BOLT, which relies on tunable biases to directly adjust the language model's output logits. Unlike prior work, BOLT maintains the generator's autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), BOLT demonstrates significantly improved efficiency and fluency. On sentiment control, BOLT is 7x faster than competitive baselines, and more fluent in 74.4% of the evaluation samples according to human judges.","Liu, Xin; Khalifa, Muhammad; Wang, Lu",,,BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases,,, ,Proceedings Paper ,,"Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose BOLT, which relies on tunable biases to directly adjust the language model's output logits. Unlike prior work, BOLT maintains the generator's autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), BOLT demonstrates significantly improved efficiency and fluency. On sentiment control, BOLT is 7x faster than competitive baselines, and more fluent in 74.4% of the evaluation samples according to human judges.",,,978-1-959429-71-5,186-200, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2602,"**Title**CEV-LM: Controlled Edit Vector Language Model for Shaping Natural Language Generations

**Abstract**As large-scale language models become the standard for text generation, there is a greater need to tailor the generations to be more or less concise, targeted, and informative, depending on the audience/application. Existing control approaches primarily adjust the semantic (e.g., emotion, topics), structural (e.g., syntax tree, parts-of-speech), and lexical (e.g., keyword/phrase inclusion) properties of text, but are insufficient to accomplish complex objectives such as pacing which control the complexity and readability of the text. In this paper, we introduce CEV-LM - a lightweight, semi-autoregressive language model that utilizes constrained edit vectors to control three complementary metrics (speed, volume, and circuitousness) that quantify the shape of text (e.g., pacing of content). We study an extensive set of state-of-the-art CTG models and find that CEV-LM provides significantly more targeted and precise control of these three metrics while preserving semantic content, using less training data, and containing fewer parameters.(1)","Moorjani, Samraj; Krishnan, Adit; Sundaram, Hari",,,CEV-LM: Controlled Edit Vector Language Model for Shaping Natural Language Generations,,, ,Proceedings Paper ,,"As large-scale language models become the standard for text generation, there is a greater need to tailor the generations to be more or less concise, targeted, and informative, depending on the audience/application. Existing control approaches primarily adjust the semantic (e.g., emotion, topics), structural (e.g., syntax tree, parts-of-speech), and lexical (e.g., keyword/phrase inclusion) properties of text, but are insufficient to accomplish complex objectives such as pacing which control the complexity and readability of the text. In this paper, we introduce CEV-LM - a lightweight, semi-autoregressive language model that utilizes constrained edit vectors to control three complementary metrics (speed, volume, and circuitousness) that quantify the shape of text (e.g., pacing of content). We study an extensive set of state-of-the-art CTG models and find that CEV-LM provides significantly more targeted and precise control of these three metrics while preserving semantic content, using less training data, and containing fewer parameters.(1)",,,979-8-89176-088-2,1325-1340, , 18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,out_of_scope,
2603,"**Title**Tailor: A Soft-Prompt-Based Approach to Attribute-Based Controlled Text Generation

**Abstract**Attribute-based Controlled Text Generation (CTG) refers to generating sentences that satisfy desirable attributes (e.g., emotions and topics). Existing work usually utilize fine-tuning or resort to extra attribute classifiers, yet suffer from increases in storage and inference time. To address these concerns, we explore attribute-based CTG in a parameter-efficient manner. In short, the proposed Tailor represents each attribute as a pre-trained continuous vector (i.e., single-attribute prompt), which guides the generation of a fixed pre-trained language model (PLM) to satisfy a pre-specified attribute. These prompts can be simply concatenated as a whole for multi-attribute CTG without any re-training. Nevertheless, this may raise problems of fluency downgrading and position sensitivity. To solve this, Tailor provides two solutions to enhance the combination. The former contains a multi-attribute prompt mask and a re-indexing position sequence to bridge the gap between the training (one singleattribute prompt for each task) and the testing stage (concatenating two prompts). The latter introduces a trainable prompt connector to further enhance the combinations. Experiments demonstrate that, only requiring 0.08% extra training parameters of the GPT-2, Tailor can achieve effective and general improvements on eleven attribute-specific generation tasks.","Yang, Kexin; Liu, Dayiheng; Lei, Wenqiang; Yang, Baosong; Xue, Mingfeng; Chen, Boxing; Xie, Jun",,,Tailor: A Soft-Prompt-Based Approach to Attribute-Based Controlled Text Generation,,, ,Proceedings Paper ,,"Attribute-based Controlled Text Generation (CTG) refers to generating sentences that satisfy desirable attributes (e.g., emotions and topics). Existing work usually utilize fine-tuning or resort to extra attribute classifiers, yet suffer from increases in storage and inference time. To address these concerns, we explore attribute-based CTG in a parameter-efficient manner. In short, the proposed Tailor represents each attribute as a pre-trained continuous vector (i.e., single-attribute prompt), which guides the generation of a fixed pre-trained language model (PLM) to satisfy a pre-specified attribute. These prompts can be simply concatenated as a whole for multi-attribute CTG without any re-training. Nevertheless, this may raise problems of fluency downgrading and position sensitivity. To solve this, Tailor provides two solutions to enhance the combination. The former contains a multi-attribute prompt mask and a re-indexing position sequence to bridge the gap between the training (one singleattribute prompt for each task) and the testing stage (concatenating two prompts). The latter introduces a trainable prompt connector to further enhance the combinations. Experiments demonstrate that, only requiring 0.08% extra training parameters of the GPT-2, Tailor can achieve effective and general improvements on eleven attribute-specific generation tasks.",,,978-1-959429-72-2,410-427, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2604,"**Title**A Retrieval-Augmented Generation Strategy to Enhance Medical Chatbot Reliability

**Abstract**The advent of Large Language Models opened new perspectives concerning their usage within the digital health domain. However, their intrinsic probabilistic and unpredictable behavior needs the design of trustworthy strategies aiming to avoid the creation of hallucinations that, especially within the digital health domain, may lead to severe harm. Such an issue has been addressed with the adoption of Retrieval-Augmented Generation solutions, where the text generation task is supported by controlled knowledge injected into the prompts. Even if the hallucination issue is mitigated, the generation of certified information (such as trustworthy content granted by the system's owner) requires more sophisticated strategies. In this work, we propose an approach where the classic Retrieval-Augmented Generation pipeline is enhanced with a further initial step where the Large Language Model is asked to generate a preliminary text used to query the repository of certified information for presenting the appropriate content to the final user.","Haez, Saba Ghanbari; Segala, Marina; Bellan, Patrizio; Magnolini, Simone; Sanna, Leonardo; Consolandi, Monica; Dragoni, Mauro","Haez, Saba/AHE-9398-2022","Consolandi, Monica/0000-0002-1516-1953; Sanna, Leonardo/0000-0003-3021-6606",A Retrieval-Augmented Generation Strategy to Enhance Medical Chatbot Reliability,14844,,10.1007/978-3-031-66538-7_22 ,Proceedings Paper ,,"The advent of Large Language Models opened new perspectives concerning their usage within the digital health domain. However, their intrinsic probabilistic and unpredictable behavior needs the design of trustworthy strategies aiming to avoid the creation of hallucinations that, especially within the digital health domain, may lead to severe harm. Such an issue has been addressed with the adoption of Retrieval-Augmented Generation solutions, where the text generation task is supported by controlled knowledge injected into the prompts. Even if the hallucination issue is mitigated, the generation of certified information (such as trustworthy content granted by the system's owner) requires more sophisticated strategies. In this work, we propose an approach where the classic Retrieval-Augmented Generation pipeline is enhanced with a further initial step where the Large Language Model is asked to generate a preliminary text used to query the repository of certified information for presenting the appropriate content to the final user.",2945-9133,1611-3349,978-3-031-66537-0; 978-3-031-66538-7,213-223, , 22nd International Conference on Artificial Intelligence in Medicine (AIME)22nd International Conference on Artificial Intelligence in Medicine (AIME) ,,out_of_scope,
2605,"**Title**Automatic Controllable Product Copywriting for E-Commerce

**Abstract**Automatic product description generation for e-commerce has witnessed significant advancement in the past decade. Product copywriting aims to attract users' interest and improve user experience by highlighting product characteristics with textual descriptions. As the services provided by e-commerce platforms become diverse, it is necessary to adapt the patterns of automatically-generated descriptions dynamically. In this paper, we report our experience in deploying an E-commerce Prefix-based Controllable Copywriting Generation (EPCCG) system into the JD.com e-commerce product recommendation platform. The development of the system contains two main components: 1) copywriting aspect extraction; 2) weakly supervised aspect labelling; 3) text generation with a prefix-based language model; and 4) copywriting quality control. We conduct experiments to validate the effectiveness of the proposed EPCCG. In addition, we introduce the deployed architecture which cooperates the EPCCG into the real-time JD.com e-commerce recommendation platform and the significant payoff since deployment. The codes for implementation are provided at https://github.com/xguo7/Automatic-Controllable-Product-Copywriting-for-E-Commerce.git.","Guo, Xiaojie; Zeng, Qingkai; Jiang, Meng; Xiao, Yun; Long, Bo; Wu, Lingfei","Guo, Xiaojie/AAC-3114-2022; Jiang, Meng/AAE-4976-2020; Wu, Lingfei/ABC-1000-2020",,Automatic Controllable Product Copywriting for E-Commerce,,,10.1145/3534678.3539171 ,Proceedings Paper ,,"Automatic product description generation for e-commerce has witnessed significant advancement in the past decade. Product copywriting aims to attract users' interest and improve user experience by highlighting product characteristics with textual descriptions. As the services provided by e-commerce platforms become diverse, it is necessary to adapt the patterns of automatically-generated descriptions dynamically. In this paper, we report our experience in deploying an E-commerce Prefix-based Controllable Copywriting Generation (EPCCG) system into the JD.com e-commerce product recommendation platform. The development of the system contains two main components: 1) copywriting aspect extraction; 2) weakly supervised aspect labelling; 3) text generation with a prefix-based language model; and 4) copywriting quality control. We conduct experiments to validate the effectiveness of the proposed EPCCG. In addition, we introduce the deployed architecture which cooperates the EPCCG into the real-time JD.com e-commerce recommendation platform and the significant payoff since deployment. The codes for implementation are provided at https://github.com/xguo7/Automatic-Controllable-Product-Copywriting-for-E-Commerce.git.",,,978-1-4503-9385-0,2946-2956, , 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KKD)28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KKD) ,,out_of_scope,
2606,"**Title**You Got the Feeling: Attributing Affective States to Dialogical Social Robots

**Abstract**In this paper we report the result of an analysis aiming at investigating, among different virtually embodied social robots (endowed with different degrees of dialogical complexity), the perceived difference in emotion attribution and understanding by the human users interacting with them. In particular, in our case study, the most complex dialogical modality - using a emotional content to vehiculate its messages - has been based entirely on the adoption of a Large Language Model (i.e. chatGPT in our case) whilst the simplest one has been based on a manual simplification of the generated text. We report the obtained results based on the adoption of a number tests and standardized scales and highlight some possibile future directions.","De Marchi, Silvia; Gena, Cristina; Lieto, Antonio","Lieto, Antonio/AAO-8167-2021","GENA, Cristina/0000-0003-0049-6213; Lieto, Antonio/0000-0002-8323-8764",You Got the Feeling: Attributing Affective States to Dialogical Social Robots,14736,,10.1007/978-3-031-60615-1_14 ,Proceedings Paper ,,"In this paper we report the result of an analysis aiming at investigating, among different virtually embodied social robots (endowed with different degrees of dialogical complexity), the perceived difference in emotion attribution and understanding by the human users interacting with them. In particular, in our case study, the most complex dialogical modality - using a emotional content to vehiculate its messages - has been based entirely on the adoption of a Large Language Model (i.e. chatGPT in our case) whilst the simplest one has been based on a manual simplification of the generated text. We report the obtained results based on the adoption of a number tests and standardized scales and highlight some possibile future directions.",2945-9133,1611-3349,978-3-031-60614-4; 978-3-031-60615-1,216-230, , 26th International Conference on Human-Computer Interaction (HCII)26th International Conference on Human-Computer Interaction (HCII) ,,out_of_scope,
2607,"**Title**Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access

**Abstract**Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs). This paper introduces sketch-guided constrained decoding (SketchGCD), a novel approach to constrained decoding for blackbox LLMs, which operates without access to the logits of the blackbox LLM. SketchGCD utilizes a locally hosted auxiliary model to refine the output of an unconstrained blackbox LLM, effectively treating this initial output as a sketch for further elaboration. This approach is complementary to traditional logit-based techniques and enables the application of constrained decoding in settings where full model transparency is unavailable. We demonstrate the efficacy of SketchGCD through experiments in closed information extraction and constituency parsing, showing how it enhances the utility and flexibility of blackbox LLMs for complex NLP tasks.(1)","Geng, Saibo; Doner, Berkay; Wendler, Chris; Josifoski, Martin; West, Robert",,,Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access,,, ,Proceedings Paper ,,"Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs). This paper introduces sketch-guided constrained decoding (SketchGCD), a novel approach to constrained decoding for blackbox LLMs, which operates without access to the logits of the blackbox LLM. SketchGCD utilizes a locally hosted auxiliary model to refine the output of an unconstrained blackbox LLM, effectively treating this initial output as a sketch for further elaboration. This approach is complementary to traditional logit-based techniques and enables the application of constrained decoding in settings where full model transparency is unavailable. We demonstrate the efficacy of SketchGCD through experiments in closed information extraction and constituency parsing, showing how it enhances the utility and flexibility of blackbox LLMs for complex NLP tasks.(1)",,,979-8-89176-095-0,234-245, , 62nd Annual Meeting of the Association-for-Computational-Linguistics (ACL) / Student Research Workshop (SRW)62nd Annual Meeting of the Association-for-Computational-Linguistics (ACL) / Student Research Workshop (SRW) ,,out_of_scope,
2608,"**Title**DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models

**Abstract**We present DiffusionBERT, a new generative masked language model based on discrete diffusion models. Diffusion models and many pretrained language models have a shared training objective, i.e., denoising, making it possible to combine the two powerful models and enjoy the best of both worlds. On the one hand, diffusion models offer a promising training strategy that helps improve the generation quality. On the other hand, pre-trained denoising language models (e.g., BERT) can be used as a good initialization that accelerates convergence. We explore training BERT to learn the reverse process of a discrete diffusion process with an absorbing state and elucidate several designs to improve it. First, we propose a new noise schedule for the forward diffusion process that controls the degree of noise added at each step based on the information of each token. Second, we investigate several designs of incorporating the time step into BERT. Experiments on unconditional text generation demonstrate that DiffusionBERT achieves significant improvement over existing diffusion models for text (e.g., D3PM and Diffusion-LM) and previous generative masked language models in terms of perplexity and BLEU score. Promising results in conditional generation tasks show that DiffusionBERT can generate texts of comparable quality and more diverse than a series of established baselines.","He, Zhengfu; Sun, Tianxiang; Tang, Qiong; Wang, Kuanning; Huang, Xuanjing; Qiu, Xipeng","Sun, Tianxiang/AAA-7123-2022",,DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models,,, ,Proceedings Paper ,,"We present DiffusionBERT, a new generative masked language model based on discrete diffusion models. Diffusion models and many pretrained language models have a shared training objective, i.e., denoising, making it possible to combine the two powerful models and enjoy the best of both worlds. On the one hand, diffusion models offer a promising training strategy that helps improve the generation quality. On the other hand, pre-trained denoising language models (e.g., BERT) can be used as a good initialization that accelerates convergence. We explore training BERT to learn the reverse process of a discrete diffusion process with an absorbing state and elucidate several designs to improve it. First, we propose a new noise schedule for the forward diffusion process that controls the degree of noise added at each step based on the information of each token. Second, we investigate several designs of incorporating the time step into BERT. Experiments on unconditional text generation demonstrate that DiffusionBERT achieves significant improvement over existing diffusion models for text (e.g., D3PM and Diffusion-LM) and previous generative masked language models in terms of perplexity and BLEU score. Promising results in conditional generation tasks show that DiffusionBERT can generate texts of comparable quality and more diverse than a series of established baselines.",,,978-1-959429-72-2,4521-4534, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_of_scope,
2609,"**Title**A new era of AI-assisted journalism at Bloomberg

**Abstract**Artificial intelligence (AI) is impacting and has the potential to upend entire business models and structures. The adoption of such new technologies to support newsgathering processes is established practice for newsrooms. For AI specifically, we are seeing a new era of AI-assisted journalism emerge with trust in the AI-driven analyses and accuracy of results as core tenets.In Part I of this position paper, we discuss the contributions of six recently published research papers co-authored by Bloomberg's Artificial Intelligence Engineering team that show the intricacies of training AI models for reliable newsgathering processes. The papers investigate (a) the creation of models for updated headline generation, showing that headline generation models benefit from access to the past state of the article, (b) sequentially controlled text generation, which is a novel task and we show that in general, more structured awareness results in higher control accuracy and grammatical coherence, (c) chart summarization, which looks into identifying the key message and generating sentences that describe salient information in the multimodal documents, (d) a semistructured natural language inference task to develop a framework for data augmentation for tabular inference, (e) the introduction of a human-annotated dataset (ENTSUM) for controllable summarization with a focus on named entities as the aspect to control, and (f) a novel defense mechanism against adversarial attacks (ATINTER). We also examine Bloomberg's research work, building its own internal, not-for-commercial-use large language model, BloombergGPT, and training it with the goal of demonstrating support for a wide range of tasks within the financial industry.In Part II, we analyze the evolution of automation tasks in the Bloomberg newsroom that led to the creation of Bloomberg's News Innovation Lab. Technology-assisted content creation has been a reality at Bloomberg News for nearly a decade and has evolved from rules-based headline generation from structured files to the constant exploration of potential ways to assist story creation and storytelling in the financial domain. The Lab now oversees the operation of hundreds of software bots that create semi- and fully automated stories of financial relevance, providing journalists with depth in terms of data and analysis, speed in terms of reacting to breaking news, and transparency to corners of the financial world where data investigation is a gigantic undertaking. The Lab recently introduced new tools that provide journalists with the ability to explore automation on demand while it continues to experiment with ways to assist story production.In Part III, we conceptually discuss the transformative impact that generative AI can have in any newsroom, along with considerations about the technology's shortcomings in its current state of development. As with any revolutionary new technology, as well as with exciting research opportunities, part of the challenge is balancing any potential positive and negative impacts on society. We offer our principles and guidelines used to inform our approach to experimenting with the new generative AI technologies. Bloomberg News' style guide reminds us that our journalism is aimed at possibly the most sophisticated audience in the world, for whom accuracy is essential.","Quinonez, Claudia; Meij, Edgar",,"Meij, Edgar/0000-0003-0516-3688",A new era of AI-assisted journalism at Bloomberg,45,2,10.1002/aaai.12181 ,Article ,,"Artificial intelligence (AI) is impacting and has the potential to upend entire business models and structures. The adoption of such new technologies to support newsgathering processes is established practice for newsrooms. For AI specifically, we are seeing a new era of AI-assisted journalism emerge with trust in the AI-driven analyses and accuracy of results as core tenets.In Part I of this position paper, we discuss the contributions of six recently published research papers co-authored by Bloomberg's Artificial Intelligence Engineering team that show the intricacies of training AI models for reliable newsgathering processes. The papers investigate (a) the creation of models for updated headline generation, showing that headline generation models benefit from access to the past state of the article, (b) sequentially controlled text generation, which is a novel task and we show that in general, more structured awareness results in higher control accuracy and grammatical coherence, (c) chart summarization, which looks into identifying the key message and generating sentences that describe salient information in the multimodal documents, (d) a semistructured natural language inference task to develop a framework for data augmentation for tabular inference, (e) the introduction of a human-annotated dataset (ENTSUM) for controllable summarization with a focus on named entities as the aspect to control, and (f) a novel defense mechanism against adversarial attacks (ATINTER). We also examine Bloomberg's research work, building its own internal, not-for-commercial-use large language model, BloombergGPT, and training it with the goal of demonstrating support for a wide range of tasks within the financial industry.In Part II, we analyze the evolution of automation tasks in the Bloomberg newsroom that led to the creation of Bloomberg's News Innovation Lab. Technology-assisted content creation has been a reality at Bloomberg News for nearly a decade and has evolved from rules-based headline generation from structured files to the constant exploration of potential ways to assist story creation and storytelling in the financial domain. The Lab now oversees the operation of hundreds of software bots that create semi- and fully automated stories of financial relevance, providing journalists with depth in terms of data and analysis, speed in terms of reacting to breaking news, and transparency to corners of the financial world where data investigation is a gigantic undertaking. The Lab recently introduced new tools that provide journalists with the ability to explore automation on demand while it continues to experiment with ways to assist story production.In Part III, we conceptually discuss the transformative impact that generative AI can have in any newsroom, along with considerations about the technology's shortcomings in its current state of development. As with any revolutionary new technology, as well as with exciting research opportunities, part of the challenge is balancing any potential positive and negative impacts on society. We offer our principles and guidelines used to inform our approach to experimenting with the new generative AI technologies. Bloomberg News' style guide reminds us that our journalism is aimed at possibly the most sophisticated audience in the world, for whom accuracy is essential.",0738-4602,2371-9621,,187-199, ,  ,,out_of_scope,
2610,"**Title**AStarTwice at SemEval-2021 Task 5: Toxic Span Detection using RoBERTa-CRF, Domain Specific Pre-Training and Self-Training

**Abstract**This paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our solution is built upon RoBERTa language model and Conditional Random Fields (CRF). We pre-trained RoBERTa on Civil Comments dataset, enabling it to create better contextual representation for this task. We also employed the semi-supervised learning technique of selftraining, which allowed us to extend our training dataset. In addition to these, we also identified some pre-processing steps that significantly improved our F1 score. Our proposed system achieved a rank of 41 with an F1 score of 66.16%.","Suman, Thakur Ashutosh; Jain, Abhinav",,,"AStarTwice at SemEval-2021 Task 5: Toxic Span Detection using RoBERTa-CRF, Domain Specific Pre-Training and Self-Training",,, ,Proceedings Paper ,,"This paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our solution is built upon RoBERTa language model and Conditional Random Fields (CRF). We pre-trained RoBERTa on Civil Comments dataset, enabling it to create better contextual representation for this task. We also employed the semi-supervised learning technique of selftraining, which allowed us to extend our training dataset. In addition to these, we also identified some pre-processing steps that significantly improved our F1 score. Our proposed system achieved a rank of 41 with an F1 score of 66.16%.",,,978-1-954085-70-1,875-880, , 15th International Workshops on Semantic Evaluation (SemEval)15th International Workshops on Semantic Evaluation (SemEval) ,,detection,
2611,"**Title**LZ1904 at SemEval-2021 Task 5: Bi-LSTM-CRF for Toxic Span Detection using PretrainedWord Embedding

**Abstract**Recurrent Neural Networks (RNN) have been widely used in various Natural Language Processing (NLP) tasks such as text classification, sequence tagging, and machine translation. Long Short Term Memory (LSTM), a special unit of RNN, has the advantage of memorizing past and even future information in a sentence (especially for bidirectional LSTM). In the shared task of detecting toxic spans in texts, we first apply pretrained word embedding (GloVe) to generate the word vectors after tokenization. Then we construct Bidirectional Long Short Term Memory-Conditional Random Field (Bi-LSTM-CRF) model by Baidu research to predict whether each word in the sentence is toxic or not. We tune hyperparameters of dropout rate, number of LSTM units, embedding size with 10 epochs and choose the epoch with best validation recall. Our model achieves an F1 score of 66.99% on test dataset.","Zou, Liang; Li, Wen",,,LZ1904 at SemEval-2021 Task 5: Bi-LSTM-CRF for Toxic Span Detection using PretrainedWord Embedding,,, ,Proceedings Paper ,,"Recurrent Neural Networks (RNN) have been widely used in various Natural Language Processing (NLP) tasks such as text classification, sequence tagging, and machine translation. Long Short Term Memory (LSTM), a special unit of RNN, has the advantage of memorizing past and even future information in a sentence (especially for bidirectional LSTM). In the shared task of detecting toxic spans in texts, we first apply pretrained word embedding (GloVe) to generate the word vectors after tokenization. Then we construct Bidirectional Long Short Term Memory-Conditional Random Field (Bi-LSTM-CRF) model by Baidu research to predict whether each word in the sentence is toxic or not. We tune hyperparameters of dropout rate, number of LSTM units, embedding size with 10 epochs and choose the epoch with best validation recall. Our model achieves an F1 score of 66.99% on test dataset.",,,978-1-954085-70-1,1009-1014, , 15th International Workshops on Semantic Evaluation (SemEval)15th International Workshops on Semantic Evaluation (SemEval) ,,detection,
2612,"**Title**Toxic comment classification and rationale extraction in code-mixed text leveraging co-attentive multi-task learning

**Abstract**Detecting toxic comments and rationale for the offensiveness of a social media post promotes moderation of social media content. For this purpose, we propose a Co-Attentive Multi-task Learning (CA-MTL) model through transfer learning for low-resource Hindi-English (commonly known as Hinglish) toxic texts. Together, the cooperative tasks of rationale/span detection and toxic comment classification create a strong multi-task learning objective. A task collaboration module is designed to leverage the bi-directional attention between the classification and span prediction tasks. The combined loss function of the model is constructed using the individual loss functions of these two tasks. Although an English toxic span detection dataset exists, one for Hinglish code-mixed text does not exist as of today. Hence, we developed a dataset with toxic span annotations for Hinglish code-mixed text. The proposed CA-MTL model is compared against single-task and multi-task learning models that lack the co-attention mechanism, using multilingual and Hinglish BERT variants. The F1 scores of the proposed CA-MTL model with HingRoBERTa encoder for both tasks are significantly higher than the baseline models. Caution: This paper may contain words disturbing to some readers.","Nelatoori, Kiran Babu; Kommanti, Hima Bindu","K, H/JEZ-2854-2023","K, Himabindu/0000-0001-8958-4222; Nelatoori, Kiran Babu/0000-0002-9425-4057",Toxic comment classification and rationale extraction in code-mixed text leveraging co-attentive multi-task learning,,,10.1007/s10579-023-09708-6 ,Article; Early Access ,,"Detecting toxic comments and rationale for the offensiveness of a social media post promotes moderation of social media content. For this purpose, we propose a Co-Attentive Multi-task Learning (CA-MTL) model through transfer learning for low-resource Hindi-English (commonly known as Hinglish) toxic texts. Together, the cooperative tasks of rationale/span detection and toxic comment classification create a strong multi-task learning objective. A task collaboration module is designed to leverage the bi-directional attention between the classification and span prediction tasks. The combined loss function of the model is constructed using the individual loss functions of these two tasks. Although an English toxic span detection dataset exists, one for Hinglish code-mixed text does not exist as of today. Hence, we developed a dataset with toxic span annotations for Hinglish code-mixed text. The proposed CA-MTL model is compared against single-task and multi-task learning models that lack the co-attention mechanism, using multilingual and Hinglish BERT variants. The F1 scores of the proposed CA-MTL model with HingRoBERTa encoder for both tasks are significantly higher than the baseline models. Caution: This paper may contain words disturbing to some readers.",1574-020X,1574-0218,,, ,  ,,out_but_toxicity,
2613,"**Title**Four Types of Toxic People: Characterizing Online Users' Toxicity over Time

**Abstract**Identifying types of online users' toxic behavior reveals important insights from social media interactions, including whether a user becomes radicalized (more toxic) or pacified (less toxic) over time. In this research, we design two metrics to identify toxic user types: F score that captures the changes in a user's toxicity, and G score that captures the direction of the shift taking place in the user's toxicity pattern. We apply these metrics to a dataset of 4M user comments from Reddit by defining four toxic user types based on the toxicity scores of a user's comments: (a) Steady Users whose toxicity scores are steady over time, (b) Fickle-Minded Users that switch between toxic and non-toxic commenting, (c) Pacified Users whose commenting becomes less toxic in time, and (d) Radicalized Users that become gradually toxic. Findings from the Reddit dataset indicate that fickle-minded users form the largest group (31.2%), followed by pacified (25.8%), radicalized (25.4%), and steadily toxic users (17.6%). The results suggest that the most typical behavior type of toxicity is switching between toxic and non-toxic commenting. This research has implications for preserving the user-friendliness of online communities by identifying continuously toxic users and users in danger of becoming radicalized (in terms of their toxic behavior), and designing interventions to mitigate these behavior types. Using the metrics we have defined, identifying these user types becomes possible. More research is needed to understand why these patterns take place and how they could be mitigated.","Mall, Raghvendra; Nagpal, Mridul; Salminen, Joni; Almerekhi, Hind; Jung, Soon-gyo; Jansen, Bernard J.","Almerekhi, Hind/ITU-8218-2023; Mall, Raghvendra/M-7132-2013",,Four Types of Toxic People: Characterizing Online Users' Toxicity over Time,,,10.1145/3419249.3420142 ,Proceedings Paper ,,"Identifying types of online users' toxic behavior reveals important insights from social media interactions, including whether a user becomes radicalized (more toxic) or pacified (less toxic) over time. In this research, we design two metrics to identify toxic user types: F score that captures the changes in a user's toxicity, and G score that captures the direction of the shift taking place in the user's toxicity pattern. We apply these metrics to a dataset of 4M user comments from Reddit by defining four toxic user types based on the toxicity scores of a user's comments: (a) Steady Users whose toxicity scores are steady over time, (b) Fickle-Minded Users that switch between toxic and non-toxic commenting, (c) Pacified Users whose commenting becomes less toxic in time, and (d) Radicalized Users that become gradually toxic. Findings from the Reddit dataset indicate that fickle-minded users form the largest group (31.2%), followed by pacified (25.8%), radicalized (25.4%), and steadily toxic users (17.6%). The results suggest that the most typical behavior type of toxicity is switching between toxic and non-toxic commenting. This research has implications for preserving the user-friendliness of online communities by identifying continuously toxic users and users in danger of becoming radicalized (in terms of their toxic behavior), and designing interventions to mitigate these behavior types. Using the metrics we have defined, identifying these user types becomes possible. More research is needed to understand why these patterns take place and how they could be mitigated.",,,978-1-4503-7579-5,, , 11th Nordic Conference on Human-Computer Interaction (NordiCHI)11th Nordic Conference on Human-Computer Interaction (NordiCHI) ,,detection#methodology,
2614,"**Title**Toxicity in Online Games: The Prevalence and Eficacy of Coping Strategies

**Abstract**Toxicity is pervasive in online multiplayer games, exposing players to disruptive and harmful behaviours. Players employ various approaches to cope with exposure to toxicity; however, game designers and researchers lack guidance on how to implement coping support within games. In this paper, we first conduct a formative study to collect a comprehensive list of coping approaches from toxicity literature and use affinity mapping to identify overarching game-based coping strategies. Then, we report findings from a survey (n = 85) on players' experiences with toxicity, how they employ the identified coping strategies, how games support coping, and their general coping styles. Our paper contributes a framework for coping strategies to deal with game-based toxicity and provides insights into the prevalence of these strategies among players and factors that affect their usage and effectiveness. These findings can be used to guide better in-game tools that help players mitigate the harm caused by toxicity.","Frommel, Julian; Mandryk, Regan L.","Frommel, Julian/JVM-8038-2024; Mandryk, Regan/HZK-7531-2023",,Toxicity in Online Games: The Prevalence and Eficacy of Coping Strategies,,,10.1145/3613904.3642523 ,Proceedings Paper ,,"Toxicity is pervasive in online multiplayer games, exposing players to disruptive and harmful behaviours. Players employ various approaches to cope with exposure to toxicity; however, game designers and researchers lack guidance on how to implement coping support within games. In this paper, we first conduct a formative study to collect a comprehensive list of coping approaches from toxicity literature and use affinity mapping to identify overarching game-based coping strategies. Then, we report findings from a survey (n = 85) on players' experiences with toxicity, how they employ the identified coping strategies, how games support coping, and their general coping styles. Our paper contributes a framework for coping strategies to deal with game-based toxicity and provides insights into the prevalence of these strategies among players and factors that affect their usage and effectiveness. These findings can be used to guide better in-game tools that help players mitigate the harm caused by toxicity.",,,979-8-4007-0330-0,, , ACM CHI Conference on Human Factors in Computing Sytems (CHI)ACM CHI Conference on Human Factors in Computing Sytems (CHI) ,,detection,
2615,"**Title**Novel Approaches for Understanding and Mitigating Emerging New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2024

**Abstract**As online spaces facilitate increasingly immersive and embodied experiences, concerns about how these emerging spaces may amplify and extend existing online harms and even lead to new harms, and how HCI researchers and developers can work to mitigate such harms also grow. Typical examples of these new and understudied forms of harm range from embodied harassment in social Virtual Reality (VR) to racist Zoombombing, new AI-powered online attacks such as hate raids on Twitch, and harmful virtual world design to manipulate users. This workshop aims to bring together a set of interdisciplinary researchers and practitioners from HCI and adjacent fields to explore further how these new harms continue to shape the current research discourse of online safety, cybersecurity, and immersive and embodied interactions in HCI, and to collectively identify what new technologies and mechanisms can be envisioned, designed, and implemented to better understand and mitigate these harms.","Freeman, Guo; Frommel, Julian; Mandryk, Regan L.; Gugenheimer, Jan; Li, Lingyuan; Johnson, Daniel","Frommel, Julian/JVM-8038-2024; Li, Lingyuan/HTR-0777-2023; Mandryk, Regan/HZK-7531-2023; Freeman, Guo/X-2261-2018; Johnson, Daniel/J-1028-2012","Li, Lingyuan/0000-0002-8640-9936; Freeman, Guo/0000-0001-5107-7794; Mandryk, Regan/0000-0003-0772-6616; Frommel, Julian/0000-0001-8783-7783; Johnson, Daniel/0000-0003-1088-3460",Novel Approaches for Understanding and Mitigating Emerging New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2024,,,10.1145/3613905.3636288 ,Proceedings Paper ,,"As online spaces facilitate increasingly immersive and embodied experiences, concerns about how these emerging spaces may amplify and extend existing online harms and even lead to new harms, and how HCI researchers and developers can work to mitigate such harms also grow. Typical examples of these new and understudied forms of harm range from embodied harassment in social Virtual Reality (VR) to racist Zoombombing, new AI-powered online attacks such as hate raids on Twitch, and harmful virtual world design to manipulate users. This workshop aims to bring together a set of interdisciplinary researchers and practitioners from HCI and adjacent fields to explore further how these new harms continue to shape the current research discourse of online safety, cybersecurity, and immersive and embodied interactions in HCI, and to collectively identify what new technologies and mechanisms can be envisioned, designed, and implemented to better understand and mitigate these harms.",,,979-8-4007-0331-7,, , ACM CHI Conference on Human Factors in Computing Sytems (CHI)ACM CHI Conference on Human Factors in Computing Sytems (CHI) ,,out_of_scope,
2616,"**Title**Analysing the Spread of Toxicity on Twitter

**Abstract**The spread of hate speech on social media platforms has become a rising concern in recent years. Understanding the spread of hate is crucial for mitigating its harmful effects and fostering a healthier online environment. In this paper, we propose a new model to capture the evolution of toxicity in a network - if a tweet with a certain toxicity (hatefulness) is posted, how much toxic a social network will become after a given number of rounds. We compute a toxicity score for each tweet, indicating the extent of the hatefulness of that tweet.Toxicity spread has not been adequately addressed in the existing literature. The two popular paradigms for modelling information spread, namely the Susceptible-Infected-Recovered (SIR) and its variants, as well as the spreading-activation models (SPA), are not suitable for modelling toxicity spread. The first paradigm employs a threshold and categorizes tweets as either toxic or non-toxic, while the second paradigm treats hate as energy and applies energy-conversion principles to model its propagation. Through analysis of a Twitter dataset consisting of 19.58 million tweets, we observe that the total toxicity, as well as the average toxicity of original tweets and retweets in the network, does not remain constant but rather increases over time.In this paper, we propose a new method for toxicity spread. First, we categorize users into three distinct groups: Amplifiers, Attenuators, and Copycats. These categories are assigned based on the exchange of toxicity by a user, with Amplifiers sending out more toxicity than they receive, Attenuators experiencing a higher influx of toxicity compared to what they generate, and Copycats simply mirroring the hate they receive. We perform extensive experimentation on Barabasi-Albert (BA) graphs, as well as subgraphs extracted from the Twitter dataset. Our model is able to replicate the patterns of toxicity.","Vaidya, Aatman; Nagar, Seema; Nanavati, Amit A.",,"Nanavati, Amit A./0000-0002-4131-9865; Nagar, Seema/0000-0003-1930-7101",Analysing the Spread of Toxicity on Twitter,,,10.1145/3632410.3632436 ,Proceedings Paper ,,"The spread of hate speech on social media platforms has become a rising concern in recent years. Understanding the spread of hate is crucial for mitigating its harmful effects and fostering a healthier online environment. In this paper, we propose a new model to capture the evolution of toxicity in a network - if a tweet with a certain toxicity (hatefulness) is posted, how much toxic a social network will become after a given number of rounds. We compute a toxicity score for each tweet, indicating the extent of the hatefulness of that tweet.Toxicity spread has not been adequately addressed in the existing literature. The two popular paradigms for modelling information spread, namely the Susceptible-Infected-Recovered (SIR) and its variants, as well as the spreading-activation models (SPA), are not suitable for modelling toxicity spread. The first paradigm employs a threshold and categorizes tweets as either toxic or non-toxic, while the second paradigm treats hate as energy and applies energy-conversion principles to model its propagation. Through analysis of a Twitter dataset consisting of 19.58 million tweets, we observe that the total toxicity, as well as the average toxicity of original tweets and retweets in the network, does not remain constant but rather increases over time.In this paper, we propose a new method for toxicity spread. First, we categorize users into three distinct groups: Amplifiers, Attenuators, and Copycats. These categories are assigned based on the exchange of toxicity by a user, with Amplifiers sending out more toxicity than they receive, Attenuators experiencing a higher influx of toxicity compared to what they generate, and Copycats simply mirroring the hate they receive. We perform extensive experimentation on Barabasi-Albert (BA) graphs, as well as subgraphs extracted from the Twitter dataset. Our model is able to replicate the patterns of toxicity.",,,979-8-4007-1634-8,118-126, , 7th ACM India Joint International Conference on Data Science and Management of Data (CODS-COMAD) / 11th ACM IKDD CODS Conference / 29th COMAD Conference7th ACM India Joint International Conference on Data Science and Management of Data (CODS-COMAD) / 11th ACM IKDD CODS Conference / 29th COMAD Conference ,,methodology,
2617,"**Title**Ecological impact of heavy metal pollution on Limnodrilus cervix -abundance, bioaccumulation, and environmental dynamics in a perennial pond of Jammu, India

**Abstract**This study examines the ecological ramifications of heavy metal contamination on benthic invertebrate communities, with a focus on Limnodrilus cervix, in a perennial pond situated in the Raipur region of Jammu, India. The study identified 11,587 individuals of Limnodrilus cervix, showing seasonal variations in abundance. Through a multidisciplinary approach encompassing taxonomic analysis, heavy metal quantification, acute toxicity testing, and bioaccumulation assessments, the research explores the intricate dynamics between pollution and aquatic ecosystems. Findings reveal pronounced seasonal fluctuations in L. cervix populations, with copper emerging as the predominant metal. Acute toxicity tests underscore dose-dependent lead (Pb) toxicity with an LC50 value of 0.03 mg/L, while bioaccumulation experiments elucidate Pb absorption in worm tissue with a bioconcentration factor (BCF) of 0.4 at 0.005 mg/L and 0.7 at 0.01 mg/L. The study underscores the urgent need for informed management strategies to mitigate the ecological risks posed by heavy metal pollution and safeguard freshwater habitats and their inhabitants.","Ahmed, Waqas; Khan, Ajaz Ali Ahmed; Sharma, Gourav; Singh, Deepika; Singh, Ravail","Ahmed, Waqas/U-4937-2019","Singh, Deepika/0000-0001-5347-6713","Ecological impact of heavy metal pollution on Limnodrilus cervix -abundance, bioaccumulation, and environmental dynamics in a perennial pond of Jammu, India",188,,10.1016/j.psep.2024.05.147 ,Article ,,"This study examines the ecological ramifications of heavy metal contamination on benthic invertebrate communities, with a focus on Limnodrilus cervix, in a perennial pond situated in the Raipur region of Jammu, India. The study identified 11,587 individuals of Limnodrilus cervix, showing seasonal variations in abundance. Through a multidisciplinary approach encompassing taxonomic analysis, heavy metal quantification, acute toxicity testing, and bioaccumulation assessments, the research explores the intricate dynamics between pollution and aquatic ecosystems. Findings reveal pronounced seasonal fluctuations in L. cervix populations, with copper emerging as the predominant metal. Acute toxicity tests underscore dose-dependent lead (Pb) toxicity with an LC50 value of 0.03 mg/L, while bioaccumulation experiments elucidate Pb absorption in worm tissue with a bioconcentration factor (BCF) of 0.4 at 0.005 mg/L and 0.7 at 0.01 mg/L. The study underscores the urgent need for informed management strategies to mitigate the ecological risks posed by heavy metal pollution and safeguard freshwater habitats and their inhabitants.",0957-5820,1744-3598,,595-607, ,  ,,out_of_scope,
2618,"**Title**Translocation and transformation of uranium along the aquatic food chain: New insights into uranium risks to the environment

**Abstract**Uranium pollution in aquatic ecosystems poses a threat to organisms. However, the metabolism and toxicity of uranium along aquatic food chains remain unknown. Here, we established an artificial aquatic ecosystem to investigate the fate of uranium along the food chain and reveal its potential toxicity. The results displayed a dose- and time-dependent toxicity of uranium on algae, leading to cell deformation and impeding cell proliferation. When uranium-exposed algae are ingested by fish, uranium tends to concentrate in the intestinal system and bones of fish. Comparatively, direct water uranium exposure resulted in a remarkable uranium accumulation in the head, skin, and muscles of fish, suggesting different toxicity depending on distinct exposure pathways. High-level uranium pollution (20 mg L-1 ) intensifies the toxicity to fish through food intake compared to direct water exposure. It has also revealed that approximately 25 % and 20 % of U(VI) were reduced to lower valence forms during its accumulation in algae and fish, respectively, and over 10 % of U(IV, VI) converted to U(0) ultimately, through which uranium toxicity was mitigated due to the lower solubility and bioavailability. Overall, this study provides new insights into the fate of uranium during its delivery along the aquatic food chain and highlights the risks associated with consuming uranium-contaminated aquatic products.","Li, Zhanming; Sun, Peipei; Zhang, Chenxi; Zhu, Nali; Xu, Nan; Li, Dongrui; Gao, Yuxi; Zhao, Jiating","Li, Zhanming/AFS-6484-2022; Xu, Nan/ABD-6900-2021","Xu, Nan/0000-0001-5996-9201",Translocation and transformation of uranium along the aquatic food chain: New insights into uranium risks to the environment,478,,10.1016/j.jhazmat.2024.135499 ,Article ,,"Uranium pollution in aquatic ecosystems poses a threat to organisms. However, the metabolism and toxicity of uranium along aquatic food chains remain unknown. Here, we established an artificial aquatic ecosystem to investigate the fate of uranium along the food chain and reveal its potential toxicity. The results displayed a dose- and time-dependent toxicity of uranium on algae, leading to cell deformation and impeding cell proliferation. When uranium-exposed algae are ingested by fish, uranium tends to concentrate in the intestinal system and bones of fish. Comparatively, direct water uranium exposure resulted in a remarkable uranium accumulation in the head, skin, and muscles of fish, suggesting different toxicity depending on distinct exposure pathways. High-level uranium pollution (20 mg L-1 ) intensifies the toxicity to fish through food intake compared to direct water exposure. It has also revealed that approximately 25 % and 20 % of U(VI) were reduced to lower valence forms during its accumulation in algae and fish, respectively, and over 10 % of U(IV, VI) converted to U(0) ultimately, through which uranium toxicity was mitigated due to the lower solubility and bioavailability. Overall, this study provides new insights into the fate of uranium during its delivery along the aquatic food chain and highlights the risks associated with consuming uranium-contaminated aquatic products.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2619,"**Title**Investigate the binding of pesticides with the TLR4 receptor protein found in mammals and zebrafish using molecular docking and molecular dynamics simulations

**Abstract**The widespread use of pesticides poses significant threats to both environmental and human health, primarily due to their potential toxic effects. The study investigated the cardiovascular toxicity of selected pesticides, focusing on their interactions with Toll-like receptor 4 (TLR4), an important part of the innate immune system. Using computational tools such as molecular docking, molecular dynamics (MD) simulations, principal component analysis (PCA), density functional theory (DFT) calculations, and ADME analysis, this study identified C160 as having the lowest binding affinity (-8.2 kcal/mol), followed by C107 and C165 (-8.0 kcal/mol). RMSD, RMSF, Rg, and hydrogen bond metrics indicated the formation of stable complexes between specific pesticides and TLR4. PCA revealed significant structural changes upon ligand binding, affecting stability and flexibility, while DFT calculations provided information about the stability, reactivity, and polarity of the compounds. ADME studies highlighted the solubility, permeability, and metabolic stability of C107, C160, and C165, suggesting their potential for bioavailability and impact on cardiovascular toxicity. C107 and C165 exhibit higher bioactivity scores, indicating favourable absorption, metabolism, and distribution properties. C165 also violated rule where molecular weight is greater than 500 g/mol. Further, DFT and NCI analysis of post MD conformations confirmed the binding of ligands at the binding pocket. The analysis shed light on the molecular mechanisms of pesticide-induced cardiovascular toxicity, aiding in the development of strategies to mitigate their harmful effects on human health.","Yadav, Sandeep; Aslam, Mohd; Prajapat, Ayushi; Massey, Iona; Nand, Bhaskara; Kumar, Durgesh; Kumari, Kamlesh; Pandey, Garima; Verma, Chandrabhan; Singh, Prashant; AlFantazi, Akram","Yadav, Sandeep/KTI-8556-2024; Saifi, Mohd Aslam/AAA-4123-2020; Pandey, Garima/ABG-9757-2020",", Sandeep Yadav/0009-0004-5993-9677; ASLAM, MOHD./0009-0004-4462-3629; Pandey, Garima/0000-0002-4615-9119",Investigate the binding of pesticides with the TLR4 receptor protein found in mammals and zebrafish using molecular docking and molecular dynamics simulations,14,1,10.1038/s41598-024-75527-6 ,Article ,,"The widespread use of pesticides poses significant threats to both environmental and human health, primarily due to their potential toxic effects. The study investigated the cardiovascular toxicity of selected pesticides, focusing on their interactions with Toll-like receptor 4 (TLR4), an important part of the innate immune system. Using computational tools such as molecular docking, molecular dynamics (MD) simulations, principal component analysis (PCA), density functional theory (DFT) calculations, and ADME analysis, this study identified C160 as having the lowest binding affinity (-8.2 kcal/mol), followed by C107 and C165 (-8.0 kcal/mol). RMSD, RMSF, Rg, and hydrogen bond metrics indicated the formation of stable complexes between specific pesticides and TLR4. PCA revealed significant structural changes upon ligand binding, affecting stability and flexibility, while DFT calculations provided information about the stability, reactivity, and polarity of the compounds. ADME studies highlighted the solubility, permeability, and metabolic stability of C107, C160, and C165, suggesting their potential for bioavailability and impact on cardiovascular toxicity. C107 and C165 exhibit higher bioactivity scores, indicating favourable absorption, metabolism, and distribution properties. C165 also violated rule where molecular weight is greater than 500 g/mol. Further, DFT and NCI analysis of post MD conformations confirmed the binding of ligands at the binding pocket. The analysis shed light on the molecular mechanisms of pesticide-induced cardiovascular toxicity, aiding in the development of strategies to mitigate their harmful effects on human health.",2045-2322,,,, ,  ,,out_of_scope,
2620,"**Title**Impact of microplastic intake via poultry products: Environmental toxicity and human health

**Abstract**In recent years, the escalating concerns surrounding the pervasive presence of microplastics in the environment had prompted a pressing need to evaluate their potential impacts on ecosystems and human health. This study investigates the pathways and implications of microplastic intake through poultry product consumption by focusing on environmental toxicity and human health risks. Through an integrated approach encompassing available experimental data and literature synthesis, the intricate mechanisms of microplastic transfer from poultry feed to animal tissues are elucidated by highlighting the potential environmental implications of such contamination. An in-depth toxicological assessment evaluated the health risks associated with microplastic ingestion with poultry food consumption by emphasizing the acute and chronic effects on human well-being. This study emphasizes the urgency of implementing informed policy decisions and sustainable practices to mitigate the environmental and human health risks posed by microplastic contamination in the poultry food chain. The insights provided by this study serve as a foundational basis for generating awareness and implementing effective measures aimed at safeguarding both environmental integrity and human well-being from the escalating threats of microplastic pollution.","Sharma, Prabhakar; Vidyarthi, Vijay Kumar","Sharma, Prabhakar/C-2133-2009","Sharma, Prabhakar/0000-0003-0894-0809",Impact of microplastic intake via poultry products: Environmental toxicity and human health,14,,10.1016/j.hazadv.2024.100426 ,Article ,,"In recent years, the escalating concerns surrounding the pervasive presence of microplastics in the environment had prompted a pressing need to evaluate their potential impacts on ecosystems and human health. This study investigates the pathways and implications of microplastic intake through poultry product consumption by focusing on environmental toxicity and human health risks. Through an integrated approach encompassing available experimental data and literature synthesis, the intricate mechanisms of microplastic transfer from poultry feed to animal tissues are elucidated by highlighting the potential environmental implications of such contamination. An in-depth toxicological assessment evaluated the health risks associated with microplastic ingestion with poultry food consumption by emphasizing the acute and chronic effects on human well-being. This study emphasizes the urgency of implementing informed policy decisions and sustainable practices to mitigate the environmental and human health risks posed by microplastic contamination in the poultry food chain. The insights provided by this study serve as a foundational basis for generating awareness and implementing effective measures aimed at safeguarding both environmental integrity and human well-being from the escalating threats of microplastic pollution.",2772-4166,,,, ,  ,,out_of_scope,
2621,"**Title**Tiltometer: Real-Time Tilt Recognition in Esports

**Abstract**This paper introduces the Tiltometer, a system designed to help mitigate the effects of emotional tilt in esports, specifically in the context of the popular multiplayer online battle arena (MOBA) game League of Legends (LoL). In esports, tilt or tilting refers to a progressive deterioration in gameplay due to negative emotions and loss of self-control. Our system integrates facial and speech emotion recognition with in-game events to compute a player's tilt level in real-time. The tilt level is visualized alongside related data as an in-game overlay. Our goal is to aid players in breaking out of tilting behavior to improve gameplay and reduce toxicity.","Ortmann, Thorben; Maute, Sune; Heil, Franziska; Hildebrandt, Kilian; Jorshery, Pedram Berendjy; Putzar, Larissa",,"Ortmann, Thorben/0009-0006-6589-4262",Tiltometer: Real-Time Tilt Recognition in Esports,,,10.1109/ACIIW59127.2023.10388192 ,Proceedings Paper ,,"This paper introduces the Tiltometer, a system designed to help mitigate the effects of emotional tilt in esports, specifically in the context of the popular multiplayer online battle arena (MOBA) game League of Legends (LoL). In esports, tilt or tilting refers to a progressive deterioration in gameplay due to negative emotions and loss of self-control. Our system integrates facial and speech emotion recognition with in-game events to compute a player's tilt level in real-time. The tilt level is visualized alongside related data as an in-game overlay. Our goal is to aid players in breaking out of tilting behavior to improve gameplay and reduce toxicity.",,,979-8-3503-2745-8,, , 11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)11th International Conference on Affective Computing and Intelligent Interaction (ACIIW) ,,out_but_toxicity,
2622,"**Title**Modulating Physiological and Antioxidant Responses in Wheat Cultivars via Foliar Application of Silicon Nanoparticles (SiNPs) Under Arsenic Stress Conditions

**Abstract**Globally, heavy metals especially arsenic (As) toxicity in staple crops like wheat has posed serious threats to human health, necessitating conducting fresh studies to find out biologically viable As toxicity mitigation strategies. Therefore, this study aimed to investigate the impact of foliar-applied silicon nanoparticles (SiNPs) at the tillering stage on the activation of physiological and antioxidant regulation in wheat to induce tolerance against varying As toxicity levels. The trial comprised two promising wheat cultivars (Anaaj and Ghazi) and five SiNPs regimes including 0, 30, 60, 90, and 120 ppm doses against As toxicity levels of 0 and 25 ppm. The recorded findings depicted that SiNPs regimes significantly improved morphological characteristics such as root length, fresh and dry weight, as well as shoot length, and fresh and dry weight of wheat cultivars. Additionally, the levels of chlorophyll pigments, including chlorophyll a, chlorophyll b, and total chlorophyll contents, were significantly increased in SiNPs-treated plants, indicating improved photosynthetic activity. The enhanced antioxidant enzyme activities, such as ascorbate peroxidase (APX), superoxide dismutase (SOD), peroxidase (POD), and catalase (CAT), played a vital role in combating oxidative stress induced by As toxicity. Moreover, SiNPs application resulted in a significant reduction in As concentration in both leaves and roots, highlighting the ability of SiNPs to regulate the uptake and accumulation of arsenic and mitigate its toxic effects. In conclusion, the foliar application of SiNPs during the tillering stage of wheat effectively activated physiological and antioxidant regulation, leading to enhanced tolerance against As toxicity.","Ahmad, Zahoor; Younis, Rooma; Ahmad, Tanveer; Iqbal, Muhammad Aamir; Artyszak, Arkadiusz; Alzahrani, Yahya M.; Alharby, Hesham F.; Alsamadany, Hameed","Artyszak, Arkadiusz/AAC-1478-2019; Alsamadany, Hameed/AAS-6193-2021; Ahmad, Zahoor/AGZ-8861-2022; Iqbal, Muhammad Aamir/AFN-2665-2022","AHMAD, Dr. ZAHOOR/0000-0002-7986-7541; Iqbal, Muhammad Aamir/0000-0003-2701-0551",Modulating Physiological and Antioxidant Responses in Wheat Cultivars via Foliar Application of Silicon Nanoparticles (SiNPs) Under Arsenic Stress Conditions,16,12,10.1007/s12633-024-03078-6 ,Article ,,"Globally, heavy metals especially arsenic (As) toxicity in staple crops like wheat has posed serious threats to human health, necessitating conducting fresh studies to find out biologically viable As toxicity mitigation strategies. Therefore, this study aimed to investigate the impact of foliar-applied silicon nanoparticles (SiNPs) at the tillering stage on the activation of physiological and antioxidant regulation in wheat to induce tolerance against varying As toxicity levels. The trial comprised two promising wheat cultivars (Anaaj and Ghazi) and five SiNPs regimes including 0, 30, 60, 90, and 120 ppm doses against As toxicity levels of 0 and 25 ppm. The recorded findings depicted that SiNPs regimes significantly improved morphological characteristics such as root length, fresh and dry weight, as well as shoot length, and fresh and dry weight of wheat cultivars. Additionally, the levels of chlorophyll pigments, including chlorophyll a, chlorophyll b, and total chlorophyll contents, were significantly increased in SiNPs-treated plants, indicating improved photosynthetic activity. The enhanced antioxidant enzyme activities, such as ascorbate peroxidase (APX), superoxide dismutase (SOD), peroxidase (POD), and catalase (CAT), played a vital role in combating oxidative stress induced by As toxicity. Moreover, SiNPs application resulted in a significant reduction in As concentration in both leaves and roots, highlighting the ability of SiNPs to regulate the uptake and accumulation of arsenic and mitigate its toxic effects. In conclusion, the foliar application of SiNPs during the tillering stage of wheat effectively activated physiological and antioxidant regulation, leading to enhanced tolerance against As toxicity.",1876-990X,1876-9918,,5199-5211, ,  ,,out_of_scope,
2623,"**Title**The probiotic SLAB51 as agent to counteract BPA toxicity on zebrafish gut microbiota -liver-brain axis

**Abstract**A plethora of studies have so far described the toxic effects of bisphenol A (BPA) on organism health, highlighting the urgent need to find new strategies not only to reduce the presence of this toxicant but also to counteract its adverse effects. In this context, probiotics emerged as a potential tool since they promote organism welfare. Using a multidisciplinary approach, this study explores the effects of SLAB51 dietary administration to counteract BPA toxicity using zebrafish as a model. Adult males and females were maintained under standard conditions (control group; C), exposed for 28 days via the water to an environmental relevant dose of BPA (10 mu g/L; BPA), dietary treated with SLAB51 (109 CFU/g of body weight; P) and co -treated with BPA plus SLAB51 (BPA + P). In the gut, exposure to BPA resulted in altered architecture in both males and females, with females also experiencing an increase of pathogenic bacterial species. Co -administration of BPA + P led to the restoration of normal gut architecture, favored beneficial bacteria colonization, and decreased the abundance of pathogenic species. In the liver, male BPA exposure led to steatosis and glycogen depletion, which was partially mitigated by SLAB51 co -administration. In contrast, in females exposed to BPA, the lack of steatosis along with the greater glycogen depletion, suggested an increase in energy demand as supported by the metabolomic phenotype. The analysis of liver metabolites in BPA + P males revealed increased levels of anserine and reduced levels of glutamine, which could lie behind the counteraction of the brain histopathological damage caused by BPA. In BPA + P females, a reduction of retinoic acid was found in the liver, suggesting an increase in retinoids responsible for BPA detoxification. Overall, these results demonstrate that SLAB51 exerts its beneficial effects on the gut microbiota-brain-liver axis through distinct molecular pathways, effectively mitigating the pleiotropic toxicity of BPA.","Giommi, Christian; Lombo, Marta; Habibi, Hamid R.; Rossi, Giacomo; Basili, Danilo; Mangiaterra, Sara; Ladisa, Claudia; Chemello, Giulia; Carnevali, Oliana; Maradonna, Francesca","Maradonna, Francesca/AAU-5167-2021; Basili, Danilo/T-3088-2019; Habibi, Hamidreza/AAP-6084-2021; Rossi, Giacomo/HCI-9726-2022; Lombo, Marta/C-1878-2016","Basili, Danilo/0000-0003-4830-7848; Lombo, Marta/0000-0002-2042-798X",The probiotic SLAB51 as agent to counteract BPA toxicity on zebrafish gut microbiota -liver-brain axis,912,,10.1016/j.scitotenv.2023.169303 ,Article ,,"A plethora of studies have so far described the toxic effects of bisphenol A (BPA) on organism health, highlighting the urgent need to find new strategies not only to reduce the presence of this toxicant but also to counteract its adverse effects. In this context, probiotics emerged as a potential tool since they promote organism welfare. Using a multidisciplinary approach, this study explores the effects of SLAB51 dietary administration to counteract BPA toxicity using zebrafish as a model. Adult males and females were maintained under standard conditions (control group; C), exposed for 28 days via the water to an environmental relevant dose of BPA (10 mu g/L; BPA), dietary treated with SLAB51 (109 CFU/g of body weight; P) and co -treated with BPA plus SLAB51 (BPA + P). In the gut, exposure to BPA resulted in altered architecture in both males and females, with females also experiencing an increase of pathogenic bacterial species. Co -administration of BPA + P led to the restoration of normal gut architecture, favored beneficial bacteria colonization, and decreased the abundance of pathogenic species. In the liver, male BPA exposure led to steatosis and glycogen depletion, which was partially mitigated by SLAB51 co -administration. In contrast, in females exposed to BPA, the lack of steatosis along with the greater glycogen depletion, suggested an increase in energy demand as supported by the metabolomic phenotype. The analysis of liver metabolites in BPA + P males revealed increased levels of anserine and reduced levels of glutamine, which could lie behind the counteraction of the brain histopathological damage caused by BPA. In BPA + P females, a reduction of retinoic acid was found in the liver, suggesting an increase in retinoids responsible for BPA detoxification. Overall, these results demonstrate that SLAB51 exerts its beneficial effects on the gut microbiota-brain-liver axis through distinct molecular pathways, effectively mitigating the pleiotropic toxicity of BPA.",0048-9697,1879-1026,,, ,  ,,out_of_scope,
2624,"**Title**Effective degradation of zearalenone by dye-decolorizing peroxidases from Pleurotus ostreatus and its metabolic pathway and toxicity analysis

**Abstract**The widespread detection of zearalenone (ZEN) in cereal crops and feeds poses a significant threat to both humans and animals. Consequently, the urgency for the international community to address this issue is evident in the demand for safe and effective measures to mitigate zearalenone contamination and explore detoxification methods. In this study, a dye-decolorizing peroxidase (PoDyP4) from Pleurotus ostreatus is characterized for its impressive ZEN degradation effectiveness. PoDyP4 was demonstrated that the ability to almost completely degrade ZEN at pH 6.0 and 40 degrees C for 2 h, even at high concentrations of 1 mM. The promotion of enzymatic degradation of ZEN was most pronounced in the presence of Mg2+, while Cu2+ and Fe2+ exhibited a notable inhibitory effect. The degradation mechanism elucidated the detoxification of ZEN by PoDyP4 through hy-droxylation and polymerization reactions. The resulting metabolic products displayed significantly reduced toxicity and minimal impact on the viability and apoptosis of mouse spermatocytes GC-2 cells, in comparison to the original ZEN. Hydrophobic contacts and hydrogen bonds were found to be crucial for ZEN-PoDyP4 stability via molecular docking. This finding suggests that PoDyP4 may have a promising application in the field of food and feed for zearalenone detoxification.","Ding, Shuai; Lin, Chen; Xiao, Qiuyun; Wang, Junfeng; Zhang, Xing; Yang, Shengjing; Li, Lingling; Li, Fei",,"Ding, Shuai/0009-0008-9803-3754",Effective degradation of zearalenone by dye-decolorizing peroxidases from Pleurotus ostreatus and its metabolic pathway and toxicity analysis,908,,10.1016/j.scitotenv.2023.168500 ,Article ,,"The widespread detection of zearalenone (ZEN) in cereal crops and feeds poses a significant threat to both humans and animals. Consequently, the urgency for the international community to address this issue is evident in the demand for safe and effective measures to mitigate zearalenone contamination and explore detoxification methods. In this study, a dye-decolorizing peroxidase (PoDyP4) from Pleurotus ostreatus is characterized for its impressive ZEN degradation effectiveness. PoDyP4 was demonstrated that the ability to almost completely degrade ZEN at pH 6.0 and 40 degrees C for 2 h, even at high concentrations of 1 mM. The promotion of enzymatic degradation of ZEN was most pronounced in the presence of Mg2+, while Cu2+ and Fe2+ exhibited a notable inhibitory effect. The degradation mechanism elucidated the detoxification of ZEN by PoDyP4 through hy-droxylation and polymerization reactions. The resulting metabolic products displayed significantly reduced toxicity and minimal impact on the viability and apoptosis of mouse spermatocytes GC-2 cells, in comparison to the original ZEN. Hydrophobic contacts and hydrogen bonds were found to be crucial for ZEN-PoDyP4 stability via molecular docking. This finding suggests that PoDyP4 may have a promising application in the field of food and feed for zearalenone detoxification.",0048-9697,1879-1026,,, ,  ,,out_of_scope,
2625,"**Title**Application and efficacy of beidellite clay for the adsorption and detoxification of deoxynivalenol (vomitoxin)

**Abstract**The incidence of mycotoxin occurrence throughout the entire lifespan of some agricultural products could be due to climatic conditions and environmental factors (including high temperature, drought, and heavy rainfall) that enhance growth of fungi. Deoxynivalenol (DON) which is also referred to as vomitoxin is a mycotoxin produced from many Fusarium species. DON ranks high among the prominent mycotoxins in cereal products and is a ubiquitous toxin in livestock feeds. DON's adverse effects present major health challenges in both livestock and humans. The use of natural sorbents including smectite clays, is an economically feasible strategy to mitigate mycotoxin toxicities. Previous studies have demonstrated the potential of edible clays as protective components of human food and animal feed to alleviate toxicity associated with short-term exposure to mycotoxins including DON. Hence, this study was designed to investigate the sorption mechanisms of DON onto the binding surfaces of beidellite clay, assessing essential binding parameters such as enthalpy, free energy, binding capacity, affinity, and plateau surface density. These markers were used to predict availability of DON under the experimental conditions. Furthermore, the protection of beidellite clay against DON-induced toxicity was carried out using living organisms susceptible to DON toxicity, including Hydra vulgaris and Lemna minor. These studies investigated the dose-dependent detoxification of DON by 0.05e2 % inclusion of beidellite. Beidellite exhibited more than 75 % protection in Lemna minor and 53 % in Hydra vulgaris validating that this clay is effective in detoxifying DON. During emergencies, or after disasters, inclusion of edible clay like beidellite in food, water or capsules could reduce bioavailability of DON and halt potential exposures to humans and animals. (c) 2024 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/ 4.0/).","Oladele, Johnson O.; Wang, Meichen; Rivenbark, Kelly J.; Phillips, Timothy D.","Oladele, Johnson. O./ABB-6466-2020","Oladele, Johnson. O./0000-0002-5434-1359",Application and efficacy of beidellite clay for the adsorption and detoxification of deoxynivalenol (vomitoxin),10,4,10.1016/j.emcon.2024.100390 ,Article ,,"The incidence of mycotoxin occurrence throughout the entire lifespan of some agricultural products could be due to climatic conditions and environmental factors (including high temperature, drought, and heavy rainfall) that enhance growth of fungi. Deoxynivalenol (DON) which is also referred to as vomitoxin is a mycotoxin produced from many Fusarium species. DON ranks high among the prominent mycotoxins in cereal products and is a ubiquitous toxin in livestock feeds. DON's adverse effects present major health challenges in both livestock and humans. The use of natural sorbents including smectite clays, is an economically feasible strategy to mitigate mycotoxin toxicities. Previous studies have demonstrated the potential of edible clays as protective components of human food and animal feed to alleviate toxicity associated with short-term exposure to mycotoxins including DON. Hence, this study was designed to investigate the sorption mechanisms of DON onto the binding surfaces of beidellite clay, assessing essential binding parameters such as enthalpy, free energy, binding capacity, affinity, and plateau surface density. These markers were used to predict availability of DON under the experimental conditions. Furthermore, the protection of beidellite clay against DON-induced toxicity was carried out using living organisms susceptible to DON toxicity, including Hydra vulgaris and Lemna minor. These studies investigated the dose-dependent detoxification of DON by 0.05e2 % inclusion of beidellite. Beidellite exhibited more than 75 % protection in Lemna minor and 53 % in Hydra vulgaris validating that this clay is effective in detoxifying DON. During emergencies, or after disasters, inclusion of edible clay like beidellite in food, water or capsules could reduce bioavailability of DON and halt potential exposures to humans and animals. (c) 2024 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/ 4.0/).",2405-6650,2405-6642,,, ,  ,,out_of_scope,
2626,"**Title**Technological Solutions to Online Toxicity: Potential and Pitfalls

**Abstract**Social media platforms present a perplexing duality, acting at once as sites to build community and a sense of belonging, while also giving rise to misinformation, facilitating and intensifying disinformation campaigns and perpetuating existing patterns of discrimination from the physical world. The first-step platforms take in mitigating the harmful side of social media involves identifying and managing toxic content. Users produce an enormous volume of posts which must be evaluated very quickly. This is an application context that requires machine-learning (ML) tools, but as we detail in this article, ML approaches rely on human annotators, analysts, and moderators. Our review of existing methods and potential improvements indicates that neither humans nor ML can be removed from this process in the near future. However, we see room for improvement in the working conditions of these human workers.","Bodaghi, Arezo; Fung, Benjamin C. M.; Schmitt, Ketra A.","Schmitt, Ketra/GWQ-5329-2022","bodaghi, Arezo/0000-0002-7450-0687; Schmitt, Ketra/0000-0002-4260-6209",Technological Solutions to Online Toxicity: Potential and Pitfalls,42,4,10.1109/MTS.2023.3340235 ,Article ,,"Social media platforms present a perplexing duality, acting at once as sites to build community and a sense of belonging, while also giving rise to misinformation, facilitating and intensifying disinformation campaigns and perpetuating existing patterns of discrimination from the physical world. The first-step platforms take in mitigating the harmful side of social media involves identifying and managing toxic content. Users produce an enormous volume of posts which must be evaluated very quickly. This is an application context that requires machine-learning (ML) tools, but as we detail in this article, ML approaches rely on human annotators, analysts, and moderators. Our review of existing methods and potential improvements indicates that neither humans nor ML can be removed from this process in the near future. However, we see room for improvement in the working conditions of these human workers.",0278-0097,1937-416X,,57-65, ,  ,,evaluation,
2627,"**Title**Selenium-molybdenum interactions reduce chromium toxicity in Nicotiana tabacum L. by promoting chromium chelation on the cell wall

**Abstract**Chromium (Cr) is a hazardous heavy metal that negatively affects animals and plants. The micronutrients se-lenium (Se) and molybdenum (Mo) have been widely shown to alleviate heavy metal toxicity in plants. However, the molecular mechanism of Cr chelation on the cell wall by combined treatment with Se and Mo has not been reported. Therefore, this study aimed to explore the effects of Se-Mo interactions on the subcellular distribution of Cr (50 mu M) and on cell wall composition, structure, functional groups and Cr content, in addition to per-forming a comprehensive analysis of the transcriptome. Our results showed that the cell walls of shoots and roots accumulated 51.0% and 65.0% of the Cr, respectively. Furthermore, pectin in the cell wall bound 69.5%/90.2% of the Cr in the shoots/roots. Se-Mo interactions upregulated the expression levels of related genes encoding galacturonosyltransferase (GAUT), UTP-glucose-1-phosphate uridylyltransferase (UGP), and UDP-glucose-4-epimerase (GALE), involved in polysaccharide biosynthesis, thereby increasing pectin and cellulose levels. Moreover, combined treatment with Se and Mo increased the lignin content and cell wall thickness by upre-gulating the expression levels of genes encoding cinnamyl alcohol dehydrogenase (CAD), peroxidase (POX) and phenylalanine amino-lyase (PAL), involved in lignin biosynthesis. Fourier-transform infrared (FTIR) spectroscopy results showed that Se + Mo treatment (in combination) increased the number of carboxylic acid groups (-COOH) groups, thereby enhancing the Cr chelation ability. The results not only elucidate the molecular mechanism of action of Se-Mo interactions in mitigating Cr toxicity but also provide new insights for phytor-emediation and food safety.","Qu, Lili; Xu, Zicheng; Huang, Wuxing; Han, Dan; Dang, Bingjun; Ma, Xiaohan; Liu, Yizan; Xu, Jiayang; Jia, Wei",,,Selenium-molybdenum interactions reduce chromium toxicity in Nicotiana tabacum L. by promoting chromium chelation on the cell wall,461,,10.1016/j.jhazmat.2023.132641 ,Article ,,"Chromium (Cr) is a hazardous heavy metal that negatively affects animals and plants. The micronutrients se-lenium (Se) and molybdenum (Mo) have been widely shown to alleviate heavy metal toxicity in plants. However, the molecular mechanism of Cr chelation on the cell wall by combined treatment with Se and Mo has not been reported. Therefore, this study aimed to explore the effects of Se-Mo interactions on the subcellular distribution of Cr (50 mu M) and on cell wall composition, structure, functional groups and Cr content, in addition to per-forming a comprehensive analysis of the transcriptome. Our results showed that the cell walls of shoots and roots accumulated 51.0% and 65.0% of the Cr, respectively. Furthermore, pectin in the cell wall bound 69.5%/90.2% of the Cr in the shoots/roots. Se-Mo interactions upregulated the expression levels of related genes encoding galacturonosyltransferase (GAUT), UTP-glucose-1-phosphate uridylyltransferase (UGP), and UDP-glucose-4-epimerase (GALE), involved in polysaccharide biosynthesis, thereby increasing pectin and cellulose levels. Moreover, combined treatment with Se and Mo increased the lignin content and cell wall thickness by upre-gulating the expression levels of genes encoding cinnamyl alcohol dehydrogenase (CAD), peroxidase (POX) and phenylalanine amino-lyase (PAL), involved in lignin biosynthesis. Fourier-transform infrared (FTIR) spectroscopy results showed that Se + Mo treatment (in combination) increased the number of carboxylic acid groups (-COOH) groups, thereby enhancing the Cr chelation ability. The results not only elucidate the molecular mechanism of action of Se-Mo interactions in mitigating Cr toxicity but also provide new insights for phytor-emediation and food safety.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2628,"**Title**Safety considerations for SPIcDER: Spacesuit integrated carbon nanotube dust ejection/removal system

**Abstract**This paper presents a multi-tier safe implementation of the Spacesuit Integrated Carbon Nanotube Dust Ejection/Removal (SPIcDER) system. SPIcDER mitigates dust contamination of spacesuits and flexible surfaces during surface exploration of Moon and Mars. SPIcDER has Carbon nanotube (CNT) fibers embedded within the spacesuit outerlayer. These are energized using high voltage, low power, Alternating Current (AC) signals ( similar to 350-1000 V). Laboratory experiments show the time-varying electric fields produced by SPIcDER repel the dust.This system mitigates astronaut exposures to lunar dust, and protects spacesuits and flexible surfaces from dust abrasion, wear and tear, and reduction in thermal performance. The adherence of lunar dust, and its entry into the habitable volume of habitats/landers, which was a major problem during Apollo missions, is also minimized.In this study, we review the primary health and safety aspects of SPIcDER for astronauts operating in these spacesuits. Simulation using ANSYS Maxwell (R) and preliminary experimental investigations were performed to conduct safety analysis and provide recommendations for implementation of SPIcDER for lunar mission opera-tions.","Manyapu, Kavya. K.; Peltz, Leora; De Leon, Pablo",,,Safety considerations for SPIcDER: Spacesuit integrated carbon nanotube dust ejection/removal system,9,1,10.1016/j.jsse.2021.10.003 ,Article ,,"This paper presents a multi-tier safe implementation of the Spacesuit Integrated Carbon Nanotube Dust Ejection/Removal (SPIcDER) system. SPIcDER mitigates dust contamination of spacesuits and flexible surfaces during surface exploration of Moon and Mars. SPIcDER has Carbon nanotube (CNT) fibers embedded within the spacesuit outerlayer. These are energized using high voltage, low power, Alternating Current (AC) signals ( similar to 350-1000 V). Laboratory experiments show the time-varying electric fields produced by SPIcDER repel the dust.This system mitigates astronaut exposures to lunar dust, and protects spacesuits and flexible surfaces from dust abrasion, wear and tear, and reduction in thermal performance. The adherence of lunar dust, and its entry into the habitable volume of habitats/landers, which was a major problem during Apollo missions, is also minimized.In this study, we review the primary health and safety aspects of SPIcDER for astronauts operating in these spacesuits. Simulation using ANSYS Maxwell (R) and preliminary experimental investigations were performed to conduct safety analysis and provide recommendations for implementation of SPIcDER for lunar mission opera-tions.",2468-8975,2468-8967,,3-11, ,  ,,out_of_scope,
2629,"**Title**Spillover effects of organic agriculture on pesticide use on nearby fields

**Abstract**The environmental impacts of organic agriculture are only partially understood and whether such practices have spillover effects on pests or pest control activity in nearby fields remains unknown. Using about 14,000 field observations per year from 2013 to 2019 in Kern County, California, we postulate that organic crop producers benefit from surrounding organic fields decreasing overall pesticide use and, specifically, pesticides targeting insect pests. Conventional fields, by contrast, tend to increase pesticide use as the area of surrounding organic production increases. Our simulation suggests that spatially clustering organic cropland can entirely mitigate spillover effects that lead to an increase in net pesticide use.","Larsen, Ashley E.; Noack, Frederik; Powers, L. Claire",,"Noack, Frederik/0000-0002-5747-4368",Spillover effects of organic agriculture on pesticide use on nearby fields,383,6689,10.1126/science.adf2572 ,Article ,,"The environmental impacts of organic agriculture are only partially understood and whether such practices have spillover effects on pests or pest control activity in nearby fields remains unknown. Using about 14,000 field observations per year from 2013 to 2019 in Kern County, California, we postulate that organic crop producers benefit from surrounding organic fields decreasing overall pesticide use and, specifically, pesticides targeting insect pests. Conventional fields, by contrast, tend to increase pesticide use as the area of surrounding organic production increases. Our simulation suggests that spatially clustering organic cropland can entirely mitigate spillover effects that lead to an increase in net pesticide use.",0036-8075,1095-9203,,, ,  ,,out_of_scope,
2630,"**Title**FLASH Proton Radiation Therapy Mitigates In fl ammatory and Fibrotic Pathways and Preserves Cardiac Function in a Preclinical Mouse Model of Radiation-Induced Heart Disease

**Abstract**Purpose: Studies during the past 9 years suggest that delivering radiation at dose rates exceeding 40 Gy/s, known as  FLASH  radiation therapy, enhances the therapeutic index of radiation therapy (RT) by decreasing normal tissue damage while maintaining tumor response compared with conventional (or standard) RT. This study demonstrates the cardioprotective bene fits of FLASH proton RT (F-PRT) compared with standard (conventional) proton RT (S-PRT), as evidenced by reduced acute and chronic cardiac toxicities. Methods and Materials: Mice were imaged using cone beam computed tomography to precisely determine the heart ' s apex as the beam isocenter. Irradiation was conducted using a shoot -through technique with a 5 -mm diameter circular collimator. Bulk RNA -sequencing was performed on nonirradiated samples, as well as apexes treated with F-PRT or S-PRT, at 2 weeks after a single 40 Gy dose. In flammatory responses were assessed through multiplex cytokine/chemokine microbead assay and immunofluorescence analyses. Levels of perivascular fibrosis were quantified using Masson ' s Trichrome and Picrosirius red staining. Additionally, cardiac tissue functionality was evaluated by 2 -dimensional echocardiograms at 8- and 30 -weeks post-PRT. Results: Radiation damage was specifically localized to the heart ' s apex. RNA pro fi ling of cardiac tissues treated with PRT revealed that S-PRT uniquely upregulated pathways associated with DNA damage response, induction of tumor necrosis factor superfamily, and in flammatory response, and F-PRT primarily affected cytoplasmic translation, mitochondrion organization, and adenosine triphosphate synthesis. Notably, F-PRT led to a milder in fl ammatory response, accompanied by signi fi cantly attenuated changes in transforming growth factor 0 1 and a smooth muscle actin levels. Critically, F-PRT decreased collagen deposition and better preserved cardiac functionality compared with S-PRT. Conclusions: This study demonstrated that F-PRT reduces the induction of an in flammatory environment with lower expression of in flammatory cytokines and pro fibrotic factors. Importantly, the results indicate that F-PRT better preserves cardiac functionality, as con firmed by echocardiography analysis, while also mitigating the development of long-term fibrosis. (c) 2024 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY -NC -ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/)","Kim, Kyle; Kim, Michele M.; Skoufos, Giorgos; Diffenderfer, Eric S.; Motlagh, Seyyedeh Azar Oliaei; Kokkorakis, Michail; Koliaki, Ilektra; Morcos, George; Shoniyozov, Khayrullo; Griffi, Joanna; Hatzigeorgiou, Artemis G.; Metz, James M.; Lin, Alexander; Feigenberg, Steven J.; Cengel, Keith A.; Ky, Bonnie; Koumenis, Constantinos; Verginadis, Ioannis I.","Kokkorakis, Michail/HTO-6439-2023; Verginadis, Ioannis/KBB-6736-2024; Kim, Michele/KBD-4844-2024; Motlagh, Seyyedeh/T-8647-2019","Kokkorakis, Michail/0000-0002-0027-5659; Morcos, George/0000-0003-1028-9402; Verginadis, Ioannis/0000-0002-0755-4511",FLASH Proton Radiation Therapy Mitigates In fl ammatory and Fibrotic Pathways and Preserves Cardiac Function in a Preclinical Mouse Model of Radiation-Induced Heart Disease,119,4,10.1016/j.ijrobp.2024.01.224 ,Article ,,"Purpose: Studies during the past 9 years suggest that delivering radiation at dose rates exceeding 40 Gy/s, known as  FLASH  radiation therapy, enhances the therapeutic index of radiation therapy (RT) by decreasing normal tissue damage while maintaining tumor response compared with conventional (or standard) RT. This study demonstrates the cardioprotective bene fits of FLASH proton RT (F-PRT) compared with standard (conventional) proton RT (S-PRT), as evidenced by reduced acute and chronic cardiac toxicities. Methods and Materials: Mice were imaged using cone beam computed tomography to precisely determine the heart ' s apex as the beam isocenter. Irradiation was conducted using a shoot -through technique with a 5 -mm diameter circular collimator. Bulk RNA -sequencing was performed on nonirradiated samples, as well as apexes treated with F-PRT or S-PRT, at 2 weeks after a single 40 Gy dose. In flammatory responses were assessed through multiplex cytokine/chemokine microbead assay and immunofluorescence analyses. Levels of perivascular fibrosis were quantified using Masson ' s Trichrome and Picrosirius red staining. Additionally, cardiac tissue functionality was evaluated by 2 -dimensional echocardiograms at 8- and 30 -weeks post-PRT. Results: Radiation damage was specifically localized to the heart ' s apex. RNA pro fi ling of cardiac tissues treated with PRT revealed that S-PRT uniquely upregulated pathways associated with DNA damage response, induction of tumor necrosis factor superfamily, and in flammatory response, and F-PRT primarily affected cytoplasmic translation, mitochondrion organization, and adenosine triphosphate synthesis. Notably, F-PRT led to a milder in fl ammatory response, accompanied by signi fi cantly attenuated changes in transforming growth factor 0 1 and a smooth muscle actin levels. Critically, F-PRT decreased collagen deposition and better preserved cardiac functionality compared with S-PRT. Conclusions: This study demonstrated that F-PRT reduces the induction of an in flammatory environment with lower expression of in flammatory cytokines and pro fibrotic factors. Importantly, the results indicate that F-PRT better preserves cardiac functionality, as con firmed by echocardiography analysis, while also mitigating the development of long-term fibrosis. (c) 2024 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY -NC -ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/)",0360-3016,1879-355X,,1234-1247, ,  ,,out_of_scope,
2631,"**Title**Recent trends and sources of lead toxicity: a review of state-of-the-art nano-remediation strategies

**Abstract**Lead (Pb) toxicity remains a significant environmental and public health concern worldwide, with diverse sources contributing to its pervasive presence in soil, water, and air. This review critically examines recent trends and emerging sources of Pb contamination, encompassing industrial activities, urbanization, agricultural practices, and legacy pollution. Understanding the dynamic interplay between these sources is crucial for planning effective remediation strategies and mitigating Pb exposure risks. Given the complex challenges posed by Pb contamination, nano-remediation has emerged as a promising approach, leveraging the unique properties of nanomaterials to remediate Pb-contaminated environments efficiently. This review provides a comprehensive overview of state-of-the-art nano-remediation strategies for addressing Pb toxicity, including nano-scale zero-valent iron (nZVI), carbon-based nanomaterials, metal-oxide nanoparticles, and polymer-based nano-adsorbents. Key advancements in the design, synthesis, and application of these nanomaterials are discussed, along with their mechanisms of action and environmental implications. Furthermore, recent trends in nano-remediation research, such as the integration of nanotechnology with phytoremediation and nano-enabled soil amendments, are explored. This review underscores the urgent need for interdisciplinary collaboration and innovation in Pb remediation, emphasizing the importance of integrating cutting-edge nano-remediation strategies with holistic environmental management approaches. Future research should focus on optimizing the performance and cost-effectiveness of nano-remediation techniques, assessing long-term environmental impacts, and developing standardized protocols for large-scale implementation. By addressing the root causes of Pb contamination and harnessing the transformative potential of nanotechnology, we could pave the way toward a sustainable and Pb-free future for generations to come.","Ali, Sajid; Naseer, Sidra; Rehman, Muzammal; Wei, Zhenggui",,,Recent trends and sources of lead toxicity: a review of state-of-the-art nano-remediation strategies,26,7,10.1007/s11051-024-06081-5 ,Review ,,"Lead (Pb) toxicity remains a significant environmental and public health concern worldwide, with diverse sources contributing to its pervasive presence in soil, water, and air. This review critically examines recent trends and emerging sources of Pb contamination, encompassing industrial activities, urbanization, agricultural practices, and legacy pollution. Understanding the dynamic interplay between these sources is crucial for planning effective remediation strategies and mitigating Pb exposure risks. Given the complex challenges posed by Pb contamination, nano-remediation has emerged as a promising approach, leveraging the unique properties of nanomaterials to remediate Pb-contaminated environments efficiently. This review provides a comprehensive overview of state-of-the-art nano-remediation strategies for addressing Pb toxicity, including nano-scale zero-valent iron (nZVI), carbon-based nanomaterials, metal-oxide nanoparticles, and polymer-based nano-adsorbents. Key advancements in the design, synthesis, and application of these nanomaterials are discussed, along with their mechanisms of action and environmental implications. Furthermore, recent trends in nano-remediation research, such as the integration of nanotechnology with phytoremediation and nano-enabled soil amendments, are explored. This review underscores the urgent need for interdisciplinary collaboration and innovation in Pb remediation, emphasizing the importance of integrating cutting-edge nano-remediation strategies with holistic environmental management approaches. Future research should focus on optimizing the performance and cost-effectiveness of nano-remediation techniques, assessing long-term environmental impacts, and developing standardized protocols for large-scale implementation. By addressing the root causes of Pb contamination and harnessing the transformative potential of nanotechnology, we could pave the way toward a sustainable and Pb-free future for generations to come.",1388-0764,1572-896X,,, ,  ,,out_of_scope,
2632,"**Title**Advancing Antimicrobial Textiles: A Comprehensive Study on Combating ESKAPE Pathogens and Ensuring User Safety

**Abstract**Antibiotic-resistant bacteria, ESKAPE pathogens, present a significant and alarming threat to public health and healthcare systems. This study addresses the urgent need to combat antimicrobial resistance by exploring alternative ways to reduce the health and cost implications of infections caused by these pathogens. To disrupt their transmission, integrating antimicrobial textiles into personal protective equipment (PPE) is an encouraging avenue. Nevertheless, ensuring the effectiveness and safety of these textiles remains a persistent challenge. To achieve this, we conduct a comprehensive study that systematically compares the effectiveness and potential toxicity of five commonly used antimicrobial agents. To guide decision making, a MULTIMOORA method is employed to select and rank the optimal antimicrobial textile finishes. Through this approach, we determine that silver nitrate is the most suitable choice, while a methoxy-terminated quaternary ammonium compound is deemed less favorable in meeting the desired criteria. The findings of this study offer valuable insights and guidelines for the development of antimicrobial textiles that effectively address the requirements of effectiveness, safety, and durability. Implementing these research outcomes within the textile industry can significantly enhance protection against microbial infections, contribute to the improvement of public health, and mitigate the spread of infectious diseases.","Vojnits, Kinga; Mohseni, Majid; Gashti, Mazeyar Parvinzadeh; Nadaraja, Anupama Vijaya; Karimianghadim, Ramin; Crowther, Ben; Field, Brad; Golovin, Kevin; Pakpour, Sepideh",,"Parvinzadeh Gashti, Mazeyar/0000-0001-6584-4827; Golovin, Kevin/0000-0001-8309-7458",Advancing Antimicrobial Textiles: A Comprehensive Study on Combating ESKAPE Pathogens and Ensuring User Safety,17,2,10.3390/ma17020383 ,Article ,,"Antibiotic-resistant bacteria, ESKAPE pathogens, present a significant and alarming threat to public health and healthcare systems. This study addresses the urgent need to combat antimicrobial resistance by exploring alternative ways to reduce the health and cost implications of infections caused by these pathogens. To disrupt their transmission, integrating antimicrobial textiles into personal protective equipment (PPE) is an encouraging avenue. Nevertheless, ensuring the effectiveness and safety of these textiles remains a persistent challenge. To achieve this, we conduct a comprehensive study that systematically compares the effectiveness and potential toxicity of five commonly used antimicrobial agents. To guide decision making, a MULTIMOORA method is employed to select and rank the optimal antimicrobial textile finishes. Through this approach, we determine that silver nitrate is the most suitable choice, while a methoxy-terminated quaternary ammonium compound is deemed less favorable in meeting the desired criteria. The findings of this study offer valuable insights and guidelines for the development of antimicrobial textiles that effectively address the requirements of effectiveness, safety, and durability. Implementing these research outcomes within the textile industry can significantly enhance protection against microbial infections, contribute to the improvement of public health, and mitigate the spread of infectious diseases.",,1996-1944,,, ,  ,,out_of_scope,
2633,"**Title**Selenium dynamics in plants: Uptake, transport, toxicity, and sustainable management strategies

**Abstract**Selenium (Se) plays crucial roles in human, animal, and plant physiology, but its varied plant functions remain complex and not fully understood. While Se deficiency affects over a billion people worldwide, excessive Se levels can be toxic, presenting substantial risks to ecosystem health and public safety. The delicate balance between Se's beneficial and harmful effects necessitates a deeper understanding of its speciation dynamics and how different organisms within ecosystems respond to Se. Since humans primarily consume Se through Se-rich foods, exploring Se's behavior, uptake, and transport within agroecosystems is critical to creating effective management strategies. Traditional physicochemical methods for Se remediation are often expensive and potentially harmful to the environment, pushing the need for more sustainable solutions. In recent years, phytotechnologies have gained traction as a promising approach to Se management by harnessing plants' natural abilities to absorb, accumulate, metabolize, and volatilize Se. These strategies range from boosting Se uptake and tolerance in plants to releasing Se as less toxic volatile compounds or utilizing it as a biofortified supplement, opening up diverse possibilities for managing Se, offering sustainable pathways to improve crop nutritional quality, and protecting human health in different environmental contexts. However, closing the gaps in our understanding of Se dynamics within agricultural systems calls for a united front of interdisciplinary collaboration from biology to environmental science, agriculture, and public health, which has a crucial role to play. Phytotechnologies offer a sustainable bridge between Se deficiency and toxicity, but further research is needed to optimize these methods and explore their potential in various agricultural and environmental settings. By shedding light on Se's multifaceted roles and refining management strategies, this review contributes to developing cost-effective and eco-friendly approaches for Se management in agroecosystems. It aims to lead the way toward a healthier and more sustainable future by balancing the need to address Se deficiency and mitigate the risks of Se toxicity.","Somagattu, Prapooja; Chinnannan, Karthik; Yammanuru, Hyndavi; Reddy, Umesh K.; Nimmakayala, Padma",,,"Selenium dynamics in plants: Uptake, transport, toxicity, and sustainable management strategies",949,,10.1016/j.scitotenv.2024.175033 ,Article ,,"Selenium (Se) plays crucial roles in human, animal, and plant physiology, but its varied plant functions remain complex and not fully understood. While Se deficiency affects over a billion people worldwide, excessive Se levels can be toxic, presenting substantial risks to ecosystem health and public safety. The delicate balance between Se's beneficial and harmful effects necessitates a deeper understanding of its speciation dynamics and how different organisms within ecosystems respond to Se. Since humans primarily consume Se through Se-rich foods, exploring Se's behavior, uptake, and transport within agroecosystems is critical to creating effective management strategies. Traditional physicochemical methods for Se remediation are often expensive and potentially harmful to the environment, pushing the need for more sustainable solutions. In recent years, phytotechnologies have gained traction as a promising approach to Se management by harnessing plants' natural abilities to absorb, accumulate, metabolize, and volatilize Se. These strategies range from boosting Se uptake and tolerance in plants to releasing Se as less toxic volatile compounds or utilizing it as a biofortified supplement, opening up diverse possibilities for managing Se, offering sustainable pathways to improve crop nutritional quality, and protecting human health in different environmental contexts. However, closing the gaps in our understanding of Se dynamics within agricultural systems calls for a united front of interdisciplinary collaboration from biology to environmental science, agriculture, and public health, which has a crucial role to play. Phytotechnologies offer a sustainable bridge between Se deficiency and toxicity, but further research is needed to optimize these methods and explore their potential in various agricultural and environmental settings. By shedding light on Se's multifaceted roles and refining management strategies, this review contributes to developing cost-effective and eco-friendly approaches for Se management in agroecosystems. It aims to lead the way toward a healthier and more sustainable future by balancing the need to address Se deficiency and mitigate the risks of Se toxicity.",0048-9697,1879-1026,,, ,  ,,out_of_scope,
2634,"**Title**CivilityCheck: An Integrated Natural Language Processing and Machine Learning Framework to Detect Hateful and Offensive Language

**Abstract**The proliferation of hate speech and offensive language in online communities has escalated into a significant societal concern, prompting an urgent demand for robust tools capable of automatically identifying and addressing such content. Introducing CivilityCheck, a comprehensive framework that seamlessly integrates Natural Language Processing (NLP) and Machine Learning (ML) methodologies to uncover instances of hate speech and offensiveness within online discourse. Utilizing logistic regression models trained on Twitter datasets, CivilityCheck demonstrates remarkable efficacy, achieving a notable test accuracy of 95.4%. Moreover, the proposed framework extends its functionality into a user-friendly web browser extension, facilitating real-time analysis of social media content to cultivate a safer online environment. By endowing users with the capability to promptly identify and address toxic language, CivilityCheck contributes significantly to the propagation of civility and respect in digital interactions. This innovative solution stands at the forefront of combating online toxicity, offering a potent means to foster constructive dialogue and mitigate the harmful effects of coarse and regressive language usage on digital platforms.","Bonthu, Bhulakshmi; Abhay, Potluri; Gottipati, Likitha Sai; Vamsi, Gangisetty Krishna",,,CivilityCheck: An Integrated Natural Language Processing and Machine Learning Framework to Detect Hateful and Offensive Language,,,10.1109/ICSCSS60660.2024.10625318 ,Proceedings Paper ,,"The proliferation of hate speech and offensive language in online communities has escalated into a significant societal concern, prompting an urgent demand for robust tools capable of automatically identifying and addressing such content. Introducing CivilityCheck, a comprehensive framework that seamlessly integrates Natural Language Processing (NLP) and Machine Learning (ML) methodologies to uncover instances of hate speech and offensiveness within online discourse. Utilizing logistic regression models trained on Twitter datasets, CivilityCheck demonstrates remarkable efficacy, achieving a notable test accuracy of 95.4%. Moreover, the proposed framework extends its functionality into a user-friendly web browser extension, facilitating real-time analysis of social media content to cultivate a safer online environment. By endowing users with the capability to promptly identify and address toxic language, CivilityCheck contributes significantly to the propagation of civility and respect in digital interactions. This innovative solution stands at the forefront of combating online toxicity, offering a potent means to foster constructive dialogue and mitigate the harmful effects of coarse and regressive language usage on digital platforms.",,,979-8-3503-9155-8; 979-8-3503-7999-0,985-988, , 2nd International Conference on Sustainable Computing and Smart Systems (ICSCSS)2nd International Conference on Sustainable Computing and Smart Systems (ICSCSS) ,,out_but_toxicity,
2635,"**Title**Assessing groundwater fluoride contamination scenario in West Bengal, India: A combined approach using meta-analysis, current research, and health risk evaluation

**Abstract**The present study was initiated by the findings of a comprehensive systematic review and meta-analysis, which synthesized all available literature on the patterns and trends of groundwater fluoride (F-) contamination in West Bengal, India. This investigation aimed to provide detailed information on F- contamination at the block level within the state, which is essential for effective monitoring and alleviation efforts addressing the acute and evolving human health concerns in affected areas. This study focuses on the six districts (South 24 Parganas, West Medinipur, Jhargram, East Bardhaman, West Bardhaman and Murshidabad) of West Bengal. Findings from more than 3000 datasets revealed that approximately 10%, 11%, 4%, and 14% of groundwater samples exceeded the safe limit of F- (1.5 mgL(-1)) from South 24 Parganas, Jhargram, West Bardhaman, and Murshidabad district, respectively. Notably 3% of samples from West Bardhaman displayed class V toxicity where F- concentrations exceeding >10 mgL(-1). This research introduces an initial assessment of F- concentrations in groundwater from nine newly identified F- contaminated blocks (Baruipur, Sonarpur, Binpur II, Salanpur, Baraboni, Jamuriya, Pandabeswar, Kandi and Khargram) within the region. Overall, 65 blocks from ten districts have been recognized as F- contaminated zones in West Bengal till 2023. The non-cancerous health risk was found to be disproportionately higher in the western districts (Jhargram, West Bardhaman, and western part of Murshidabad) compared to their southeastern counterparts (East Bardhaman, Paschim Medinipur, and South 24 Parganas). A demographic analysis of health risk indicated infants as the most susceptible group to F- toxicity. The probabilistic health risk at P95 dose for eight blocks further corroborated the heightened vulnerability of infants. These insights offer critical implications for the policy-makers, suggesting an urgent need for tailored health policies to mitigate the risk associated with F- contamination in West Bengal.","De, Ayan; Ghosh, Swetanjana; Dey, Archita; Islam, Kazi Hamidul; Maji, Krishnendu; Mandal, Jajati; Das, Bilash Chandra; Roychowdhury, Tarit","Mandal, Dr. Jajati/V-7490-2019","KHAN, Dr. ULFAT/0000-0003-3234-293X; Islam, Kazi Hamidul/0000-0003-0888-5811; Roychowdhury, Tarit/0000-0001-6515-5634","Assessing groundwater fluoride contamination scenario in West Bengal, India: A combined approach using meta-analysis, current research, and health risk evaluation",26,,10.1016/j.gsd.2024.101286 ,Article ,,"The present study was initiated by the findings of a comprehensive systematic review and meta-analysis, which synthesized all available literature on the patterns and trends of groundwater fluoride (F-) contamination in West Bengal, India. This investigation aimed to provide detailed information on F- contamination at the block level within the state, which is essential for effective monitoring and alleviation efforts addressing the acute and evolving human health concerns in affected areas. This study focuses on the six districts (South 24 Parganas, West Medinipur, Jhargram, East Bardhaman, West Bardhaman and Murshidabad) of West Bengal. Findings from more than 3000 datasets revealed that approximately 10%, 11%, 4%, and 14% of groundwater samples exceeded the safe limit of F- (1.5 mgL(-1)) from South 24 Parganas, Jhargram, West Bardhaman, and Murshidabad district, respectively. Notably 3% of samples from West Bardhaman displayed class V toxicity where F- concentrations exceeding >10 mgL(-1). This research introduces an initial assessment of F- concentrations in groundwater from nine newly identified F- contaminated blocks (Baruipur, Sonarpur, Binpur II, Salanpur, Baraboni, Jamuriya, Pandabeswar, Kandi and Khargram) within the region. Overall, 65 blocks from ten districts have been recognized as F- contaminated zones in West Bengal till 2023. The non-cancerous health risk was found to be disproportionately higher in the western districts (Jhargram, West Bardhaman, and western part of Murshidabad) compared to their southeastern counterparts (East Bardhaman, Paschim Medinipur, and South 24 Parganas). A demographic analysis of health risk indicated infants as the most susceptible group to F- toxicity. The probabilistic health risk at P95 dose for eight blocks further corroborated the heightened vulnerability of infants. These insights offer critical implications for the policy-makers, suggesting an urgent need for tailored health policies to mitigate the risk associated with F- contamination in West Bengal.",2352-801X,,,, ,  ,,out_of_scope,
2636,"**Title**Co-application of biochar and plant growth regulators improves maize growth and decreases Cd accumulation in cadmium-contaminated soil

**Abstract**To ensure the sustainable cultivation of agronomic crops in agricultural soils polluted with cadmium (Cd), the integrated application of Cd-remediation strategies at edaphic and foliar levels has been examined. However, the integrated application of biochar (BC) and plant growth regulators (PGRs) for mitigating Cd stress, especially in maize, remains unexplored. Additionally, the expression patterns of PGRs and heavy metal transporters during Cd stress are unknown. To address these gaps, a pot experiment (having four replications) was performed to explore the potential effects of the integrated application of BC (B0 = no BC added; B1 = low BC at 2.5% w/w; and B2 = high BC at 5% w/w) and PGRs (H0 = control; WS = water spray; GA = gibberellin, and IAA = auxin) on maize growth, Cd remediation, and productivity. The study was conducted following a factorial completely randomized design. The pots were artificially spiked with Cd (30 ppm) by using Cd(NO3)2 as a source. The synergistic application of IAA/GA and BC, improved the morphological characteristics, photosynthetic activity, stomatal conductance, and catalase activity of maize under Cd stress while simultaneously decreasing electrolyte leakage and oxidant activity. The leaf area, shoot fresh biomass (SFB), and root fresh biomass (RFB), were increased by (13.4, 11.7%), (52.8, 39.3%), and (89.2, 74.3%) in the synergistic application of PGRs (i.e., IAA and GA) + BC (5% w/w) treatments, respectively, than control. Furthermore, a drastic reduction in Cd uptake was observed in maize leaves by (201.53, 179.24%) under the dual application of PGRs + BC (5% w/w) treatments, compared to control, which altered Cd bioconcentration in plant parts and modified Cd species in the soil. Decreased expression of heavy metal transporter PMPCB gene and YCF1 indicated reduced Cd uptake in 5% w/w BC based on RT-PCR quantification. The synergistic application of BC with PGRs can serve as an environmentally friendly remediation to mitigate the hazardous effects of Cd stress on cultivated maize. This was achieved by reducing the bio-concentration and metal transport coefficients of Cd in plants through BC's absorption properties. Overall, applying BC and foliar application of PGRs could be suggested as a sustainable approach for cultivating crops on Cd-contaminated soils while ensuring safety.","Haider, Fasih Ullah; Noor-ul-Ain; Khan, Imran; Farooq, Muhammad; Habiba; Cai, Liqun; Li, Yuelin","Muhammad, Farooq/KMY-9001-2024; HABIBA, HABIBA/ISU-8139-2023; Khan, Imran/AAW-3795-2020; Li, Yuelin/GSM-7921-2022",", HABIBA/0009-0002-8819-2432; Li, Yuelin/0000-0002-4707-9954",Co-application of biochar and plant growth regulators improves maize growth and decreases Cd accumulation in cadmium-contaminated soil,440,,10.1016/j.jclepro.2023.140515 ,Article ,,"To ensure the sustainable cultivation of agronomic crops in agricultural soils polluted with cadmium (Cd), the integrated application of Cd-remediation strategies at edaphic and foliar levels has been examined. However, the integrated application of biochar (BC) and plant growth regulators (PGRs) for mitigating Cd stress, especially in maize, remains unexplored. Additionally, the expression patterns of PGRs and heavy metal transporters during Cd stress are unknown. To address these gaps, a pot experiment (having four replications) was performed to explore the potential effects of the integrated application of BC (B0 = no BC added; B1 = low BC at 2.5% w/w; and B2 = high BC at 5% w/w) and PGRs (H0 = control; WS = water spray; GA = gibberellin, and IAA = auxin) on maize growth, Cd remediation, and productivity. The study was conducted following a factorial completely randomized design. The pots were artificially spiked with Cd (30 ppm) by using Cd(NO3)2 as a source. The synergistic application of IAA/GA and BC, improved the morphological characteristics, photosynthetic activity, stomatal conductance, and catalase activity of maize under Cd stress while simultaneously decreasing electrolyte leakage and oxidant activity. The leaf area, shoot fresh biomass (SFB), and root fresh biomass (RFB), were increased by (13.4, 11.7%), (52.8, 39.3%), and (89.2, 74.3%) in the synergistic application of PGRs (i.e., IAA and GA) + BC (5% w/w) treatments, respectively, than control. Furthermore, a drastic reduction in Cd uptake was observed in maize leaves by (201.53, 179.24%) under the dual application of PGRs + BC (5% w/w) treatments, compared to control, which altered Cd bioconcentration in plant parts and modified Cd species in the soil. Decreased expression of heavy metal transporter PMPCB gene and YCF1 indicated reduced Cd uptake in 5% w/w BC based on RT-PCR quantification. The synergistic application of BC with PGRs can serve as an environmentally friendly remediation to mitigate the hazardous effects of Cd stress on cultivated maize. This was achieved by reducing the bio-concentration and metal transport coefficients of Cd in plants through BC's absorption properties. Overall, applying BC and foliar application of PGRs could be suggested as a sustainable approach for cultivating crops on Cd-contaminated soils while ensuring safety.",0959-6526,1879-1786,,, ,  ,,out_of_scope,
2637,"**Title**Modifying national industrial structure for reducing heavy metals in China: A nexus-based multi-objective optimization approach

**Abstract**Heavy metals (HMs) exhibit significant toxicity and can lead to a range of health issues. Certain HMs share common emission sources, necessitating an exploration of the nexus among various HMs for achieving collaborative reductions. Considering the efficacy and feasibility of industrial modification to environmental pressures, this paper proposes a novel nexus-based optimization approach based on nexus analysis, multi-region inputoutput (MRIO) table, and multi-objective optimization to mitigate atmospheric HMs. The atmospheric HM emission inventory in 2017 is first compiled. Subsequently, the Integrated Nexus Strength of HMs Risk (HMR-INS) is proposed and employed to determine the range of sectoral output variations. Finally, a multi-objective optimization approach is employed based on the MRIO table in 2017. Compared with the traditional optimization method, the proposed approach performs better regarding HM-related risks and total output, leading to a 1.9 million tons increase in reduction on HM-related risks and a 1.37 trillion yuan increment in total output. Some further analyses are also given to provide feasible solutions for industrial modification, which considers both the economic efficiency and the stability of the industrial structure.","Yang, Guangfei; Guo, Zitong; Wu, Wenjun","wenjun, wu/ABI-4150-2020",,Modifying national industrial structure for reducing heavy metals in China: A nexus-based multi-objective optimization approach,912,,10.1016/j.scitotenv.2023.169478 ,Article ,,"Heavy metals (HMs) exhibit significant toxicity and can lead to a range of health issues. Certain HMs share common emission sources, necessitating an exploration of the nexus among various HMs for achieving collaborative reductions. Considering the efficacy and feasibility of industrial modification to environmental pressures, this paper proposes a novel nexus-based optimization approach based on nexus analysis, multi-region inputoutput (MRIO) table, and multi-objective optimization to mitigate atmospheric HMs. The atmospheric HM emission inventory in 2017 is first compiled. Subsequently, the Integrated Nexus Strength of HMs Risk (HMR-INS) is proposed and employed to determine the range of sectoral output variations. Finally, a multi-objective optimization approach is employed based on the MRIO table in 2017. Compared with the traditional optimization method, the proposed approach performs better regarding HM-related risks and total output, leading to a 1.9 million tons increase in reduction on HM-related risks and a 1.37 trillion yuan increment in total output. Some further analyses are also given to provide feasible solutions for industrial modification, which considers both the economic efficiency and the stability of the industrial structure.",0048-9697,1879-1026,,, ,  ,,out_of_scope,
2638,"**Title**Molecular insights reveal how the glycolipids in cell membrane mitigates nanomaterial's invasion

**Abstract**Nanomaterial-cellular membrane interaction is crucial for the cytotoxicity of such materials in theoretical investigations. However, previous research often used cellular membrane models with one or few lipid types, which deviates significantly from realistic membrane compositions. Here, employing molecular dynamics (MD) simulations, we investigate the impact of a typical nanomaterial, boron nitride (BN), on a cellular membrane model based on the realistic small intestinal epithelial cell (SIEC) membrane. This membrane contains a complex composition, including abundant glycolipids. Our MD simulations reveal that BN nanosheet can partially insert into the SIEC membrane, maintaining a stable binding conformation without causing obvious structural changes. Dynamic analyses suggest that van der Waals (vdW) interactions drive the binding process between BN and the SIEC membrane. Further simulation of the interaction between BN nanosheet and deglycosylated SIEC membrane confirms that BN nanosheet cause significant structural damage to deglycosylated SIEC membranes, completely inserting into the membrane, extracting lipids, and burying some lipid hydrophilic heads within the membrane interior. Quantitative analyses of mean squared displacements (MSD) of membranes, membrane thicknesses, area per lipid, and order parameters indicate that BN nanosheet causes more substantial damage to deglycosylated SIEC membrane than to intact SIEC membrane. This comparison suggests the molecular mechanism involved in mitigating BN invasion by SIEC membrane that the polysaccharide heads of glycolipids in the SIEC membrane form a significant steric hindrance on membrane surface, not only hindering the insertion of BN, but also resisting the lipid extraction by BN. Free energy calculations further support this conclusion. Overall, our MD simulations not only shed new light into the reduced impact of BN nanosheet on the realistic SIEC membrane but also highlight the importance of glycolipids in protecting cell membranes from nanomaterial invasion, contributing to a deeper understanding of nanomaterial-realistic cell membrane interactions.","Luo, Yuqi; Gu, Zonglin; Yin, Xiuhua",,"Gu, Zonglin/0000-0001-7822-5857",Molecular insights reveal how the glycolipids in cell membrane mitigates nanomaterial's invasion,360,,10.1016/j.envpol.2024.124678 ,Article ,,"Nanomaterial-cellular membrane interaction is crucial for the cytotoxicity of such materials in theoretical investigations. However, previous research often used cellular membrane models with one or few lipid types, which deviates significantly from realistic membrane compositions. Here, employing molecular dynamics (MD) simulations, we investigate the impact of a typical nanomaterial, boron nitride (BN), on a cellular membrane model based on the realistic small intestinal epithelial cell (SIEC) membrane. This membrane contains a complex composition, including abundant glycolipids. Our MD simulations reveal that BN nanosheet can partially insert into the SIEC membrane, maintaining a stable binding conformation without causing obvious structural changes. Dynamic analyses suggest that van der Waals (vdW) interactions drive the binding process between BN and the SIEC membrane. Further simulation of the interaction between BN nanosheet and deglycosylated SIEC membrane confirms that BN nanosheet cause significant structural damage to deglycosylated SIEC membranes, completely inserting into the membrane, extracting lipids, and burying some lipid hydrophilic heads within the membrane interior. Quantitative analyses of mean squared displacements (MSD) of membranes, membrane thicknesses, area per lipid, and order parameters indicate that BN nanosheet causes more substantial damage to deglycosylated SIEC membrane than to intact SIEC membrane. This comparison suggests the molecular mechanism involved in mitigating BN invasion by SIEC membrane that the polysaccharide heads of glycolipids in the SIEC membrane form a significant steric hindrance on membrane surface, not only hindering the insertion of BN, but also resisting the lipid extraction by BN. Free energy calculations further support this conclusion. Overall, our MD simulations not only shed new light into the reduced impact of BN nanosheet on the realistic SIEC membrane but also highlight the importance of glycolipids in protecting cell membranes from nanomaterial invasion, contributing to a deeper understanding of nanomaterial-realistic cell membrane interactions.",0269-7491,1873-6424,,, ,  ,,out_of_scope,
2639,"**Title**Microalgae potential to protect from heavy metals-induced carcinogenicity

**Abstract**Toxic elements are present naturally in the environment; however, during the last century, their level has been continuously rising in the air, water, and soil due to anthropogenic activities, including urban runoff, pesticides and fertilizers, industrial effluents, and vehicle emissions. Once released in the environment, they are extremely stable, and therefore humans can get in contact with them through different routes of exposure. In addition, because of their toxicities, they are increasingly threatening human health. Exposure to toxic elements such as heavy metals (HMs) might contribute to the onset of disorders through their ability to generate reactive oxygen species (ROS), which are involved in cell macromolecule injuries. Moreover, several heavy metals (arsenic (As), cadmium (Cd), nickel (Ni), chromium (Cr), and beryllium (Be)) are classified by the International Agency for Research on Cancer as group one carcinogens and can induce different types of cancer through various and heterogeneous mechanisms. Therefore, a better understanding of heavy metals etiopathogenesis in cancer development and the identification of new bioactive products to prevent heavy metal carcinogenicity is warranted. Microalgae, known for their wide range of biological activities, could possess a promising metalloprotective effect against heavy metal-induced carcinogenicity. This protective effect is mainly attributed to their antioxidant and anti-cancer capacities as well as their heavy metal chelating potential. This review discusses the mechanisms implicated in heavy metal carcinogenicity. In addition, a deep understanding of microalgae's mitigating roles and strategies against heavy metal carcinogenicity are reviewed.","Hamai-Amara, Hadjira; Abou-Saleh, Haissam; Al-Ghouti, Mohammad A.; Crovella, Sergio; Saadaoui, Imen; Soubra, Lama","Crovella, Sergio/LUZ-5866-2024; Saadaoui, Imen/AAX-6658-2020",,Microalgae potential to protect from heavy metals-induced carcinogenicity,78,,10.1016/j.algal.2024.103411 ,Review ,,"Toxic elements are present naturally in the environment; however, during the last century, their level has been continuously rising in the air, water, and soil due to anthropogenic activities, including urban runoff, pesticides and fertilizers, industrial effluents, and vehicle emissions. Once released in the environment, they are extremely stable, and therefore humans can get in contact with them through different routes of exposure. In addition, because of their toxicities, they are increasingly threatening human health. Exposure to toxic elements such as heavy metals (HMs) might contribute to the onset of disorders through their ability to generate reactive oxygen species (ROS), which are involved in cell macromolecule injuries. Moreover, several heavy metals (arsenic (As), cadmium (Cd), nickel (Ni), chromium (Cr), and beryllium (Be)) are classified by the International Agency for Research on Cancer as group one carcinogens and can induce different types of cancer through various and heterogeneous mechanisms. Therefore, a better understanding of heavy metals etiopathogenesis in cancer development and the identification of new bioactive products to prevent heavy metal carcinogenicity is warranted. Microalgae, known for their wide range of biological activities, could possess a promising metalloprotective effect against heavy metal-induced carcinogenicity. This protective effect is mainly attributed to their antioxidant and anti-cancer capacities as well as their heavy metal chelating potential. This review discusses the mechanisms implicated in heavy metal carcinogenicity. In addition, a deep understanding of microalgae's mitigating roles and strategies against heavy metal carcinogenicity are reviewed.",2211-9264,,,, ,  ,,out_of_scope,
2640,"**Title**On Antimicrobial Polymers: Development, Mechanism of Action, International Testing Procedures, and Applications

**Abstract**The development of antimicrobial polymeric materials has evolved into one of the more promising methods for preventing the growth of microbes and mitigating the spread of infectious diseases in several applications including the health and food packaging sectors. The outbreak of global pandemics, and particularly the recent COVID-19 pandemic, further strengthen the importance of developing such solutions. This review paper presents a fundamental understanding of how antimicrobial polymers are developed, describes the possible surface modification approaches to render polymers with antimicrobial properties, highlights the potential mechanism of action against a range of microorganisms (bacterial, viral, and fungal), and details some of the international standard protocols and procedures to evaluate the antimicrobial properties of modified materials (such as plastics and textiles). In addition, this review paper discusses the toxicity of antimicrobial additives when used in healthcare and food packaging applications.","Alkarri, Saleh; Bin Saad, Hawra; Soliman, Maria",,"Alkarri, Saleh/0009-0003-3549-9585","On Antimicrobial Polymers: Development, Mechanism of Action, International Testing Procedures, and Applications",16,6,10.3390/polym16060771 ,Review ,,"The development of antimicrobial polymeric materials has evolved into one of the more promising methods for preventing the growth of microbes and mitigating the spread of infectious diseases in several applications including the health and food packaging sectors. The outbreak of global pandemics, and particularly the recent COVID-19 pandemic, further strengthen the importance of developing such solutions. This review paper presents a fundamental understanding of how antimicrobial polymers are developed, describes the possible surface modification approaches to render polymers with antimicrobial properties, highlights the potential mechanism of action against a range of microorganisms (bacterial, viral, and fungal), and details some of the international standard protocols and procedures to evaluate the antimicrobial properties of modified materials (such as plastics and textiles). In addition, this review paper discusses the toxicity of antimicrobial additives when used in healthcare and food packaging applications.",,2073-4360,,, ,  ,,out_of_scope,
2641,"**Title**Structural analysis of ExaC, an NAD plus -dependent aldehyde dehydrogenase, from Pseudomonas aeruginosa

**Abstract**The opportunistic pathogen Pseudomonas aeruginosa (Pa) utilizes ethanol as an energy source, however, ethanol metabolism generates acetaldehyde, a toxic byproduct. To mitigate this toxicity, P. aeruginosa employs aldehyde dehydrogenases (ALDHs) to oxidize acetaldehyde into less harmful compounds. ExaC, an NAD+- dependent ALDH from P. aeruginosa (PaExaC) and a member of group X ALDHs, plays a critical role in this detoxification by oxidizing both aldehydes and hydrazones. In this study, we determined the crystal structures of Pa ExaC in its apo and NAD+-bound forms. Pa ExaC functions as a homodimer, with three distinct domains: an NAD+ binding domain, a catalytic domain, and an oligomerization domain. Structural analyses revealed that Pa ExaC's substrate entry channel (SEC) is optimized for size-selective aldehyde metabolism, with Leu120, Tyr462, and Thr302. Comparative structural and docking analyses with other ALDHs further validated Pa ExaC's preference for small aliphatic aldehydes and hydrazones. These findings highlight Pa ExaC's role in aldehyde detoxification, facilitating P. aeruginosa survival in diverse environments, and provide structural insights for developing targeted inhibitors to help treat infections.","Ko, Ji Hyuk; Jeong, Kang Hwa; Son, Su Bin; Lee, Jae Young",,,"Structural analysis of ExaC, an NAD plus -dependent aldehyde dehydrogenase, from Pseudomonas aeruginosa",742,,10.1016/j.bbrc.2024.151077 ,Article ,,"The opportunistic pathogen Pseudomonas aeruginosa (Pa) utilizes ethanol as an energy source, however, ethanol metabolism generates acetaldehyde, a toxic byproduct. To mitigate this toxicity, P. aeruginosa employs aldehyde dehydrogenases (ALDHs) to oxidize acetaldehyde into less harmful compounds. ExaC, an NAD+- dependent ALDH from P. aeruginosa (PaExaC) and a member of group X ALDHs, plays a critical role in this detoxification by oxidizing both aldehydes and hydrazones. In this study, we determined the crystal structures of Pa ExaC in its apo and NAD+-bound forms. Pa ExaC functions as a homodimer, with three distinct domains: an NAD+ binding domain, a catalytic domain, and an oligomerization domain. Structural analyses revealed that Pa ExaC's substrate entry channel (SEC) is optimized for size-selective aldehyde metabolism, with Leu120, Tyr462, and Thr302. Comparative structural and docking analyses with other ALDHs further validated Pa ExaC's preference for small aliphatic aldehydes and hydrazones. These findings highlight Pa ExaC's role in aldehyde detoxification, facilitating P. aeruginosa survival in diverse environments, and provide structural insights for developing targeted inhibitors to help treat infections.",0006-291X,1090-2104,,, ,  ,,out_of_scope,
2642,"**Title**Particulate matter and nanoplastics: synergistic impact on Artemia salina

**Abstract**Global air pollution presents substantial risks to both human health and the environment. Particulate Matter (PM) adversely affects ecosystems through pollution, bioaccumulation, and endangerment of aquatic organisms. These contaminants enter water systems via precipitation and industrial runoff, damaging aquatic invertebrates through physical, physiological, and molecular mechanisms, leading to developmental issues and organ toxicity. This study investigates the combined toxicological effect of environmental exposure to polystyrene (PS) nanoparticles and varying PM concentrations from indoor and outdoor dust particles on Artemia salina. Our findings reveal noteworthy elevations in reactive oxygen species (ROS) and malondialdehyde (MDA) levels in air conditioner (AC) dust and PM2.5 exposures, highlighting potential health risks associated with high particulate contamination. Conversely, superoxide dismutase (SOD) activity decreased, indicating harm to enzyme systems. In contrast, catalase activity (CAT) increased, suggesting a compensatory response to oxidative stress induced by Polystyrene (PS) and suspended particulate pollutants. These results underscore the severe oxidative stress experienced by marine zooplankton when exposed to PM2.5 combined with NPs, potentially impairing growth. Further research should explore the combined toxicological effects of PM2.5 and NPs on other marine species and investigate long-term exposure effects and bioaccumulation pathways. Understanding these dynamics is crucial for developing effective strategies to mitigate NP pollution and protect human health and aquatic ecosystems.","Gopikrishnan, Mohanraj; Subramanian, Kanimozhi; Krn, Ashwin; Doss, C. George Priya; Srimuruganandam, B.; Chandrasekaran, Natarajan","B, SRIMURUGANANDAM/M-2823-2019; Chandrasekaran, Natarajan/F-2312-2018; B, SRIMURUGANANDAM/K-3617-2017","Chandrasekaran, Natarajan/0000-0002-0586-134X; C, George Priya Doss/0000-0002-5971-8290; Gopikrishnan, Mohanraj/0000-0002-6758-443X; B, SRIMURUGANANDAM/0000-0003-1324-5552; KRN, Ashwin/0000-0001-5544-0319",Particulate matter and nanoplastics: synergistic impact on Artemia salina,4,9,10.1039/d4ea00065j ,Article ,,"Global air pollution presents substantial risks to both human health and the environment. Particulate Matter (PM) adversely affects ecosystems through pollution, bioaccumulation, and endangerment of aquatic organisms. These contaminants enter water systems via precipitation and industrial runoff, damaging aquatic invertebrates through physical, physiological, and molecular mechanisms, leading to developmental issues and organ toxicity. This study investigates the combined toxicological effect of environmental exposure to polystyrene (PS) nanoparticles and varying PM concentrations from indoor and outdoor dust particles on Artemia salina. Our findings reveal noteworthy elevations in reactive oxygen species (ROS) and malondialdehyde (MDA) levels in air conditioner (AC) dust and PM2.5 exposures, highlighting potential health risks associated with high particulate contamination. Conversely, superoxide dismutase (SOD) activity decreased, indicating harm to enzyme systems. In contrast, catalase activity (CAT) increased, suggesting a compensatory response to oxidative stress induced by Polystyrene (PS) and suspended particulate pollutants. These results underscore the severe oxidative stress experienced by marine zooplankton when exposed to PM2.5 combined with NPs, potentially impairing growth. Further research should explore the combined toxicological effects of PM2.5 and NPs on other marine species and investigate long-term exposure effects and bioaccumulation pathways. Understanding these dynamics is crucial for developing effective strategies to mitigate NP pollution and protect human health and aquatic ecosystems.",,2634-3606,,, ,  ,,out_of_scope,
2643,"**Title**Recent advances in nano-fertilizers: synthesis, crop yield impact, and economic analysis

**Abstract**The escalating global demand for food production has predominantly relied on the extensive application of conventional fertilizers (CFs). However, the increased use of CFs has raised concerns regarding environmental risks, including soil and water contamination, especially within cereal-based cropping systems. In response, the agricultural sector has witnessed the emergence of healthier alternatives by utilizing nanotechnology and nano-fertilizers (NFs). These innovative NFs harness the remarkable properties of nanoparticles, ranging in size from 1 to 100 nm, such as nanoclays and zeolites, to enhance nutrient utilization efficiency. Unlike their conventional counterparts, NFs offer many advantages, including variable solubility, consistent and effective performance, controlled release mechanisms, enhanced targeted activity, reduced eco-toxicity, and straightforward and safe delivery and disposal methods. By facilitating rapid and complete plant absorption, NFs effectively conserve nutrients that would otherwise go to waste, mitigating potential environmental harm. Moreover, their superior formulations enable more efficient promotion of sustainable crop growth and production than conventional fertilizers. This review comprehensively examines the global utilization of NFs, emphasizing their immense potential in maintaining environmentally friendly crop output while ensuring agricultural sustainability.The escalating global demand for food production has predominantly relied on the extensive application of conventional fertilizers (CFs).","Channab, Badr-Eddine; EL Idrissi, Ayoub; Ammar, Ayyoub; Dardari, Othmane; Marrane, Salah Eddine; el Gharrak, Abdelouahed; Akil, Adil; Essemlali, Youness; Zahouily, Mohamed","Ammar, Ammar/CAF-7943-2022; EL IDRISSI, Ayoub/ADR-8481-2022; EL GHARRAK, Abdelouahed/ABC-2341-2022; DARDARI, OTHMANE/HJG-5985-2022; CHANNAB, Badr-Eddine/HKN-4189-2023","CHANNAB, Badr-Eddine/0000-0002-4584-2776; Ayyoub, AMMAR/0000-0003-3765-1416; EL IDRISSI, Ayoub/0000-0001-5907-9129","Recent advances in nano-fertilizers: synthesis, crop yield impact, and economic analysis",16,9,10.1039/d3nr05012b ,Review ,,"The escalating global demand for food production has predominantly relied on the extensive application of conventional fertilizers (CFs). However, the increased use of CFs has raised concerns regarding environmental risks, including soil and water contamination, especially within cereal-based cropping systems. In response, the agricultural sector has witnessed the emergence of healthier alternatives by utilizing nanotechnology and nano-fertilizers (NFs). These innovative NFs harness the remarkable properties of nanoparticles, ranging in size from 1 to 100 nm, such as nanoclays and zeolites, to enhance nutrient utilization efficiency. Unlike their conventional counterparts, NFs offer many advantages, including variable solubility, consistent and effective performance, controlled release mechanisms, enhanced targeted activity, reduced eco-toxicity, and straightforward and safe delivery and disposal methods. By facilitating rapid and complete plant absorption, NFs effectively conserve nutrients that would otherwise go to waste, mitigating potential environmental harm. Moreover, their superior formulations enable more efficient promotion of sustainable crop growth and production than conventional fertilizers. This review comprehensively examines the global utilization of NFs, emphasizing their immense potential in maintaining environmentally friendly crop output while ensuring agricultural sustainability.The escalating global demand for food production has predominantly relied on the extensive application of conventional fertilizers (CFs).",2040-3364,2040-3372,,4484-4513, ,  ,,out_of_scope,
2644,"**Title**Polystyrene nanoplastic exposure induces excessive mitophagy by activating AMPK/ULK1 pathway in differentiated SH-SY5Y cells and dopaminergic neurons in vivo

**Abstract**BackgroundMicroplastics and nanoplastics (MNPs) are emerging environmental contaminants detected in human samples, and have raised concerns regarding their potential risks to human health, particularly neurotoxicity. This study aimed to investigate the deleterious effects of polystyrene nanoplastics (PS-NPs, 50 nm) and understand their mechanisms in inducing Parkinson's disease (PD)-like neurodegeneration, along with exploring preventive strategies.MethodsFollowing exposure to PS-NPs (0.5-500 mu g/mL), we assessed cytotoxicity, mitochondrial integrity, ATP levels, and mitochondrial respiration in dopaminergic-differentiated SH-SY5Y cells. Molecular docking and dynamic simulations explored PS-NPs' interactions with mitochondrial complexes. We further probed mitophagy's pivotal role in PS-NP-induced mitochondrial damage and examined melatonin's ameliorative potential in vitro. We validated melatonin's intervention (intraperitoneal, 10 mg/kg/d) in C57BL/6 J mice exposed to 250 mg/kg/d of PS-NPs for 28 days.ResultsIn our in vitro experiments, we observed PS-NP accumulation in cells, including mitochondria, leading to cell toxicity and reduced viability. Notably, antioxidant treatment failed to fully rescue viability, suggesting reactive oxygen species (ROS)-independent cytotoxicity. PS-NPs caused significant mitochondrial damage, characterized by altered morphology, reduced mitochondrial membrane potential, and decreased ATP production. Subsequent investigations pointed to PS-NP-induced disruption of mitochondrial respiration, potentially through interference with complex I (CI), a concept supported by molecular docking studies highlighting the influence of PS-NPs on CI. Rescue experiments using an AMPK pathway inhibitor (compound C) and an autophagy inhibitor (3-methyladenine) revealed that excessive mitophagy was induced through AMPK/ULK1 pathway activation, worsening mitochondrial damage and subsequent cell death in differentiated SH-SY5Y cells. Notably, we identified melatonin as a potential protective agent, capable of alleviating PS-NP-induced mitochondrial dysfunction. Lastly, our in vivo experiments demonstrated that melatonin could mitigate dopaminergic neuron loss and motor impairments by restoring mitophagy regulation in mice.ConclusionsOur study demonstrated that PS-NPs disrupt mitochondrial function by affecting CI, leading to excessive mitophagy through the AMPK/ULK1 pathway, causing dopaminergic neuron death. Melatonin can counteract PS-NP-induced mitochondrial dysfunction and motor impairments by regulating mitochondrial autophagy. These findings offer novel insights into the MNP-induced PD-like neurodegenerative mechanisms, and highlight melatonin's protective potential in mitigating the MNP's environmental risk.","Huang, Yuji; Liang, Boxuan; Li, Zhiming; Zhong, Yizhou; Wang, Bo; Zhang, Bingli; Du, Jiaxin; Ye, Rongyi; Xian, Hongyi; Min, Weicui; Yan, Xiliang; Deng, Yanhong; Feng, Yu; Bai, Ruobing; Fan, Bingchi; Yang, Xingfen; Huang, Zhenlie","Bai, Ruobing/HPE-6299-2023; Du, Jiaxin/LIG-2985-2024; Yan, Xiliang/N-7119-2019; Huang, Zhenlie/AAQ-9970-2020; Hu, man/HPG-9675-2023; YAN, Zheng-Guang/HGC-8374-2022; Liang, Boxuan/GZL-6240-2022; Zhong, Yizhou/HTS-0493-2023","Li, Zhiming/0009-0000-7497-3559; Liang, Boxuan/0000-0001-8223-2419",Polystyrene nanoplastic exposure induces excessive mitophagy by activating AMPK/ULK1 pathway in differentiated SH-SY5Y cells and dopaminergic neurons in vivo,20,1,10.1186/s12989-023-00556-4 ,Article ,,"BackgroundMicroplastics and nanoplastics (MNPs) are emerging environmental contaminants detected in human samples, and have raised concerns regarding their potential risks to human health, particularly neurotoxicity. This study aimed to investigate the deleterious effects of polystyrene nanoplastics (PS-NPs, 50 nm) and understand their mechanisms in inducing Parkinson's disease (PD)-like neurodegeneration, along with exploring preventive strategies.MethodsFollowing exposure to PS-NPs (0.5-500 mu g/mL), we assessed cytotoxicity, mitochondrial integrity, ATP levels, and mitochondrial respiration in dopaminergic-differentiated SH-SY5Y cells. Molecular docking and dynamic simulations explored PS-NPs' interactions with mitochondrial complexes. We further probed mitophagy's pivotal role in PS-NP-induced mitochondrial damage and examined melatonin's ameliorative potential in vitro. We validated melatonin's intervention (intraperitoneal, 10 mg/kg/d) in C57BL/6 J mice exposed to 250 mg/kg/d of PS-NPs for 28 days.ResultsIn our in vitro experiments, we observed PS-NP accumulation in cells, including mitochondria, leading to cell toxicity and reduced viability. Notably, antioxidant treatment failed to fully rescue viability, suggesting reactive oxygen species (ROS)-independent cytotoxicity. PS-NPs caused significant mitochondrial damage, characterized by altered morphology, reduced mitochondrial membrane potential, and decreased ATP production. Subsequent investigations pointed to PS-NP-induced disruption of mitochondrial respiration, potentially through interference with complex I (CI), a concept supported by molecular docking studies highlighting the influence of PS-NPs on CI. Rescue experiments using an AMPK pathway inhibitor (compound C) and an autophagy inhibitor (3-methyladenine) revealed that excessive mitophagy was induced through AMPK/ULK1 pathway activation, worsening mitochondrial damage and subsequent cell death in differentiated SH-SY5Y cells. Notably, we identified melatonin as a potential protective agent, capable of alleviating PS-NP-induced mitochondrial dysfunction. Lastly, our in vivo experiments demonstrated that melatonin could mitigate dopaminergic neuron loss and motor impairments by restoring mitophagy regulation in mice.ConclusionsOur study demonstrated that PS-NPs disrupt mitochondrial function by affecting CI, leading to excessive mitophagy through the AMPK/ULK1 pathway, causing dopaminergic neuron death. Melatonin can counteract PS-NP-induced mitochondrial dysfunction and motor impairments by regulating mitochondrial autophagy. These findings offer novel insights into the MNP-induced PD-like neurodegenerative mechanisms, and highlight melatonin's protective potential in mitigating the MNP's environmental risk.",1743-8977,,,, ,  ,,out_of_scope,
2645,"**Title**Binding of Per- and Polyfluoroalkyl Substances to β-Lactoglobulin from Bovine Milk

**Abstract**Per- and polyfluoroalkyl substances (PFAS) are known for their high environmental persistence and potential toxicity. The presence of PFAS has been reported in many dairy products. However, the mechanisms underlying the accumulation of PFAS in these products remain unclear. Here, we used native mass spectrometry and molecular dynamics simulations to probe the interactions between 19 PFAS of environmental concern and two isoforms of the major bovine whey protein beta-lactoglobulin (beta-LG). We observed that six of these PFAS bound to both protein isoforms with low- to mid-micromolar dissociation constants. Based on quantitative, competitive binding experiments with endogenous ligands, PFAS can bind orthosterically and preferentially to beta-LG's hydrophobic ligand-binding calyx. beta-Cyclodextrin can also suppress binding of PFAS to beta-LG owing to the ability of beta-cyclodextrin to directly sequester PFAS from solution. This research sheds light on PFAS-beta-LG binding, suggesting that such interactions could impact lipid-fatty acid transport in bovine mammary glands at high PFAS concentrations. Furthermore, our results highlight the potential use of beta-cyclodextrin in mitigating PFAS binding, providing insights toward the development of strategies to reduce PFAS accumulation in dairy products and other biological systems.","Pham, P. Chi; Taylor, Mackenzie; Nguyen, Giang T. H.; Beltran, Jeunesse; Bennett, Jack L.; Ho, Junming; Donald, William A.","Ho, Junming/J-9366-2019; Nguyen, D./Q-6703-2017",,Binding of Per- and Polyfluoroalkyl Substances to β-Lactoglobulin from Bovine Milk,37,5,10.1021/acs.chemrestox.4c00021 ,Article ,,"Per- and polyfluoroalkyl substances (PFAS) are known for their high environmental persistence and potential toxicity. The presence of PFAS has been reported in many dairy products. However, the mechanisms underlying the accumulation of PFAS in these products remain unclear. Here, we used native mass spectrometry and molecular dynamics simulations to probe the interactions between 19 PFAS of environmental concern and two isoforms of the major bovine whey protein beta-lactoglobulin (beta-LG). We observed that six of these PFAS bound to both protein isoforms with low- to mid-micromolar dissociation constants. Based on quantitative, competitive binding experiments with endogenous ligands, PFAS can bind orthosterically and preferentially to beta-LG's hydrophobic ligand-binding calyx. beta-Cyclodextrin can also suppress binding of PFAS to beta-LG owing to the ability of beta-cyclodextrin to directly sequester PFAS from solution. This research sheds light on PFAS-beta-LG binding, suggesting that such interactions could impact lipid-fatty acid transport in bovine mammary glands at high PFAS concentrations. Furthermore, our results highlight the potential use of beta-cyclodextrin in mitigating PFAS binding, providing insights toward the development of strategies to reduce PFAS accumulation in dairy products and other biological systems.",0893-228X,1520-5010,,757-770, ,  ,,out_of_scope,
2646,"**Title**Chronic cadmium exposure impairs flight behavior by dampening flight muscle carbon metabolism in bumblebees

**Abstract**Cadmium pollution affects the global ecosystem because cadmium can be transferred up the food chain. The bumblebee, Bombus terrestris, is an important insect pollinator. Their foraging activity on flowers exposes them to harmful heavy metals, which damages their health and leads to massive population declines. However, the effects of chronic exposure to heavy metals on the flight performance of bumblebees have not yet been characterized. Here, we studied variation in the flight capacity of bumblebees induced by chronic cadmium exposure at field -realistic concentrations using behavioral, physiological, and molecular approaches. Chronic cadmium exposure caused a significant reduction in the duration, distance, and mean velocity of bumblebee flight. Transcriptome analysis showed that the impairment of carbon metabolism and mitochondrial dysfunction in the flight muscle were the primary causes. Physiological, biochemical, and metabolomic analyses validated disruptions in energy metabolism, and impairments in mitochondrial respiratory chain complexes activities. Histological analysis revealed muscle fiber damage and mitochondrial loss. Exogenous decanoic acid or citric acid partially restored sustained flight ability of bumblebees by mitigating muscle fiber damage and increasing energy generation. These findings provide insights into how long-term cadmium stress affects the flight ability of insects and will aid human muscle or exercise -related disease research.","Gao, Shen; Zheng, Fei; Yue, Lei; Chen, Bing",,,Chronic cadmium exposure impairs flight behavior by dampening flight muscle carbon metabolism in bumblebees,466,,10.1016/j.jhazmat.2024.133628 ,Article ,,"Cadmium pollution affects the global ecosystem because cadmium can be transferred up the food chain. The bumblebee, Bombus terrestris, is an important insect pollinator. Their foraging activity on flowers exposes them to harmful heavy metals, which damages their health and leads to massive population declines. However, the effects of chronic exposure to heavy metals on the flight performance of bumblebees have not yet been characterized. Here, we studied variation in the flight capacity of bumblebees induced by chronic cadmium exposure at field -realistic concentrations using behavioral, physiological, and molecular approaches. Chronic cadmium exposure caused a significant reduction in the duration, distance, and mean velocity of bumblebee flight. Transcriptome analysis showed that the impairment of carbon metabolism and mitochondrial dysfunction in the flight muscle were the primary causes. Physiological, biochemical, and metabolomic analyses validated disruptions in energy metabolism, and impairments in mitochondrial respiratory chain complexes activities. Histological analysis revealed muscle fiber damage and mitochondrial loss. Exogenous decanoic acid or citric acid partially restored sustained flight ability of bumblebees by mitigating muscle fiber damage and increasing energy generation. These findings provide insights into how long-term cadmium stress affects the flight ability of insects and will aid human muscle or exercise -related disease research.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2647,"**Title**Challenges in moderating disruptive player behavior in online competitive action games

**Abstract**Online competitive action games are a very popular form of entertainment. While most are respectfully enjoyed by millions of players, a small group of players engages in disruptive behavior, such as cheating and hate speech. Identifying and subsequently moderating these toxic players is a challenging task. Previous research has only studied specific aspects of this problem using curated data and with limited access to real-world moderation practices. In contrast, our work offers a unique and holistic view of the universal challenges of moderating disruptive behavior in online systems. We combine an analysis of a large dataset from a popular online competitive first-person action title (Call of Duty (R): Modern Warfare (R) II) with insights from stakeholders involved in moderation. We identify six universal challenges related to handling disruptive behaviors in such games. We discuss challenges omitted by prior work, such as handling high-volume imbalanced data or ensuring the comfort of human moderators. We also offer a discussion of possible technical, design, and policy approaches to mitigating these challenges.","Kocielnik, Rafal; Li, Zhuofang; Kann, Claudia; Sambrano, Deshawn; Morrier, Jacob; Linegar, Mitchell; Taylor, Carly; Kim, Min; Naqvie, Nabiha; Soltani, Feri; Dehpanah, Arman; Cahill, Grant; Anandkumar, Animashree; Alvarez, R. Michael","Linegar, Mitchell/KHY-6717-2024",,Challenges in moderating disruptive player behavior in online competitive action games,6,,10.3389/fcomp.2024.1283735 ,Article ,,"Online competitive action games are a very popular form of entertainment. While most are respectfully enjoyed by millions of players, a small group of players engages in disruptive behavior, such as cheating and hate speech. Identifying and subsequently moderating these toxic players is a challenging task. Previous research has only studied specific aspects of this problem using curated data and with limited access to real-world moderation practices. In contrast, our work offers a unique and holistic view of the universal challenges of moderating disruptive behavior in online systems. We combine an analysis of a large dataset from a popular online competitive first-person action title (Call of Duty (R): Modern Warfare (R) II) with insights from stakeholders involved in moderation. We identify six universal challenges related to handling disruptive behaviors in such games. We discuss challenges omitted by prior work, such as handling high-volume imbalanced data or ensuring the comfort of human moderators. We also offer a discussion of possible technical, design, and policy approaches to mitigating these challenges.",,2624-9898,,, ,  ,,Gen_dataset#detection#methodology,
2648,"**Title**Predicting FFAR4 agonists using structure-based machine learning approach based on molecular fingerprints

**Abstract**Free Fatty Acid Receptor 4 (FFAR4), a G-protein-coupled receptor, is responsible for triggering intracellular signaling pathways that regulate various physiological processes. FFAR4 agonists are associated with enhancing insulin release and mitigating the atherogenic, obesogenic, pro-carcinogenic, and pro-diabetogenic effects, normally associated with the free fatty acids bound to FFAR4. In this research, molecular structure-based machine-learning techniques were employed to evaluate compounds as potential agonists for FFAR4. Molecular structures were encoded into bit arrays, serving as molecular fingerprints, which were subsequently analyzed using the Bayesian network algorithm to identify patterns for screening the data. The shortlisted hits obtained via machine learning protocols were further validated by Molecular Docking and via ADME and Toxicity predictions. The shortlisted compounds were then subjected to MD Simulations of the membrane-bound FFAR4-ligand complexes for 100 ns each. Molecular analyses, encompassing binding interactions, RMSD, RMSF, RoG, PCA, and FEL, were conducted to scrutinize the protein-ligand complexes at the inter-atomic level. The analyses revealed significant interactions of the shortlisted compounds with the crucial residues of FFAR4 previously documented. FFAR4 as part of the complexes demonstrated consistent RMSDs, ranging from 3.57 to 3.64, with minimal residue fluctuations 5.27 to 6.03 nm, suggesting stable complexes. The gyration values fluctuated between 22.8 to 23.5 nm, indicating structural compactness and orderliness across the studied systems. Additionally, distinct conformational motions were observed in each complex, with energy contours shifting to broader energy basins throughout the simulation, suggesting thermodynamically stable protein-ligand complexes. The two compounds CHEMBL2012662 and CHEMBL64616 are presented as potential FFAR4 agonists, based on these insights and in-depth analyses. Collectively, these findings advance our comprehension of FFAR4's functions and mechanisms, highlighting these compounds as potential FFAR4 agonists worthy of further exploration as innovative treatments for metabolic and immune-related conditions.","Sherwani, Zaid Anis; Tariq, Syeda Sumayya; Mushtaq, Mamona; Siddiqui, Ali Raza; Nur-e-Alam, Mohammad; Ahmed, Aftab; Ul-Haq, Zaheer","Nur-e-Alam, Mohammad/GXH-6338-2022; Ul-haq, zaheer/G-6673-2015; siddiqui, ali/JXX-1250-2024","Mushtaq, Mamona/0000-0003-4320-9843; Tariq, Syeda Sumayya/0000-0001-5692-8703",Predicting FFAR4 agonists using structure-based machine learning approach based on molecular fingerprints,14,1,10.1038/s41598-024-60056-z ,Article ,,"Free Fatty Acid Receptor 4 (FFAR4), a G-protein-coupled receptor, is responsible for triggering intracellular signaling pathways that regulate various physiological processes. FFAR4 agonists are associated with enhancing insulin release and mitigating the atherogenic, obesogenic, pro-carcinogenic, and pro-diabetogenic effects, normally associated with the free fatty acids bound to FFAR4. In this research, molecular structure-based machine-learning techniques were employed to evaluate compounds as potential agonists for FFAR4. Molecular structures were encoded into bit arrays, serving as molecular fingerprints, which were subsequently analyzed using the Bayesian network algorithm to identify patterns for screening the data. The shortlisted hits obtained via machine learning protocols were further validated by Molecular Docking and via ADME and Toxicity predictions. The shortlisted compounds were then subjected to MD Simulations of the membrane-bound FFAR4-ligand complexes for 100 ns each. Molecular analyses, encompassing binding interactions, RMSD, RMSF, RoG, PCA, and FEL, were conducted to scrutinize the protein-ligand complexes at the inter-atomic level. The analyses revealed significant interactions of the shortlisted compounds with the crucial residues of FFAR4 previously documented. FFAR4 as part of the complexes demonstrated consistent RMSDs, ranging from 3.57 to 3.64, with minimal residue fluctuations 5.27 to 6.03 nm, suggesting stable complexes. The gyration values fluctuated between 22.8 to 23.5 nm, indicating structural compactness and orderliness across the studied systems. Additionally, distinct conformational motions were observed in each complex, with energy contours shifting to broader energy basins throughout the simulation, suggesting thermodynamically stable protein-ligand complexes. The two compounds CHEMBL2012662 and CHEMBL64616 are presented as potential FFAR4 agonists, based on these insights and in-depth analyses. Collectively, these findings advance our comprehension of FFAR4's functions and mechanisms, highlighting these compounds as potential FFAR4 agonists worthy of further exploration as innovative treatments for metabolic and immune-related conditions.",2045-2322,,,, ,  ,,out_of_scope,
2649,"**Title**Water-Soluble Bimodal Magnetic-Fluorescent Radical Dendrimers as Potential MRI-FI Imaging Probes

**Abstract**Dual or multimodal imaging probes have become potent tools for enhancing detection sensitivity and accuracy in disease diagnosis. In this context, we present a bimodal imaging dendrimer-based structure that integrates magnetic and fluorescent imaging probes for potential applications in magnetic resonance imaging and fluorescence imaging. It stands out as one of the rare examples where bimodal imaging probes use organic radicals as the magnetic source, despite their tendency to entirely quench fluorophore fluorescence. Opting for organic radicals over metal-based contrast agents like gadolinium (Gd3+)-chelates is crucial to mitigate associated toxicity concerns. We utilized an amino-terminated polyamide dendrimer containing a 1,8-naphthalimide (Naft) fluorescent group, amino acid derivatives as linkers to enhance water solubility, and TEMPO organic radicals as terminal groups. The same dendrimer structure, featuring an equivalent number of branches but lacking the fluorophore group, was also functionalized with amino acid and terminal radicals to serve as a reference. Remarkably, we achieved a fully water-soluble dendrimer-based structure exhibiting both magnetic and fluorescent properties simultaneously. The fluorescence of the Naft group in the final structure is somewhat quenched by the organic radicals, likely due to photoinduced electron transfer with the nitroxyl radical acting as an electron acceptor, which has been supported by density functional theory calculations. Molecular dynamics simulations are employed to investigate how the dendrimers' structure influences the electron paramagnetic resonance characteristics, relaxivity, and fluorescence. In summary, despite the influence of the radicals-fluorophore interactions on fluorescence, this bimodal dendrimer demonstrates significant fluorescent properties and effective r 1 relaxivity of 1.3 mM-1 s-1. These properties have proven effective in staining the live mesenchymal stem cells without affecting the cell nucleus.","Wu, Yufei; Lloveras, Vega; Morgado, Anjara; Perez-Inestrosa, Ezequiel; Babaliari, Eleftheria; Psilodimitrakopoulos, Sotiris; Vida, Yolanda; Vidal-Gancedo, Jose","Wu, Yufei/LXB-0657-2024; Lloveras, Vega/AAA-8281-2019; Vidal-Gancedo, José/AAV-8413-2020; Babaliari, Eleftheria/AAG-7850-2019; Vidal-Gancedo, Jose/C-2281-2012; PEREZ DE INESTROSA VILLATORO, EZEQUIEL/H-9801-2015","Vidal-Gancedo, Jose/0000-0002-1853-9675; Wu, Yufei/0000-0002-8264-9326; Lloveras Monserrat, Vega/0000-0002-9653-3340; PEREZ DE INESTROSA VILLATORO, EZEQUIEL/0000-0001-7546-5273",Water-Soluble Bimodal Magnetic-Fluorescent Radical Dendrimers as Potential MRI-FI Imaging Probes,16,47,10.1021/acsami.4c13578 ,Article ,,"Dual or multimodal imaging probes have become potent tools for enhancing detection sensitivity and accuracy in disease diagnosis. In this context, we present a bimodal imaging dendrimer-based structure that integrates magnetic and fluorescent imaging probes for potential applications in magnetic resonance imaging and fluorescence imaging. It stands out as one of the rare examples where bimodal imaging probes use organic radicals as the magnetic source, despite their tendency to entirely quench fluorophore fluorescence. Opting for organic radicals over metal-based contrast agents like gadolinium (Gd3+)-chelates is crucial to mitigate associated toxicity concerns. We utilized an amino-terminated polyamide dendrimer containing a 1,8-naphthalimide (Naft) fluorescent group, amino acid derivatives as linkers to enhance water solubility, and TEMPO organic radicals as terminal groups. The same dendrimer structure, featuring an equivalent number of branches but lacking the fluorophore group, was also functionalized with amino acid and terminal radicals to serve as a reference. Remarkably, we achieved a fully water-soluble dendrimer-based structure exhibiting both magnetic and fluorescent properties simultaneously. The fluorescence of the Naft group in the final structure is somewhat quenched by the organic radicals, likely due to photoinduced electron transfer with the nitroxyl radical acting as an electron acceptor, which has been supported by density functional theory calculations. Molecular dynamics simulations are employed to investigate how the dendrimers' structure influences the electron paramagnetic resonance characteristics, relaxivity, and fluorescence. In summary, despite the influence of the radicals-fluorophore interactions on fluorescence, this bimodal dendrimer demonstrates significant fluorescent properties and effective r 1 relaxivity of 1.3 mM-1 s-1. These properties have proven effective in staining the live mesenchymal stem cells without affecting the cell nucleus.",1944-8244,1944-8252,,65295-65306, ,  ,,out_of_scope,
2650,"**Title**Can Hallucination Reduction in LLMs Improve Online Sexism Detection?

**Abstract**Online sexism is a pervasive problem with a significant impact on the targeted individuals and social inequalities. Automated tools are now widely used to identify sexist content at scale, but most of these tools do not provide any further explanations beyond generic categories such as 'toxicity', 'abuse' or 'sexism'. This paper explores the impact of hallucination reduction in LLMs on enhancing sexism detection across three different levels: binary sexism, four-categories of sexism, and fine-grained vectors, with a focus on explainability in sexism detection. We have successfully applied Neural Path Hunter (NPH) to GPT-2, with the purpose of teaching the model to hallucinate less. We have used hallucination-reduced GPT-2, achieving accuracy rates of 83.2% for binary detection, 52.2% for four-categories classification and 38.0% for the 11-vectors fine-grained classification, respectively. The results indicate that: i) While the model performances may slightly lag behind the baseline models, hallucination-reducing methods have the potential to significantly influence LLM performance across various applications, beyond just dialogue-response systems. Additionally, this method could potentially mitigate model bias and improve generalization capabilities, based upon the dataset quality and the selected hallucination reduction technique.","Ding, Leyuan; Rajapaksha, Praboda; Aung Kaung Myat; Farahbakhsh, Reza; Crespi, Noel","Crespi, Noel/ABE-7052-2020; Rajapaksha, Praboda/GLT-9388-2022",,Can Hallucination Reduction in LLMs Improve Online Sexism Detection?,1065,,10.1007/978-3-031-66329-1_40 ,Proceedings Paper ,,"Online sexism is a pervasive problem with a significant impact on the targeted individuals and social inequalities. Automated tools are now widely used to identify sexist content at scale, but most of these tools do not provide any further explanations beyond generic categories such as 'toxicity', 'abuse' or 'sexism'. This paper explores the impact of hallucination reduction in LLMs on enhancing sexism detection across three different levels: binary sexism, four-categories of sexism, and fine-grained vectors, with a focus on explainability in sexism detection. We have successfully applied Neural Path Hunter (NPH) to GPT-2, with the purpose of teaching the model to hallucinate less. We have used hallucination-reduced GPT-2, achieving accuracy rates of 83.2% for binary detection, 52.2% for four-categories classification and 38.0% for the 11-vectors fine-grained classification, respectively. The results indicate that: i) While the model performances may slightly lag behind the baseline models, hallucination-reducing methods have the potential to significantly influence LLM performance across various applications, beyond just dialogue-response systems. Additionally, this method could potentially mitigate model bias and improve generalization capabilities, based upon the dataset quality and the selected hallucination reduction technique.",2367-3370,2367-3389,978-3-031-66328-4; 978-3-031-66329-1,625-638, , Intelligent Systems ConferenceIntelligent Systems Conference ,,detection,
2651,"**Title**The utilization of Lysinibacillus bacterial powder to induce Fe plaque formation mitigates cadmium and chromium levels in rice

**Abstract**The presence of cadmium (Cd) and chromium (Cr) contamination in soil poses an environmental risk to food safety. Microorganisms are crucial for biotransforming heavy metals, but their limited survival in contaminated soils hinders their application in bioremediation. Here, we isolated Lysinibacillus sp. OR-15, which effectively removed Cd(II) and reduced Cr(VI) from the culture. Proteomic analyses and heterologous expression assays showed that QueF, an NADPH-dependent reductase, enhanced bacterial resistance to Cd(II) and Cr(VI), enhancing metal removal capacity. The dry bacterial powder, produced through deep liquid fermentation and spray drying, contained 2.3 x 1010 viable cells per gram. It effectively reduced Cd and Cr levels in rice grains and maintained a concentration of 105 per gram in soils even after 60 days of cultivation following one application. Scanning and microscopy analysis revealed that Lysinibacillus sp. OR-15 facilitated the formation of iron plaque on rice roots. The formation of iron plaque on the root surface serves as a protective barrier against the upward translocation of heavy metals. Our findings suggest that Lysinibacillus sp. OR-15 exhibits stable and effective properties as a factor for Cd and Cr adsorb on rice iron plaque, thus mitigating the levels of Cd and Cr in rice grains.","Xu, Qing; Zhang, Yuxiao; Yang, Ruijia; Li, Jinfang; Chen, Jiongxi; Wang, Jingyi; Wang, Gejiao; Li, Mingshun; Shi, Kaixiang","Wang, Jingyi/AHE-1352-2022; Liu, Yang/JVD-6777-2023; Shi, Kaixiang/GPW-5793-2022","Shi, Kaixiang/0000-0002-2823-551X",The utilization of Lysinibacillus bacterial powder to induce Fe plaque formation mitigates cadmium and chromium levels in rice,463,,10.1016/j.jhazmat.2023.132825 ,Article ,,"The presence of cadmium (Cd) and chromium (Cr) contamination in soil poses an environmental risk to food safety. Microorganisms are crucial for biotransforming heavy metals, but their limited survival in contaminated soils hinders their application in bioremediation. Here, we isolated Lysinibacillus sp. OR-15, which effectively removed Cd(II) and reduced Cr(VI) from the culture. Proteomic analyses and heterologous expression assays showed that QueF, an NADPH-dependent reductase, enhanced bacterial resistance to Cd(II) and Cr(VI), enhancing metal removal capacity. The dry bacterial powder, produced through deep liquid fermentation and spray drying, contained 2.3 x 1010 viable cells per gram. It effectively reduced Cd and Cr levels in rice grains and maintained a concentration of 105 per gram in soils even after 60 days of cultivation following one application. Scanning and microscopy analysis revealed that Lysinibacillus sp. OR-15 facilitated the formation of iron plaque on rice roots. The formation of iron plaque on the root surface serves as a protective barrier against the upward translocation of heavy metals. Our findings suggest that Lysinibacillus sp. OR-15 exhibits stable and effective properties as a factor for Cd and Cr adsorb on rice iron plaque, thus mitigating the levels of Cd and Cr in rice grains.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2652,"**Title**Trends and drivers of global dietary methylmercury exposure during 1995-2020

**Abstract**Methylmercury (MeHg) exposure primarily comes from diet, posing serious health risks. However, the trends of global dietary MeHg exposure and underlying drivers remain unknown. This study reveals the recent global trend in dietary MeHg exposure (expressed in per capita probable daily intake of MeHg), and the sources and drivers of exposure changes. Results show that global dietary MeHg exposure has increased by 29 % during 1995-2020, especially in South Asia (203 %), Southeast Asia (104 %), and Sub-Saharan Africa (77 %). Freshwater fish consumption was the main source for increased MeHg exposure. The increase in food consumption was the main driver of the growth in global dietary MeHg exposure, while dietary structure transition was the primary driver of its decline. The changes in MeHg concentrations of foods have mitigated dietary MeHg exposures in developed economies, but aggravated them in underdeveloped economies. Our findings can guide decision-making on managing increasing dietary MeHg exposure.","Zhou, Haifeng; Chen, Long; Li, Yumeng; Wu, Xiaohui; Zhong, Qiumeng; Liang, Sai",,"Zhou, Haifeng/0000-0001-7911-3566; Liang, Sai/0000-0002-6306-5800",Trends and drivers of global dietary methylmercury exposure during 1995-2020,211,,10.1016/j.resconrec.2024.107858 ,Article ,,"Methylmercury (MeHg) exposure primarily comes from diet, posing serious health risks. However, the trends of global dietary MeHg exposure and underlying drivers remain unknown. This study reveals the recent global trend in dietary MeHg exposure (expressed in per capita probable daily intake of MeHg), and the sources and drivers of exposure changes. Results show that global dietary MeHg exposure has increased by 29 % during 1995-2020, especially in South Asia (203 %), Southeast Asia (104 %), and Sub-Saharan Africa (77 %). Freshwater fish consumption was the main source for increased MeHg exposure. The increase in food consumption was the main driver of the growth in global dietary MeHg exposure, while dietary structure transition was the primary driver of its decline. The changes in MeHg concentrations of foods have mitigated dietary MeHg exposures in developed economies, but aggravated them in underdeveloped economies. Our findings can guide decision-making on managing increasing dietary MeHg exposure.",0921-3449,1879-0658,,, ,  ,,out_of_scope,
2653,"**Title**Eco-friendly and bio-based approaches for flame-retardant functionalization of textile materials: a review

**Abstract**The use of natural and synthetic textile materials in various industries is significant, but their flammability poses a risk in case of fire accidents. These textile materials contain a significant amount of carbon and hydrogen in their structure, which can act as fuel for combustion. As a result, these textile materials can be hazardous in the event of a fire accident. Therefore, the application of fire-retardant treatments to textile materials has great importance to mitigate fire risks. Despite the availability of numerous effective flame retardants for textile applications, there is a need to develop new environmentally friendly flame-retardant agents and treatments that are both effective and environmentally friendly. The application of flame-retardant compounds is evolving globally, considering modifications to textile surfaces and the use of environmentally friendly materials. Thus, this review focuses on the functionalization of textile materials with bio-based and eco-friendly flame retardants and reviews recent studies on the use of compounds such as phytic acid, lignin, eggshell, gelatin, chitosan, nanosized/nanomaterial, and phosphorus-containing flame retardants on natural and synthetic textiles. The review highlights bio-based and eco-friendly approaches and improvement of flame-retardant efficiency of textiles through synergistic interaction of phosphorus with other environmentally acceptable elements like nitrogen and silicon.","Daget, Tekalgn Mamay; Kassie, Bantamlak Birlie; Abate, Molla Tadesse; Teshome, Meseret Fantahun; Arega, Mekides Mastewal; Atalie, Desalegn","Abate, Molla/GOG-9979-2022; Wollelaw, Desalegn Atalie/S-6819-2017; Kassie, Bantamlak Birlie/LBH-1241-2024","Wollelaw, Desalegn Atalie/0000-0002-6127-9979; Daget, Tekalgn Mamay/0000-0002-9461-4227; Kassie, Bantamlak Birlie/0000-0002-1576-4180",Eco-friendly and bio-based approaches for flame-retardant functionalization of textile materials: a review,63,14,10.1080/25740881.2024.2363260 ,Review ,,"The use of natural and synthetic textile materials in various industries is significant, but their flammability poses a risk in case of fire accidents. These textile materials contain a significant amount of carbon and hydrogen in their structure, which can act as fuel for combustion. As a result, these textile materials can be hazardous in the event of a fire accident. Therefore, the application of fire-retardant treatments to textile materials has great importance to mitigate fire risks. Despite the availability of numerous effective flame retardants for textile applications, there is a need to develop new environmentally friendly flame-retardant agents and treatments that are both effective and environmentally friendly. The application of flame-retardant compounds is evolving globally, considering modifications to textile surfaces and the use of environmentally friendly materials. Thus, this review focuses on the functionalization of textile materials with bio-based and eco-friendly flame retardants and reviews recent studies on the use of compounds such as phytic acid, lignin, eggshell, gelatin, chitosan, nanosized/nanomaterial, and phosphorus-containing flame retardants on natural and synthetic textiles. The review highlights bio-based and eco-friendly approaches and improvement of flame-retardant efficiency of textiles through synergistic interaction of phosphorus with other environmentally acceptable elements like nitrogen and silicon.",2574-0881,2574-089X,,1887-1916, ,  ,,out_of_scope,
2654,"**Title**Dual roles of nanocrystalline cellulose extracted from jute (Corchorus olitorius L.) leaves in resisting antibiotics and protecting probiotics

**Abstract**Antibiotics can cure diseases caused by bacterial infections, but their widespread use can have some side effects, such as probiotic reduction. There is an urgent need for such agents that can not only alleviate the damage caused by antibiotics, but also maintain the balance of the gut microbiota. In this study, we first characterized the nanocrystalline cellulose (NCC) extracted from plant jute (Corchorus olitorius L.) leaves. Next, we evaluated the protective effect of jute NCC and cellulose on human model gut bacteria (Lacticaseibacillus rhamnosus and Escherichia coli) under antibiotic stress by measuring bacterial growth and colony forming units. We found that NCC is more effective than cellulose in adsorbing antibiotics and defending the gut bacteria E. coli. Interestingly, the low-dose jute NCC clearly maintained the balance of key gut bacteria like Snodgrassella alvi and Lactobacillus Firm-4 in bees treated with tetracycline and reduced the toxicity caused by antibiotics. It also showed a more significant protective effect on human gut bacteria, especially L. rhamnosus, than cellulose. This study first demonstrated that low-dose NCC performed satisfactorily as a specific probiotic to mitigate the adverse effects of antibiotics on gut bacteria.","Deng, Yanchun; Pan, Jiangpeng; Yang, Xiai; Yang, Sa; Chi, Haiyang; Yang, Xiushi; Qu, Xiaoxin; Sun, Shitao; You, Linfeng; Hou, Chunsheng","xiai, yang/LLL-8222-2024; Deng, Yanchun/JPL-8947-2023; Linfeng, You/P-7240-2018; Yang, Xiushi/AGE-7718-2022","Chi, Haiyang/0000-0002-4319-3370",Dual roles of nanocrystalline cellulose extracted from jute (Corchorus olitorius L.) leaves in resisting antibiotics and protecting probiotics,5,23,10.1039/d3na00345k ,Article ,,"Antibiotics can cure diseases caused by bacterial infections, but their widespread use can have some side effects, such as probiotic reduction. There is an urgent need for such agents that can not only alleviate the damage caused by antibiotics, but also maintain the balance of the gut microbiota. In this study, we first characterized the nanocrystalline cellulose (NCC) extracted from plant jute (Corchorus olitorius L.) leaves. Next, we evaluated the protective effect of jute NCC and cellulose on human model gut bacteria (Lacticaseibacillus rhamnosus and Escherichia coli) under antibiotic stress by measuring bacterial growth and colony forming units. We found that NCC is more effective than cellulose in adsorbing antibiotics and defending the gut bacteria E. coli. Interestingly, the low-dose jute NCC clearly maintained the balance of key gut bacteria like Snodgrassella alvi and Lactobacillus Firm-4 in bees treated with tetracycline and reduced the toxicity caused by antibiotics. It also showed a more significant protective effect on human gut bacteria, especially L. rhamnosus, than cellulose. This study first demonstrated that low-dose NCC performed satisfactorily as a specific probiotic to mitigate the adverse effects of antibiotics on gut bacteria.",2516-0230,,,6435-6448, ,  ,,out_of_scope,
2655,"**Title**Characterization and genetic determination of a newly isolated cotinine-degrading bacterium Terrabacter sp. strain cot-2 from synergistic consortium

**Abstract**Cotinine, the main metabolite of nicotine, was frequently detected in aquatic environment and pose a high risk to environmental safety and human health. Microbial degradation was considered as the most effective and environmental-friendly method for cotinine elimination. However, the microbial resources including bacterial consortia and pure cultures were limited. In this study, a synergistic consortium involved in cotinine degradation was successfully obtained and metagenomic analysis were investigated to reveal the key microorganisms responsible for cotinine and 6-hydroxy-3-succinoylpyridine (HSP) degradation, respectively. The genes encoding for cotinine hydroxylation (cotA1A2A3) and for HSP cleavage (hspB) were successfully amplified from the consortium C2 and functionally identified. Furthermore, a new cotinine-degrading pure culture strain, Terrabacter sp. cot-2, was isolated from the consortium C2. The degradation characterization and key intermediates of cotinine by strain cot-2 were analyzed. Then, the complete genome of strain cot-2 was determined and the gene cluster cot was demonstrated to be widely distributed in different environments. This study significantly broadened the knowledge on the degradation of the functional consortium and mechanism involved in cotinine biodegradation at molecular level, which also offering a promising solution to mitigate the impact of cotinine in aquatic ecosystems.","Jiang, Yinhu; Xu, Lu; Wang, Kexin; Liu, Guiping; Ma, Jiale; Zhou, Ying; Xu, Qimiao; Hong, Qing; He, Jian; Qiu, Jiguo","Lu, Xu/JRX-8095-2023; Qiu, Jiguo/J-1664-2016","Qiu, Jiguo/0000-0002-7633-6227",Characterization and genetic determination of a newly isolated cotinine-degrading bacterium Terrabacter sp. strain cot-2 from synergistic consortium,454,,10.1016/j.jclepro.2024.142278 ,Article ,,"Cotinine, the main metabolite of nicotine, was frequently detected in aquatic environment and pose a high risk to environmental safety and human health. Microbial degradation was considered as the most effective and environmental-friendly method for cotinine elimination. However, the microbial resources including bacterial consortia and pure cultures were limited. In this study, a synergistic consortium involved in cotinine degradation was successfully obtained and metagenomic analysis were investigated to reveal the key microorganisms responsible for cotinine and 6-hydroxy-3-succinoylpyridine (HSP) degradation, respectively. The genes encoding for cotinine hydroxylation (cotA1A2A3) and for HSP cleavage (hspB) were successfully amplified from the consortium C2 and functionally identified. Furthermore, a new cotinine-degrading pure culture strain, Terrabacter sp. cot-2, was isolated from the consortium C2. The degradation characterization and key intermediates of cotinine by strain cot-2 were analyzed. Then, the complete genome of strain cot-2 was determined and the gene cluster cot was demonstrated to be widely distributed in different environments. This study significantly broadened the knowledge on the degradation of the functional consortium and mechanism involved in cotinine biodegradation at molecular level, which also offering a promising solution to mitigate the impact of cotinine in aquatic ecosystems.",0959-6526,1879-1786,,, ,  ,,out_of_scope,
2656,"**Title**Decoding uranium variation over the Indian peninsula through leveraging standardized precipitation evapotranspiration indices and groundwater level fluctuations

**Abstract**The present study aims to predict the concentration of uranium (U) in groundwater in India by utilizing water quantity indicators, such as Standardised Precipitation Index (SPI), Standardised Precipitation Evapotranspiration Index (SPEI), and Gravity Recovery and Climate Experiment (GRACE) based groundwater levels. The study adopts a multi-scale approach, ranging from state-level to agroclimatic zones. The findings indicate that the highest levels of U (101-500 mu g.L-1), which surpass the World Health Organization (WHO) prescribed limit of 30 mu g.L-1 for drinking water, are primarily concentrated in India's plateau and hills regions. The GRACE data map portrays a downward trend in groundwater levels throughout India, with the mid-Gangetic plains experiencing the most significant decline. The meteorological aspect of the study, as indicated by SPI and SPEI, reveals that the plateau and hills region is experiencing a decline in rainfall. The SPEI further underscores the grim picture of decreasing precipitation in northern India. Additionally, the study employs cluster analysis to cluster states according to the division of agro-climatic zones. Lastly, the study employs a random forest algorithm to assess the relative importance of each predictor and predict U concentration under the trinity of precipitation, extraction, and evaporation. The most significant contribution of this work is to identify the hotspots in India that require the most attention in terms of U toxicity owing to groundwater decline. Overall, this study highlights the need for immediate attention to mitigate the adverse impacts of U contamination and aims at sensitizing the stakeholders towards the compelling need to fulfil SDG-3 (health aspects due to U hazard) and SDG-6 (groundwater over -exploitation and deteriorating water quality).","Panday, Durga Prasad; Kumar, Manish","Panday, Durga/X-9195-2019","Panday, Durga Prasad/0000-0003-3707-7936",Decoding uranium variation over the Indian peninsula through leveraging standardized precipitation evapotranspiration indices and groundwater level fluctuations,26,,10.1016/j.gsd.2024.101241 ,Article ,,"The present study aims to predict the concentration of uranium (U) in groundwater in India by utilizing water quantity indicators, such as Standardised Precipitation Index (SPI), Standardised Precipitation Evapotranspiration Index (SPEI), and Gravity Recovery and Climate Experiment (GRACE) based groundwater levels. The study adopts a multi-scale approach, ranging from state-level to agroclimatic zones. The findings indicate that the highest levels of U (101-500 mu g.L-1), which surpass the World Health Organization (WHO) prescribed limit of 30 mu g.L-1 for drinking water, are primarily concentrated in India's plateau and hills regions. The GRACE data map portrays a downward trend in groundwater levels throughout India, with the mid-Gangetic plains experiencing the most significant decline. The meteorological aspect of the study, as indicated by SPI and SPEI, reveals that the plateau and hills region is experiencing a decline in rainfall. The SPEI further underscores the grim picture of decreasing precipitation in northern India. Additionally, the study employs cluster analysis to cluster states according to the division of agro-climatic zones. Lastly, the study employs a random forest algorithm to assess the relative importance of each predictor and predict U concentration under the trinity of precipitation, extraction, and evaporation. The most significant contribution of this work is to identify the hotspots in India that require the most attention in terms of U toxicity owing to groundwater decline. Overall, this study highlights the need for immediate attention to mitigate the adverse impacts of U contamination and aims at sensitizing the stakeholders towards the compelling need to fulfil SDG-3 (health aspects due to U hazard) and SDG-6 (groundwater over -exploitation and deteriorating water quality).",2352-801X,,,, ,  ,,out_of_scope,
2657,"**Title**Enhanced biodegradation of trinitrotoluene in rhizosphere soil by native grasses

**Abstract**Soil contamination by the munition explosive residues of 2,4,6-trinitrotoluene (TNT) and its metabolites resulting primarily from military operations has been identified as a threat to human health and ecosystems. Biodegradation by native plants to remove this hazardous compound or reduce its toxicity is considered a cost-effective and environmentally sound approach for the cleanup or restoration of TNT-contaminated soils. This study aims to investigate the TNT biodegradation and kinetics by two selected native grasses in the species-specific rhizosphere soils through growth chamber experiments. Native eastern gamma grass (Tripsacum dactyloides) and switchgrass (Panicum virgatum L.) were grown in soil spiked with 14C-TNT for 8 weeks. The 14C-TNT degradation and degradative metabolite profile in the rhizosphere soils were determined by liquid scintillation counter and high-performance liquid chromatography, respectively. The results indicated that both native grass species significantly enhanced the TNT degradation in the rhizosphere soils as compared with the control rhizosphere soils. More than 95% of the applied 14C-TNT was degraded in the first 7 days, and the rate then reached a steady state afterward, but less than 10% of the TNT applied was completely mineralized and transformed into CO2. The degradative reaction was found to follow second-order kinetics. Six major TNT degradative metabolites have been detected and identified in the rhizosphere soils. Overall, switchgrass appeared more effective for biodegrading TNT than eastern gamma grass. This research demonstrated that the native grass species, especially switchgrass, has the potential to mitigate the adverse human health and ecological risks of TNT-contaminated sites and can be considered an environmentally friendly, sustainable approach to safeguarding human health from TNT contamination.","Li, Na; Yang, Kenny; Lin, Chungho; Yang, John",,,Enhanced biodegradation of trinitrotoluene in rhizosphere soil by native grasses,12,,10.3389/fenvs.2024.1426203 ,Article ,,"Soil contamination by the munition explosive residues of 2,4,6-trinitrotoluene (TNT) and its metabolites resulting primarily from military operations has been identified as a threat to human health and ecosystems. Biodegradation by native plants to remove this hazardous compound or reduce its toxicity is considered a cost-effective and environmentally sound approach for the cleanup or restoration of TNT-contaminated soils. This study aims to investigate the TNT biodegradation and kinetics by two selected native grasses in the species-specific rhizosphere soils through growth chamber experiments. Native eastern gamma grass (Tripsacum dactyloides) and switchgrass (Panicum virgatum L.) were grown in soil spiked with 14C-TNT for 8 weeks. The 14C-TNT degradation and degradative metabolite profile in the rhizosphere soils were determined by liquid scintillation counter and high-performance liquid chromatography, respectively. The results indicated that both native grass species significantly enhanced the TNT degradation in the rhizosphere soils as compared with the control rhizosphere soils. More than 95% of the applied 14C-TNT was degraded in the first 7 days, and the rate then reached a steady state afterward, but less than 10% of the TNT applied was completely mineralized and transformed into CO2. The degradative reaction was found to follow second-order kinetics. Six major TNT degradative metabolites have been detected and identified in the rhizosphere soils. Overall, switchgrass appeared more effective for biodegrading TNT than eastern gamma grass. This research demonstrated that the native grass species, especially switchgrass, has the potential to mitigate the adverse human health and ecological risks of TNT-contaminated sites and can be considered an environmentally friendly, sustainable approach to safeguarding human health from TNT contamination.",,2296-665X,,, ,  ,,out_of_scope,
2658,"**Title**Application of EDEM Simulation for Calculating and Optimizing a Closed Coal Fly Ash Screw Conveyor

**Abstract**In contemporary bulk material transportation systems, closed screw conveyors have become prevalent. These conveyors, enclosed within troughs or cylindrical bodies, effectively mitigate environmental contamination and material toxicity during transit. Their hermetic design prevents material dispersion by wind, thereby minimizing losses and preserving the integrity of raw materials, particularly those with potential health implications such as urea and cement. Consequently, employing a screw conveyor constitutes a prudent safety measure. Despite the widespread use of screw conveyors, a comprehensive understanding of the behavior of material particles within these systems remains elusive and subject to discrepancies across various methodologies. Presently, a multitude of calculation methods and applications exist, resulting in disparities between theoretical computations and practical implementation. Drawing upon Alan W. Roberts' meticulously devised calculation methodology, renowned for its precision, the authors have developed a swift computational tool utilizing VBA Excel software 2023. Additionally, EDEM simulation software was employed to model granular material behavior. The ensuing calculations guided the selection of optimized technical dimensions for the screw conveyor, which were then fabricated and subjected to real-world testing at the Vinh Tan thermal power plant. Remarkably, the achieved output capacity demonstrated a mere 7% deviation from calculations performed with the VBA program and a 2% variation from those conducted via EDEM simulation. Furthermore, a comprehensive graph depicting the relationship between screw conveyor speed and capacity has been provided, affording a means to finely tune throughput with exceptional accuracy along the production line. The results obtained provide the basis for the development of a device that meets the required capacity specifications accurately and precisely on the first attempt. This accomplishment satisfies stringent capacity standards without the need for any adjustments or modifications, all while ensuring minimal cost and time efficiency.","Tran, Van-Thien; Bui, Ngoc-Tam; Bui, Tuan-Anh","Bui, Anh/AGU-2130-2022; BUI, Ngoc-Tam/AAD-1522-2020","BUI, Ngoc-Tam/0000-0003-0437-6104; Bui, Tuan-Anh/0000-0002-5630-0884",Application of EDEM Simulation for Calculating and Optimizing a Closed Coal Fly Ash Screw Conveyor,13,22,10.3390/app132212169 ,Article ,,"In contemporary bulk material transportation systems, closed screw conveyors have become prevalent. These conveyors, enclosed within troughs or cylindrical bodies, effectively mitigate environmental contamination and material toxicity during transit. Their hermetic design prevents material dispersion by wind, thereby minimizing losses and preserving the integrity of raw materials, particularly those with potential health implications such as urea and cement. Consequently, employing a screw conveyor constitutes a prudent safety measure. Despite the widespread use of screw conveyors, a comprehensive understanding of the behavior of material particles within these systems remains elusive and subject to discrepancies across various methodologies. Presently, a multitude of calculation methods and applications exist, resulting in disparities between theoretical computations and practical implementation. Drawing upon Alan W. Roberts' meticulously devised calculation methodology, renowned for its precision, the authors have developed a swift computational tool utilizing VBA Excel software 2023. Additionally, EDEM simulation software was employed to model granular material behavior. The ensuing calculations guided the selection of optimized technical dimensions for the screw conveyor, which were then fabricated and subjected to real-world testing at the Vinh Tan thermal power plant. Remarkably, the achieved output capacity demonstrated a mere 7% deviation from calculations performed with the VBA program and a 2% variation from those conducted via EDEM simulation. Furthermore, a comprehensive graph depicting the relationship between screw conveyor speed and capacity has been provided, affording a means to finely tune throughput with exceptional accuracy along the production line. The results obtained provide the basis for the development of a device that meets the required capacity specifications accurately and precisely on the first attempt. This accomplishment satisfies stringent capacity standards without the need for any adjustments or modifications, all while ensuring minimal cost and time efficiency.",,2076-3417,,, ,  ,,out_of_scope,
2659,"**Title**The Role of Fungi in Food Production and Processing

**Abstract**Fungi play an important and multifaceted role in the production and processing of food, influencing various stages from cultivation to consumption. This paper explores the complex relationship between fungi and food systems, highlighting their diverse contributions. Firstly, fungi serve as essential agents in food cultivation, aiding in the breakdown of organic matter and the recycling of nutrients, and promoting plant growth through symbiotic relationships. Moreover, fungi such as yeasts and molds are integral to fermentation processes, yielding a wide array of fermented foods and beverages with unique flavors and textures. Additionally, fungi are indispensable in the creation of enzymes and bioactive compounds utilized in food processing, enhancing the nutritional value, shelf life, and safety. However, certain fungal species pose significant challenges as food spoilage agents and mycotoxin producers, necessitating stringent quality control measures. Understanding the intricate interplay between fungi and food systems is essential for optimizing food production, ensuring food security, and mitigating the risks associated with fungal contamination. This paper synthesizes current research to elucidate the important role that fungus play in shaping the modern food industry and underscores the importance of ongoing scientific inquiry in harnessing their potential for sustainable and safe food production.","Pouris, John; Kolyva, Foteini; Bratakou, Spyridoula; Vogiatzi, Chrysovalantou Argyro; Chaniotis, Dimitrios; Beloukas, Apostolos","Beloukas, Apostolos/I-2644-2014","Beloukas, Apostolos/0000-0001-5639-0528; Chaniotis, Dimitrios/0000-0003-2313-1305; Pouris, John/0000-0001-5733-7446",The Role of Fungi in Food Production and Processing,14,12,10.3390/app14125046 ,Review ,,"Fungi play an important and multifaceted role in the production and processing of food, influencing various stages from cultivation to consumption. This paper explores the complex relationship between fungi and food systems, highlighting their diverse contributions. Firstly, fungi serve as essential agents in food cultivation, aiding in the breakdown of organic matter and the recycling of nutrients, and promoting plant growth through symbiotic relationships. Moreover, fungi such as yeasts and molds are integral to fermentation processes, yielding a wide array of fermented foods and beverages with unique flavors and textures. Additionally, fungi are indispensable in the creation of enzymes and bioactive compounds utilized in food processing, enhancing the nutritional value, shelf life, and safety. However, certain fungal species pose significant challenges as food spoilage agents and mycotoxin producers, necessitating stringent quality control measures. Understanding the intricate interplay between fungi and food systems is essential for optimizing food production, ensuring food security, and mitigating the risks associated with fungal contamination. This paper synthesizes current research to elucidate the important role that fungus play in shaping the modern food industry and underscores the importance of ongoing scientific inquiry in harnessing their potential for sustainable and safe food production.",,2076-3417,,, ,  ,,out_of_scope,
2660,"**Title**Trends, risks and opportunities in environmental nanotechnology

**Abstract**Engineered nanomaterials (ENMs), intentionally synthesized materials with sizes less than 100 nm in at least one dimension, have numerous potential environmental applications, such as pollution remediation and water treatment. However, concerns regarding their potential health and environmental impacts have been raised. In this Review, we assess the opportunities of ENMs in environmental applications versus their potential public and environmental health risks, focusing on water treatment and reuse, and identify strategies for their responsible use. Life-cycle analyses indicate that the highest potential environmental and health impacts of ENMs used in commercial products are associated with production rather than incidental release during use. Typically, the detected or predicted ENM concentrations are 1 to 4 orders of magnitude lower than their respective predicted no-effect concentrations. In addition, ENMs often undergo passivating transformations, such as agglomeration and oxidation, reducing risks after release. Therefore, the environmental and health risks of ENMs are relatively low. However, some point sources under extreme scenarios, such as sewage effluent, can potentially increase localized risks. Adopting green chemistry and immobilization strategies can further limit the release of ENMs, minimizing their potential discharge into the environment. Such strategies to reduce toxicity and exposure enable sustainable application of ENMs, such that the environmental benefits could outweigh the risks if managed properly.Engineered nanomaterials (ENMs) have numerous environmental applications, such as in water treatment and reuse. This Review explores the trade-offs between the risks and benefits of environmental ENMs, and highlights that the environmental and health risks of ENMs are relatively low when used responsibly.Environmental applications of nanomaterials include pollution control, green chemistry, clean water production, and sensing and monitoring.Despite the potentially substantial environmental benefits of nanotechnology, the large-scale manufacturing requirements, cost limitations and potential health and environmental risks of engineered nanomaterials (ENMs) are common barriers to their widespread use.The environmental and health risks of ENMs are relatively low considering the very low ENM concentrations involved and the passivating transformations that occur in the environment, although the potential human health and ecosystem impacts of long-term (months to years) exposure to low ENM concentrations (for example, sub-microgram per litre level in water) remain largely unexplored.Life-cycle analyses of ENMs used in commercial products indicate that the highest potential environmental and human health risks are associated with production rather than incidental release.To prevent their release into the environment and mitigate exposure, ENMs should be immobilized in or on substrates such as electrodes, membranes and other matrices. Immobilization also enables ENMs to be reused, promoting sustainable and circular practice.Additionally, ENM-enabled products and processes should undergo a certification process to meet regulated safety standards to promote best practice and increase social acceptance.","Huang, Xiaochuan; Auffan, Melanie; Eckelman, Matthew J.; Elimelech, Menachem; Kim, Jae-Hong; Rose, Jerome; Zuo, Kuichang; Li, Qilin; Alvarez, Pedro J. J.","auffan, melanie/B-7022-2009; Alvarez, Pedro/AAE-7216-2019; Zuo, Kuichang/GQG-8890-2022; ROSE, Jerome/J-5063-2017; Li, Qilin/A-8970-2008; Elimelech, Menachem/E-7137-2012","Zuo, Kuichang/0000-0002-3922-8702; Alvarez, Pedro/0000-0002-6725-7199; ROSE, Jerome/0000-0003-3071-8147; Li, Qilin/0000-0001-5756-3873; Huang, Xiaochuan/0000-0002-3273-8048; Elimelech, Menachem/0000-0003-4186-1563","Trends, risks and opportunities in environmental nanotechnology",5,8,10.1038/s43017-024-00567-5 ,Review ,,"Engineered nanomaterials (ENMs), intentionally synthesized materials with sizes less than 100 nm in at least one dimension, have numerous potential environmental applications, such as pollution remediation and water treatment. However, concerns regarding their potential health and environmental impacts have been raised. In this Review, we assess the opportunities of ENMs in environmental applications versus their potential public and environmental health risks, focusing on water treatment and reuse, and identify strategies for their responsible use. Life-cycle analyses indicate that the highest potential environmental and health impacts of ENMs used in commercial products are associated with production rather than incidental release during use. Typically, the detected or predicted ENM concentrations are 1 to 4 orders of magnitude lower than their respective predicted no-effect concentrations. In addition, ENMs often undergo passivating transformations, such as agglomeration and oxidation, reducing risks after release. Therefore, the environmental and health risks of ENMs are relatively low. However, some point sources under extreme scenarios, such as sewage effluent, can potentially increase localized risks. Adopting green chemistry and immobilization strategies can further limit the release of ENMs, minimizing their potential discharge into the environment. Such strategies to reduce toxicity and exposure enable sustainable application of ENMs, such that the environmental benefits could outweigh the risks if managed properly.Engineered nanomaterials (ENMs) have numerous environmental applications, such as in water treatment and reuse. This Review explores the trade-offs between the risks and benefits of environmental ENMs, and highlights that the environmental and health risks of ENMs are relatively low when used responsibly.Environmental applications of nanomaterials include pollution control, green chemistry, clean water production, and sensing and monitoring.Despite the potentially substantial environmental benefits of nanotechnology, the large-scale manufacturing requirements, cost limitations and potential health and environmental risks of engineered nanomaterials (ENMs) are common barriers to their widespread use.The environmental and health risks of ENMs are relatively low considering the very low ENM concentrations involved and the passivating transformations that occur in the environment, although the potential human health and ecosystem impacts of long-term (months to years) exposure to low ENM concentrations (for example, sub-microgram per litre level in water) remain largely unexplored.Life-cycle analyses of ENMs used in commercial products indicate that the highest potential environmental and human health risks are associated with production rather than incidental release.To prevent their release into the environment and mitigate exposure, ENMs should be immobilized in or on substrates such as electrodes, membranes and other matrices. Immobilization also enables ENMs to be reused, promoting sustainable and circular practice.Additionally, ENM-enabled products and processes should undergo a certification process to meet regulated safety standards to promote best practice and increase social acceptance.",,2662-138X,,572-587, ,  ,,out_of_scope,
2661,"**Title**Bystander Detection: Automatic Labeling Techniques using Feature Selection and Machine Learning

**Abstract**A hostile or aggressive behavior on an online platform by an individual or a group of people is termed as cyberbullying. A bystander is the one who sees or knows about such incidences of cyberbullying. A defender who intervenes can mitigate the impact of bullying, an instigator who accomplices the bully, can add to the victim's suffering, and an impartial onlooker who remains neutral and observes the scenario without getting engaged. Studying the behavior of Bystanders role can help in shaping the scale and progression of bullying incidents. However, the lack of data hinders the research in this area. Recently, a dataset, CYBY23, of Twitter threads having main tweets and the replies of Bystanders was published on Kaggle in Oct 2023. The dataset has extracted features related to toxicity and sensitivity of the main tweets and reply tweets. The authors have got manual annotators to assign the labels of Bystanders' roles. Manually labeling bystanders' roles is a labor-intensive task which eventually raises the need to have an automatic labeling technique for identifying the Bystander role. In this work, we aim to suggest a machine-learning model with high efficiency for the automatic labeling of Bystanders. Initially, the dataset was re-sampled using SMOTE to make it a balanced dataset. Next, we experimented with 12 models using various feature engineering techniques. Best features were selected for further experimentation by removing highly correlated and less relevant features. The models were evaluated on the metrics of accuracy, precision, recall, and F1 score. We found that the Random Forest Classifier (RFC) model with a certain set of features is the highest scorer among all 12 models. The RFC model was further tested against various splits of training and test sets. The highest results were achieved using a training set of 85% and a test set of 15%, having 78.83% accuracy, 81.79% precision, 74.83% recall, and 79.45% F1 score. Automatic labeling proposed in this work, will help in scaling the dataset which will be useful for further studies related to cyberbullying.","Gupta, Anamika; Thakkar, Khushboo; Bhasin, Veenu; Tiwari, Aman; Mathur, Vibhor",,,Bystander Detection: Automatic Labeling Techniques using Feature Selection and Machine Learning,15,1, ,Article ,,"A hostile or aggressive behavior on an online platform by an individual or a group of people is termed as cyberbullying. A bystander is the one who sees or knows about such incidences of cyberbullying. A defender who intervenes can mitigate the impact of bullying, an instigator who accomplices the bully, can add to the victim's suffering, and an impartial onlooker who remains neutral and observes the scenario without getting engaged. Studying the behavior of Bystanders role can help in shaping the scale and progression of bullying incidents. However, the lack of data hinders the research in this area. Recently, a dataset, CYBY23, of Twitter threads having main tweets and the replies of Bystanders was published on Kaggle in Oct 2023. The dataset has extracted features related to toxicity and sensitivity of the main tweets and reply tweets. The authors have got manual annotators to assign the labels of Bystanders' roles. Manually labeling bystanders' roles is a labor-intensive task which eventually raises the need to have an automatic labeling technique for identifying the Bystander role. In this work, we aim to suggest a machine-learning model with high efficiency for the automatic labeling of Bystanders. Initially, the dataset was re-sampled using SMOTE to make it a balanced dataset. Next, we experimented with 12 models using various feature engineering techniques. Best features were selected for further experimentation by removing highly correlated and less relevant features. The models were evaluated on the metrics of accuracy, precision, recall, and F1 score. We found that the Random Forest Classifier (RFC) model with a certain set of features is the highest scorer among all 12 models. The RFC model was further tested against various splits of training and test sets. The highest results were achieved using a training set of 85% and a test set of 15%, having 78.83% accuracy, 81.79% precision, 74.83% recall, and 79.45% F1 score. Automatic labeling proposed in this work, will help in scaling the dataset which will be useful for further studies related to cyberbullying.",2158-107X,2156-5570,,1135-1143, ,  ,,detection,
2662,"**Title**Sodium butyrate alleviates deoxynivalenol-induced porcine intestinal barrier disruption by promoting mitochondrial homeostasis via PCK2 signaling

**Abstract**Deoxynivalenol (DON) is one of the most plentiful trichothecenes occurring in food and feed, which brings severe health hazards to both animals and humans. This study aims to investigate whether sodium butyrate (NaB) can protect the porcine intestinal barrier from DON exposure through promoting mitochondrial homeostasis. In a 4week feeding experiment, 28 male piglets were allocated according to a 2 by 2 factorial arrangement of treatments with the main factors including supplementation of DON (< 0.8 vs. 4.0 mg/kg) and NaB (0.0 vs. 2 g/kg) in a corn/soybean-based diet. Dietary NaB supplementation mitigated the damaged mitochondrial morphology within the jejunal mucosa and the disrupted gut epithelial tight junctions irritated by DON. In IPEC-J2 cells, we found efficient recovery of the intestinal epithelial barrier occurred following NaB administration. This intestinal barrier reparation was facilitated by NaB-induced PCK2-mediated glyceroneogenesis and restoration of mitochondrial structure and function. In conclusion, we elucidated a mechanism of PCK2-mediated improvement of mitochondrial function by NaB to repair porcine intestinal barrier disruption during chronic DON exposure. Our findings highlight the promise of NaB for use in protecting against DON-induced gut epithelial tight junction disruption in piglets.","Xue, Dongfang; Cheng, Yating; Pang, Tiantian; Kuai, Yunyi; An, Yu; Wu, Kuntan; Li, Yuqing; Lai, Mengyu; Wang, Bihan; Wang, Shuai","Wang, Shuai/HZJ-7466-2023; Wen, Jing/KCL-6614-2024","Wang, Shuai/0000-0001-8365-420X",Sodium butyrate alleviates deoxynivalenol-induced porcine intestinal barrier disruption by promoting mitochondrial homeostasis via PCK2 signaling,459,,10.1016/j.jhazmat.2023.132013 ,Article ,,"Deoxynivalenol (DON) is one of the most plentiful trichothecenes occurring in food and feed, which brings severe health hazards to both animals and humans. This study aims to investigate whether sodium butyrate (NaB) can protect the porcine intestinal barrier from DON exposure through promoting mitochondrial homeostasis. In a 4week feeding experiment, 28 male piglets were allocated according to a 2 by 2 factorial arrangement of treatments with the main factors including supplementation of DON (< 0.8 vs. 4.0 mg/kg) and NaB (0.0 vs. 2 g/kg) in a corn/soybean-based diet. Dietary NaB supplementation mitigated the damaged mitochondrial morphology within the jejunal mucosa and the disrupted gut epithelial tight junctions irritated by DON. In IPEC-J2 cells, we found efficient recovery of the intestinal epithelial barrier occurred following NaB administration. This intestinal barrier reparation was facilitated by NaB-induced PCK2-mediated glyceroneogenesis and restoration of mitochondrial structure and function. In conclusion, we elucidated a mechanism of PCK2-mediated improvement of mitochondrial function by NaB to repair porcine intestinal barrier disruption during chronic DON exposure. Our findings highlight the promise of NaB for use in protecting against DON-induced gut epithelial tight junction disruption in piglets.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2663,"**Title**An Integrated Approach for Electronic Waste Management-Overview of Sources of Generation, Toxicological Effects, Assessment, Governance, and Mitigation Approaches

**Abstract**Electronic waste (e-waste) management has become a significant challenge in recent years due to the increasing consumption of electronic devices and their improper disposal. Effective e-waste management requires a comprehensive approach that considers the environmental, economic, and social impacts of e-waste. This comprehensive review provides a critical assessment of e-waste management procedures, encompassing the stages of collection, transportation, treatment, and disposal. Emphasising the significance of embracing sustainable approaches like reusing, repairing, and recycling, the review underscores their pivotal role in mitigating the adverse environmental and human health effects of e-waste. This review provides an overview of e-waste management concerns specifically in India from its collection to the end cycle including toxicological, environmental, and human impacts and a graphical analysis of current and future e-waste trends. It emphasises the need to effectively enforce regulations and establish extended producer responsibility (EPR) to promote sustainable e-waste management practices. Additionally, the review delves into the complexities surrounding e-waste management, such as insufficient infrastructure, resource and funding constraints, and a dearth of awareness among stakeholders. It strongly underscores the necessity for a concerted endeavour involving governments, industries, and communities to tackle these obstacles and advance the cause of efficient e-waste management practices. This paper is valuable to the scientific community as it offers a thorough assessment of e-waste management, focusing on environmental, economic, and social impacts. It emphasises sustainable practices and regulatory measures, providing actionable insights to address e-waste challenges. Overall, this review provides a comprehensive overview of e-waste management and highlights the importance of adopting sustainable practices to address the negative impacts of e-waste on the environment, human health, and the economy.","Nandan, Abhishek; Suresh, Albin C.; Saole, Parth; Jeevanasai, S. Amulya; Chandrasekaran, Ramprasad; Meili, Lucas; Azelee, Nur Izyan Wan; Selvasembian, Rangabhashiyam","Nandan, Abhishek/X-4844-2019; Selvasembian, Rangabhashiyam/N-8801-2017; Meili, Lucas/E-8962-2015; Chandrasekaran, Ramprasad/K-6973-2019","S, Rangabhashiyam/0000-0003-0306-6753; Meili, Lucas/0000-0002-0307-8204; Chandrasekaran, Ramprasad/0000-0002-4042-3476","An Integrated Approach for Electronic Waste Management-Overview of Sources of Generation, Toxicological Effects, Assessment, Governance, and Mitigation Approaches",15,24,10.3390/su152416946 ,Review ,,"Electronic waste (e-waste) management has become a significant challenge in recent years due to the increasing consumption of electronic devices and their improper disposal. Effective e-waste management requires a comprehensive approach that considers the environmental, economic, and social impacts of e-waste. This comprehensive review provides a critical assessment of e-waste management procedures, encompassing the stages of collection, transportation, treatment, and disposal. Emphasising the significance of embracing sustainable approaches like reusing, repairing, and recycling, the review underscores their pivotal role in mitigating the adverse environmental and human health effects of e-waste. This review provides an overview of e-waste management concerns specifically in India from its collection to the end cycle including toxicological, environmental, and human impacts and a graphical analysis of current and future e-waste trends. It emphasises the need to effectively enforce regulations and establish extended producer responsibility (EPR) to promote sustainable e-waste management practices. Additionally, the review delves into the complexities surrounding e-waste management, such as insufficient infrastructure, resource and funding constraints, and a dearth of awareness among stakeholders. It strongly underscores the necessity for a concerted endeavour involving governments, industries, and communities to tackle these obstacles and advance the cause of efficient e-waste management practices. This paper is valuable to the scientific community as it offers a thorough assessment of e-waste management, focusing on environmental, economic, and social impacts. It emphasises sustainable practices and regulatory measures, providing actionable insights to address e-waste challenges. Overall, this review provides a comprehensive overview of e-waste management and highlights the importance of adopting sustainable practices to address the negative impacts of e-waste on the environment, human health, and the economy.",,2071-1050,,, ,  ,,out_of_scope,
2664,"**Title**Insight into the mechanism of nano-TiO2-doped biochar in mitigating cadmium mobility in soil-pak choi system

**Abstract**Soil cadmium (Cd) pollution poses severe threats to food security and human health. Previous studies have reported that both nanoparticles (NPs) and biochar have potential for soil Cd remediation. In this study, a composite material (BN) was synthesized using low-dose TiO2 NPs and silkworm excrement-based biochar, and the mechanism of its effect on the Cd-contaminated soil-pak choi system was investigated. The application of 0.5 % BN to the soil effectively reduced 24.8 % of diethylenetriaminepentaacetic acid (DTPA) Cd in the soil and promoted the conversion of Cd from leaching and HOAc-extractive to reducible forms. BN could improve the adsorption capacity of soil for Cd by promoting the formation of humic acid (HA) and increasing the cation exchange capacity (CEC), as well as activating the oxygen-containing functional groups such as C-O and C--O. BN also increased soil urease and catalase activities and improved the synergistic network among soil bacterial communities to promote soil microbial carbon (C) and nitrogen (N) cycling, thus enhancing Cd passivation. Moreover, BN increased soil biological activity -associated metabolites like T-2 Triol and altered lipid metabolism -related fatty acids, especially hexadecanoic acid and dodecanoic acid, crucial for bacterial Cd tolerance. In addition, BN inhibited Cd uptake and root -to -shoot translocation in pak choi, which ultimately decreased Cd accumulation in shoots by 51.0 %. BN significantly increased the phosphorus (P) uptake in shoots by 59.4 % by improving the soil microbial P cycling. This may serve as a beneficial strategy for pak choi to counteract Cd toxicity. These findings provide new insights into nanomaterial-doped biochar for remediation of heavy metal contamination in soil -plant systems.","Liu, Jing; He, Tieguang; Yang, Zhixing; Peng, Shirui; Zhu, Yanhuan; Li, Hong; Lu, Dan; Li, Qiaoxian; Feng, Yaxuan; Chen, Kuiyuan; Wei, Yanyan","yi, xiao/JHT-3220-2023; Feng, yaxuan/KLC-1664-2024","Liu, Jing/0009-0001-7220-215X",Insight into the mechanism of nano-TiO2-doped biochar in mitigating cadmium mobility in soil-pak choi system,916,,10.1016/j.scitotenv.2024.169996 ,Article ,,"Soil cadmium (Cd) pollution poses severe threats to food security and human health. Previous studies have reported that both nanoparticles (NPs) and biochar have potential for soil Cd remediation. In this study, a composite material (BN) was synthesized using low-dose TiO2 NPs and silkworm excrement-based biochar, and the mechanism of its effect on the Cd-contaminated soil-pak choi system was investigated. The application of 0.5 % BN to the soil effectively reduced 24.8 % of diethylenetriaminepentaacetic acid (DTPA) Cd in the soil and promoted the conversion of Cd from leaching and HOAc-extractive to reducible forms. BN could improve the adsorption capacity of soil for Cd by promoting the formation of humic acid (HA) and increasing the cation exchange capacity (CEC), as well as activating the oxygen-containing functional groups such as C-O and C--O. BN also increased soil urease and catalase activities and improved the synergistic network among soil bacterial communities to promote soil microbial carbon (C) and nitrogen (N) cycling, thus enhancing Cd passivation. Moreover, BN increased soil biological activity -associated metabolites like T-2 Triol and altered lipid metabolism -related fatty acids, especially hexadecanoic acid and dodecanoic acid, crucial for bacterial Cd tolerance. In addition, BN inhibited Cd uptake and root -to -shoot translocation in pak choi, which ultimately decreased Cd accumulation in shoots by 51.0 %. BN significantly increased the phosphorus (P) uptake in shoots by 59.4 % by improving the soil microbial P cycling. This may serve as a beneficial strategy for pak choi to counteract Cd toxicity. These findings provide new insights into nanomaterial-doped biochar for remediation of heavy metal contamination in soil -plant systems.",0048-9697,1879-1026,,, ,  ,,out_of_scope,
2665,"**Title**The toxicological assessment of hazardous elements (Pb, Cd and Hg) in low-cost jewelry for adults from Chinese E-commerce platforms: In situ analysis by portable X-ray fluorescence measurement

**Abstract**This article focusses on the environmental implications of low-cost jewelry for adults from Chinese e-commerce platforms ((n = 8) with heavy metal impurities (Pb, Cd and Hg) and their potential impact on human health and the environment. The study highlights the advantages of using portable X-ray fluorescence (pXRF) analysis for rapid, non-destructive, and in situ analysis of heavy metals in jewelry. The results reveal that all products (n = 106) contained heavy metals at varying levels, Hg being the most commonly detected heavy metal. The fact that 71% of the samples exceeded the EU limit for Pb and 51% exceeded the EU limit for Cd is alarming and highlights the need for stricter regulations and monitoring of the jewelry industry to mitigate the risks posed by heavy metals in the environment. The study emphasizes the importance of using pXRF analysis to identify heavy metals in jewelry and address the literature gap in environmental risk assessments of Pb, Cd, and Hg in low-cost jewelry for adults from China. In general, the findings call for urgent action to ensure the safety of consumers and prevent environmental pollution by strengthening regulations and monitoring the jewelry industry.","Jurowski, Kamil",,"Jurowski, Kamil/0000-0003-0310-2849","The toxicological assessment of hazardous elements (Pb, Cd and Hg) in low-cost jewelry for adults from Chinese E-commerce platforms: In situ analysis by portable X-ray fluorescence measurement",460,,10.1016/j.jhazmat.2023.132167 ,Article ,,"This article focusses on the environmental implications of low-cost jewelry for adults from Chinese e-commerce platforms ((n = 8) with heavy metal impurities (Pb, Cd and Hg) and their potential impact on human health and the environment. The study highlights the advantages of using portable X-ray fluorescence (pXRF) analysis for rapid, non-destructive, and in situ analysis of heavy metals in jewelry. The results reveal that all products (n = 106) contained heavy metals at varying levels, Hg being the most commonly detected heavy metal. The fact that 71% of the samples exceeded the EU limit for Pb and 51% exceeded the EU limit for Cd is alarming and highlights the need for stricter regulations and monitoring of the jewelry industry to mitigate the risks posed by heavy metals in the environment. The study emphasizes the importance of using pXRF analysis to identify heavy metals in jewelry and address the literature gap in environmental risk assessments of Pb, Cd, and Hg in low-cost jewelry for adults from China. In general, the findings call for urgent action to ensure the safety of consumers and prevent environmental pollution by strengthening regulations and monitoring the jewelry industry.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2666,"**Title**Visual whole-process monitoring of pesticide residues: An environmental perspective using surface-enhanced Raman spectroscopy with dynamic borohydride-reduced silver nanoparticles

**Abstract**Environmental monitoring of pesticide residues in crops is essential for both food safety and environmental protection. Traditional methodologies face challenges due to the interference of endogenous compounds in peel and pulp tissues, often being invasive, labor-intensive, and inadequate for real-time observation of hazardous substance distribution. In this study, dynamic borohydride-reduced nanoparticles were employed as enhanced substrates. For the first time, surface-enhanced Raman spectroscopy (SERS) imaging was harnessed to enable whole-process visual detection of pesticide residues. The developed method is both stable and sensitive, boasting a detection lower limit below 1 pg/mL, coupled with robust quantitative analytical capabilities. This technique was successfully employed to detect residue signals across various crops and fruit juices. Furthermore, SERS imaging was utilized to map the distribution of pesticide residues from the exterior to the interior of fruits and vegetables. Vertex component analysis further refined the process by mitigating interference from plant auto fluorescence. Collectively, this innovative strategy facilitates comprehensive pesticide residue monitoring, offering a potent tool for controlling hazardous substances in crops. Its potential applications extend beyond food safety, holding significant promise for sustainable agricultural production and enhanced environmental safeguarding.","Sun, Xiaomeng; Zhao, Yue; Liu, Ling; Qiao, Yuxin; Yang, Chunjuan; Wang, Xiaotong; Li, Qian; Li, Yang","Li, Yang/AAE-1517-2021","Li, Yang/0000-0002-0677-3245",Visual whole-process monitoring of pesticide residues: An environmental perspective using surface-enhanced Raman spectroscopy with dynamic borohydride-reduced silver nanoparticles,465,,10.1016/j.jhazmat.2023.133338 ,Article ,,"Environmental monitoring of pesticide residues in crops is essential for both food safety and environmental protection. Traditional methodologies face challenges due to the interference of endogenous compounds in peel and pulp tissues, often being invasive, labor-intensive, and inadequate for real-time observation of hazardous substance distribution. In this study, dynamic borohydride-reduced nanoparticles were employed as enhanced substrates. For the first time, surface-enhanced Raman spectroscopy (SERS) imaging was harnessed to enable whole-process visual detection of pesticide residues. The developed method is both stable and sensitive, boasting a detection lower limit below 1 pg/mL, coupled with robust quantitative analytical capabilities. This technique was successfully employed to detect residue signals across various crops and fruit juices. Furthermore, SERS imaging was utilized to map the distribution of pesticide residues from the exterior to the interior of fruits and vegetables. Vertex component analysis further refined the process by mitigating interference from plant auto fluorescence. Collectively, this innovative strategy facilitates comprehensive pesticide residue monitoring, offering a potent tool for controlling hazardous substances in crops. Its potential applications extend beyond food safety, holding significant promise for sustainable agricultural production and enhanced environmental safeguarding.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2667,"**Title**The Role of Fermented Vegetables as a Sustainable and Health-Promoting Nutritional Resource

**Abstract**The increasing global burden of morbidity and mortality from chronic diseases related to poor diet quality, coupled with the unsustainable depletion of vital planetary resources by current food production systems, threatens future food security and highlights the urgent need to transition to high-quality plant-based diets as a viable solution to mitigate economic, health, and environmental challenges. Taking into consideration the significant role that fermented vegetables may play as a sustainable, healthy, long-lasting, and plant-based nutritional resource, this narrative review analyzes their production and benefits. For this purpose, the mechanisms of the fermentation process are explored, along with the importance of probiotic cultures in plant-based fermented foods, and with the implications of fermentation on food safety within the broader framework of low-impact, organic, plant-derived nutrition. Additionally, the health benefits of fermented vegetables and probiotics are examined, including their effects on mental health. Vegetable fermentation is a versatile method for enhancing food preservation, nutritional quality, and safety. This ancient practice prolongs the shelf life of perishable items, reduces the toxicity of raw ingredients, and improves digestibility. Specific starter cultures, particularly lactic acid bacteria, are essential for controlling fermentation, ensuring safety, and maximizing health benefits. Fermented vegetables, rich in probiotics, support gut health and immune function. Emerging research indicates their potential to alleviate adverse mental health symptoms such as stress and anxiety, highlighting their significance in modern dietary guidelines and chronic health management.","Borrego-Ruiz, Alejandro; Gonzalez-Domenech, Carmen M.; Borrego, Juan J.","Domenech, Carmen/F-6068-2019; Borrego-Ruiz, Alejandro/KII-7568-2024; Borrego, Juan/H-2010-2014","Borrego-Ruiz, Alejandro/0000-0002-4699-3031; Borrego, Juan/0000-0002-2174-0652",The Role of Fermented Vegetables as a Sustainable and Health-Promoting Nutritional Resource,14,23,10.3390/app142310853 ,Review ,,"The increasing global burden of morbidity and mortality from chronic diseases related to poor diet quality, coupled with the unsustainable depletion of vital planetary resources by current food production systems, threatens future food security and highlights the urgent need to transition to high-quality plant-based diets as a viable solution to mitigate economic, health, and environmental challenges. Taking into consideration the significant role that fermented vegetables may play as a sustainable, healthy, long-lasting, and plant-based nutritional resource, this narrative review analyzes their production and benefits. For this purpose, the mechanisms of the fermentation process are explored, along with the importance of probiotic cultures in plant-based fermented foods, and with the implications of fermentation on food safety within the broader framework of low-impact, organic, plant-derived nutrition. Additionally, the health benefits of fermented vegetables and probiotics are examined, including their effects on mental health. Vegetable fermentation is a versatile method for enhancing food preservation, nutritional quality, and safety. This ancient practice prolongs the shelf life of perishable items, reduces the toxicity of raw ingredients, and improves digestibility. Specific starter cultures, particularly lactic acid bacteria, are essential for controlling fermentation, ensuring safety, and maximizing health benefits. Fermented vegetables, rich in probiotics, support gut health and immune function. Emerging research indicates their potential to alleviate adverse mental health symptoms such as stress and anxiety, highlighting their significance in modern dietary guidelines and chronic health management.",,2076-3417,,, ,  ,,out_of_scope,
2668,"**Title**Bioaccumulation, Bioindication and Health Risk Assessment of Heavy Metals in Cape Horse Mackerel (Trachurus trachurus) and Slinger Seabream (Chrysoblephus puniceus) in the Durban Basin and Cape Vidal, South Africa

**Abstract**The bioaccumulation of heavy metals (HMs) in marine fish is a growing global concern due to potential human health risks. The study analyzed HM in the muscle tissue, gills, and gut of adult male and female cape horse mackerel and slinger seabream caught in the polluted Durban Basin and pristine Cape Vidal from April 2018 to February 2019. Results revealed interspecific, spatial, and organ-specific variability in HM levels. In the Durban Basin, slinger seabream had bioaccumulation (in mg/kg) of As (2.3 & PLUSMN; 0.2), Cr (2.6 & PLUSMN; 0.2), Ni (2.0 & PLUSMN; 0.1), and Pb (4.1 & PLUSMN; 0.3) while cape horse mackerel had Ni (1.6 & PLUSMN; 0.2), Pb (4.7 & PLUSMN; 0.6), and Zn (52 & PLUSMN; 3.01) exceeding World Health Organization (WHO) regulatory limits. Metal pollution index (MPI) values were also higher in Durban Basin (> 5.13) than Cape Vidal (< 3.32) for both species' muscles. Liver and gills of slinger seabream and gut of cape horse mackerel exhibited higher HM accumulation patterns proportionate to the environmental concentrations, indicating the bioindicative potential of HM pollution by the two species. Risk assessment indicated that both fish species had target hazard quotient > 1 for Cr, and target cancer risk < 10(-4) for Pb, implying significant potential non-carcinogenic and carcinogenic health risks associated with fish consumption from the Durban Basin. The study recommends daily consumption limits of 16 g/day for slinger seabream and 14 g/day for cape horse mackerel to ensure health safety. The findings contribute to the understanding of HM pollution in the Durban Basin and provide important information for decision-makers and policymakers in developing effective strategies to mitigate and manage HM contamination in fish populations.","Debipersadh, Sanjeev; Ogola, Henry Joseph Oduor; Mearns, Kevin; Selvarajan, Ramganesh","Selvarajan, Ramganesh/AFA-6567-2022; Mearns, Kevin/C-7411-2015; Ogola, Henry Joseph Oduor/N-5904-2017","Selvarajan, Ramganesh/0000-0002-7104-3599; Mearns, Kevin/0000-0001-5874-3542; Ogola, Henry Joseph Oduor/0000-0003-1603-6430","Bioaccumulation, Bioindication and Health Risk Assessment of Heavy Metals in Cape Horse Mackerel (Trachurus trachurus) and Slinger Seabream (Chrysoblephus puniceus) in the Durban Basin and Cape Vidal, South Africa",,,10.1007/s00244-023-01028-8 ,Article; Early Access ,,"The bioaccumulation of heavy metals (HMs) in marine fish is a growing global concern due to potential human health risks. The study analyzed HM in the muscle tissue, gills, and gut of adult male and female cape horse mackerel and slinger seabream caught in the polluted Durban Basin and pristine Cape Vidal from April 2018 to February 2019. Results revealed interspecific, spatial, and organ-specific variability in HM levels. In the Durban Basin, slinger seabream had bioaccumulation (in mg/kg) of As (2.3 & PLUSMN; 0.2), Cr (2.6 & PLUSMN; 0.2), Ni (2.0 & PLUSMN; 0.1), and Pb (4.1 & PLUSMN; 0.3) while cape horse mackerel had Ni (1.6 & PLUSMN; 0.2), Pb (4.7 & PLUSMN; 0.6), and Zn (52 & PLUSMN; 3.01) exceeding World Health Organization (WHO) regulatory limits. Metal pollution index (MPI) values were also higher in Durban Basin (> 5.13) than Cape Vidal (< 3.32) for both species' muscles. Liver and gills of slinger seabream and gut of cape horse mackerel exhibited higher HM accumulation patterns proportionate to the environmental concentrations, indicating the bioindicative potential of HM pollution by the two species. Risk assessment indicated that both fish species had target hazard quotient > 1 for Cr, and target cancer risk < 10(-4) for Pb, implying significant potential non-carcinogenic and carcinogenic health risks associated with fish consumption from the Durban Basin. The study recommends daily consumption limits of 16 g/day for slinger seabream and 14 g/day for cape horse mackerel to ensure health safety. The findings contribute to the understanding of HM pollution in the Durban Basin and provide important information for decision-makers and policymakers in developing effective strategies to mitigate and manage HM contamination in fish populations.",0090-4341,1432-0703,,, ,  ,,out_of_scope,
2669,"**Title**A Pilot Study of an Educational and Clinical Mobile Application for Patients Receiving Radiation Treatment

**Abstract**Abstract
The use of IT applications for patients undergoing radiotherapy is limited. This study aimed to develop an integrated system for communication between patients and radiation oncologists using IT technology and report the first test results for the system “Assisted Radiation Oncology Mobile Application” (AROMA). This system consisted of a manager program, a server running on a PC, and a mobile application on a smartphone. A prospective survey was conducted to evaluate the usefulness of this system from October 2020 to January 2021. The survey consisted of a specific questionnaire on basic information and application use by the patients. The management program was designed such that the user (doctor) edits the treatment schedule, member (patient and doctor) information, self-management, disease information, and side effect questionnaire. The mobile application for patients consisted of the current schedule, treatment schedule calendar, side effect questionnaire, side effect management method, and disease information entered by the doctor. A total of 41 patients were enrolled in this study. The mean adverse event response time was 4.4 days. In the survey, the mobile application received positive views (8.6/10 points). Most responses related to the side effect reporting function (94%) and communication using the application (91%) were positive. Satisfaction with the application design and each menu item was high, with an average of ≥8 and ≥8.5 points in most cases, respectively. The survey showed good satisfaction with the design, operability, and reporting system. Therefore, the system can facilitate communication between patients and radiation oncologists in the future.
Keywords: radiotherapy, mobile application, mobile healthcare","Ladbury, C. J.; Culbert, M.; Huang, Z.; Abuali, T.; Chandra, R. A.; Maroongroge, S.; Glaser, S. M.; Dandapani, S. V.; Chen, Y. J.; Wong, J. Y. C.; Sampath, S.; Li, Y. R.; Amini, A.",,,A Pilot Study of an Educational and Clinical Mobile Application for Patients Receiving Radiation Treatment,120,2, ,Meeting Abstract ,,"Abstract
The use of IT applications for patients undergoing radiotherapy is limited. This study aimed to develop an integrated system for communication between patients and radiation oncologists using IT technology and report the first test results for the system “Assisted Radiation Oncology Mobile Application” (AROMA). This system consisted of a manager program, a server running on a PC, and a mobile application on a smartphone. A prospective survey was conducted to evaluate the usefulness of this system from October 2020 to January 2021. The survey consisted of a specific questionnaire on basic information and application use by the patients. The management program was designed such that the user (doctor) edits the treatment schedule, member (patient and doctor) information, self-management, disease information, and side effect questionnaire. The mobile application for patients consisted of the current schedule, treatment schedule calendar, side effect questionnaire, side effect management method, and disease information entered by the doctor. A total of 41 patients were enrolled in this study. The mean adverse event response time was 4.4 days. In the survey, the mobile application received positive views (8.6/10 points). Most responses related to the side effect reporting function (94%) and communication using the application (91%) were positive. Satisfaction with the application design and each menu item was high, with an average of ≥8 and ≥8.5 points in most cases, respectively. The survey showed good satisfaction with the design, operability, and reporting system. Therefore, the system can facilitate communication between patients and radiation oncologists in the future.
Keywords: radiotherapy, mobile application, mobile healthcare",0360-3016,1879-355X,,E699-E700, , 66th International Conference on American-Society-for-Radiation-Oncology (ASTRO)66th International Conference on American-Society-for-Radiation-Oncology (ASTRO) ,,out_of_scope,
2670,"**Title**Multivariate Statistical Methods and GIS-Based Evaluation of Potable Water in Urban Children's Parks Due to Potentially Toxic Elements Contamination: A Children's Health Risk Assessment Study in a Developing Country

**Abstract**Contamination of potentially toxic elements (PTEs) has received widespread attention in urban children's parks (UCPs) worldwide in the past few decades. However, the risk assessment of PTEs in drinking water sources of UCPs is still unknown particularly in developing countries. Hence, the present study investigated the spatial distribution, sources for PTEs (Cd, Cr, Pb, Ni, and Cu), and health risk assessment in drinking water sources of UCPs in Khyber Pakhtunkhwa, Pakistan. Among PTEs, Cd, Cr, and Pb had low to high concentrations and exceeded the safe limits of WHO and PAK-EPA in most UCPs. PCA results showed high anthropogenic and low natural sources, contributing to the release of PTEs in all UCPs. Heavy-metal pollution index (PTE-PI) results showed low to high pollution levels for all UCPs, with the highest values of 113 and 116 for Sardaryab Park Charsadda (SPC) and Zoo Park Peshawar (ZPP), respectively. Heavy-metal evaluation index (PTE-EI) results also showed low to high pollution levels for all UCPs. UCPs samples (50%) showed low pollution levels in PTE-PI results. To the contrary, UCPs samples (50%) exhibited high pollution levels in PTE-EI results. The non-carcinogenic risk of HQ and HI values of all PTEs were below the permissible limit (<1) for adults and children via ingestion and dermal contact. CR and TCR results showed that PTEs (Cr, Cd, Pb, and Ni) had the highest carcinogenic risk (>1.00 x 10(-4)) for both adults and children in all UCPs, except Cd and Ni for adults via the ingestion route, while Cr values (>1.00 x 10(-4)) were exceeded for children in some of the UCPs via the dermal route. Consequently, long-term exposure to toxic PTEs could pose a carcinogenic risk to the local population. Thus, the present study suggests that the government should implement enforcement with firm protocols and monitoring guidelines of environmental regulations to mitigate PTEs originating from anthropogenic sources in order to reduce health risks and improve public health safety in urban areas.","Ghani, Junaid; Nawab, Javed; Ullah, Zahid; Rafiq, Naseem; Hasan, Shah Zaib; Khan, Sardar; Shah, Muddaser; Almutairi, Mikhlid H.","Ullah, Zahid/ITW-0775-2023; Rafiq, Naseem/GVT-6215-2022; Nawab, Javed/HLQ-1477-2023","Shah, Muddaser/0000-0001-8839-4419; ALMUTAIRI, MIKHLID/0000-0002-0337-6412",Multivariate Statistical Methods and GIS-Based Evaluation of Potable Water in Urban Children's Parks Due to Potentially Toxic Elements Contamination: A Children's Health Risk Assessment Study in a Developing Country,15,17,10.3390/su151713177 ,Article ,,"Contamination of potentially toxic elements (PTEs) has received widespread attention in urban children's parks (UCPs) worldwide in the past few decades. However, the risk assessment of PTEs in drinking water sources of UCPs is still unknown particularly in developing countries. Hence, the present study investigated the spatial distribution, sources for PTEs (Cd, Cr, Pb, Ni, and Cu), and health risk assessment in drinking water sources of UCPs in Khyber Pakhtunkhwa, Pakistan. Among PTEs, Cd, Cr, and Pb had low to high concentrations and exceeded the safe limits of WHO and PAK-EPA in most UCPs. PCA results showed high anthropogenic and low natural sources, contributing to the release of PTEs in all UCPs. Heavy-metal pollution index (PTE-PI) results showed low to high pollution levels for all UCPs, with the highest values of 113 and 116 for Sardaryab Park Charsadda (SPC) and Zoo Park Peshawar (ZPP), respectively. Heavy-metal evaluation index (PTE-EI) results also showed low to high pollution levels for all UCPs. UCPs samples (50%) showed low pollution levels in PTE-PI results. To the contrary, UCPs samples (50%) exhibited high pollution levels in PTE-EI results. The non-carcinogenic risk of HQ and HI values of all PTEs were below the permissible limit (<1) for adults and children via ingestion and dermal contact. CR and TCR results showed that PTEs (Cr, Cd, Pb, and Ni) had the highest carcinogenic risk (>1.00 x 10(-4)) for both adults and children in all UCPs, except Cd and Ni for adults via the ingestion route, while Cr values (>1.00 x 10(-4)) were exceeded for children in some of the UCPs via the dermal route. Consequently, long-term exposure to toxic PTEs could pose a carcinogenic risk to the local population. Thus, the present study suggests that the government should implement enforcement with firm protocols and monitoring guidelines of environmental regulations to mitigate PTEs originating from anthropogenic sources in order to reduce health risks and improve public health safety in urban areas.",,2071-1050,,, ,  ,,out_of_scope,
2671,"**Title**The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement

**Abstract**YouTube is a major social media platform that plays a significant role in digital culture, with content creators at its core. These creators often engage in controversial behaviour to drive engagement, which can foster toxicity. This paper presents a quantitative analysis of controversial content on YouTube, focusing on the relationship between controversy, toxicity, and monetisation. We introduce a curated dataset comprising 20 controversial YouTube channels extracted from Reddit discussions, including 16,349 videos and more than 105 million comments. We identify and categorise monetisation cues from video descriptions into various models, including affiliate marketing and direct selling, using lists of URLs and keywords. Additionally, we train a machine learning model to measure the toxicity of comments in these videos. Our findings reveal that while toxic comments correlate with higher engagement, they negatively impact monetisation, indicating that controversy-driven interaction does not necessarily lead to financial gain. We also observed significant variation in monetisation strategies, with some creators showing extensive monetisation despite high toxicity levels. Our study introduces a curated dataset, lists of URLs and keywords to categorise monetisation, a machine learning model to measure toxicity, and is a significant step towards understanding the complex relationship between controversy, engagement, and monetisation on YouTube. The lists used for detecting and categorising monetisation cues are available on https://github.com/thalesbertaglia/toxmon.","Bertaglia, Thales; Goanta, Catalina; Iamnitchi, Adriana",,"Bertaglia, Thales/0000-0003-0897-4005; Goanta, Catalina/0000-0002-1044-9800",The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement,,,10.1145/3677117.3685005 ,Proceedings Paper ,,"YouTube is a major social media platform that plays a significant role in digital culture, with content creators at its core. These creators often engage in controversial behaviour to drive engagement, which can foster toxicity. This paper presents a quantitative analysis of controversial content on YouTube, focusing on the relationship between controversy, toxicity, and monetisation. We introduce a curated dataset comprising 20 controversial YouTube channels extracted from Reddit discussions, including 16,349 videos and more than 105 million comments. We identify and categorise monetisation cues from video descriptions into various models, including affiliate marketing and direct selling, using lists of URLs and keywords. Additionally, we train a machine learning model to measure the toxicity of comments in these videos. Our findings reveal that while toxic comments correlate with higher engagement, they negatively impact monetisation, indicating that controversy-driven interaction does not necessarily lead to financial gain. We also observed significant variation in monetisation strategies, with some creators showing extensive monetisation despite high toxicity levels. Our study introduces a curated dataset, lists of URLs and keywords to categorise monetisation, a machine learning model to measure toxicity, and is a significant step towards understanding the complex relationship between controversy, engagement, and monetisation on YouTube. The lists used for detecting and categorising monetisation cues are available on https://github.com/thalesbertaglia/toxmon.",,,979-8-4007-1082-7,1-9, , Conference on Open Challenges in Online Social Media (OASIS)Conference on Open Challenges in Online Social Media (OASIS) ,,out_but_toxicity,
2672,"**Title**Developing Epidemiological Models with Differentiated Infected Intensity

**Abstract**This study investigates the spread of toxic content on social media, a growing concern as online platforms serve as primary information sources. This research aims to enhance the accuracy of models capturing toxicity spread by differentiating between varying levels of toxicity intensity. Two epidemiological models are developed and assessed: the SEIRS model and a novel SEImIhRS model. The latter divides infected users into moderate and highly infected groups to reflect the varying severity of toxic behavior. Both models are tested on six datasets to evaluate their performance. The SEImIhRS model achieves even lower error rates, indicating a more precise representation of toxicity propagation. This research contributes a sophisticated tool for analyzing online toxicity, aiding policymakers and online platforms in developing targeted interventions and enhancing content moderation systems.","Yousefi, Niloofar; Agarwal, Nitin; Addai, Emmanuel","Addai, Emmanuel/AIF-1959-2022","Yousefi, Niloofar/0009-0005-0071-733X; Addai, Emmanuel/0000-0003-2159-6299",Developing Epidemiological Models with Differentiated Infected Intensity,14972,,10.1007/978-3-031-72241-7_6 ,Proceedings Paper ,,"This study investigates the spread of toxic content on social media, a growing concern as online platforms serve as primary information sources. This research aims to enhance the accuracy of models capturing toxicity spread by differentiating between varying levels of toxicity intensity. Two epidemiological models are developed and assessed: the SEIRS model and a novel SEImIhRS model. The latter divides infected users into moderate and highly infected groups to reflect the varying severity of toxic behavior. Both models are tested on six datasets to evaluate their performance. The SEImIhRS model achieves even lower error rates, indicating a more precise representation of toxicity propagation. This research contributes a sophisticated tool for analyzing online toxicity, aiding policymakers and online platforms in developing targeted interventions and enhancing content moderation systems.",0302-9743,1611-3349,978-3-031-72240-0; 978-3-031-72241-7,58-68, ," 17th International Conference on Social, Cultural, and Behavioral Modeling (SBP-BRiMS)17th International Conference on Social, Cultural, and Behavioral Modeling (SBP-BRiMS) ",,out_of_scope,
2673,"**Title**The influence of coordinated behavior on toxicity

**Abstract**In the intricate landscape of social media, genuine content dissemination may be altered by a number of threats. Coordinated Behavior (CB), defined as orchestrated efforts by entities to deceive or mislead users about their identity and intentions, emerges as a tactic to exploit or manipulate online discourse. This study delves into the relationship between CB and toxic conversation on X (formerly known as Twitter). Using a dataset of 11 million tweets from 1 million users preceding the 2019 UK general election, we show that users displaying CB typically disseminate less harmful content, irrespective of political affiliation. However, distinct toxicity patterns emerge among different coordinated cohorts. Compared to their non-CB counterparts, CB participants show marginally higher toxicity levels only when considering their original posts. We further show the effects of CB-driven toxic content on non-CB users, gauging its impact based on political leanings. Our findings suggest that CB only has a limited impact on the toxicity of digital discourse.","Loru, Edoardo; Cinelli, Matteo; Tesconi, Maurizio; Quattrociocchi, Walter","Loru, Edoardo/LRT-9718-2024; Cinelli, Matteo/AFO-0408-2022","Loru, Edoardo/0009-0007-4629-930X",The influence of coordinated behavior on toxicity,43-44,,10.1016/j.osnem.2024.100289 ,Article ,,"In the intricate landscape of social media, genuine content dissemination may be altered by a number of threats. Coordinated Behavior (CB), defined as orchestrated efforts by entities to deceive or mislead users about their identity and intentions, emerges as a tactic to exploit or manipulate online discourse. This study delves into the relationship between CB and toxic conversation on X (formerly known as Twitter). Using a dataset of 11 million tweets from 1 million users preceding the 2019 UK general election, we show that users displaying CB typically disseminate less harmful content, irrespective of political affiliation. However, distinct toxicity patterns emerge among different coordinated cohorts. Compared to their non-CB counterparts, CB participants show marginally higher toxicity levels only when considering their original posts. We further show the effects of CB-driven toxic content on non-CB users, gauging its impact based on political leanings. Our findings suggest that CB only has a limited impact on the toxicity of digital discourse.",,2468-6964,,, ,  ,,out_but_toxicity,
2674,"**Title**Anatomy of Hate Speech Datasets: Composition Analysis and Cross-dataset Classification

**Abstract**Manifestations of hate speech in different scenarios are increasingly frequent on social platforms. In this context, there is a large number of works that propose solutions for identifying this type of content in these environments. Most efforts to automatically detect hate speech follow the same process of supervised learning, using annotators to label a predefined set of messages, which are, in turn, used to train classifiers. However, annotators can create labels for different classification tasks, with divergent definitions of hate speech, binary or multi-label schemes, and various methodologies for collecting data. In this context, we examine the principal publicly available datasets for hate speech research. We investigate the types of hate speech (e.g., ethnicity, religion, sexual orientation) present in their composition, explore their content beyond the labels, and use cross-dataset classification to examine the use of the labeled data beyond its original work. Our results reveal interesting insights toward a better understanding of the hate speech phenomenon and improving its detection on social platforms.Warning. This paper contains offensive words and tweet examples.","Guimaraes, Samuel; Kakizaki, Gabriel; Melo, Philipe; Silva, Marcio; Murai, Fabricio; Reis, Julio C. S.; Benevenuto, Fabricio",,,Anatomy of Hate Speech Datasets: Composition Analysis and Cross-dataset Classification,,,10.1145/3603163.3609158 ,Proceedings Paper ,,"Manifestations of hate speech in different scenarios are increasingly frequent on social platforms. In this context, there is a large number of works that propose solutions for identifying this type of content in these environments. Most efforts to automatically detect hate speech follow the same process of supervised learning, using annotators to label a predefined set of messages, which are, in turn, used to train classifiers. However, annotators can create labels for different classification tasks, with divergent definitions of hate speech, binary or multi-label schemes, and various methodologies for collecting data. In this context, we examine the principal publicly available datasets for hate speech research. We investigate the types of hate speech (e.g., ethnicity, religion, sexual orientation) present in their composition, explore their content beyond the labels, and use cross-dataset classification to examine the use of the labeled data beyond its original work. Our results reveal interesting insights toward a better understanding of the hate speech phenomenon and improving its detection on social platforms.Warning. This paper contains offensive words and tweet examples.",,,979-8-4007-0232-7,, , 34th ACM Conference on Hypertext and Social Media (HT)34th ACM Conference on Hypertext and Social Media (HT) ,,evaluation#methodology,
2675,"**Title**Automated machine learning in nanotoxicity assessment: A comparative study of predictive model performance

**Abstract**Computational modeling has earned significant interest as an alternative to animal testing of toxicity assessment. However, the process of selecting an appropriate algorithm and fine-tuning hyperparameters for the developing of optimized models takes considerable time, expertise, and an intensive search. The recent emergence of automated machine learning (autoML) approaches, available as user-friendly platforms, has proven beneficial for individuals with limited knowledge in ML-based predictive model development. These autoML platforms automate crucial steps in model development, including data preprocessing, algorithm selection, and hyperparameter tuning. In this study, we used seven previously published and publicly available datasets for oxides and metals to develop nanotoxicity prediction models. AutoML platforms, namely Vertex AI, Azure, and Dataiku, were employed and performance measures such as accuracy, F1 score, precision, and recall for these autoML-based models were then compared with those of conventional ML-based models. The results demonstrated clearly that the autoML platforms produced more reliable nanotoxicity prediction models, outperforming those built with conventional ML algorithms. While none of the three autoML platforms significantly outperformed the others, distinctions exist among them in terms of the available options for choosing technical features throughout the model development steps. This allows users to select an autoML platform that aligns with their knowledge of predictive model development and its technical features. Additionally, prediction models constructed from datasets with better data quality displayed, enhanced performance than those built from datasets with lower data quality, indicating that future studies with high-quality datasets can further improve the performance of those autoML-based prediction models.","Xiao, Xiao; Trinh, Tung X.; Gerelkhuu, Zayakhuu; Ha, Eunyong; Yoon, Tae Hyun","Gerelkhuu, Zayakhuu/LEN-0275-2024; Trinh, Xuan-Tung/KHX-8849-2024","Gerelkhuu, Zayakhuu/0009-0007-5132-2703; Trinh, Xuan-Tung/0000-0002-8961-2876; Ha, Eunyong/0009-0002-1249-9745",Automated machine learning in nanotoxicity assessment: A comparative study of predictive model performance,25,,10.1016/j.csbj.2024.02.003 ,Article ,,"Computational modeling has earned significant interest as an alternative to animal testing of toxicity assessment. However, the process of selecting an appropriate algorithm and fine-tuning hyperparameters for the developing of optimized models takes considerable time, expertise, and an intensive search. The recent emergence of automated machine learning (autoML) approaches, available as user-friendly platforms, has proven beneficial for individuals with limited knowledge in ML-based predictive model development. These autoML platforms automate crucial steps in model development, including data preprocessing, algorithm selection, and hyperparameter tuning. In this study, we used seven previously published and publicly available datasets for oxides and metals to develop nanotoxicity prediction models. AutoML platforms, namely Vertex AI, Azure, and Dataiku, were employed and performance measures such as accuracy, F1 score, precision, and recall for these autoML-based models were then compared with those of conventional ML-based models. The results demonstrated clearly that the autoML platforms produced more reliable nanotoxicity prediction models, outperforming those built with conventional ML algorithms. While none of the three autoML platforms significantly outperformed the others, distinctions exist among them in terms of the available options for choosing technical features throughout the model development steps. This allows users to select an autoML platform that aligns with their knowledge of predictive model development and its technical features. Additionally, prediction models constructed from datasets with better data quality displayed, enhanced performance than those built from datasets with lower data quality, indicating that future studies with high-quality datasets can further improve the performance of those autoML-based prediction models.",2001-0370,,,9-19, ,  ,,out_of_scope,
2676,"**Title**Improving Hate Speech Detection Using Double-Layers Hybrid CNN-RNN Model on Imbalanced Dataset

**Abstract**Hate speech detection is crucial in curbing online toxicity and fostering a safer digital environment. Previous research has proposed the use of a hybrid CNN-RNN model for this purpose. This study aims to improve the performance of the hybrid CNN-RNN method by using a double-layer approach to address imbalanced datasets. The novelty lies in using double layers of hybrid CNN-RNN to enhance hate speech detection accuracy. This research also employed an oversampling technique alongside the double-layer model. The process included preprocessing, feature extraction, training tuning, testing, and performance evaluation. The results demonstrated that the double-layer hybrid CNN-RNN model achieved an accuracy of 0.827, a precision of 0.797, a recall of 0.759, and an F1 score of 0.883, with imbalanced data. Meanwhile, balanced data yielded a higher accuracy of 0.908, a precision of 0.943, a recall of 0.894, and an F1 score of 0.914. Moreover, the proposed model outperformed the hybrid CNN-RNN with an imbalanced dataset, generating an accuracy of 0.752, a precision of 0.797, a recall of 0.559, and an F1 score of 0.657. Dropout and early stopping techniques addressed overfitting in complex models and large datasets. This research has advanced hate speech detection methodologies by demonstrating the effectiveness of a double-layer hybrid CNN-RNN model, especially for imbalanced data. It underscores the importance of addressing imbalanced datasets for improved model accuracy. Future work could explore alternative data augmentation techniques or compare the proposed model with other architectures.","Riyadi, Slamet; Andriyani, Annisa Divayu; Sulaiman, Siti Noraini","Sulaiman, Siti Noraini/J-2316-2019",,Improving Hate Speech Detection Using Double-Layers Hybrid CNN-RNN Model on Imbalanced Dataset,12,,10.1109/ACCESS.2024.3487433 ,Article ,,"Hate speech detection is crucial in curbing online toxicity and fostering a safer digital environment. Previous research has proposed the use of a hybrid CNN-RNN model for this purpose. This study aims to improve the performance of the hybrid CNN-RNN method by using a double-layer approach to address imbalanced datasets. The novelty lies in using double layers of hybrid CNN-RNN to enhance hate speech detection accuracy. This research also employed an oversampling technique alongside the double-layer model. The process included preprocessing, feature extraction, training tuning, testing, and performance evaluation. The results demonstrated that the double-layer hybrid CNN-RNN model achieved an accuracy of 0.827, a precision of 0.797, a recall of 0.759, and an F1 score of 0.883, with imbalanced data. Meanwhile, balanced data yielded a higher accuracy of 0.908, a precision of 0.943, a recall of 0.894, and an F1 score of 0.914. Moreover, the proposed model outperformed the hybrid CNN-RNN with an imbalanced dataset, generating an accuracy of 0.752, a precision of 0.797, a recall of 0.559, and an F1 score of 0.657. Dropout and early stopping techniques addressed overfitting in complex models and large datasets. This research has advanced hate speech detection methodologies by demonstrating the effectiveness of a double-layer hybrid CNN-RNN model, especially for imbalanced data. It underscores the importance of addressing imbalanced datasets for improved model accuracy. Future work could explore alternative data augmentation techniques or compare the proposed model with other architectures.",2169-3536,,,159660-159668, ,  ,,detection,
2677,"**Title**Understanding and identifying the use of emotes in toxic chat on Twitch

**Abstract**The latest advances in NLP (natural language processing) have led to the launch of the much needed machine- driven toxic chat detection. Nevertheless, people continuously find new forms of hateful expressions that are easily identified by humans, but not by machines. One such common expression is the mix of text and emotes, a type of visual toxic chat that is increasingly used to evade algorithmic moderation and a trend that is an understudied aspect of the problem of online toxicity. This research analyzes chat conversations from the popular streaming platform Twitch to understand the varied types of visual toxic chat. Emotes were sometimes used to replace a letter, seek attention, or for emotional expression. We created a labeled dataset that contains 29,721 cases of emotes replacing letters. Based on the dataset, we built a neural network classifier and identified visual toxic chat that would otherwise be undetected through traditional methods and caught an additional 1.3% examples of toxic chat out of 15 million chat utterances.","Kim, Jaeheon; Wohn, Donghee Yvette; Cha, Meeyoung","Cha, Meeyoung/B-6925-2011; Cha, Meeyoung/KOD-4491-2024","Cha, Meeyoung/0000-0003-4085-9648",Understanding and identifying the use of emotes in toxic chat on Twitch,27,,10.1016/j.osnem.2021.100180 ,Article ,,"The latest advances in NLP (natural language processing) have led to the launch of the much needed machine- driven toxic chat detection. Nevertheless, people continuously find new forms of hateful expressions that are easily identified by humans, but not by machines. One such common expression is the mix of text and emotes, a type of visual toxic chat that is increasingly used to evade algorithmic moderation and a trend that is an understudied aspect of the problem of online toxicity. This research analyzes chat conversations from the popular streaming platform Twitch to understand the varied types of visual toxic chat. Emotes were sometimes used to replace a letter, seek attention, or for emotional expression. We created a labeled dataset that contains 29,721 cases of emotes replacing letters. Based on the dataset, we built a neural network classifier and identified visual toxic chat that would otherwise be undetected through traditional methods and caught an additional 1.3% examples of toxic chat out of 15 million chat utterances.",,2468-6964,,, ,  ,,Gen_dataset#detection,
2678,"**Title**Accuracy and Fairness for Web-Based Content Analysis under Temporal Shifts and Delayed Labeling

**Abstract**Web-based content analysis tasks, such as labeling toxicity, misinformation, or spam often rely on machine learning models to achieve cost and scale efficiencies. As these models impact real human lives, ensuring accuracy and fairness of such models is critical. However, maintaining the performance of these models over time can be challenging due to the temporal shifts in the application context and the sub-populations represented. Furthermore, there is often a delay in obtaining human expert labels for the raw data, which hinders the timely adaptation and safe deployment of the models. To overcome these challenges, we propose a novel approach that anticipates future distributions of data, especially in settings where unlabeled data becomes available earlier than the labels to estimate the future distribution of labels per sub-population and adapt the model preemptively. We evaluate our approach using multiple temporally-shifting datasets and consider bias based on racial, political, and demographic identities. We find that the proposed approach yields promising performance with respect to both accuracy and fairness. Our paper contributes to the web science literature by proposing a novel method for enhancing the quality and equity of web-based content analysis using machine learning. Experimental code and datasets are publicly available at https://github.com/Behavioral-Informatics-Lab/FAIRCAST.","Almuzaini, Abdulaziz A.; Pennock, David M.; Singh, Vivek K.",,"Singh, Vivek Kumar/0000-0002-8194-2336; Pennock, David/0000-0003-0522-4815",Accuracy and Fairness for Web-Based Content Analysis under Temporal Shifts and Delayed Labeling,,,10.1145/3614419.3644028 ,Proceedings Paper ,,"Web-based content analysis tasks, such as labeling toxicity, misinformation, or spam often rely on machine learning models to achieve cost and scale efficiencies. As these models impact real human lives, ensuring accuracy and fairness of such models is critical. However, maintaining the performance of these models over time can be challenging due to the temporal shifts in the application context and the sub-populations represented. Furthermore, there is often a delay in obtaining human expert labels for the raw data, which hinders the timely adaptation and safe deployment of the models. To overcome these challenges, we propose a novel approach that anticipates future distributions of data, especially in settings where unlabeled data becomes available earlier than the labels to estimate the future distribution of labels per sub-population and adapt the model preemptively. We evaluate our approach using multiple temporally-shifting datasets and consider bias based on racial, political, and demographic identities. We find that the proposed approach yields promising performance with respect to both accuracy and fairness. Our paper contributes to the web science literature by proposing a novel method for enhancing the quality and equity of web-based content analysis using machine learning. Experimental code and datasets are publicly available at https://github.com/Behavioral-Informatics-Lab/FAIRCAST.",,,979-8-4007-0334-8,268-278, ," 16th ACM Web Science Conference (WebScience) - Reflecting on the Web, AI, and Society16th ACM Web Science Conference (WebScience) - Reflecting on the Web, AI, and Society ",,detection#methodology,
2679,"**Title**Constructive and Toxic Speech Detection for Open-Domain Social Media Comments in Vietnamese

**Abstract**The rise of social media has led to the increasing of comments on online forums. However, there still exists invalid comments which are not informative for users. Moreover, those comments are also quite toxic and harmful to people. In this paper, we create a dataset for constructive and toxic speech detection, named UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset) with 10,000 human-annotated comments. For these tasks, we propose a system for constructive and toxic speech detection with the state-of-the-art transfer learning model in Vietnamese NLP as PhoBERT. With this system, we obtain F1-scores of 78.59% and 59.40% for classifying constructive and toxic comments, respectively. Besides, we implement various baseline models as traditional Machine Learning and Deep Neural Network-Based models to evaluate the dataset. With the results, we can solve several tasks on the online discussions and develop the framework for identifying constructiveness and toxicity of Vietnamese social media comments automatically.",Luan Thanh Nguyen; Kiet Van Nguyen; Ngan Luu-Thuy Nguyen,,"Nguyen, Luan/0000-0003-4882-8336",Constructive and Toxic Speech Detection for Open-Domain Social Media Comments in Vietnamese,12798,,10.1007/978-3-030-79457-6_49 ,Proceedings Paper ,,"The rise of social media has led to the increasing of comments on online forums. However, there still exists invalid comments which are not informative for users. Moreover, those comments are also quite toxic and harmful to people. In this paper, we create a dataset for constructive and toxic speech detection, named UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset) with 10,000 human-annotated comments. For these tasks, we propose a system for constructive and toxic speech detection with the state-of-the-art transfer learning model in Vietnamese NLP as PhoBERT. With this system, we obtain F1-scores of 78.59% and 59.40% for classifying constructive and toxic comments, respectively. Besides, we implement various baseline models as traditional Machine Learning and Deep Neural Network-Based models to evaluate the dataset. With the results, we can solve several tasks on the online discussions and develop the framework for identifying constructiveness and toxicity of Vietnamese social media comments automatically.",2945-9133,1611-3349,978-3-030-79456-9; 978-3-030-79457-6,572-583, ," 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems (IEA/AIE)34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems (IEA/AIE) ",,out_but_toxicity,
2680,"**Title**Persistent interaction patterns across social media platforms and over time

**Abstract**Growing concern surrounds the impact of social media platforms on public discourse(1-4) and their influence on social dynamics(5-9), especially in the context of toxicity(10-12). Here, to better understand these phenomena, we use a comparative approach to isolate human behavioural patterns across multiple social media platforms. In particular, we analyse conversations in different online communities, focusing on identifying consistent patterns of toxic content. Drawing from an extensive dataset that spans eight platforms over 34 years-from Usenet to contemporary social media-our findings show consistent conversation patterns and user behaviour, irrespective of the platform, topic or time. Notably, although long conversations consistently exhibit higher toxicity, toxic language does not invariably discourage people from participating in a conversation, and toxicity does not necessarily escalate as discussions evolve. Our analysis suggests that debates and contrasting sentiments among users significantly contribute to more intense and hostile discussions. Moreover, the persistence of these patterns across three decades, despite changes in platforms and societal norms, underscores the pivotal role of human behaviour in shaping online discourse.","Avalle, Michele; Di Marco, Niccolo; Etta, Gabriele; Sangiorgio, Emanuele; Alipour, Shayan; Bonetti, Anita; Alvisi, Lorenzo; Scala, Antonio; Baronchelli, Andrea; Cinelli, Matteo; Quattrociocchi, Walter","Cinelli, Matteo/AFO-0408-2022; Alipour, Shayan/KGM-2672-2024; Scala, Antonio/A-2098-2012; Avalle, Michele/KVA-6179-2024; Baronchelli, Andrea/F-9550-2016","Di Marco, Niccolo/0000-0003-4335-7328; Alvisi, Lorenzo/0009-0007-4222-348X; Scala, Antonio/0000-0002-3414-2686; Sangiorgio, Emanuele/0009-0003-1024-3735; Avalle, Michele/0009-0007-4934-2326; Baronchelli, Andrea/0000-0002-0255-0829",Persistent interaction patterns across social media platforms and over time,628,8008,10.1038/s41586-024-07229-y ,Article ,,"Growing concern surrounds the impact of social media platforms on public discourse(1-4) and their influence on social dynamics(5-9), especially in the context of toxicity(10-12). Here, to better understand these phenomena, we use a comparative approach to isolate human behavioural patterns across multiple social media platforms. In particular, we analyse conversations in different online communities, focusing on identifying consistent patterns of toxic content. Drawing from an extensive dataset that spans eight platforms over 34 years-from Usenet to contemporary social media-our findings show consistent conversation patterns and user behaviour, irrespective of the platform, topic or time. Notably, although long conversations consistently exhibit higher toxicity, toxic language does not invariably discourage people from participating in a conversation, and toxicity does not necessarily escalate as discussions evolve. Our analysis suggests that debates and contrasting sentiments among users significantly contribute to more intense and hostile discussions. Moreover, the persistence of these patterns across three decades, despite changes in platforms and societal norms, underscores the pivotal role of human behaviour in shaping online discourse.",0028-0836,1476-4687,,, ,  ,,Gen_dataset,
2681,"**Title**QSAR modelling of enzyme inhibition toxicity of ionic liquid based on chaotic spotted hyena optimization algorithm

**Abstract**Ionic liquids (ILs) have attracted considerable interest due to their unique properties and prospective uses in various industries. However, their potential toxicity, particularly regarding enzyme inhibition, has become a growing concern. In this study, a QSAR model was proposed to predict the enzyme inhibition toxicity of ILs. A dataset of diverse ILs with corresponding toxicity data against three enzymes was compiled. Molecular descriptors that capture the physicochemical, structural, and topological properties of the ILs were calculated. To optimize the selection of descriptors and develop a robust QSAR model, the chaotic spotted hyena optimization algorithm, a novel nature-inspired metaheuristic, was employed. The proposed algorithm efficiently searches for an optimal subset of descriptors and model parameters, enhancing the predictive performance and interpretability of the QSAR model. The developed model exhibits excellent predictive capability, with high classification accuracy and low computation time. Sensitivity analysis and molecular interpretation of the selected descriptors provide insights into the critical structural features influencing the toxicity of ILs. This study showcases the successful application of the chaotic spotted hyena optimization algorithm in QSAR modelling and contributes to a better understanding of the toxicity mechanisms of ILs, aiding in the design of safer alternatives for industrial applications.","Alharthi, A. M.; Al-Thanoon, N. A.; Al-Fakih, A. M.; Algamal, Z. Y.","Alharthi, Aiedh/ABB-8188-2020; Al-Thanoon, Niam/AAM-8782-2020; Al-Fakih, Abdo/GVT-0221-2022; Algamal, Zakariya/D-9767-2019","Algamal, Zakariya/0000-0002-0229-7958; Alharthi, Aiedh/0000-0002-4379-9532",QSAR modelling of enzyme inhibition toxicity of ionic liquid based on chaotic spotted hyena optimization algorithm,35,9,10.1080/1062936X.2024.2404853 ,Article ,,"Ionic liquids (ILs) have attracted considerable interest due to their unique properties and prospective uses in various industries. However, their potential toxicity, particularly regarding enzyme inhibition, has become a growing concern. In this study, a QSAR model was proposed to predict the enzyme inhibition toxicity of ILs. A dataset of diverse ILs with corresponding toxicity data against three enzymes was compiled. Molecular descriptors that capture the physicochemical, structural, and topological properties of the ILs were calculated. To optimize the selection of descriptors and develop a robust QSAR model, the chaotic spotted hyena optimization algorithm, a novel nature-inspired metaheuristic, was employed. The proposed algorithm efficiently searches for an optimal subset of descriptors and model parameters, enhancing the predictive performance and interpretability of the QSAR model. The developed model exhibits excellent predictive capability, with high classification accuracy and low computation time. Sensitivity analysis and molecular interpretation of the selected descriptors provide insights into the critical structural features influencing the toxicity of ILs. This study showcases the successful application of the chaotic spotted hyena optimization algorithm in QSAR modelling and contributes to a better understanding of the toxicity mechanisms of ILs, aiding in the design of safer alternatives for industrial applications.",1062-936X,1029-046X,,757-770, ,  ,,out_of_scope,
2682,"**Title**FAIR assessment of nanosafety data reusability with community standards

**Abstract**Nanomaterials hold great promise for improving our society, and it is crucial to understand their effects on biological systems in order to enhance their properties and ensure their safety. However, the lack of consistency in experimental reporting, the absence of universally accepted machine-readable metadata standards, and the challenge of combining such standards hamper the reusability of previously produced data for risk assessment. Fortunately, the research community has responded to these challenges by developing minimum reporting standards that address several of these issues. By converting twelve published minimum reporting standards into a machine-readable representation using FAIR maturity indicators, we have created a machine-friendly approach to annotate and assess datasets' reusability according to those standards. Furthermore, our NanoSafety Data Reusability Assessment (NSDRA) framework includes a metadata generator web application that can be integrated into experimental data management, and a new web application that can summarize the reusability of nanosafety datasets for one or more subsets of maturity indicators, tailored to specific computational risk assessment use cases. This approach enhances the transparency, communication, and reusability of experimental data and metadata. With this improved FAIR approach, we can facilitate the reuse of nanosafety research for exploration, toxicity prediction, and regulation, thereby advancing the field and benefiting society as a whole.","Ammar, Ammar; Evelo, Chris; Willighagen, Egon","Ammar, Ammar/CAF-7943-2022","Willighagen, Egon/0000-0001-7542-0286; Ammar, Ammar/0000-0002-8399-8990",FAIR assessment of nanosafety data reusability with community standards,11,1,10.1038/s41597-024-03324-x ,Article ,,"Nanomaterials hold great promise for improving our society, and it is crucial to understand their effects on biological systems in order to enhance their properties and ensure their safety. However, the lack of consistency in experimental reporting, the absence of universally accepted machine-readable metadata standards, and the challenge of combining such standards hamper the reusability of previously produced data for risk assessment. Fortunately, the research community has responded to these challenges by developing minimum reporting standards that address several of these issues. By converting twelve published minimum reporting standards into a machine-readable representation using FAIR maturity indicators, we have created a machine-friendly approach to annotate and assess datasets' reusability according to those standards. Furthermore, our NanoSafety Data Reusability Assessment (NSDRA) framework includes a metadata generator web application that can be integrated into experimental data management, and a new web application that can summarize the reusability of nanosafety datasets for one or more subsets of maturity indicators, tailored to specific computational risk assessment use cases. This approach enhances the transparency, communication, and reusability of experimental data and metadata. With this improved FAIR approach, we can facilitate the reuse of nanosafety research for exploration, toxicity prediction, and regulation, thereby advancing the field and benefiting society as a whole.",,2052-4463,,, ,  ,,out_of_scope,
2683,"**Title**Towards Causality Inference for Very Important Person Localization

**Abstract**Very Important Person Localization (VIPLoc) aims at detecting certain individuals in a given image, who are more attractive than others in the image. Existing uncontrolled VIPLoc benchmark assumes that the image has one single VIP, which is not suitable for actual application scenarios when multiple VIPs or no VIPs appear in the image. In this paper, we re-built a complex uncontrolled conditions (CUC) dataset to make the VIPLoc closer to the actual situation, containing no, single, and multiple VIPs. Existing methods use the hand-designed and deep learning strategies to extract the features of persons and analyze the differences between VIPs and other persons from the perspective of statistics. They are not explainable as to why the VIP located this output for that input. Thus, there exist the severe performance degradation when we use these models in real-world VIPLoc. Specifically, we establish a causal inference framework that unpacks the causes of previous methods and derives a new principled solution for VIPLoc. It treats the scene as confounding factor, allowing the ever-elusive confounding effects to be eliminated and the essential determinants to be uncovered. Through extensive experiments, our method outperforms the state-of-the-art methods on public VIPLoc datasets and the re-built CUC dataset.","Wang, Xiao; Wang, Zheng; Liu, Wu; Xu, Xin; Zhao, Qijun; Satoh, Shin'ichi","Xu, Xin/JRW-5800-2023",,Towards Causality Inference for Very Important Person Localization,,,10.1145/3503161.3548014 ,Proceedings Paper ,,"Very Important Person Localization (VIPLoc) aims at detecting certain individuals in a given image, who are more attractive than others in the image. Existing uncontrolled VIPLoc benchmark assumes that the image has one single VIP, which is not suitable for actual application scenarios when multiple VIPs or no VIPs appear in the image. In this paper, we re-built a complex uncontrolled conditions (CUC) dataset to make the VIPLoc closer to the actual situation, containing no, single, and multiple VIPs. Existing methods use the hand-designed and deep learning strategies to extract the features of persons and analyze the differences between VIPs and other persons from the perspective of statistics. They are not explainable as to why the VIP located this output for that input. Thus, there exist the severe performance degradation when we use these models in real-world VIPLoc. Specifically, we establish a causal inference framework that unpacks the causes of previous methods and derives a new principled solution for VIPLoc. It treats the scene as confounding factor, allowing the ever-elusive confounding effects to be eliminated and the essential determinants to be uncovered. Through extensive experiments, our method outperforms the state-of-the-art methods on public VIPLoc datasets and the re-built CUC dataset.",,,978-1-4503-9203-7,6618-6626, , 30th ACM International Conference on Multimedia (MM)30th ACM International Conference on Multimedia (MM) ,,out_of_scope,
2684,"**Title**IndicCONAN: A Multilingual Dataset for Combating Hate Speech in Indian Context

**Abstract**Hate speech (HS) is a growing concern in many parts of the world, including India, where it has led to numerous instances of violence and discrimination. The development of effective counter-narratives (CNs) is a critical step in combating hate speech, but there is a lack of research in this area, especially in non-English languages. In this paper, we introduce a new dataset, IndicCONAN, of counter-narratives against hate speech in Hindi and Indian English. We propose a scalable human-in-the-loop approach for generating counter-narratives by an auto-regressive language model through machine generation - human correction cycle, where the model uses augmented data from previous cycles to generate new training samples. These newly generated samples are then reviewed and edited by annotators, leading to further model refinement. The dataset consists of over (2) over tilde ,500 examples of counter-narratives each in both English and Hindi corresponding to various hate speeches in the Indian context. We also present a framework for generating CNs conditioned on specific CN type with a mean perplexity of 3.85 for English and 3.70 for Hindi, a mean toxicity score of 0.04 for English and 0.06 for Hindi, and a mean diversity of 0.08 for English and 0.14 for Hindi. Our dataset and framework provide valuable resources for researchers and practitioners working to combat hate speech in the Indian context.","Sahoo, Nihar Ranja; Beria, Gyana Prakash; Bhattacharyya, Pushpak",,,IndicCONAN: A Multilingual Dataset for Combating Hate Speech in Indian Context,,, ,Proceedings Paper ,,"Hate speech (HS) is a growing concern in many parts of the world, including India, where it has led to numerous instances of violence and discrimination. The development of effective counter-narratives (CNs) is a critical step in combating hate speech, but there is a lack of research in this area, especially in non-English languages. In this paper, we introduce a new dataset, IndicCONAN, of counter-narratives against hate speech in Hindi and Indian English. We propose a scalable human-in-the-loop approach for generating counter-narratives by an auto-regressive language model through machine generation - human correction cycle, where the model uses augmented data from previous cycles to generate new training samples. These newly generated samples are then reviewed and edited by annotators, leading to further model refinement. The dataset consists of over (2) over tilde ,500 examples of counter-narratives each in both English and Hindi corresponding to various hate speeches in the Indian context. We also present a framework for generating CNs conditioned on specific CN type with a mean perplexity of 3.85 for English and 3.70 for Hindi, a mean toxicity score of 0.04 for English and 0.06 for Hindi, and a mean diversity of 0.08 for English and 0.14 for Hindi. Our dataset and framework provide valuable resources for researchers and practitioners working to combat hate speech in the Indian context.",2159-5399,2374-3468,*****************,22313-22321, , 38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence ,,out_but_toxicity,
2685,"**Title**AlexU-BackTranslation-TL at SemEval-2020 Task 12: Improving Offensive Language Detection using Data Augmentation and Transfer Learning

**Abstract**Social media platforms, online news commenting spaces, and many other public forums have become widely known for issues of abusive behavior such as cyber-bullying and personal attacks. In this paper, we use the annotated tweets of Offensive Language Identification Dataset (OLID) to train three levels of deep learning classifiers to solve the three sub-tasks associated with the dataset. Sub-task A is to determine if the tweet is toxic or not. Then, for offensive tweets, sub-task B requires determining whether the toxicity is targeted. Finally, for sub-task C, we predict the target of the offense; i.e. a group, individual or other entity. In our solution, we tackle the problem of class imbalance in the dataset by using back translation for data augmentation and utilizing fine-tuned BERT model in an ensemble of deep learning classifiers. We used this solution to participate in the three English sub-tasks of SemEval-2020 task 12. The proposed solution achieved 0:91393, 0:6300 and 0:57607 macro F1-average in sub-tasks A, B and C respectively. We achieved the 8th, 14th and 21st places for sub-tasks A, B and C respectively.","Ibrahim, Mai; Torki, Marwan; El-Makky, Nagwa","Torki, Marwan/ACE-3852-2022","Torki, Marwan/0000-0002-6149-1718",AlexU-BackTranslation-TL at SemEval-2020 Task 12: Improving Offensive Language Detection using Data Augmentation and Transfer Learning,,, ,Proceedings Paper ,,"Social media platforms, online news commenting spaces, and many other public forums have become widely known for issues of abusive behavior such as cyber-bullying and personal attacks. In this paper, we use the annotated tweets of Offensive Language Identification Dataset (OLID) to train three levels of deep learning classifiers to solve the three sub-tasks associated with the dataset. Sub-task A is to determine if the tweet is toxic or not. Then, for offensive tweets, sub-task B requires determining whether the toxicity is targeted. Finally, for sub-task C, we predict the target of the offense; i.e. a group, individual or other entity. In our solution, we tackle the problem of class imbalance in the dataset by using back translation for data augmentation and utilizing fine-tuned BERT model in an ensemble of deep learning classifiers. We used this solution to participate in the three English sub-tasks of SemEval-2020 task 12. The proposed solution achieved 0:91393, 0:6300 and 0:57607 macro F1-average in sub-tasks A, B and C respectively. We achieved the 8th, 14th and 21st places for sub-tasks A, B and C respectively.",,,978-1-952148-31-6,1881-1890, , 14th International Workshops on Semantic Evaluation (SemEval)14th International Workshops on Semantic Evaluation (SemEval) ,,detection,
2686,No abstract available,"Gil, M.; Harrow, S.; Nailon, W.; Marshall, S.; Doucet, R.; Bahig, H.; Bissonnette, J. P.; Hope, A.; Debenham, B. J.; Gaede, S.; Warner, A.; Ryerson, C.; Palma, D. A.","Bissonnette, Jean-Pierre/LLW-8842-2024","Gil, Matthew/0000-0003-2108-3274",Predicting Pulmonary Toxicity in Lung Cancer Patients with Interstitial Lung Disease Receiving SABR Using Machine Learning: A Secondary Analysis of ASPIRE-ILD,120,2, ,Meeting Abstract ,,,0360-3016,1879-355X,,S171-S172, , 66th International Conference on American-Society-for-Radiation-Oncology (ASTRO)66th International Conference on American-Society-for-Radiation-Oncology (ASTRO) ,,out_of_scope,
2687,"**Title**Moral Values in Social Media for Disinformation and Hate Speech Analysis

**Abstract**Social networks face criticism for their links to disinformation and hate speech but offer unprecedented research opportunities to contrast them. This work focuses on three categories in the Italian social dialogue: political entities (parties or politicians), reliable news outlets and questionable news outlets. Social media behavioural differences emerge between these categories when including moral information in analysing tweet production and their responses. We created a dataset of over 175,000 tweets on immigration covering a 5-year period and enriched it with reliability annotation and toxicity scores. Also, we exploited a neural network model to label tweets according to the Moral Foundations Theory. We found significant relations between moral information, unreliability, engagement, and toxicity score, allowing us to interpret those behaviours. These relationswere analysed over time for tweets sorted bymoral content, and significant differences in the distribution of production and toxicity levels emerged between the categories. This result and the analysis of similarities between the accounts based on moral expressions and community engagement showed that the accounts categories have distinct behaviours, demonstrating the importance of moral information in assessing the news and political debate in social media.","Brugnoli, Emanuele; Gravino, Pietro; Prevedello, Giulio","Gravino, Pietro/JCO-2254-2023; Brugnoli, Emanuele/LTZ-1737-2024","Gravino, Pietro/0000-0002-0937-8830",Moral Values in Social Media for Disinformation and Hate Speech Analysis,14520,,10.1007/978-3-031-58202-8_5 ,Proceedings Paper ,,"Social networks face criticism for their links to disinformation and hate speech but offer unprecedented research opportunities to contrast them. This work focuses on three categories in the Italian social dialogue: political entities (parties or politicians), reliable news outlets and questionable news outlets. Social media behavioural differences emerge between these categories when including moral information in analysing tweet production and their responses. We created a dataset of over 175,000 tweets on immigration covering a 5-year period and enriched it with reliability annotation and toxicity scores. Also, we exploited a neural network model to label tweets according to the Moral Foundations Theory. We found significant relations between moral information, unreliability, engagement, and toxicity score, allowing us to interpret those behaviours. These relationswere analysed over time for tweets sorted bymoral content, and significant differences in the distribution of production and toxicity levels emerged between the categories. This result and the analysis of similarities between the accounts based on moral expressions and community engagement showed that the accounts categories have distinct behaviours, demonstrating the importance of moral information in assessing the news and political debate in social media.",2945-9133,1611-3349,978-3-031-58204-2; 978-3-031-58202-8,67-82, , 1st International Workshop on Value Engineering in Artificial Intelligence (VALE)1st International Workshop on Value Engineering in Artificial Intelligence (VALE) ,,out_but_toxicity,
2688,"**Title**An approach of data augmentation to improve the performance of BERTology models for vietnamese hate speech detection

**Abstract**Hate speech detection on social media networks is the classification task that automatically detects harmful comments from users and prevents the appearance of those toxic comments on social sites. The profit of the hate speech detection task is preventing harassment and toxicity content on the social networks site to protect the users that join the social media networks. Many attempts to solve the problem of hate speech detection in Vietnamese social texts have been proposed and achieved optimal results. However, with the robust ability of BERTology, the advantage of popular text pre-processing methods is not as significant as traditional models. In this paper, we investigate the effect of text pre-processing methods to the BERTology models on the two Vietnamese hate speech detection datasets - the ViHSD and the UIT-ViCTSD. The results show that the popular text pre-processing methods are not efficient in the performance of the classification models. Besides, we propose a new approach for the EDA data augmentation that has more benefit for the BERTology models when training with the imbalance dataset. Moreover, we also implement the Focal loss for BERTology models to investigate the efficiency in imbalanced classification. From the empirical results, our proposed EDA method is good for both multiclass and binary classification, while the Focal loss shows its robustness for only the multiclass classification when working with imbalanced data.","Luu, Son T.; Van Nguyen, Kiet; Nguyen, Ngan Luu-Thuy","Luu, Son/AAY-5897-2020","Luu, Son T./0000-0002-1231-5865",An approach of data augmentation to improve the performance of BERTology models for vietnamese hate speech detection,,,10.1007/s11042-023-16968-5 ,Article; Early Access ,,"Hate speech detection on social media networks is the classification task that automatically detects harmful comments from users and prevents the appearance of those toxic comments on social sites. The profit of the hate speech detection task is preventing harassment and toxicity content on the social networks site to protect the users that join the social media networks. Many attempts to solve the problem of hate speech detection in Vietnamese social texts have been proposed and achieved optimal results. However, with the robust ability of BERTology, the advantage of popular text pre-processing methods is not as significant as traditional models. In this paper, we investigate the effect of text pre-processing methods to the BERTology models on the two Vietnamese hate speech detection datasets - the ViHSD and the UIT-ViCTSD. The results show that the popular text pre-processing methods are not efficient in the performance of the classification models. Besides, we propose a new approach for the EDA data augmentation that has more benefit for the BERTology models when training with the imbalance dataset. Moreover, we also implement the Focal loss for BERTology models to investigate the efficiency in imbalanced classification. From the empirical results, our proposed EDA method is good for both multiclass and binary classification, while the Focal loss shows its robustness for only the multiclass classification when working with imbalanced data.",1380-7501,1573-7721,,, ,  ,,out_but_toxicity,
2689,"**Title**Detecting Community Sensitive Norm Violations in Online Conversations

**Abstract**Online platforms and communities establish their own norms that govern what behavior is acceptable within the community. Substantial effort in NLP has focused on identifying unacceptable behaviors and, recently, on forecasting them before they occur. However, these efforts have largely focused on toxicity as the sole form of community norm violation. Such focus has overlooked the much larger set of rules that moderators enforce. Here, we introduce a new dataset focusing on a more complete spectrum of community norms and their violations in the local conversational and global community contexts. We introduce a series of models that use this data to develop context- and community-sensitive norm violation detection, showing that these changes give high performance.(1)","Park, Chan Young; Mendelsohn, Julia; Radhakrishnan, Karthik; Jain, Kinjal; Kanakagiri, Tushar; Jurgens, David; Tsvetkov, Yulia",,"Jurgens, David/0000-0002-2135-9878",Detecting Community Sensitive Norm Violations in Online Conversations,,, ,Proceedings Paper ,,"Online platforms and communities establish their own norms that govern what behavior is acceptable within the community. Substantial effort in NLP has focused on identifying unacceptable behaviors and, recently, on forecasting them before they occur. However, these efforts have largely focused on toxicity as the sole form of community norm violation. Such focus has overlooked the much larger set of rules that moderators enforce. Here, we introduce a new dataset focusing on a more complete spectrum of community norms and their violations in the local conversational and global community contexts. We introduce a series of models that use this data to develop context- and community-sensitive norm violation detection, showing that these changes give high performance.(1)",,,978-1-955917-10-0,3386-3397, , Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP) ,,out_but_toxicity,
2690,"**Title**Evaluating Twitter's algorithmic amplification of low-credibility content: an observational study

**Abstract**Artificial intelligence (AI)-powered recommender systems play a crucial role in determining the content that users are exposed to on social media platforms. However, the behavioural patterns of these systems are often opaque, complicating the evaluation of their impact on the dissemination and consumption of disinformation and misinformation. To begin addressing this evidence gap, this study presents a measurement approach that uses observed digital traces to infer the status of algorithmic amplification of low-credibility content on Twitter over a 14-day period in January 2023. Using an original dataset of approximate to 2.7 million posts on COVID-19 and climate change published on the platform, this study identifies tweets sharing information from low-credibility domains, and uses a bootstrapping model with two stratifications, a tweet's engagement level and a user's followers level, to compare any differences in impressions generated between low-credibility and high-credibility samples. Additional stratification variables of toxicity, political bias, and verified status are also examined. This analysis provides valuable observational evidence on whether the Twitter algorithm favours the visibility of low-credibility content, with results indicating that, on aggregate, tweets containing low-credibility URL domains perform better than tweets that do not across both datasets. However, this effect is largely attributable to a difference in high-engagement, high-followers tweets, which are very impactful in terms of impressions generation, and are more likely receive amplified visibility when containing low-credibility content. Furthermore, high toxicity tweets and those with right-leaning bias see heightened amplification, as do low-credibility tweets from verified accounts. Ultimately, this suggests that Twitter's recommender system may have facilitated the diffusion of false content by amplifying the visibility of low-credibility content with high-engagement generated by very influential users.","Corsi, Giulio",,"Corsi, Giulio/0000-0002-5130-2258",Evaluating Twitter's algorithmic amplification of low-credibility content: an observational study,13,1,10.1140/epjds/s13688-024-00456-3 ,Article ,,"Artificial intelligence (AI)-powered recommender systems play a crucial role in determining the content that users are exposed to on social media platforms. However, the behavioural patterns of these systems are often opaque, complicating the evaluation of their impact on the dissemination and consumption of disinformation and misinformation. To begin addressing this evidence gap, this study presents a measurement approach that uses observed digital traces to infer the status of algorithmic amplification of low-credibility content on Twitter over a 14-day period in January 2023. Using an original dataset of approximate to 2.7 million posts on COVID-19 and climate change published on the platform, this study identifies tweets sharing information from low-credibility domains, and uses a bootstrapping model with two stratifications, a tweet's engagement level and a user's followers level, to compare any differences in impressions generated between low-credibility and high-credibility samples. Additional stratification variables of toxicity, political bias, and verified status are also examined. This analysis provides valuable observational evidence on whether the Twitter algorithm favours the visibility of low-credibility content, with results indicating that, on aggregate, tweets containing low-credibility URL domains perform better than tweets that do not across both datasets. However, this effect is largely attributable to a difference in high-engagement, high-followers tweets, which are very impactful in terms of impressions generation, and are more likely receive amplified visibility when containing low-credibility content. Furthermore, high toxicity tweets and those with right-leaning bias see heightened amplification, as do low-credibility tweets from verified accounts. Ultimately, this suggests that Twitter's recommender system may have facilitated the diffusion of false content by amplifying the visibility of low-credibility content with high-engagement generated by very influential users.",,2193-1127,,, ,  ,,out_of_scope,
2691,"**Title**Mineralogical, Petrological and Geochemical Characterisation of Chrysotile, Amosite and Crocidolite Asbestos Mine Waste from Southern Africa in Context of Risk Assessment and Rehabilitation

**Abstract**Derelict asbestos mine sites in South Africa pose a considerable risk to human, environmental and socio-economic health. Comprehensive mineralogical and geochemical datasets for the existing hazardous geological materials still exposed in Southern African derelict asbestos mines remain largely non-existent, as very little published and up-to-date literature is available. In this study, three representative types of asbestos mineral fibres from derelict asbestos mines in Southern Africa, namely chrysotile from Havelock mine, amosite from Penge mine and crocidolite from Prieska mine, are characterized mineralogically and geochemically to critically evaluate actual hazards in rural and asbestos-fibre-contaminated regions. The samples were examined using polarising light microscopy, X-ray fluorescence (major and trace elemental analysis), X-ray diffraction (including Rietveld refinement), specific surface area analysis and bio-durability testing. Data are discussed in view of their potential toxicities on both human health and the environment in the context of developing countries. Finally, information on the mineralogical and geochemical status of asbestos mine waste and its importance as baseline data for rehabilitation considerations is also evaluated.","Schapira, Jessica Shaye; Bolhar, Robert; Master, Sharad; Wilson, Allan H.",,"Schapira, Jessica/0000-0003-3819-9847; Wilson, Allan/0000-0002-0267-2236","Mineralogical, Petrological and Geochemical Characterisation of Chrysotile, Amosite and Crocidolite Asbestos Mine Waste from Southern Africa in Context of Risk Assessment and Rehabilitation",13,10,10.3390/min13101352 ,Article ,,"Derelict asbestos mine sites in South Africa pose a considerable risk to human, environmental and socio-economic health. Comprehensive mineralogical and geochemical datasets for the existing hazardous geological materials still exposed in Southern African derelict asbestos mines remain largely non-existent, as very little published and up-to-date literature is available. In this study, three representative types of asbestos mineral fibres from derelict asbestos mines in Southern Africa, namely chrysotile from Havelock mine, amosite from Penge mine and crocidolite from Prieska mine, are characterized mineralogically and geochemically to critically evaluate actual hazards in rural and asbestos-fibre-contaminated regions. The samples were examined using polarising light microscopy, X-ray fluorescence (major and trace elemental analysis), X-ray diffraction (including Rietveld refinement), specific surface area analysis and bio-durability testing. Data are discussed in view of their potential toxicities on both human health and the environment in the context of developing countries. Finally, information on the mineralogical and geochemical status of asbestos mine waste and its importance as baseline data for rehabilitation considerations is also evaluated.",,2075-163X,,, ,  ,,out_of_scope,
2692,"**Title**The Real MVP: Quantifying Individual Performances in Multiplayer Online Games

**Abstract**Online multiplayer games are getting increasingly popular and complex at the same time, while acknowledging adequate individual contributions to the success or failure of a session remains a formidable challenge. Yet, explainable and tangible insights are a necessity for players' self-improvement, understanding one's own performance can diminish frustration and toxicity, and properly quantifying proficiency yields promising potential in overcoming balancing as well as matchmaking issues. Motivated by this series of use cases, we set out to conduct an ecologically valid co-design study with players of the MMORPG Guild Wars 2, implement visualizations and measures drawing from a rich endgame dataset, and derive simple but intricate guidelines to consider when quantifying individual player performance.","Pfau, Johannes",,,The Real MVP: Quantifying Individual Performances in Multiplayer Online Games,,,10.1109/CoG60054.2024.10645665 ,Proceedings Paper ,,"Online multiplayer games are getting increasingly popular and complex at the same time, while acknowledging adequate individual contributions to the success or failure of a session remains a formidable challenge. Yet, explainable and tangible insights are a necessity for players' self-improvement, understanding one's own performance can diminish frustration and toxicity, and properly quantifying proficiency yields promising potential in overcoming balancing as well as matchmaking issues. Motivated by this series of use cases, we set out to conduct an ecologically valid co-design study with players of the MMORPG Guild Wars 2, implement visualizations and measures drawing from a rich endgame dataset, and derive simple but intricate guidelines to consider when quantifying individual player performance.",2325-4270,,979-8-3503-5068-5; 979-8-3503-5067-8,, , 6th Annual IEEE Conference on Games (CoG)6th Annual IEEE Conference on Games (CoG) ,,out_of_scope,
2693,"**Title**Prediction of central nervous system oxygen toxicity symptoms using electrodermal activity and machine learning

**Abstract**Objective: Breathing elevated oxygen partial pressures (PO2) prior to SCUBA diving increases the risk of developing central nervous system oxygen toxicity (CNS-OT), which could impair performance or result in seizure and subsequent drowning. We aimed to study the dynamics of electrodermal activity (EDA) while breathing elevated PO2 in the hyperbaric environment (HBO2) as a possible means to predict impending CNS-OT. To this end, we used machine learning to automatically detect and predict the onset of symptoms associated with CNS-OT in humans by using features derived from EDA in both time and frequency domains.Methods: We collected electrodermal activity (EDA) data from forty-nine exposures to HBO2 while subjects were undergoing cognitive load and exercise in a hyperbaric oxygen chamber. Four independent experts were present during the experiment to monitor and classify any symptoms associated with hyperbaric oxygen toxicity. We computed a highly sensitive time varying spectral EDA index, named TVSymp, and extracted informative features from skin conductance responses (SCRs). Machine learning algorithms were trained and validated for classifying features from SCRs and TVSymp as CNS-OT related or non-CNS-OT related. Machine learning models were validated using a subject -independent leave one subject out (LOSO) validation scheme.Results: Our machine learning model was able to classify EDA dynamics related to CNS-OT with 100 % sensitivity and 84 % specificity via LOSO validation. Moreover, the median prediction time for CNS-OT symptoms was similar to 250 s preceding the occurrence of actual symptoms.Significance: This study shows that EDA can potentially be used for early prediction of CNS-OT in divers with a high sensitivity and sufficient prediction time for countermeasures. While the study results are promising, independent validation datasets are warranted to confirm the findings. However, the current results are well corroborated in an animal study, which consistently showed seizure prediction time of 2 min prior to seizure.","Hossain, Md-Billal; Golzari, Kia; Kong, Youngsun; Derrick, Bruce J.; Moon, Richard E.; Natoli, Michael J.; Ellis, M. Claire; Winstead-Derlega, Christopher; Gonzalez, Sara I.; Allen, Christopher M.; Makowski, Mathew S.; Keuski, Brian M.; Freiberger, John J.; Posada-Quintero, Hugo F.; Chon, Ki H.","Hossain, Md Billal/AAT-6811-2021; Moon, Richard/AAF-2170-2019; Posada-Quintero, Hugo/E-2581-2016","Golzari, Kia/0000-0001-6559-379X",Prediction of central nervous system oxygen toxicity symptoms using electrodermal activity and machine learning,44,2,10.1016/j.bbe.2024.03.004 ,Article ,,"Objective: Breathing elevated oxygen partial pressures (PO2) prior to SCUBA diving increases the risk of developing central nervous system oxygen toxicity (CNS-OT), which could impair performance or result in seizure and subsequent drowning. We aimed to study the dynamics of electrodermal activity (EDA) while breathing elevated PO2 in the hyperbaric environment (HBO2) as a possible means to predict impending CNS-OT. To this end, we used machine learning to automatically detect and predict the onset of symptoms associated with CNS-OT in humans by using features derived from EDA in both time and frequency domains.Methods: We collected electrodermal activity (EDA) data from forty-nine exposures to HBO2 while subjects were undergoing cognitive load and exercise in a hyperbaric oxygen chamber. Four independent experts were present during the experiment to monitor and classify any symptoms associated with hyperbaric oxygen toxicity. We computed a highly sensitive time varying spectral EDA index, named TVSymp, and extracted informative features from skin conductance responses (SCRs). Machine learning algorithms were trained and validated for classifying features from SCRs and TVSymp as CNS-OT related or non-CNS-OT related. Machine learning models were validated using a subject -independent leave one subject out (LOSO) validation scheme.Results: Our machine learning model was able to classify EDA dynamics related to CNS-OT with 100 % sensitivity and 84 % specificity via LOSO validation. Moreover, the median prediction time for CNS-OT symptoms was similar to 250 s preceding the occurrence of actual symptoms.Significance: This study shows that EDA can potentially be used for early prediction of CNS-OT in divers with a high sensitivity and sufficient prediction time for countermeasures. While the study results are promising, independent validation datasets are warranted to confirm the findings. However, the current results are well corroborated in an animal study, which consistently showed seizure prediction time of 2 min prior to seizure.",0208-5216,,,304-311, ,  ,,out_of_scope,
2694,"**Title**Interpretation modeling: Social grounding of sentences by reasoning over their implicit moral judgments

**Abstract**The social and implicit nature of human communication ramifies readers' understandings of written sentences. Single gold-standard interpretations rarely exist, challenging conventional assumptions in natural language processing. This work introduces the interpretation modeling (IM) task which involves modeling several interpretations of a sentence's underlying semantics to unearth layers of implicit meaning. To obtain these, IM is guided by multiple annotations of social relation and common ground- in this work approximated by reader attitudes towards the author and their understanding of moral judgments subtly embedded in the sentence. We propose a number of modeling strategies that rely on one-to-one and one-to-many generation methods that take inspiration from the philosophical study of interpretation. A first-of-its-kind IM dataset is curated to support experiments and analyses. The modeling results, coupled with scrutiny of the dataset, underline the challenges of IM as conflicting and complex interpretations are socially plausible. This interplay of diverse readings is affirmed by automated and human evaluations on the generated interpretations. Finally, toxicity analyses in the generated interpretations demonstrate the importance of IM for refining filters of content and assisting content moderators in safeguarding the safety in online discourse.1","Allein, Liesbeth; Trusca, Maria Mihaela; Moens, Marie-Francine","Allein, Liesbeth/HMV-0826-2023","Allein, Liesbeth/0000-0002-7776-2156",Interpretation modeling: Social grounding of sentences by reasoning over their implicit moral judgments,338,,10.1016/j.artint.2024.104234 ,Article ,,"The social and implicit nature of human communication ramifies readers' understandings of written sentences. Single gold-standard interpretations rarely exist, challenging conventional assumptions in natural language processing. This work introduces the interpretation modeling (IM) task which involves modeling several interpretations of a sentence's underlying semantics to unearth layers of implicit meaning. To obtain these, IM is guided by multiple annotations of social relation and common ground- in this work approximated by reader attitudes towards the author and their understanding of moral judgments subtly embedded in the sentence. We propose a number of modeling strategies that rely on one-to-one and one-to-many generation methods that take inspiration from the philosophical study of interpretation. A first-of-its-kind IM dataset is curated to support experiments and analyses. The modeling results, coupled with scrutiny of the dataset, underline the challenges of IM as conflicting and complex interpretations are socially plausible. This interplay of diverse readings is affirmed by automated and human evaluations on the generated interpretations. Finally, toxicity analyses in the generated interpretations demonstrate the importance of IM for refining filters of content and assisting content moderators in safeguarding the safety in online discourse.1",0004-3702,1872-7921,,, ,  ,,out_of_scope,
2695,"**Title**BiasAsker: Measuring the Bias in Conversational AI System

**Abstract**Powered by advanced Artificial Intelligence (AI) techniques, conversational AI systems, such as ChatGPT, and digital assistants like Siri, have been widely deployed in daily life. However, such systems may still produce content containing biases and stereotypes, causing potential social problems. Due to modern AI techniques' data-driven, black-box nature, comprehensively identifying and measuring biases in conversational systems remains challenging. Particularly, it is hard to generate inputs that can comprehensively trigger potential bias due to the lack of data containing both social groups and biased properties. In addition, modern conversational systems can produce diverse responses (e.g., chatting and explanation), which makes existing bias detection methods based solely on sentiment and toxicity hardly being adopted. In this paper, we propose BiasAsker, an automated framework to identify and measure social bias in conversational AI systems. To obtain social groups and biased properties, we construct a comprehensive social bias dataset containing a total of 841 groups and 5,021 biased properties. Given the dataset, BiasAsker automatically generates questions and adopts a novel method based on existence measurement to identify two types of biases (i.e., absolute bias and related bias) in conversational systems. Extensive experiments on eight commercial systems and two famous research models, such as ChatGPT and GPT-3, show that 32.83% of the questions generated by BiasAsker can trigger biased behaviors in these widely deployed conversational systems. All the code, data, and experimental results have been released to facilitate future research.","Wan, Yuxuan; Wang, Wenxuan; He, Pinjia; Gu, Jiazhen; Bai, Haonan; Lyu, Michael R.","Wang, Wenxuan/AAW-9073-2020; Gu, Jiazhen/KHX-5779-2024","Wan, Yuxuan/0009-0006-6739-4675; Bai, Haonan/0009-0008-6061-107X; Lyu, Michael/0000-0002-3666-5798",BiasAsker: Measuring the Bias in Conversational AI System,,,10.1145/3611643.3616310 ,Proceedings Paper ,,"Powered by advanced Artificial Intelligence (AI) techniques, conversational AI systems, such as ChatGPT, and digital assistants like Siri, have been widely deployed in daily life. However, such systems may still produce content containing biases and stereotypes, causing potential social problems. Due to modern AI techniques' data-driven, black-box nature, comprehensively identifying and measuring biases in conversational systems remains challenging. Particularly, it is hard to generate inputs that can comprehensively trigger potential bias due to the lack of data containing both social groups and biased properties. In addition, modern conversational systems can produce diverse responses (e.g., chatting and explanation), which makes existing bias detection methods based solely on sentiment and toxicity hardly being adopted. In this paper, we propose BiasAsker, an automated framework to identify and measure social bias in conversational AI systems. To obtain social groups and biased properties, we construct a comprehensive social bias dataset containing a total of 841 groups and 5,021 biased properties. Given the dataset, BiasAsker automatically generates questions and adopts a novel method based on existence measurement to identify two types of biases (i.e., absolute bias and related bias) in conversational systems. Extensive experiments on eight commercial systems and two famous research models, such as ChatGPT and GPT-3, show that 32.83% of the questions generated by BiasAsker can trigger biased behaviors in these widely deployed conversational systems. All the code, data, and experimental results have been released to facilitate future research.",,,979-8-4007-0327-0,515-527, , 31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE) ,,out_of_scope,
2696,"**Title**Hybrid random projection technique for enhanced representation in high-dimensional data

**Abstract**This paper introduces a novel hybrid random projection method (HRP) that effectively combines the strengths of normal random projection (NRP) and plus-minus one random projection (PMRP). By incorporating a blending parameter, HRP optimises the contributions of the NRP and PMRP, reducing the dimensions of the data while ensuring that the structure of the data is preserved. Conventional methods, such as NRP and PMRP, are recognised for their benefits; however, they also have limitations. NRP is generally accurate but can encounter difficulties with certain data types or noise. The PMRP is simple, but occasionally fails to capture complex relationships within the data. The performance of HRP is investigated through comprehensive evaluations, including simulations and real-world data analyses from key machine learning datasets, such as period change, toxicity, MNIST, and human activity recognition (HAR). We examine various factors such as sample size, dimensions of the original and reduced data, and sparsity. Distance distortion is the primary metric utilised to measure performance, and indicates how well the dataset structure is maintained after dimension reduction. In every test, HRP consistently demonstrates the least distance distortion, performing superiorly to the NRP and PMRP. This is true fora range of scenarios and datasets. HRP represents a significant advancement in dimension reduction techniques. Its ability to minimise information loss during the reduction process demonstrates its potential as a powerful tool for managing complex high-dimensional data in practical applications. This renders HRP an important development in the fields of machine learning, intelligent systems, and artificial intelligence, offering improved efficiency and precision in data analyses.","Yahaya, Yussif; Ajadi, Jimoh Olawale; Sanusi, Ridwan A.; Sawlan, Zaid; Adegoke, Nurudeen A.","Adegoke, Nurudeen/AAE-6116-2022; Ajadi, Jimoh/ADA-7412-2022; Sawlan, Zaid/JGD-5261-2023; Sanusi, Ridwan/E-4132-2017","Sawlan, Zaid/0000-0002-4361-2491; AJADI, JIMOH/0000-0001-8445-8155; Sanusi, Ridwan/0000-0002-7322-2670; Adegoke, Nurudeen/0000-0001-7592-5460",Hybrid random projection technique for enhanced representation in high-dimensional data,262,,10.1016/j.eswa.2024.125569 ,Article ,,"This paper introduces a novel hybrid random projection method (HRP) that effectively combines the strengths of normal random projection (NRP) and plus-minus one random projection (PMRP). By incorporating a blending parameter, HRP optimises the contributions of the NRP and PMRP, reducing the dimensions of the data while ensuring that the structure of the data is preserved. Conventional methods, such as NRP and PMRP, are recognised for their benefits; however, they also have limitations. NRP is generally accurate but can encounter difficulties with certain data types or noise. The PMRP is simple, but occasionally fails to capture complex relationships within the data. The performance of HRP is investigated through comprehensive evaluations, including simulations and real-world data analyses from key machine learning datasets, such as period change, toxicity, MNIST, and human activity recognition (HAR). We examine various factors such as sample size, dimensions of the original and reduced data, and sparsity. Distance distortion is the primary metric utilised to measure performance, and indicates how well the dataset structure is maintained after dimension reduction. In every test, HRP consistently demonstrates the least distance distortion, performing superiorly to the NRP and PMRP. This is true fora range of scenarios and datasets. HRP represents a significant advancement in dimension reduction techniques. Its ability to minimise information loss during the reduction process demonstrates its potential as a powerful tool for managing complex high-dimensional data in practical applications. This renders HRP an important development in the fields of machine learning, intelligent systems, and artificial intelligence, offering improved efficiency and precision in data analyses.",0957-4174,1873-6793,,, ,  ,,out_of_scope,
2697,"**Title**RETRACTED: Detection of hate: speech tweets based convolutional neural network and machine learning algorithms (Retracted article. See vol. 14, 2024)

**Abstract**There is no doubt that social media sites have provided many benefits to humanity, such as sharing information continuously and communicating with others easily. It also seems that social media sites have many advantages, but in addition to these advantages, there are disadvantages that we always strive to find a solution. One of these disadvantages is sharing hate speech. In our study, we're discussing a way to solve this phenomenon by using Term Frequency-Inverse Document Frequency (TF-IDF) based approach to feature engineering on eleven classifiers for machine and deep learning that can automatically identify hate speech. Three different databases were used, the first of which Hate speech offensive tweets by Davidson et al., the second called Twitter hate speech and finally we merged the second data with (Cyberbullying dataset (toxicity_parsed_dataset). The classifiers involved are Logistic Regression (LR), Naive Bayes (NB), Multi-layer Perceptron (MLP), and Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbor (KNN), K-Means, Decision Tree (DT), Gradient Boosting classifier (GBC), and the Extra Trees (ET) in addition to the convolutional neural network (CNN). Maximum accuracy was attained, which exceeded 99%.","Sennary, Hameda A.; Abozaid, Ghada; Hemeida, Ashraf; Mikhaylov, Alexey; Broderick, Tamara","sennary, Hameda/AAJ-7255-2021; Mikhaylov, Alexey/A-7964-2015","Abozaid, Ghada/0000-0002-8013-5110; Mikhaylov, Alexey/0000-0003-2478-0307","RETRACTED: Detection of hate: speech tweets based convolutional neural network and machine learning algorithms (Retracted article. See vol. 14, 2024)",14,1,10.1038/s41598-024-76632-2 ,Article; Retracted Publication ,,"There is no doubt that social media sites have provided many benefits to humanity, such as sharing information continuously and communicating with others easily. It also seems that social media sites have many advantages, but in addition to these advantages, there are disadvantages that we always strive to find a solution. One of these disadvantages is sharing hate speech. In our study, we're discussing a way to solve this phenomenon by using Term Frequency-Inverse Document Frequency (TF-IDF) based approach to feature engineering on eleven classifiers for machine and deep learning that can automatically identify hate speech. Three different databases were used, the first of which Hate speech offensive tweets by Davidson et al., the second called Twitter hate speech and finally we merged the second data with (Cyberbullying dataset (toxicity_parsed_dataset). The classifiers involved are Logistic Regression (LR), Naive Bayes (NB), Multi-layer Perceptron (MLP), and Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbor (KNN), K-Means, Decision Tree (DT), Gradient Boosting classifier (GBC), and the Extra Trees (ET) in addition to the convolutional neural network (CNN). Maximum accuracy was attained, which exceeded 99%.",2045-2322,,,, ,  ,,out_but_toxicity,
2698,"**Title**Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers

**Abstract**To address the problem of NLP classifiers learning spurious correlations between training features and target labels, a common approach is to make the model's predictions invariant to these features. However, this can be counterproductive when the features have a non-zero causal effect on the target label and thus are important for prediction. Therefore, using methods from the causal inference literature, we propose an algorithm to regularize the learnt effect of the features on the model's prediction to the estimated effect of feature on label. This results in an automated augmentation method that leverages the estimated effect of a feature to appropriately change the labels for new augmented inputs. On toxicity and IMDB review datasets, the proposed algorithm minimises spurious correlations and improves the minority group (i.e., samples breaking spurious correlations) accuracy, while also improving the total accuracy compared to standard training. (1)","Bansal, Parikshit; Sharma, Amit","Sharma, Amit/JEF-9067-2023",,Controlling Learned Effects to Reduce Spurious Correlations in Text Classifiers,,, ,Proceedings Paper ,,"To address the problem of NLP classifiers learning spurious correlations between training features and target labels, a common approach is to make the model's predictions invariant to these features. However, this can be counterproductive when the features have a non-zero causal effect on the target label and thus are important for prediction. Therefore, using methods from the causal inference literature, we propose an algorithm to regularize the learnt effect of the features on the model's prediction to the estimated effect of feature on label. This results in an automated augmentation method that leverages the estimated effect of a feature to appropriately change the labels for new augmented inputs. On toxicity and IMDB review datasets, the proposed algorithm minimises spurious correlations and improves the minority group (i.e., samples breaking spurious correlations) accuracy, while also improving the total accuracy compared to standard training. (1)",,,978-1-959429-72-2,2271-2287, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,detection,
2699,"**Title**Is the Lottery Fair? EvaluatingWinning Tickets Across Demographics

**Abstract**Recent studies have suggested that weight pruning, e.g. using lottery ticket extraction techniques (Frankle and Carbin, 2018), comes at the risk of compromising the group fairness of machine learning models (Paganini, 2020; Hooker et al., 2020), but to the best of our knowledge, no one has empirically evaluated this hypothesis at scale in the context of natural language processing. We present experiments with two text classification datasets annotated with demographic information: the Trustpilot Corpus (sentiment) and CivilComments (toxicity). We evaluate the fairness of lottery ticket extraction through layer-wise and global weight pruning across three languages and two tasks. Our results suggest that there is a small increase in group disparity, which is most pronounced at high pruning rates and correlates with instability. The fairness of models trained with distributionally robust optimization objectives is sometimes less sensitive to pruning, but results are not consistent. The code for our experiments is available at https://github. com/vpetren/fairness_lottery.","Hansen, Victor Petren Bach; Sogaard, Anders",,,Is the Lottery Fair? EvaluatingWinning Tickets Across Demographics,,, ,Proceedings Paper ,,"Recent studies have suggested that weight pruning, e.g. using lottery ticket extraction techniques (Frankle and Carbin, 2018), comes at the risk of compromising the group fairness of machine learning models (Paganini, 2020; Hooker et al., 2020), but to the best of our knowledge, no one has empirically evaluated this hypothesis at scale in the context of natural language processing. We present experiments with two text classification datasets annotated with demographic information: the Trustpilot Corpus (sentiment) and CivilComments (toxicity). We evaluate the fairness of lottery ticket extraction through layer-wise and global weight pruning across three languages and two tasks. Our results suggest that there is a small increase in group disparity, which is most pronounced at high pruning rates and correlates with instability. The fairness of models trained with distributionally robust optimization objectives is sometimes less sensitive to pruning, but results are not consistent. The code for our experiments is available at https://github. com/vpetren/fairness_lottery.",,,978-1-954085-54-1,3214-3224, , Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP)Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP) ,,out_of_scope,
2700,"**Title**A context-aware attention and graph neural network-based multimodal framework for misogyny detection

**Abstract**A substantial portion of offensive content on social media is directed towards women. Since the approaches for general offensive content detection face a challenge in detecting misogynistic content, it requires solutions tailored to address offensive content against women. To this end, we propose a novel multimodal framework for the detection of misogynistic and sexist content. The framework comprises three modules: the Multimodal Attention module (MANM), the Graph-based Feature Reconstruction Module (GFRM), and the Content-specific Features Learning Module (CFLM). The MANM employs adaptive gating-based multimodal context-aware attention, enabling the model to focus on relevant visual and textual information and generating contextually relevant features. The GFRM module utilizes graphs to refine features within individual modalities, while the CFLM focuses on learning text and image-specific features such as toxicity features and caption features. Additionally, we curate a set of misogynous lexicons to compute the misogyny-specific lexicon score from the text. We apply test-time augmentation in feature space to better generalize the predictions on diverse inputs. The performance of the proposed approach has been evaluated on two multimodal datasets, MAMI, and MMHS150K, with 11,000 and 13,494 samples, respectively. The proposed method demonstrates an average improvement of 11.87% and 10.82% in macro-F1 over existing multimodal methods on the MAMI and MMHS150K datasets, respectively.","Rehman, Mohammad Zia Ur; Zahoor, Sufyaan; Manzoor, Areeb; Maqbool, Musharaf; Kumar, Nagendra",,", Mohammad Zia Ur Rehman/0000-0001-6374-8102; Kumar, Nagendra/0000-0003-4644-3168",A context-aware attention and graph neural network-based multimodal framework for misogyny detection,62,1,10.1016/j.ipm.2024.103895 ,Article ,,"A substantial portion of offensive content on social media is directed towards women. Since the approaches for general offensive content detection face a challenge in detecting misogynistic content, it requires solutions tailored to address offensive content against women. To this end, we propose a novel multimodal framework for the detection of misogynistic and sexist content. The framework comprises three modules: the Multimodal Attention module (MANM), the Graph-based Feature Reconstruction Module (GFRM), and the Content-specific Features Learning Module (CFLM). The MANM employs adaptive gating-based multimodal context-aware attention, enabling the model to focus on relevant visual and textual information and generating contextually relevant features. The GFRM module utilizes graphs to refine features within individual modalities, while the CFLM focuses on learning text and image-specific features such as toxicity features and caption features. Additionally, we curate a set of misogynous lexicons to compute the misogyny-specific lexicon score from the text. We apply test-time augmentation in feature space to better generalize the predictions on diverse inputs. The performance of the proposed approach has been evaluated on two multimodal datasets, MAMI, and MMHS150K, with 11,000 and 13,494 samples, respectively. The proposed method demonstrates an average improvement of 11.87% and 10.82% in macro-F1 over existing multimodal methods on the MAMI and MMHS150K datasets, respectively.",0306-4573,1873-5371,,, ,  ,,detection#methodology,
2701,"**Title**Genomic Insights into Bacillus thuringiensis V-CO3.3: Unveiling Its Genetic Potential against Nematodes

**Abstract**Bacillus thuringiensis (Bt) is a Gram-positive, spore-forming, and ubiquitous bacterium harboring plasmids encoding a variety of proteins with insecticidal activity, but also with activity against nematodes. The aim of this work was to perform the genome sequencing and analysis of a native Bt strain showing bipyramidal parasporal crystals and designated V-CO3.3, which was isolated from the dust of a grain storehouse in C & oacute;rdoba (Spain). Its genome comprised 99 high-quality assembled contigs accounting for a total size of 5.2 Mb and 35.1% G + C. Phylogenetic analyses suggested that this strain should be renamed as Bacillus cereus s.s. biovar Thuringiensis. Gene annotation revealed a total of 5495 genes, among which, 1 was identified as encoding a Cry5Ba homolog protein with well-documented toxicity against nematodes. These results suggest that this Bt strain has interesting potential for nematode biocontrol. Dataset: The BioSample data have been submitted under accession number SAMN41014059. The whole-genome sequences have been submitted to the NCBI with BioProject number PRJNA1102171. The assembled genome sequences are available under accession number JBCGZW000000000. The (Illumina) raw reads have been submitted to Sequence Read Archives (SRA) under accession number SRR28927673. The V-CO-3.3 strain has been stored in the Spanish Type Culture Collection (CECT) at the University of Valencia (Spain) under accession number CECT 31068. Dataset License: CC-BY-NC","Palma, Leopoldo; Bel, Yolanda; Escriche, Baltasar","Bel, Yolanda/I-2700-2015; Escriche, Baltasar/N-5136-2014; Palma Dovis, Leopoldo/K-1299-2014","Bel, Yolanda/0000-0002-6367-9220; Escriche, Baltasar/0000-0003-4889-793X; Palma Dovis, Leopoldo/0000-0002-4817-7580",Genomic Insights into Bacillus thuringiensis V-CO3.3: Unveiling Its Genetic Potential against Nematodes,9,8,10.3390/data9080097 ,Article ,,"Bacillus thuringiensis (Bt) is a Gram-positive, spore-forming, and ubiquitous bacterium harboring plasmids encoding a variety of proteins with insecticidal activity, but also with activity against nematodes. The aim of this work was to perform the genome sequencing and analysis of a native Bt strain showing bipyramidal parasporal crystals and designated V-CO3.3, which was isolated from the dust of a grain storehouse in C & oacute;rdoba (Spain). Its genome comprised 99 high-quality assembled contigs accounting for a total size of 5.2 Mb and 35.1% G + C. Phylogenetic analyses suggested that this strain should be renamed as Bacillus cereus s.s. biovar Thuringiensis. Gene annotation revealed a total of 5495 genes, among which, 1 was identified as encoding a Cry5Ba homolog protein with well-documented toxicity against nematodes. These results suggest that this Bt strain has interesting potential for nematode biocontrol. Dataset: The BioSample data have been submitted under accession number SAMN41014059. The whole-genome sequences have been submitted to the NCBI with BioProject number PRJNA1102171. The assembled genome sequences are available under accession number JBCGZW000000000. The (Illumina) raw reads have been submitted to Sequence Read Archives (SRA) under accession number SRR28927673. The V-CO-3.3 strain has been stored in the Spanish Type Culture Collection (CECT) at the University of Valencia (Spain) under accession number CECT 31068. Dataset License: CC-BY-NC",,2306-5729,,, ,  ,,out_of_scope,
2702,"**Title**Machine Learning to Predict Teratogenicity: Theory and Practice.

**Abstract**Machine learning (ML) is a subfield of artificial intelligence (AI) that consists of developing algorithms that can automatically learn patterns and relationships from data, without being explicitly programmed. It continues to advance with the development of more sophisticated algorithms, increased computational power, and larger datasets, leading to significant advancements in AI technology. With the significant progress made in ML, the need to apply these systems in the area of teratogenicity is growing. It is sought as robust boosting methods to overcome many limitations and restrictions facing the experimental studies. By performing tasks such as classification, regression, clustering, anomaly detection, and decision systems, ML can be used to assess whether an agent is teratogen or not or to determine its teratogenic potential. It may also be used for the purpose of deciding on the use of medicinal products. In this chapter, we describe how ML can be used to investigate teratogenicity.","Douali, Latifa",,"Douali, Latifa/0000-0002-8020-936X",Machine Learning to Predict Teratogenicity: Theory and Practice.,2753,,10.1007/978-1-0716-3625-1_7 ,Journal Article ,,"Machine learning (ML) is a subfield of artificial intelligence (AI) that consists of developing algorithms that can automatically learn patterns and relationships from data, without being explicitly programmed. It continues to advance with the development of more sophisticated algorithms, increased computational power, and larger datasets, leading to significant advancements in AI technology. With the significant progress made in ML, the need to apply these systems in the area of teratogenicity is growing. It is sought as robust boosting methods to overcome many limitations and restrictions facing the experimental studies. By performing tasks such as classification, regression, clustering, anomaly detection, and decision systems, ML can be used to assess whether an agent is teratogen or not or to determine its teratogenic potential. It may also be used for the purpose of deciding on the use of medicinal products. In this chapter, we describe how ML can be used to investigate teratogenicity.",,1940-6029,,159-180, ,  ,,out_of_scope,
2703,"**Title**Monitoring Dynamics of Emotional Sentiment in Social Network Commentaries

**Abstract**The proliferation of social media offers a real-time reflection of public sentiments. Sentiment analysis on such platforms yields crucial insights for sectors like market research, politics, business strategy, and public health. In this study, we introduce an innovative framework to examine evolving sentiments in social media comments and understand their wider implications. Utilizing a pre-trained BERT base uncase model, we estimate emotional values from comments and align them with various sentiment trends such as Approval, Toxicity, and Neutral, among others. By leveraging machine learning, we train on a distinctive dataset, correlating emotional values with sentiment trends to generate trend likelihood scores. Through a bottom-up methodology, we compile emotional ratings across comment threads to forecast overarching sentiment scores. Our results reveal that the BERT base uncase model excels in emotional prediction, achieving an AUC of 0.91. Meanwhile, Decision Tree models stand out, registering an F1 score above 0.40 on a macro average basis.","Hossain, Ismail; Puppala, Sai; Alam, Md Jahangir; Talukder, Sajedul","Hossain, Ismail/ABM-8339-2022; Alam, Md. Jahangir/HZM-3321-2023; Puppala, Sai/JYQ-0856-2024","Puppala, Sai/0009-0008-0334-5756",Monitoring Dynamics of Emotional Sentiment in Social Network Commentaries,,,10.1145/3625007.3627730 ,Proceedings Paper ,,"The proliferation of social media offers a real-time reflection of public sentiments. Sentiment analysis on such platforms yields crucial insights for sectors like market research, politics, business strategy, and public health. In this study, we introduce an innovative framework to examine evolving sentiments in social media comments and understand their wider implications. Utilizing a pre-trained BERT base uncase model, we estimate emotional values from comments and align them with various sentiment trends such as Approval, Toxicity, and Neutral, among others. By leveraging machine learning, we train on a distinctive dataset, correlating emotional values with sentiment trends to generate trend likelihood scores. Through a bottom-up methodology, we compile emotional ratings across comment threads to forecast overarching sentiment scores. Our results reveal that the BERT base uncase model excels in emotional prediction, achieving an AUC of 0.91. Meanwhile, Decision Tree models stand out, registering an F1 score above 0.40 on a macro average basis.",2473-9928,2473-991X,979-8-4007-0409-3,51-55, , 15th IEEE/ACM Annual International Conference on Advances in Social Networks Analysis and Mining (ASONAM)15th IEEE/ACM Annual International Conference on Advances in Social Networks Analysis and Mining (ASONAM) ,,out_of_scope,
2704,"**Title**POSEIDON: Peptidic Objects SEquence-based Interaction with cellular DOmaiNs: a new database and predictor

**Abstract**Cell-penetrating peptides (CPPs) are short chains of amino acids that have shown remarkable potential to cross the cell membrane and deliver coupled therapeutic cargoes into cells. Designing and testing different CPPs to target specific cells or tissues is crucial to ensure high delivery efficiency and reduced toxicity. However, in vivo/in vitro testing of various CPPs can be both time-consuming and costly, which has led to interest in computational methodologies, such as Machine Learning (ML) approaches, as faster and cheaper methods for CPP design and uptake prediction. However, most ML models developed to date focus on classification rather than regression techniques, because of the lack of informative quantitative uptake values. To address these challenges, we developed POSEIDON, an open-access and up-to-date curated database that provides experimental quantitative uptake values for over 2,300 entries and physicochemical properties of 1,315 peptides. POSEIDON also offers physicochemical properties, such as cell line, cargo, and sequence, among others. By leveraging this database along with cell line genomic features, we processed a dataset of over 1,200 entries to develop an ML regression CPP uptake predictor. Our results demonstrated that POSEIDON accurately predicted peptide cell line uptake, achieving a Pearson correlation of 0.87, Spearman correlation of 0.88, and r2 score of 0.76, on an independent test set. With its comprehensive and novel dataset, along with its potent predictive capabilities, the POSEIDON database and its associated ML predictor signify a significant leap forward in CPP research and development. The POSEIDON database and ML Predictor are available for free and with a user-friendly interface at https://moreiralab.com/resources/poseidon/, making them valuable resources for advancing research on CPP-related topics. Scientific Contribution Statement: Our research addresses the critical need for more efficient and cost-effective methodologies in Cell-Penetrating Peptide (CPP) research. We introduced POSEIDON, a comprehensive and freely accessible database that delivers quantitative uptake values for over 2,300 entries, along with detailed physicochemical profiles for 1,315 peptides. Recognizing the limitations of current Machine Learning (ML) models for CPP design, our work leveraged the rich dataset provided by POSEIDON to develop a highly accurate ML regression model for predicting CPP uptake.","Preto, Antonio J.; Caniceiro, Ana B.; Duarte, Francisco; Fernandes, Hugo; Ferreira, Lino; Mourao, Joana; Moreira, Irina S.","Fernandes, Hugo/H-6192-2014; Duarte, Francisco/AAC-8280-2021; Moreira, Irina/K-4711-2012; Mourao, Joana/N-9035-2015","Fernandes, Hugo/0000-0002-4574-7648; Caniceiro, Ana Beatriz/0000-0002-4074-9142; ferreira, lino/0000-0001-8985-9302; Mourao, Joana/0000-0002-1296-5964",POSEIDON: Peptidic Objects SEquence-based Interaction with cellular DOmaiNs: a new database and predictor,16,1,10.1186/s13321-024-00810-7 ,Article ,,"Cell-penetrating peptides (CPPs) are short chains of amino acids that have shown remarkable potential to cross the cell membrane and deliver coupled therapeutic cargoes into cells. Designing and testing different CPPs to target specific cells or tissues is crucial to ensure high delivery efficiency and reduced toxicity. However, in vivo/in vitro testing of various CPPs can be both time-consuming and costly, which has led to interest in computational methodologies, such as Machine Learning (ML) approaches, as faster and cheaper methods for CPP design and uptake prediction. However, most ML models developed to date focus on classification rather than regression techniques, because of the lack of informative quantitative uptake values. To address these challenges, we developed POSEIDON, an open-access and up-to-date curated database that provides experimental quantitative uptake values for over 2,300 entries and physicochemical properties of 1,315 peptides. POSEIDON also offers physicochemical properties, such as cell line, cargo, and sequence, among others. By leveraging this database along with cell line genomic features, we processed a dataset of over 1,200 entries to develop an ML regression CPP uptake predictor. Our results demonstrated that POSEIDON accurately predicted peptide cell line uptake, achieving a Pearson correlation of 0.87, Spearman correlation of 0.88, and r2 score of 0.76, on an independent test set. With its comprehensive and novel dataset, along with its potent predictive capabilities, the POSEIDON database and its associated ML predictor signify a significant leap forward in CPP research and development. The POSEIDON database and ML Predictor are available for free and with a user-friendly interface at https://moreiralab.com/resources/poseidon/, making them valuable resources for advancing research on CPP-related topics. Scientific Contribution Statement: Our research addresses the critical need for more efficient and cost-effective methodologies in Cell-Penetrating Peptide (CPP) research. We introduced POSEIDON, a comprehensive and freely accessible database that delivers quantitative uptake values for over 2,300 entries, along with detailed physicochemical profiles for 1,315 peptides. Recognizing the limitations of current Machine Learning (ML) models for CPP design, our work leveraged the rich dataset provided by POSEIDON to develop a highly accurate ML regression model for predicting CPP uptake.",1758-2946,,,, ,  ,,out_of_scope,
2705,"**Title**The usefulness of artificial intelligence in breast reconstruction: a systematic review

**Abstract**BackgroundArtificial Intelligence (AI) offers an approach to predictive modeling. The model learns to determine specific patterns of undesirable outcomes in a dataset. Therefore, a decision-making algorithm can be built based on these patterns to prevent negative results. This systematic review aimed to evaluate the usefulness of AI in breast reconstruction.MethodsA systematic review was conducted in August 2022 following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. MEDLINE, EMBASE, SCOPUS, and Google Scholar online databases were queried to capture all publications studying the use of artificial intelligence in breast reconstruction.ResultsA total of 23 studies were full text-screened after removing duplicates, and twelve articles fulfilled our inclusion criteria. The Machine Learning algorithms applied for neuropathic pain, lymphedema diagnosis, microvascular abdominal flap failure, donor site complications associated to muscle sparing Transverse Rectus Abdominis flap, surgical complications, financial toxicity, and patient-reported outcomes after breast surgery demonstrated that AI is a helpful tool to accurately predict patient results. In addition, one study used Computer Vision technology to assist in Deep Inferior Epigastric Perforator Artery detection for flap design, considerably reducing the preoperative time compared to manual identification.ConclusionsIn breast reconstruction, AI can help the surgeon by optimizing the perioperative patients' counseling to predict negative outcomes, allowing execution of timely interventions and reducing the postoperative burden, which leads to obtaining the most successful results and improving patient satisfaction.","Maita, Karla C.; Avila, Francisco R.; Torres-Guzman, Ricardo A.; Garcia, John P.; De Sario Velasquez, Gioacchino D.; Borna, Sahar; Brown, Sally A.; Haider, Clifton R.; Ho, Olivia S.; Forte, Antonio Jorge","Torres-Guzman, Ricardo/ABC-5975-2021; Forte, Antonio/I-2970-2019",,The usefulness of artificial intelligence in breast reconstruction: a systematic review,31,4,10.1007/s12282-024-01582-6 ,Review ,,"BackgroundArtificial Intelligence (AI) offers an approach to predictive modeling. The model learns to determine specific patterns of undesirable outcomes in a dataset. Therefore, a decision-making algorithm can be built based on these patterns to prevent negative results. This systematic review aimed to evaluate the usefulness of AI in breast reconstruction.MethodsA systematic review was conducted in August 2022 following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. MEDLINE, EMBASE, SCOPUS, and Google Scholar online databases were queried to capture all publications studying the use of artificial intelligence in breast reconstruction.ResultsA total of 23 studies were full text-screened after removing duplicates, and twelve articles fulfilled our inclusion criteria. The Machine Learning algorithms applied for neuropathic pain, lymphedema diagnosis, microvascular abdominal flap failure, donor site complications associated to muscle sparing Transverse Rectus Abdominis flap, surgical complications, financial toxicity, and patient-reported outcomes after breast surgery demonstrated that AI is a helpful tool to accurately predict patient results. In addition, one study used Computer Vision technology to assist in Deep Inferior Epigastric Perforator Artery detection for flap design, considerably reducing the preoperative time compared to manual identification.ConclusionsIn breast reconstruction, AI can help the surgeon by optimizing the perioperative patients' counseling to predict negative outcomes, allowing execution of timely interventions and reducing the postoperative burden, which leads to obtaining the most successful results and improving patient satisfaction.",1340-6868,1880-4233,,562-571, ,  ,,out_of_scope,
2706,"**Title**Multi -Modality Machine Learning Prediction Model of Hematologic Toxicity in Neoadjuvant Chemoradiotherapy for Locally Advanced Rectal Cancer

**Abstract**Abstract:
  Simple SummaryNeoadjuvant chemotherapy is the standard treatment for locally advanced rectal cancer. Preoperative chemoradiotherapy yields clinically significant tumor regression; while some patients exhibit a minimal response, others exhibit a complete pathologic response. We developed deep learning and machine learning models to predict chemoradiotherapy response across external tests using multicenter data. The machine learning model, which used harmonized image features extracted from 18F-FDG PET, showed higher performance and demonstrated reproducibility through external tests compared to the deep learning models using 18F-FDG PET images. Our study highlights the feasibility of predicting the chemoradiotherapy response of individual patients using non-invasive and reliable image feature values.  AbstractWe developed machine and deep learning models to predict chemoradiotherapy in rectal cancer using 18F-FDG PET images and harmonized image features extracted from 18F-FDG PET/CT images. Patients diagnosed with pathologic T-stage III rectal cancer with a tumor size > 2 cm were treated with neoadjuvant chemoradiotherapy. Patients with rectal cancer were divided into an internal dataset (n = 116) and an external dataset obtained from a separate institution (n = 40), which were used in the model. AUC was calculated to select image features associated with radiochemotherapy response. In the external test, the machine-learning signature extracted from 18F-FDG PET image features achieved the highest accuracy and AUC value of 0.875 and 0.896. The harmonized first-order radiomics model had a higher efficiency with accuracy and an AUC of 0.771 than the second-order model in the external test. The deep learning model using the balanced dataset showed an accuracy of 0.867 in the internal test but an accuracy of 0.557 in the external test. Deep-learning models using 18F-FDG PET images must be harmonized to demonstrate reproducibility with external data. Harmonized 18F-FDG PET image features as an element of machine learning could help predict chemoradiotherapy responses in external tests with reproducibility.","Li, B.; Li, Y.; Zhen, X.; Xiao, W.",,,Multi -Modality Machine Learning Prediction Model of Hematologic Toxicity in Neoadjuvant Chemoradiotherapy for Locally Advanced Rectal Cancer,120,2, ,Meeting Abstract ,,"Abstract:
  Simple SummaryNeoadjuvant chemotherapy is the standard treatment for locally advanced rectal cancer. Preoperative chemoradiotherapy yields clinically significant tumor regression; while some patients exhibit a minimal response, others exhibit a complete pathologic response. We developed deep learning and machine learning models to predict chemoradiotherapy response across external tests using multicenter data. The machine learning model, which used harmonized image features extracted from 18F-FDG PET, showed higher performance and demonstrated reproducibility through external tests compared to the deep learning models using 18F-FDG PET images. Our study highlights the feasibility of predicting the chemoradiotherapy response of individual patients using non-invasive and reliable image feature values.  AbstractWe developed machine and deep learning models to predict chemoradiotherapy in rectal cancer using 18F-FDG PET images and harmonized image features extracted from 18F-FDG PET/CT images. Patients diagnosed with pathologic T-stage III rectal cancer with a tumor size > 2 cm were treated with neoadjuvant chemoradiotherapy. Patients with rectal cancer were divided into an internal dataset (n = 116) and an external dataset obtained from a separate institution (n = 40), which were used in the model. AUC was calculated to select image features associated with radiochemotherapy response. In the external test, the machine-learning signature extracted from 18F-FDG PET image features achieved the highest accuracy and AUC value of 0.875 and 0.896. The harmonized first-order radiomics model had a higher efficiency with accuracy and an AUC of 0.771 than the second-order model in the external test. The deep learning model using the balanced dataset showed an accuracy of 0.867 in the internal test but an accuracy of 0.557 in the external test. Deep-learning models using 18F-FDG PET images must be harmonized to demonstrate reproducibility with external data. Harmonized 18F-FDG PET image features as an element of machine learning could help predict chemoradiotherapy responses in external tests with reproducibility.",0360-3016,1879-355X,,E461-E461, , 66th International Conference on American-Society-for-Radiation-Oncology (ASTRO)66th International Conference on American-Society-for-Radiation-Oncology (ASTRO) ,,out_of_scope,
2707,"**Title**Survival Prediction of Children after Bone Marrow Transplant Using Machine Learning Algorithms

**Abstract**Bone marrow is the source of many blood -related diseases, such as blood cancers, and Bone Marrow Transplantation (BMT), also known as Hematopoietic Stem Cell Transplantation (HSCT), is a life-saving surgical procedure. However, this treatment is associated with a high risk of mortality. Predicting survival after BMT is therefore essential for effective and accurate treatment. BMT is considered a treatment -related mortality due to several primary causes of death such as infections, toxicity, and Graft -versus -Host Disease (GvHD) that occur after treatment. In addition, several risk factors affect the success of BMT and long-term survival after treatment. Therefore, there is a need for a prediction system based on machine learning techniques that can predict whether the patient will survive after BMT or not, which will definitely help the physicians to make the right decisions before performing the surgery for the patient. In this paper, using a publicly available BMT dataset from the University of California, Irvine ML repository (UCI ML repository), different machine learning models were investigated to predict the survival status of children undergoing BMT treatment. In particular, Random Forest (RF), Bagging Classifier, Extreme Gradient Boost (XGBoost), Adaptive Boosting (AdaBoost), Decision Tree (DT), Gradient Boost (GB), and K -Nearest Neighbors (KNN) were trained on the given dataset. The dataset consists of 45 variables after applying a series of preprocessing steps and removing the multicollinearity features based on the correlation heat map. Then, a feature engineering and modelling step was applied to identify the most significant features, followed by the use of machine learning models to simplify the overall classification process. It's important to note that the most important features obtained by DT and those obtained by GB were the most suitable for training the Bagging classifier and the KNN model, respectively. In addition to that, hyper -parameters optimization using Grid Search Cross -Validation (GSCV) was applied to both approaches to improve the accuracy of the survival prediction. RF, AdaBoost, GB, and Bagging techniques have achieved the best accuracy of 97.37% .","Alawneh, Hussam; Hasasneh, Ahmad",,,Survival Prediction of Children after Bone Marrow Transplant Using Machine Learning Algorithms,21,3,10.34028/iajit/21/3/4 ,Article ,,"Bone marrow is the source of many blood -related diseases, such as blood cancers, and Bone Marrow Transplantation (BMT), also known as Hematopoietic Stem Cell Transplantation (HSCT), is a life-saving surgical procedure. However, this treatment is associated with a high risk of mortality. Predicting survival after BMT is therefore essential for effective and accurate treatment. BMT is considered a treatment -related mortality due to several primary causes of death such as infections, toxicity, and Graft -versus -Host Disease (GvHD) that occur after treatment. In addition, several risk factors affect the success of BMT and long-term survival after treatment. Therefore, there is a need for a prediction system based on machine learning techniques that can predict whether the patient will survive after BMT or not, which will definitely help the physicians to make the right decisions before performing the surgery for the patient. In this paper, using a publicly available BMT dataset from the University of California, Irvine ML repository (UCI ML repository), different machine learning models were investigated to predict the survival status of children undergoing BMT treatment. In particular, Random Forest (RF), Bagging Classifier, Extreme Gradient Boost (XGBoost), Adaptive Boosting (AdaBoost), Decision Tree (DT), Gradient Boost (GB), and K -Nearest Neighbors (KNN) were trained on the given dataset. The dataset consists of 45 variables after applying a series of preprocessing steps and removing the multicollinearity features based on the correlation heat map. Then, a feature engineering and modelling step was applied to identify the most significant features, followed by the use of machine learning models to simplify the overall classification process. It's important to note that the most important features obtained by DT and those obtained by GB were the most suitable for training the Bagging classifier and the KNN model, respectively. In addition to that, hyper -parameters optimization using Grid Search Cross -Validation (GSCV) was applied to both approaches to improve the accuracy of the survival prediction. RF, AdaBoost, GB, and Bagging techniques have achieved the best accuracy of 97.37% .",1683-3198,,,394-407, ,  ,,out_of_scope,
2708,"**Title**DODGE: automated point source bacterial outbreak detection using cumulative long term genomic surveillance

**Abstract**The reliable and timely recognition of outbreaks is a key component of public health surveillance for foodborne diseases. Whole genome sequencing (WGS) offers high resolution typing of foodborne bacterial pathogens and facilitates the accurate detection of outbreaks. This detection relies on grouping WGS data into clusters at an appropriate genetic threshold. However, methods and tools for selecting and adjusting such thresholds according to the required resolution of surveillance and epidemiological context are lacking. Here we present DODGE (Dynamic Outbreak Detection for Genomic Epidemiology), an algorithm to dynamically select and compare these genetic thresholds. DODGE can analyse expanding datasets over time and clusters that are predicted to correspond to outbreaks (or investigation clusters) can be named with established genomic nomenclature systems to facilitate integrated analysis across jurisdictions. DODGE was tested in two real-world Salmonella genomic surveillance datasets of different duration, 2 months from Australia and 9 years from the United Kingdom. In both cases only a minority of isolates were identified as investigation clusters. Two known outbreaks in the United Kingdom dataset were detected by DODGE and were recognized at an earlier timepoint than the outbreaks were reported. These findings demonstrated the potential of the DODGE approach to improve the effectiveness and timeliness of genomic surveillance for foodborne diseases and the effectiveness of the algorithm developed.","Payne, Michael; Hu, Dalong; Wang, Qinning; Sullivan, Geraldine; Graham, Rikki M.; Rathnayake, Irani U.; Jennison, Amy, V; Sintchenko, Vitali; Lan, Ruiting","Payne, Michael/ABB-2834-2020; Hu, Dalong/GOP-2877-2022","Payne, Michael/0000-0003-1911-7033",DODGE: automated point source bacterial outbreak detection using cumulative long term genomic surveillance,40,7,10.1093/bioinformatics/btae427 ,Article ,,"The reliable and timely recognition of outbreaks is a key component of public health surveillance for foodborne diseases. Whole genome sequencing (WGS) offers high resolution typing of foodborne bacterial pathogens and facilitates the accurate detection of outbreaks. This detection relies on grouping WGS data into clusters at an appropriate genetic threshold. However, methods and tools for selecting and adjusting such thresholds according to the required resolution of surveillance and epidemiological context are lacking. Here we present DODGE (Dynamic Outbreak Detection for Genomic Epidemiology), an algorithm to dynamically select and compare these genetic thresholds. DODGE can analyse expanding datasets over time and clusters that are predicted to correspond to outbreaks (or investigation clusters) can be named with established genomic nomenclature systems to facilitate integrated analysis across jurisdictions. DODGE was tested in two real-world Salmonella genomic surveillance datasets of different duration, 2 months from Australia and 9 years from the United Kingdom. In both cases only a minority of isolates were identified as investigation clusters. Two known outbreaks in the United Kingdom dataset were detected by DODGE and were recognized at an earlier timepoint than the outbreaks were reported. These findings demonstrated the potential of the DODGE approach to improve the effectiveness and timeliness of genomic surveillance for foodborne diseases and the effectiveness of the algorithm developed.",1367-4803,1367-4811,,, ,  ,,out_of_scope,
2709,"**Title**How important is it to update the existing environmental quality standard for nickel? An example based on the UK

**Abstract**In Europe the Environmental Quality Standard (EQS) for nickel in freshwaters was set in 2013 based on the best available evidence at the time. Since then, additional information about the toxicity of nickel to aquatic organisms and the effects of water chemistry conditions on nickel bioavailability have become available, and there is much more information available about the water chemistry conditions that affect nickel toxicity in freshwaters. This study has taken the updated information about nickel ecotoxicity and bioavailability and evaluates how this could potentially affect the EQS for nickel if it was to be updated. Although the sensitivity of freshwaters to nickel based on the update is very similar to the EQS on a site-specific basis, the thresholds derived are slightly lower. A broader range of water chemistry conditions can be covered by the update than are currently covered by the existing EQS. An updated standard of 2.9 mu g L-1 bioavailable nickel could be derived based on the UK dataset evaluated here, which is slightly lower than the existing EQS of 4 mu g L-1 bioavailable nickel. Consequently, a slightly higher number of potential compliance failures would be expected based on the update. A simple and practical approach toward the incorporation of local nickel background concentrations into the compliance assessment process for sites that fail the bioavailability based EQS is also proposed. Initial assessments suggest that compliance with the existing EQS could potentially result in more than 5% of species in freshwater aquatic ecosystems being affected, but that with the exception of a very small number of cases the proportion of potentially affected species would be less than 8% of species in the ecosystem. In regions where the existing EQS is not fully implemented, particularly through limited consideration of bioavailability, the adoption of the updated standard is likely to be less beneficial than focusing on better implementation of the existing EQS. However, in regions where the existing EQS has been implemented extensively for some time the updated standard offers a refinement in terms of the coverage of a higher proportion of surface waters and a slightly higher level of protection for sensitive species than the existing EQS.Updated information about nickel ecotoxicity and bioavailability has been used to evaluate whether the EQS for nickel should be revised.","Peters, Adam; Merrington, Graham; Middleton, Elizabeth","Middleton, Elizabeth/KHT-9643-2024","Middleton, Elizabeth Traudt/0000-0002-4775-2774",How important is it to update the existing environmental quality standard for nickel? An example based on the UK,3,8,10.1039/d4va00098f ,Article ,,"In Europe the Environmental Quality Standard (EQS) for nickel in freshwaters was set in 2013 based on the best available evidence at the time. Since then, additional information about the toxicity of nickel to aquatic organisms and the effects of water chemistry conditions on nickel bioavailability have become available, and there is much more information available about the water chemistry conditions that affect nickel toxicity in freshwaters. This study has taken the updated information about nickel ecotoxicity and bioavailability and evaluates how this could potentially affect the EQS for nickel if it was to be updated. Although the sensitivity of freshwaters to nickel based on the update is very similar to the EQS on a site-specific basis, the thresholds derived are slightly lower. A broader range of water chemistry conditions can be covered by the update than are currently covered by the existing EQS. An updated standard of 2.9 mu g L-1 bioavailable nickel could be derived based on the UK dataset evaluated here, which is slightly lower than the existing EQS of 4 mu g L-1 bioavailable nickel. Consequently, a slightly higher number of potential compliance failures would be expected based on the update. A simple and practical approach toward the incorporation of local nickel background concentrations into the compliance assessment process for sites that fail the bioavailability based EQS is also proposed. Initial assessments suggest that compliance with the existing EQS could potentially result in more than 5% of species in freshwater aquatic ecosystems being affected, but that with the exception of a very small number of cases the proportion of potentially affected species would be less than 8% of species in the ecosystem. In regions where the existing EQS is not fully implemented, particularly through limited consideration of bioavailability, the adoption of the updated standard is likely to be less beneficial than focusing on better implementation of the existing EQS. However, in regions where the existing EQS has been implemented extensively for some time the updated standard offers a refinement in terms of the coverage of a higher proportion of surface waters and a slightly higher level of protection for sensitive species than the existing EQS.Updated information about nickel ecotoxicity and bioavailability has been used to evaluate whether the EQS for nickel should be revised.",,2754-7000,,1139-1152, ,  ,,out_of_scope,
2710,"**Title**Managing false positives during detection of pathogen sequences in shotgun metagenomics datasets

**Abstract**BackgroundCulture-independent diagnostic tests are gaining popularity as tools for detecting pathogens in food. Shotgun sequencing holds substantial promise for food testing as it provides abundant information on microbial communities, but the challenge is in analyzing large and complex sequencing datasets with a high degree of both sensitivity and specificity. Falsely classifying sequencing reads as originating from pathogens can lead to unnecessary food recalls or production shutdowns, while low sensitivity resulting in false negatives could lead to preventable illness.ResultsWe used simulated and published shotgun sequencing datasets containing Salmonella-derived reads to explore the appearance and mitigation of false positive results using the popular taxonomic annotation softwares Kraken2 and Metaphlan4. Using default parameters, Kraken2 is sensitive but prone to false positives, while Metaphlan4 is more specific but unable to detect Salmonella at low abundance. We then developed a bioinformatic pipeline for identifying and removing reads falsely identified as Salmonella by Kraken2 while retaining high sensitivity. Carefully considering software parameters and database choices is essential to avoiding false positive sample calls. With well-chosen parameters plus additional steps to confirm the taxonomic origin of reads, it is possible to detect pathogens with very high specificity and sensitivity.","Bradford, Lauren M.; Carrillo, Catherine; Wong, Alex","Carrillo, Catherine/X-2714-2019",,Managing false positives during detection of pathogen sequences in shotgun metagenomics datasets,25,1,10.1186/s12859-024-05952-x ,Article ,,"BackgroundCulture-independent diagnostic tests are gaining popularity as tools for detecting pathogens in food. Shotgun sequencing holds substantial promise for food testing as it provides abundant information on microbial communities, but the challenge is in analyzing large and complex sequencing datasets with a high degree of both sensitivity and specificity. Falsely classifying sequencing reads as originating from pathogens can lead to unnecessary food recalls or production shutdowns, while low sensitivity resulting in false negatives could lead to preventable illness.ResultsWe used simulated and published shotgun sequencing datasets containing Salmonella-derived reads to explore the appearance and mitigation of false positive results using the popular taxonomic annotation softwares Kraken2 and Metaphlan4. Using default parameters, Kraken2 is sensitive but prone to false positives, while Metaphlan4 is more specific but unable to detect Salmonella at low abundance. We then developed a bioinformatic pipeline for identifying and removing reads falsely identified as Salmonella by Kraken2 while retaining high sensitivity. Carefully considering software parameters and database choices is essential to avoiding false positive sample calls. With well-chosen parameters plus additional steps to confirm the taxonomic origin of reads, it is possible to detect pathogens with very high specificity and sensitivity.",1471-2105,,,, ,  ,,out_of_scope,
2711,"**Title**In silico assessment of nanoparticle toxicity powered by the Enalos Cloud Platform: Integrating automated machine learning and synthetic data for enhanced nanosafety evaluation

**Abstract**The rapid advance of nanotechnology has led to the development and widespread application of nanomaterials, raising concerns regarding their potential adverse effects on human health and the environment. Traditional (experimental) methods for assessing the nanoparticles (NPs) safety are time-consuming, expensive, and resource-intensive, and raise ethical concerns due to their reliance on animals. To address these challenges, we propose an in silico workflow that serves as an alternative or complementary approach to conventional hazard and risk assessment strategies, which incorporates state-of-the-art computational methodologies. In this study we present an automated machine learning (autoML) scheme that employs dose-response toxicity data for silver (Ag), titanium dioxide (TiO2), and copper oxide (CuO) NPs. This model is further enriched with atomistic descriptors to capture the NPs' underlying structural properties. To overcome the issue of limited data availability, synthetic data generation techniques are used. These techniques help in broadening the dataset, thus improving the representation of different NP classes. A key aspect of this approach is a novel three-step applicability domain method (which includes the development of a local similarity approach) that enhances user confidence in the results by evaluating the prediction's reliability. We anticipate that this approach will significantly expedite the nanosafety assessment process enabling regulation to keep pace with innovation, and will provide valuable insights for the design and development of safe and sustainable NPs. The ML model developed in this study is made available to the scientific community as an easy-to-use web-service through the Enalos Cloud Platform (www.en aloscloud.novamechanics.com/sabydoma/safenanoscope/), facilitating broader access and collaborative advancements in nanosafety.","Varsou, Dimitra-Danai; Kolokathis, Panagiotis D.; Antoniou, Maria; Sidiropoulos, Nikolaos K.; Tsoumanis, Andreas; Papadiamantis, Anastasios G.; Melagraki, Georgia; Lynch, Iseult; Afantitis, Antreas","Melagraki, Georgia/AAR-7807-2020; Afantitis, Antreas/A-9637-2010; Lynch, Iseult/I-3915-2014","Lynch, Iseult/0000-0003-4250-4584; Varsou, Dimitra-Danai/0000-0002-7474-7014",In silico assessment of nanoparticle toxicity powered by the Enalos Cloud Platform: Integrating automated machine learning and synthetic data for enhanced nanosafety evaluation,25,,10.1016/j.csbj.2024.03.020 ,Article ,,"The rapid advance of nanotechnology has led to the development and widespread application of nanomaterials, raising concerns regarding their potential adverse effects on human health and the environment. Traditional (experimental) methods for assessing the nanoparticles (NPs) safety are time-consuming, expensive, and resource-intensive, and raise ethical concerns due to their reliance on animals. To address these challenges, we propose an in silico workflow that serves as an alternative or complementary approach to conventional hazard and risk assessment strategies, which incorporates state-of-the-art computational methodologies. In this study we present an automated machine learning (autoML) scheme that employs dose-response toxicity data for silver (Ag), titanium dioxide (TiO2), and copper oxide (CuO) NPs. This model is further enriched with atomistic descriptors to capture the NPs' underlying structural properties. To overcome the issue of limited data availability, synthetic data generation techniques are used. These techniques help in broadening the dataset, thus improving the representation of different NP classes. A key aspect of this approach is a novel three-step applicability domain method (which includes the development of a local similarity approach) that enhances user confidence in the results by evaluating the prediction's reliability. We anticipate that this approach will significantly expedite the nanosafety assessment process enabling regulation to keep pace with innovation, and will provide valuable insights for the design and development of safe and sustainable NPs. The ML model developed in this study is made available to the scientific community as an easy-to-use web-service through the Enalos Cloud Platform (www.en aloscloud.novamechanics.com/sabydoma/safenanoscope/), facilitating broader access and collaborative advancements in nanosafety.",2001-0370,,,47-60, ,  ,,out_of_scope,
2712,"**Title**MoS-TEC: A toxicogenomics database based on model selection for time-expression curves

**Abstract**MoS-TEC is a newly developed toxicogenomics database for time-expression curves fitted with a statistical model selection approach. Toxicogenomic data provide information on the response of the genome to compounds, often measured in terms of gene expression values. When such experimental data are available for different exposure times, the functional relationships between the exposure time and the expression values of genes might be of interest. The TG-GATEs (Open Toxicogenomics Project-Genomics Assisted Toxicity Evaluation System) database provides such information for genomewide gene expression data for 170 compounds. We performed extensive model selection using MCP-Mod on these data. Specifically, gene expression data measured for eight time points from in vivo experiments on rat liver for 120 compounds with complete datasets were considered. MCP-Mod is a two-step approach, including a multiple comparison procedure (MCP) and a modelling (Mod) approach. The results are estimated time-expression curves that model the relationship between exposure time and gene expression values for all combinations of genes and compounds. We present an appropriate data normalization approach and report which models were selected per compound and in total. For high-quality model fits with a large value for the explained variance, the sigEmax model was most frequently selected. The new R Shiny application MoS-TEC provides easy access for researchers to the best curve fit for all genes individually for all compounds. It can be used online without installing additional software.","Kappenberg, Franziska; Kuethe, Benedikt; Rahnenfuehrer, Joerg",,"Kappenberg, Franziska/0000-0001-8066-5333; Rahnenfuhrer, Jorg/0000-0002-8947-440X",MoS-TEC: A toxicogenomics database based on model selection for time-expression curves,30,,10.1016/j.comtox.2024.100313 ,Article ,,"MoS-TEC is a newly developed toxicogenomics database for time-expression curves fitted with a statistical model selection approach. Toxicogenomic data provide information on the response of the genome to compounds, often measured in terms of gene expression values. When such experimental data are available for different exposure times, the functional relationships between the exposure time and the expression values of genes might be of interest. The TG-GATEs (Open Toxicogenomics Project-Genomics Assisted Toxicity Evaluation System) database provides such information for genomewide gene expression data for 170 compounds. We performed extensive model selection using MCP-Mod on these data. Specifically, gene expression data measured for eight time points from in vivo experiments on rat liver for 120 compounds with complete datasets were considered. MCP-Mod is a two-step approach, including a multiple comparison procedure (MCP) and a modelling (Mod) approach. The results are estimated time-expression curves that model the relationship between exposure time and gene expression values for all combinations of genes and compounds. We present an appropriate data normalization approach and report which models were selected per compound and in total. For high-quality model fits with a large value for the explained variance, the sigEmax model was most frequently selected. The new R Shiny application MoS-TEC provides easy access for researchers to the best curve fit for all genes individually for all compounds. It can be used online without installing additional software.",2468-1113,,,, ,  ,,out_of_scope,
2713,"**Title**A data reusability assessment in the nanosafety domain based on the NSDRA framework followed by an exploratory quantitative structure activity relationships (QSAR) modeling targeting cellular viability

**Abstract**Introduction: The current effort towards the digital transformation across multiple scientific domains requires data that is Findable, Accessible, Interoperable and Reusable (FAIR). In addition to the FAIR data, what is required for the application of computational tools, such as Quantitative Structure Activity Relationships (QSARs), is a sufficient data volume and the ability to merge sources into homogeneous digital assets. In the nanosafety domain there is a lack of FAIR available metadata.Methodology: To address this challenge, we utilized 34 datasets from the nanosafety domain by exploiting the NanoSafety Data Reusability Assessment (NSDRA) framework, which allowed the annotation and assessment of dataset's reusability. From the framework's application results, eight datasets targeting the same endpoint (i.e. numerical cellular viability) were selected, processed and merged to test several hypothesis including universal versus nanogroup-specific QSAR models (metal oxide and nanotubes), and regression versus classification Machine Learning (ML) algorithms. Results: Universal regression and classification QSARs reached an 0.86 R2 and 0.92 accuracy, respectively, for the test set. Nanogroup-specific regression models reached 0.88 R2 for nanotubes test set followed by metal oxide (0.78). Nanogroup-specific classification models reached 0.99 accuracy for nanotubes test set, followed by metal oxide (0.91). Feature importance revealed different patterns depending on the dataset with common influential features including core size, exposure conditions and toxicological assay. Even in the case where the available experimental knowledge was merged, the models still failed to correctly predict the outputs of an unseen dataset, revealing the cumbersome conundrum of scientific reproducibility in realistic applications of QSAR for nanosafety. To harness the full potential of computational tools and ensure their long-term applications, embracing FAIR data practices is imperative in driving the development of responsible QSAR models. Conclusions: This study reveals that the digitalization of nanosafety knowledge in a reproducible manner has a long way towards its successful pragmatic implementation. The workflow carried out in the study shows a promising approach to increase the FAIRness across all the elements of computational studies, from dataset's annotation, selection, merging to FAIR modeling reporting. This has significant implications for future research as it provides an example of how to utilize and report different tools available in the nanosafety knowledge system, while increasing the transparency of the results. One of the main benefits of this workflow is that it promotes data sharing and reuse, which is essential for advancing scientific knowledge by making data and metadata FAIR compliant. In addition, the increased transparency and reproducibility of the results can enhance the trustworthiness of the computational findings.","Furxhi, Irini; Willighagen, Egon; Evelo, Chris; Costa, Anna; Gardini, Davide; Ammar, Ammar","Gardini, Davide/A-8708-2012; Evelo, Chris/D-2914-2009; Ammar, Ammar/CAF-7943-2022; Costa, Anna Luisa/A-8534-2012","Ammar, Ammar/0000-0002-8399-8990; Furxhi, Irini/0000-0002-2263-0279; Evelo, Chris/0000-0002-5301-3142; Willighagen, Egon/0000-0001-7542-0286; Costa, Anna Luisa/0000-0003-1407-6498",A data reusability assessment in the nanosafety domain based on the NSDRA framework followed by an exploratory quantitative structure activity relationships (QSAR) modeling targeting cellular viability,31,,10.1016/j.impact.2023.100475 ,Article ,,"Introduction: The current effort towards the digital transformation across multiple scientific domains requires data that is Findable, Accessible, Interoperable and Reusable (FAIR). In addition to the FAIR data, what is required for the application of computational tools, such as Quantitative Structure Activity Relationships (QSARs), is a sufficient data volume and the ability to merge sources into homogeneous digital assets. In the nanosafety domain there is a lack of FAIR available metadata.Methodology: To address this challenge, we utilized 34 datasets from the nanosafety domain by exploiting the NanoSafety Data Reusability Assessment (NSDRA) framework, which allowed the annotation and assessment of dataset's reusability. From the framework's application results, eight datasets targeting the same endpoint (i.e. numerical cellular viability) were selected, processed and merged to test several hypothesis including universal versus nanogroup-specific QSAR models (metal oxide and nanotubes), and regression versus classification Machine Learning (ML) algorithms. Results: Universal regression and classification QSARs reached an 0.86 R2 and 0.92 accuracy, respectively, for the test set. Nanogroup-specific regression models reached 0.88 R2 for nanotubes test set followed by metal oxide (0.78). Nanogroup-specific classification models reached 0.99 accuracy for nanotubes test set, followed by metal oxide (0.91). Feature importance revealed different patterns depending on the dataset with common influential features including core size, exposure conditions and toxicological assay. Even in the case where the available experimental knowledge was merged, the models still failed to correctly predict the outputs of an unseen dataset, revealing the cumbersome conundrum of scientific reproducibility in realistic applications of QSAR for nanosafety. To harness the full potential of computational tools and ensure their long-term applications, embracing FAIR data practices is imperative in driving the development of responsible QSAR models. Conclusions: This study reveals that the digitalization of nanosafety knowledge in a reproducible manner has a long way towards its successful pragmatic implementation. The workflow carried out in the study shows a promising approach to increase the FAIRness across all the elements of computational studies, from dataset's annotation, selection, merging to FAIR modeling reporting. This has significant implications for future research as it provides an example of how to utilize and report different tools available in the nanosafety knowledge system, while increasing the transparency of the results. One of the main benefits of this workflow is that it promotes data sharing and reuse, which is essential for advancing scientific knowledge by making data and metadata FAIR compliant. In addition, the increased transparency and reproducibility of the results can enhance the trustworthiness of the computational findings.",2452-0748,,,, ,  ,,out_of_scope,
2714,"**Title**Quantitative and qualitative performance evaluation of commercial metal artifact reduction methods: Dosimetric effects on the treatment planning

**Abstract**The presence of metal implants within CT imaging causes severe attenuation of the X-ray beam. Due to the incomplete information recorded by CT detectors, artifacts in the form of streaks and dark bands would appear in the resulting CT images. The metal-induced artifacts would firstly affect the quantitative accuracy of CT imaging, and consequently, the radiation treatment planning and dose estimation in radiation therapy. To address this issue, CT scanner vendors have implemented metal artifact reduction (MAR) algorithms to avoid such artifacts and enhance the overall quality of CT images. The orthopedic-MAR (OMAR) and normalized MAR (NMAR) algorithms are the most well-known metal artifact reduction (MAR) algorithms, used worldwide. These algorithms have been implemented on Philips and Siemens scanners, respectively. In this study, we set out to quantitatively and qualitatively evaluate the effectiveness of these two MAR algorithms and their impact on accurate radiation treatment planning and CT-based dosimetry. The quantitative metrics measured on the simulated metal artifact dataset demonstrated superior performance of the OMAR technique over the NMAR one in metal artifact reduction. The analysis of radiation treatment planning using the OMAR and NMAR techniques in the corrected CT images showed that the OMAR technique reduced the toxicity of healthy tissues by 10% compared to the uncorrected CT images.","Ghorbanzadeh, Mohammad; Hosseini, Seyed Abolfazl; Vahdat, Bijan Vosoughi; Mirzaiy, Hamed; Akhavanallaf, Azadeh; Arabi, Hossein","ARABI, Hossein/AAF-4502-2021",,Quantitative and qualitative performance evaluation of commercial metal artifact reduction methods: Dosimetric effects on the treatment planning,225,,10.1016/j.radphyschem.2024.112140 ,Article ,,"The presence of metal implants within CT imaging causes severe attenuation of the X-ray beam. Due to the incomplete information recorded by CT detectors, artifacts in the form of streaks and dark bands would appear in the resulting CT images. The metal-induced artifacts would firstly affect the quantitative accuracy of CT imaging, and consequently, the radiation treatment planning and dose estimation in radiation therapy. To address this issue, CT scanner vendors have implemented metal artifact reduction (MAR) algorithms to avoid such artifacts and enhance the overall quality of CT images. The orthopedic-MAR (OMAR) and normalized MAR (NMAR) algorithms are the most well-known metal artifact reduction (MAR) algorithms, used worldwide. These algorithms have been implemented on Philips and Siemens scanners, respectively. In this study, we set out to quantitatively and qualitatively evaluate the effectiveness of these two MAR algorithms and their impact on accurate radiation treatment planning and CT-based dosimetry. The quantitative metrics measured on the simulated metal artifact dataset demonstrated superior performance of the OMAR technique over the NMAR one in metal artifact reduction. The analysis of radiation treatment planning using the OMAR and NMAR techniques in the corrected CT images showed that the OMAR technique reduced the toxicity of healthy tissues by 10% compared to the uncorrected CT images.",0969-806X,1879-0895,,, ,  ,,out_of_scope,
2715,"**Title**Fish 3D Locomotion app: a user-friendly computer application package for automatic data calculation and endpoint extraction for novel tank behavior in fish

**Abstract**This paper introduces the Fish 3D Locomotion app (F3LA), a Python-based, Graphical User Interface (GUI)-equipped tool designed to automate behavioral endpoint extraction in zebrafish locomotion assays. Building on our previous work, which utilized a specialized aquatic tank with a mirror and a single camera for fish movement tracking in three dimensions, F3LA significantly enhances data processing efficiency. Its accuracy was tested by reanalyzing and comprehensively comparing the calculated data with the previously published data from prior publications. From the comparison results, 90% of endpoints showed a similar statistical difference result. These minor differences were due to the different starting points for the dataset and updated calculation formulas that are implemented in F3LA. In addition, shoaling area or shoaling volume calculations are also included in F3LA as a new feature that can serve as sensitive indicators of social cohesion, group dynamics, or stress responses, offering insights into neuropsychological conditions or the effects of pharmacological interventions. Furthermore, F3LA offers a marked improvement over manual operations, being at least five times faster, while maintaining consistent accuracy as it reduces human-induced errors, ensuring a higher degree of reliability in the results. Finally, the potency of F3LA was tested to evaluate the toxicities of 14 rare earth elements (REEs) to the adult zebrafish behaviors. Based on the results, our findings suggested that each tested REE altered fish behaviors in different patterns and magnitudes to each other. However, among the tested light rare earth elements (LREEs), neodymium was demonstrated to cause more relatively severe behavior alterations than other LREEs, indicated by the statistically higher value of entropy (0.2695 +/- 0.04977 (mean with a standard deviation)) than the control group (0.2352 +/- 0.05896). Meanwhile, in terms of heavy rare earth elements (HREEs), erbium seemed to lead to more distinct behavior toxicities than other HREEs, which was shown by the statistically lower level of fractal dimension (2.022 +/- 0.3412) than the untreated group (2.255 +/- 0.1661). Taken together, F3LA's development marks a significant advance in high-throughput toxicological and pharmacological assessments in zebrafish, leveraging three-dimensional locomotion data for a more comprehensive analysis of fish behavior performance, providing a significant contribution to research in various fields.","Luong, Cao Thang; Audira, Gilbert; Kurnia, Kevin Adi; Hung, Chih-Hsin; Hsiao, Chung-Der","Hsiao, Chung-Der/W-4535-2019","Hsiao, Chung-Der/0000-0002-6398-8672",Fish 3D Locomotion app: a user-friendly computer application package for automatic data calculation and endpoint extraction for novel tank behavior in fish,,,10.1111/jfb.15860 ,Article; Early Access ,,"This paper introduces the Fish 3D Locomotion app (F3LA), a Python-based, Graphical User Interface (GUI)-equipped tool designed to automate behavioral endpoint extraction in zebrafish locomotion assays. Building on our previous work, which utilized a specialized aquatic tank with a mirror and a single camera for fish movement tracking in three dimensions, F3LA significantly enhances data processing efficiency. Its accuracy was tested by reanalyzing and comprehensively comparing the calculated data with the previously published data from prior publications. From the comparison results, 90% of endpoints showed a similar statistical difference result. These minor differences were due to the different starting points for the dataset and updated calculation formulas that are implemented in F3LA. In addition, shoaling area or shoaling volume calculations are also included in F3LA as a new feature that can serve as sensitive indicators of social cohesion, group dynamics, or stress responses, offering insights into neuropsychological conditions or the effects of pharmacological interventions. Furthermore, F3LA offers a marked improvement over manual operations, being at least five times faster, while maintaining consistent accuracy as it reduces human-induced errors, ensuring a higher degree of reliability in the results. Finally, the potency of F3LA was tested to evaluate the toxicities of 14 rare earth elements (REEs) to the adult zebrafish behaviors. Based on the results, our findings suggested that each tested REE altered fish behaviors in different patterns and magnitudes to each other. However, among the tested light rare earth elements (LREEs), neodymium was demonstrated to cause more relatively severe behavior alterations than other LREEs, indicated by the statistically higher value of entropy (0.2695 +/- 0.04977 (mean with a standard deviation)) than the control group (0.2352 +/- 0.05896). Meanwhile, in terms of heavy rare earth elements (HREEs), erbium seemed to lead to more distinct behavior toxicities than other HREEs, which was shown by the statistically lower level of fractal dimension (2.022 +/- 0.3412) than the untreated group (2.255 +/- 0.1661). Taken together, F3LA's development marks a significant advance in high-throughput toxicological and pharmacological assessments in zebrafish, leveraging three-dimensional locomotion data for a more comprehensive analysis of fish behavior performance, providing a significant contribution to research in various fields.",0022-1112,1095-8649,,, ,  ,,out_of_scope,
2716,"**Title**Deep CNN-Based Insect Detection for Precision Agriculture and Design of UAV to Spray Pesticides on Detected Area

**Abstract**Agriculture is India's most common job, yet it lacks innovation and technology. As the world's population expands, so does the demand for more food. Pesticides are used on farms to boost yield. The toxicity of the fertilizer has serious health repercussions for the farmer. So, it's recommended to measure the amount of pesticide used and only apply it when necessary. We devised an insect-finding and insecticide-spraying mechanism. This is accomplished by employing a drone or Uninterrupted Ariel Vehicle. The drone has a camera that can photograph fields and lift pesticides weighing 3 to 4kg. After locating the insect, the insecticide is sprayed through the nozzles. In the proposed model, the Deep Convolutional Neural Network (CNN) has reached state of the art in image processing and object detection issues. Deep CNN has the potential to self-learn hidden features that help with insect detection. When compared to other similar approaches, experimental findings on a real dataset to illustrate the usefulness of the suggested methodology. We identified insects on the crop with 90% accuracy using deep CNN. It helps farmers to increase crop yield while also shielding them from the detrimental effects of spraying pesticides on the field manually.","Agrawal, Smita; Kathiria, Preeti; Vora, Hitesh; Mirani, Hardik; Dani, Aastha; Oza, Parita; Patel, Usha","Kathiria, Preeti/HCI-1646-2022; Oza, Parita/ABA-9864-2020; Patel, Usha/AGX-0340-2022",,Deep CNN-Based Insect Detection for Precision Agriculture and Design of UAV to Spray Pesticides on Detected Area,,,10.1142/S0219467826500282 ,Article; Early Access ,,"Agriculture is India's most common job, yet it lacks innovation and technology. As the world's population expands, so does the demand for more food. Pesticides are used on farms to boost yield. The toxicity of the fertilizer has serious health repercussions for the farmer. So, it's recommended to measure the amount of pesticide used and only apply it when necessary. We devised an insect-finding and insecticide-spraying mechanism. This is accomplished by employing a drone or Uninterrupted Ariel Vehicle. The drone has a camera that can photograph fields and lift pesticides weighing 3 to 4kg. After locating the insect, the insecticide is sprayed through the nozzles. In the proposed model, the Deep Convolutional Neural Network (CNN) has reached state of the art in image processing and object detection issues. Deep CNN has the potential to self-learn hidden features that help with insect detection. When compared to other similar approaches, experimental findings on a real dataset to illustrate the usefulness of the suggested methodology. We identified insects on the crop with 90% accuracy using deep CNN. It helps farmers to increase crop yield while also shielding them from the detrimental effects of spraying pesticides on the field manually.",0219-4678,1793-6756,,, ,  ,,out_of_scope,
2717,"**Title**Deep Learning Based on EfficientNet for Multiorgan Segmentation of Thoracic Structures on a 0.35 T MR-Linac Radiation Therapy System

**Abstract**The advent of the 0.35 T MR-Linac (MRIdian, ViewRay) system in radiation therapy allows precise tumor targeting for moving lesions. However, the lack of an automatic volume segmentation function in the MR-Linac's treatment planning system poses a challenge. In this paper, we propose a deep-learning-based multiorgan segmentation approach for the thoracic region, using EfficientNet as the backbone for the network architecture. The objectives of this approach include accurate segmentation of critical organs, such as the left and right lungs, the heart, the spinal cord, and the esophagus, essential for minimizing radiation toxicity during external radiation therapy. Our proposed approach, when evaluated on an internal dataset comprising 81 patients, demonstrated superior performance compared to other state-of-the-art methods. Specifically, the results for our approach with a 2.5D strategy were as follows: a dice similarity coefficient (DSC) of 0.820 +/- 0.041, an intersection over union (IoU) of 0.725 +/- 0.052, and a 3D Hausdorff distance (HD) of 10.353 +/- 4.974 mm. Notably, the 2.5D strategy surpassed the 2D strategy in all three metrics, exhibiting higher DSC and IoU values, as well as lower HD values. This improvement strongly suggests that our proposed approach with the 2.5D strategy may hold promise in achieving more precise and accurate segmentations when compared to the conventional 2D strategy. Our work has practical implications in the improvement of treatment planning precision, aligning with the evolution of medical imaging and innovative strategies for multiorgan segmentation tasks.","Chekroun, Mohammed; Mourchid, Youssef; Bessieres, Igor; Lalande, Alain","Lalande, Alain/T-1050-2017; Mourchid, Youssef/AAK-3314-2021","Lalande, Alain/0000-0002-7970-366X; MOURCHID, Youssef/0000-0003-4108-4557",Deep Learning Based on EfficientNet for Multiorgan Segmentation of Thoracic Structures on a 0.35 T MR-Linac Radiation Therapy System,16,12,10.3390/a16120564 ,Article ,,"The advent of the 0.35 T MR-Linac (MRIdian, ViewRay) system in radiation therapy allows precise tumor targeting for moving lesions. However, the lack of an automatic volume segmentation function in the MR-Linac's treatment planning system poses a challenge. In this paper, we propose a deep-learning-based multiorgan segmentation approach for the thoracic region, using EfficientNet as the backbone for the network architecture. The objectives of this approach include accurate segmentation of critical organs, such as the left and right lungs, the heart, the spinal cord, and the esophagus, essential for minimizing radiation toxicity during external radiation therapy. Our proposed approach, when evaluated on an internal dataset comprising 81 patients, demonstrated superior performance compared to other state-of-the-art methods. Specifically, the results for our approach with a 2.5D strategy were as follows: a dice similarity coefficient (DSC) of 0.820 +/- 0.041, an intersection over union (IoU) of 0.725 +/- 0.052, and a 3D Hausdorff distance (HD) of 10.353 +/- 4.974 mm. Notably, the 2.5D strategy surpassed the 2D strategy in all three metrics, exhibiting higher DSC and IoU values, as well as lower HD values. This improvement strongly suggests that our proposed approach with the 2.5D strategy may hold promise in achieving more precise and accurate segmentations when compared to the conventional 2D strategy. Our work has practical implications in the improvement of treatment planning precision, aligning with the evolution of medical imaging and innovative strategies for multiorgan segmentation tasks.",,1999-4893,,, ,  ,,out_of_scope,
2718,"**Title**Cyber democracy in the digital age: Characterizing hate networks in the 2022 US midterm elections

**Abstract**Social media has become integral to societal discourse and play a role in shaping public engagement, particularly in democratic electoral processes. This paper addresses the pressing issue of hate speech on social media during the 2022 US midterm elections. Unlike previous research, which often relies on limited datasets and classic methodologies, we leverage Open Source Intelligence (OSINT) and Natural Language Processing (NLP) techniques to analyze Twitter data through advanced models of entity recognition, sentiment analysis, and community extraction, having persistence in Knowledge Graphs for consuming the intelligence efficiently. Results indicate that in the US midterm elections 2022, Arizona was the state that provided more content (507,551 tweets) related to a Chief Electoral Official, with 31.58% of them identified in the most aggressive cluster due to its mean attribute values of attack on commenter(0.7), inflammatory(similar to 0.3), attack on author(similar to 0.2), and toxicity(similar to 0.2). The name entity recognition model also identified an association between those aggressive tweets and the previous 2020 US Presidential campaign, characterized by attacks on election officials based on conspiracy theories campaigns. Knowledge graphs contributed to understanding the concentration of attacks and connectivity between topics commonly mentioned in hate speech content. Thus, our results offer detailed insights into the actors and dynamics of online harassment in electoral contexts, illuminating the challenges posed by harassment and proposing preventive mechanisms applicable to diverse electoral processes worldwide.","Rozo, Andres Zapata; Campo-Archbold, Alejandra; Diaz-Lopez, Daniel; Gray, Ian; Pastor-Galindo, Javier; Nespoli, Pantaleone; Marmol, Felix Gomez; McCoy, Damon","Mármol, Félix/A-7505-2016","Diaz-Lopez, Daniel/0000-0001-7244-2631; Campo-Archbold, Alejandra/0000-0002-2574-8184",Cyber democracy in the digital age: Characterizing hate networks in the 2022 US midterm elections,110,,10.1016/j.inffus.2024.102459 ,Article ,,"Social media has become integral to societal discourse and play a role in shaping public engagement, particularly in democratic electoral processes. This paper addresses the pressing issue of hate speech on social media during the 2022 US midterm elections. Unlike previous research, which often relies on limited datasets and classic methodologies, we leverage Open Source Intelligence (OSINT) and Natural Language Processing (NLP) techniques to analyze Twitter data through advanced models of entity recognition, sentiment analysis, and community extraction, having persistence in Knowledge Graphs for consuming the intelligence efficiently. Results indicate that in the US midterm elections 2022, Arizona was the state that provided more content (507,551 tweets) related to a Chief Electoral Official, with 31.58% of them identified in the most aggressive cluster due to its mean attribute values of attack on commenter(0.7), inflammatory(similar to 0.3), attack on author(similar to 0.2), and toxicity(similar to 0.2). The name entity recognition model also identified an association between those aggressive tweets and the previous 2020 US Presidential campaign, characterized by attacks on election officials based on conspiracy theories campaigns. Knowledge graphs contributed to understanding the concentration of attacks and connectivity between topics commonly mentioned in hate speech content. Thus, our results offer detailed insights into the actors and dynamics of online harassment in electoral contexts, illuminating the challenges posed by harassment and proposing preventive mechanisms applicable to diverse electoral processes worldwide.",1566-2535,1872-6305,,, ,  ,,Gen_dataset,
2719,"**Title**Leaky Integrate-and-Fire Model and Short-Term Synaptic Plasticity Emulated in a Novel Bismuth-Based Diffusive Memristor

**Abstract**Memristors, being prospective work-horses of future electronics offer various types of memory (volatile and nonvolatile) along with specific computational functionalities. Further development of memristive technologies depends on the availability of suitable materials. These materials should be easily available, stable, and preferably of low toxicity. Commonly used materials are lead halide perovskites, however, they are highly toxic and unstable under ambient conditions. Therefore a novel material is developed on the basis of bismuth iodide. In reaction with butylammonium iodide, it yields a novel compound, butylammonium iodobismuthate (BABI). Here, a diffusive memristor is introduced based on this compound and evaluates its memristive and neuromorphic properties. In contrast to nonvolatile memristors, the BABI memristors exhibit diffusive dynamics, which enable them to store the information only for short periods of time. This property is utilized to mimic the short-term synaptic plasticity described by the leaky integrate-and-fire model of a biological neuron. Combined with high switching uniformity and self-rectifying behavior, these devices show high classification accuracy for MNIST handwritten datasets, paving the way for their application in neuromorphic computing systems.Butylammonium iodobismuthate presents unique volatile memristive properties resulting from diffusive dynamics of iodide vacancies. These materials can be used for the fabrication of synaptic devices with high ON-OFF ratios, and unique temporal characteristics that pave the way for new-generation neuromorphic computing systems. image","Zawal, Piotr; Abdi, Gisya; Gryl, Marlena; Das, Dip; Slawek, Andrzej; Gerouville, Emilie A.; Marciszko-Wiackowska, Marianna; Marzec, Mateusz; Hess, Grzegorz; Georgiadou, Dimitra G.; Szacilowski, Konrad","Marciszko-Wiąckowska, Marianna/HKV-1207-2023; Gryl, Marlena/O-6242-2017; Szaciłowski, Konrad/AAU-2864-2020; Abdi, Gisya/AAU-5960-2020; Hess, Grzegorz/HGQ-0966-2022; Zawal, Piotr/AAV-4767-2021","Gerouville, Emilie/0000-0003-2569-5198; Marciszko-Wiackowska, Marianna/0000-0003-3490-4422; Szacilowski, Konrad/0000-0002-1596-9856; Slawek, Andrzej/0000-0002-1846-6883",Leaky Integrate-and-Fire Model and Short-Term Synaptic Plasticity Emulated in a Novel Bismuth-Based Diffusive Memristor,10,7,10.1002/aelm.202300865 ,Article ,,"Memristors, being prospective work-horses of future electronics offer various types of memory (volatile and nonvolatile) along with specific computational functionalities. Further development of memristive technologies depends on the availability of suitable materials. These materials should be easily available, stable, and preferably of low toxicity. Commonly used materials are lead halide perovskites, however, they are highly toxic and unstable under ambient conditions. Therefore a novel material is developed on the basis of bismuth iodide. In reaction with butylammonium iodide, it yields a novel compound, butylammonium iodobismuthate (BABI). Here, a diffusive memristor is introduced based on this compound and evaluates its memristive and neuromorphic properties. In contrast to nonvolatile memristors, the BABI memristors exhibit diffusive dynamics, which enable them to store the information only for short periods of time. This property is utilized to mimic the short-term synaptic plasticity described by the leaky integrate-and-fire model of a biological neuron. Combined with high switching uniformity and self-rectifying behavior, these devices show high classification accuracy for MNIST handwritten datasets, paving the way for their application in neuromorphic computing systems.Butylammonium iodobismuthate presents unique volatile memristive properties resulting from diffusive dynamics of iodide vacancies. These materials can be used for the fabrication of synaptic devices with high ON-OFF ratios, and unique temporal characteristics that pave the way for new-generation neuromorphic computing systems. image",2199-160X,,,, ,  ,,out_of_scope,
2720,"**Title**The difference of model robustness assessment using cross-validation and bootstrap methods

**Abstract**The validation principles on Quantitative Structure Activity Relationship issued by Organization for Economic and Co-operation and Development describe three criteria of model assessment: goodness of fit, robustness and prediction. In the case of robustness, two ways are possible as internal validation: bootstrap and cross-validation. We compared these validation metrics by checking their sample size dependence, rank correlations to other metrics and uncertainty. We used modeling methods from multivariate linear regression to artificial neural network on 14 open access datasets. We found that the metrics provide similar sample size dependence and correlation to other validation parameters. The individual uncertainty originating from the calculation recipes of the metrics is much smaller for both ways than the part caused by the selection of the training set or the training/test split. We concluded that the metrics of the two techniques are interchangeable, but the interpretation of cross-validation parameters is easier according to their similar range to goodness-of-fit and prediction metrics. Furthermore, the variance originating from the random elements of the calculation of cross-validation metrics is slightly smaller than those of bootstrap ones, if equal calculation load is applied.The two methods provide close to the same information on robustness, but we suggest to use cross-validation, because: a) Bootstrap values are outliers within the metrics for other validation tasks as goodness-of-fit or predictivity. b) The uncertainty of the robustness calculation is smaller for cross-validation at equal calculation load.image","Lasfar, Rita; Toth, Gergely",,,The difference of model robustness assessment using cross-validation and bootstrap methods,38,6,10.1002/cem.3530 ,Article ,,"The validation principles on Quantitative Structure Activity Relationship issued by Organization for Economic and Co-operation and Development describe three criteria of model assessment: goodness of fit, robustness and prediction. In the case of robustness, two ways are possible as internal validation: bootstrap and cross-validation. We compared these validation metrics by checking their sample size dependence, rank correlations to other metrics and uncertainty. We used modeling methods from multivariate linear regression to artificial neural network on 14 open access datasets. We found that the metrics provide similar sample size dependence and correlation to other validation parameters. The individual uncertainty originating from the calculation recipes of the metrics is much smaller for both ways than the part caused by the selection of the training set or the training/test split. We concluded that the metrics of the two techniques are interchangeable, but the interpretation of cross-validation parameters is easier according to their similar range to goodness-of-fit and prediction metrics. Furthermore, the variance originating from the random elements of the calculation of cross-validation metrics is slightly smaller than those of bootstrap ones, if equal calculation load is applied.The two methods provide close to the same information on robustness, but we suggest to use cross-validation, because: a) Bootstrap values are outliers within the metrics for other validation tasks as goodness-of-fit or predictivity. b) The uncertainty of the robustness calculation is smaller for cross-validation at equal calculation load.image",0886-9383,1099-128X,,, ,  ,,out_of_scope,
2721,"**Title**Generate and Analyze Three-Dimensional Dendritic Spine Morphology Datasets With SpineTool Software

**Abstract**Dendritic spine morphology is associated with the current state of the synapse and neuron, and changes during synaptic plasticity in response to stimulus. At the same time, dendritic spine alterations are reported during various neurodegenerative and neurodevelopmental disorders and other brain states. Accurate and informative analysis of spine shape has an urgent need for studying the synaptic processes and molecular pathways in normal and pathological conditions, and for testing synapto-protective strategies during preclinical studies. Primary neuronal cultures enable high quality imaging of dendritic spines and offer a wide spectrum of accessible experimental manipulations. This article outlines the protocol for isolating, culturing, fluorescent labeling, and imaging of mouse primary hippocampal neurons by three-dimensional (3D) confocal microscopy in a normal state and in conditions of low amyloid toxicity-an in vitro model of Alzheimer's disease. An alternate protocol describes the neuronal morphology analysis using the EGFP expressing neurons in line-M transgenic mouse brain slices. Since the dendritic spines are relatively small structures lying close to the confocal microscope resolution limit, their proper segmentation on the images is challenging. This protocol highlights the image-preprocessing steps, including generation of theoretical point spread function and deconvolution, which enhances resolution and removes noise, thereby enhancing the 3D spine reconstruction results. SpineTool, an open source Python-based script, enables 3D segmentation of dendrites and spines and numerical metric calculation, including key measures, such as spine length, volume, and surface area, with a new feature, the chord length distribution histogram, improving clustering results. SpineTool supports both manual and machine learning spine classification (i.e., mushroom, thin, stubby, filopodia) and automated clustering using k-means and DBSCAN methods. This protocol provides detailed instructions for using SpineTool to analyze and classify dendritic spines in control and experimental groups, enhancing our understanding of spine morphology across different experimental conditions. (c) 2024 Wiley Periodicals LLC.Basic Protocol 1: Obtaining 3D confocal dendritic spine images of hippocampal neuronal culture in normal state and conditions of low amyloid toxicityAlternate Protocol: Obtaining confocal dendritic spine images of mice hippocampal neurons from fixed brain slicesSupport Protocol: Post-processing deconvolution of confocal imagesBasic Protocol 2: Segmentation of dendritic spines with SpineToolBasic Protocol 3: Spine dataset preparation using SpineToolBasic Protocol 4: Clustering of dendritic spines with SpineToolBasic Protocol 5: Machine classification of dendritic spines with SpineTool","Ustinova, Anita; Volkova, Ekaterina; Rakovskaya, Anastasiya; Smirnova, Daria; Korovina, Olesya; Pchitskaya, Ekaterina","Volkova, Ekaterina/MCI-8098-2025; Rakovskaya, Anastasiya/HLW-5359-2023","Ustinova, Anita/0009-0004-5524-3090; Volkova, Ekaterina/0009-0005-5367-963X",Generate and Analyze Three-Dimensional Dendritic Spine Morphology Datasets With SpineTool Software,4,12,10.1002/cpz1.70061 ,Article ,,"Dendritic spine morphology is associated with the current state of the synapse and neuron, and changes during synaptic plasticity in response to stimulus. At the same time, dendritic spine alterations are reported during various neurodegenerative and neurodevelopmental disorders and other brain states. Accurate and informative analysis of spine shape has an urgent need for studying the synaptic processes and molecular pathways in normal and pathological conditions, and for testing synapto-protective strategies during preclinical studies. Primary neuronal cultures enable high quality imaging of dendritic spines and offer a wide spectrum of accessible experimental manipulations. This article outlines the protocol for isolating, culturing, fluorescent labeling, and imaging of mouse primary hippocampal neurons by three-dimensional (3D) confocal microscopy in a normal state and in conditions of low amyloid toxicity-an in vitro model of Alzheimer's disease. An alternate protocol describes the neuronal morphology analysis using the EGFP expressing neurons in line-M transgenic mouse brain slices. Since the dendritic spines are relatively small structures lying close to the confocal microscope resolution limit, their proper segmentation on the images is challenging. This protocol highlights the image-preprocessing steps, including generation of theoretical point spread function and deconvolution, which enhances resolution and removes noise, thereby enhancing the 3D spine reconstruction results. SpineTool, an open source Python-based script, enables 3D segmentation of dendrites and spines and numerical metric calculation, including key measures, such as spine length, volume, and surface area, with a new feature, the chord length distribution histogram, improving clustering results. SpineTool supports both manual and machine learning spine classification (i.e., mushroom, thin, stubby, filopodia) and automated clustering using k-means and DBSCAN methods. This protocol provides detailed instructions for using SpineTool to analyze and classify dendritic spines in control and experimental groups, enhancing our understanding of spine morphology across different experimental conditions. (c) 2024 Wiley Periodicals LLC.Basic Protocol 1: Obtaining 3D confocal dendritic spine images of hippocampal neuronal culture in normal state and conditions of low amyloid toxicityAlternate Protocol: Obtaining confocal dendritic spine images of mice hippocampal neurons from fixed brain slicesSupport Protocol: Post-processing deconvolution of confocal imagesBasic Protocol 2: Segmentation of dendritic spines with SpineToolBasic Protocol 3: Spine dataset preparation using SpineToolBasic Protocol 4: Clustering of dendritic spines with SpineToolBasic Protocol 5: Machine classification of dendritic spines with SpineTool",2691-1299,,,, ,  ,,out_of_scope,
2722,"**Title**Design rules applied to silver nanoparticles synthesis: A practical example of machine learning application.

**Abstract**The synthesis of silver nanoparticles with controlled physicochemical properties is essential for governing their intended functionalities and safety profiles. However, synthesis process involves multiple parameters that could influence the resulting properties. This challenge could be addressed with the development of predictive models that forecast endpoints based on key synthesis parameters. In this study, we manually extracted synthesis -related data from the literature and leveraged various machine learning algorithms. Data extraction included parameters such as reactant concentrations, experimental conditions, as well as physicochemical properties. The antibacterial efficiencies and toxicological profiles of the synthesized nanoparticles were also extracted. In a second step, based on data completeness, we employed regression algorithms to establish relationships between synthesis parameters and desired endpoints and to build predictive models. The models for core size and antibacterial efficiency were trained and validated using a cross -validation approach. Finally, the features' impact was evaluated via Shapley values to provide insights into the contribution of features to the predictions. Factors such as synthesis duration, scale of synthesis and the choice of capping agents emerged as the most significant predictors. This study demonstrated the potential of machine learning to aid in the rational design of synthesis process and paves the way for the safe -by -design principles development by providing insights into the optimization of the synthesis process to achieve the desired properties. Finally, this study provides a valuable dataset compiled from literature sources with significant time and effort from multiple researchers. Access to such datasets notably aids computational advances in the field of nanotechnology.","Furxhi, Irini; Faccani, Lara; Zanoni, Ilaria; Brigliadori, Andrea; Vespignani, Maurizio; Costa, Anna Luisa","Brigliadori, Andrea/KBQ-4714-2024; Costa, Anna/A-8534-2012",,Design rules applied to silver nanoparticles synthesis: A practical example of machine learning application.,25,,10.1016/j.csbj.2024.02.010 ,Article ,,"The synthesis of silver nanoparticles with controlled physicochemical properties is essential for governing their intended functionalities and safety profiles. However, synthesis process involves multiple parameters that could influence the resulting properties. This challenge could be addressed with the development of predictive models that forecast endpoints based on key synthesis parameters. In this study, we manually extracted synthesis -related data from the literature and leveraged various machine learning algorithms. Data extraction included parameters such as reactant concentrations, experimental conditions, as well as physicochemical properties. The antibacterial efficiencies and toxicological profiles of the synthesized nanoparticles were also extracted. In a second step, based on data completeness, we employed regression algorithms to establish relationships between synthesis parameters and desired endpoints and to build predictive models. The models for core size and antibacterial efficiency were trained and validated using a cross -validation approach. Finally, the features' impact was evaluated via Shapley values to provide insights into the contribution of features to the predictions. Factors such as synthesis duration, scale of synthesis and the choice of capping agents emerged as the most significant predictors. This study demonstrated the potential of machine learning to aid in the rational design of synthesis process and paves the way for the safe -by -design principles development by providing insights into the optimization of the synthesis process to achieve the desired properties. Finally, this study provides a valuable dataset compiled from literature sources with significant time and effort from multiple researchers. Access to such datasets notably aids computational advances in the field of nanotechnology.",2001-0370,,,20-33, ,  ,,out_of_scope,
2723,"**Title**Imputation of label-free quantitative mass spectrometry-based proteomics data using self-supervised deep learning

**Abstract**Imputation techniques provide means to replace missing measurements with a value and are used in almost all downstream analysis of mass spectrometry (MS) based proteomics data using label-free quantification (LFQ). Here we demonstrate how collaborative filtering, denoising autoencoders, and variational autoencoders can impute missing values in the context of LFQ at different levels. We applied our method, proteomics imputation modeling mass spectrometry (PIMMS), to an alcohol-related liver disease (ALD) cohort with blood plasma proteomics data available for 358 individuals. Removing 20 percent of the intensities we were able to recover 15 out of 17 significant abundant protein groups using PIMMS-VAE imputations. When analyzing the full dataset we identified 30 additional proteins (+13.2%) that were significantly differentially abundant across disease stages compared to no imputation and found that some of these were predictive of ALD progression in machine learning models. We, therefore, suggest the use of deep learning approaches for imputing missing values in MS-based proteomics on larger datasets and provide workflows for these.Imputation in mass spectrometry-based proteomics is a recurrent step of importance for downstream analysis. Here, the authors offer an extensive comparison workflow of 27 established with three new scalable, fast and performant methods from deep learning for large and high-dimensional data.","Webel, Henry; Niu, Lili; Nielsen, Annelaura Bach; Locard-Paulet, Marie; Mann, Matthias; Jensen, Lars Juhl; Rasmussen, Simon","Rasmussen, Simon/G-6258-2016","Rasmussen, Simon/0000-0001-6323-9041; Niu, Lili/0000-0003-4571-4368; Webel, Henry/0000-0001-8833-7617; Nielsen, Annelaura Bach/0009-0005-2855-208X",Imputation of label-free quantitative mass spectrometry-based proteomics data using self-supervised deep learning,15,1,10.1038/s41467-024-48711-5 ,Article ,,"Imputation techniques provide means to replace missing measurements with a value and are used in almost all downstream analysis of mass spectrometry (MS) based proteomics data using label-free quantification (LFQ). Here we demonstrate how collaborative filtering, denoising autoencoders, and variational autoencoders can impute missing values in the context of LFQ at different levels. We applied our method, proteomics imputation modeling mass spectrometry (PIMMS), to an alcohol-related liver disease (ALD) cohort with blood plasma proteomics data available for 358 individuals. Removing 20 percent of the intensities we were able to recover 15 out of 17 significant abundant protein groups using PIMMS-VAE imputations. When analyzing the full dataset we identified 30 additional proteins (+13.2%) that were significantly differentially abundant across disease stages compared to no imputation and found that some of these were predictive of ALD progression in machine learning models. We, therefore, suggest the use of deep learning approaches for imputing missing values in MS-based proteomics on larger datasets and provide workflows for these.Imputation in mass spectrometry-based proteomics is a recurrent step of importance for downstream analysis. Here, the authors offer an extensive comparison workflow of 27 established with three new scalable, fast and performant methods from deep learning for large and high-dimensional data.",,2041-1723,,, ,  ,,out_of_scope,
2724,"**Title**Predicting photovoltaic efficiency in Cs-based perovskite solar cells: A comprehensive study integrating SCAPS simulation and machine learning models

**Abstract**Conventional perovskite-based solar cells (PSCs) have emerged as promising candidates for next -generation solar energy due to their remarkable features, including a high absorption coefficient, tunable bandgaps, high mobility, low maintenance cost, and high power conversion efficiency (PCE). However, the major bottleneck in commercialization of conventional PSCs is their poor stability (of few days), and toxicity concerns (due to lead content). To address these challenges cesium -based perovskites are widely adopted by researchers. However, detailed understanding of these devices considering several device parameters and their connection with overall PCE is not comprehensively disclosed in previous findings. Therefore, in this study, the PV performance of six (6) different PSCs with Cs -based absorber layer (CAL) viz. CsPbI3, CsPbBr3, CsSnCl3, CsSnI3, Cs2AgBiBr6 and CsSn0.5Ge0.5I3 has been investigated through SCAPS simulator, followed by developing few machine learning models to forecast the efficiency. Total 2160 dataset has been obtained by varying the absorber layer, thickness, and doping and defect density for training and testing the five different machine learning algorithms such as linear regression (LR), support vector regression (SVR), neural network (NN), random forest (RF), and XGBoost (XGB). The XGB algorithm outperforms other approaches, achieving an impressive R2 of 99.99 % and low MSE of 0.0006. Impact of each input variable on the efficiency is also obtained by generating SHAP plot for each model which revealed that absorber layer and it thickness variation greatly affected the PCE and least impact of doping is observed on PCE. Among all the absorbers, CsPbI3 shows promising performance by delivering a maximum PCE of 14.00 %. Results reported in this work along with developed ML models may pave the way in the development of Cs based PSCs without the need of complex device simulations.","Shrivastav, Nikhil; Madan, Jaya; Pandey, Rahul","Shrivastav, Nikhil/KCL-2175-2024; Pandey, Rahul/IAN-2528-2023; Madan, Jaya/L-8687-2019; Madan, Jaya/O-4614-2016","Madan, Jaya/0000-0003-4805-9258; Shrivastav, Nikhil/0000-0001-5787-2393",Predicting photovoltaic efficiency in Cs-based perovskite solar cells: A comprehensive study integrating SCAPS simulation and machine learning models,380,,10.1016/j.ssc.2024.115437 ,Article ,,"Conventional perovskite-based solar cells (PSCs) have emerged as promising candidates for next -generation solar energy due to their remarkable features, including a high absorption coefficient, tunable bandgaps, high mobility, low maintenance cost, and high power conversion efficiency (PCE). However, the major bottleneck in commercialization of conventional PSCs is their poor stability (of few days), and toxicity concerns (due to lead content). To address these challenges cesium -based perovskites are widely adopted by researchers. However, detailed understanding of these devices considering several device parameters and their connection with overall PCE is not comprehensively disclosed in previous findings. Therefore, in this study, the PV performance of six (6) different PSCs with Cs -based absorber layer (CAL) viz. CsPbI3, CsPbBr3, CsSnCl3, CsSnI3, Cs2AgBiBr6 and CsSn0.5Ge0.5I3 has been investigated through SCAPS simulator, followed by developing few machine learning models to forecast the efficiency. Total 2160 dataset has been obtained by varying the absorber layer, thickness, and doping and defect density for training and testing the five different machine learning algorithms such as linear regression (LR), support vector regression (SVR), neural network (NN), random forest (RF), and XGBoost (XGB). The XGB algorithm outperforms other approaches, achieving an impressive R2 of 99.99 % and low MSE of 0.0006. Impact of each input variable on the efficiency is also obtained by generating SHAP plot for each model which revealed that absorber layer and it thickness variation greatly affected the PCE and least impact of doping is observed on PCE. Among all the absorbers, CsPbI3 shows promising performance by delivering a maximum PCE of 14.00 %. Results reported in this work along with developed ML models may pave the way in the development of Cs based PSCs without the need of complex device simulations.",0038-1098,1879-2766,,, ,  ,,out_of_scope,
2725,"**Title**Interactions Between Heavy Metal Exposure and Blood Biochemistry in an Urban Population of the Black Swan (Cygnus atratus) in Australia

**Abstract**There is growing recognition of the threat posed to wildlife by pollutants. Waterbirds are robust bioindicators of ecosystem health, and metal toxicity is a threat to these species in waterways worldwide. Urban waterbirds are likely to be at the highest risk of heavy metal exposure, but this issue has not been widely explored in Australia. Our aim was to estimate contemporary heavy metal exposure in a sedentary urban waterbird population: black swans (Cygnus atratus) inhabiting an inner-city wetland in one of Australia's largest cities, Melbourne. To investigate the physiological implications of legacy heavy metal exposure in these birds, we quantified blood biochemistry profiles and examined their relationships with metal concentrations in feathers. We caught 15 swans in 2021 and took feather samples to measure the concentration of eight heavy metals (chromium (Cr), manganese (Mn), iron (Fe), nickel (Ni), copper (Cu), zinc (Zn), lead (Pb), and mercury (Hg)), and blood samples to measure the concentration of 13 plasma analytes. Multivariate regression analysis revealed few associations between heavy metals and biochemistry markers, and no differences between sexes or age classes. This study presents a baseline dataset of these contaminants and blood biochemical profiles of swans at this wetland that can be used for future monitoring and is an important step toward a better understanding of the threat posed by heavy metals to Australian urban waterbirds.","Nzabanita, Damien; Mulder, Raoul A.; Lettoof, Damian C.; Grist, Stephen; Hampton, Jordan O.; Hufschmid, Jasmin; Nugegoda, Dayanthi","Lettoof, Damian/HCH-5194-2022; Hampton, Jordan/AAV-7736-2020; Nugegoda, Dayanthi/R-9770-2019; Hufschmid, Jasmin/Y-9079-2019","Nugegoda, Dayanthi/0000-0002-6327-4581; Hampton, Jordan/0000-0003-0472-3241; NZABANITA, Dr. Damien/0000-0001-6035-663X; Lettoof, Damian/0000-0002-6309-6914; Grist, Stephen/0000-0003-0694-745X; Hufschmid, Jasmin/0000-0001-9427-7702; Mulder, Raoul/0000-0002-2710-0947",Interactions Between Heavy Metal Exposure and Blood Biochemistry in an Urban Population of the Black Swan (Cygnus atratus) in Australia,86,2,10.1007/s00244-024-01055-z ,Article ,,"There is growing recognition of the threat posed to wildlife by pollutants. Waterbirds are robust bioindicators of ecosystem health, and metal toxicity is a threat to these species in waterways worldwide. Urban waterbirds are likely to be at the highest risk of heavy metal exposure, but this issue has not been widely explored in Australia. Our aim was to estimate contemporary heavy metal exposure in a sedentary urban waterbird population: black swans (Cygnus atratus) inhabiting an inner-city wetland in one of Australia's largest cities, Melbourne. To investigate the physiological implications of legacy heavy metal exposure in these birds, we quantified blood biochemistry profiles and examined their relationships with metal concentrations in feathers. We caught 15 swans in 2021 and took feather samples to measure the concentration of eight heavy metals (chromium (Cr), manganese (Mn), iron (Fe), nickel (Ni), copper (Cu), zinc (Zn), lead (Pb), and mercury (Hg)), and blood samples to measure the concentration of 13 plasma analytes. Multivariate regression analysis revealed few associations between heavy metals and biochemistry markers, and no differences between sexes or age classes. This study presents a baseline dataset of these contaminants and blood biochemical profiles of swans at this wetland that can be used for future monitoring and is an important step toward a better understanding of the threat posed by heavy metals to Australian urban waterbirds.",0090-4341,1432-0703,,178-186, ,  ,,out_of_scope,
2726,"**Title**Stress Monitoring in Free-Living Environments

**Abstract**Stress monitoring is an important area of research with significant implications for individuals' physical and mental health. We present a data-driven approach for stress detection based on convolutional neural networks while addressing the problems of the best sensor channel and the lack of knowledge about stress episodes. Our work is the first to present an analysis of stress-related sensor data collected in real-world conditions from individuals diagnosed with Alcohol Use Disorder (AUD) and undergoing treatment to abstain from alcohol. We developed polynomial-time sensor channel selection algorithms to determine the best sensor modality for a machine learning task. We model the time variation in stress labels expressed by the participants as the subjective effects of stress. We addressed the subjective nature of stress by determining the optimal input length around stress events with an iterative search algorithm. We found the skin conductance modality to be most indicative of stress, and the segment length of 60 seconds around user-reported stress labels resulted in top stress detection performance. We used both majority undersampling and minority oversampling to balance our dataset. With majority undersampling, the binary stress classification model achieved an average accuracy of 99% and an f1-score of 0.99 on the training and test sets after 5-fold cross-validation. With minority oversampling, the performance on the test set dropped to an average accuracy of 76.25% and an f1-score of 0.68, highlighting the challenges of working with real-world datasets.","Sah, Ramesh Kumar; Cleveland, Michael J.; Ghasemzadeh, Hassan","Sah, Ramesh/AAA-5845-2021","Sah, Ramesh/0000-0002-3051-0402; Ghasemzadeh, Hassan/0000-0002-1844-1416",Stress Monitoring in Free-Living Environments,27,12,10.1109/JBHI.2023.3315755 ,Article ,,"Stress monitoring is an important area of research with significant implications for individuals' physical and mental health. We present a data-driven approach for stress detection based on convolutional neural networks while addressing the problems of the best sensor channel and the lack of knowledge about stress episodes. Our work is the first to present an analysis of stress-related sensor data collected in real-world conditions from individuals diagnosed with Alcohol Use Disorder (AUD) and undergoing treatment to abstain from alcohol. We developed polynomial-time sensor channel selection algorithms to determine the best sensor modality for a machine learning task. We model the time variation in stress labels expressed by the participants as the subjective effects of stress. We addressed the subjective nature of stress by determining the optimal input length around stress events with an iterative search algorithm. We found the skin conductance modality to be most indicative of stress, and the segment length of 60 seconds around user-reported stress labels resulted in top stress detection performance. We used both majority undersampling and minority oversampling to balance our dataset. With majority undersampling, the binary stress classification model achieved an average accuracy of 99% and an f1-score of 0.99 on the training and test sets after 5-fold cross-validation. With minority oversampling, the performance on the test set dropped to an average accuracy of 76.25% and an f1-score of 0.68, highlighting the challenges of working with real-world datasets.",2168-2194,2168-2208,,5699-5709, ,  ,,out_of_scope,
2727,"**Title**Feasibility of proton dosimetry overriding planning CT with daily CBCT elaborated through generative artificial intelligence tools

**Abstract**Radiotherapy commonly utilizes cone beam computed tomography (CBCT) for patient positioning and treatment monitoring. CBCT is deemed to be secure for patients, making it suitable for the delivery of fractional doses. However, limitations such as a narrow field of view, beam hardening, scattered radiation artifacts, and variability in pixel intensity hinder the direct use of raw CBCT for dose recalculation during treatment. To address this issue, reliable correction techniques are necessary to remove artifacts and remap pixel intensity into Hounsfield Units (HU) values. This study proposes a deep-learning framework for calibrating CBCT images acquired with narrow field of view (FOV) systems and demonstrates its potential use in proton treatment planning updates. Cycle-consistent generative adversarial networks (cGAN) processes raw CBCT to reduce scatter and remap HU. Monte Carlo simulation is used to generate CBCT scans, enabling the possibility to focus solely on the algorithm's ability to reduce artifacts and cupping effects without considering intra-patient longitudinal variability and producing a fair comparison between planning CT (pCT) and calibrated CBCT dosimetry. To showcase the viability of the approach using real-world data, experiments were also conducted using real CBCT. Tests were performed on a publicly available dataset of 40 patients who received ablative radiation therapy for pancreatic cancer. The simulated CBCT calibration led to a difference in proton dosimetry of less than 2%, compared to the planning CT. The potential toxicity effect on the organs at risk decreased from about 50% (uncalibrated) up the 2% (calibrated). The gamma pass rate at 3%/2 mm produced an improvement of about 37% in replicating the prescribed dose before and after calibration (53.78% vs 90.26%). Real data also confirmed this with slightly inferior performances for the same criteria (65.36% vs 87.20%). These results may confirm that generative artificial intelligence brings the use of narrow FOV CBCT scans incrementally closer to clinical translation in proton therapy planning updates.","Rossi, Matteo; Belotti, Gabriele; Mainardi, Luca; Baroni, Guido; Cerveri, Pietro","Belotti, Gabriele/ABA-7991-2021; MAINARDI, LUCA/CAG-8179-2022; Rossi, Matteo/GNW-5658-2022","Belotti, Gabriele/0000-0003-2630-745X; Rossi, Matteo/0000-0003-2519-0720; Mainardi, Luca/0000-0002-6276-6314",Feasibility of proton dosimetry overriding planning CT with daily CBCT elaborated through generative artificial intelligence tools,29,1,10.1080/24699322.2024.2327981 ,Article ,,"Radiotherapy commonly utilizes cone beam computed tomography (CBCT) for patient positioning and treatment monitoring. CBCT is deemed to be secure for patients, making it suitable for the delivery of fractional doses. However, limitations such as a narrow field of view, beam hardening, scattered radiation artifacts, and variability in pixel intensity hinder the direct use of raw CBCT for dose recalculation during treatment. To address this issue, reliable correction techniques are necessary to remove artifacts and remap pixel intensity into Hounsfield Units (HU) values. This study proposes a deep-learning framework for calibrating CBCT images acquired with narrow field of view (FOV) systems and demonstrates its potential use in proton treatment planning updates. Cycle-consistent generative adversarial networks (cGAN) processes raw CBCT to reduce scatter and remap HU. Monte Carlo simulation is used to generate CBCT scans, enabling the possibility to focus solely on the algorithm's ability to reduce artifacts and cupping effects without considering intra-patient longitudinal variability and producing a fair comparison between planning CT (pCT) and calibrated CBCT dosimetry. To showcase the viability of the approach using real-world data, experiments were also conducted using real CBCT. Tests were performed on a publicly available dataset of 40 patients who received ablative radiation therapy for pancreatic cancer. The simulated CBCT calibration led to a difference in proton dosimetry of less than 2%, compared to the planning CT. The potential toxicity effect on the organs at risk decreased from about 50% (uncalibrated) up the 2% (calibrated). The gamma pass rate at 3%/2 mm produced an improvement of about 37% in replicating the prescribed dose before and after calibration (53.78% vs 90.26%). Real data also confirmed this with slightly inferior performances for the same criteria (65.36% vs 87.20%). These results may confirm that generative artificial intelligence brings the use of narrow FOV CBCT scans incrementally closer to clinical translation in proton therapy planning updates.",,2469-9322,,, ,  ,,out_of_scope,
2728,"**Title**Cluster-based radiomics reveal spatial heterogeneity of bevacizumab response for treatment of radiotherapy-induced cerebral necrosis

**Abstract**Background: Bevacizumab is used in the treatment of radiation necrosis (RN), which is a debilitating toxicity following head and neck radiotherapy. However, there is no biomarker to predict if a patient would respond to bevacizumab. Purpose: We aimed to develop a cluster-based radiomics approach to characterize the spatial heterogeneity of RN and map their responses to bevacizumab. Methods: 118 consecutive nasopharyngeal carcinoma patients diagnosed with RN were enrolled. We divided 152 lesions from the patients into 101 for training, and 51 for validation. We extracted voxel-level radiomics features from each lesion segmented on T1-weighted+contrast and T2 FLAIR sequences of pre- and post-bevacizumab magnetic resonance images, followed by a three-step analysis involving individual- and population-level clustering, before delta-radiomics to derive five radiomics clusters within the lesions. We tested the association of each cluster with response to bevacizumab and developed a clinico-radiomics model using clinical predictors and cluster-specific features. Results: 71 (70.3%) and 34 (66.7%) lesions had responded to bevacizumab in the training and validation datasets, respectively. Two radiomics clusters were spatially mapped to the edema region, and the volume changes were significantly associated with bevacizumab response (OR:11.12 [95% CI: 2.54-73.47], P = 0.004; and 1.63 [1.07-2.78], P = 0.042). The combined clinico-radiomics model based on textural features extracted from the most significant cluster improved the prediction of bevacizumab response, compared with a clinical-only model (AUC:0.755 [0.645-0.865] to 0.852 [0.764-0.940], training; 0.708 [0.554-0.861] to 0.816 [0.699-0.933], validation). Conclusion: Our radiomics approach yielded intralesional resolution, enabling a more refined feature selection for predicting bevacizumab efficacy in the treatment of RN.","Tan, Hong Qi; Cai, Jinhua; Tay, Shi Hui; Sim, Adelene Y. L.; Huang, Luo; Chua, Melvin L. K.; Tang, Yamei","Chua, Melvin/ABG-6045-2020","Tan, Hong Qi/0000-0001-7878-4544; Tang, Yamei/0000-0002-6353-6107",Cluster-based radiomics reveal spatial heterogeneity of bevacizumab response for treatment of radiotherapy-induced cerebral necrosis,23,,10.1016/j.csbj.2023.11.040 ,Article ,,"Background: Bevacizumab is used in the treatment of radiation necrosis (RN), which is a debilitating toxicity following head and neck radiotherapy. However, there is no biomarker to predict if a patient would respond to bevacizumab. Purpose: We aimed to develop a cluster-based radiomics approach to characterize the spatial heterogeneity of RN and map their responses to bevacizumab. Methods: 118 consecutive nasopharyngeal carcinoma patients diagnosed with RN were enrolled. We divided 152 lesions from the patients into 101 for training, and 51 for validation. We extracted voxel-level radiomics features from each lesion segmented on T1-weighted+contrast and T2 FLAIR sequences of pre- and post-bevacizumab magnetic resonance images, followed by a three-step analysis involving individual- and population-level clustering, before delta-radiomics to derive five radiomics clusters within the lesions. We tested the association of each cluster with response to bevacizumab and developed a clinico-radiomics model using clinical predictors and cluster-specific features. Results: 71 (70.3%) and 34 (66.7%) lesions had responded to bevacizumab in the training and validation datasets, respectively. Two radiomics clusters were spatially mapped to the edema region, and the volume changes were significantly associated with bevacizumab response (OR:11.12 [95% CI: 2.54-73.47], P = 0.004; and 1.63 [1.07-2.78], P = 0.042). The combined clinico-radiomics model based on textural features extracted from the most significant cluster improved the prediction of bevacizumab response, compared with a clinical-only model (AUC:0.755 [0.645-0.865] to 0.852 [0.764-0.940], training; 0.708 [0.554-0.861] to 0.816 [0.699-0.933], validation). Conclusion: Our radiomics approach yielded intralesional resolution, enabling a more refined feature selection for predicting bevacizumab efficacy in the treatment of RN.",2001-0370,,,43-51, ,  ,,out_of_scope,
2729,No abstract available,"Upadhaya, T.; McKenzie, E.; Zhang, S. C.; Chetty, I. J.; Atkins, K. M.",,,Application of Radiomic and Dosiomic Analyses to Predict for Pneumonitis in Patients with Locally Advanced Non- Small Cell Lung Cancer on the NRG Oncology RTOG 0617 Dataset,120,2, ,Meeting Abstract ,,,0360-3016,1879-355X,,E73-E73, , 66th International Conference on American-Society-for-Radiation-Oncology (ASTRO)66th International Conference on American-Society-for-Radiation-Oncology (ASTRO) ,,out_of_scope,
2730,"**Title**Multimodality radiomics prediction of radiotherapy-induced the early proctitis and cystitis in rectal cancer patients: a machine learning study

**Abstract**Purpose. This study aims to predict radiotherapy-induced rectal and bladder toxicity using computed tomography (CT) and magnetic resonance imaging (MRI) radiomics features in combination with clinical and dosimetric features in rectal cancer patients. Methods. A total of sixty-three patients with locally advanced rectal cancer who underwent three-dimensional conformal radiation therapy (3D-CRT) were included in this study. Radiomics features were extracted from the rectum and bladder walls in pretreatment CT and MR-T2W-weighted images. Feature selection was performed using various methods, including Least Absolute Shrinkage and Selection Operator (Lasso), Minimum Redundancy Maximum Relevance (MRMR), Chi-square (Chi2), Analysis of Variance (ANOVA), Recursive Feature Elimination (RFE), and SelectPercentile. Predictive modeling was carried out using machine learning algorithms, such as K-nearest neighbor (KNN), Support Vector Machine (SVM), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Naive Bayes (NB), Gradient Boosting (XGB), and Linear Discriminant Analysis (LDA). The impact of the Laplacian of Gaussian (LoG) filter was investigated with sigma values ranging from 0.5 to 2. Model performance was evaluated in terms of the area under the receiver operating characteristic curve (AUC), accuracy, precision, sensitivity, and specificity. Results. A total of 479 radiomics features were extracted, and 59 features were selected. The pre-MRI T2W model exhibited the highest predictive performance with an AUC: 91.0/96.57%, accuracy: 90.38/96.92%, precision: 90.0/97.14%, sensitivity: 93.33/96.50%, and specificity: 88.09/97.14%. These results were achieved with both original image and LoG filter (sigma = 0.5-1.5) based on LDA/DT-RF classifiers for proctitis and cystitis, respectively. Furthermore, for the CT data, AUC: 90.71/96.0%, accuracy: 90.0/96.92%, precision: 88.14/97.14%, sensitivity: 93.0/96.0%, and specificity: 88.09/97.14% were acquired. The highest values were achieved using XGB/DT-XGB classifiers for proctitis and cystitis with LoG filter (sigma = 2)/LoG filter (sigma = 0.5-2), respectively. MRMR/RFE-Chi2 feature selection methods demonstrated the best performance for proctitis and cystitis in the pre-MRI T2W model. MRMR/MRMR-Lasso yielded the highest model performance for CT. Conclusion. Radiomics features extracted from pretreatment CT and MR images can effectively predict radiation-induced proctitis and cystitis. The study found that LDA, DT, RF, and XGB classifiers, combined with MRMR, RFE, Chi2, and Lasso feature selection algorithms, along with the LoG filter, offer strong predictive performance. With the inclusion of a larger training dataset, these models can be valuable tools for personalized radiotherapy decision-making.","Abbaspour, Samira; Barahman, Maedeh; Abdollahi, Hamid; Arabalibeik, Hossein; Hajainfar, Ghasem; Babaei, Mohammadreza; Iraji, Hamed; Barzegartahamtan, Mohammadreza; Ay, Mohammad Reza; Mahdavi, Seied Rabi","Barahman, Maedeh/AAB-7376-2019; Barzegartahamtan, Mohammadreza/AAA-9867-2020","abbaspour, samira/0000-0002-1560-876X; Hajianfar, Ghasem/0000-0001-5359-2407",Multimodality radiomics prediction of radiotherapy-induced the early proctitis and cystitis in rectal cancer patients: a machine learning study,10,1,10.1088/2057-1976/ad0f3e ,Article ,,"Purpose. This study aims to predict radiotherapy-induced rectal and bladder toxicity using computed tomography (CT) and magnetic resonance imaging (MRI) radiomics features in combination with clinical and dosimetric features in rectal cancer patients. Methods. A total of sixty-three patients with locally advanced rectal cancer who underwent three-dimensional conformal radiation therapy (3D-CRT) were included in this study. Radiomics features were extracted from the rectum and bladder walls in pretreatment CT and MR-T2W-weighted images. Feature selection was performed using various methods, including Least Absolute Shrinkage and Selection Operator (Lasso), Minimum Redundancy Maximum Relevance (MRMR), Chi-square (Chi2), Analysis of Variance (ANOVA), Recursive Feature Elimination (RFE), and SelectPercentile. Predictive modeling was carried out using machine learning algorithms, such as K-nearest neighbor (KNN), Support Vector Machine (SVM), Logistic Regression (LR), Decision Tree (DT), Random Forest (RF), Naive Bayes (NB), Gradient Boosting (XGB), and Linear Discriminant Analysis (LDA). The impact of the Laplacian of Gaussian (LoG) filter was investigated with sigma values ranging from 0.5 to 2. Model performance was evaluated in terms of the area under the receiver operating characteristic curve (AUC), accuracy, precision, sensitivity, and specificity. Results. A total of 479 radiomics features were extracted, and 59 features were selected. The pre-MRI T2W model exhibited the highest predictive performance with an AUC: 91.0/96.57%, accuracy: 90.38/96.92%, precision: 90.0/97.14%, sensitivity: 93.33/96.50%, and specificity: 88.09/97.14%. These results were achieved with both original image and LoG filter (sigma = 0.5-1.5) based on LDA/DT-RF classifiers for proctitis and cystitis, respectively. Furthermore, for the CT data, AUC: 90.71/96.0%, accuracy: 90.0/96.92%, precision: 88.14/97.14%, sensitivity: 93.0/96.0%, and specificity: 88.09/97.14% were acquired. The highest values were achieved using XGB/DT-XGB classifiers for proctitis and cystitis with LoG filter (sigma = 2)/LoG filter (sigma = 0.5-2), respectively. MRMR/RFE-Chi2 feature selection methods demonstrated the best performance for proctitis and cystitis in the pre-MRI T2W model. MRMR/MRMR-Lasso yielded the highest model performance for CT. Conclusion. Radiomics features extracted from pretreatment CT and MR images can effectively predict radiation-induced proctitis and cystitis. The study found that LDA, DT, RF, and XGB classifiers, combined with MRMR, RFE, Chi2, and Lasso feature selection algorithms, along with the LoG filter, offer strong predictive performance. With the inclusion of a larger training dataset, these models can be valuable tools for personalized radiotherapy decision-making.",2057-1976,,,, ,  ,,out_of_scope,
2731,"**Title**New QSPR models for predicting critical temperature of binary organic mixtures using linear and nonlinear methods

**Abstract**The critical temperature is an important parameter in the design and selection of binary organic mixtures. Rapid and accurate prediction has been a focus of research. Strong nonlinear relationships exist between molecular characteristics and critical temperature. Developing nonlinear models is an important measure to improve the prediction accuracy. In this paper, 56 different QSPR models are developed to predict the critical temperature using 14 types of mixture descriptors and four modeling methods (MLR, XGBoost, RBFNN and SVM). A dataset containing 2540 data points is adopted. Results show x1d1+x2d2 is the optimum mixture descriptor type, and the accuracy of the nonlinear models is better than that of the linear models. The model combining x1d1+x2d2 and SVM exhibits the best predictive power; the R2ext, RMSEext, and AARD are 0.988, 10.057 K, and 1.27%, respectively. For this model, 78.98% of the data have an absolute deviation of less than 5 K, and the accuracy is better than that of existing QSPR models for critical temperature of mixtures. The application domain analysis shows the model has good performance for novel binary organic mixtures. In addition, compared with the empirical calculation methods for predicting the critical temperature, the results show the developed model has higher reliability.","Pan, Yachao; Yang, Fubin; Zhang, Hongguang; Yan, Yinlian; Ping, Xu; Yu, Mingzhe; Yang, Anren","Ping, Xu/GXG-7317-2022; Yang, Fubin/AAT-7130-2021",,New QSPR models for predicting critical temperature of binary organic mixtures using linear and nonlinear methods,575,,10.1016/j.fluid.2023.113916 ,Article ,,"The critical temperature is an important parameter in the design and selection of binary organic mixtures. Rapid and accurate prediction has been a focus of research. Strong nonlinear relationships exist between molecular characteristics and critical temperature. Developing nonlinear models is an important measure to improve the prediction accuracy. In this paper, 56 different QSPR models are developed to predict the critical temperature using 14 types of mixture descriptors and four modeling methods (MLR, XGBoost, RBFNN and SVM). A dataset containing 2540 data points is adopted. Results show x1d1+x2d2 is the optimum mixture descriptor type, and the accuracy of the nonlinear models is better than that of the linear models. The model combining x1d1+x2d2 and SVM exhibits the best predictive power; the R2ext, RMSEext, and AARD are 0.988, 10.057 K, and 1.27%, respectively. For this model, 78.98% of the data have an absolute deviation of less than 5 K, and the accuracy is better than that of existing QSPR models for critical temperature of mixtures. The application domain analysis shows the model has good performance for novel binary organic mixtures. In addition, compared with the empirical calculation methods for predicting the critical temperature, the results show the developed model has higher reliability.",0378-3812,1879-0224,,, ,  ,,out_of_scope,
2732,"**Title**Situations of work-related diseases and injuries among agriculturists in the upper northeast regions of Thailand.

**Abstract**Background: Agriculturists exposed to health hazards are affected by increased occupational disease. This retrospective study aimed to investigate situations of work-related diseases and injuries among agriculturists in upper northeast Thailand. Methods: The secondary data of international classification of diseases 10 th revision (ICD-10) case reports of occupational disease among farmers, from the database of the Health Data Center (HDC), were used. The registered farmers data was collected as a dataset from the provincial agricultural office and the data of ICD-10 code utilised from the hospital information system (HIS) of healthcare services in Udon Thani and Roi-Et provinces, which was extracted for cases of work-related diseases and injuries of registered agriculturists. The annual morbidity rate of occupational diseases was analysed and presented at a rate per 100,000 farmers. Results: Among farmers in the HDC database, lung disease, which was not reported as occupational disease of the HDC database, was the highest ranking of all diseases, followed by work-related musculoskeletal disorders (WMSDs), noise- and heat-related diseases, and pesticide toxicity, respectively, while the injury rate was as high as that of WMSDs. Those morbidity rates of Roi-Et and Udon Thani provinces were representative of the morbidity ranking of diseases of the nation and had increasing trends from 2014 to 2016. The number of farmers in the HDC database did not consistently reflect the number of registered farmers in the agricultural database. Conclusions: Situations of work-related diseases and injuries discovered among registered farmers reflect the health problems of Thai agriculturists, and the underestimation in the reported disease rate in the health database is explained by big data analysis, which showed that work-related cases with an identifying code of Y96 had rarely been reported among agriculturists. Therefore, Thai agriculturists should be supported in registration with occupational diseases and injuries surveillance as holistic healthcare.","Chaiklieng, Sunisa; Chagkornburee, Chuthamas; Suggaravetsiri, Pornnapa","; Chaiklieng, Sunisa/AAO-9644-2020","Chagkornburee, Chuthamas/0009-0003-7481-9545; Chaiklieng, Sunisa/0000-0003-4190-4930",Situations of work-related diseases and injuries among agriculturists in the upper northeast regions of Thailand.,11,,10.12688/f1000research.73221.2 ,"Journal Article; Research Support, Non-U.S. Gov't ",,"Background: Agriculturists exposed to health hazards are affected by increased occupational disease. This retrospective study aimed to investigate situations of work-related diseases and injuries among agriculturists in upper northeast Thailand. Methods: The secondary data of international classification of diseases 10 th revision (ICD-10) case reports of occupational disease among farmers, from the database of the Health Data Center (HDC), were used. The registered farmers data was collected as a dataset from the provincial agricultural office and the data of ICD-10 code utilised from the hospital information system (HIS) of healthcare services in Udon Thani and Roi-Et provinces, which was extracted for cases of work-related diseases and injuries of registered agriculturists. The annual morbidity rate of occupational diseases was analysed and presented at a rate per 100,000 farmers. Results: Among farmers in the HDC database, lung disease, which was not reported as occupational disease of the HDC database, was the highest ranking of all diseases, followed by work-related musculoskeletal disorders (WMSDs), noise- and heat-related diseases, and pesticide toxicity, respectively, while the injury rate was as high as that of WMSDs. Those morbidity rates of Roi-Et and Udon Thani provinces were representative of the morbidity ranking of diseases of the nation and had increasing trends from 2014 to 2016. The number of farmers in the HDC database did not consistently reflect the number of registered farmers in the agricultural database. Conclusions: Situations of work-related diseases and injuries discovered among registered farmers reflect the health problems of Thai agriculturists, and the underestimation in the reported disease rate in the health database is explained by big data analysis, which showed that work-related cases with an identifying code of Y96 had rarely been reported among agriculturists. Therefore, Thai agriculturists should be supported in registration with occupational diseases and injuries surveillance as holistic healthcare.",,2046-1402,,145-145, ,  ,,out_of_scope,
2733,"**Title**Observational Seismic Fragility Curves for Steel Cylindrical Tanks

**Abstract**The evaluation of seismic vulnerability of atmospheric above ground steel storage tanks is a fundamental topic in the context of industrial safety. Depending on the shell portion affected, on the extent of damage, and on toxicity, flammability, and reactivity of stored substances, liquid leakages can trigger hazardous chains of events whose consequences affect not only the plant but also the surrounding environment. In light of that, the study proposed herein provides an analysis of the seismic fragility of cylindrical above ground storage tanks based on observational damage data. The first phase of this work has consisted in collecting a large empirical dataset of information on failures of atmospheric tanks during past earthquakes. Two sets of damage states have then been used in order to characterize the severity of damage and the intensity of liquid releases. Empirical fragility curves have been fitted by using Bayesian regression. The advantage of this approach is that it is well suited to treat direct and indirect information obtained from field observations and to incorporate subjective engineering judgement. Different models have been employed in order to investigate the effects of tank aspect ratio, filling level, and base anchorage. Moreover, the effects of interaction between these critical aspects are included in fragility analysis. The hazard parameter used is the peak ground acceleration (PGA). Seismic fragility curves obtained from the described procedure are compared to those available in the technical literature.","D'Amico, Marta; Buratti, Nicola","Buratti, Nicola/F-2386-2012",,Observational Seismic Fragility Curves for Steel Cylindrical Tanks,141,1,10.1115/1.4040137 ,Article ,,"The evaluation of seismic vulnerability of atmospheric above ground steel storage tanks is a fundamental topic in the context of industrial safety. Depending on the shell portion affected, on the extent of damage, and on toxicity, flammability, and reactivity of stored substances, liquid leakages can trigger hazardous chains of events whose consequences affect not only the plant but also the surrounding environment. In light of that, the study proposed herein provides an analysis of the seismic fragility of cylindrical above ground storage tanks based on observational damage data. The first phase of this work has consisted in collecting a large empirical dataset of information on failures of atmospheric tanks during past earthquakes. Two sets of damage states have then been used in order to characterize the severity of damage and the intensity of liquid releases. Empirical fragility curves have been fitted by using Bayesian regression. The advantage of this approach is that it is well suited to treat direct and indirect information obtained from field observations and to incorporate subjective engineering judgement. Different models have been employed in order to investigate the effects of tank aspect ratio, filling level, and base anchorage. Moreover, the effects of interaction between these critical aspects are included in fragility analysis. The hazard parameter used is the peak ground acceleration (PGA). Seismic fragility curves obtained from the described procedure are compared to those available in the technical literature.",0094-9930,1528-8978,,, ,  ,,out_of_scope,
2734,"**Title**Application and Optimization of a Fast Non-Local Means Noise Reduction Algorithm in Pediatric Abdominal Virtual Monoenergetic Images

**Abstract**In this study, we applied and optimized a fast non-local means (FNLM) algorithm to reduce noise in pediatric abdominal virtual monoenergetic images (VMIs). To analyze various contrast agent concentrations, we produced contrast agent concentration samples (20, 40, 60, 80, and 100%) and inserted them into a phantom model of a one-year-old pediatric patient. Single-energy computed tomography (SECT) and dual-energy computed tomography (DECT) images were acquired from the phantom, and 40 kilo-electron-volt (keV) VMI was acquired based on the DECT images. For the 40 keV VMI, the smoothing factor of the FNLM algorithm was applied from 0.01 to 1.00 in increments of 0.01. We derived the optimized value of the FNLM algorithm based on quantitative evaluation and performed a comparative assessment with SECT, DECT, and a total variation (TV) algorithm. As a result of the analysis, we found that the average contrast to noise ratio (CNR) and coefficient of variation (COV) of each concentration were most improved at a smoothing factor of 0.02. Based on these results, we derived the optimized smoothing factor value of 0.02. Comparative evaluation shows that the optimized FNLM algorithm improves the CNR and COV results by approximately 3.14 and 2.45 times, respectively, compared with the DECT image, and the normalized noise power spectrum result shows a 10-1 mm2 improvement. The main contribution of this study is to demonstrate the effectiveness of an optimized FNLM algorithm in reducing noise in pediatric abdominal VMI, allowing high-quality images to be acquired while reducing contrast dose. This advancement has significant implications for minimizing the risk of contrast-induced toxicity, especially in pediatric patients. Our approach addresses the problem of limited datasets in pediatric imaging by providing a computationally efficient noise reduction technique and highlights the clinical applicability of the FNLM algorithm. In addition, effective noise reduction enables high-contrast imaging with minimal radiation and contrast exposure, which is expected to be suitable for repeat CT examinations of pediatric liver cancer patients and other abdominal diseases.","Kim, Hajin; Park, Juho; Shim, Jina; Lee, Youngjin",,,Application and Optimization of a Fast Non-Local Means Noise Reduction Algorithm in Pediatric Abdominal Virtual Monoenergetic Images,13,23,10.3390/electronics13234684 ,Article ,,"In this study, we applied and optimized a fast non-local means (FNLM) algorithm to reduce noise in pediatric abdominal virtual monoenergetic images (VMIs). To analyze various contrast agent concentrations, we produced contrast agent concentration samples (20, 40, 60, 80, and 100%) and inserted them into a phantom model of a one-year-old pediatric patient. Single-energy computed tomography (SECT) and dual-energy computed tomography (DECT) images were acquired from the phantom, and 40 kilo-electron-volt (keV) VMI was acquired based on the DECT images. For the 40 keV VMI, the smoothing factor of the FNLM algorithm was applied from 0.01 to 1.00 in increments of 0.01. We derived the optimized value of the FNLM algorithm based on quantitative evaluation and performed a comparative assessment with SECT, DECT, and a total variation (TV) algorithm. As a result of the analysis, we found that the average contrast to noise ratio (CNR) and coefficient of variation (COV) of each concentration were most improved at a smoothing factor of 0.02. Based on these results, we derived the optimized smoothing factor value of 0.02. Comparative evaluation shows that the optimized FNLM algorithm improves the CNR and COV results by approximately 3.14 and 2.45 times, respectively, compared with the DECT image, and the normalized noise power spectrum result shows a 10-1 mm2 improvement. The main contribution of this study is to demonstrate the effectiveness of an optimized FNLM algorithm in reducing noise in pediatric abdominal VMI, allowing high-quality images to be acquired while reducing contrast dose. This advancement has significant implications for minimizing the risk of contrast-induced toxicity, especially in pediatric patients. Our approach addresses the problem of limited datasets in pediatric imaging by providing a computationally efficient noise reduction technique and highlights the clinical applicability of the FNLM algorithm. In addition, effective noise reduction enables high-contrast imaging with minimal radiation and contrast exposure, which is expected to be suitable for repeat CT examinations of pediatric liver cancer patients and other abdominal diseases.",2079-9292,,,, ,  ,,out_of_scope,
2735,"**Title**A New Data Science Model With Supervised Learning and its Application on Pesticide Poisoning Diagnosis in Rural Workers

**Abstract**In a Data Science project, it is essential to determine the relevance of the data and identify patterns that contribute to decision-making based on domain-specific knowledge. Furthermore, a clear definition of methodologies and creation of documentation to guide a project's development from inception to completion are essential elements. This study presents a Data Science model designed to guide the process, covering data collection through training with the aim of facilitating knowledge discovery. Motivated by deficiencies in existing Data Science methodologies, particularly the lack of practical step-by-step guidance on how to prepare data to reach the production phase. Named Data Refinement Cycle with Supervised Machine Learning (DRC-SML), the proposed model was developed based on the emerging needs of a Data Sciense project aimed at assisting healthcare professionals in diagnosing pesticide poisoning among rural workers. The dataset used in this project resulted from scientific research in which 1027 samples were collected, containing data related to toxicity biomarkers and clinical analyses. We achieved an accuracy of 99.61% with only 27 rules for determining the diagnosis. The results optimized healthcare practices and improved quality of life in rural areas. The project outcomes demonstrated the success of the proposed model.","Carvalho, Jaqueline C. S.; Pimenta, Tales C.; Silverio, Alessandra C. P.; Carvalho, Marcos A.; Carvalho, Joao Paulo C. S.","Pimenta, Tales/C-4449-2013; Pimenta, Tales/I-3153-2015","Pimenta, Tales/0000-0002-2791-7332; Pupin Silverio, Alessandra Cristina/0000-0003-2093-2713",A New Data Science Model With Supervised Learning and its Application on Pesticide Poisoning Diagnosis in Rural Workers,12,,10.1109/ACCESS.2024.3375764 ,Article ,,"In a Data Science project, it is essential to determine the relevance of the data and identify patterns that contribute to decision-making based on domain-specific knowledge. Furthermore, a clear definition of methodologies and creation of documentation to guide a project's development from inception to completion are essential elements. This study presents a Data Science model designed to guide the process, covering data collection through training with the aim of facilitating knowledge discovery. Motivated by deficiencies in existing Data Science methodologies, particularly the lack of practical step-by-step guidance on how to prepare data to reach the production phase. Named Data Refinement Cycle with Supervised Machine Learning (DRC-SML), the proposed model was developed based on the emerging needs of a Data Sciense project aimed at assisting healthcare professionals in diagnosing pesticide poisoning among rural workers. The dataset used in this project resulted from scientific research in which 1027 samples were collected, containing data related to toxicity biomarkers and clinical analyses. We achieved an accuracy of 99.61% with only 27 rules for determining the diagnosis. The results optimized healthcare practices and improved quality of life in rural areas. The project outcomes demonstrated the success of the proposed model.",2169-3536,,,40871-40882, ,  ,,out_of_scope,
2736,"**Title**Contact size does not affect high frequency oscillation detection in intracerebral EEG recordings in a rat epilepsy model

**Abstract**Objective: High frequency oscillations (HFOs) have been implicated in ictogenesis and epileptogenesis. The effect of contact size (in the clinical range: 1-10 mm(2)) on HFO detection has not been determined. This study assesses the feasibility of HFO detection in a rat epilepsy model using macrocontacts and clinical amplifiers, and the effect of contact size on HFO detection within the macrocontact range.Methods: Eight epileptic rats were implanted with intracerebral electrodes containing three adjacent contacts of different sizes (0.02, 0.05 and 0.09 mm(2)). HFOs were manually marked on 5 min interictal EEG segments. HFO rates and durations were compared between the different contacts.Results: 10,966 ripples and 1475 fast ripples were identified in the recordings from 30 contacts. There were no significant differences in spike or HFO rates between the different contact sizes, nor was there a significant difference in HFO duration.Conclusions: HFOs can be detected in a rat epilepsy model using macrocontacts. Within the studied range, size did not significantly influence HFO detection.Significance: Using comparative anatomy of rat and human limbic structures, these findings suggest that reducing the size of macrocontacts (compared to those commercially available) would not improve HFO detection rates. (C) 2011 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.","Chatillon, Claude-Edouard; Zelmann, Rina; Bortel, Aleksandra; Avoli, Massimo; Gotman, Jean","Mari, Francesco/AAB-8462-2019","Mari, Francesco/0000-0001-6914-5812; Zelmann, Rina/0000-0002-2142-7324; Zijlmans, Maeike/0000-0003-1258-5678",Contact size does not affect high frequency oscillation detection in intracerebral EEG recordings in a rat epilepsy model,122,9,10.1016/j.clinph.2011.02.022 ,Article ,,"Objective: High frequency oscillations (HFOs) have been implicated in ictogenesis and epileptogenesis. The effect of contact size (in the clinical range: 1-10 mm(2)) on HFO detection has not been determined. This study assesses the feasibility of HFO detection in a rat epilepsy model using macrocontacts and clinical amplifiers, and the effect of contact size on HFO detection within the macrocontact range.Methods: Eight epileptic rats were implanted with intracerebral electrodes containing three adjacent contacts of different sizes (0.02, 0.05 and 0.09 mm(2)). HFOs were manually marked on 5 min interictal EEG segments. HFO rates and durations were compared between the different contacts.Results: 10,966 ripples and 1475 fast ripples were identified in the recordings from 30 contacts. There were no significant differences in spike or HFO rates between the different contact sizes, nor was there a significant difference in HFO duration.Conclusions: HFOs can be detected in a rat epilepsy model using macrocontacts. Within the studied range, size did not significantly influence HFO detection.Significance: Using comparative anatomy of rat and human limbic structures, these findings suggest that reducing the size of macrocontacts (compared to those commercially available) would not improve HFO detection rates. (C) 2011 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.",1388-2457,1872-8952,,1701-1705, ,  ,,out_of_scope,
2737,"**Title**Spatio-Temporal Distribution of Dissolved Inorganic Nitrogen in the Changshan Islands Archipelago Based on a Multiple Weighted Regression Model Considering Spatial Characteristics

**Abstract**Ammonia nitrogen (NH4-N), nitrite nitrogen (NO2-N), and nitrate nitrogen (NO3-N) are important nutrients for maintaining the ecological balance of seawater archipelagos. Obtaining the concentrations of the three nitrogenous compounds simultaneously can allow us to comprehensively analyze nitrogen cycling in archipelago waters, which is beneficial to the ecological protection of both agriculture and fisheries. The existing studies have usually considered a single nitrogen compound or dissolved inorganic nitrogen (DIN), which can only identify the water quality but cannot comprehensively judge the water purification situation or the toxicity of the nitrogen compounds in the water. In the process of constructing an inversion model, only the specific bands of remote sensing imageries used in training/learning are directly related to the actual measured values, ignoring the fact that the specific bands contain information on water quality parameters is different that would affect the fitting accuracy. Furthermore, the existing empirical models and machine learning models have not yet been applied to high-resolution inversion in archipelago waters with active fishing activities. In view of this, we constructed a multiple weighted regression model considering spatial characteristics (S-WSVR) to simultaneously retrieve the distribution of NH4-N, NO2-N, and NO3-N in archipelagic waters. By using the S-WSVR model and considering the complexity of the spatial distribution of the three nitrogen compounds in the mesoscale archipelagic waters, longitude and latitude were added to the experimental dataset as spatial features to fit the nonlinear spatial relationships. Meanwhile, a multivariate weighting module based on the Mahalanobis distance was integrated to calculate the contribution of the characteristic bands and improve the inversion accuracy. The S-WSVR model was applied in the water of Changshan Islands, China, with a retrieval resolution of 30 m, and the r-values of the three nitrogen compounds achieved 0.9063, 0.8900, and 0.9755, respectively. Notably, the sum of the three nitrogen compounds has an r-value of 0.9028 when compared with the measured DIN. In addition, we obtained the Landsat 8 characteristic bands for the three nitrogen compounds and plotted the spatial distributions of the nitrogen compounds in spring and autumn from 2013 to 2022. By analyzing the spatio-temporal variations, it was apparent that the three nitrogen compounds are controlled by human activities and river inputs, and the anoxic discharge of the Yalu River has a strong influence on NO2-N content. Therefore, the accurate estimation in this study can provide scientific support for the protection of sensitive archipelago ecosystems.","Lan, Xinmei; Qi, Jin; Song, Weidong; Zhu, Hongbo; Zhang, Bing; Dai, Jiguang; Ye, Yang; Xue, Guokun","Zhu, Hongbo/IWV-3844-2023","Qi, Jin/0000-0003-4536-2542; Dai, Jiguang/0000-0003-1539-0673",Spatio-Temporal Distribution of Dissolved Inorganic Nitrogen in the Changshan Islands Archipelago Based on a Multiple Weighted Regression Model Considering Spatial Characteristics,15,18,10.3390/w15183176 ,Article ,,"Ammonia nitrogen (NH4-N), nitrite nitrogen (NO2-N), and nitrate nitrogen (NO3-N) are important nutrients for maintaining the ecological balance of seawater archipelagos. Obtaining the concentrations of the three nitrogenous compounds simultaneously can allow us to comprehensively analyze nitrogen cycling in archipelago waters, which is beneficial to the ecological protection of both agriculture and fisheries. The existing studies have usually considered a single nitrogen compound or dissolved inorganic nitrogen (DIN), which can only identify the water quality but cannot comprehensively judge the water purification situation or the toxicity of the nitrogen compounds in the water. In the process of constructing an inversion model, only the specific bands of remote sensing imageries used in training/learning are directly related to the actual measured values, ignoring the fact that the specific bands contain information on water quality parameters is different that would affect the fitting accuracy. Furthermore, the existing empirical models and machine learning models have not yet been applied to high-resolution inversion in archipelago waters with active fishing activities. In view of this, we constructed a multiple weighted regression model considering spatial characteristics (S-WSVR) to simultaneously retrieve the distribution of NH4-N, NO2-N, and NO3-N in archipelagic waters. By using the S-WSVR model and considering the complexity of the spatial distribution of the three nitrogen compounds in the mesoscale archipelagic waters, longitude and latitude were added to the experimental dataset as spatial features to fit the nonlinear spatial relationships. Meanwhile, a multivariate weighting module based on the Mahalanobis distance was integrated to calculate the contribution of the characteristic bands and improve the inversion accuracy. The S-WSVR model was applied in the water of Changshan Islands, China, with a retrieval resolution of 30 m, and the r-values of the three nitrogen compounds achieved 0.9063, 0.8900, and 0.9755, respectively. Notably, the sum of the three nitrogen compounds has an r-value of 0.9028 when compared with the measured DIN. In addition, we obtained the Landsat 8 characteristic bands for the three nitrogen compounds and plotted the spatial distributions of the nitrogen compounds in spring and autumn from 2013 to 2022. By analyzing the spatio-temporal variations, it was apparent that the three nitrogen compounds are controlled by human activities and river inputs, and the anoxic discharge of the Yalu River has a strong influence on NO2-N content. Therefore, the accurate estimation in this study can provide scientific support for the protection of sensitive archipelago ecosystems.",,2073-4441,,, ,  ,,out_of_scope,
2738,"**Title**Comprehensive review of nickel biogeochemistry, bioavailability, and health risks in the environment

**Abstract**Elevated nickel (Ni) content in soils and water cause a potential threat to food safety and human health. Owing to its numerous uses from common domestic items to industrial usage, it is vital to assess its bioavailability and speciation in the natural environment. In this review, the biogeochemical cycling of Ni in the natural environment and numerous aspects like dissolution, reducing-oxidizing condition, pH, precipitation, and biological transformations have been briefly discussed. Moreover, health risks associated with Ni have been assessed based on the datasets (soil samples from diverse countries) collected from the literature, and it exerts various health perils in humans for example punctures of the nasal septum, prolonged rhinitis, and contact dermatitis instigated by the absorption of Ni-metal dust, Ni alloys, and Ni salts on injured skin etc. The carcinogenic and non-carcinogenic risks inferences showed that dermal interaction is the foremost method of revelation, and children are more susceptible than adults. The findings of this study will be significant for scientists, environmentalists, and policymakers in making strategic strategies for environmental protection and strategic human health management to reduce Ni pollution in the natural environment.","Kumar, Amit; Kumar, Vinod; Thakur, Monika; Bakshi, Palak; Koul, Anju; Javaid, Asma; Radziemska, Maja; Pandey, Vimal Chandra","Bakshi, Palak/AAC-8108-2020; Pandey, Vimal/C-1275-2012; Radziemska, Maja/AAW-2607-2020; kumar, Amit/M-3541-2015","kumar, Amit/0000-0002-6073-0860","Comprehensive review of nickel biogeochemistry, bioavailability, and health risks in the environment",34,14,10.1002/ldr.4775 ,Review ,,"Elevated nickel (Ni) content in soils and water cause a potential threat to food safety and human health. Owing to its numerous uses from common domestic items to industrial usage, it is vital to assess its bioavailability and speciation in the natural environment. In this review, the biogeochemical cycling of Ni in the natural environment and numerous aspects like dissolution, reducing-oxidizing condition, pH, precipitation, and biological transformations have been briefly discussed. Moreover, health risks associated with Ni have been assessed based on the datasets (soil samples from diverse countries) collected from the literature, and it exerts various health perils in humans for example punctures of the nasal septum, prolonged rhinitis, and contact dermatitis instigated by the absorption of Ni-metal dust, Ni alloys, and Ni salts on injured skin etc. The carcinogenic and non-carcinogenic risks inferences showed that dermal interaction is the foremost method of revelation, and children are more susceptible than adults. The findings of this study will be significant for scientists, environmentalists, and policymakers in making strategic strategies for environmental protection and strategic human health management to reduce Ni pollution in the natural environment.",1085-3278,1099-145X,,4141-4156, ,  ,,out_of_scope,
2739,"**Title**Prioritized regional management for antibiotics and heavy metals in animal manure across China

**Abstract**High levels of antibiotics and heavy metals in animal manure pose a potential threat to both the ecological environment and public health. A regional knowledge of their distribution and risk assessment across China remains unclear. A dataset containing 4082 records covering a total of forty-two antibiotics and eight heavy metals was established for animal manure across China. The results showed that the residual concentration of antibiotics was in the order of tetracyclines > aminoglycosides > fluoroquinolones > macrolides > sulfonamides > beta-lactams, and that of heavy metals is Zn > Cu > Cr > Pb > Ni > As > Cd > Hg. The mean concentration of antibiotics and heavy metals was higher in pig manure compared to chicken and cow manure (Kruskal-Wallis test). The lowest level of antibiotics was observed in Northwest China based on geographic distribution characteristics. It was related to the high ratio of cow and sheep farming that less antibiotics were administered to. The pollution status of heavy metals was more severe in East China. Furthermore, high correlations were observed between antibiotics (tetracyclines) and heavy metals (Cu, Zn, and As). Especially, tetracycline in North China and Cd in Northeast China exhibited a high risk in manure; thus, they were priority regions for antibiotics/ heavy metals pollution control. This study identified risk assessment of typical antibiotics and heavy metals in animal manure and emphasized the necessity of regional management across China.","Wang, Xuerong; Zhang, Xu; Li, Na; Yang, Zhenzhen; Li, Binxu; Zhang, Xiaoli; Li, Hongna","Zhang, Xiaoli/M-9016-2019; Li, Binxu/KDO-3273-2024; Li, Hongna/AFU-9967-2022; Li, Hongna/L-3269-2018","Li, Hongna/0000-0003-0061-0776",Prioritized regional management for antibiotics and heavy metals in animal manure across China,461,,10.1016/j.jhazmat.2023.132706 ,Article ,,"High levels of antibiotics and heavy metals in animal manure pose a potential threat to both the ecological environment and public health. A regional knowledge of their distribution and risk assessment across China remains unclear. A dataset containing 4082 records covering a total of forty-two antibiotics and eight heavy metals was established for animal manure across China. The results showed that the residual concentration of antibiotics was in the order of tetracyclines > aminoglycosides > fluoroquinolones > macrolides > sulfonamides > beta-lactams, and that of heavy metals is Zn > Cu > Cr > Pb > Ni > As > Cd > Hg. The mean concentration of antibiotics and heavy metals was higher in pig manure compared to chicken and cow manure (Kruskal-Wallis test). The lowest level of antibiotics was observed in Northwest China based on geographic distribution characteristics. It was related to the high ratio of cow and sheep farming that less antibiotics were administered to. The pollution status of heavy metals was more severe in East China. Furthermore, high correlations were observed between antibiotics (tetracyclines) and heavy metals (Cu, Zn, and As). Especially, tetracycline in North China and Cd in Northeast China exhibited a high risk in manure; thus, they were priority regions for antibiotics/ heavy metals pollution control. This study identified risk assessment of typical antibiotics and heavy metals in animal manure and emphasized the necessity of regional management across China.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2740,"**Title**Quantitative identification of the co-exposure effects of e-waste pollutants on human oxidative stress by explainable machine learning

**Abstract**Global electronic waste (e-waste) generation continues to grow. The various pollutants released during precarious e-waste disposal activities can contribute to human oxidative stress. This study encompassed 129 individuals residing near e-waste dismantling sites in China, with elevated urinary concentrations of e-waste-related pollutants including heavy metals, polycyclic aromatic hydrocarbons (PAHs), organophosphorus flame retardants (OPFRs), bisphenols (BPs), and phthalate esters (PAEs). Utilizing an explainable machine learning framework, the study quantified the co-exposure effects of these pollutants, finding that approximately 23% and 18% of the variance in oxidative DNA damage and lipid peroxidation, respectively, was attributable to these substances. Heavy metals emerged as the most critical factor in inducing oxidative stress, followed by PAHs and PAEs for oxidative DNA damage, and BPs, OPFRs, and PAEs for lipid peroxidation. The interactions between different pollutant classes were found to be weak, attributable to their disparate biological pathways. In contrast, the interactions among congeneric pollutants were strong, stemming from their shared pathways and resultant synergistic or additive effects on oxidative stress. An intelligent analysis system for e-waste pollutants was also developed, which enables more efficient processing of large-scale and dynamic datasets in evolving environments. This study offered an enticing peek into the intricacies of co-exposure effect of e-waste pollutants.","Yang, Luhan; Zhang, Tao; Gao, Yanxia; Li, Dairui; Cui, Rui; Gu, Cheng; Wang, Lei; Sun, Hongwen","Yanxia, Gao/IAQ-6177-2023; Dai, Kai/O-5669-2016",,Quantitative identification of the co-exposure effects of e-waste pollutants on human oxidative stress by explainable machine learning,466,,10.1016/j.jhazmat.2024.133560 ,Article ,,"Global electronic waste (e-waste) generation continues to grow. The various pollutants released during precarious e-waste disposal activities can contribute to human oxidative stress. This study encompassed 129 individuals residing near e-waste dismantling sites in China, with elevated urinary concentrations of e-waste-related pollutants including heavy metals, polycyclic aromatic hydrocarbons (PAHs), organophosphorus flame retardants (OPFRs), bisphenols (BPs), and phthalate esters (PAEs). Utilizing an explainable machine learning framework, the study quantified the co-exposure effects of these pollutants, finding that approximately 23% and 18% of the variance in oxidative DNA damage and lipid peroxidation, respectively, was attributable to these substances. Heavy metals emerged as the most critical factor in inducing oxidative stress, followed by PAHs and PAEs for oxidative DNA damage, and BPs, OPFRs, and PAEs for lipid peroxidation. The interactions between different pollutant classes were found to be weak, attributable to their disparate biological pathways. In contrast, the interactions among congeneric pollutants were strong, stemming from their shared pathways and resultant synergistic or additive effects on oxidative stress. An intelligent analysis system for e-waste pollutants was also developed, which enables more efficient processing of large-scale and dynamic datasets in evolving environments. This study offered an enticing peek into the intricacies of co-exposure effect of e-waste pollutants.",0304-3894,1873-3336,,, ,  ,,out_of_scope,
2741,"**Title**Harmful Communication Detection of Toxic Language and Threats on Swedish

**Abstract**Harmful communication, such as toxic language and threats directed toward individuals or groups, is a common problem on most social media platforms and online spaces. While several approaches exist for detecting toxic language and threats in English, few attempts have detected such communication in Swedish. Thus, we used transfer learning and BERT to train two machine learning models: one that detects toxic language and one that detects threats in Swedish. We also examined the intersection between toxicity and threat. The models are trained on data from several different sources, with authentic social media posts and data translated from English. Our models perform well on test data with an F1-score above 0.94 for detecting toxic language and 0.86 for detecting threats. However, the models' performance decreases significantly when they are applied to new unseen social media data. Examining the intersection between toxic language and threats, we found that 20% of the threats on social media are not toxic, which means that they would not be detected using only methods for detecting toxic language. Our finding highlights the difficulties with harmful language and the need to use different methods to detect different kinds of harmful language.","Kaati, Lisa; Moshfegh, Arvin; Linden, Kevin; Shrestha, Amendra; Akrami, Nazar","Akrami, Nazar/O-7169-2019","Moshfegh, Arvin/0000-0002-7584-2355; Akrami, Nazar/0000-0002-9641-6275; Kaati, Lisa/0000-0002-3724-7504",Harmful Communication Detection of Toxic Language and Threats on Swedish,,,10.1145/3625007.3627597 ,Proceedings Paper ,,"Harmful communication, such as toxic language and threats directed toward individuals or groups, is a common problem on most social media platforms and online spaces. While several approaches exist for detecting toxic language and threats in English, few attempts have detected such communication in Swedish. Thus, we used transfer learning and BERT to train two machine learning models: one that detects toxic language and one that detects threats in Swedish. We also examined the intersection between toxicity and threat. The models are trained on data from several different sources, with authentic social media posts and data translated from English. Our models perform well on test data with an F1-score above 0.94 for detecting toxic language and 0.86 for detecting threats. However, the models' performance decreases significantly when they are applied to new unseen social media data. Examining the intersection between toxic language and threats, we found that 20% of the threats on social media are not toxic, which means that they would not be detected using only methods for detecting toxic language. Our finding highlights the difficulties with harmful language and the need to use different methods to detect different kinds of harmful language.",2473-9928,2473-991X,979-8-4007-0409-3,625-631, , 15th IEEE/ACM Annual International Conference on Advances in Social Networks Analysis and Mining (ASONAM)15th IEEE/ACM Annual International Conference on Advances in Social Networks Analysis and Mining (ASONAM) ,,out_but_toxicity,
2742,"**Title**Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models

**Abstract**Toxic content detection is crucial for online services to remove inappropriate content that violates community standards. To automate the detection process, prior works have proposed varieties of machine learning (ML) approaches to train Language Models (LMs) for toxic content detection. However, both their accuracy and transferability across datasets are limited. Recently, Large Language Models (LLMs) have shown promise in toxic content detection due to their superior zero-shot and few-shot in-context learning ability as well as broad transferability on ML tasks. However, efficiently designing prompts for LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder their deployments in production. To address these challenges, in this work, we propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling LLMs for toxic content detection. Specifically, we design a novel prompting method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection performance and extract high-quality rationales. DToT can automatically select more fine-grained context to re-prompt LLMs when their responses lack confidence. Additionally, we use the rationales extracted via DToT to fine-tune student LMs. Our experimental results on various datasets demonstrate that DToT can improve the accuracy of LLMs by up to 4.6%. Furthermore, student LMs fine-tuned with rationales extracted via DToT outperform baselines on all datasets with up to 16.9% accuracy improvement, while being more than 60x smaller than conventional LLMs. Finally, we observe that student LMs fine-tuned with rationales exhibit better cross-dataset transferability.","Zhang, Jiang; Wu, Qiong; Xu, Yiming; Cao, Cheng; Du, Zheng; Psounis, Konstantinos",,,Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models,,, ,Proceedings Paper ,,"Toxic content detection is crucial for online services to remove inappropriate content that violates community standards. To automate the detection process, prior works have proposed varieties of machine learning (ML) approaches to train Language Models (LMs) for toxic content detection. However, both their accuracy and transferability across datasets are limited. Recently, Large Language Models (LLMs) have shown promise in toxic content detection due to their superior zero-shot and few-shot in-context learning ability as well as broad transferability on ML tasks. However, efficiently designing prompts for LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder their deployments in production. To address these challenges, in this work, we propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling LLMs for toxic content detection. Specifically, we design a novel prompting method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection performance and extract high-quality rationales. DToT can automatically select more fine-grained context to re-prompt LLMs when their responses lack confidence. Additionally, we use the rationales extracted via DToT to fine-tune student LMs. Our experimental results on various datasets demonstrate that DToT can improve the accuracy of LLMs by up to 4.6%. Furthermore, student LMs fine-tuned with rationales extracted via DToT outperform baselines on all datasets with up to 16.9% accuracy improvement, while being more than 60x smaller than conventional LLMs. Finally, we observe that student LMs fine-tuned with rationales exhibit better cross-dataset transferability.",2159-5399,2374-3468,*****************,21779-21787, , 38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence38th AAAI Conference on Artificial Intelligence (AAAI) / 36th Conference on Innovative Applications of Artificial Intelligence / 14th Symposium on Educational Advances in Artificial Intelligence ,,detection#methodology,
2743,"**Title**Improving the Detection of Multilingual Online Attacks with Rich Social Media Data from Singapore

**Abstract**Toxic content is a global problem, but most resources for detecting toxic content are in English. When datasets are created in other languages, they often focus exclusively on one language or dialect. In many cultural and geographical settings, however, it is common to code-mix languages, combining and interchanging them throughout conversations. To shine a light on this practice, and enable more research into code-mixed toxic content, we introduce SOA, a new multilingual dataset of online attacks. Using the multilingual city-state of Singapore as a starting point, we collect a large corpus of Reddit comments in Indonesian, Malay, Singlish, and other languages, and provide fine-grained hierarchical labels for online attacks. We publish the corpus with rich metadata, as well as additional unlabelled data for domain adaptation. We share comprehensive baseline results, show how the metadata can be used for granular error analysis, and demonstrate the benefits of domain adaptation for detecting multilingual online attacks.","Haber, Janosch; Vidgen, Bertie; Chapman, Matt; Agarwal, Vibhor; Lee, Roy Ka-Wei; Yap, Yong Keong; Rottger, Paul","Lee, Roy Ka-Wei/LFG-0170-2024","Lee, Roy Ka-Wei/0000-0002-1986-7750",Improving the Detection of Multilingual Online Attacks with Rich Social Media Data from Singapore,,, ,Proceedings Paper ,,"Toxic content is a global problem, but most resources for detecting toxic content are in English. When datasets are created in other languages, they often focus exclusively on one language or dialect. In many cultural and geographical settings, however, it is common to code-mix languages, combining and interchanging them throughout conversations. To shine a light on this practice, and enable more research into code-mixed toxic content, we introduce SOA, a new multilingual dataset of online attacks. Using the multilingual city-state of Singapore as a starting point, we collect a large corpus of Reddit comments in Indonesian, Malay, Singlish, and other languages, and provide fine-grained hierarchical labels for online attacks. We publish the corpus with rich metadata, as well as additional unlabelled data for domain adaptation. We share comprehensive baseline results, show how the metadata can be used for granular error analysis, and demonstrate the benefits of domain adaptation for detecting multilingual online attacks.",,,978-1-959429-72-2,12705-12721, , 61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL) ,,out_but_toxicity,
2744,"**Title**Offensive Language Detection of Arabic Tweets Using Deep Learning Algorithm

**Abstract**Offensive language has become a common occurrence in Arabic social media. Toxic textual content can be prohibited more easily with the use of automatic offensive language identification technologies. In this study, a deep learning approach was used to detect offensive Arabic language. Three models were used: RNN with LSTM, RNN with BLSTM, and the SVM learning algorithm. A dataset of 7000 tweets with two attributes from the Egyptian dialect was used. After data preprocessing, a 6-fold cross-validation was used to train and test the data. The evaluation of the three models showed the suitability of the RNN models (with an accuracy of 95.6%) over the SVM.","AlSukhni, Emad; AlAzzam, Iyad; Hanandeh, Sereen",,,Offensive Language Detection of Arabic Tweets Using Deep Learning Algorithm,,,10.1109/ICICS63486.2024.10638282 ,Proceedings Paper ,,"Offensive language has become a common occurrence in Arabic social media. Toxic textual content can be prohibited more easily with the use of automatic offensive language identification technologies. In this study, a deep learning approach was used to detect offensive Arabic language. Three models were used: RNN with LSTM, RNN with BLSTM, and the SVM learning algorithm. A dataset of 7000 tweets with two attributes from the Egyptian dialect was used. After data preprocessing, a 6-fold cross-validation was used to train and test the data. The evaluation of the three models showed the suitability of the RNN models (with an accuracy of 95.6%) over the SVM.",2471-125X,,979-8-3315-4077-7; 979-8-3315-4076-0,, , 15th International Conference on Information and Communication Systems (ICICS)15th International Conference on Information and Communication Systems (ICICS) ,,out_but_toxicity,
2745,"**Title**Violent Speech Detection in Educational Environments

**Abstract**Nowadays, social networks allow people to interact by exchanging messages, publishing public or private photos or videos. But sometimes they become a space of toxic language to criticise, insult, hate, and attack. In this context, researchers promote a strong intention to study, analyse and detect hate speech. By automating its detection, the spread of anxiety and the rise of hateful content can be limited, especially among children in the online schools. However, with the absence of online database of vulgar English speech by Students in schools, detecting violent speech becomes a difficult task. In this paper, we propose a new dataset-based framework for the detection of students violent speech using natural language processing and learning techniques. This focuses on a proposed Students's Violent Speech (SVS) dataset with 7056 tagged tweets. The dataset is collected and pre-processed to be analyzed to show the performance and accuracy of the proposed model.","Chnini, Manel; Fredj, Nissaf; BenSaid, Fatma; Kacem, Yessine Hadj","kacem, Yessine/C-3434-2014",,Violent Speech Detection in Educational Environments,,,10.1109/AICCSA59173.2023.10479330 ,Proceedings Paper ,,"Nowadays, social networks allow people to interact by exchanging messages, publishing public or private photos or videos. But sometimes they become a space of toxic language to criticise, insult, hate, and attack. In this context, researchers promote a strong intention to study, analyse and detect hate speech. By automating its detection, the spread of anxiety and the rise of hateful content can be limited, especially among children in the online schools. However, with the absence of online database of vulgar English speech by Students in schools, detecting violent speech becomes a difficult task. In this paper, we propose a new dataset-based framework for the detection of students violent speech using natural language processing and learning techniques. This focuses on a proposed Students's Violent Speech (SVS) dataset with 7056 tagged tweets. The dataset is collected and pre-processed to be analyzed to show the performance and accuracy of the proposed model.",2161-5322,,979-8-3503-1943-9,, , 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA)20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA) ,,Gen_dataset,
2746,"**Title**So-haTRed: A Novel Hybrid System for Turkish Hate Speech Detection in Social Media With Ensemble Deep Learning Improved by BERT and Clustered-Graph Networks

**Abstract**Hate speech on online platforms, characterized by discriminatory language targeting individuals or groups, poses significant harm and necessitates robust detection methods for digital safety. Recognizing the ease with which individuals can engage in such speech online, our study delved into detecting Turkish hate speech using deep learning algorithms and natural language processing techniques. We developed innovative methodologies, including a k-means+textGCN classifier with BERT, which marked the first such attempt in the literature, and explored multiple vector representation techniques such as Term Frequency, Word2Vec, Doc2Vec, and GloVe. Additionally, we investigated various learning algorithms and natural language processing techniques, conducting thorough evaluations on three distinct Turkish hate speech datasets. Notably, our newly presented algorithm exhibited superior performance, achieving an impressive F1-score of 87.81% on the 9K dataset, showcasing advancements in hate speech detection and contributing to a safer online environment.","Altinel, Ayse Berna; Baydogmus, Gozde Karatas; Sahin, Sema; Gurbuz, Mustafa Zahid","Gürbüz, M Zahid/GYU-5959-2022; sahin, Sema/KPB-7466-2024; Karatas Baydogmus, Gozde/U-8286-2019","Gurbuz, Mustafa Zahid/0000-0002-5125-6378",So-haTRed: A Novel Hybrid System for Turkish Hate Speech Detection in Social Media With Ensemble Deep Learning Improved by BERT and Clustered-Graph Networks,12,,10.1109/ACCESS.2024.3415350 ,Article ,,"Hate speech on online platforms, characterized by discriminatory language targeting individuals or groups, poses significant harm and necessitates robust detection methods for digital safety. Recognizing the ease with which individuals can engage in such speech online, our study delved into detecting Turkish hate speech using deep learning algorithms and natural language processing techniques. We developed innovative methodologies, including a k-means+textGCN classifier with BERT, which marked the first such attempt in the literature, and explored multiple vector representation techniques such as Term Frequency, Word2Vec, Doc2Vec, and GloVe. Additionally, we investigated various learning algorithms and natural language processing techniques, conducting thorough evaluations on three distinct Turkish hate speech datasets. Notably, our newly presented algorithm exhibited superior performance, achieving an impressive F1-score of 87.81% on the 9K dataset, showcasing advancements in hate speech detection and contributing to a safer online environment.",2169-3536,,,86252-86270, ,  ,,out_but_toxicity,
2747,"**Title**A Generalizable Context-Aware Deep Learning Model for Abusive Language Detection

**Abstract**The proliferation of abusive language and hate speech in online content has become a pressing societal concern, necessitating effective detection methods. Recent years have witnessed a surge in datasets and computational methods for detecting abusive language, reflecting the growing interest in combating online abuse. Deep learning, in particular, has emerged as a powerful tool for addressing this pervasive issue. This paper presents a novel context-aware, attention-based Bidirectional Long Short-Term Memory (Bi-LSTM) model that relies exclusively on textual features. The model is designed for robust detection of abusive language. The proposed model integrates a domain-specific language model, HateBERT, with stacked Bi-LSTM and attention mechanism to enhance the processing capabilities of neural networks, enabling nuanced understanding of abusive language patterns. The versatility of the model is demonstrated through experiments on diverse abuse categories, showcasing its ability to effectively classify various types of abuse. The paper compares the model with existing state-of-the-art approaches and the findings underscore the potential of deep learning-based models in addressing the pervasive issue of online abusive behavior.","Kia, Mahsa Abazari; Samiee, Dorsa; Pournajar, Nasrin",,,A Generalizable Context-Aware Deep Learning Model for Abusive Language Detection,15022,,10.1007/978-3-031-72350-6_4 ,Proceedings Paper ,,"The proliferation of abusive language and hate speech in online content has become a pressing societal concern, necessitating effective detection methods. Recent years have witnessed a surge in datasets and computational methods for detecting abusive language, reflecting the growing interest in combating online abuse. Deep learning, in particular, has emerged as a powerful tool for addressing this pervasive issue. This paper presents a novel context-aware, attention-based Bidirectional Long Short-Term Memory (Bi-LSTM) model that relies exclusively on textual features. The model is designed for robust detection of abusive language. The proposed model integrates a domain-specific language model, HateBERT, with stacked Bi-LSTM and attention mechanism to enhance the processing capabilities of neural networks, enabling nuanced understanding of abusive language patterns. The versatility of the model is demonstrated through experiments on diverse abuse categories, showcasing its ability to effectively classify various types of abuse. The paper compares the model with existing state-of-the-art approaches and the findings underscore the potential of deep learning-based models in addressing the pervasive issue of online abusive behavior.",0302-9743,1611-3349,978-3-031-72349-0; 978-3-031-72350-6,49-63, , 33rd International Conference on Artificial Neural Networks and Machine Learning (ICANN)33rd International Conference on Artificial Neural Networks and Machine Learning (ICANN) ,,detection#methodology,
2748,"**Title**A Review of Deep Learning Techniques for Multimodal Fake News and Harmful Languages Detection

**Abstract**The detection of fake news and harmful languages has become increasingly important in today's digital age. As the prevalence of fake news and harmful languages continue to increase, so also is the correspondent negative impact on individuals and the society. Researchers are exploring new techniques to identify and combat these issues. Deep neural network (DNN) has found a wide range of applications in diverse problem domains including but not limited to fake news and harmful languages detection. Fake news and harmful languages are currently increasing online and the mode of dissemination of these contents is fast changing from the traditional unimodal to multiple data forms including texts, audios, images and videos. Multimedia contents containing fake news and harmful languages pose more complex challenges than unimodal contents. The choice and efficacy of the fusion methods of the multimedia contents is one of the most challenging. Our area of focus is multimodal techniques based on deep learning that combines diverse data forms to improve detection accuracy. In this review, we delve into the current state of research, the evolution of deep learning techniques that have been proposed for multimodal fake news and harmful languages detection and the state-of-the-art (SOTA) multimedia data fusion methods. In all cases, we discuss the prospects, relationships, breakthroughs and challenges.","Festus Ayetiran, Eniafe; Ozgobek, Ozlem","Ayetiran, Eniafe Festus/AAD-4278-2019","Ayetiran, Eniafe Festus/0000-0002-6816-2781; Ozgobek, Ozlem/0000-0003-2612-2009",A Review of Deep Learning Techniques for Multimodal Fake News and Harmful Languages Detection,12,,10.1109/ACCESS.2024.3406258 ,Article ,,"The detection of fake news and harmful languages has become increasingly important in today's digital age. As the prevalence of fake news and harmful languages continue to increase, so also is the correspondent negative impact on individuals and the society. Researchers are exploring new techniques to identify and combat these issues. Deep neural network (DNN) has found a wide range of applications in diverse problem domains including but not limited to fake news and harmful languages detection. Fake news and harmful languages are currently increasing online and the mode of dissemination of these contents is fast changing from the traditional unimodal to multiple data forms including texts, audios, images and videos. Multimedia contents containing fake news and harmful languages pose more complex challenges than unimodal contents. The choice and efficacy of the fusion methods of the multimedia contents is one of the most challenging. Our area of focus is multimodal techniques based on deep learning that combines diverse data forms to improve detection accuracy. In this review, we delve into the current state of research, the evolution of deep learning techniques that have been proposed for multimodal fake news and harmful languages detection and the state-of-the-art (SOTA) multimedia data fusion methods. In all cases, we discuss the prospects, relationships, breakthroughs and challenges.",2169-3536,,,76133-76153, ,  ,,out_but_toxicity,
2749,"**Title**Hacker's Paradise: Analysing music in a cybercrime forum

**Abstract**Underground cybercrime forums have numerous discussion boards where users interact with each other. The majority of the topics revolve around technology, but a substantial number also discuss everyday topics and interests, including music. The aim of this research is to analyse the musical content posted on a large English-language underground forum to understand what types of musical content is shared, if the lyrics glamorise cybercrime, and if those who post musical content also post more about criminal activity. We find little evidence of the glamorisation of cybercrime. However, lyrics often depict a 'gangster' lifestyle, including the promotion of violence. We find that users who post on music boards post significantly less criminal content elsewhere on the forum, however when broken down by crime type they are significantly more likely to post about eWhoring and trading credentials than other forum users. We evaluate the performance of Google's Perspective API in detecting toxic content in music lyrics. We find the toxicity classifier was able to detect toxic speech to an extent, but was not particularly reliable. In exploring this further, we find a bug, in that the classifier only takes the first 501 characters as input, providing a way to evade the detection of toxic content.Content Warning: This research paper contains example forum posts, which contain graphic/explicit language that some readers might find upsetting. Please contact the author if you would prefer to read the article with toxic content removed.","Talas, Anna; Hutchings, Alice","Hutchings, Alice/LJK-4306-2024",,Hacker's Paradise: Analysing music in a cybercrime forum,,,10.1109/ECRIME61234.2023.10485503 ,Proceedings Paper ,,"Underground cybercrime forums have numerous discussion boards where users interact with each other. The majority of the topics revolve around technology, but a substantial number also discuss everyday topics and interests, including music. The aim of this research is to analyse the musical content posted on a large English-language underground forum to understand what types of musical content is shared, if the lyrics glamorise cybercrime, and if those who post musical content also post more about criminal activity. We find little evidence of the glamorisation of cybercrime. However, lyrics often depict a 'gangster' lifestyle, including the promotion of violence. We find that users who post on music boards post significantly less criminal content elsewhere on the forum, however when broken down by crime type they are significantly more likely to post about eWhoring and trading credentials than other forum users. We evaluate the performance of Google's Perspective API in detecting toxic content in music lyrics. We find the toxicity classifier was able to detect toxic speech to an extent, but was not particularly reliable. In exploring this further, we find a bug, in that the classifier only takes the first 501 characters as input, providing a way to evade the detection of toxic content.Content Warning: This research paper contains example forum posts, which contain graphic/explicit language that some readers might find upsetting. Please contact the author if you would prefer to read the article with toxic content removed.",2159-1237,,979-8-3503-6027-1; 979-8-3503-6028-8,, , APWG Symposium on Electronic Crime Research (eCrime)APWG Symposium on Electronic Crime Research (eCrime) ,,out_of_scope,
2750,"**Title**S-NLP at SemEval-2021 Task 5: An Analysis of Dual Networks for Sequence Tagging

**Abstract**The SemEval 2021 task 5: Toxic Spans Detection is a task of identifying considered-toxic spans in text, which provides a valuable, automatic tool for moderating online contents. This paper represents the second-place method for the task, an ensemble of two approaches. While one approach relies on combining different embedding methods to extract diverse semantic and syntactic representations of words in context; the other utilizes extra data with a slightly customized Self-training, a semisupervised learning technique, for sequence tagging problems. Both of our architectures take advantage of a strong language model, which was fine-tuned on a toxic classification task. Although experimental evidence indicates higher effectiveness of the first approach than the second one, combining them leads to our best results of 70.77 F1-score on the test dataset.",Viet Anh Nguyen; Tam Minh Nguyen; Huy Quang Dao; Quang Huu Pham,,,S-NLP at SemEval-2021 Task 5: An Analysis of Dual Networks for Sequence Tagging,,, ,Proceedings Paper ,,"The SemEval 2021 task 5: Toxic Spans Detection is a task of identifying considered-toxic spans in text, which provides a valuable, automatic tool for moderating online contents. This paper represents the second-place method for the task, an ensemble of two approaches. While one approach relies on combining different embedding methods to extract diverse semantic and syntactic representations of words in context; the other utilizes extra data with a slightly customized Self-training, a semisupervised learning technique, for sequence tagging problems. Both of our architectures take advantage of a strong language model, which was fine-tuned on a toxic classification task. Although experimental evidence indicates higher effectiveness of the first approach than the second one, combining them leads to our best results of 70.77 F1-score on the test dataset.",,,978-1-954085-70-1,888-897, , 15th International Workshops on Semantic Evaluation (SemEval)15th International Workshops on Semantic Evaluation (SemEval) ,,detection,
2751,"**Title**Attention-Based Bi-LSTM Network for Abusive Language Detection

**Abstract**Prevention of abusive content in social media platforms has received a lot of attention in recent years. The problem is still a challenge due to the nuances present in the content posted and the tactics of users to pass through the abusive detection algorithms employed by the social media giants. This paper presents a robust deep learning model that takes the advantage of both character and word representations, to address the challenges associated with the text content of a social media post for detecting abusive content. The proposed model uses character CNN to capture morphological information and learns the important features to distinguish abusive content with the help of an Attention-based Bi-LSTM network. In addition, it uses the pooling layer to avoid spatial translations. We confined our model to only the text content of the social media posts due to the limitations of collecting user characteristics for existing datasets and to honour the privacy concerns of users. Our model is dataset agnostic, as revealed by the empirical results on the data sets of multiple social media platforms. It outperformed all previous methods for abusive language detection with text-only features.","Nelatoori, Kiran Babu; Kommanti, Hima Bindu","K, H/JEZ-2854-2023","K, Himabindu/0000-0001-8958-4222; Nelatoori, Kiran Babu/0000-0002-9425-4057",Attention-Based Bi-LSTM Network for Abusive Language Detection,69,11,10.1080/03772063.2022.2034534 ,Article ,,"Prevention of abusive content in social media platforms has received a lot of attention in recent years. The problem is still a challenge due to the nuances present in the content posted and the tactics of users to pass through the abusive detection algorithms employed by the social media giants. This paper presents a robust deep learning model that takes the advantage of both character and word representations, to address the challenges associated with the text content of a social media post for detecting abusive content. The proposed model uses character CNN to capture morphological information and learns the important features to distinguish abusive content with the help of an Attention-based Bi-LSTM network. In addition, it uses the pooling layer to avoid spatial translations. We confined our model to only the text content of the social media posts due to the limitations of collecting user characteristics for existing datasets and to honour the privacy concerns of users. Our model is dataset agnostic, as revealed by the empirical results on the data sets of multiple social media platforms. It outperformed all previous methods for abusive language detection with text-only features.",0377-2063,0974-780X,,7884-7892, ,  ,,detection#methodology,
2752,"**Title**Polarized Opinion Detection Improves the Detection of Toxic Language

**Abstract**Distance from unimodality (DFU) has been found to correlate well with human judgment for the assessment of polarized opinions. However, its un-normalized nature makes it less intuitive and somewhat difficult to exploit in machine learning (e.g., as a supervised signal). In this work a normalized version of this measure, called nDFU, is proposed that leads to better assessment of the degree of polarization. Then, we propose a methodology for K-class text classification, based on nDFU, that exploits polarized texts in the dataset. Such polarized instances are assigned to a separate K+1 class, so that a K+1-class classifier is trained. An empirical analysis on three datasets for abusive language detection, shows that nDFU can be used to model polarized annotations and prevent them from harming the classification performance. Finally, we further exploit nDFU to specify conditions that could explain polarization given a dimension and present text examples that polarized the annotators when the dimension was gender and race. Our code is available at https://github.com/ipavlopoulos/ndfu.","Pavlopoulos, John; Likas, Aristidis","Pavlopoulos, John/MEO-1328-2025",,Polarized Opinion Detection Improves the Detection of Toxic Language,,, ,Proceedings Paper ,,"Distance from unimodality (DFU) has been found to correlate well with human judgment for the assessment of polarized opinions. However, its un-normalized nature makes it less intuitive and somewhat difficult to exploit in machine learning (e.g., as a supervised signal). In this work a normalized version of this measure, called nDFU, is proposed that leads to better assessment of the degree of polarization. Then, we propose a methodology for K-class text classification, based on nDFU, that exploits polarized texts in the dataset. Such polarized instances are assigned to a separate K+1 class, so that a K+1-class classifier is trained. An empirical analysis on three datasets for abusive language detection, shows that nDFU can be used to model polarized annotations and prevent them from harming the classification performance. Finally, we further exploit nDFU to specify conditions that could explain polarization given a dimension and present text examples that polarized the annotators when the dimension was gender and race. Our code is available at https://github.com/ipavlopoulos/ndfu.",,,979-8-89176-088-2,1946-1958, , 18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)18th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL) ,,methodology,
2753,"**Title**KERMIT: Knowledge-EmpoweRed Model In harmful meme deTection

**Abstract**Internet memes, while often humorous in nature, can be used to spread hate speech, toxic content, and disinformation across the digital information ecosystem. As a result, detecting harmful memes has become a crucial task for maintaining online safety and fostering responsible online behavior. Prior research in this field has mainly targeted multimodal internal aspects of memes, specifically the image and text modalities, and has sought to interpret their significance by analyzing intra- and inter -modality signals via sophisticated visual -language models. However, understanding the message of a (harmful) meme entails tacit background knowledge, which is not explicitly expressed in the meme itself, but rather relies on cultural references, shared knowledge, and social context. In this paper, we propose KERMIT (Knowledge-EmpoweRed Model In harmful meme deTection), a novel framework which incorporates and uses external knowledge into the process of identifying harmful memes. Specifically, KERMIT builds the meme's knowledge -enriched information network by integrating internal entities of the meme with relevant external knowledge obtained from ConceptNet. Subsequently, the framework employs a dynamic learning mechanism that leverages memoryaugmented neural networks and attention mechanisms to discern the most informative knowledge for accurate classification of harmful memes. Our experiments on four benchmark datasets demonstrate that KERMIT effectively utilizes external knowledge to improve classification performance compared to several state-ofthe-art baselines. Overall, the findings of this study shed light on the complex nature of Internet memes and highlight the importance of knowledge -informed decision -making for harmful meme detection.","Grasso, Biagio; La Gatta, Valerio; Moscato, Vincenzo; Sperli, Giancarlo","Moscato, Vincenzo/H-2526-2012; La Gatta, Valerio/HLW-2658-2023","La Gatta, Valerio/0000-0002-5941-4684",KERMIT: Knowledge-EmpoweRed Model In harmful meme deTection,106,,10.1016/j.inffus.2024.102269 ,Article ,,"Internet memes, while often humorous in nature, can be used to spread hate speech, toxic content, and disinformation across the digital information ecosystem. As a result, detecting harmful memes has become a crucial task for maintaining online safety and fostering responsible online behavior. Prior research in this field has mainly targeted multimodal internal aspects of memes, specifically the image and text modalities, and has sought to interpret their significance by analyzing intra- and inter -modality signals via sophisticated visual -language models. However, understanding the message of a (harmful) meme entails tacit background knowledge, which is not explicitly expressed in the meme itself, but rather relies on cultural references, shared knowledge, and social context. In this paper, we propose KERMIT (Knowledge-EmpoweRed Model In harmful meme deTection), a novel framework which incorporates and uses external knowledge into the process of identifying harmful memes. Specifically, KERMIT builds the meme's knowledge -enriched information network by integrating internal entities of the meme with relevant external knowledge obtained from ConceptNet. Subsequently, the framework employs a dynamic learning mechanism that leverages memoryaugmented neural networks and attention mechanisms to discern the most informative knowledge for accurate classification of harmful memes. Our experiments on four benchmark datasets demonstrate that KERMIT effectively utilizes external knowledge to improve classification performance compared to several state-ofthe-art baselines. Overall, the findings of this study shed light on the complex nature of Internet memes and highlight the importance of knowledge -informed decision -making for harmful meme detection.",1566-2535,1872-6305,,, ,  ,,out_but_toxicity,
2754,"**Title**Towards safer online communities: Deep learning and explainable AI for hate speech detection and classification

**Abstract**The internet and social media facilitate widespread idea sharing but also contribute to cybercrimes and harmful behaviors, notably the dissemination of abusive and hateful speech, which poses a significant threat to societal cohesion. Hence, prompt and accurate detection of such harmful content is crucial. To address this issue, our study introduces a fully automated end-toend model for hate speech detection and classification using Natural Language Processing and Deep Learning techniques. The proposed architecture comprising embedding, Convolutional, bidirectional Recurrent Neural Network, and bidirectional Long Short Term Memory layers, achieved the highest accuracy of 98.5%. Additionally, we employ explainable AI techniques, such as SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), to gain insights into the performance of the proposed framework. This comprehensive approach meets the pressing demand for swift and precise detection and categorization of harmful online content.","Kibriya, Hareem; Siddiqa, Ayesha; Khan, Wazir Zada; Khan, Muhammad Khurram","KHAN, MUHAMMAD KHURRAM/E-4836-2014; Siddiqa, Ayesha/GXW-1936-2022; Khan, Wazir Zada/G-8580-2015",", Hareem Kibriya/0009-0003-1525-226X; Siddiqa, Ayesha/0000-0003-0780-6376; Khan, Wazir Zada/0000-0003-0819-4236",Towards safer online communities: Deep learning and explainable AI for hate speech detection and classification,116,,10.1016/j.compeleceng.2024.109153 ,Article ,,"The internet and social media facilitate widespread idea sharing but also contribute to cybercrimes and harmful behaviors, notably the dissemination of abusive and hateful speech, which poses a significant threat to societal cohesion. Hence, prompt and accurate detection of such harmful content is crucial. To address this issue, our study introduces a fully automated end-toend model for hate speech detection and classification using Natural Language Processing and Deep Learning techniques. The proposed architecture comprising embedding, Convolutional, bidirectional Recurrent Neural Network, and bidirectional Long Short Term Memory layers, achieved the highest accuracy of 98.5%. Additionally, we employ explainable AI techniques, such as SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), to gain insights into the performance of the proposed framework. This comprehensive approach meets the pressing demand for swift and precise detection and categorization of harmful online content.",0045-7906,1879-0755,,, ,  ,,detection,
2755,"**Title**Inappropriate Text Detection and Rephrasing Using NLP

**Abstract**The impact of offensive language on public and professional discourse highlights the need for efficient mitigating measures. Cutting-edge computational linguistic techniques were used to identify and treat such language in a novel way. A two-pronged mechanism is used when hazardous content is found: offending terminology is either removed or put through Natural Language Pre-processing, producing rephrased information that maintains the original meaning of the text. Additionally, this work uses two freely accessible datasets for text categorization. The technique is unique, because during the rephrasing stage, we consider the incorrect words to get their synonyms, and we choose to fit for replacement in the phrase. Classification best accuracy we have achieved of about 95%. The method is comprehensive and aims to create a setting that encourages courteous and peaceful discussion while maintaining semantic integrity. This research provides a sophisticated approach to fostering meaningful relationships in both public and professional contexts by fully addressing incorrect language.","Jain, Sanyam; Tripathy, B. K.","Tripathy, Bata/AAO-7494-2020",,Inappropriate Text Detection and Rephrasing Using NLP,2030,,10.1007/978-3-031-53731-8_21 ,Proceedings Paper ,,"The impact of offensive language on public and professional discourse highlights the need for efficient mitigating measures. Cutting-edge computational linguistic techniques were used to identify and treat such language in a novel way. A two-pronged mechanism is used when hazardous content is found: offending terminology is either removed or put through Natural Language Pre-processing, producing rephrased information that maintains the original meaning of the text. Additionally, this work uses two freely accessible datasets for text categorization. The technique is unique, because during the rephrasing stage, we consider the incorrect words to get their synonyms, and we choose to fit for replacement in the phrase. Classification best accuracy we have achieved of about 95%. The method is comprehensive and aims to create a setting that encourages courteous and peaceful discussion while maintaining semantic integrity. This research provides a sophisticated approach to fostering meaningful relationships in both public and professional contexts by fully addressing incorrect language.",1865-0929,1865-0937,978-3-031-53730-1; 978-3-031-53731-8,261-273, , 5th International Conference on Soft Computing and its Engineering Applications (IcSoftComp)5th International Conference on Soft Computing and its Engineering Applications (IcSoftComp) ,,detox,
2756,"**Title**LAION-5B: An open large-scale dataset for training next generation image-text models

**Abstract**Groundbreaking language-vision architectures like CLIP and DALL-E proved the utility of training on large amounts of noisy image-text data, without relying on expensive accurate labels used in standard vision unimodal supervised learning. The resulting models showed capabilities of strong text-guided image generation and transfer to downstream tasks, while performing remarkably at zero-shot classification with noteworthy out-of-distribution robustness. Since then, large-scale language-vision models like ALIGN, BASIC, GLIDE, Flamingo and Imagen made further improvements. Studying the training and capabilities of such models requires datasets containing billions of image-text pairs. Until now, no datasets of this size have been made openly available for the broader research community. To address this problem and democratize research on large-scale multi-modal models, we present LAION-5B - a dataset consisting of 5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English language. We show successful replication and fine-tuning of foundational models like CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further experiments enabled with an openly available dataset of this scale. Additionally we provide several nearest neighbor indices, an improved web-interface for dataset exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection. (1)","Schuhmann, Christoph; Beaumont, Romain; Vencu, Richard; Gordon, Cade; Wightman, Ross; Cherti, Mehdi; Coombes, Theo; Katta, Aarush; Mullis, Clayton; Wortsman, Mitchell; Schramowski, Patrick; Kundurthy, Srivatsa; Crowson, Katherine; Schmidt, Ludwig; Kaczmarczyk, Robert; Jitsev, Jenia",,,LAION-5B: An open large-scale dataset for training next generation image-text models,,, ,Proceedings Paper ,,"Groundbreaking language-vision architectures like CLIP and DALL-E proved the utility of training on large amounts of noisy image-text data, without relying on expensive accurate labels used in standard vision unimodal supervised learning. The resulting models showed capabilities of strong text-guided image generation and transfer to downstream tasks, while performing remarkably at zero-shot classification with noteworthy out-of-distribution robustness. Since then, large-scale language-vision models like ALIGN, BASIC, GLIDE, Flamingo and Imagen made further improvements. Studying the training and capabilities of such models requires datasets containing billions of image-text pairs. Until now, no datasets of this size have been made openly available for the broader research community. To address this problem and democratize research on large-scale multi-modal models, we present LAION-5B - a dataset consisting of 5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English language. We show successful replication and fine-tuning of foundational models like CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further experiments enabled with an openly available dataset of this scale. Additionally we provide several nearest neighbor indices, an improved web-interface for dataset exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection. (1)",1049-5258,,978-1-7138-7108-8,, , 36th Conference on Neural Information Processing Systems (NeurIPS)36th Conference on Neural Information Processing Systems (NeurIPS) ,,out_but_toxicity,
2757,"**Title**NewsCom-TOX: a corpus of comments on news articles annotated for toxicity in Spanish

**Abstract**In this article, we present the NewsCom-TOX corpus, a new corpus manually annotated for toxicity in Spanish. NewsCom-TOX consists of 4359 comments in Spanish posted in response to 21 news articles on social media related to immigration, in order to analyse and identify messages with racial and xenophobic content. This corpus is multi-level annotated with different binary linguistic categories -stance, target, stereotype, sarcasm, mockery, insult, improper language, aggressiveness and intolerance- taking into account not only the information conveyed in each comment, but also the whole discourse thread in which the comment occurs, as well as the information conveyed in the news article, including their images. These categories allow us to identify the presence of toxicity and its intensity, that is, the level of toxicity of each comment. All this information is available for research purposes upon request. Here we describe the NewsCom-TOX corpus, the annotation tagset used, the criteria applied and the annotation process carried out, including the inter-annotator agreement tests conducted. A quantitative analysis of the results obtained is also provided. NewsCom-TOX is a linguistic resource that will be valuable for both linguistic and computational research in Spanish in NLP tasks for the detection of toxic information.","Taule, Mariona; Nofre, Montserrat; Bargiela, Victor; Bonet, Xavier","Bargiela Zotes, Víctor/JJF-9985-2023; Nofre, Montserrat/ABD-6945-2020; Taule, Mariona/G-9732-2015","Taule, Mariona/0000-0003-0089-940X; Bargiela, Victor/0000-0001-6542-5104",NewsCom-TOX: a corpus of comments on news articles annotated for toxicity in Spanish,58,4,10.1007/s10579-023-09711-x ,Article ,,"In this article, we present the NewsCom-TOX corpus, a new corpus manually annotated for toxicity in Spanish. NewsCom-TOX consists of 4359 comments in Spanish posted in response to 21 news articles on social media related to immigration, in order to analyse and identify messages with racial and xenophobic content. This corpus is multi-level annotated with different binary linguistic categories -stance, target, stereotype, sarcasm, mockery, insult, improper language, aggressiveness and intolerance- taking into account not only the information conveyed in each comment, but also the whole discourse thread in which the comment occurs, as well as the information conveyed in the news article, including their images. These categories allow us to identify the presence of toxicity and its intensity, that is, the level of toxicity of each comment. All this information is available for research purposes upon request. Here we describe the NewsCom-TOX corpus, the annotation tagset used, the criteria applied and the annotation process carried out, including the inter-annotator agreement tests conducted. A quantitative analysis of the results obtained is also provided. NewsCom-TOX is a linguistic resource that will be valuable for both linguistic and computational research in Spanish in NLP tasks for the detection of toxic information.",1574-020X,1574-0218,,1115-1155, ,  ,,out_but_toxicity,
2758,"**Title**Automated Detection of Offensive Images and Sarcastic Memes in Social Media Through NLP

**Abstract**In this digital era, social media is one of the key platforms for collecting customer feedback and reflecting their views on various aspects, including products, services, brands, events, and other topics of interest. However, there is a rise of sarcastic memes on social media, which often convey contrary meaning to the implied sentiments and challenge traditional machine learning identification techniques. The memes, blending text and visuals on social media, are difficult to discern solely from the captions or images, as their humor often relies on subtle contextual cues requiring a nuanced understanding for accurate interpretation. Our study introduces Offensive Images and Sarcastic Memes Detection to address this problem. Our model employs various techniques to identify sarcastic memes and offensive images. The model uses Optical Character Recognition (OCR) and bidirectional long-short term memory (Bi-LSTM) for sarcastic meme detection. For offensive image detection, the model employs Autoencoder LSTM, deep learning models such as Densenet and mobilenet, and computer vision techniques like Feature Fusion Process (FFP) based on Transfer Learning (TL) with Image Augmentation. The study showcases the effectiveness of the proposed methods in achieving high accuracy in detecting offensive content across different modalities, such as text, memes, and images. Based on tests conducted on real-world datasets, our model has demonstrated an accuracy rate of 92% on the Hateful Memes Challenge dataset. The proposed methodology has also achieved a Testing Accuracy (TA) of 95.7% for Densenet with transfer learning on the NPDI dataset and 95.12% on the Pornography dataset. Moreover, implementing Transfer Learning with a Feature Fusion Process (FFP) has resulted in a TA of 99.45% for the NPDI dataset and 98.5% for the Pornography dataset.","Purnima, Tummala; Rao, Ch Koteswara","CH, Koteswararao/ABE-1822-2021; Tummala, Purnima/LXV-2271-2024",,Automated Detection of Offensive Images and Sarcastic Memes in Social Media Through NLP,15,7, ,Article ,,"In this digital era, social media is one of the key platforms for collecting customer feedback and reflecting their views on various aspects, including products, services, brands, events, and other topics of interest. However, there is a rise of sarcastic memes on social media, which often convey contrary meaning to the implied sentiments and challenge traditional machine learning identification techniques. The memes, blending text and visuals on social media, are difficult to discern solely from the captions or images, as their humor often relies on subtle contextual cues requiring a nuanced understanding for accurate interpretation. Our study introduces Offensive Images and Sarcastic Memes Detection to address this problem. Our model employs various techniques to identify sarcastic memes and offensive images. The model uses Optical Character Recognition (OCR) and bidirectional long-short term memory (Bi-LSTM) for sarcastic meme detection. For offensive image detection, the model employs Autoencoder LSTM, deep learning models such as Densenet and mobilenet, and computer vision techniques like Feature Fusion Process (FFP) based on Transfer Learning (TL) with Image Augmentation. The study showcases the effectiveness of the proposed methods in achieving high accuracy in detecting offensive content across different modalities, such as text, memes, and images. Based on tests conducted on real-world datasets, our model has demonstrated an accuracy rate of 92% on the Hateful Memes Challenge dataset. The proposed methodology has also achieved a Testing Accuracy (TA) of 95.7% for Densenet with transfer learning on the NPDI dataset and 95.12% on the Pornography dataset. Moreover, implementing Transfer Learning with a Feature Fusion Process (FFP) has resulted in a TA of 99.45% for the NPDI dataset and 98.5% for the Pornography dataset.",2158-107X,2156-5570,,1415-1425, ,  ,,out_but_toxicity,
2759,"**Title**Expert-Annotated Dataset to Study Cyberbullying in Polish Language

**Abstract**We introduce the first dataset of harmful and offensive language collected from the Polish Internet. This dataset was meticulously curated to facilitate the exploration of harmful online phenomena such as cyberbullying and hate speech, which have exhibited a significant surge both within the Polish Internet as well as globally. The dataset was systematically collected and then annotated using two approaches. First, it was annotated by two proficient layperson volunteers, operating under the guidance of a specialist in the language of cyberbullying and hate speech. To enhance the precision of the annotations, a secondary round of annotations was carried out by a team of adept annotators with specialized long-term expertise in cyberbullying and hate speech annotations. This second phase was further overseen by an experienced annotator, acting as a super-annotator. In its initial application, the dataset was leveraged for the categorization of cyberbullying instances in the Polish language. Specifically, the dataset serves as the foundation for two distinct tasks: (1) a binary classification that segregates harmful and non-harmful messages and (2) a multi-class classification that distinguishes between two variations of harmful content (cyberbullying and hate speech), as well as a non-harmful category. Alongside the dataset itself, we also provide the models that showed satisfying classification performance. These models are made accessible for third-party use in constructing cyberbullying prevention systems.","Ptaszynski, Michal; Pieciukiewicz, Agata; Dybala, Pawel; Skrzek, Pawel; Soliwoda, Kamil; Fortuna, Marcin; Leliwa, Gniewosz; Wroczynski, Michal",,"Ptaszynski, Michal/0000-0002-1910-9183",Expert-Annotated Dataset to Study Cyberbullying in Polish Language,9,1,10.3390/data9010001 ,Article; Data Paper ,,"We introduce the first dataset of harmful and offensive language collected from the Polish Internet. This dataset was meticulously curated to facilitate the exploration of harmful online phenomena such as cyberbullying and hate speech, which have exhibited a significant surge both within the Polish Internet as well as globally. The dataset was systematically collected and then annotated using two approaches. First, it was annotated by two proficient layperson volunteers, operating under the guidance of a specialist in the language of cyberbullying and hate speech. To enhance the precision of the annotations, a secondary round of annotations was carried out by a team of adept annotators with specialized long-term expertise in cyberbullying and hate speech annotations. This second phase was further overseen by an experienced annotator, acting as a super-annotator. In its initial application, the dataset was leveraged for the categorization of cyberbullying instances in the Polish language. Specifically, the dataset serves as the foundation for two distinct tasks: (1) a binary classification that segregates harmful and non-harmful messages and (2) a multi-class classification that distinguishes between two variations of harmful content (cyberbullying and hate speech), as well as a non-harmful category. Alongside the dataset itself, we also provide the models that showed satisfying classification performance. These models are made accessible for third-party use in constructing cyberbullying prevention systems.",,2306-5729,,, ,  ,,out_but_toxicity,
2760,"**Title**Robustness of models addressing Information Disorder: A comprehensive review and benchmarking study

**Abstract**Machine learning and deep learning models are increasingly susceptible to adversarial attacks, particularly in critical areas like cybersecurity and Information Disorder. This study provides a comprehensive evaluation of model Robustness against such attacks across key tasks well -assessed in Information Disorder literature: Toxic Speech Detection, Sentiment Analysis, Propaganda Detection, and Hate Speech Detection. Rigorous experiments conducted across 13 models and 12 diverse datasets highlight significant vulnerabilities. The methodological framework implements adversarial attacks that strategically manipulates model inputs based on keyword significance, identified using the LIME method, an advanced explainable AI technique. The evaluation measures Robustness primarily through accuracy of the models and attack success rates. The experiments reveal that current models display inconsistent resistance to adversarial manipulations, underscoring an urgent need for developing more sophisticated defensive strategies. The study sheds light on the critical weaknesses in existing models and charts a course for future research to fortify AI resilience against evolving cyber threats. The findings advocate for a paradigm shift in model training and development to prioritize adversarial Robustness, ensuring that AI systems are equipped to handle real -world adversarial scenarios effectively.","Fenza, Giuseppe; Loia, Vincenzo; Stanzione, Claudio; Di Gisi, Maria",,"Di Gisi, Maria/0009-0003-5434-5426; FENZA, GIUSEPPE/0000-0002-4736-0113; stanzione, claudio/0000-0003-0158-3132",Robustness of models addressing Information Disorder: A comprehensive review and benchmarking study,596,,10.1016/j.neucom.2024.127951 ,Article ,,"Machine learning and deep learning models are increasingly susceptible to adversarial attacks, particularly in critical areas like cybersecurity and Information Disorder. This study provides a comprehensive evaluation of model Robustness against such attacks across key tasks well -assessed in Information Disorder literature: Toxic Speech Detection, Sentiment Analysis, Propaganda Detection, and Hate Speech Detection. Rigorous experiments conducted across 13 models and 12 diverse datasets highlight significant vulnerabilities. The methodological framework implements adversarial attacks that strategically manipulates model inputs based on keyword significance, identified using the LIME method, an advanced explainable AI technique. The evaluation measures Robustness primarily through accuracy of the models and attack success rates. The experiments reveal that current models display inconsistent resistance to adversarial manipulations, underscoring an urgent need for developing more sophisticated defensive strategies. The study sheds light on the critical weaknesses in existing models and charts a course for future research to fortify AI resilience against evolving cyber threats. The findings advocate for a paradigm shift in model training and development to prioritize adversarial Robustness, ensuring that AI systems are equipped to handle real -world adversarial scenarios effectively.",0925-2312,1872-8286,,, ,  ,,survey,
2761,"**Title**Framework for Detecting Toxic Speech Using BERT and Deep Learning

**Abstract**We have witnessed a big surge in the use of online social media platforms in the past few years with the widespread availability of mobile phones and cheaper data rates. This has also led to an increase in misuse of these platforms to spread hatred in the society. The stats show that most of the cyberbullying happens on social media platforms like Facebook, WhatsApp, etc. The Hatred speech was used for spreading hatred against specific persons, communities, etc. It is necessary to check for the hate speech on social media platforms before it can lead to damaging the peace situation. Automating the task of hate speech detection is a very important step in mitigating this issue as such contents can be quickly acted upon before it spreads hatred. In this paper, we are proposing an Automated Hate speech identification system. The datasets are obtained from HASOC which stands for Hate Speech and Offensive Content Identification in Indo-European Languages, for sub-task b to classify into one of the four categories, Hate, Profane, Offensive, or None for English and Hindi languages. The experiments are carried out to compare the performance of Bert-based architecture with conventional deep learning architectures including CNN (Convolution Neural Network) architecture for English subtask and for Hindi Subtask we fine-tuned the Bert model which gave better results than conventional solutions. We obtained 75.41% accuracy with BERT-based fine tuning better than baseline methods LSTM (Long Short-Term Memory) with 41% accuracy for Hindi dataset and for English dataset, we achieved an accuracy of 82.92% compared to 81.57% with baseline models.","Barai, Ankit; Jain, Pooja; Kumar, Tapan",,,Framework for Detecting Toxic Speech Using BERT and Deep Learning,1455,,10.1007/978-981-97-1549-7_1 ,Proceedings Paper ,,"We have witnessed a big surge in the use of online social media platforms in the past few years with the widespread availability of mobile phones and cheaper data rates. This has also led to an increase in misuse of these platforms to spread hatred in the society. The stats show that most of the cyberbullying happens on social media platforms like Facebook, WhatsApp, etc. The Hatred speech was used for spreading hatred against specific persons, communities, etc. It is necessary to check for the hate speech on social media platforms before it can lead to damaging the peace situation. Automating the task of hate speech detection is a very important step in mitigating this issue as such contents can be quickly acted upon before it spreads hatred. In this paper, we are proposing an Automated Hate speech identification system. The datasets are obtained from HASOC which stands for Hate Speech and Offensive Content Identification in Indo-European Languages, for sub-task b to classify into one of the four categories, Hate, Profane, Offensive, or None for English and Hindi languages. The experiments are carried out to compare the performance of Bert-based architecture with conventional deep learning architectures including CNN (Convolution Neural Network) architecture for English subtask and for Hindi Subtask we fine-tuned the Bert model which gave better results than conventional solutions. We obtained 75.41% accuracy with BERT-based fine tuning better than baseline methods LSTM (Long Short-Term Memory) with 41% accuracy for Hindi dataset and for English dataset, we achieved an accuracy of 82.92% compared to 81.57% with baseline models.",2194-5357,2194-5365,978-981-97-1548-0; 978-981-97-1549-7,3-17, , 27th International Symposium on Frontiers of Research in Speech and Music (FRSM)27th International Symposium on Frontiers of Research in Speech and Music (FRSM) ,,out_but_toxicity,
2762,"**Title**Uniting Politics and Pandemic: a Social Network Analysis on the COVID Parliamentary Commission of Inquiry in Brazil

**Abstract**Installed in April 2021, the COVID-19 Parliamentary Commission of Inquiry (PCI) aimed to investigate omissions and irregularities committed by the federal government during the COVID pandemic in Brazil, which resulted in the death of more than 660,000 Brazilians and placed it among the countries with the most deaths caused by COVID-19. The investigated government was elected in 2018, in one of the most polarized elections in Brazilian history, and social media played a prominent role in this polarization. Not far from that, the PCI also generated a great popular commotion on social media networks. This paper aims to analyze the public debate related to the PCI of COVID on Twitter, identifying groups, examining their characteristics and interactions, and verifying evidence of political polarization in this social network. For this, we collected 3,397,933 tweets over a period of 26 weeks, and analyzed four distinct networks, based on different types of users interactions, to identify the main actors and verify the presence of segregated groups. In addition, we use natural language preprocessing to detect group characteristics and toxic speech. As a result, we identified three users groups, based on their use of hashtags and using a community detection technique. The group against the PCI is made up of conservatives and supporters of the government targeted by the investigations and presents the highest internal homogeneity. The other two groups, moderated users and opposed to the government, are formed by actors from the most varied political spectrum, containing users from the political left, center, and right, in addition to the main media outlets in the country. Moreover, other evidences of political polarization were found even in less segregated networks, where users from different groups interact with each other, but with the presence of toxic speech.","Juvino Santos, Lucas Raniere; Marinho, Leandro Balby; Calazans Campelo, Claudio Elizio","Campelo, Claudio/AES-0082-2022","Balby Marinho, Leandro/0000-0001-7599-372X; Campelo, Claudio/0000-0003-4404-2344; Juvino Santos, Lucas Raniere/0000-0003-1072-5067",Uniting Politics and Pandemic: a Social Network Analysis on the COVID Parliamentary Commission of Inquiry in Brazil,,,10.1145/3539637.3556992 ,Proceedings Paper ,,"Installed in April 2021, the COVID-19 Parliamentary Commission of Inquiry (PCI) aimed to investigate omissions and irregularities committed by the federal government during the COVID pandemic in Brazil, which resulted in the death of more than 660,000 Brazilians and placed it among the countries with the most deaths caused by COVID-19. The investigated government was elected in 2018, in one of the most polarized elections in Brazilian history, and social media played a prominent role in this polarization. Not far from that, the PCI also generated a great popular commotion on social media networks. This paper aims to analyze the public debate related to the PCI of COVID on Twitter, identifying groups, examining their characteristics and interactions, and verifying evidence of political polarization in this social network. For this, we collected 3,397,933 tweets over a period of 26 weeks, and analyzed four distinct networks, based on different types of users interactions, to identify the main actors and verify the presence of segregated groups. In addition, we use natural language preprocessing to detect group characteristics and toxic speech. As a result, we identified three users groups, based on their use of hashtags and using a community detection technique. The group against the PCI is made up of conservatives and supporters of the government targeted by the investigations and presents the highest internal homogeneity. The other two groups, moderated users and opposed to the government, are formed by actors from the most varied political spectrum, containing users from the political left, center, and right, in addition to the main media outlets in the country. Moreover, other evidences of political polarization were found even in less segregated networks, where users from different groups interact with each other, but with the presence of toxic speech.",,,978-1-4503-9409-3,99-107, , 28th Brazilian Symposium on Multimedia and the Web (WebMedia)28th Brazilian Symposium on Multimedia and the Web (WebMedia) ,,out_but_toxicity,
2763,"**Title**Beyond Binary Classification: A Fine-Grained Safety Dataset for Large Language Models

**Abstract**Large Language Models (LLMs) excel in interactive chat scenarios due to their advanced conversational abilities. However, their training process invariably exposes them to a diverse range of harmful or toxic content, posing significant challenges in ensuring that LLM responses align with human ethical values. Consequently, the detection and quantification of adverse content remains a paramount issue in contemporary research. In this paper, we introduce the SAFE dataset, a novel resource designed to advance safety assessment research in LLMs. Our dataset extends beyond the binary categorization of content into safe and unsafe. Drawing upon human interpretations of safety, we further delineate unsafe content into six granular categories: Sensitivity, Harmfulness, Falsehood, Information Corruption, Unnaturalness, and Deviation from Instructions. This refined classification aims to enhance LLMs' ability to discern unsafe data more accurately. In total, we have created a dataset comprising 52,340 instruction-response pairs, each annotated with safety meta-tags. Additionally, we have compiled expert comparative assessments for these indicators. We developed a multi-expert rating model trained on the SAFE dataset, designed to evaluate the responses of LLMs across various dimensions. This approach highlights the potential of our dataset in the realm of safety assessment for LLMs. The model's capability to provide multi-faceted evaluations reflects an advanced understanding of the nuanced requirements in LLM response assessment. We believe this dataset represents a valuable resource for the community, contributing to the safe development and deployment of LLMs. Our findings and resources are poised to fuel future research endeavors in this domain.","Yu, Jia; Li, Long; Lan, Zhenzhong",,,Beyond Binary Classification: A Fine-Grained Safety Dataset for Large Language Models,12,,10.1109/ACCESS.2024.3393245 ,Article ,,"Large Language Models (LLMs) excel in interactive chat scenarios due to their advanced conversational abilities. However, their training process invariably exposes them to a diverse range of harmful or toxic content, posing significant challenges in ensuring that LLM responses align with human ethical values. Consequently, the detection and quantification of adverse content remains a paramount issue in contemporary research. In this paper, we introduce the SAFE dataset, a novel resource designed to advance safety assessment research in LLMs. Our dataset extends beyond the binary categorization of content into safe and unsafe. Drawing upon human interpretations of safety, we further delineate unsafe content into six granular categories: Sensitivity, Harmfulness, Falsehood, Information Corruption, Unnaturalness, and Deviation from Instructions. This refined classification aims to enhance LLMs' ability to discern unsafe data more accurately. In total, we have created a dataset comprising 52,340 instruction-response pairs, each annotated with safety meta-tags. Additionally, we have compiled expert comparative assessments for these indicators. We developed a multi-expert rating model trained on the SAFE dataset, designed to evaluate the responses of LLMs across various dimensions. This approach highlights the potential of our dataset in the realm of safety assessment for LLMs. The model's capability to provide multi-faceted evaluations reflects an advanced understanding of the nuanced requirements in LLM response assessment. We believe this dataset represents a valuable resource for the community, contributing to the safe development and deployment of LLMs. Our findings and resources are poised to fuel future research endeavors in this domain.",2169-3536,,,64717-64726, ,  ,,Gen_dataset,
2764,"**Title**StereoHate: Toward identifying stereotypical bias and target group in hate speech detection

**Abstract**Though social media helps spread knowledge more effectively, it also stimulates the propagation of online abuse and harassment, including hate speech. It is crucial to prevent hate speech since it may have serious adverse effects on both society and individuals. Therefore, it is not only important for models to detect these speeches but to also output explanations of why a given text is toxic. While plenty of research is going on to detect online hate speech in English, there is very little research on low-resource languages like Hindi and the explainability aspect of hate speech. Recent laws like the right to explanations of the General Data Protection Regulation have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we create the first interpretable benchmark hate speech corpus hate speech explanation (HHES) in the Hindi language, where each hate post has its stereotypical bias and target group category. Providing descriptions of internal stereotypical bias as an explanation of hate posts makes a hate speech detection model more trustworthy. Current work proposes a commonsense-aware unified generative framework, CGenEx, by reframing the multitask problem as a text-to-text generation task. The novelty of this framework is it can solve two different categories of tasks (generation and classification) simultaneously. We establish the efficacy of our proposed model (CGenEx-fuse) on various evaluation metrics over other baselines when applied to the Hindi HHES dataset.Disclaimer The article contains profanity, an inevitable situation for the nature of the work involved. These in no way reflect the opinion of authors.","Maity, Krishanu; Ghosh, Nilabja; Jain, Raghav; Saha, Sriparna; Bhattacharyya, Pushpak",,"Maity, Krishanu/0000-0002-9542-9250",StereoHate: Toward identifying stereotypical bias and target group in hate speech detection,,,10.1017/nlp.2024.29 ,Article; Early Access ,,"Though social media helps spread knowledge more effectively, it also stimulates the propagation of online abuse and harassment, including hate speech. It is crucial to prevent hate speech since it may have serious adverse effects on both society and individuals. Therefore, it is not only important for models to detect these speeches but to also output explanations of why a given text is toxic. While plenty of research is going on to detect online hate speech in English, there is very little research on low-resource languages like Hindi and the explainability aspect of hate speech. Recent laws like the right to explanations of the General Data Protection Regulation have spurred research in developing interpretable models rather than only focusing on performance. Motivated by this, we create the first interpretable benchmark hate speech corpus hate speech explanation (HHES) in the Hindi language, where each hate post has its stereotypical bias and target group category. Providing descriptions of internal stereotypical bias as an explanation of hate posts makes a hate speech detection model more trustworthy. Current work proposes a commonsense-aware unified generative framework, CGenEx, by reframing the multitask problem as a text-to-text generation task. The novelty of this framework is it can solve two different categories of tasks (generation and classification) simultaneously. We establish the efficacy of our proposed model (CGenEx-fuse) on various evaluation metrics over other baselines when applied to the Hindi HHES dataset.Disclaimer The article contains profanity, an inevitable situation for the nature of the work involved. These in no way reflect the opinion of authors.",,2977-0424,,, ,  ,,out_but_toxicity,
2765,"**Title**New records on toxic cyanobacteria from Brazil: Exploring their occurrence and geography

**Abstract**Cyanobacterial Harmful Algal Blooms (CyanoHABs) pose a significant threat to communities globally, impacting ecosystems and public health. This study provides an in-depth review of the current state of cyanotoxins and the distribution of CyanoHABs species in Brazil, while also detailing the methods used for their detection. Four hundred and twenty-one incidents were analyzed from 1993 to 2021, compiling cyanotoxin records and toxic CyanoHABs occurrences. The investigation begins with the first detection of microcystins in 1994 and highlights pivotal moments, like the 1996 Caruaru Syndrome  outbreak. This event encouraged research and updated cyanotoxin-monitoring guidelines. The Brazilian drought period of 2015 -2016 exacerbated cyanobacterial growth and saxitoxin levels, coinciding with Zika-related microcephaly. This study delves into methods used for cyanotoxin analysis, including ELISA, bioassays, HPLC, and LC -MS. Additionally, we investigated the toxicity of 37 cyanobacterial strains isolated from various Brazilian environments. Extracts were tested against Artemia salina and analyzed by LC -MS. Results revealed toxicity in extracts from 49 % of cyanobacterial strains. LC -MS results were analyzed using GNPS MS/MS molecular networking for comparing experimental spectra with those of cyanotoxin standards against in-house databases and the existing literature. Our research underscores the variability in cyanotoxin production among species and over time, extending beyond microcystins. LC -MS re- sults, interpreted through the GNPS platform, revealed six cyanotoxin groups in Brazilian strains. Yet, com- pounds present in 75 % of the toxic extracts remained unidentified. Further research is crucial for fully comprehending the impact of potentially harmful organisms on water quality and public health management strategies. The study highlights the urgent need for continuously monitoring cyanobacteria and the cyanotoxin inclusion of management in public health policies.","Campos, Thaissa Giovanna Valverde; Gama, Watson A.; Geraldes, Vanessa; Yoon, Jaewon; Crnkovic, Camila M.; Pinto, Ernani; Jacinavicius, Fernanda Rios","Geraldes, Vanessa/F-2318-2015; Arantes Gama Jr, Watson/HLH-6351-2023; JACINAVICIUS, Fernanda/F-1536-2015; Manoel Crnkovic, Camila/S-6945-2019; Pinto, Ernani/A-4617-2010","Manoel Crnkovic, Camila/0000-0001-6581-9031; Pinto, Ernani/0000-0001-7614-3014",New records on toxic cyanobacteria from Brazil: Exploring their occurrence and geography,931,,10.1016/j.scitotenv.2024.172689 ,Article ,,"Cyanobacterial Harmful Algal Blooms (CyanoHABs) pose a significant threat to communities globally, impacting ecosystems and public health. This study provides an in-depth review of the current state of cyanotoxins and the distribution of CyanoHABs species in Brazil, while also detailing the methods used for their detection. Four hundred and twenty-one incidents were analyzed from 1993 to 2021, compiling cyanotoxin records and toxic CyanoHABs occurrences. The investigation begins with the first detection of microcystins in 1994 and highlights pivotal moments, like the 1996 Caruaru Syndrome  outbreak. This event encouraged research and updated cyanotoxin-monitoring guidelines. The Brazilian drought period of 2015 -2016 exacerbated cyanobacterial growth and saxitoxin levels, coinciding with Zika-related microcephaly. This study delves into methods used for cyanotoxin analysis, including ELISA, bioassays, HPLC, and LC -MS. Additionally, we investigated the toxicity of 37 cyanobacterial strains isolated from various Brazilian environments. Extracts were tested against Artemia salina and analyzed by LC -MS. Results revealed toxicity in extracts from 49 % of cyanobacterial strains. LC -MS results were analyzed using GNPS MS/MS molecular networking for comparing experimental spectra with those of cyanotoxin standards against in-house databases and the existing literature. Our research underscores the variability in cyanotoxin production among species and over time, extending beyond microcystins. LC -MS re- sults, interpreted through the GNPS platform, revealed six cyanotoxin groups in Brazilian strains. Yet, com- pounds present in 75 % of the toxic extracts remained unidentified. Further research is crucial for fully comprehending the impact of potentially harmful organisms on water quality and public health management strategies. The study highlights the urgent need for continuously monitoring cyanobacteria and the cyanotoxin inclusion of management in public health policies.",0048-9697,1879-1026,,, ,  ,,out_of_scope,
2766,"**Title**How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models

**Abstract**Abstract:Language is a deep-rooted means of perpetration of stereotypes and discrimination. Large Language Models (LLMs), now a pervasive technology in our everyday lives, can cause extensive harm when prone to generating toxic responses. The standard way to address this issue is to align the LLM, which, however, dampens the issue without constituting a definitive solution. Therefore, testing LLM even after alignment efforts remains crucial for detecting any residual deviations with respect to ethical standards. We present EvoTox, an automated testing framework for LLMs' inclination to toxicity, providing a way to quantitatively assess how much LLMs can be pushed towards toxic responses even in the presence of alignment. The framework adopts an iterative evolution strategy that exploits the interplay between two LLMs, the System Under Test (SUT) and the Prompt Generator steering SUT responses toward higher toxicity. The toxicity level is assessed by an automated oracle based on an existing toxicity classifier. We conduct a quantitative and qualitative empirical evaluation using four state-of-the-art LLMs as evaluation subjects having increasing complexity (7-13 billion parameters). Our quantitative evaluation assesses the cost-effectiveness of four alternative versions of EvoTox against existing baseline methods, based on random search, curated datasets of toxic prompts, and adversarial attacks. Our qualitative assessment engages human evaluators to rate the fluency of the generated prompts and the perceived toxicity of the responses collected during the testing sessions. Results indicate that the effectiveness, in terms of detected toxicity level, is significantly higher than the selected baseline methods (effect size up to 1.0 against random search and up to 0.99 against adversarial attacks). Furthermore, EvoTox yields a limited cost overhead (from 22% to 35% on average).","Corbo S,Bancale L,Gennaro V,Lestingi L,Scotti V,Camilli M",,,How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models,abs/2501.01741,,10.48550/ARXIV.2501.01741 , Journal Article,,"Abstract:Language is a deep-rooted means of perpetration of stereotypes and discrimination. Large Language Models (LLMs), now a pervasive technology in our everyday lives, can cause extensive harm when prone to generating toxic responses. The standard way to address this issue is to align the LLM, which, however, dampens the issue without constituting a definitive solution. Therefore, testing LLM even after alignment efforts remains crucial for detecting any residual deviations with respect to ethical standards. We present EvoTox, an automated testing framework for LLMs' inclination to toxicity, providing a way to quantitatively assess how much LLMs can be pushed towards toxic responses even in the presence of alignment. The framework adopts an iterative evolution strategy that exploits the interplay between two LLMs, the System Under Test (SUT) and the Prompt Generator steering SUT responses toward higher toxicity. The toxicity level is assessed by an automated oracle based on an existing toxicity classifier. We conduct a quantitative and qualitative empirical evaluation using four state-of-the-art LLMs as evaluation subjects having increasing complexity (7-13 billion parameters). Our quantitative evaluation assesses the cost-effectiveness of four alternative versions of EvoTox against existing baseline methods, based on random search, curated datasets of toxic prompts, and adversarial attacks. Our qualitative assessment engages human evaluators to rate the fluency of the generated prompts and the perceived toxicity of the responses collected during the testing sessions. Results indicate that the effectiveness, in terms of detected toxicity level, is significantly higher than the selected baseline methods (effect size up to 1.0 against random search and up to 0.99 against adversarial attacks). Furthermore, EvoTox yields a limited cost overhead (from 22% to 35% on average).",,,,, CoRR,  ,,evaluation,
2767,"**Title**Realistic Evaluation of Toxicity in Large Language Models

**Abstract**Large language models (LLMs) have become
     integral to our professional workflows and daily
     lives. Nevertheless, these machine companions
    of ours have a critical flaw: the huge amount of
    data which endows them with vast and diverse
    knowledge, also exposes them to the inevitable
    toxicity and bias. While most LLMs incorpo-
     rate defense mechanisms to prevent the gener-
    ation of harmful content, these safeguards can
    be easily bypassed with minimal prompt engi-
    neering. In this paper, we introduce the new
    Thoroughly Engineered Toxicity (TET) dataset,
    comprising manually crafted prompts designed
    to nullify the protective layers of such models.
    Through extensive evaluations, we demonstrate
    the pivotal role of TET in providing a rigorous
    benchmark for evaluation of toxicity awareness
     in several popular LLMs: it highlights the toxic-
     ity in the LLMs that might remain hidden when
    using normal prompts, thus revealing subtler
    issues in their behavior.

1  Introduction

Large language models (LLMs), or any other sys-
tem achieving such widespread popularity, necessi-
tate a meticulous evaluation of safety to ensure their
positive impact on the world. Numerous safety as-
sessments (Chang et al., 2023; Mukherjee et al.,
2023; Wang et al., 2023b; Zhuo et al., 2023) have
been conducted, each employing diverse strategies,
safety definitions, and prompts.
  However, these evaluations and the datasets
they employ have a significant drawback: they of-
ten rely on unnatural prompting methods, which
does not represent how people interact with chat
models in real-life scenarios. For instance, Real-
ToxicityPrompts (Gehman et al., 2020) is a no-
table dataset designed for toxicity testing of Large
Language Models, comprising 100,000 sentences

    ∗Equal contribution.
    †Corresponding author.sourced from the OpenWebTextCorpus (Gokaslan
and Cohen, 2019). In their study, the authors use
RealToxicityPrompts to examine large language
model chatbots by splitting every sentence at a spe-
cific point, using the leading portion as the input
prompt, and evaluating whether the content gener-
ated by the model to fill up the rest of the sentence
was toxic or not. Another noteworthy dataset is
ToxiGen (Hartvigsen et al., 2022), which consists
of 274,186 sentences generated by GPT-3 (Brown
et al., 2020). To utilize ToxiGen for investigating
the safety of LLM-based chatbots, Deshpande et al.
(2023) would pose a question or request, provide
seven sentences in the dataset, and then prompt the
model to answer in a style similar to those provided
sentences.
  To address the unrealistic nature of the current
toxic dataset benchmark for large language models,
we introduce the Thoroughly Engineered Toxicity
(TET) dataset, comprising 2546 prompts filtered
from over 1 million real-world interactions with
25 different Large Language Models compiled in
the chat-lmsys-1M dataset (Zheng et al., 2023).
Collected from 210K unique IP addresses in the
wild on the Vicuna demo and Chatbot Arena web-
site1, this dataset presents a repository of realistic
prompts that people commonly use to engage with
LLMs in real-world contexts.
  Besides the challenge of being distant from real-
world usage, another well-known issue in evalu-
ating LLMs involves their susceptibility to jail-
break prompts, where prompt engineering can pro-
foundly alter these models’ behavior (Liu et al.,
2023). This vulnerability implies that individuals
with harmful intentions could potentially exploit
prompt engineering techniques, turning LLMs into
powerful tools for malicious purposes and caus-
ing them to generate toxicity and harmful content
that may go undetected during evaluation. This

    1https://chat.lmsys.org1038","Luong T,Le TT,Ngo L,Nguyen T",,,Realistic Evaluation of Toxicity in Large Language Models,,,10.18653/V1/2024.FINDINGS-ACL.61 , Conference Paper,,"Large language models (LLMs) have become
     integral to our professional workflows and daily
     lives. Nevertheless, these machine companions
    of ours have a critical flaw: the huge amount of
    data which endows them with vast and diverse
    knowledge, also exposes them to the inevitable
    toxicity and bias. While most LLMs incorpo-
     rate defense mechanisms to prevent the gener-
    ation of harmful content, these safeguards can
    be easily bypassed with minimal prompt engi-
    neering. In this paper, we introduce the new
    Thoroughly Engineered Toxicity (TET) dataset,
    comprising manually crafted prompts designed
    to nullify the protective layers of such models.
    Through extensive evaluations, we demonstrate
    the pivotal role of TET in providing a rigorous
    benchmark for evaluation of toxicity awareness
     in several popular LLMs: it highlights the toxic-
     ity in the LLMs that might remain hidden when
    using normal prompts, thus revealing subtler
    issues in their behavior.

1  Introduction

Large language models (LLMs), or any other sys-
tem achieving such widespread popularity, necessi-
tate a meticulous evaluation of safety to ensure their
positive impact on the world. Numerous safety as-
sessments (Chang et al., 2023; Mukherjee et al.,
2023; Wang et al., 2023b; Zhuo et al., 2023) have
been conducted, each employing diverse strategies,
safety definitions, and prompts.
  However, these evaluations and the datasets
they employ have a significant drawback: they of-
ten rely on unnatural prompting methods, which
does not represent how people interact with chat
models in real-life scenarios. For instance, Real-
ToxicityPrompts (Gehman et al., 2020) is a no-
table dataset designed for toxicity testing of Large
Language Models, comprising 100,000 sentences

    ∗Equal contribution.
    †Corresponding author.sourced from the OpenWebTextCorpus (Gokaslan
and Cohen, 2019). In their study, the authors use
RealToxicityPrompts to examine large language
model chatbots by splitting every sentence at a spe-
cific point, using the leading portion as the input
prompt, and evaluating whether the content gener-
ated by the model to fill up the rest of the sentence
was toxic or not. Another noteworthy dataset is
ToxiGen (Hartvigsen et al., 2022), which consists
of 274,186 sentences generated by GPT-3 (Brown
et al., 2020). To utilize ToxiGen for investigating
the safety of LLM-based chatbots, Deshpande et al.
(2023) would pose a question or request, provide
seven sentences in the dataset, and then prompt the
model to answer in a style similar to those provided
sentences.
  To address the unrealistic nature of the current
toxic dataset benchmark for large language models,
we introduce the Thoroughly Engineered Toxicity
(TET) dataset, comprising 2546 prompts filtered
from over 1 million real-world interactions with
25 different Large Language Models compiled in
the chat-lmsys-1M dataset (Zheng et al., 2023).
Collected from 210K unique IP addresses in the
wild on the Vicuna demo and Chatbot Arena web-
site1, this dataset presents a repository of realistic
prompts that people commonly use to engage with
LLMs in real-world contexts.
  Besides the challenge of being distant from real-
world usage, another well-known issue in evalu-
ating LLMs involves their susceptibility to jail-
break prompts, where prompt engineering can pro-
foundly alter these models’ behavior (Liu et al.,
2023). This vulnerability implies that individuals
with harmful intentions could potentially exploit
prompt engineering techniques, turning LLMs into
powerful tools for malicious purposes and caus-
ing them to generate toxicity and harmful content
that may go undetected during evaluation. This

    1https://chat.lmsys.org1038",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024  ",,Gen_dataset#evaluation,
2768,"**Title**Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias

**Abstract**The common toxicity and societal bias in
    contents generated by large language mod-
     els (LLMs) necessitate strategies to reduce
    harm. Present solutions often demand white-
   box access to the model or substantial train-
     ing, which is impractical for cutting-edge com-
    mercial LLMs. Moreover, prevailing prompt-
    ing methods depend on external tool feed-
    back and fail to simultaneously lessen toxi-
    city and bias.  Motivated by social psychol-
   ogy principles, we propose a novel strategy
   named perspective-taking prompting (PET)
    that inspires LLMs to integrate diverse hu-
   man perspectives and self-regulate their re-
    sponses. This self-correction mechanism can
     significantly diminish toxicity (up to 89%) and
    bias (up to 73%) in LLMs’ responses. Rigor-
    ous evaluations and ablation studies are con-
    ducted on two commercial LLMs (ChatGPT
    and GLM) and three open-source LLMs, reveal-
    ing PET’s superiority in producing less harmful
    responses, outperforming five strong baselines.

  “Words kill, words give life; they’re either poison
or fruit—you choose.”
                   ~ Proverbs 18:21 (MSG)

1  Introduction
Large language models (LLMs; OpenAI et al. 2023;
Chowdhery et al. 2023; Touvron et al. 2023; Chiang
et al. 2023) excel in numerous NLP tasks, enhanc-
ing the efficiency of our work and life (Kasneci
et al., 2023; Kung et al., 2023). Meanwhile, recent
research pointed out that LLMs inevitably give ob-
jectionable responses, as they are pre-trained on
a vast amount of unsanitized web text (Gehman
et al., 2020). For instance, LLMs could output
toxic content with harmful attributes (e.g., rude,
disrespectful, insulting sentences) (Gehman et al.,
2020). They may also generate content with so-
cietal bias (Sheng et al., 2021b), which exhibits

   *Corresponding author.Figure 1: Shortcomings and limitations in current mea-
sures on reducing toxicity and bias.

stereotypes towards particular demographic groups,
e.g., “Asians are good at math.”).  It remains an
ongoing endeavor to make LLMs deliver harmless
and unbiased content (Gabriel, 2020; Bai et al.,
2022a; Liu et al., 2023; Shen et al., 2023).
  While many efforts have been devoted to alle-
viating toxicity and bias (Weidinger et al., 2021;
Mehrabi et al., 2021), existing measures exhibit
two shortcomings when applied to state-of-the-
art commercial LLMs, e.g., GPT-4 (OpenAI et al.,
2023). (1) Impractical requirement of white-box ac-
cess. Many solutions require access to the model’s
internal representations (Leong et al., 2023) or con-
trol decoding processes (Krause et al., 2021; Liu
et al., 2021), which is impossible to deploy on
commercial LLMs that only reveal limited log-
its.  (2) Huge training cost. Some solutions re-
quire domain-specific training, which is very cost-
prohibitive (Gururangan et al., 2020). While they
may work for older models like GPT-2, it is diffi-
cult to extend them to up-to-date LLMs (Gou et al.,
2023), which have significantly distinct behaviors
and features (c.f. Table 1).
  Driven by these issues, in this study, we con-
centrate on the black-box scenario. However, we
notice two limitations of existing measures. (1)
Single-issue focus. One issue is their focus on
addressing a single type of problematic behavior
while neglecting the need for concurrent adjust-
ments across various problematic attributes. More
seriously, Yang et al. (2022) point out some detoxi-
fication techniques (Liu et al., 2021) may inadver-8341Commercial LLMs





    Without
  External Tools             Two Shortcomings
     White-box access          Huge training cost

Unable to deploy on commercial LLMs      Results are hard to reproduce
             Two Limitations
      Single-issue focus            External tool reliance

    Inadvertently exacerbate bias     Complicates deployment and adaptation","Xu R,Zhou Z,Zhang T,Qi Z,Yao S,Xu K,Xu W,Qiu H",,,Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias,,, , Conference Paper,,"The common toxicity and societal bias in
    contents generated by large language mod-
     els (LLMs) necessitate strategies to reduce
    harm. Present solutions often demand white-
   box access to the model or substantial train-
     ing, which is impractical for cutting-edge com-
    mercial LLMs. Moreover, prevailing prompt-
    ing methods depend on external tool feed-
    back and fail to simultaneously lessen toxi-
    city and bias.  Motivated by social psychol-
   ogy principles, we propose a novel strategy
   named perspective-taking prompting (PET)
    that inspires LLMs to integrate diverse hu-
   man perspectives and self-regulate their re-
    sponses. This self-correction mechanism can
     significantly diminish toxicity (up to 89%) and
    bias (up to 73%) in LLMs’ responses. Rigor-
    ous evaluations and ablation studies are con-
    ducted on two commercial LLMs (ChatGPT
    and GLM) and three open-source LLMs, reveal-
    ing PET’s superiority in producing less harmful
    responses, outperforming five strong baselines.

  “Words kill, words give life; they’re either poison
or fruit—you choose.”
                   ~ Proverbs 18:21 (MSG)

1  Introduction
Large language models (LLMs; OpenAI et al. 2023;
Chowdhery et al. 2023; Touvron et al. 2023; Chiang
et al. 2023) excel in numerous NLP tasks, enhanc-
ing the efficiency of our work and life (Kasneci
et al., 2023; Kung et al., 2023). Meanwhile, recent
research pointed out that LLMs inevitably give ob-
jectionable responses, as they are pre-trained on
a vast amount of unsanitized web text (Gehman
et al., 2020). For instance, LLMs could output
toxic content with harmful attributes (e.g., rude,
disrespectful, insulting sentences) (Gehman et al.,
2020). They may also generate content with so-
cietal bias (Sheng et al., 2021b), which exhibits

   *Corresponding author.Figure 1: Shortcomings and limitations in current mea-
sures on reducing toxicity and bias.

stereotypes towards particular demographic groups,
e.g., “Asians are good at math.”).  It remains an
ongoing endeavor to make LLMs deliver harmless
and unbiased content (Gabriel, 2020; Bai et al.,
2022a; Liu et al., 2023; Shen et al., 2023).
  While many efforts have been devoted to alle-
viating toxicity and bias (Weidinger et al., 2021;
Mehrabi et al., 2021), existing measures exhibit
two shortcomings when applied to state-of-the-
art commercial LLMs, e.g., GPT-4 (OpenAI et al.,
2023). (1) Impractical requirement of white-box ac-
cess. Many solutions require access to the model’s
internal representations (Leong et al., 2023) or con-
trol decoding processes (Krause et al., 2021; Liu
et al., 2021), which is impossible to deploy on
commercial LLMs that only reveal limited log-
its.  (2) Huge training cost. Some solutions re-
quire domain-specific training, which is very cost-
prohibitive (Gururangan et al., 2020). While they
may work for older models like GPT-2, it is diffi-
cult to extend them to up-to-date LLMs (Gou et al.,
2023), which have significantly distinct behaviors
and features (c.f. Table 1).
  Driven by these issues, in this study, we con-
centrate on the black-box scenario. However, we
notice two limitations of existing measures. (1)
Single-issue focus. One issue is their focus on
addressing a single type of problematic behavior
while neglecting the need for concurrent adjust-
ments across various problematic attributes. More
seriously, Yang et al. (2022) point out some detoxi-
fication techniques (Liu et al., 2021) may inadver-8341Commercial LLMs





    Without
  External Tools             Two Shortcomings
     White-box access          Huge training cost

Unable to deploy on commercial LLMs      Results are hard to reproduce
             Two Limitations
      Single-issue focus            External tool reliance

    Inadvertently exacerbate bias     Complicates deployment and adaptation",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,detox,
2769,"**Title**Down the Toxicity Rabbit Hole: A Framework to Bias Audit Large Language Models with Key Emphasis on Racism, Antisemitism, and Misogyny

**Abstract**Abstract:This paper makes three contributions. First, it presents a generalizable, novel framework dubbed \textit{toxicity rabbit hole} that iteratively elicits toxic content from a wide suite of large language models. Spanning a set of 1,266 identity groups, we first conduct a bias audit of \texttt{PaLM 2} guardrails presenting key insights. Next, we report generalizability across several other models. Through the elicited toxic content, we present a broad analysis with a key emphasis on racism, antisemitism, misogyny, Islamophobia, homophobia, and transphobia. Finally, driven by concrete examples, we discuss potential ramifications.","Dutta A,Khorramrouz A,Dutta S,KhudaBukhsh AR",,,"Down the Toxicity Rabbit Hole: A Framework to Bias Audit Large Language Models with Key Emphasis on Racism, Antisemitism, and Misogyny",,, , Conference Paper,,"Abstract:This paper makes three contributions. First, it presents a generalizable, novel framework dubbed \textit{toxicity rabbit hole} that iteratively elicits toxic content from a wide suite of large language models. Spanning a set of 1,266 identity groups, we first conduct a bias audit of \texttt{PaLM 2} guardrails presenting key insights. Next, we report generalizability across several other models. Through the elicited toxic content, we present a broad analysis with a key emphasis on racism, antisemitism, misogyny, Islamophobia, homophobia, and transphobia. Finally, driven by concrete examples, we discuss potential ramifications.",,,,,ijcai.org ,"Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI 2024, Jeju, South Korea, August 3-9, 2024  ",,evaluation,
2770,"**Title**Efficient Detection of Toxic Prompts in Large Language Models

**Abstract**Abstract:Large language models (LLMs) like ChatGPT and Gemini have significantly advanced natural language processing, enabling various applications such as chatbots and automated content generation. However, these models can be exploited by malicious individuals who craft toxic prompts to elicit harmful or unethical responses. These individuals often employ jailbreaking techniques to bypass safety mechanisms, highlighting the need for robust toxic prompt detection methods. Existing detection techniques, both blackbox and whitebox, face challenges related to the diversity of toxic prompts, scalability, and computational efficiency. In response, we propose ToxicDetector, a lightweight greybox method designed to efficiently detect toxic prompts in LLMs. ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP) classifier for prompt classification. Our evaluation on various versions of the LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector achieves a high accuracy of 96.39\% and a low false positive rate of 2.00\%, outperforming state-of-the-art methods. Additionally, ToxicDetector's processing time of 0.0780 seconds per prompt makes it highly suitable for real-time applications. ToxicDetector achieves high accuracy, efficiency, and scalability, making it a practical method for toxic prompt detection in LLMs.","Liu Y,Yu J,Sun H,Shi L,Deng G,Chen Y,Liu Y",,,Efficient Detection of Toxic Prompts in Large Language Models,,,10.1145/3691620.3695018 , Conference Paper,,"Abstract:Large language models (LLMs) like ChatGPT and Gemini have significantly advanced natural language processing, enabling various applications such as chatbots and automated content generation. However, these models can be exploited by malicious individuals who craft toxic prompts to elicit harmful or unethical responses. These individuals often employ jailbreaking techniques to bypass safety mechanisms, highlighting the need for robust toxic prompt detection methods. Existing detection techniques, both blackbox and whitebox, face challenges related to the diversity of toxic prompts, scalability, and computational efficiency. In response, we propose ToxicDetector, a lightweight greybox method designed to efficiently detect toxic prompts in LLMs. ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP) classifier for prompt classification. Our evaluation on various versions of the LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector achieves a high accuracy of 96.39\% and a low false positive rate of 2.00\%, outperforming state-of-the-art methods. Additionally, ToxicDetector's processing time of 0.0780 seconds per prompt makes it highly suitable for real-time applications. ToxicDetector achieves high accuracy, efficiency, and scalability, making it a practical method for toxic prompt detection in LLMs.",,,,,ACM ,"Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering, ASE 2024, Sacramento, CA, USA, October 27 - November 1, 2024  ",,detection#methodology,
2771,No abstract available,"Taveekitworachai P,Abdullah F,Gursesli MC,Lanatà A,Guazzini A,Thawonmas R",,,Prompt Evolution Through Examples for Large Language Models-A Case Study in Game Comment Toxicity Classification,,,10.1109/METROIND4.0IOT61288.2024.10584130 , Conference Paper,,,,,,,IEEE ,"IEEE International Workshop on Metrology for Industry 4.0 and IoT, MetroInd4.0 & IoT 2024, Firenze, Italy, May 29-31, 2024  ",,,
2772,"**Title**Toxic Speech Detection in Portuguese: A Comparative Study of Large Language Models

**Abstract**This research addresses the automatic detec-
    tion of toxic speech in Portuguese. Utilizing
    the ToLD-Br dataset, which includes 21,000 an-
    notated tweets, we examine the performance of
    Large Language Models (LLMs) such as Ope-
    nAI’s ChatGPT and the monolingual MariTalk
   from Maritaca AI. The study focuses on their
    effectiveness in identifying Toxic speech, the
    influence of few-shot learning, and the intrica-
    cies of annotating datasets, particularly regard-
    ing vulgar language (swear words). Our ex-
    periments reveal that MariTalk (Sabiá) demon-
     strates a nuanced understanding of colloquial
    Portuguese. Meanwhile, ChatGPT, especially
   when augmented with few-shot learning, shows
    robustness comparable to baseline methods.
    This investigation underscores the value of
    both monolingual and lower-capacity models
     in the nuanced field of language-specific Toxic
    speech detection, offering insights into their
    competitive edge against models like ChatGPT.

1  Introduction

In 2023, X (formerly Twitter) updated its documen-
tation on hateful conduct (Twitter, 2023), clearly
defining what they consider a violation of this pol-
icy. This includes explicit prohibitions against mes-
sages that promote fear and discrimination against
specific groups. Additionally, the policy considers
the repeated use of insults, degrading stereotypes,
or images that dehumanize a particular group as
violations. In light of these updated policies, de-
veloping effective automatic hate and toxic speech
detection strategies becomes increasingly crucial.
  Automated toxic speech detection strategies typ-
ically involve linguistic feature analysis, lexicon-based approaches, and supervised machine learning
algorithms trained on labeled datasets (Schmidt and
Wiegand, 2017; Vargas et al., 2022b). Advanced
techniques, including natural language processing
and deep learning methods, seek to comprehend
the semantics and context of textual content (Leite
et al., 2020; Vargas et al., 2022a). Yet, substantial
challenges persist due to the complexity of human
language, the fast evolution of toxic speech, and
the balance needed between free speech and the
fight against harmful content.
  Moreover, while research has predominantly fo-
cused on English, there has been notable progress
in detecting toxic speech in Portuguese. For in-
stance, the ToLD-Br dataset (Leite et al., 2020),
containing 21,000 annotated tweets, allows for new
advancements. Despite BERT-based models reach-
ing macro-F1 scores between 70% and 80% on this
dataset, room for improvement exists.
  The use of Large Language Models (LLMs)
has gained significant notoriety due to the success
of OpenAI’s ChatGPT. Today, impressive results
are being achieved using LLMs for various nat-
ural language tasks (Koco´n et al., 2023), includ-
ing for Portuguese, such as answering questions
from the Brazilian National High School Exam
(Silveira and Mauá, 2018; Nunes et al., 2023), text
reading and comprehension (FaQuAD) (Sayama
et al., 2019), and social network sentiment anal-
ysis (Brum and Nunes, 2017), prediction of de-
pressive disorder (dos Santos and Paraboni, 2023),
among others. A comprehensive study by Koco´n
et al. (2023) demonstrated how ChatGPT, via Ope-
nAI’s API, can be competitive for various NLP
tasks, including hate speech.  In Oliveira et al.","da Silva Oliveira A,de Carvalho Cecote T,Alvarenga JP,de Souza Freitas VL,da Silva Luz EJ",,,Toxic Speech Detection in Portuguese: A Comparative Study of Large Language Models,,, , Conference Paper,,"This research addresses the automatic detec-
    tion of toxic speech in Portuguese. Utilizing
    the ToLD-Br dataset, which includes 21,000 an-
    notated tweets, we examine the performance of
    Large Language Models (LLMs) such as Ope-
    nAI’s ChatGPT and the monolingual MariTalk
   from Maritaca AI. The study focuses on their
    effectiveness in identifying Toxic speech, the
    influence of few-shot learning, and the intrica-
    cies of annotating datasets, particularly regard-
    ing vulgar language (swear words). Our ex-
    periments reveal that MariTalk (Sabiá) demon-
     strates a nuanced understanding of colloquial
    Portuguese. Meanwhile, ChatGPT, especially
   when augmented with few-shot learning, shows
    robustness comparable to baseline methods.
    This investigation underscores the value of
    both monolingual and lower-capacity models
     in the nuanced field of language-specific Toxic
    speech detection, offering insights into their
    competitive edge against models like ChatGPT.

1  Introduction

In 2023, X (formerly Twitter) updated its documen-
tation on hateful conduct (Twitter, 2023), clearly
defining what they consider a violation of this pol-
icy. This includes explicit prohibitions against mes-
sages that promote fear and discrimination against
specific groups. Additionally, the policy considers
the repeated use of insults, degrading stereotypes,
or images that dehumanize a particular group as
violations. In light of these updated policies, de-
veloping effective automatic hate and toxic speech
detection strategies becomes increasingly crucial.
  Automated toxic speech detection strategies typ-
ically involve linguistic feature analysis, lexicon-based approaches, and supervised machine learning
algorithms trained on labeled datasets (Schmidt and
Wiegand, 2017; Vargas et al., 2022b). Advanced
techniques, including natural language processing
and deep learning methods, seek to comprehend
the semantics and context of textual content (Leite
et al., 2020; Vargas et al., 2022a). Yet, substantial
challenges persist due to the complexity of human
language, the fast evolution of toxic speech, and
the balance needed between free speech and the
fight against harmful content.
  Moreover, while research has predominantly fo-
cused on English, there has been notable progress
in detecting toxic speech in Portuguese. For in-
stance, the ToLD-Br dataset (Leite et al., 2020),
containing 21,000 annotated tweets, allows for new
advancements. Despite BERT-based models reach-
ing macro-F1 scores between 70% and 80% on this
dataset, room for improvement exists.
  The use of Large Language Models (LLMs)
has gained significant notoriety due to the success
of OpenAI’s ChatGPT. Today, impressive results
are being achieved using LLMs for various nat-
ural language tasks (Koco´n et al., 2023), includ-
ing for Portuguese, such as answering questions
from the Brazilian National High School Exam
(Silveira and Mauá, 2018; Nunes et al., 2023), text
reading and comprehension (FaQuAD) (Sayama
et al., 2019), and social network sentiment anal-
ysis (Brum and Nunes, 2017), prediction of de-
pressive disorder (dos Santos and Paraboni, 2023),
among others. A comprehensive study by Koco´n
et al. (2023) demonstrated how ChatGPT, via Ope-
nAI’s API, can be competitive for various NLP
tasks, including hate speech.  In Oliveira et al.",,,,,Association for Computational Lingustics ,"Proceedings of the 16th International Conference on Computational Processing of Portuguese, PROPOR 2024, Santiago de Compostela, Galicia/Spain, 12-15 March, 2024  ",,out_but_toxicity,
2773,"**Title**Eliciting and Measuring Toxic Bias in Human-to-Machine Interactions in Large Language Models

**Abstract**Merit is a central pillar of liberal epistemology, humanism, and democracy. The scientific enterprise, built on merit, has proven effective in generating scientific and technological advances, reducing suffering, narrowing social gaps, and improving the quality of life globally. This perspective documents the ongoing attempts to undermine the core principles of liberal epistemology and to replace merit with non-scientific, politically motivated criteria. We explain the philosophical origins of this conflict, document the intrusion of ideology into our scientific institutions, discuss the perils of abandoning merit, and offer an alternative, human-centered approach to address existing social inequalities.","Stein K,Harvey A,Lopez A,Taj U,Watkins S,Watkins LA",,,Eliciting and Measuring Toxic Bias in Human-to-Machine Interactions in Large Language Models,,,10.1109/UEMCON62879.2024.10754689 , Conference Paper,,"Merit is a central pillar of liberal epistemology, humanism, and democracy. The scientific enterprise, built on merit, has proven effective in generating scientific and technological advances, reducing suffering, narrowing social gaps, and improving the quality of life globally. This perspective documents the ongoing attempts to undermine the core principles of liberal epistemology and to replace merit with non-scientific, politically motivated criteria. We explain the philosophical origins of this conflict, document the intrusion of ideology into our scientific institutions, discuss the perils of abandoning merit, and offer an alternative, human-centered approach to address existing social inequalities.",,,,,IEEE ,"15th IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference, UEMCON 2024, Yorktown Heights, NY, USA, October 17-19, 2024  ",,methodology,
2774,"**Title**Social Evolution of Published Text and The Emergence of Artificial Intelligence Through Large Language Models and The Problem of Toxicity and Bias

**Abstract**Abstract:We provide a birds eye view of the rapid developments in AI and Deep Learning that has led to the path-breaking emergence of AI in Large Language Models. The aim of this study is to place all these developments in a pragmatic broader historical social perspective without any exaggerations while at the same time without any pessimism that created the AI winter in the 1970s to 1990s. We also at the same time point out toxicity, bias, memorization, sycophancy, logical inconsistencies, hallucinations that exist just as a warning to the overly optimistic. We note here that just as this emergence of AI seems to occur at a threshold point in the number of neural connections or weights, it has also been observed that human brain and especially the cortex region is nothing special or extraordinary but simply a case of scaled-up version of the primate brain and that even the human intelligence seems like an emergent phenomena of scale.","Khan A,Saravanan P,Venkatesan SK",,,Social Evolution of Published Text and The Emergence of Artificial Intelligence Through Large Language Models and The Problem of Toxicity and Bias,abs/2402.07166,,10.48550/ARXIV.2402.07166 , Journal Article,,"Abstract:We provide a birds eye view of the rapid developments in AI and Deep Learning that has led to the path-breaking emergence of AI in Large Language Models. The aim of this study is to place all these developments in a pragmatic broader historical social perspective without any exaggerations while at the same time without any pessimism that created the AI winter in the 1970s to 1990s. We also at the same time point out toxicity, bias, memorization, sycophancy, logical inconsistencies, hallucinations that exist just as a warning to the overly optimistic. We note here that just as this emergence of AI seems to occur at a threshold point in the number of neural connections or weights, it has also been observed that human brain and especially the cortex region is nothing special or extraordinary but simply a case of scaled-up version of the primate brain and that even the human intelligence seems like an emergent phenomena of scale.",,,,, CoRR,  ,,evaluation,
2775,"**Title**PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models

**Abstract**Abstract:Recent advances in large language models (LLMs) have led to their extensive global deployment, and ensuring their safety calls for comprehensive and multilingual toxicity evaluations. However, existing toxicity benchmarks are overwhelmingly focused on English, posing serious risks to deploying LLMs in other languages. We address this by introducing PolygloToxicityPrompts (PTP), the first large-scale multilingual toxicity evaluation benchmark of 425K naturally occurring prompts spanning 17 languages. We overcome the scarcity of naturally occurring toxicity in web-text and ensure coverage across languages with varying resources by automatically scraping over 100M web-text documents. Using PTP, we investigate research questions to study the impact of model size, prompt language, and instruction and preference-tuning methods on toxicity by benchmarking over 60 LLMs. Notably, we find that toxicity increases as language resources decrease or model size increases. Although instruction- and preference-tuning reduce toxicity, the choice of preference-tuning method does not have any significant impact. Our findings shed light on crucial shortcomings of LLM safeguarding and highlight areas for future research.","Jain D,Kumar P,Gehman S,Zhou X,Hartvigsen T,Sap M",,,PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models,abs/2405.09373,,10.48550/ARXIV.2405.09373 , Journal Article,,"Abstract:Recent advances in large language models (LLMs) have led to their extensive global deployment, and ensuring their safety calls for comprehensive and multilingual toxicity evaluations. However, existing toxicity benchmarks are overwhelmingly focused on English, posing serious risks to deploying LLMs in other languages. We address this by introducing PolygloToxicityPrompts (PTP), the first large-scale multilingual toxicity evaluation benchmark of 425K naturally occurring prompts spanning 17 languages. We overcome the scarcity of naturally occurring toxicity in web-text and ensure coverage across languages with varying resources by automatically scraping over 100M web-text documents. Using PTP, we investigate research questions to study the impact of model size, prompt language, and instruction and preference-tuning methods on toxicity by benchmarking over 60 LLMs. Notably, we find that toxicity increases as language resources decrease or model size increases. Although instruction- and preference-tuning reduce toxicity, the choice of preference-tuning method does not have any significant impact. Our findings shed light on crucial shortcomings of LLM safeguarding and highlight areas for future research.",,,,, CoRR,  ,,evaluation,
2776,"**Title**Testing and Evaluation of Large Language Models: Correctness, Non-Toxicity, and Fairness

**Abstract**Large language models (LLMs) have become
     integral to our professional workflows and daily
     lives. Nevertheless, these machine companions
    of ours have a critical flaw: the huge amount of
    data which endows them with vast and diverse
    knowledge, also exposes them to the inevitable
    toxicity and bias. While most LLMs incorpo-
     rate defense mechanisms to prevent the gener-
    ation of harmful content, these safeguards can
    be easily bypassed with minimal prompt engi-
    neering. In this paper, we introduce the new
    Thoroughly Engineered Toxicity (TET) dataset,
    comprising manually crafted prompts designed
    to nullify the protective layers of such models.
    Through extensive evaluations, we demonstrate
    the pivotal role of TET in providing a rigorous
    benchmark for evaluation of toxicity awareness
     in several popular LLMs: it highlights the toxic-
     ity in the LLMs that might remain hidden when
    using normal prompts, thus revealing subtler
    issues in their behavior.

1  Introduction

Large language models (LLMs), or any other sys-
tem achieving such widespread popularity, necessi-
tate a meticulous evaluation of safety to ensure their
positive impact on the world. Numerous safety as-
sessments (Chang et al., 2023; Mukherjee et al.,
2023; Wang et al., 2023b; Zhuo et al., 2023) have
been conducted, each employing diverse strategies,
safety definitions, and prompts.
  However, these evaluations and the datasets
they employ have a significant drawback: they of-
ten rely on unnatural prompting methods, which
does not represent how people interact with chat
models in real-life scenarios. For instance, Real-
ToxicityPrompts (Gehman et al., 2020) is a no-
table dataset designed for toxicity testing of Large
Language Models, comprising 100,000 sentences

    ∗Equal contribution.
    †Corresponding author.sourced from the OpenWebTextCorpus (Gokaslan
and Cohen, 2019). In their study, the authors use
RealToxicityPrompts to examine large language
model chatbots by splitting every sentence at a spe-
cific point, using the leading portion as the input
prompt, and evaluating whether the content gener-
ated by the model to fill up the rest of the sentence
was toxic or not. Another noteworthy dataset is
ToxiGen (Hartvigsen et al., 2022), which consists
of 274,186 sentences generated by GPT-3 (Brown
et al., 2020). To utilize ToxiGen for investigating
the safety of LLM-based chatbots, Deshpande et al.
(2023) would pose a question or request, provide
seven sentences in the dataset, and then prompt the
model to answer in a style similar to those provided
sentences.
  To address the unrealistic nature of the current
toxic dataset benchmark for large language models,
we introduce the Thoroughly Engineered Toxicity
(TET) dataset, comprising 2546 prompts filtered
from over 1 million real-world interactions with
25 different Large Language Models compiled in
the chat-lmsys-1M dataset (Zheng et al., 2023).
Collected from 210K unique IP addresses in the
wild on the Vicuna demo and Chatbot Arena web-
site1, this dataset presents a repository of realistic
prompts that people commonly use to engage with
LLMs in real-world contexts.
  Besides the challenge of being distant from real-
world usage, another well-known issue in evalu-
ating LLMs involves their susceptibility to jail-
break prompts, where prompt engineering can pro-
foundly alter these models’ behavior (Liu et al.,
2023). This vulnerability implies that individuals
with harmful intentions could potentially exploit
prompt engineering techniques, turning LLMs into
powerful tools for malicious purposes and caus-
ing them to generate toxicity and harmful content
that may go undetected during evaluation. This

    1https://chat.lmsys.org1038",Wang W,,,"Testing and Evaluation of Large Language Models: Correctness, Non-Toxicity, and Fairness",abs/2409.00551,,10.48550/ARXIV.2409.00551 , Journal Article,,"Large language models (LLMs) have become
     integral to our professional workflows and daily
     lives. Nevertheless, these machine companions
    of ours have a critical flaw: the huge amount of
    data which endows them with vast and diverse
    knowledge, also exposes them to the inevitable
    toxicity and bias. While most LLMs incorpo-
     rate defense mechanisms to prevent the gener-
    ation of harmful content, these safeguards can
    be easily bypassed with minimal prompt engi-
    neering. In this paper, we introduce the new
    Thoroughly Engineered Toxicity (TET) dataset,
    comprising manually crafted prompts designed
    to nullify the protective layers of such models.
    Through extensive evaluations, we demonstrate
    the pivotal role of TET in providing a rigorous
    benchmark for evaluation of toxicity awareness
     in several popular LLMs: it highlights the toxic-
     ity in the LLMs that might remain hidden when
    using normal prompts, thus revealing subtler
    issues in their behavior.

1  Introduction

Large language models (LLMs), or any other sys-
tem achieving such widespread popularity, necessi-
tate a meticulous evaluation of safety to ensure their
positive impact on the world. Numerous safety as-
sessments (Chang et al., 2023; Mukherjee et al.,
2023; Wang et al., 2023b; Zhuo et al., 2023) have
been conducted, each employing diverse strategies,
safety definitions, and prompts.
  However, these evaluations and the datasets
they employ have a significant drawback: they of-
ten rely on unnatural prompting methods, which
does not represent how people interact with chat
models in real-life scenarios. For instance, Real-
ToxicityPrompts (Gehman et al., 2020) is a no-
table dataset designed for toxicity testing of Large
Language Models, comprising 100,000 sentences

    ∗Equal contribution.
    †Corresponding author.sourced from the OpenWebTextCorpus (Gokaslan
and Cohen, 2019). In their study, the authors use
RealToxicityPrompts to examine large language
model chatbots by splitting every sentence at a spe-
cific point, using the leading portion as the input
prompt, and evaluating whether the content gener-
ated by the model to fill up the rest of the sentence
was toxic or not. Another noteworthy dataset is
ToxiGen (Hartvigsen et al., 2022), which consists
of 274,186 sentences generated by GPT-3 (Brown
et al., 2020). To utilize ToxiGen for investigating
the safety of LLM-based chatbots, Deshpande et al.
(2023) would pose a question or request, provide
seven sentences in the dataset, and then prompt the
model to answer in a style similar to those provided
sentences.
  To address the unrealistic nature of the current
toxic dataset benchmark for large language models,
we introduce the Thoroughly Engineered Toxicity
(TET) dataset, comprising 2546 prompts filtered
from over 1 million real-world interactions with
25 different Large Language Models compiled in
the chat-lmsys-1M dataset (Zheng et al., 2023).
Collected from 210K unique IP addresses in the
wild on the Vicuna demo and Chatbot Arena web-
site1, this dataset presents a repository of realistic
prompts that people commonly use to engage with
LLMs in real-world contexts.
  Besides the challenge of being distant from real-
world usage, another well-known issue in evalu-
ating LLMs involves their susceptibility to jail-
break prompts, where prompt engineering can pro-
foundly alter these models’ behavior (Liu et al.,
2023). This vulnerability implies that individuals
with harmful intentions could potentially exploit
prompt engineering techniques, turning LLMs into
powerful tools for malicious purposes and caus-
ing them to generate toxicity and harmful content
that may go undetected during evaluation. This

    1https://chat.lmsys.org1038",,,,, CoRR,  ,,evaluation,
2777,"**Title**How Toxicity Classifiers and Large Language Models Respond to Ableism

**Abstract**Abstract.
People with disabilities (PwD) regularly encounter ableist hate and microaggressions online. While online platforms use machine learning models to moderate online harm, there is little research investigating how these models interact with ableism. In this paper, we curated a dataset of 100 social media comments targeted towards PwD, and recruited 160 participants to rate and explain how toxic and ableist these comments were. We then prompted state-of-the art toxicity classifiers (TCs) and large language models (LLMs) to rate and explain the harm. Our analysis revealed that TCs and LLMs rated toxicity significantly lower than PwD, but LLMs rated ableism generally on par with PwD. However, ableism explanations by LLMs overlooked emotional harm, and lacked specificity and acknowledgement of context, important facets of PwD explanations. Going forward, we discuss challenges in designing disability-aware toxicity classifiers, and advocate for the shift from ableism detection to ableism interpretation and explanation.","Phutane M,Seelam A,Vashistha A",,,How Toxicity Classifiers and Large Language Models Respond to Ableism,abs/2410.03448,,10.48550/ARXIV.2410.03448 , Journal Article,,"Abstract.
People with disabilities (PwD) regularly encounter ableist hate and microaggressions online. While online platforms use machine learning models to moderate online harm, there is little research investigating how these models interact with ableism. In this paper, we curated a dataset of 100 social media comments targeted towards PwD, and recruited 160 participants to rate and explain how toxic and ableist these comments were. We then prompted state-of-the art toxicity classifiers (TCs) and large language models (LLMs) to rate and explain the harm. Our analysis revealed that TCs and LLMs rated toxicity significantly lower than PwD, but LLMs rated ableism generally on par with PwD. However, ableism explanations by LLMs overlooked emotional harm, and lacked specificity and acknowledgement of context, important facets of PwD explanations. Going forward, we discuss challenges in designing disability-aware toxicity classifiers, and advocate for the shift from ableism detection to ableism interpretation and explanation.",,,,, CoRR,  ,,evaluation,
2778,"**Title**Toxic Subword Pruning for Dialogue Response Generation on Large Language Models

**Abstract**Abstract:How to defend large language models (LLMs) from generating toxic content is an important research area. Yet, most research focused on various model training techniques to remediate LLMs by updating their weights. A typical related research area is safety alignment. This however is often costly and tedious and can expose the model to even more problems such as catastrophic forgetting if the trainings are not carefully handled by experienced NLP practitioners. We thus propose a simple yet effective and novel algorithm, namely \textbf{Tox}ic Subword \textbf{Prun}ing (ToxPrune) to prune the subword contained by the toxic words from BPE in trained LLMs. In contrast to the previous work that demonstrates pruning BPE tokens as harmful to the task of machine translation, we surprisingly found its usefulness in preventing toxic content from being generated on LLMs. Fortunately, our findings suggest that ToxPrune simultaneously improves the toxic language model NSFW-3B on the task of dialogue response generation obviously. We surprisingly found that ToxPrune can even obviously improve official Llama-3.1-6B in the metric of dialogue diversity. Extensive automatic results and human evaluation indicate that ToxPrune could be helpful for both remediating toxic LLMs and improving non-toxic LLMs on the task of dialogue response generation.\footnote{We plan to release the resources to facilitate future work.}","Lu H,Lam W",,,Toxic Subword Pruning for Dialogue Response Generation on Large Language Models,abs/2410.04155,,10.48550/ARXIV.2410.04155 , Journal Article,,"Abstract:How to defend large language models (LLMs) from generating toxic content is an important research area. Yet, most research focused on various model training techniques to remediate LLMs by updating their weights. A typical related research area is safety alignment. This however is often costly and tedious and can expose the model to even more problems such as catastrophic forgetting if the trainings are not carefully handled by experienced NLP practitioners. We thus propose a simple yet effective and novel algorithm, namely \textbf{Tox}ic Subword \textbf{Prun}ing (ToxPrune) to prune the subword contained by the toxic words from BPE in trained LLMs. In contrast to the previous work that demonstrates pruning BPE tokens as harmful to the task of machine translation, we surprisingly found its usefulness in preventing toxic content from being generated on LLMs. Fortunately, our findings suggest that ToxPrune simultaneously improves the toxic language model NSFW-3B on the task of dialogue response generation obviously. We surprisingly found that ToxPrune can even obviously improve official Llama-3.1-6B in the metric of dialogue diversity. Extensive automatic results and human evaluation indicate that ToxPrune could be helpful for both remediating toxic LLMs and improving non-toxic LLMs on the task of dialogue response generation.\footnote{We plan to release the resources to facilitate future work.}",,,,, CoRR,  ,,detox,
2779,"**Title**Leveraging Large Language Models and Topic Modeling for Toxicity Classification

**Abstract**Abstract:Content moderation and toxicity classification represent critical tasks with significant social implications. However, studies have shown that major classification models exhibit tendencies to magnify or reduce biases and potentially overlook or disadvantage certain marginalized groups within their classification processes. Researchers suggest that the positionality of annotators influences the gold standard labels in which the models learned from propagate annotators' bias. To further investigate the impact of annotator positionality, we delve into fine-tuning BERTweet and HateBERT on the dataset while using topic-modeling strategies for content moderation. The results indicate that fine-tuning the models on specific topics results in a notable improvement in the F1 score of the models when compared to the predictions generated by other prominent classification models such as GPT-4, PerspectiveAPI, and RewireAPI. These findings further reveal that the state-of-the-art large language models exhibit significant limitations in accurately detecting and interpreting text toxicity contrasted with earlier methodologies. Code is available at this https URL.","Oskouie HE,Chance C,Huang C,Capetz M,Eyeson E,Sarrafzadeh M",,,Leveraging Large Language Models and Topic Modeling for Toxicity Classification,abs/2411.17876,,10.48550/ARXIV.2411.17876 , Journal Article,,"Abstract:Content moderation and toxicity classification represent critical tasks with significant social implications. However, studies have shown that major classification models exhibit tendencies to magnify or reduce biases and potentially overlook or disadvantage certain marginalized groups within their classification processes. Researchers suggest that the positionality of annotators influences the gold standard labels in which the models learned from propagate annotators' bias. To further investigate the impact of annotator positionality, we delve into fine-tuning BERTweet and HateBERT on the dataset while using topic-modeling strategies for content moderation. The results indicate that fine-tuning the models on specific topics results in a notable improvement in the F1 score of the models when compared to the predictions generated by other prominent classification models such as GPT-4, PerspectiveAPI, and RewireAPI. These findings further reveal that the state-of-the-art large language models exhibit significant limitations in accurately detecting and interpreting text toxicity contrasted with earlier methodologies. Code is available at this https URL.",,,,, CoRR,  ,,detection,
2780,"**Title**Hierarchical Adversarial Correction to Mitigate Identity Term Bias in Toxicity Detection

**Abstract**Corpora that are the fundament for toxicity de-
    tection contain such expressions typically di-
    rected against a target individual or group, e.g.,
    people of a specific gender or ethnicity. Prior
   work has shown that the target identity mention
    can constitute a confounding variable. As an ex-
    ample, a model might learn that Christians are
    always mentioned in the context of hate speech.
    This misguided focus can lead to a limited gen-
    eralization to newly emerging targets that are
    not found in the training data. In this paper, we
    hypothesize and subsequently show that this is-
    sue can be mitigated by considering targets on
    different levels of specificity. We distinguish
     levels of (1) the existence of a target, (2) a class
     (e.g., that the target is a religious group), or
    (3) a specific target group (e.g., Christians or
    Muslims). We define a target label hierarchy
    based on these three levels and then exploit this
    hierarchy in an adversarial correction for the
    lowest level (i.e. (3)) while maintaining some
    basic target features. This approach does not
    lower the toxicity detection performance but
    increases the generalization to targets not being
    available at training time.

1  Introduction

The EU Code of conduct on countering illegal hate
speech online relies on the definition of hate speech
as “all conduct publicly inciting to violence or ha-
tred directed against a group of persons or a mem-
ber of such a group defined by reference to race,
colour, religion, descent or national or ethnic ori-
gin.”1,2 This definition points out the role of the
target in hate speech, which is one form of toxicity
in text, next to other offensive language (Leite et al.,
2020). Targets as a constituting element already

   1This paper contains some examples of toxicity. This is
strictly for the purpose of explaining subtleties of the phe-
nomenon that are important for this research. Please be aware
that this content could be offensive and cause you distress.
   2https://ec.europa.eu/newsroom/just/document.
cfm?doc_id=42985received some attention in previous work (Silva
et al., 2016; Lemmens et al., 2021, i.a.).
  Hate speech expressions vary a lot, from ex-
plicit formulations to more implicit, and sometimes
even intentionally cryptic references, to bypass
automatic filters. This is an issue, because data
collection procedures can never be entirely fair –
they suffer from being focused on specific time
frames, topics, and therefore also targets (Dixon
et al., 2018). The working hypothesis in our pa-
per follows Waseem and Hovy (2016), Talat et al.
(2018) and Davidson et al. (2019) who have shown
that models learn regularly occurring target terms
as features of toxicity, because corpora developed
for annotation and training might mention poten-
tial targets predominantly in a toxic context. For
toxicity directed against less frequently mentioned
targets or where identity terms are not explicitely
mentioned (e.g., Examples #8 and #9 in Table 1), a
biased model is more apt to not detect toxicity.
  We aim at improving on this situation and pro-
pose to perform adversarial correction of toxicity
classifiers with regard to target identities.  This
leads to a challenge: How specific should the target
mention that we correct for be? Correcting for spe-
cific targets might lead to a sparsity problem while
correcting for the occurrence in a binary fashion
might not provide sufficiently specific informationtarget
occurrence?     yestoxicity?

         yesclass?identity?   Figure 1: Example for toxicity and hierarchical identity
   classification. We study if debiasing for the identity
   prediction on various levels of specificity (Occurrence
   O, Class C and Identity I) improves the robustness of
   the toxicity classification.

35. . .    . . .
           religions



             muslims“I hate muslims.”","Schäfer J,Heid U,Klinger R",,,Hierarchical Adversarial Correction to Mitigate Identity Term Bias in Toxicity Detection,,, , Conference Paper,,"Corpora that are the fundament for toxicity de-
    tection contain such expressions typically di-
    rected against a target individual or group, e.g.,
    people of a specific gender or ethnicity. Prior
   work has shown that the target identity mention
    can constitute a confounding variable. As an ex-
    ample, a model might learn that Christians are
    always mentioned in the context of hate speech.
    This misguided focus can lead to a limited gen-
    eralization to newly emerging targets that are
    not found in the training data. In this paper, we
    hypothesize and subsequently show that this is-
    sue can be mitigated by considering targets on
    different levels of specificity. We distinguish
     levels of (1) the existence of a target, (2) a class
     (e.g., that the target is a religious group), or
    (3) a specific target group (e.g., Christians or
    Muslims). We define a target label hierarchy
    based on these three levels and then exploit this
    hierarchy in an adversarial correction for the
    lowest level (i.e. (3)) while maintaining some
    basic target features. This approach does not
    lower the toxicity detection performance but
    increases the generalization to targets not being
    available at training time.

1  Introduction

The EU Code of conduct on countering illegal hate
speech online relies on the definition of hate speech
as “all conduct publicly inciting to violence or ha-
tred directed against a group of persons or a mem-
ber of such a group defined by reference to race,
colour, religion, descent or national or ethnic ori-
gin.”1,2 This definition points out the role of the
target in hate speech, which is one form of toxicity
in text, next to other offensive language (Leite et al.,
2020). Targets as a constituting element already

   1This paper contains some examples of toxicity. This is
strictly for the purpose of explaining subtleties of the phe-
nomenon that are important for this research. Please be aware
that this content could be offensive and cause you distress.
   2https://ec.europa.eu/newsroom/just/document.
cfm?doc_id=42985received some attention in previous work (Silva
et al., 2016; Lemmens et al., 2021, i.a.).
  Hate speech expressions vary a lot, from ex-
plicit formulations to more implicit, and sometimes
even intentionally cryptic references, to bypass
automatic filters. This is an issue, because data
collection procedures can never be entirely fair –
they suffer from being focused on specific time
frames, topics, and therefore also targets (Dixon
et al., 2018). The working hypothesis in our pa-
per follows Waseem and Hovy (2016), Talat et al.
(2018) and Davidson et al. (2019) who have shown
that models learn regularly occurring target terms
as features of toxicity, because corpora developed
for annotation and training might mention poten-
tial targets predominantly in a toxic context. For
toxicity directed against less frequently mentioned
targets or where identity terms are not explicitely
mentioned (e.g., Examples #8 and #9 in Table 1), a
biased model is more apt to not detect toxicity.
  We aim at improving on this situation and pro-
pose to perform adversarial correction of toxicity
classifiers with regard to target identities.  This
leads to a challenge: How specific should the target
mention that we correct for be? Correcting for spe-
cific targets might lead to a sparsity problem while
correcting for the occurrence in a binary fashion
might not provide sufficiently specific informationtarget
occurrence?     yestoxicity?

         yesclass?identity?   Figure 1: Example for toxicity and hierarchical identity
   classification. We study if debiasing for the identity
   prediction on various levels of specificity (Occurrence
   O, Class C and Identity I) improves the robustness of
   the toxicity classification.

35. . .    . . .
           religions



             muslims“I hate muslims.”",,,,,Association for Computational Linguistics ,"Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis, WASSA 2024, Bangkok, Thailand, August 15, 2024  ",,detection#methodology,
2781,"**Title**Implanting LLM's Knowledge via Reading Comprehension Tree for Toxicity Detection

**Abstract**Warning: This paper contains several toxic
and offensive statements.    Toxicity detection plays a crucial role in main-
    taining the peace of the society. Existing meth-
    ods can be roughly categorized as small lan-
    guage model (SLM) based and large language
    model (LLM) based. However, due to the limi-
     tation of SLMs on general knowledge and the
     potential embedded bias in LLMs despite their
    large amount of knowledge, it is not a good
    idea to detect toxicity only with either SLM or
  LLM based method.
    In this work, we propose to implant LLM’s
    knowledge into SLM based methods such that
   we can stick to both types of models’ strengths.
   To this end, we develop a reading comprehen-
    sion (RC) tree to transfer knowledge between
   two models.  Specifically, we first construct
    the RC tree, from an extensive to intensive
    reading perspective, to capture the local and
    global information in the text. We then model
    samples encoded by SLM and knowledge ex-
    tracted from LLM as two distributions using
    the constructed RT tree. We finally transfer
    knowledge via optimal transportation between
    two distributions. Extensive experiments prove
    the effectiveness of our method on real-world
    and machine-generated datasets. Our code and
    data are available at https://github.com/
    khk-abc/toxic-detection.

1  Introduction

With the prevailing of online communication, toxic
content has been growing in recent years on the
websites. In addition, the malicious use of large
language models makes toxic language more com-
mon and difficult to detect. Toxic language may
result in serious hazards such as the promotion of
violent crimes and discrimination against marginal-
ized groups. Due to its harmfulness to individuals

    ∗Corresponding author.Figure 1: Illustration of the shortcomings of SLM (here
RoBERTa) and LLM (here ChatGPT) based methods
for toxicity detection.

and society (Shakespeare, 2013), toxic language
has become a serious concern.
  The harm of toxic content can be prevented ei-
ther by pre-detection before online release or by
post-detection before spreading to a broader au-
dience, and thus the detection of toxic content
plays a crucial role in controlling toxicity. Existing
methods for this purpose can be roughly catego-
rized into small language model (SLM) based and
large language model (LLM) based types. The fine-
tuned SLM based methods (Antypas and Camacho-
Collados, 2023; He et al., 2023) are the mainstream.
Due to the limited knowledge, the performance of
these methods is not very satisfying. Recently, a
LLM based method (Zhang et al., 2023a) is pre-
sented for this task.  However, the potential of
LLMs has not been fully exploited. More impor-
tantly, LLMs have their own bias which may lead to
new safety issues (Liyanage and Ranaweera, 2023;
Leong et al., 2023; Zhang et al., 2024).
  As  Fig. 1  (a) and  (b) show,  neither  the
RoBERTa (Liu et al., 2019) based method nor Chat-
GPT (OpenAI, 2022) can make a correct prediction
about the given sample. To have a close look, we
let two language models paraphrase ‘cockroaches’
and ’scorpions’ by masking these two words for947","Kang H,Qian T",,,Implanting LLM's Knowledge via Reading Comprehension Tree for Toxicity Detection,,,10.18653/V1/2024.FINDINGS-ACL.56 , Conference Paper,,"Warning: This paper contains several toxic
and offensive statements.    Toxicity detection plays a crucial role in main-
    taining the peace of the society. Existing meth-
    ods can be roughly categorized as small lan-
    guage model (SLM) based and large language
    model (LLM) based. However, due to the limi-
     tation of SLMs on general knowledge and the
     potential embedded bias in LLMs despite their
    large amount of knowledge, it is not a good
    idea to detect toxicity only with either SLM or
  LLM based method.
    In this work, we propose to implant LLM’s
    knowledge into SLM based methods such that
   we can stick to both types of models’ strengths.
   To this end, we develop a reading comprehen-
    sion (RC) tree to transfer knowledge between
   two models.  Specifically, we first construct
    the RC tree, from an extensive to intensive
    reading perspective, to capture the local and
    global information in the text. We then model
    samples encoded by SLM and knowledge ex-
    tracted from LLM as two distributions using
    the constructed RT tree. We finally transfer
    knowledge via optimal transportation between
    two distributions. Extensive experiments prove
    the effectiveness of our method on real-world
    and machine-generated datasets. Our code and
    data are available at https://github.com/
    khk-abc/toxic-detection.

1  Introduction

With the prevailing of online communication, toxic
content has been growing in recent years on the
websites. In addition, the malicious use of large
language models makes toxic language more com-
mon and difficult to detect. Toxic language may
result in serious hazards such as the promotion of
violent crimes and discrimination against marginal-
ized groups. Due to its harmfulness to individuals

    ∗Corresponding author.Figure 1: Illustration of the shortcomings of SLM (here
RoBERTa) and LLM (here ChatGPT) based methods
for toxicity detection.

and society (Shakespeare, 2013), toxic language
has become a serious concern.
  The harm of toxic content can be prevented ei-
ther by pre-detection before online release or by
post-detection before spreading to a broader au-
dience, and thus the detection of toxic content
plays a crucial role in controlling toxicity. Existing
methods for this purpose can be roughly catego-
rized into small language model (SLM) based and
large language model (LLM) based types. The fine-
tuned SLM based methods (Antypas and Camacho-
Collados, 2023; He et al., 2023) are the mainstream.
Due to the limited knowledge, the performance of
these methods is not very satisfying. Recently, a
LLM based method (Zhang et al., 2023a) is pre-
sented for this task.  However, the potential of
LLMs has not been fully exploited. More impor-
tantly, LLMs have their own bias which may lead to
new safety issues (Liyanage and Ranaweera, 2023;
Leong et al., 2023; Zhang et al., 2024).
  As  Fig. 1  (a) and  (b) show,  neither  the
RoBERTa (Liu et al., 2019) based method nor Chat-
GPT (OpenAI, 2022) can make a correct prediction
about the given sample. To have a close look, we
let two language models paraphrase ‘cockroaches’
and ’scorpions’ by masking these two words for947",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024  ",,detection#methodology,
2782,"**Title**ToxVidLM: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos

**Abstract**In an era of rapidly evolving internet technol-
    ogy, the surge in multimodal content, including
    videos, has expanded the horizons of online
    communication.   However,  the  detection
    of toxic content in this diverse landscape,
    particularly  in  low-resource  code-mixed
    languages, remains a critical challenge. While
    substantial  research  has  addressed  toxic
    content detection in textual data, the realm
    of video content, especially in non-English
    languages, has been relatively underexplored.
    This paper addresses this research gap by
    introducing a benchmark dataset, the first of
     its kind, consisting of 931 videos with 4021
    code-mixed Hindi-English utterances collected
   from YouTube.  Each utterance within this
    dataset has been meticulously annotated for
     toxicity, severity, and sentiment labels. We
    have developed an advanced Multimodal Mul-
     titask framework built for Toxicity detection in
   Video Content by leveraging Language Models
   (LMs),  crafted  for  the primary  objective
    along with the additional tasks of conducting
    sentiment and severity analysis.  ToxVidLM
    incorporates three key modules – the Encoder
    module, Cross-Modal Synchronization module,
   and Multitask module – crafting a generic
    multimodal LM customized for intricate video
    classification tasks. Our experiments reveal
     that incorporating multiple modalities from the
    videos substantially enhances the performance
    of toxic content detection by achieving an
   Accuracy and Weighted F1 score of 94.29%
    and 94.35%, respectively.


    Disclaimer: The article contains profanity, an
    inevitable situation for the nature of the work
    involved. These in no way reflect the opinion
    of the authors.

   ∗Denotes an equal contribution to this work by the re-
spective authors and are jointly the first authors.
   The code and  dataset  will be made  available  at
https://github.com/justaguyalways/ToxVidLM_ACL_20241  Introduction

In an age where social media platforms empower
users to become content creators, the digital land-
scape has witnessed an unprecedented proliferation
of information dissemination. By 2023, it is esti-
mated that 82% of internet traffic will be video
content (Wilson, 2022). As a result, platforms
like YouTube and Dailymotion have become major
sources of information. A remarkable statistic un-
derscores the colossal impact of these platforms: on
YouTube alone, users collectively view more than a
billion hours of video content each day2. The viral
nature of video content is a double-edged sword:
it facilitates rapid news propagation yet simultane-
ously accelerates the dissemination of toxic speech.
We adhere to the definition of toxic speech pro-
vided by Dixon et al. (2018), which characterizes
it as ""discourteous, disrespectful, or unreasonable
language likely to compel someone to exit a discus-
sion"".
  This expansive realm of videos on platforms like
YouTube encompasses an array of topics, with the
majority of content being innocuous. However,
there exists a darker side – videos that blatantly con-
travene community guidelines and foster harmful
narratives (O’Connor, 2021). The non-removal of
toxic content from these platforms can have severe
repercussions, including the formation of hostile
online environments with echo chambers of hateful
users, potential loss of revenue, fines, and legal
entanglements3. While some platforms deploy hu-
man moderators to identify and remove harmful
content, the sheer volume of daily user-generated
content poses an overwhelming challenge. Face-
book, for instance, engages approximately 15,000
moderators to review content flagged by both AI
algorithms and users but still faces approximately

    2https://blog.youtube/press/
    3https://www.wsj.com/articles/germany-to-social-
networks-delete-hate-speech-faster-or-face-fines-
149875767911130","Maity K,Sangeetha P,Saha S,Bhattacharyya P",,,ToxVidLM: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos,,,10.18653/V1/2024.FINDINGS-ACL.663 , Conference Paper,,"In an era of rapidly evolving internet technol-
    ogy, the surge in multimodal content, including
    videos, has expanded the horizons of online
    communication.   However,  the  detection
    of toxic content in this diverse landscape,
    particularly  in  low-resource  code-mixed
    languages, remains a critical challenge. While
    substantial  research  has  addressed  toxic
    content detection in textual data, the realm
    of video content, especially in non-English
    languages, has been relatively underexplored.
    This paper addresses this research gap by
    introducing a benchmark dataset, the first of
     its kind, consisting of 931 videos with 4021
    code-mixed Hindi-English utterances collected
   from YouTube.  Each utterance within this
    dataset has been meticulously annotated for
     toxicity, severity, and sentiment labels. We
    have developed an advanced Multimodal Mul-
     titask framework built for Toxicity detection in
   Video Content by leveraging Language Models
   (LMs),  crafted  for  the primary  objective
    along with the additional tasks of conducting
    sentiment and severity analysis.  ToxVidLM
    incorporates three key modules – the Encoder
    module, Cross-Modal Synchronization module,
   and Multitask module – crafting a generic
    multimodal LM customized for intricate video
    classification tasks. Our experiments reveal
     that incorporating multiple modalities from the
    videos substantially enhances the performance
    of toxic content detection by achieving an
   Accuracy and Weighted F1 score of 94.29%
    and 94.35%, respectively.


    Disclaimer: The article contains profanity, an
    inevitable situation for the nature of the work
    involved. These in no way reflect the opinion
    of the authors.

   ∗Denotes an equal contribution to this work by the re-
spective authors and are jointly the first authors.
   The code and  dataset  will be made  available  at
https://github.com/justaguyalways/ToxVidLM_ACL_20241  Introduction

In an age where social media platforms empower
users to become content creators, the digital land-
scape has witnessed an unprecedented proliferation
of information dissemination. By 2023, it is esti-
mated that 82% of internet traffic will be video
content (Wilson, 2022). As a result, platforms
like YouTube and Dailymotion have become major
sources of information. A remarkable statistic un-
derscores the colossal impact of these platforms: on
YouTube alone, users collectively view more than a
billion hours of video content each day2. The viral
nature of video content is a double-edged sword:
it facilitates rapid news propagation yet simultane-
ously accelerates the dissemination of toxic speech.
We adhere to the definition of toxic speech pro-
vided by Dixon et al. (2018), which characterizes
it as ""discourteous, disrespectful, or unreasonable
language likely to compel someone to exit a discus-
sion"".
  This expansive realm of videos on platforms like
YouTube encompasses an array of topics, with the
majority of content being innocuous. However,
there exists a darker side – videos that blatantly con-
travene community guidelines and foster harmful
narratives (O’Connor, 2021). The non-removal of
toxic content from these platforms can have severe
repercussions, including the formation of hostile
online environments with echo chambers of hateful
users, potential loss of revenue, fines, and legal
entanglements3. While some platforms deploy hu-
man moderators to identify and remove harmful
content, the sheer volume of daily user-generated
content poses an overwhelming challenge. Face-
book, for instance, engages approximately 15,000
moderators to review content flagged by both AI
algorithms and users but still faces approximately

    2https://blog.youtube/press/
    3https://www.wsj.com/articles/germany-to-social-
networks-delete-hate-speech-faster-or-face-fines-
149875767911130",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024  ",,out_of_scope,
2783,"**Title**E\(^2\)T\(^2\): Emote Embedding for Twitch Toxicity Detection

**Abstract**AbstractThe Internet has become the medium of choice for socialization and communication. The rise of live streaming services has created countless online communities of varying sizes with their own jokes, references, slang, and other means of communication. One of the largest live streaming services is Twitch.tv or Twitch, where a unique culture of niche language and emote usage has developed. Emotes are custom-made images, or GIFs, used in chat with varying degrees of access influenced by channel and external site subscription status. Emotes render standard forms of English Natural Language Process- ing (NLP) for tasks such as detection of toxicity or cyberbullying ineffective on Twitch. In this paper, we propose a methodology and offer a largely-trained dataset for detecting emote-based toxicity on live streaming platforms such as Twitch.","Moosavi K,Martin E,Ahmad MA,Mashhadi A",,,E\(^2\)T\(^2\): Emote Embedding for Twitch Toxicity Detection,,,10.1145/3678884.3681840 , Conference Paper,,"AbstractThe Internet has become the medium of choice for socialization and communication. The rise of live streaming services has created countless online communities of varying sizes with their own jokes, references, slang, and other means of communication. One of the largest live streaming services is Twitch.tv or Twitch, where a unique culture of niche language and emote usage has developed. Emotes are custom-made images, or GIFs, used in chat with varying degrees of access influenced by channel and external site subscription status. Emotes render standard forms of English Natural Language Process- ing (NLP) for tasks such as detection of toxicity or cyberbullying ineffective on Twitch. In this paper, we propose a methodology and offer a largely-trained dataset for detecting emote-based toxicity on live streaming platforms such as Twitch.",,,,,ACM ,"Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing, CSCW Companion 2024, San Jose, Costa Rica, November 9-13, 2024  ",,Gen_dataset#detection,
2784,"**Title**Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method

**Abstract**Extensive efforts in automated approaches for
    content moderation have been focused on devel-
    oping models to identify toxic, offensive, and
    hateful content with the aim of lightening the
    load for moderators. Yet, it remains uncertain
    whether improvements on those tasks have truly
    addressed moderators’ needs in accomplishing
     their work. In this paper, we surface gaps be-
    tween past research efforts that have aimed to
    provide automation for aspects of content mod-
     eration and the needs of volunteer content mod-
     erators, regarding identifying violations of var-
    ious moderation rules. To do so, we conduct
    a model review on Hugging Face to reveal the
     availability of models to cover various modera-
    tion rules and guidelines from three exemplar
    forums. We further put state-of-the-art LLMs
    to the test, evaluating how well these models
    perform in flagging violations of platform rules
    from one particular forum. Finally, we conduct
    a user survey study with volunteer moderators
     to gain insight into their perspectives on useful
    moderation models. Overall, we observe a non-
     trivial gap, as missing developed models and
   LLMs exhibit moderate to low performance
   on a significant portion of the rules. Modera-
     tors’ reports provide guides for future work on
    developing moderation assistant models.
1  Introduction
Content moderation guards online forums against
hostility and extremism while maintaining commu-
nity norms, ensuring the forums remain healthy
and open to all participants. While many platforms
pay for this service, others, such as Reddit, Discord,
Facebook, and Twitch, use a hybrid model, relying
on the labor of volunteers. Yet, behind the screen,
being a volunteer content moderator is time- and
emotionally-draining work. Moderators frequently
deal with abusive language, sensitive posts, and
unpleasant interactions with users (Seering et al.,
2019; Gilbert, 2020; Dosono and Semaan, 2019;
Wohn, 2019; Jiang et al., 2019), often doing thiswork in addition to full-time jobs. To support these
volunteers, efforts have been made to develop mod-
els, such as Google Perspective API1 and OpenAI
undesired content detection (Markov et al., 2023),
that can automatically identify content for removal
in order to alleviate moderators’ workload.
  Although these systems have shown great suc-
cess in detecting “undesired” content, they primar-
ily focus on toxic content. Yet, content moderation
encompasses more than toxicity detection,2 partic-
ularly in platforms that leverage volunteer modera-
tion within smaller communities hosted by the site.
For example, Reddit is a platform consisting of var-
ious communities, known as “subreddits,” focused
on a diverse set of topics, and each subreddit has
its own moderation rules. Fiesler et al. (2018) con-
ducted a study to explore various subreddit rules,
consolidating similar ones, and arrived at 25 dis-
tinct rule types. Hence, in order to support moder-
ators in detecting potential rule-violating content,
content moderation tools need to support much
more than just toxicity detection.
  In this paper, we aim to assess to what extent
current natural language processing (NLP) models
can serve the wide spectrum of moderation rules
so that they can be helpful in assisting moderators.
First, to understand the functions previous auto-
mated content moderation models have focused on,
we conduct a model review on Hugging Face (HF)
with rules from three subreddits as exemplars. This
allows us to gauge the progress of past model devel-
opments in covering various moderation rules. We
use model review as opposed to the more common
literature review to gain a technical understanding
of the existing models’ functions. In addition to
examining models that are built to handle specific
tasks, we also assess so-called “general-purposed”
large language models’ (LLMs’) capability in cov-

   1https://perspectiveapi.com/
   2We use “toxicity detection” as an umbrella term for hate
speech detection, incivility detection, etc.3567","Cao YT,Domingo LF,Gilbert SA,Mazurek ML,Shilton K,Iii HD",,,Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method,,, , Conference Paper,,"Extensive efforts in automated approaches for
    content moderation have been focused on devel-
    oping models to identify toxic, offensive, and
    hateful content with the aim of lightening the
    load for moderators. Yet, it remains uncertain
    whether improvements on those tasks have truly
    addressed moderators’ needs in accomplishing
     their work. In this paper, we surface gaps be-
    tween past research efforts that have aimed to
    provide automation for aspects of content mod-
     eration and the needs of volunteer content mod-
     erators, regarding identifying violations of var-
    ious moderation rules. To do so, we conduct
    a model review on Hugging Face to reveal the
     availability of models to cover various modera-
    tion rules and guidelines from three exemplar
    forums. We further put state-of-the-art LLMs
    to the test, evaluating how well these models
    perform in flagging violations of platform rules
    from one particular forum. Finally, we conduct
    a user survey study with volunteer moderators
     to gain insight into their perspectives on useful
    moderation models. Overall, we observe a non-
     trivial gap, as missing developed models and
   LLMs exhibit moderate to low performance
   on a significant portion of the rules. Modera-
     tors’ reports provide guides for future work on
    developing moderation assistant models.
1  Introduction
Content moderation guards online forums against
hostility and extremism while maintaining commu-
nity norms, ensuring the forums remain healthy
and open to all participants. While many platforms
pay for this service, others, such as Reddit, Discord,
Facebook, and Twitch, use a hybrid model, relying
on the labor of volunteers. Yet, behind the screen,
being a volunteer content moderator is time- and
emotionally-draining work. Moderators frequently
deal with abusive language, sensitive posts, and
unpleasant interactions with users (Seering et al.,
2019; Gilbert, 2020; Dosono and Semaan, 2019;
Wohn, 2019; Jiang et al., 2019), often doing thiswork in addition to full-time jobs. To support these
volunteers, efforts have been made to develop mod-
els, such as Google Perspective API1 and OpenAI
undesired content detection (Markov et al., 2023),
that can automatically identify content for removal
in order to alleviate moderators’ workload.
  Although these systems have shown great suc-
cess in detecting “undesired” content, they primar-
ily focus on toxic content. Yet, content moderation
encompasses more than toxicity detection,2 partic-
ularly in platforms that leverage volunteer modera-
tion within smaller communities hosted by the site.
For example, Reddit is a platform consisting of var-
ious communities, known as “subreddits,” focused
on a diverse set of topics, and each subreddit has
its own moderation rules. Fiesler et al. (2018) con-
ducted a study to explore various subreddit rules,
consolidating similar ones, and arrived at 25 dis-
tinct rule types. Hence, in order to support moder-
ators in detecting potential rule-violating content,
content moderation tools need to support much
more than just toxicity detection.
  In this paper, we aim to assess to what extent
current natural language processing (NLP) models
can serve the wide spectrum of moderation rules
so that they can be helpful in assisting moderators.
First, to understand the functions previous auto-
mated content moderation models have focused on,
we conduct a model review on Hugging Face (HF)
with rules from three subreddits as exemplars. This
allows us to gauge the progress of past model devel-
opments in covering various moderation rules. We
use model review as opposed to the more common
literature review to gain a technical understanding
of the existing models’ functions. In addition to
examining models that are built to handle specific
tasks, we also assess so-called “general-purposed”
large language models’ (LLMs’) capability in cov-

   1https://perspectiveapi.com/
   2We use “toxicity detection” as an umbrella term for hate
speech detection, incivility detection, etc.3567",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,detection,
2785,"**Title**Voice Toxicity Detection Using Multi-Task Learning

**Abstract**—Toxicity is a prevalent social behavior that involves
the use of hate speech, offensive language, bullying, and abusive
speech. While text-based approaches for toxicity detection are
common, there is limited research on processing speech signals
in the physical world. Detecting toxicity in the physical world
is challenging due to the difﬁculty of integrating AI-capable
computers  into  the environment. We propose a  lightweight
transformer model based on wav2vec2.0 and optimize  it using
techniques such as quantization and knowledge distillation. Our
model uses multitask learning and achieves an average macro F1-
score of 90.3% and a weighted accuracy of 88%, outperforming
state-of-the-art methods on DeToxy-B and a public dataset. Our
results show that quantization reduces the model size by almost
4 times and RAM usage by 3.3%, with only a 1% F1 score
decrease. Knowledge distillation reduces the model size by 3.7
times, RAM usage by 1.9, and inference time by 2 times, but
decreases accuracy by 8%. Combining both techniques reduces
the model size by 14.6 times and RAM usage by around 4.3 times,
with a two-fold inference time improvement. Our compact model
is the ﬁrst end-to-end speech-based toxicity detection model based
on a lightweight transformer model suitable for deployment
in physical spaces. The results show  its feasibility for toxicity
detection on edge devices in real-world environments.


                            I. INTRODUCTION

  Toxic behavior is a social phenomenon that occurs in places
where people gather, both virtually and physically. This can
include social platforms and online gaming communities, as
well as schools, ofﬁces, and homes [1] [2]. Such toxicity can
target different groups and individuals, especially minority
communities and individuals [3]. In addition to having a
negative psychological impact on individuals, toxic language is
used in several scenarios when making threats or being violent
[4]; some laws classify such language as a crime because
it promotes discrimination and violence. This motivates the
researchers to look for effective ways to detect toxicity to
govern language and maintain a healthy environment.
   Traditional methods of identifying and managing toxic
language often require human oversight, which can be both
labor-intensive and time-consuming, making it difﬁcult to scale
effectively. While a formal and precise deﬁnition of “toxic
language” is lacking, it generally refers to any expression that
is abusive, discriminatory, hateful, offensive, or racist. Artiﬁcial
intelligence (AI)-based automated systems have emerged as
a promising solution for identifying and addressing toxic
language in both physical and virtual spaces.

  Ahlam Husni Abu Nada and Junaid Qadir are afﬁliated with Qatar University,
Doha.
  Siddique Latif is afﬁliated with Queensland University of Technology (QUT),
Australia.
  Email: siddique.latif@qut.edu.au  As the Internet continues to grow exponentially, social
networking platforms are expanding rapidly, resulting often in
toxic user interactions. Several studies have been conducted to
detect hate content on social media platforms such as Twitter,
Facebook, and online gaming, including cyberbullying [5],
hate speech [6], offensive speech [7], and sentiment detection
[8]. All of which can be classiﬁed as a single form of toxic
language that focuses on a single feature of toxicity. Detecting
toxic speech in its general meaning has also been the subject
of studies that have suggested detection techniques based on
various machine learning (ML) models [9], [10].
  Existing research on combating toxic language has, for
the most part, focused on analyzing textual content such as
comments and posts using natural language processing (NLP).
Recent advances have prompted increased interest in strategies
that focus on multimedia audiovisual data. In this paper, we
focus on sound, which is a rich source of information that can
provide valuable insights into the speaker and their surroundings
[11]. Despite the potential beneﬁts of using audio data to
detect toxic language, existing research in both online and
physical settings has been limited. This is particularly true in
physical spaces, as it has traditionally been very challenging
to seamlessly integrate computers capable of running AI and
ML models into the physical environment—however, this has
been changing recently as embedded ML and edge AI become
common [12], [13].
  Developing models for detecting toxic audio presents a
signiﬁcant challenge for researchers. The use of traditional
simple techniques has resulted in low performance in detecting
toxicity, as evidenced by previous studies [14]. To enable
accurate decision-making while accounting for diverse factors
such as acoustic and linguistic information (including semantics,
emotion, and tone), it is necessary to develop robust repre-
sentations of speech signals. These representations must be
invariant to speaker variability, background noise, reverberation,
and other natural speech variations [15]. To achieve this, a
comprehensive representation of the acoustic context of an
utterance is required, which necessitates capturing both global
and local features. In recent times, transformer-based models
have proven to be highly effective in modeling long-range
dependencies in speech and have surpassed traditional models
such as convolutional neural networks (CNNs) and recurrent
neural networks (RNNs) in a variety of speech-related tasks,
including speech recognition, emotion recognition, and speaker
identiﬁcation [16]–[18].
  Furthermore, detecting toxic language in real-world contexts
through audio modality  presents an  additional  challenge.
Speciﬁcally, the deployment of the trained model on an edge","Nandwana MK,He Y,Liu J,Yu X,Shang C,du Bois E,McGuire M,Bhat K",,,Voice Toxicity Detection Using Multi-Task Learning,,,10.1109/ICASSP48485.2024.10448289 , Conference Paper,,"—Toxicity is a prevalent social behavior that involves
the use of hate speech, offensive language, bullying, and abusive
speech. While text-based approaches for toxicity detection are
common, there is limited research on processing speech signals
in the physical world. Detecting toxicity in the physical world
is challenging due to the difﬁculty of integrating AI-capable
computers  into  the environment. We propose a  lightweight
transformer model based on wav2vec2.0 and optimize  it using
techniques such as quantization and knowledge distillation. Our
model uses multitask learning and achieves an average macro F1-
score of 90.3% and a weighted accuracy of 88%, outperforming
state-of-the-art methods on DeToxy-B and a public dataset. Our
results show that quantization reduces the model size by almost
4 times and RAM usage by 3.3%, with only a 1% F1 score
decrease. Knowledge distillation reduces the model size by 3.7
times, RAM usage by 1.9, and inference time by 2 times, but
decreases accuracy by 8%. Combining both techniques reduces
the model size by 14.6 times and RAM usage by around 4.3 times,
with a two-fold inference time improvement. Our compact model
is the ﬁrst end-to-end speech-based toxicity detection model based
on a lightweight transformer model suitable for deployment
in physical spaces. The results show  its feasibility for toxicity
detection on edge devices in real-world environments.


                            I. INTRODUCTION

  Toxic behavior is a social phenomenon that occurs in places
where people gather, both virtually and physically. This can
include social platforms and online gaming communities, as
well as schools, ofﬁces, and homes [1] [2]. Such toxicity can
target different groups and individuals, especially minority
communities and individuals [3]. In addition to having a
negative psychological impact on individuals, toxic language is
used in several scenarios when making threats or being violent
[4]; some laws classify such language as a crime because
it promotes discrimination and violence. This motivates the
researchers to look for effective ways to detect toxicity to
govern language and maintain a healthy environment.
   Traditional methods of identifying and managing toxic
language often require human oversight, which can be both
labor-intensive and time-consuming, making it difﬁcult to scale
effectively. While a formal and precise deﬁnition of “toxic
language” is lacking, it generally refers to any expression that
is abusive, discriminatory, hateful, offensive, or racist. Artiﬁcial
intelligence (AI)-based automated systems have emerged as
a promising solution for identifying and addressing toxic
language in both physical and virtual spaces.

  Ahlam Husni Abu Nada and Junaid Qadir are afﬁliated with Qatar University,
Doha.
  Siddique Latif is afﬁliated with Queensland University of Technology (QUT),
Australia.
  Email: siddique.latif@qut.edu.au  As the Internet continues to grow exponentially, social
networking platforms are expanding rapidly, resulting often in
toxic user interactions. Several studies have been conducted to
detect hate content on social media platforms such as Twitter,
Facebook, and online gaming, including cyberbullying [5],
hate speech [6], offensive speech [7], and sentiment detection
[8]. All of which can be classiﬁed as a single form of toxic
language that focuses on a single feature of toxicity. Detecting
toxic speech in its general meaning has also been the subject
of studies that have suggested detection techniques based on
various machine learning (ML) models [9], [10].
  Existing research on combating toxic language has, for
the most part, focused on analyzing textual content such as
comments and posts using natural language processing (NLP).
Recent advances have prompted increased interest in strategies
that focus on multimedia audiovisual data. In this paper, we
focus on sound, which is a rich source of information that can
provide valuable insights into the speaker and their surroundings
[11]. Despite the potential beneﬁts of using audio data to
detect toxic language, existing research in both online and
physical settings has been limited. This is particularly true in
physical spaces, as it has traditionally been very challenging
to seamlessly integrate computers capable of running AI and
ML models into the physical environment—however, this has
been changing recently as embedded ML and edge AI become
common [12], [13].
  Developing models for detecting toxic audio presents a
signiﬁcant challenge for researchers. The use of traditional
simple techniques has resulted in low performance in detecting
toxicity, as evidenced by previous studies [14]. To enable
accurate decision-making while accounting for diverse factors
such as acoustic and linguistic information (including semantics,
emotion, and tone), it is necessary to develop robust repre-
sentations of speech signals. These representations must be
invariant to speaker variability, background noise, reverberation,
and other natural speech variations [15]. To achieve this, a
comprehensive representation of the acoustic context of an
utterance is required, which necessitates capturing both global
and local features. In recent times, transformer-based models
have proven to be highly effective in modeling long-range
dependencies in speech and have surpassed traditional models
such as convolutional neural networks (CNNs) and recurrent
neural networks (RNNs) in a variety of speech-related tasks,
including speech recognition, emotion recognition, and speaker
identiﬁcation [16]–[18].
  Furthermore, detecting toxic language in real-world contexts
through audio modality  presents an  additional  challenge.
Speciﬁcally, the deployment of the trained model on an edge",,,,,IEEE ,"IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2024, Seoul, Republic of Korea, April 14-19, 2024  ",,out_but_toxicity,
2786,"**Title**Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and Generation

**Abstract**Abstract:Large Language Models (LLMs) drive current AI breakthroughs despite very little being known about their internal representations. In this work, we propose to shed the light on LLMs inner mechanisms through the lens of geometry. In particular, we develop in closed form $(i)$ the intrinsic dimension in which the Multi-Head Attention embeddings are constrained to exist and $(ii)$ the partition and per-region affine mappings of the feedforward (MLP) network of LLMs' layers. Our theoretical findings further enable the design of novel principled solutions applicable to state-of-the-art LLMs. First, we show that, through our geometric understanding, we can bypass LLMs' RLHF protection by controlling the embedding's intrinsic dimension through informed prompt manipulation. Second, we derive interpretable geometrical features that can be extracted from any (pre-trained) LLM, providing a rich abstract representation of their inputs. We observe that these features are sufficient to help solve toxicity detection, and even allow the identification of various types of toxicity. Our results demonstrate how, even in large-scale regimes, exact theoretical results can answer practical questions in LLMs. Code: this https URL","Balestriero R,Cosentino R,Shekkizhar S",,,Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and Generation,,, , Conference Paper,,"Abstract:Large Language Models (LLMs) drive current AI breakthroughs despite very little being known about their internal representations. In this work, we propose to shed the light on LLMs inner mechanisms through the lens of geometry. In particular, we develop in closed form $(i)$ the intrinsic dimension in which the Multi-Head Attention embeddings are constrained to exist and $(ii)$ the partition and per-region affine mappings of the feedforward (MLP) network of LLMs' layers. Our theoretical findings further enable the design of novel principled solutions applicable to state-of-the-art LLMs. First, we show that, through our geometric understanding, we can bypass LLMs' RLHF protection by controlling the embedding's intrinsic dimension through informed prompt manipulation. Second, we derive interpretable geometrical features that can be extracted from any (pre-trained) LLM, providing a rich abstract representation of their inputs. We observe that these features are sufficient to help solve toxicity detection, and even allow the identification of various types of toxicity. Our results demonstrate how, even in large-scale regimes, exact theoretical results can answer practical questions in LLMs. Code: this https URL",,,,,OpenReview.net ,"Forty-first International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024  ",,detox,
2787,"**Title**Toxicity Detection for Free

**Abstract**Abstract:Current LLMs are generally aligned to follow safety requirements and tend to refuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be overcautious and refuse benign examples. In addition, state-of-the-art toxicity detectors have low TPRs at low FPR, incurring high costs in real-world applications where toxic examples are rare. In this paper, we introduce Moderation Using LLM Introspection (MULI), which detects toxic prompts using the information extracted directly from LLMs themselves. We found we can distinguish between benign and toxic prompts from the distribution of the first response token's logits. Using this idea, we build a robust detector of toxic prompts using a sparse logistic regression model on the first response token logits. Our scheme outperforms SOTA detectors under multiple metrics.","Hu Z,Piet J,Zhao G,Jiao J,Wagner DA",,,Toxicity Detection for Free,,, , Conference Paper,,"Abstract:Current LLMs are generally aligned to follow safety requirements and tend to refuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be overcautious and refuse benign examples. In addition, state-of-the-art toxicity detectors have low TPRs at low FPR, incurring high costs in real-world applications where toxic examples are rare. In this paper, we introduce Moderation Using LLM Introspection (MULI), which detects toxic prompts using the information extracted directly from LLMs themselves. We found we can distinguish between benign and toxic prompts from the distribution of the first response token's logits. Using this idea, we build a robust detector of toxic prompts using a sparse logistic regression model on the first response token logits. Our scheme outperforms SOTA detectors under multiple metrics.",,,,, ,"Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024  ",,detection#methodology,
2788,"**Title**A Critical Reflection on the Use of Toxicity Detection Algorithms in Proactive Content Moderation Systems

**Abstract**Abstract:Toxicity detection algorithms, originally designed with reactive content moderation in mind, are increasingly being deployed into proactive end-user interventions to moderate content. Through a socio-technical lens and focusing on contexts in which they are applied, we explore the use of these algorithms in proactive moderation systems. Placing a toxicity detection algorithm in an imagined virtual mobile keyboard, we critically explore how such algorithms could be used to proactively reduce the sending of toxic content. We present findings from design workshops conducted with four distinct stakeholder groups and find concerns around how contextual complexities may exasperate inequalities around content moderation processes. Whilst only specific user groups are likely to directly benefit from these interventions, we highlight the potential for other groups to misuse them to circumvent detection, validate and gamify hate, and manipulate algorithmic models to exasperate harm.","Warner M,Strohmayer A,Higgs M,Coventry LM",,,A Critical Reflection on the Use of Toxicity Detection Algorithms in Proactive Content Moderation Systems,abs/2401.10629,,10.48550/ARXIV.2401.10629 , Journal Article,,"Abstract:Toxicity detection algorithms, originally designed with reactive content moderation in mind, are increasingly being deployed into proactive end-user interventions to moderate content. Through a socio-technical lens and focusing on contexts in which they are applied, we explore the use of these algorithms in proactive moderation systems. Placing a toxicity detection algorithm in an imagined virtual mobile keyboard, we critically explore how such algorithms could be used to proactively reduce the sending of toxic content. We present findings from design workshops conducted with four distinct stakeholder groups and find concerns around how contextual complexities may exasperate inequalities around content moderation processes. Whilst only specific user groups are likely to directly benefit from these interventions, we highlight the potential for other groups to misuse them to circumvent detection, validate and gamify hate, and manipulate algorithmic models to exasperate harm.",,,,, CoRR,  ,,detection,
2789,"**Title**ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in Code-Mixed Videos

**Abstract**In an era of rapidly evolving internet technol-
    ogy, the surge in multimodal content, including
    videos, has expanded the horizons of online
    communication.   However,  the  detection
    of toxic content in this diverse landscape,
    particularly  in  low-resource  code-mixed
    languages, remains a critical challenge. While
    substantial  research  has  addressed  toxic
    content detection in textual data, the realm
    of video content, especially in non-English
    languages, has been relatively underexplored.
    This paper addresses this research gap by
    introducing a benchmark dataset, the first of
     its kind, consisting of 931 videos with 4021
    code-mixed Hindi-English utterances collected
   from YouTube.  Each utterance within this
    dataset has been meticulously annotated for
     toxicity, severity, and sentiment labels. We
    have developed an advanced Multimodal Mul-
     titask framework built for Toxicity detection in
   Video Content by leveraging Language Models
   (LMs),  crafted  for  the primary  objective
    along with the additional tasks of conducting
    sentiment and severity analysis.  ToxVidLM
    incorporates three key modules – the Encoder
    module, Cross-Modal Synchronization module,
   and Multitask module – crafting a generic
    multimodal LM customized for intricate video
    classification tasks. Our experiments reveal
     that incorporating multiple modalities from the
    videos substantially enhances the performance
    of toxic content detection by achieving an
   Accuracy and Weighted F1 score of 94.29%
    and 94.35%, respectively.


    Disclaimer: The article contains profanity, an
    inevitable situation for the nature of the work
    involved. These in no way reflect the opinion
    of the authors.

   ∗Denotes an equal contribution to this work by the re-
spective authors and are jointly the first authors.
   The code and  dataset  will be made  available  at
https://github.com/justaguyalways/ToxVidLM_ACL_20241  Introduction

In an age where social media platforms empower
users to become content creators, the digital land-
scape has witnessed an unprecedented proliferation
of information dissemination. By 2023, it is esti-
mated that 82% of internet traffic will be video
content (Wilson, 2022). As a result, platforms
like YouTube and Dailymotion have become major
sources of information. A remarkable statistic un-
derscores the colossal impact of these platforms: on
YouTube alone, users collectively view more than a
billion hours of video content each day2. The viral
nature of video content is a double-edged sword:
it facilitates rapid news propagation yet simultane-
ously accelerates the dissemination of toxic speech.
We adhere to the definition of toxic speech pro-
vided by Dixon et al. (2018), which characterizes
it as ""discourteous, disrespectful, or unreasonable
language likely to compel someone to exit a discus-
sion"".
  This expansive realm of videos on platforms like
YouTube encompasses an array of topics, with the
majority of content being innocuous. However,
there exists a darker side – videos that blatantly con-
travene community guidelines and foster harmful
narratives (O’Connor, 2021). The non-removal of
toxic content from these platforms can have severe
repercussions, including the formation of hostile
online environments with echo chambers of hateful
users, potential loss of revenue, fines, and legal
entanglements3. While some platforms deploy hu-
man moderators to identify and remove harmful
content, the sheer volume of daily user-generated
content poses an overwhelming challenge. Face-
book, for instance, engages approximately 15,000
moderators to review content flagged by both AI
algorithms and users but still faces approximately

    2https://blog.youtube/press/
    3https://www.wsj.com/articles/germany-to-social-
networks-delete-hate-speech-faster-or-face-fines-
149875767911130","Maity K,Poornash AS,Saha S,Bhattacharyya P",,,ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in Code-Mixed Videos,abs/2405.20628,,10.48550/ARXIV.2405.20628 , Journal Article,,"In an era of rapidly evolving internet technol-
    ogy, the surge in multimodal content, including
    videos, has expanded the horizons of online
    communication.   However,  the  detection
    of toxic content in this diverse landscape,
    particularly  in  low-resource  code-mixed
    languages, remains a critical challenge. While
    substantial  research  has  addressed  toxic
    content detection in textual data, the realm
    of video content, especially in non-English
    languages, has been relatively underexplored.
    This paper addresses this research gap by
    introducing a benchmark dataset, the first of
     its kind, consisting of 931 videos with 4021
    code-mixed Hindi-English utterances collected
   from YouTube.  Each utterance within this
    dataset has been meticulously annotated for
     toxicity, severity, and sentiment labels. We
    have developed an advanced Multimodal Mul-
     titask framework built for Toxicity detection in
   Video Content by leveraging Language Models
   (LMs),  crafted  for  the primary  objective
    along with the additional tasks of conducting
    sentiment and severity analysis.  ToxVidLM
    incorporates three key modules – the Encoder
    module, Cross-Modal Synchronization module,
   and Multitask module – crafting a generic
    multimodal LM customized for intricate video
    classification tasks. Our experiments reveal
     that incorporating multiple modalities from the
    videos substantially enhances the performance
    of toxic content detection by achieving an
   Accuracy and Weighted F1 score of 94.29%
    and 94.35%, respectively.


    Disclaimer: The article contains profanity, an
    inevitable situation for the nature of the work
    involved. These in no way reflect the opinion
    of the authors.

   ∗Denotes an equal contribution to this work by the re-
spective authors and are jointly the first authors.
   The code and  dataset  will be made  available  at
https://github.com/justaguyalways/ToxVidLM_ACL_20241  Introduction

In an age where social media platforms empower
users to become content creators, the digital land-
scape has witnessed an unprecedented proliferation
of information dissemination. By 2023, it is esti-
mated that 82% of internet traffic will be video
content (Wilson, 2022). As a result, platforms
like YouTube and Dailymotion have become major
sources of information. A remarkable statistic un-
derscores the colossal impact of these platforms: on
YouTube alone, users collectively view more than a
billion hours of video content each day2. The viral
nature of video content is a double-edged sword:
it facilitates rapid news propagation yet simultane-
ously accelerates the dissemination of toxic speech.
We adhere to the definition of toxic speech pro-
vided by Dixon et al. (2018), which characterizes
it as ""discourteous, disrespectful, or unreasonable
language likely to compel someone to exit a discus-
sion"".
  This expansive realm of videos on platforms like
YouTube encompasses an array of topics, with the
majority of content being innocuous. However,
there exists a darker side – videos that blatantly con-
travene community guidelines and foster harmful
narratives (O’Connor, 2021). The non-removal of
toxic content from these platforms can have severe
repercussions, including the formation of hostile
online environments with echo chambers of hateful
users, potential loss of revenue, fines, and legal
entanglements3. While some platforms deploy hu-
man moderators to identify and remove harmful
content, the sheer volume of daily user-generated
content poses an overwhelming challenge. Face-
book, for instance, engages approximately 15,000
moderators to review content flagged by both AI
algorithms and users but still faces approximately

    2https://blog.youtube/press/
    3https://www.wsj.com/articles/germany-to-social-
networks-delete-hate-speech-faster-or-face-fines-
149875767911130",,,,, CoRR,  ,,out_but_toxicity,
2790,"**Title**Enhancing Multilingual Voice Toxicity Detection with Speech-Text Alignment

**Abstract**Abstract:Toxicity classification for voice heavily relies on the semantic content of speech. We propose a novel framework that utilizes cross-modal learning to integrate the semantic embedding of text into a multilabel speech toxicity classifier during training. This enables us to incorporate textual information during training while still requiring only audio during inference. We evaluate this classifier on large-scale datasets with real-world characteristics to validate the effectiveness of this framework. Through ablation studies, we demonstrate that general-purpose semantic text embeddings are rich and aligned with speech for toxicity classification purposes. Conducting experiments across multiple languages at scale, we show improvements in voice toxicity classification across five languages and different toxicity categories.","Liu J,Nandwana MK,Pylkkönen J,Heikinheimo H,McGuire M",,,Enhancing Multilingual Voice Toxicity Detection with Speech-Text Alignment,abs/2406.10325,,10.48550/ARXIV.2406.10325 , Journal Article,,"Abstract:Toxicity classification for voice heavily relies on the semantic content of speech. We propose a novel framework that utilizes cross-modal learning to integrate the semantic embedding of text into a multilabel speech toxicity classifier during training. This enables us to incorporate textual information during training while still requiring only audio during inference. We evaluate this classifier on large-scale datasets with real-world characteristics to validate the effectiveness of this framework. Through ablation studies, we demonstrate that general-purpose semantic text embeddings are rich and aligned with speech for toxicity classification purposes. Conducting experiments across multiple languages at scale, we show improvements in voice toxicity classification across five languages and different toxicity categories.",,,,, CoRR,  ,,out_but_toxicity,
2791,"**Title**Challenges for Real-Time Toxicity Detection in Online Games

**Abstract**AbstractReal-time toxicity detection in online environments poses a significant challenge, due to the increasing prevalence of social media and gaming platforms. We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata. ToxBuster consistently outperforms conventional toxicity models across popular multiplayer games, including Rainbow Six Siege, For Honor, and DOTA 2. We conduct an ablation study to assess the importance of each model component and explore ToxBuster’s transferability across the datasets. Furthermore, we showcase ToxBuster’s efficacy in post-game moderation, successfully flagging 82.1% of chat-reported players at a precision level of 90.0%. Additionally, we show how an additional 6% of unreported toxic players can be proactively moderated.","Ng LH,Lim AX,Yoder MM",,,Challenges for Real-Time Toxicity Detection in Online Games,abs/2407.04383,,10.48550/ARXIV.2407.04383 , Journal Article,,"AbstractReal-time toxicity detection in online environments poses a significant challenge, due to the increasing prevalence of social media and gaming platforms. We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata. ToxBuster consistently outperforms conventional toxicity models across popular multiplayer games, including Rainbow Six Siege, For Honor, and DOTA 2. We conduct an ablation study to assess the importance of each model component and explore ToxBuster’s transferability across the datasets. Furthermore, we showcase ToxBuster’s efficacy in post-game moderation, successfully flagging 82.1% of chat-reported players at a precision level of 90.0%. Additionally, we show how an additional 6% of unreported toxic players can be proactively moderated.",,,,, CoRR,  ,,detection,
2792,"**Title**Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity

**Abstract**Abstract:We introduce a novel family of adversarial attacks that exploit the inability of language models to interpret ASCII art. To evaluate these attacks, we propose the ToxASCII benchmark and develop two custom ASCII art fonts: one leveraging special tokens and another using text-filled letter shapes. Our attacks achieve a perfect 1.0 Attack Success Rate across ten models, including OpenAI's o1-preview and LLaMA 3.1.
Warning: this paper contains examples of toxic language used for research purposes.","Berezin S,Farahbakhsh R,Crespi N",,,Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity,abs/2409.18708,,10.48550/ARXIV.2409.18708 , Journal Article,,"Abstract:We introduce a novel family of adversarial attacks that exploit the inability of language models to interpret ASCII art. To evaluate these attacks, we propose the ToxASCII benchmark and develop two custom ASCII art fonts: one leveraging special tokens and another using text-filled letter shapes. Our attacks achieve a perfect 1.0 Attack Success Rate across ten models, including OpenAI's o1-preview and LLaMA 3.1.
Warning: this paper contains examples of toxic language used for research purposes.",,,,, CoRR,  ,,methodology,
2793,"**Title**DeMod: A Holistic Tool with Explainable Detection and Personalized Modification for Toxicity Censorship

**Abstract**Abstract:Although there have been automated approaches and tools supporting toxicity censorship for social posts, most of them focus on detection. Toxicity censorship is a complex process, wherein detection is just an initial task and a user can have further needs such as rationale understanding and content modification. For this problem, we conduct a needfinding study to investigate people's diverse needs in toxicity censorship and then build a ChatGPT-based censorship tool named DeMod accordingly. DeMod is equipped with the features of explainable Detection and personalized Modification, providing fine-grained detection results, detailed explanations, and personalized modification suggestions. We also implemented the tool and recruited 35 Weibo users for evaluation. The results suggest DeMod's multiple strengths like the richness of functionality, the accuracy of censorship, and ease of use. Based on the findings, we further propose several insights into the design of content censorship systems.","Li Y,Zhang P,Gu H,Lu T,Qiao S,Shu Y,Shao Y,Gu N",,,DeMod: A Holistic Tool with Explainable Detection and Personalized Modification for Toxicity Censorship,abs/2411.01844,,10.48550/ARXIV.2411.01844 , Journal Article,,"Abstract:Although there have been automated approaches and tools supporting toxicity censorship for social posts, most of them focus on detection. Toxicity censorship is a complex process, wherein detection is just an initial task and a user can have further needs such as rationale understanding and content modification. For this problem, we conduct a needfinding study to investigate people's diverse needs in toxicity censorship and then build a ChatGPT-based censorship tool named DeMod accordingly. DeMod is equipped with the features of explainable Detection and personalized Modification, providing fine-grained detection results, detailed explanations, and personalized modification suggestions. We also implemented the tool and recruited 35 Weibo users for evaluation. The results suggest DeMod's multiple strengths like the richness of functionality, the accuracy of censorship, and ease of use. Based on the findings, we further propose several insights into the design of content censorship systems.",,,,, CoRR,  ,,detection#methodology,
2794,"**Title**A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement

**Abstract**Abstract:Content moderation typically combines the efforts of human moderators and machine learning models. However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception. Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered. In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task. Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and this http URL framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review. We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.","Villate-Castillo G,Ser J,Sanz B",,,A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement,abs/2411.04090,,10.48550/ARXIV.2411.04090 , Journal Article,,"Abstract:Content moderation typically combines the efforts of human moderators and machine learning models. However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception. Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered. In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task. Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and this http URL framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review. We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.",,,,, CoRR,  ,,detection#methodology,
2795,"**Title**On the Role of Speech Data in Reducing Toxicity Detection Bias

**Abstract**Abstract:Text toxicity detection systems exhibit significant biases, producing disproportionate rates of false positives on samples mentioning demographic groups. But what about toxicity detection in speech? To investigate the extent to which text-based biases are mitigated by speech-based systems, we produce a set of high-quality group annotations for the multilingual MuTox dataset, and then leverage these annotations to systematically compare speech- and text-based toxicity classifiers. Our findings indicate that access to speech data during inference supports reduced bias against group mentions, particularly for ambiguous and disagreement-inducing samples. Our results also suggest that improving classifiers, rather than transcription pipelines, is more helpful for reducing group bias. We publicly release our annotations and provide recommendations for future toxicity dataset construction.","Bell SJ,Meglioli MC,Richards M,Sánchez E,Ropers C,Wang S,Williams A,Sagun L,Costa-jussà MR",,,On the Role of Speech Data in Reducing Toxicity Detection Bias,abs/2411.08135,,10.48550/ARXIV.2411.08135 , Journal Article,,"Abstract:Text toxicity detection systems exhibit significant biases, producing disproportionate rates of false positives on samples mentioning demographic groups. But what about toxicity detection in speech? To investigate the extent to which text-based biases are mitigated by speech-based systems, we produce a set of high-quality group annotations for the multilingual MuTox dataset, and then leverage these annotations to systematically compare speech- and text-based toxicity classifiers. Our findings indicate that access to speech data during inference supports reduced bias against group mentions, particularly for ambiguous and disagreement-inducing samples. Our results also suggest that improving classifiers, rather than transcription pipelines, is more helpful for reducing group bias. We publicly release our annotations and provide recommendations for future toxicity dataset construction.",,,,, CoRR,  ,,out_but_toxicity,
2796,"**Title**Dialectal Toxicity Detection: Evaluating LLM-as-a-Judge Consistency Across Language Varieties

**Abstract**Abstract:There has been little systematic study on how dialectal differences affect toxicity detection by modern LLMs. Furthermore, although using LLMs as evaluators (""LLM-as-a-judge"") is a growing research area, their sensitivity to dialectal nuances is still underexplored and requires more focused attention. In this paper, we address these gaps through a comprehensive toxicity evaluation of LLMs across diverse dialects. We create a multi-dialect dataset through synthetic transformations and human-assisted translations, covering 10 language clusters and 60 varieties. We then evaluated three LLMs on their ability to assess toxicity across multilingual, dialectal, and LLM-human consistency. Our findings show that LLMs are sensitive in handling both multilingual and dialectal variations. However, if we have to rank the consistency, the weakest area is LLM-human agreement, followed by dialectal consistency. Code repository: \url{this https URL}","Faisal F,Rahman MM,Anastasopoulos A",,,Dialectal Toxicity Detection: Evaluating LLM-as-a-Judge Consistency Across Language Varieties,abs/2411.10954,,10.48550/ARXIV.2411.10954 , Journal Article,,"Abstract:There has been little systematic study on how dialectal differences affect toxicity detection by modern LLMs. Furthermore, although using LLMs as evaluators (""LLM-as-a-judge"") is a growing research area, their sensitivity to dialectal nuances is still underexplored and requires more focused attention. In this paper, we address these gaps through a comprehensive toxicity evaluation of LLMs across diverse dialects. We create a multi-dialect dataset through synthetic transformations and human-assisted translations, covering 10 language clusters and 60 varieties. We then evaluated three LLMs on their ability to assess toxicity across multilingual, dialectal, and LLM-human consistency. Our findings show that LLMs are sensitive in handling both multilingual and dialectal variations. However, if we have to rank the consistency, the weakest area is LLM-human agreement, followed by dialectal consistency. Code repository: \url{this https URL}",,,,, CoRR,  ,,out_but_toxicity,
2797,"**Title**Toxicity Detection towards Adaptability to Changing Perturbations

**Abstract**Abstract:Toxicity detection is crucial for maintaining the peace of the society. While existing methods perform well on normal toxic contents or those generated by specific perturbation methods, they are vulnerable to evolving perturbation patterns. However, in real-world scenarios, malicious users tend to create new perturbation patterns for fooling the detectors. For example, some users may circumvent the detector of large language models (LLMs) by adding `I am a scientist' at the beginning of the prompt. In this paper, we introduce a novel problem, i.e., continual learning jailbreak perturbation patterns, into the toxicity detection field. To tackle this problem, we first construct a new dataset generated by 9 types of perturbation patterns, 7 of them are summarized from prior work and 2 of them are developed by us. We then systematically validate the vulnerability of current methods on this new perturbation pattern-aware dataset via both the zero-shot and fine tuned cross-pattern detection. Upon this, we present the domain incremental learning paradigm and the corresponding benchmark to ensure the detector's robustness to dynamically emerging types of perturbed toxic text. Our code and dataset are provided in the appendix and will be publicly available at GitHub, by which we wish to offer new research opportunities for the security-relevant communities.","Kang H,Chen J,Li Y,Miao X,Xu M,Zhong M,Zhu Y,Qian T",,,Toxicity Detection towards Adaptability to Changing Perturbations,abs/2412.15267,,10.48550/ARXIV.2412.15267 , Journal Article,,"Abstract:Toxicity detection is crucial for maintaining the peace of the society. While existing methods perform well on normal toxic contents or those generated by specific perturbation methods, they are vulnerable to evolving perturbation patterns. However, in real-world scenarios, malicious users tend to create new perturbation patterns for fooling the detectors. For example, some users may circumvent the detector of large language models (LLMs) by adding `I am a scientist' at the beginning of the prompt. In this paper, we introduce a novel problem, i.e., continual learning jailbreak perturbation patterns, into the toxicity detection field. To tackle this problem, we first construct a new dataset generated by 9 types of perturbation patterns, 7 of them are summarized from prior work and 2 of them are developed by us. We then systematically validate the vulnerability of current methods on this new perturbation pattern-aware dataset via both the zero-shot and fine tuned cross-pattern detection. Upon this, we present the domain incremental learning paradigm and the corresponding benchmark to ensure the detector's robustness to dynamically emerging types of perturbed toxic text. Our code and dataset are provided in the appendix and will be publicly available at GitHub, by which we wish to offer new research opportunities for the security-relevant communities.",,,,, CoRR,  ,,evaluation#methodology,
2798,"**Title**Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph

**Abstract**Abstract:The rapid growth of social media platforms has raised significant concerns regarding online content toxicity. When Large Language Models (LLMs) are used for toxicity detection, two key challenges emerge: 1) the absence of domain-specific toxic knowledge leads to false negatives; 2) the excessive sensitivity of LLMs to toxic speech results in false positives, limiting freedom of speech. To address these issues, we propose a novel method called MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance hatred and toxicity detection. First, we construct a comprehensive meta-toxic knowledge graph by utilizing LLMs to extract toxic information through a three-step pipeline, with toxic benchmark datasets serving as corpora. Second, we query the graph via retrieval and ranking processes to supplement accurate, relevant toxic knowledge. Extensive experiments and in-depth case studies across multiple datasets demonstrate that our MetaTox significantly decreases the false positive rate while boosting overall toxicity detection performance. Our code will be available soon.","Zhao Y,Zhu J,Xu C,Li X",,,Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph,abs/2412.15268,,10.48550/ARXIV.2412.15268 , Journal Article,,"Abstract:The rapid growth of social media platforms has raised significant concerns regarding online content toxicity. When Large Language Models (LLMs) are used for toxicity detection, two key challenges emerge: 1) the absence of domain-specific toxic knowledge leads to false negatives; 2) the excessive sensitivity of LLMs to toxic speech results in false positives, limiting freedom of speech. To address these issues, we propose a novel method called MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance hatred and toxicity detection. First, we construct a comprehensive meta-toxic knowledge graph by utilizing LLMs to extract toxic information through a three-step pipeline, with toxic benchmark datasets serving as corpora. Second, we query the graph via retrieval and ranking processes to supplement accurate, relevant toxic knowledge. Extensive experiments and in-depth case studies across multiple datasets demonstrate that our MetaTox significantly decreases the false positive rate while boosting overall toxicity detection performance. Our code will be available soon.",,,,, CoRR,  ,,detection,
2799,"**Title**Microbial Fuel Cell Biosensor with Capillary Carbon Source Delivery for Real-Time Toxicity Detection

**Abstract**A microbial fuel cell (MFC) biosensor with an anode as a sensing element is often unreliable at low or significantly fluctuating organic matter concentrations. To remove this limitation, this work demonstrates capillary action-aided carbon source delivery to an anode-sensing MFC biosensor for use in carbon-depleted environments, e.g., potable water. First, different carbon source delivery configurations using several thread types, silk, nylon, cotton, and polyester, are evaluated. Silk thread was determined to be the most suitable material for passive delivery of a 40 g L−1 acetate solution. This carbon source delivery system was then incorporated into the design of an MFC biosensor for real-time detection of toxicity spikes in tap water, providing an organic matter concentration of 56 ± 15 mg L−1. The biosensor was subsequently able to detect spikes of toxicants such as chlorine, formaldehyde, mercury, and cyanobacterial microcystins. The 16S sequencing results demonstrated the proliferation of Desulfatirhabdium (10.7% of the total population), Pelobacter (10.3%), and Geobacter (10.2%) genera. Overall, this work shows that the proposed approach can be used to achieve real-time toxicant detection by MFC biosensors in carbon-depleted environments.","Adekunle A,Bambace S,Tanguay-Rioux F,Tartakovsky B",,,Microbial Fuel Cell Biosensor with Capillary Carbon Source Delivery for Real-Time Toxicity Detection,23,16,10.3390/S23167065 , Journal Article,,"A microbial fuel cell (MFC) biosensor with an anode as a sensing element is often unreliable at low or significantly fluctuating organic matter concentrations. To remove this limitation, this work demonstrates capillary action-aided carbon source delivery to an anode-sensing MFC biosensor for use in carbon-depleted environments, e.g., potable water. First, different carbon source delivery configurations using several thread types, silk, nylon, cotton, and polyester, are evaluated. Silk thread was determined to be the most suitable material for passive delivery of a 40 g L−1 acetate solution. This carbon source delivery system was then incorporated into the design of an MFC biosensor for real-time detection of toxicity spikes in tap water, providing an organic matter concentration of 56 ± 15 mg L−1. The biosensor was subsequently able to detect spikes of toxicants such as chlorine, formaldehyde, mercury, and cyanobacterial microcystins. The 16S sequencing results demonstrated the proliferation of Desulfatirhabdium (10.7% of the total population), Pelobacter (10.3%), and Geobacter (10.2%) genera. Overall, this work shows that the proposed approach can be used to achieve real-time toxicant detection by MFC biosensors in carbon-depleted environments.",,,,, Sensors,  ,,out_of_scope,
2800,No abstract available,"M P,K R,Hegde A,Girish K,Coelho S,Shashirekha HL",,,Taming Toxicity: Learning Models for Hate Speech and Offensive Language Detection in Social Media Text,3681,, , Conference Paper,,,,,,,CEUR-WS.org ,"Working Notes of FIRE 2023 - Forum for Information Retrieval Evaluation (FIRE-WN 2023), Goa, India, December 15-18, 2023  ",,detection,
2801,"**Title**Automatic detection of ellipsoid zone loss due to Hydroxychloroquine retinal toxicity from SD-OCT imaging

**Abstract**Abstract
Purpose
Retinal toxicity resulting from hydroxychloroquine use manifests photoreceptor loss and disruption of the ellipsoid zone (EZ) reflectivity band detectable on spectral-domain (SD) OCT imaging. This study investigated whether an automatic deep learning-based algorithm can detect and quantitate EZ loss on SD OCT images with an accuracy comparable with that of human annotations.Design
Retrospective analysis of data acquired in a prospective, single-center, case-control study.Participants
Eighty-five patients (168 eyes) who were long-term hydroxychloroquine users (average exposure time, 14 ± 7.2 years).Methods
A mask region-based convolutional neural network (M-RCNN) was implemented and trained on individual OCT B-scans. Scan-by-scan detections were aggregated to produce an en face map of EZ loss per 3-dimensional SD OCT volume image. To improve the accuracy and robustness of the EZ loss map, a dual network architecture was proposed that learns to detect EZ loss in parallel using horizontal (horizontal mask region-based convolutional neural network [M-RCNNH]) and vertical (vertical mask region-based convolutional neural network [M-RCNNV]) B-scans independently. To quantify accuracy, 10-fold cross-validation was performed.Main Outcome Measures
Precision, recall, intersection over union (IOU), F1-score metrics, and measured total EZ loss area were compared against human grader annotations and with the determination of toxicity based on the recommended screening guidelines.Results
The combined projection network demonstrated the best overall performance: precision, 0.90 ± 0.09; recall, 0.88 ± 0.08; and F1 score, 0.89 ± 0.07. The combined model performed superiorly to the M-RCNNH only model (precision, 0.79 ± 0.17; recall, 0.96 ± 0.04; IOU, 0.78 ± 0.15; and F1 score, 0.86 ± 0.12) and M-RCNNV only model (precision, 0.71 ± 0.21; recall, 0.94 ± 0.06; IOU, 0.69 ± 0.21; and F1 score, 0.79 ± 0.16). The accuracy was comparable with the variability of human experts: precision, 0.85 ± 0.09; recall, 0.98 ± 0.01; IOU, 0.82 ± 0.12; and F1 score, 0.91 ± 0.06. Automatically generated en face EZ loss maps provide quantitative SD OCT metrics for accurate toxicity determination combined with other functional testing.Conclusions
The algorithm can provide a fast, objective, automatic method for measuring areas with EZ loss and can serve as a quantitative assistance tool to screen patients for the presence and extent of toxicity.Keywords: Automatic detection, Deep learning, Ellipsoid zone loss, Hydroxychloroquine toxicityAbbreviations and Acronyms: AAO, American Academy of Ophthalmology; CPN, combined projection network; EZ, ellipsoid zone; IOU, intersection over union; mfERG, multifocal electroretinography; M-RCNN, mask region-based convolutional neural network; M-RCNNH, horizontal mask region-based convolutional neural network; M-RCNNV, vertical mask region-based convolutional neural network; SD, spectral-domain; SNR, signal-to-noise ratio; 3D, 3-dimensional; 2D, 2-dimensional","Silva TS,Jayakar G,Grisso P,Chew EY,Hotaling N,Cukras CA",,,Automatic detection of ellipsoid zone loss due to Hydroxychloroquine retinal toxicity from SD-OCT imaging,11597,,10.1117/12.2582153 , Conference Paper,,"Abstract
Purpose
Retinal toxicity resulting from hydroxychloroquine use manifests photoreceptor loss and disruption of the ellipsoid zone (EZ) reflectivity band detectable on spectral-domain (SD) OCT imaging. This study investigated whether an automatic deep learning-based algorithm can detect and quantitate EZ loss on SD OCT images with an accuracy comparable with that of human annotations.Design
Retrospective analysis of data acquired in a prospective, single-center, case-control study.Participants
Eighty-five patients (168 eyes) who were long-term hydroxychloroquine users (average exposure time, 14 ± 7.2 years).Methods
A mask region-based convolutional neural network (M-RCNN) was implemented and trained on individual OCT B-scans. Scan-by-scan detections were aggregated to produce an en face map of EZ loss per 3-dimensional SD OCT volume image. To improve the accuracy and robustness of the EZ loss map, a dual network architecture was proposed that learns to detect EZ loss in parallel using horizontal (horizontal mask region-based convolutional neural network [M-RCNNH]) and vertical (vertical mask region-based convolutional neural network [M-RCNNV]) B-scans independently. To quantify accuracy, 10-fold cross-validation was performed.Main Outcome Measures
Precision, recall, intersection over union (IOU), F1-score metrics, and measured total EZ loss area were compared against human grader annotations and with the determination of toxicity based on the recommended screening guidelines.Results
The combined projection network demonstrated the best overall performance: precision, 0.90 ± 0.09; recall, 0.88 ± 0.08; and F1 score, 0.89 ± 0.07. The combined model performed superiorly to the M-RCNNH only model (precision, 0.79 ± 0.17; recall, 0.96 ± 0.04; IOU, 0.78 ± 0.15; and F1 score, 0.86 ± 0.12) and M-RCNNV only model (precision, 0.71 ± 0.21; recall, 0.94 ± 0.06; IOU, 0.69 ± 0.21; and F1 score, 0.79 ± 0.16). The accuracy was comparable with the variability of human experts: precision, 0.85 ± 0.09; recall, 0.98 ± 0.01; IOU, 0.82 ± 0.12; and F1 score, 0.91 ± 0.06. Automatically generated en face EZ loss maps provide quantitative SD OCT metrics for accurate toxicity determination combined with other functional testing.Conclusions
The algorithm can provide a fast, objective, automatic method for measuring areas with EZ loss and can serve as a quantitative assistance tool to screen patients for the presence and extent of toxicity.Keywords: Automatic detection, Deep learning, Ellipsoid zone loss, Hydroxychloroquine toxicityAbbreviations and Acronyms: AAO, American Academy of Ophthalmology; CPN, combined projection network; EZ, ellipsoid zone; IOU, intersection over union; mfERG, multifocal electroretinography; M-RCNN, mask region-based convolutional neural network; M-RCNNH, horizontal mask region-based convolutional neural network; M-RCNNV, vertical mask region-based convolutional neural network; SD, spectral-domain; SNR, signal-to-noise ratio; 3D, 3-dimensional; 2D, 2-dimensional",,,,,SPIE ,"Medical Imaging 2021: Computer-Aided Diagnosis, Online, February 15-20, 2021  ",,out_of_scope,
2802,"**Title**Beyond plain toxic: building datasets for detection of flammable topics and inappropriate statements

**Abstract**Abstract:Toxicity on the Internet, such as hate speech, offenses towards particular users or groups of people, or the use of obscene words, is an acknowledged problem. However, there also exist other types of inappropriate messages which are usually not viewed as toxic, e.g. as they do not contain explicit offences. Such messages can contain covered toxicity or generalizations, incite harmful actions (crime, suicide, drug use), provoke ""heated"" discussions. Such messages are often related to particular sensitive topics, e.g. on politics, sexual minorities, social injustice which more often than other topics, e.g. cars or computing, yield toxic emotional reactions. At the same time, clearly not all messages within such flammable topics are inappropriate.
Towards this end, in this work, we present two text collections labelled according to binary notion of inapropriateness and a multinomial notion of sensitive topic. Assuming that the notion of inappropriateness is common among people of the same culture, we base our approach on human intuitive understanding of what is not acceptable and harmful. To objectivise the notion of inappropriateness, we define it in a data-driven way though crowdsourcing. Namely we run a large-scale annotation study asking workers if a given chatbot textual statement could harm reputation of a company created it. Acceptably high values of inter-annotator agreement suggest that the notion of inappropriateness exists and can be uniformly understood by different people. To define the notion of sensitive topics in an objective way we use on guidelines suggested commonly by specialists of legal and PR department of a large public company as potentially harmful.","Babakov N,Logacheva V,Panchenko A",,,Beyond plain toxic: building datasets for detection of flammable topics and inappropriate statements,58,2,10.1007/S10579-023-09682-Z , Journal Article,,"Abstract:Toxicity on the Internet, such as hate speech, offenses towards particular users or groups of people, or the use of obscene words, is an acknowledged problem. However, there also exist other types of inappropriate messages which are usually not viewed as toxic, e.g. as they do not contain explicit offences. Such messages can contain covered toxicity or generalizations, incite harmful actions (crime, suicide, drug use), provoke ""heated"" discussions. Such messages are often related to particular sensitive topics, e.g. on politics, sexual minorities, social injustice which more often than other topics, e.g. cars or computing, yield toxic emotional reactions. At the same time, clearly not all messages within such flammable topics are inappropriate.
Towards this end, in this work, we present two text collections labelled according to binary notion of inapropriateness and a multinomial notion of sensitive topic. Assuming that the notion of inappropriateness is common among people of the same culture, we base our approach on human intuitive understanding of what is not acceptable and harmful. To objectivise the notion of inappropriateness, we define it in a data-driven way though crowdsourcing. Namely we run a large-scale annotation study asking workers if a given chatbot textual statement could harm reputation of a company created it. Acceptably high values of inter-annotator agreement suggest that the notion of inappropriateness exists and can be uniformly understood by different people. To define the notion of sensitive topics in an objective way we use on guidelines suggested commonly by specialists of legal and PR department of a large public company as potentially harmful.",,,,, Lang. Resour. Evaluation,  ,,Gen_dataset#detection,
2803,"**Title**MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector

**Abstract**Research in toxicity detection in natural lan-
    guage processing for the speech modality
    (audio-based) is quite limited, particularly for
    languages other than English. To address these
    limitations and lay the groundwork for truly
    multilingual audio-based toxicity detection, we
    introduce MuTox, the first highly multilingual
    audio-based dataset with toxicity labels which
    covers 14 different linguistic families.  The
    dataset comprises 20,000 audio utterances for
    English and Spanish, and 4,000 for the other
   28 languages. To demonstrate the quality of
     this dataset, we trained the MuTox audio-based
     toxicity classifier, which enables zero-shot toxi-
     city detection across a wide range of languages.
    This classifier performs on par with existing
    text-based trainable classifiers, while expand-
    ing the language coverage more than tenfold.
   When compared to a wordlist-based classifier
     that covers a similar number of languages, Mu-
   Tox improves F1-Score by an average of 100%.
    This significant improvement underscores the
    potential of MuTox in advancing the field of
    audio-based toxicity detection.

  Warning: This article includes examples of lan-
guage that can be considered offensive or upsetting.

1  Introduction

Text toxicity detection has been largely explored
for different tasks in Natural Language Process-
ing (NLP) (Kaggle, 2018). Wordlist-based toxicity
classifiers—e.g., ETOX (Costa-jussà et al., 2023)—
scale well to a large number of languages (NLLB
Team et al., 2022) and context-based classifiers are
able to detect beyond lexical toxicity with tools
such as DETOXIFY1.
  When exploring audio-based toxicity detection,
there are either cascaded systems which extend text
toxicity detection with speech recognition (Seam-
less Communication et al., 2023a); or end-to-end

    1 https://github.com/unitaryai/detoxifyaudio-based toxicity classification (Ghosh et al.,
2021) which provides an English dataset together
with end-to-end toxicity detection results.  This
work shows that gains of English text-less audio-
based classifiers over text-based classifiers are spe-
cially relevant when applied to out-of-domain, co-
herently with the previous study on a non-disclosed
dataset (Yousefi and Emmanouilidou, 2021).
   In this paper, we go far beyond existing research
in audio-based toxicity detection by providing the
first highly multilingual audio-based toxicity an-
notated dataset (MuTox dataset, 30 languages, see
Table 6 in appendix A) together with the first text-
less massive multilingual metric (MuTox classi-
fier, 100+ languages). Note that multilinguality
for audio-based toxicity detection becomes even
more crucial for the task of added toxicity in the
context of multimodal and multilingual translation,
where the case of adding or deleting toxicity may
be considered as a critical error (Seamless Commu-
nication et al., 2023a).
  In particular, the main contributions of this pa-
per are: providing guidelines for audio-based tox-
icity annotation (section 3); releasing the  first
highly multilingual audio-based toxicity dataset
and benchmark with human annotations for 30 lan-
guages (section 4); analyzing the performance of
text-based classifiers when applied to audio-based
toxicity detection (section 6); proposing MuTox, a
massively multilingual audio-based toxicity classi-
fier (section 5). Our results can be summarized:

    • When compared to the strongest performing
     systems, which are composed of speech recog-
     nition plus trainable text-based toxicity detec-
      tors, MuTox performs on par, while offering
    more than 10 times the language coverage 2.

    2 We want to clarify that while MuTox dataset evaluates 30
languages, the MuTox classifier relies on SONAR (Duquenne
et al., 2023) embeddings. As of March 2024, SONAR en-
coders are available for 57 languages in speech and 200 in text.
Thanks to this architecture, by design, the MuTox classifier5725","Costa-jussà MR,Meglioli MC,Andrews P,Dale D,Hansanti P,Kalbassi E,Mourachko A,Ropers C,Wood C",,,MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector,,,10.18653/V1/2024.FINDINGS-ACL.340 , Conference Paper,,"Research in toxicity detection in natural lan-
    guage processing for the speech modality
    (audio-based) is quite limited, particularly for
    languages other than English. To address these
    limitations and lay the groundwork for truly
    multilingual audio-based toxicity detection, we
    introduce MuTox, the first highly multilingual
    audio-based dataset with toxicity labels which
    covers 14 different linguistic families.  The
    dataset comprises 20,000 audio utterances for
    English and Spanish, and 4,000 for the other
   28 languages. To demonstrate the quality of
     this dataset, we trained the MuTox audio-based
     toxicity classifier, which enables zero-shot toxi-
     city detection across a wide range of languages.
    This classifier performs on par with existing
    text-based trainable classifiers, while expand-
    ing the language coverage more than tenfold.
   When compared to a wordlist-based classifier
     that covers a similar number of languages, Mu-
   Tox improves F1-Score by an average of 100%.
    This significant improvement underscores the
    potential of MuTox in advancing the field of
    audio-based toxicity detection.

  Warning: This article includes examples of lan-
guage that can be considered offensive or upsetting.

1  Introduction

Text toxicity detection has been largely explored
for different tasks in Natural Language Process-
ing (NLP) (Kaggle, 2018). Wordlist-based toxicity
classifiers—e.g., ETOX (Costa-jussà et al., 2023)—
scale well to a large number of languages (NLLB
Team et al., 2022) and context-based classifiers are
able to detect beyond lexical toxicity with tools
such as DETOXIFY1.
  When exploring audio-based toxicity detection,
there are either cascaded systems which extend text
toxicity detection with speech recognition (Seam-
less Communication et al., 2023a); or end-to-end

    1 https://github.com/unitaryai/detoxifyaudio-based toxicity classification (Ghosh et al.,
2021) which provides an English dataset together
with end-to-end toxicity detection results.  This
work shows that gains of English text-less audio-
based classifiers over text-based classifiers are spe-
cially relevant when applied to out-of-domain, co-
herently with the previous study on a non-disclosed
dataset (Yousefi and Emmanouilidou, 2021).
   In this paper, we go far beyond existing research
in audio-based toxicity detection by providing the
first highly multilingual audio-based toxicity an-
notated dataset (MuTox dataset, 30 languages, see
Table 6 in appendix A) together with the first text-
less massive multilingual metric (MuTox classi-
fier, 100+ languages). Note that multilinguality
for audio-based toxicity detection becomes even
more crucial for the task of added toxicity in the
context of multimodal and multilingual translation,
where the case of adding or deleting toxicity may
be considered as a critical error (Seamless Commu-
nication et al., 2023a).
  In particular, the main contributions of this pa-
per are: providing guidelines for audio-based tox-
icity annotation (section 3); releasing the  first
highly multilingual audio-based toxicity dataset
and benchmark with human annotations for 30 lan-
guages (section 4); analyzing the performance of
text-based classifiers when applied to audio-based
toxicity detection (section 6); proposing MuTox, a
massively multilingual audio-based toxicity classi-
fier (section 5). Our results can be summarized:

    • When compared to the strongest performing
     systems, which are composed of speech recog-
     nition plus trainable text-based toxicity detec-
      tors, MuTox performs on par, while offering
    more than 10 times the language coverage 2.

    2 We want to clarify that while MuTox dataset evaluates 30
languages, the MuTox classifier relies on SONAR (Duquenne
et al., 2023) embeddings. As of March 2024, SONAR en-
coders are available for 57 languages in speech and 200 in text.
Thanks to this architecture, by design, the MuTox classifier5725",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024  ",,out_but_toxicity,
2804,"**Title**UniTox: Leveraging LLMs to Curate a Unified Dataset of Drug-Induced Toxicity from FDA Labels

**Abstract**Drug-induced toxicity is one of the leading reasons new drugs fail clinical trials.
       Machine learning models that predict drug toxicity from molecular structure could
        help researchers prioritize less toxic drug candidates. However, current toxicity
         datasets are typically small and limited to a single organ system (e.g., cardio, renal,
         or liver). Creating these datasets often involved time-intensive expert curation
       by parsing drug labelling documents that can exceed 100 pages per drug. Here,
      we introduce UniTox1, a unified dataset of 2,418 FDA-approved drugs with drug-
        induced toxicity summaries and ratings created by using GPT-4o to process FDA
        drug labels. UniTox spans eight types of toxicity: cardiotoxicity, liver toxicity,
         renal toxicity, pulmonary toxicity, hematological toxicity, dermatological toxicity,
         ototoxicity, and infertility. This is, to the best of our knowledge, the largest such
         systematic human in vivo database by number of drugs and toxicities, and the first
        covering nearly all non-combination FDA-approved medications for several of
         these toxicities. We recruited clinicians to validate a random sample of our GPT-4o
        annotated toxicities, and UniTox’s toxicity ratings concord with clinician labelers
      85–96% of the time. Finally, we benchmark several machine learning models
         trained on UniTox to demonstrate the utility of this dataset for building molecular
          toxicity prediction models.


1  Introduction

An estimated 90% of drugs fail in clinical trials [1]. While the most common cause of failure is
efficacy, one study found that the second largest cause (24% of failures) was drug safety [2]. Further,
every year, previously approved drugs are taken off the market as unanticipated toxicities become
apparent in post-marketing data that can be difficult to screen pre-clinically [3]. These different
drug-induced toxicities span many different organ systems, including the heart, liver, kidneys, blood,
and lungs. As a result, there is a strong need for predictive models that can anticipate a broad range

   1UniTox data is available at https://zou-group.github.io/UniTox-website. Code available at:
https://github.com/jsilbergDS/UniTox


38th Conference on Neural Information Processing Systems (NeurIPS 2024) Track on Datasets and Benchmarks.","Silberg J,Swanson K,Simon E,Zhang A,Ghazizadeh Z,Ogden S,Hamadeh H,Zou JY",,,UniTox: Leveraging LLMs to Curate a Unified Dataset of Drug-Induced Toxicity from FDA Labels,,, , Conference Paper,,"Drug-induced toxicity is one of the leading reasons new drugs fail clinical trials.
       Machine learning models that predict drug toxicity from molecular structure could
        help researchers prioritize less toxic drug candidates. However, current toxicity
         datasets are typically small and limited to a single organ system (e.g., cardio, renal,
         or liver). Creating these datasets often involved time-intensive expert curation
       by parsing drug labelling documents that can exceed 100 pages per drug. Here,
      we introduce UniTox1, a unified dataset of 2,418 FDA-approved drugs with drug-
        induced toxicity summaries and ratings created by using GPT-4o to process FDA
        drug labels. UniTox spans eight types of toxicity: cardiotoxicity, liver toxicity,
         renal toxicity, pulmonary toxicity, hematological toxicity, dermatological toxicity,
         ototoxicity, and infertility. This is, to the best of our knowledge, the largest such
         systematic human in vivo database by number of drugs and toxicities, and the first
        covering nearly all non-combination FDA-approved medications for several of
         these toxicities. We recruited clinicians to validate a random sample of our GPT-4o
        annotated toxicities, and UniTox’s toxicity ratings concord with clinician labelers
      85–96% of the time. Finally, we benchmark several machine learning models
         trained on UniTox to demonstrate the utility of this dataset for building molecular
          toxicity prediction models.


1  Introduction

An estimated 90% of drugs fail in clinical trials [1]. While the most common cause of failure is
efficacy, one study found that the second largest cause (24% of failures) was drug safety [2]. Further,
every year, previously approved drugs are taken off the market as unanticipated toxicities become
apparent in post-marketing data that can be difficult to screen pre-clinically [3]. These different
drug-induced toxicities span many different organ systems, including the heart, liver, kidneys, blood,
and lungs. As a result, there is a strong need for predictive models that can anticipate a broad range

   1UniTox data is available at https://zou-group.github.io/UniTox-website. Code available at:
https://github.com/jsilbergDS/UniTox


38th Conference on Neural Information Processing Systems (NeurIPS 2024) Track on Datasets and Benchmarks.",,,,, ,"Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024  ",,out_of_scope,
2805,"**Title**BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text

**Abstract**Abstract:Many of the recent breakthroughs in language modeling have resulted from scaling effectively the same model architecture to larger datasets. In this vein, recent work has highlighted performance gains from increasing training dataset size and quality, suggesting a need for novel sources of large-scale datasets. In this work, we introduce BeanCounter, a public dataset consisting of more than 159B tokens extracted from businesses' disclosures. We show that this data is indeed novel: less than 0.1% of BeanCounter appears in Common Crawl-based datasets and it is an order of magnitude larger than datasets relying on similar sources. Given the data's provenance, we hypothesize that BeanCounter is comparatively more factual and less toxic than web-based datasets. Exploring this hypothesis, we find that many demographic identities occur with similar prevalence in BeanCounter but with significantly less toxic context relative to other datasets. To demonstrate the utility of BeanCounter, we evaluate and compare two LLMs continually pre-trained on BeanCounter with their base models. We find an 18-33% reduction in toxic generation and improved performance within the finance domain for the continually pretrained models. Collectively, our work suggests that BeanCounter is a novel source of low-toxicity and high-quality domain-specific data with sufficient scale to train multi-billion parameter LLMs.","Wang S,Levy B",,,"BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text",,, , Conference Paper,,"Abstract:Many of the recent breakthroughs in language modeling have resulted from scaling effectively the same model architecture to larger datasets. In this vein, recent work has highlighted performance gains from increasing training dataset size and quality, suggesting a need for novel sources of large-scale datasets. In this work, we introduce BeanCounter, a public dataset consisting of more than 159B tokens extracted from businesses' disclosures. We show that this data is indeed novel: less than 0.1% of BeanCounter appears in Common Crawl-based datasets and it is an order of magnitude larger than datasets relying on similar sources. Given the data's provenance, we hypothesize that BeanCounter is comparatively more factual and less toxic than web-based datasets. Exploring this hypothesis, we find that many demographic identities occur with similar prevalence in BeanCounter but with significantly less toxic context relative to other datasets. To demonstrate the utility of BeanCounter, we evaluate and compare two LLMs continually pre-trained on BeanCounter with their base models. We find an 18-33% reduction in toxic generation and improved performance within the finance domain for the continually pretrained models. Collectively, our work suggests that BeanCounter is a novel source of low-toxicity and high-quality domain-specific data with sufficient scale to train multi-billion parameter LLMs.",,,,, ,"Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024  ",,out_of_scope,
2806,"**Title**Toxic Content Detection in online social networks: a new dataset from Brazilian Reddit Communities

**Abstract**The proliferation of online social interactions
    in recent years, with the consequent growth in
    user-generated content, has brought the esca-
     lating issue of toxic language.While automatic
    machine learning models have been effective
    in moderating the vast amount of data on on-
     line social networks, low-resource languages,
    such as Brazilian Portuguese, still lack efficient
    automated moderation tools. We address this
    gap by creating a high-quality dataset collected
    from some of the most popular Brazilian Reddit
    communities. To that end, we manually labeled
    a sample dataset of 2,500 comments extracted
    from the most engaging communities. We con-
    ducted an in-depth exploratory analysis to gain
    valuable insights into the language of toxic and
    non-toxic content. Our results show a high level
    of agreement among annotators, attesting to
    the suitability of this dataset for various down-
    stream machine learning tasks. This research
     offers a significant contribution to the creation
    of a safer online environment for users engag-
    ing in discussions in Portuguese and paves the
   way for more effective automatic moderation
     tools using machine learning.

1  Introduction

With the growth in the number of online social net-
work platforms, increasingly more users are inter-
acting through online media. According to (Statista,
2022), the total number of users of different social
networks is 4 billion people. This figure indicates
the level of importance and ubiquity of these online
platforms in society and their impact, not always
beneficial, on people’s lives. According to (Vogels,
2021), a study conducted in 2020 with US adults
found that around 41% of respondents had experi-
enced some form of online harassment. In addition,
abusive comments in discussions propagate toxicity
and harmful user engagement, radicalizing discus-
sions (Salehabadi et al., 2022). The consequences
of these interactions transcend the virtual world,seriously affecting the lives of real users. Accord-
ing to (Vogels, 2021), 18% of the users who took
part in a survey had suffered some kind of abuse
considered severe beyond the online environment,
including physical threats and stalking.
  The manual moderation of user-generated con-
tent has long been considered the primary approach
to mitigate the negative impact of toxic interactions.
However, the scale and speed at which content is
generated make manual moderation impractical,
prompting the need for automated solutions. Ma-
chine learning models have emerged as a promis-
ing alternative for automating the moderation of
online created content. These models can identify
potentially harmful content, enabling platforms to
proactively take actions such as banning users and
removing harmful content. While machine learning
models have proved effective in several languages
(Perspective, 2022b), their performance for low re-
source languages, such as Brazilian Portuguese, is
still a concern.
  Seeking to address these challenges, this paper
introduces a new dataset for toxicity detection in
Brazilian Portuguese. The annotated texts were re-
trieved from one of the most relevant online social
networks - Reddit -, which has around 1.5 billion
registered users and 430 million active users (Wise,
2023). Reddit is a community that allows users
to interact through anonymous posts (submissions)
and comments. Users are organized into communi-
ties (subreddits) and subscribe to the communities
most aligned with their topics of interest. The col-
lection and annotation of these data are motivated
by the need to propose new models of toxicity de-
tection and improve existing ones for the unique
characteristics of the Portuguese language. Also,
the dataset is tailored specifically for online social
network data, filling the gap on available models
for Portuguese in this domain.
  The remainder of this paper is organized as fol-
lows. We first review the available literature on","Lima LH,Pagano AS,da Silva AP",,,Toxic Content Detection in online social networks: a new dataset from Brazilian Reddit Communities,,, , Conference Paper,,"The proliferation of online social interactions
    in recent years, with the consequent growth in
    user-generated content, has brought the esca-
     lating issue of toxic language.While automatic
    machine learning models have been effective
    in moderating the vast amount of data on on-
     line social networks, low-resource languages,
    such as Brazilian Portuguese, still lack efficient
    automated moderation tools. We address this
    gap by creating a high-quality dataset collected
    from some of the most popular Brazilian Reddit
    communities. To that end, we manually labeled
    a sample dataset of 2,500 comments extracted
    from the most engaging communities. We con-
    ducted an in-depth exploratory analysis to gain
    valuable insights into the language of toxic and
    non-toxic content. Our results show a high level
    of agreement among annotators, attesting to
    the suitability of this dataset for various down-
    stream machine learning tasks. This research
     offers a significant contribution to the creation
    of a safer online environment for users engag-
    ing in discussions in Portuguese and paves the
   way for more effective automatic moderation
     tools using machine learning.

1  Introduction

With the growth in the number of online social net-
work platforms, increasingly more users are inter-
acting through online media. According to (Statista,
2022), the total number of users of different social
networks is 4 billion people. This figure indicates
the level of importance and ubiquity of these online
platforms in society and their impact, not always
beneficial, on people’s lives. According to (Vogels,
2021), a study conducted in 2020 with US adults
found that around 41% of respondents had experi-
enced some form of online harassment. In addition,
abusive comments in discussions propagate toxicity
and harmful user engagement, radicalizing discus-
sions (Salehabadi et al., 2022). The consequences
of these interactions transcend the virtual world,seriously affecting the lives of real users. Accord-
ing to (Vogels, 2021), 18% of the users who took
part in a survey had suffered some kind of abuse
considered severe beyond the online environment,
including physical threats and stalking.
  The manual moderation of user-generated con-
tent has long been considered the primary approach
to mitigate the negative impact of toxic interactions.
However, the scale and speed at which content is
generated make manual moderation impractical,
prompting the need for automated solutions. Ma-
chine learning models have emerged as a promis-
ing alternative for automating the moderation of
online created content. These models can identify
potentially harmful content, enabling platforms to
proactively take actions such as banning users and
removing harmful content. While machine learning
models have proved effective in several languages
(Perspective, 2022b), their performance for low re-
source languages, such as Brazilian Portuguese, is
still a concern.
  Seeking to address these challenges, this paper
introduces a new dataset for toxicity detection in
Brazilian Portuguese. The annotated texts were re-
trieved from one of the most relevant online social
networks - Reddit -, which has around 1.5 billion
registered users and 430 million active users (Wise,
2023). Reddit is a community that allows users
to interact through anonymous posts (submissions)
and comments. Users are organized into communi-
ties (subreddits) and subscribe to the communities
most aligned with their topics of interest. The col-
lection and annotation of these data are motivated
by the need to propose new models of toxicity de-
tection and improve existing ones for the unique
characteristics of the Portuguese language. Also,
the dataset is tailored specifically for online social
network data, filling the gap on available models
for Portuguese in this domain.
  The remainder of this paper is organized as fol-
lows. We first review the available literature on",,,,,Association for Computational Lingustics ,"Proceedings of the 16th International Conference on Computational Processing of Portuguese, PROPOR 2024, Santiago de Compostela, Galicia/Spain, 12-15 March, 2024  ",,out_but_toxicity,
2807,"**Title**ApisTox: a new benchmark dataset for the classification of small molecules toxicity on honey bees

**Abstract**Abstract:The global decline in bee populations poses significant risks to agriculture, biodiversity, and environmental stability. To bridge the gap in existing data, we introduce ApisTox, a comprehensive dataset focusing on the toxicity of pesticides to honey bees (Apis mellifera). This dataset combines and leverages data from existing sources such as ECOTOX and PPDB, providing an extensive, consistent, and curated collection that surpasses the previous datasets. ApisTox incorporates a wide array of data, including toxicity levels for chemicals, details such as time of their publication in literature, and identifiers linking them to external chemical databases. This dataset may serve as an important tool for environmental and agricultural research, but also can support the development of policies and practices aimed at minimizing harm to bee populations. Finally, ApisTox offers a unique resource for benchmarking molecular property prediction methods on agrochemical compounds, facilitating advancements in both environmental science and cheminformatics. This makes it a valuable tool for both academic research and practical applications in bee conservation.","Adamczyk J,Poziemski J,Siedlecki P",,,ApisTox: a new benchmark dataset for the classification of small molecules toxicity on honey bees,abs/2404.16196,,10.48550/ARXIV.2404.16196 , Journal Article,,"Abstract:The global decline in bee populations poses significant risks to agriculture, biodiversity, and environmental stability. To bridge the gap in existing data, we introduce ApisTox, a comprehensive dataset focusing on the toxicity of pesticides to honey bees (Apis mellifera). This dataset combines and leverages data from existing sources such as ECOTOX and PPDB, providing an extensive, consistent, and curated collection that surpasses the previous datasets. ApisTox incorporates a wide array of data, including toxicity levels for chemicals, details such as time of their publication in literature, and identifiers linking them to external chemical databases. This dataset may serve as an important tool for environmental and agricultural research, but also can support the development of policies and practices aimed at minimizing harm to bee populations. Finally, ApisTox offers a unique resource for benchmarking molecular property prediction methods on agrochemical compounds, facilitating advancements in both environmental science and cheminformatics. This makes it a valuable tool for both academic research and practical applications in bee conservation.",,,,, CoRR,  ,,out_of_scope,
2808,"**Title**IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language

**Abstract**Abstract:Hate speech poses a significant threat to social harmony. Over the past two years, Indonesia has seen a ten-fold increase in the online hate speech ratio, underscoring the urgent need for effective detection mechanisms. However, progress is hindered by the limited availability of labeled data for Indonesian texts. The condition is even worse for marginalized minorities, such as Shia, LGBTQ, and other ethnic minorities because hate speech is underreported and less understood by detection tools. Furthermore, the lack of accommodation for subjectivity in current datasets compounds this issue. To address this, we introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity classification dataset. Comprising 43,692 entries annotated by 19 diverse individuals, the dataset focuses on texts targeting vulnerable groups in Indonesia, specifically during the hottest political event in the country: the presidential election. We establish baselines for seven binary classification tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet) fine-tuned for hate speech classification. Furthermore, we demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo. However, we also caution that an overemphasis on demographic information can negatively impact the fine-tuned model performance due to data fragmentation.","Susanto L,Wijanarko MI,Pratama PA,Hong T,Idris I,Aji AF,Wijaya D",,,IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language,abs/2406.19349,,10.48550/ARXIV.2406.19349 , Journal Article,,"Abstract:Hate speech poses a significant threat to social harmony. Over the past two years, Indonesia has seen a ten-fold increase in the online hate speech ratio, underscoring the urgent need for effective detection mechanisms. However, progress is hindered by the limited availability of labeled data for Indonesian texts. The condition is even worse for marginalized minorities, such as Shia, LGBTQ, and other ethnic minorities because hate speech is underreported and less understood by detection tools. Furthermore, the lack of accommodation for subjectivity in current datasets compounds this issue. To address this, we introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity classification dataset. Comprising 43,692 entries annotated by 19 diverse individuals, the dataset focuses on texts targeting vulnerable groups in Indonesia, specifically during the hottest political event in the country: the presidential election. We establish baselines for seven binary classification tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet) fine-tuned for hate speech classification. Furthermore, we demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo. However, we also caution that an overemphasis on demographic information can negatively impact the fine-tuned model performance due to data fragmentation.",,,,, CoRR,  ,,out_but_toxicity,
2809,"**Title**Toxic language detection: a systematic survey of Arabic datasets

**Abstract**Abstract:The detection of toxic language in the Arabic language has emerged as an active area of research in recent years, and reviewing the existing datasets employed for training the developed solutions has become a pressing need. This paper offers a comprehensive survey of Arabic datasets focused on online toxic language. We systematically gathered a total of 54 available datasets and their corresponding papers and conducted a thorough analysis, considering 18 criteria across four primary dimensions: availability details, content, annotation process, and reusability. This analysis enabled us to identify existing gaps and make recommendations for future research works. For the convenience of the research community, the list of the analysed datasets is maintained in a GitHub repository (this https URL).","Bensalem I,Rosso P,Zitouni H",,,Toxic language detection: a systematic survey of Arabic datasets,abs/2312.07228,,10.48550/ARXIV.2312.07228 , Journal Article,,"Abstract:The detection of toxic language in the Arabic language has emerged as an active area of research in recent years, and reviewing the existing datasets employed for training the developed solutions has become a pressing need. This paper offers a comprehensive survey of Arabic datasets focused on online toxic language. We systematically gathered a total of 54 available datasets and their corresponding papers and conducted a thorough analysis, considering 18 criteria across four primary dimensions: availability details, content, annotation process, and reusability. This analysis enabled us to identify existing gaps and make recommendations for future research works. For the convenience of the research community, the list of the analysed datasets is maintained in a GitHub repository (this https URL).",,,,, CoRR,  ,,out_but_toxicity,
2810,"**Title**Leveraging deep learning for toxic comment detection in cursive languages

**Abstract**Comment sections of online news platforms are an essential space
to express opinions and discuss political topics. In contrast to other online
posts, news discussions are related to particular news articles, comments re-
fer to each other, and individual conversations emerge. However, the misuse
by spammers, haters, and trolls makes costly content moderation necessary.
Sentiment analysis can not only support moderation but also help to under-
stand the dynamics of online discussions. A subtask of content moderation
is the identiﬁcation of toxic comments. To this end, we describe the con-
cept of toxicity and characterize its subclasses. Further, we present various
deep learning approaches, including datasets and architectures, tailored to
sentiment analysis in online discussions. One way to make these approaches
more comprehensible and trustworthy is ﬁne-grained instead of binary com-
ment classiﬁcation. On the downside, more classes require more training data.
Therefore, we propose to augment training data by using transfer learning.
We discuss real-world applications, such as semi-automated comment mod-
eration and troll detection. Finally, we outline future challenges and current
limitations in the light of most recent research publications.

Key words: Deep Learning; Natural Language Processing; User-generated
Content; Toxic Comment Classiﬁcation; Hate Speech Detection;





Julian Risch (corresponding author)
Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Str. 2–3, 14482
Potsdam, Germany e-mail: julian.risch@hpi.de phone: +49 331 5509 272

Ralf Krestel
Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Str. 2–3, 14482
Potsdam, Germany e-mail: ralf.krestel@hpi.de","Shahid M,Umair M,Iqbal MA,Rashid M,Akram S,Zubair M",,,Leveraging deep learning for toxic comment detection in cursive languages,10,,10.7717/PEERJ-CS.2486 , Journal Article,,"Comment sections of online news platforms are an essential space
to express opinions and discuss political topics. In contrast to other online
posts, news discussions are related to particular news articles, comments re-
fer to each other, and individual conversations emerge. However, the misuse
by spammers, haters, and trolls makes costly content moderation necessary.
Sentiment analysis can not only support moderation but also help to under-
stand the dynamics of online discussions. A subtask of content moderation
is the identiﬁcation of toxic comments. To this end, we describe the con-
cept of toxicity and characterize its subclasses. Further, we present various
deep learning approaches, including datasets and architectures, tailored to
sentiment analysis in online discussions. One way to make these approaches
more comprehensible and trustworthy is ﬁne-grained instead of binary com-
ment classiﬁcation. On the downside, more classes require more training data.
Therefore, we propose to augment training data by using transfer learning.
We discuss real-world applications, such as semi-automated comment mod-
eration and troll detection. Finally, we outline future challenges and current
limitations in the light of most recent research publications.

Key words: Deep Learning; Natural Language Processing; User-generated
Content; Toxic Comment Classiﬁcation; Hate Speech Detection;





Julian Risch (corresponding author)
Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Str. 2–3, 14482
Potsdam, Germany e-mail: julian.risch@hpi.de phone: +49 331 5509 272

Ralf Krestel
Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Str. 2–3, 14482
Potsdam, Germany e-mail: ralf.krestel@hpi.de",,,,, PeerJ Comput. Sci.,  ,,detection,
2811,"**Title**Take Its Essence, Discard Its Dross! Debiasing for Toxic Language Detection via Counterfactual Causal Effect

**Abstract**Current methods of toxic language detection (TLD) typically rely on specific tokens to conduct decisions, which
makes them suffer from lexical bias, leading to inferior performance and generalization. Lexical bias has both “useful”
and “misleading” impacts on understanding toxicity. Unfortunately, instead of distinguishing between these impacts,
current debiasing methods typically eliminate them indiscriminately, resulting in a degradation in the detection
accuracy of the model. To this end, we propose a Counterfactual Causal Debiasing Framework (CCDF) to mitigate
lexical bias in TLD. It preserves the “useful impact” of lexical bias and eliminates the “misleading impact”. Specifically,
we first represent the total effect of the original sentence and biased tokens on decisions from a causal view. We then
conduct counterfactual inference to exclude the direct causal effect of lexical bias from the total effect. Empirical
evaluations demonstrate that the debiased TLD model incorporating CCDF achieves state-of-the-art performance in
both accuracy and fairness compared to competitive baselines applied on several vanilla models. The generalization
capability of our model outperforms current debiased models for out-of-distribution data.
Disclaimer: The samples presented by this paper may be considered offensive or vulgar.
Keywords: Toxic Language Detection, Lexical Bias, Causal Inference             1.  Introduction

In recent years, researchers have introduced natu-
ral language processing techniques to detect toxic
language. However, due to biased training, cur-
rent toxic language detection (TLD) methods are
prone to relying on lexical bias to perform deci-
sions. The lexical bias associates toxicity with the
presence of biased tokens (e.g., identity mentions,
insults, and markers of African American English)
(Davidson et al., 2019; Zhang et al., 2020), which
undermines the fairness of minorities (Thiago et al.,
2021; Hutchinson et al., 2020). As an example, as
shown in Figure 1, the TLD model tends to classify
all samples containing ""n*gga"" (a cordial phrase for
dialogue between Africans) as toxic language, due
to its frequent occurrence in toxic samples during
training. This actually compromises the freedom
of expression of Africans (Sap et al., 2019). Mean-
while, lexical bias also affects the generalization
ability of the TLD model, resulting in limited detec-
tion performance of the model for out-of-distribution
(OOD) data (Vidgen et al., 2019; Ramponi and
Tonelli, 2022; Zhou et al., 2021b).
  Researchers have presented several methods
to mitigate lexical bias in TLD. Due to the expen-
sive labor costs of constructing unbiased datasets
(Dinan et al., 2019), many studies have attempted
to weaken lexical prior while training with original


     * Corresponding author                        Non-
   Token      Toxic                 Ratio (%)
                           Toxic
    black       244        76         76.25
   n*gga      541        17         96.95
     f*ck       878        46         95.02
    ass       1592       132        92.34

Table 1: Proportion of toxic samples containing
several biased tokens in the dataset (Founta et al.,
2018), which are crawled from Twitter.


data, and enable models to make decisions without
the impact of the bias (Swayamdipta et al., 2020;
Chuang et al., 2021; Ramponi and Tonelli, 2022).
However, these methods fail to distinguish the “use-
ful impact” and “misleading impact” of lexical bias
for understanding toxicity. In fact, lexical bias has
positive effects on TLD, which was viewed as an ef-
fective surface feature for identifying toxic language
in earlier work (Abney, 2014; Dinakar et al., 2015).
As shown in Table 1, biased tokens are used to
express toxic semantics in considerable comments.
Therefore, interpreting lexical bias as a detriment
to TLD and directly eliminating the bias can lead to
a significant reduction in the accuracy of debiased
models (Zhou et al., 2021b). To maintain detection
performance while debiasing, it is necessary to ex-
amine how lexical bias influences model decisions
from the dual characteristics.
  In this work, we propose a novel Counterfactual15566","Lu J,Xu B,Zhang X,Liu K,Zhang D,Yang L,Lin H",,,"Take Its Essence, Discard Its Dross! Debiasing for Toxic Language Detection via Counterfactual Causal Effect",,, , Conference Paper,,"Current methods of toxic language detection (TLD) typically rely on specific tokens to conduct decisions, which
makes them suffer from lexical bias, leading to inferior performance and generalization. Lexical bias has both “useful”
and “misleading” impacts on understanding toxicity. Unfortunately, instead of distinguishing between these impacts,
current debiasing methods typically eliminate them indiscriminately, resulting in a degradation in the detection
accuracy of the model. To this end, we propose a Counterfactual Causal Debiasing Framework (CCDF) to mitigate
lexical bias in TLD. It preserves the “useful impact” of lexical bias and eliminates the “misleading impact”. Specifically,
we first represent the total effect of the original sentence and biased tokens on decisions from a causal view. We then
conduct counterfactual inference to exclude the direct causal effect of lexical bias from the total effect. Empirical
evaluations demonstrate that the debiased TLD model incorporating CCDF achieves state-of-the-art performance in
both accuracy and fairness compared to competitive baselines applied on several vanilla models. The generalization
capability of our model outperforms current debiased models for out-of-distribution data.
Disclaimer: The samples presented by this paper may be considered offensive or vulgar.
Keywords: Toxic Language Detection, Lexical Bias, Causal Inference             1.  Introduction

In recent years, researchers have introduced natu-
ral language processing techniques to detect toxic
language. However, due to biased training, cur-
rent toxic language detection (TLD) methods are
prone to relying on lexical bias to perform deci-
sions. The lexical bias associates toxicity with the
presence of biased tokens (e.g., identity mentions,
insults, and markers of African American English)
(Davidson et al., 2019; Zhang et al., 2020), which
undermines the fairness of minorities (Thiago et al.,
2021; Hutchinson et al., 2020). As an example, as
shown in Figure 1, the TLD model tends to classify
all samples containing ""n*gga"" (a cordial phrase for
dialogue between Africans) as toxic language, due
to its frequent occurrence in toxic samples during
training. This actually compromises the freedom
of expression of Africans (Sap et al., 2019). Mean-
while, lexical bias also affects the generalization
ability of the TLD model, resulting in limited detec-
tion performance of the model for out-of-distribution
(OOD) data (Vidgen et al., 2019; Ramponi and
Tonelli, 2022; Zhou et al., 2021b).
  Researchers have presented several methods
to mitigate lexical bias in TLD. Due to the expen-
sive labor costs of constructing unbiased datasets
(Dinan et al., 2019), many studies have attempted
to weaken lexical prior while training with original


     * Corresponding author                        Non-
   Token      Toxic                 Ratio (%)
                           Toxic
    black       244        76         76.25
   n*gga      541        17         96.95
     f*ck       878        46         95.02
    ass       1592       132        92.34

Table 1: Proportion of toxic samples containing
several biased tokens in the dataset (Founta et al.,
2018), which are crawled from Twitter.


data, and enable models to make decisions without
the impact of the bias (Swayamdipta et al., 2020;
Chuang et al., 2021; Ramponi and Tonelli, 2022).
However, these methods fail to distinguish the “use-
ful impact” and “misleading impact” of lexical bias
for understanding toxicity. In fact, lexical bias has
positive effects on TLD, which was viewed as an ef-
fective surface feature for identifying toxic language
in earlier work (Abney, 2014; Dinakar et al., 2015).
As shown in Table 1, biased tokens are used to
express toxic semantics in considerable comments.
Therefore, interpreting lexical bias as a detriment
to TLD and directly eliminating the bias can lead to
a significant reduction in the accuracy of debiased
models (Zhou et al., 2021b). To maintain detection
performance while debiasing, it is necessary to ex-
amine how lexical bias influences model decisions
from the dual characteristics.
  In this work, we propose a novel Counterfactual15566",,,,,ELRA and ICCL ,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC/COLING 2024, 20-25 May, 2024, Torino, Italy  ",,detection#detox,
2812,"**Title**ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations

**Abstract**Detecting hate speech and offensive language is
    essential for maintaining a safe and respectful
     digital environment. This study examines the
    limitations of state-of-the-art large language
    models (LLMs) in identifying offensive con-
     tent within systematically perturbed data, with
    a focus on Chinese, a language particularly sus-
    ceptible to such perturbations. We introduce
   ToxiCloakCN1, an enhanced dataset derived
   from ToxiCN, augmented with homophonic
     substitutions and emoji transformations, to test
    the robustness of LLMs against these cloaking
    perturbations. Our findings reveal that existing
    models significantly underperform in detecting
    offensive content when these perturbations are
    applied. We provide an in-depth analysis of
   how different types of offensive content are af-
    fected by these perturbations and explore the
    alignment between human and model expla-
    nations of offensiveness. Our work highlights
    the urgent need for more advanced techniques
    in offensive language detection to combat the
    evolving tactics used to evade detection mecha-
    nisms.

Disclaimer:   This paper describes violent and
discriminatory content that may be disturbing to
some readers.

1  Introduction

Offensive language, which includes hate speech,
cyberbullying, and adult-oriented content, poses
significant risks to user well-being and social har-
mony (Davidson et al., 2019). With the rapid ex-
pansion and widespread usage of social media plat-
forms, the proliferation of offensive language has
become a critical issue. Consequently, social media
platforms and researchers have explored develop-
ing robust machine learning and linguistic analy-

   *Yunze Xiao and Yujia Hu contributed equally to this work.
   1GitHub:  https://github.com/Social-AI-Studio/
ToxiCloakCNsis solutions to effectively identify and mitigate
the harmful effects of offensive content (Davidson
et al., 2017; Dhanya and Balakrishnan, 2021).

Recent advances in Natural Language Processing
(NLP), particularly with Large Language Mod-
els (LLMs), have significantly improved the abil-
ity to detect offensive language across multiple
languages (Pitsilis et al., 2018; Wei et al., 2021;
Fatemah and Ozlem, 2021; Battistelli et al., 2020;
Beyhan et al., 2022; Dhanya and Balakrishnan,
2021; Deng et al., 2022a; Zhou et al., 2023; Awal
et al., 2023). However, these models often strug-
gle with systematically perturbed data designed to
evade detection mechanisms. Common perturba-
tion techniques include homophonic substitutions,
emoji replacement, insertions, character splits, and
synonyms (Su et al., 2022; Kirk et al., 2022). These
techniques, referred to as ”cloaking”, exploit lin-
guistic nuances to mask offensive content, posing
a substantial challenge to both automated systems
and human moderators.

The Chinese language, in particular, is heavily im-
pacted by these techniques due to intensive lexicon-
based censorship, leading to a new linguistic phe-
nomenon (Wiener, 2011) where significant parts
of sentences are replaced by either homophones
or emojis to mask underlying offensive content or
to circumvent censorship rules. Figure 1 shows
two examples of offensive texts cloaked using ho-
mophone and emoji replacement techniques. In
these examples, the words and phrases highlighted
in yellow are replaced with homophones or emo-
jis. In the first example, homophones are used to
replace phrases that identify the target (e.g., “贺楠
仁” as the homophone for “河南人,” which means
people from the Henan region in China) and offen-
sive terms such as “太贱” with “肽键.” Similarly,
in the second example, the offensive term “舔狗”
(i.e., Simps) is replaced with         . Using such
techniques, users can fool automated offensive lan-6012","Xiao Y,Hu Y,Choo KT,Lee RK",,,ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations,,, , Conference Paper,,"Detecting hate speech and offensive language is
    essential for maintaining a safe and respectful
     digital environment. This study examines the
    limitations of state-of-the-art large language
    models (LLMs) in identifying offensive con-
     tent within systematically perturbed data, with
    a focus on Chinese, a language particularly sus-
    ceptible to such perturbations. We introduce
   ToxiCloakCN1, an enhanced dataset derived
   from ToxiCN, augmented with homophonic
     substitutions and emoji transformations, to test
    the robustness of LLMs against these cloaking
    perturbations. Our findings reveal that existing
    models significantly underperform in detecting
    offensive content when these perturbations are
    applied. We provide an in-depth analysis of
   how different types of offensive content are af-
    fected by these perturbations and explore the
    alignment between human and model expla-
    nations of offensiveness. Our work highlights
    the urgent need for more advanced techniques
    in offensive language detection to combat the
    evolving tactics used to evade detection mecha-
    nisms.

Disclaimer:   This paper describes violent and
discriminatory content that may be disturbing to
some readers.

1  Introduction

Offensive language, which includes hate speech,
cyberbullying, and adult-oriented content, poses
significant risks to user well-being and social har-
mony (Davidson et al., 2019). With the rapid ex-
pansion and widespread usage of social media plat-
forms, the proliferation of offensive language has
become a critical issue. Consequently, social media
platforms and researchers have explored develop-
ing robust machine learning and linguistic analy-

   *Yunze Xiao and Yujia Hu contributed equally to this work.
   1GitHub:  https://github.com/Social-AI-Studio/
ToxiCloakCNsis solutions to effectively identify and mitigate
the harmful effects of offensive content (Davidson
et al., 2017; Dhanya and Balakrishnan, 2021).

Recent advances in Natural Language Processing
(NLP), particularly with Large Language Mod-
els (LLMs), have significantly improved the abil-
ity to detect offensive language across multiple
languages (Pitsilis et al., 2018; Wei et al., 2021;
Fatemah and Ozlem, 2021; Battistelli et al., 2020;
Beyhan et al., 2022; Dhanya and Balakrishnan,
2021; Deng et al., 2022a; Zhou et al., 2023; Awal
et al., 2023). However, these models often strug-
gle with systematically perturbed data designed to
evade detection mechanisms. Common perturba-
tion techniques include homophonic substitutions,
emoji replacement, insertions, character splits, and
synonyms (Su et al., 2022; Kirk et al., 2022). These
techniques, referred to as ”cloaking”, exploit lin-
guistic nuances to mask offensive content, posing
a substantial challenge to both automated systems
and human moderators.

The Chinese language, in particular, is heavily im-
pacted by these techniques due to intensive lexicon-
based censorship, leading to a new linguistic phe-
nomenon (Wiener, 2011) where significant parts
of sentences are replaced by either homophones
or emojis to mask underlying offensive content or
to circumvent censorship rules. Figure 1 shows
two examples of offensive texts cloaked using ho-
mophone and emoji replacement techniques. In
these examples, the words and phrases highlighted
in yellow are replaced with homophones or emo-
jis. In the first example, homophones are used to
replace phrases that identify the target (e.g., “贺楠
仁” as the homophone for “河南人,” which means
people from the Henan region in China) and offen-
sive terms such as “太贱” with “肽键.” Similarly,
in the second example, the offensive term “舔狗”
(i.e., Simps) is replaced with         . Using such
techniques, users can fool automated offensive lan-6012",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,out_but_toxicity,
2813,"**Title**Harmful Communication: Detection of Toxic Language and Threats on Swedish

**Abstract**AbstractHarmful communication, such as toxic language and threats directed toward individuals or groups, is a common problem on most social media platforms and online spaces. While several approaches exist for detecting toxic language and threats in English, few attempts have detected such communication in Swedish. Thus, we used transfer learning and BERT to train two machine learning models: one that detects toxic language and one that detects threats in Swedish. We also examined the intersection between toxicity and threat. The models are trained on data from several different sources, with authentic social media posts and data translated from English. Our models perform well on test data with an F1-score above 0.94 for detecting toxic language and 0.86 for detecting threats. However, the models' performance decreases significantly when they are applied to new unseen social media data. Examining the intersection between toxic language and threats, we found that 20% of the threats on social media are not toxic, which means that they would not be detected using only methods for detecting toxic language. Our finding highlights the difficulties with harmful language and the need to use different methods to detect different kinds of harmful language.","Shrestha A,Kaati L,Akrami N,Lindén K,Moshfegh A",,,Harmful Communication: Detection of Toxic Language and Threats on Swedish,,,10.1145/3625007.3627597 , Conference Paper,,"AbstractHarmful communication, such as toxic language and threats directed toward individuals or groups, is a common problem on most social media platforms and online spaces. While several approaches exist for detecting toxic language and threats in English, few attempts have detected such communication in Swedish. Thus, we used transfer learning and BERT to train two machine learning models: one that detects toxic language and one that detects threats in Swedish. We also examined the intersection between toxicity and threat. The models are trained on data from several different sources, with authentic social media posts and data translated from English. Our models perform well on test data with an F1-score above 0.94 for detecting toxic language and 0.86 for detecting threats. However, the models' performance decreases significantly when they are applied to new unseen social media data. Examining the intersection between toxic language and threats, we found that 20% of the threats on social media are not toxic, which means that they would not be detected using only methods for detecting toxic language. Our finding highlights the difficulties with harmful language and the need to use different methods to detect different kinds of harmful language.",,,,,ACM ,"Proceedings of the International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023, Kusadasi, Turkey, November 6-9, 2023  ",,out_but_toxicity,
2814,"**Title**Mitigating Toxicity in Dialogue Agents through Adversarial Reinforcement Learning

**Abstract**Large Language Models (LLMs) have revolutionized dialogue agents, but they still suffer from biases, inconsis-
             tencies, and factual inaccuracies. This paper focuses on addressing toxicity, a critical aspect of the ""Diversity,
            non-discrimination, and fairness"" pillar of Trustworthy AI, in dialogue agents. We propose a methodology
            inspired by InstructGPT and ChatGPT to mitigate toxicity in chatbots by incorporating toxicity detection tools
           from industry leaders, such as Microsoft and Google Jigsaw, into a reward model. The reward model was extended
          by our developed ToxDialogDefender, a context-aware toxic language identification model. To evaluate our
            approach, we curate a dataset of 1.5 million comments, with 14.13% serving as successful adversarial examples, to
           induce toxicity in the BlenderBot 1 90M model. While our primary focus is on BlenderBot 1, our approach is
             applicable to models with similar Seq2Seq architectures. Experimental results demonstrate a substantial reduction
            in toxicity levels from 24% to 5%, as validated by a subset analysis. This research highlights the potential for
             integrating toxicity mitigation techniques into the training paradigm of dialogue agents, paving the way for more
          more aligned and unbiased conversational AI systems.

       Keywords
             Toxicity, Alignment, Large Language Models, Reinforcement Learning



1. Introduction

Dialogue agents driven by open-domain chatbots [1, 2] play a pivotal role in applications like restaurant
reservations [3], healthcare [4] and online shopping [5]. More recent cases of general-purpose dialog
agents are ChatGPT [6] or Llama 2 [7], which have been trained to follow societal norms. These models
undergo training with extensive datasets from platforms like Reddit1, Twitter (currently X2), and 4chan3,
with examples including BlenderBot 1 [1], TwitterBot Tay [8], and Luda [9]. However, these data
sources are known for producing toxic content [10, 11, 12], leading to undesirable behaviors observed
in the output of these models. Toxicity mitigation is a key task at a time when the research community
is fervently engaged in AI alignment and in ensuring that AI adopts human principles such as respect,
fairness, non-discrimination, etc [13].
  This research focuses on mitigating toxic speech in dialogue agents, which has been defined repeatedly
as rude, disrespectful, or unreasonable comments likely to disrupt conversations4, often related to gender,
politics, race, or culture [14]. Previous efforts aimed at reducing toxicity in dialogue agents include
continuous curation of datasets [15, 16], toxic behavior detection during text generation [17, 18], and
safety layers [1, 19]. While effective, these approaches have limitations (𝐿):

• 𝐿1: The continuous curation of datasets is expensive, requiring human annotators at every stage. In


AEQUITAS 2024: Workshop on Fairness and Bias in AI | co-located with ECAI 2024, Santiago de Compostela, Spain
*Corresponding author.
$ guillermo.villate@tecnalia.com (G. Villate-Castillo); borja.sanz@deusto.es (B. Sanz); javier.delser@tecnalia.com (J. Del Ser)
   0009-0001-0783-7984 (G. Villate-Castillo); 0000-0003-2039-7773 (B. Sanz); 0000-0002-1260-9775 (J. Del Ser)

          © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
1Reddit:https://www.reddit.com/
2X:https://twitter.com/
34chan:https://www.4chan.org/index.php
4Perspective   API,  About   the  API   -   Attributes  and  Languages,   https://developers.perspectiveapi.com/s/CEURceur-ws.org","Villate-Castillo G,Sanz B,Ser J",,,Mitigating Toxicity in Dialogue Agents through Adversarial Reinforcement Learning,3808,, , Conference Paper,,"Large Language Models (LLMs) have revolutionized dialogue agents, but they still suffer from biases, inconsis-
             tencies, and factual inaccuracies. This paper focuses on addressing toxicity, a critical aspect of the ""Diversity,
            non-discrimination, and fairness"" pillar of Trustworthy AI, in dialogue agents. We propose a methodology
            inspired by InstructGPT and ChatGPT to mitigate toxicity in chatbots by incorporating toxicity detection tools
           from industry leaders, such as Microsoft and Google Jigsaw, into a reward model. The reward model was extended
          by our developed ToxDialogDefender, a context-aware toxic language identification model. To evaluate our
            approach, we curate a dataset of 1.5 million comments, with 14.13% serving as successful adversarial examples, to
           induce toxicity in the BlenderBot 1 90M model. While our primary focus is on BlenderBot 1, our approach is
             applicable to models with similar Seq2Seq architectures. Experimental results demonstrate a substantial reduction
            in toxicity levels from 24% to 5%, as validated by a subset analysis. This research highlights the potential for
             integrating toxicity mitigation techniques into the training paradigm of dialogue agents, paving the way for more
          more aligned and unbiased conversational AI systems.

       Keywords
             Toxicity, Alignment, Large Language Models, Reinforcement Learning



1. Introduction

Dialogue agents driven by open-domain chatbots [1, 2] play a pivotal role in applications like restaurant
reservations [3], healthcare [4] and online shopping [5]. More recent cases of general-purpose dialog
agents are ChatGPT [6] or Llama 2 [7], which have been trained to follow societal norms. These models
undergo training with extensive datasets from platforms like Reddit1, Twitter (currently X2), and 4chan3,
with examples including BlenderBot 1 [1], TwitterBot Tay [8], and Luda [9]. However, these data
sources are known for producing toxic content [10, 11, 12], leading to undesirable behaviors observed
in the output of these models. Toxicity mitigation is a key task at a time when the research community
is fervently engaged in AI alignment and in ensuring that AI adopts human principles such as respect,
fairness, non-discrimination, etc [13].
  This research focuses on mitigating toxic speech in dialogue agents, which has been defined repeatedly
as rude, disrespectful, or unreasonable comments likely to disrupt conversations4, often related to gender,
politics, race, or culture [14]. Previous efforts aimed at reducing toxicity in dialogue agents include
continuous curation of datasets [15, 16], toxic behavior detection during text generation [17, 18], and
safety layers [1, 19]. While effective, these approaches have limitations (𝐿):

• 𝐿1: The continuous curation of datasets is expensive, requiring human annotators at every stage. In


AEQUITAS 2024: Workshop on Fairness and Bias in AI | co-located with ECAI 2024, Santiago de Compostela, Spain
*Corresponding author.
$ guillermo.villate@tecnalia.com (G. Villate-Castillo); borja.sanz@deusto.es (B. Sanz); javier.delser@tecnalia.com (J. Del Ser)
   0009-0001-0783-7984 (G. Villate-Castillo); 0000-0003-2039-7773 (B. Sanz); 0000-0002-1260-9775 (J. Del Ser)

          © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
1Reddit:https://www.reddit.com/
2X:https://twitter.com/
34chan:https://www.4chan.org/index.php
4Perspective   API,  About   the  API   -   Attributes  and  Languages,   https://developers.perspectiveapi.com/s/CEURceur-ws.org",,,,,CEUR-WS.org ,"Proceedings of the 2nd Workshop on Fairness and Bias in AI co-located with 27th European Conference on Artificial Intelligence (ECAI 2024), Santiago de Compostela, Spain, October 20th, 2024  ",,detox,
2815,"**Title**Mitigating Text Toxicity with Counterfactual Generation

**Abstract**An increasingly prevalent problem for intelli-
    gent technologies is text safety, as uncontrolled
    systems may generate recommendations to
     their users that lead to injury or life-threatening
    consequences. However, the degree of explic-
    itness of a generated statement that can cause
    physical harm varies. In this paper, we distin-
    guish types of text that can lead to physical
   harm and establish one particularly underex-
    plored category: covertly unsafe text. Then,
   we further break down this category with re-
    spect to the system’s information and discuss
    solutions to mitigate the generation of text in
    each of these subcategories. Ultimately, our
   work defines the problem of covertly unsafe
    language that causes physical harm and argues
     that this subtle yet dangerous issue needs to be
    prioritized by stakeholders and regulators. We
    highlight mitigation strategies to inspire future
    researchers to tackle this challenging problem
    and help improve safety within smart systems.
1  Introduction
In recent years, intelligent personal assistants have
increased information accessibility. However, this
has also raised concerns for user safety since these
systems may provide dangerous recommendations
to unsuspecting users. For instance, a child may
ask a device for a fun challenge. The device may
respond with an unsafe viral internet challenge
such as the salt and ice challenge, where partic-
ipants cover their body with salt and rub it with
ice, causing frostbite-like pain1. Though work has
been done in mitigating violent language and hate
speech in natural language systems (Kiritchenko
et al., 2021), there has been a relatively minimal ex-
ploration into covertly unsafe statements that may

    *Equal Contribution.
   1wikipedia.org/wiki/Salt_and_ice_challengeFigure 1: Example statements that can lead to the physi-
cal harm of people; we focus on covertly unsafe text.


lead to injury or even fatal consequences. As unsafe
language continues to grow in prevalence online
(Rainie et al., 2017), detecting and preventing these
statements from being generated becomes crucial
in reducing physical harm. Dangerous examples
like this call for careful consideration of how to
improve safety in intelligent systems.
  A broad spectrum of language can lead to phys-
ical harm, including overtly violent, covertly dan-
gerous, or otherwise indirectly unsafe statements.
Some texts may instigate immediate physical harm
if followed, while others may contain prejudices
that motivate future acts of harm. To better under-
stand these nuances, we examine this spectrum and
distinguish subcategories based on two key notions:
whether a statement is actionable and physically
unsafe and, if so, whether it is explicitly dangerous.
  An example of an overtly unsafe statement is
“punch his face” because “punch” is commonly
considered violent and detectable independent of
any deeper form of reasoning. In contrast, “pour
water on a grease fire” is an example of covertly
unsafe language2; the sentence structure and vo-
cabulary do not have explicitly violent semantics,

    2verywellhealth.com/how-to-put-out-a-grease-fire-
12987092914""I'll shoot you""
""Push him down the stairs""
""Stick a fork in an electrical outlet""
""Take a bite out of a ghost pepper""
""He's a thug. This is his address...""
""She's asking for it with that outfit""Overtly
Unsafe

Covertly
Unsafe

Indirectly
Unsafe","Bhan M,Vittaut JN,Achache N,Legrand V,Chesneau N,Blangero A,Murris J,Lesot MJ",,,Mitigating Text Toxicity with Counterfactual Generation,abs/2405.09948,,10.48550/ARXIV.2405.09948 , Journal Article,,"An increasingly prevalent problem for intelli-
    gent technologies is text safety, as uncontrolled
    systems may generate recommendations to
     their users that lead to injury or life-threatening
    consequences. However, the degree of explic-
    itness of a generated statement that can cause
    physical harm varies. In this paper, we distin-
    guish types of text that can lead to physical
   harm and establish one particularly underex-
    plored category: covertly unsafe text. Then,
   we further break down this category with re-
    spect to the system’s information and discuss
    solutions to mitigate the generation of text in
    each of these subcategories. Ultimately, our
   work defines the problem of covertly unsafe
    language that causes physical harm and argues
     that this subtle yet dangerous issue needs to be
    prioritized by stakeholders and regulators. We
    highlight mitigation strategies to inspire future
    researchers to tackle this challenging problem
    and help improve safety within smart systems.
1  Introduction
In recent years, intelligent personal assistants have
increased information accessibility. However, this
has also raised concerns for user safety since these
systems may provide dangerous recommendations
to unsuspecting users. For instance, a child may
ask a device for a fun challenge. The device may
respond with an unsafe viral internet challenge
such as the salt and ice challenge, where partic-
ipants cover their body with salt and rub it with
ice, causing frostbite-like pain1. Though work has
been done in mitigating violent language and hate
speech in natural language systems (Kiritchenko
et al., 2021), there has been a relatively minimal ex-
ploration into covertly unsafe statements that may

    *Equal Contribution.
   1wikipedia.org/wiki/Salt_and_ice_challengeFigure 1: Example statements that can lead to the physi-
cal harm of people; we focus on covertly unsafe text.


lead to injury or even fatal consequences. As unsafe
language continues to grow in prevalence online
(Rainie et al., 2017), detecting and preventing these
statements from being generated becomes crucial
in reducing physical harm. Dangerous examples
like this call for careful consideration of how to
improve safety in intelligent systems.
  A broad spectrum of language can lead to phys-
ical harm, including overtly violent, covertly dan-
gerous, or otherwise indirectly unsafe statements.
Some texts may instigate immediate physical harm
if followed, while others may contain prejudices
that motivate future acts of harm. To better under-
stand these nuances, we examine this spectrum and
distinguish subcategories based on two key notions:
whether a statement is actionable and physically
unsafe and, if so, whether it is explicitly dangerous.
  An example of an overtly unsafe statement is
“punch his face” because “punch” is commonly
considered violent and detectable independent of
any deeper form of reasoning. In contrast, “pour
water on a grease fire” is an example of covertly
unsafe language2; the sentence structure and vo-
cabulary do not have explicitly violent semantics,

    2verywellhealth.com/how-to-put-out-a-grease-fire-
12987092914""I'll shoot you""
""Push him down the stairs""
""Stick a fork in an electrical outlet""
""Take a bite out of a ghost pepper""
""He's a thug. This is his address...""
""She's asking for it with that outfit""Overtly
Unsafe

Covertly
Unsafe

Indirectly
Unsafe",,,,, CoRR,  ,,detox,
2816,"**Title**FrenchToxicityPrompts: a Large Benchmark for Evaluating and Mitigating Toxicity in French Texts

**Abstract**Large language models (LLMs) are increasingly popular but are also prone to generating bias, toxic or harmful
language, which can have detrimental effects on individuals and communities.  Although most efforts is put to
assess and mitigate toxicity in generated content,  it is primarily concentrated on English, while it’s essential to
consider other languages as well.  For addressing this issue, we create and release FrenchToxicityPrompts, a
dataset of 50K naturally occurring French prompts and their continuations, annotated with toxicity scores from a
widely used toxicity classifier. We evaluate 14 different models from four prevalent open-sourced families of LLMs
against our dataset to assess their potential toxicity across various dimensions. We hope that our contribution will
foster future research on toxicity detection and mitigation beyond English.

Keywords: Text generation, toxicity, dataset, French, large language models             1.  Introduction

Generative large language models such as GPT4
(OpenAI,  2023), GPT3 (Brown  et  al.,  2020),
BLOOM (Scao et al., 2022) or LLaMa (Touvron
et al., 2023a,b) have recently gained significant at-
tention due to their ability to generate human-like
text across a wide range of languages and natu-
ral language processing (NLP) tasks.  However,
their proliferation has also raised concerns about
the potential for generating toxic or harmful con-
tent (Bender et al., 2021; Yong et al., 2023). These
models are exposed to huge quantities of text data,
which may contain significant amounts of toxicity,
and present risks of reproducing harmful content.
  Most effort to evaluate and mitigate toxicity in
generated content focuses on English, but the
problem extends naturally to other languages, and
there is a need to address it in a multilingual and
multicultural context (Talat et al., 2022). Starting
from this observation, our main motivation is to
evaluate toxicity both on real and non-English data
(here, French). For this, we created a new dataset
dedicated to assessing toxicity in generative LLMs
in French.  To annotate the data, we relied on
the widely used toxicity detector Perspective API1,
available in 18 languages, including French. We
selected four prevalent open-sourced families of
generative LLMs, diversified with various parame-
ter sizes, to evaluate the impact of the type of mod-
els and their sizes on toxicity generation.
Our contribution is two-fold:
• We craft FrenchToxicityPrompts, a large dataset
  of 50,000 real text prompts and continuations in


  1https://www.perspectiveapi.com/  French, to be released to the NLP community2;

• We evaluate different generative LLMs of differ-
  ent parameter sizes in order to illustrate how
  FrenchToxicityPrompts allows us to identify po-
  tential toxicity across various axes.
In what follows, we first review some related work,
and describe the dataset creation. Next, we focus
on the generation processes, and provide insights
into the toxicity of the generated content.  Finally,
we discuss the outcomes and provide some con-
cluding remarks.


            2.  Related Work

Recently, many studies have explored the pres-
ence of toxicity in the context of natural language
generation (NLG). Sheng et al. (2019) have used
template prompts to examine the existence of so-
cial biases in NLG, showing that LLMs are prone to
generating biased and harmful language. Wallace
et al. (2019) demonstrated that certain nonsensi-
cal prompts can incite the generation of toxic out-
put in the GPT-2 model. Deshpande et al. (2023)
recently discovered that assigning personas to
chatGPT can increase the toxicity of generated
text, depending on the type of persona  it is as-
signed. They also found patterns that reflect in-
herent discriminatory biases in the model, where
specific entities (e.g., certain races) are targeted
more than others irrespective of the assigned per-
sona, that reflect inherent discriminatory biases in
the model. Gehman et al. (2020) crafted the Real-

   2available  here:   https://download.europe.
naverlabs.com/FrenchToxicityPrompts/105","Brun C,Nikoulina V",,,FrenchToxicityPrompts: a Large Benchmark for Evaluating and Mitigating Toxicity in French Texts,abs/2406.17566,,10.48550/ARXIV.2406.17566 , Journal Article,,"Large language models (LLMs) are increasingly popular but are also prone to generating bias, toxic or harmful
language, which can have detrimental effects on individuals and communities.  Although most efforts is put to
assess and mitigate toxicity in generated content,  it is primarily concentrated on English, while it’s essential to
consider other languages as well.  For addressing this issue, we create and release FrenchToxicityPrompts, a
dataset of 50K naturally occurring French prompts and their continuations, annotated with toxicity scores from a
widely used toxicity classifier. We evaluate 14 different models from four prevalent open-sourced families of LLMs
against our dataset to assess their potential toxicity across various dimensions. We hope that our contribution will
foster future research on toxicity detection and mitigation beyond English.

Keywords: Text generation, toxicity, dataset, French, large language models             1.  Introduction

Generative large language models such as GPT4
(OpenAI,  2023), GPT3 (Brown  et  al.,  2020),
BLOOM (Scao et al., 2022) or LLaMa (Touvron
et al., 2023a,b) have recently gained significant at-
tention due to their ability to generate human-like
text across a wide range of languages and natu-
ral language processing (NLP) tasks.  However,
their proliferation has also raised concerns about
the potential for generating toxic or harmful con-
tent (Bender et al., 2021; Yong et al., 2023). These
models are exposed to huge quantities of text data,
which may contain significant amounts of toxicity,
and present risks of reproducing harmful content.
  Most effort to evaluate and mitigate toxicity in
generated content focuses on English, but the
problem extends naturally to other languages, and
there is a need to address it in a multilingual and
multicultural context (Talat et al., 2022). Starting
from this observation, our main motivation is to
evaluate toxicity both on real and non-English data
(here, French). For this, we created a new dataset
dedicated to assessing toxicity in generative LLMs
in French.  To annotate the data, we relied on
the widely used toxicity detector Perspective API1,
available in 18 languages, including French. We
selected four prevalent open-sourced families of
generative LLMs, diversified with various parame-
ter sizes, to evaluate the impact of the type of mod-
els and their sizes on toxicity generation.
Our contribution is two-fold:
• We craft FrenchToxicityPrompts, a large dataset
  of 50,000 real text prompts and continuations in


  1https://www.perspectiveapi.com/  French, to be released to the NLP community2;

• We evaluate different generative LLMs of differ-
  ent parameter sizes in order to illustrate how
  FrenchToxicityPrompts allows us to identify po-
  tential toxicity across various axes.
In what follows, we first review some related work,
and describe the dataset creation. Next, we focus
on the generation processes, and provide insights
into the toxicity of the generated content.  Finally,
we discuss the outcomes and provide some con-
cluding remarks.


            2.  Related Work

Recently, many studies have explored the pres-
ence of toxicity in the context of natural language
generation (NLG). Sheng et al. (2019) have used
template prompts to examine the existence of so-
cial biases in NLG, showing that LLMs are prone to
generating biased and harmful language. Wallace
et al. (2019) demonstrated that certain nonsensi-
cal prompts can incite the generation of toxic out-
put in the GPT-2 model. Deshpande et al. (2023)
recently discovered that assigning personas to
chatGPT can increase the toxicity of generated
text, depending on the type of persona  it is as-
signed. They also found patterns that reflect in-
herent discriminatory biases in the model, where
specific entities (e.g., certain races) are targeted
more than others irrespective of the assigned per-
sona, that reflect inherent discriminatory biases in
the model. Gehman et al. (2020) crafted the Real-

   2available  here:   https://download.europe.
naverlabs.com/FrenchToxicityPrompts/105",,,,, CoRR,  ,,out_but_toxicity,
2817,"**Title**ReZG: Retrieval-augmented zero-shot counter narrative generation for hate speech

**Abstract**Abstract:The proliferation of hate speech (HS) on social media poses a serious threat to societal security. Automatic counter narrative (CN) generation, as an active strategy for HS intervention, has garnered increasing attention in recent years. Existing methods for automatically generating CNs mainly rely on re-training or fine-tuning pre-trained language models (PLMs) on human-curated CN corpora. Unfortunately, the annotation speed of CN corpora cannot keep up with the growth of HS targets, while generating specific and effective CNs for unseen targets remains a significant challenge for the model. To tackle this issue, we propose Retrieval-Augmented Zero-shot Generation (ReZG) to generate CNs with high-specificity for unseen targets. Specifically, we propose a multi-dimensional hierarchical retrieval method that integrates stance, semantics, and fitness, extending the retrieval metric from single dimension to multiple dimensions suitable for the knowledge that refutes HS. Then, we implement an energy-based constrained decoding mechanism that enables PLMs to use differentiable knowledge preservation, countering, and fluency constraint functions instead of in-target CNs as control signals for generation, thereby achieving zero-shot CN generation. With the above techniques, ReZG can integrate external knowledge flexibly and improve the specificity of CNs. Experimental results show that ReZG exhibits stronger generalization capabilities and outperforms strong baselines with significant improvements of 2.0%+ in the relevance and 4.5%+ in the countering success rate metrics.","Jiang S,Tang W,Chen X,Tang R,Wang H,Wang W",,,ReZG: Retrieval-augmented zero-shot counter narrative generation for hate speech,620,,10.1016/J.NEUCOM.2024.129140 , Journal Article,,"Abstract:The proliferation of hate speech (HS) on social media poses a serious threat to societal security. Automatic counter narrative (CN) generation, as an active strategy for HS intervention, has garnered increasing attention in recent years. Existing methods for automatically generating CNs mainly rely on re-training or fine-tuning pre-trained language models (PLMs) on human-curated CN corpora. Unfortunately, the annotation speed of CN corpora cannot keep up with the growth of HS targets, while generating specific and effective CNs for unseen targets remains a significant challenge for the model. To tackle this issue, we propose Retrieval-Augmented Zero-shot Generation (ReZG) to generate CNs with high-specificity for unseen targets. Specifically, we propose a multi-dimensional hierarchical retrieval method that integrates stance, semantics, and fitness, extending the retrieval metric from single dimension to multiple dimensions suitable for the knowledge that refutes HS. Then, we implement an energy-based constrained decoding mechanism that enables PLMs to use differentiable knowledge preservation, countering, and fluency constraint functions instead of in-target CNs as control signals for generation, thereby achieving zero-shot CN generation. With the above techniques, ReZG can integrate external knowledge flexibly and improve the specificity of CNs. Experimental results show that ReZG exhibits stronger generalization capabilities and outperforms strong baselines with significant improvements of 2.0%+ in the relevance and 4.5%+ in the countering success rate metrics.",,,,, Neurocomputing,  ,,detox,
2818,"**Title**Basque and Spanish Counter Narrative Generation: Data Creation and Evaluation

**Abstract**r Narratives (CNs) are non-negative textual responses to Hate Speech (HS) aiming at defusing online hatred
 tigating its spreading across media. Despite the recent increase in HS content posted online, research on
atic CN generation has been relatively scarce and predominantly focused on English. In this paper, we present
N-EUS, a new Basque and Spanish dataset for CN generation developed by means of Machine Translation
nd professional post-edition. Being a parallel corpus, also with respect to the original English CONAN, it allows
orm novel research on multilingual and crosslingual automatic generation of CNs. Our experiments on CN
 tion with mT5, a multilingual encoder-decoder model, show that generation greatly benefits from training on
dited data, as opposed to relying on silver MT data only. These results are confirmed by their correlation with
 tative manual evaluation, demonstrating that manually revised training data remains crucial for the quality
generated CNs. Furthermore, multilingual data augmentation improves results over monolingual settings
 cturally similar languages such as English and Spanish, while being detrimental for Basque, a language
  Similar findings occur in zero-shot crosslingual evaluations, where model transfer (fine-tuning in English and
 ting in a different target language) outperforms fine-tuning mT5 on machine translated data for Spanish but
 Basque. This provides an interesting insight into the asymmetry in the multilinguality of generative models, a
 ging topic which is still open to research.
nt Warning: This paper contains examples of offensive language that do not reflect the authors’ views.

 rds: Counter Narratives, Hate Speech, Multilinguality, Text Generation

        1.  Introduction                  ple who produce the HS. In this context, Counter
                                              Narratives (CNs) have been proposed as an ef-
  last few years, and partially due to the    fective approach to tackle and mitigate the spread
 mity of citizens when interacting in the on-    of HS (Benesch, 2014; Schieb and Preuss, 2016).
orld, hate speech (HS) has become an ever-   Counter Narratives are non-aggressive responses
 sing media presence, to the point of being    to a hateful comment that includes non-negative
  normalized. Davidson et al. (2017) defined    factual-based argumentative feedback (Benesch,
 “language that is used to express hatred to-   2014; Schieb and Preuss, 2016). An example of an
 a targeted group or is intended to be deroga-  HS-CN pair can be observed below (Chung et al.,
o humiliate, or to insult the members of the    2019):
 ”
                                           Hate Speech Islamic are criminals: they
 ently, online sites and social media platforms
                                                  rape, enslave and murder people. Islam
 nstantly updating their policies to fight the
                                                                is more a worship than a religion and we
 volving online hate, with the majority taking
                                          do not have anything to share with them.
 k-and-delete approach. In order to facilitate
 rkload that these policies could produce, au-                                          Counter Narrative The myth that Mus-
 c detection of HS has become a very ac-                                                    lims are dangerous and violent is a prod-
 search field, including the development of                                                   uct of our vilifying media. Don’t believe
 tasets (Basile et al., 2019; Kolhatkar et al.,                                                  everything you read.
 and machine learning and deep learning
ques (Nobata et al., 2016; Davidson et al.,     While recent interest in automatic approaches
 Faris et al., 2020).                               to CN studies has grown considerably, including
as been argued that while such methods    studies on data curation (Chung et al., 2019; Fan-
 on content moderation can immediately re-   ton et al., 2021), detection (Chung et al., 2021a;
 he amount of HS,  it draws limits on free   Mathew et al., 2018), and generation (Tekiroglu
h (Schieb and Preuss, 2016) and may not be    et al., 2020; Chung et al., 2021b; Zhu and Bhat,
ve at challenging HS in the long term. For ex-   2021; Tekiroğlu et al., 2022), experimental work on
   it does not address the root causes that lead    automatic CN generation has been predominantly
HS or attempts to change the outlook of peo-   carried out for English. This is due to the lack of

                                   2132","Bengoetxea J,Chung YL,Guerini M,Agerri R",,,Basque and Spanish Counter Narrative Generation: Data Creation and Evaluation,,, , Conference Paper,,"r Narratives (CNs) are non-negative textual responses to Hate Speech (HS) aiming at defusing online hatred
 tigating its spreading across media. Despite the recent increase in HS content posted online, research on
atic CN generation has been relatively scarce and predominantly focused on English. In this paper, we present
N-EUS, a new Basque and Spanish dataset for CN generation developed by means of Machine Translation
nd professional post-edition. Being a parallel corpus, also with respect to the original English CONAN, it allows
orm novel research on multilingual and crosslingual automatic generation of CNs. Our experiments on CN
 tion with mT5, a multilingual encoder-decoder model, show that generation greatly benefits from training on
dited data, as opposed to relying on silver MT data only. These results are confirmed by their correlation with
 tative manual evaluation, demonstrating that manually revised training data remains crucial for the quality
generated CNs. Furthermore, multilingual data augmentation improves results over monolingual settings
 cturally similar languages such as English and Spanish, while being detrimental for Basque, a language
  Similar findings occur in zero-shot crosslingual evaluations, where model transfer (fine-tuning in English and
 ting in a different target language) outperforms fine-tuning mT5 on machine translated data for Spanish but
 Basque. This provides an interesting insight into the asymmetry in the multilinguality of generative models, a
 ging topic which is still open to research.
nt Warning: This paper contains examples of offensive language that do not reflect the authors’ views.

 rds: Counter Narratives, Hate Speech, Multilinguality, Text Generation

        1.  Introduction                  ple who produce the HS. In this context, Counter
                                              Narratives (CNs) have been proposed as an ef-
  last few years, and partially due to the    fective approach to tackle and mitigate the spread
 mity of citizens when interacting in the on-    of HS (Benesch, 2014; Schieb and Preuss, 2016).
orld, hate speech (HS) has become an ever-   Counter Narratives are non-aggressive responses
 sing media presence, to the point of being    to a hateful comment that includes non-negative
  normalized. Davidson et al. (2017) defined    factual-based argumentative feedback (Benesch,
 “language that is used to express hatred to-   2014; Schieb and Preuss, 2016). An example of an
 a targeted group or is intended to be deroga-  HS-CN pair can be observed below (Chung et al.,
o humiliate, or to insult the members of the    2019):
 ”
                                           Hate Speech Islamic are criminals: they
 ently, online sites and social media platforms
                                                  rape, enslave and murder people. Islam
 nstantly updating their policies to fight the
                                                                is more a worship than a religion and we
 volving online hate, with the majority taking
                                          do not have anything to share with them.
 k-and-delete approach. In order to facilitate
 rkload that these policies could produce, au-                                          Counter Narrative The myth that Mus-
 c detection of HS has become a very ac-                                                    lims are dangerous and violent is a prod-
 search field, including the development of                                                   uct of our vilifying media. Don’t believe
 tasets (Basile et al., 2019; Kolhatkar et al.,                                                  everything you read.
 and machine learning and deep learning
ques (Nobata et al., 2016; Davidson et al.,     While recent interest in automatic approaches
 Faris et al., 2020).                               to CN studies has grown considerably, including
as been argued that while such methods    studies on data curation (Chung et al., 2019; Fan-
 on content moderation can immediately re-   ton et al., 2021), detection (Chung et al., 2021a;
 he amount of HS,  it draws limits on free   Mathew et al., 2018), and generation (Tekiroglu
h (Schieb and Preuss, 2016) and may not be    et al., 2020; Chung et al., 2021b; Zhu and Bhat,
ve at challenging HS in the long term. For ex-   2021; Tekiroğlu et al., 2022), experimental work on
   it does not address the root causes that lead    automatic CN generation has been predominantly
HS or attempts to change the outlook of peo-   carried out for English. This is due to the lack of

                                   2132",,,,,ELRA and ICCL ,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC/COLING 2024, 20-25 May, 2024, Torino, Italy  ",,out_but_toxicity,
2819,"**Title**Leveraging Pre-existing Resources for Data-Efficient Counter-Narrative Generation in Korean

**Abstract**Warning: This paper contains content that may be offensive or upsetting.
Counter-narrative generation, i.e., the generation of fact-based responses to hate speech with the aim of correcting
discriminatory beliefs, has been demonstrated to be an effective method to combat hate speech. However, its
effectiveness is limited by the resource-intensive nature of dataset construction processes and only focuses on
the primary language. To alleviate this problem, we propose a Korean Hate Speech Counter Punch (KHSCP),
a cost-effective counter-narrative generation method in the Korean language. To this end, we release the first
counter-narrative generation dataset in Korean and pose two research questions. Under the questions, we propose an
effective augmentation method and investigate the reasonability of a large language model to overcome data scarcity
in low-resource environments by leveraging existing resources. In this regard, we conduct several experiments to
verify the effectiveness of the proposed method. Our results reveal that applying pre-existing resources can improve
the generation performance by a significant margin. Through deep analysis on these experiments, this work proposes
the possibility of overcoming the challenges of generating counter-narratives in low-resource environments.

Keywords: Hate Speech, Counter-Narrative Generation, Dataset Construction1.  IntroductionHate Speech: Women are basically childlike, they remain
this way most of their lives. Soft and emotional. It has dev-
astated our once great patriarchal civilizations.
Counter-Narrative: Soft and emotional are personality traits,† Corresponding author                       and constructing sentences based on credible ev-

                                    10380","Lee S,Park C,Jung D,Moon H,Seo J,Eo S,Lim H",,,Leveraging Pre-existing Resources for Data-Efficient Counter-Narrative Generation in Korean,,, , Conference Paper,,"Warning: This paper contains content that may be offensive or upsetting.
Counter-narrative generation, i.e., the generation of fact-based responses to hate speech with the aim of correcting
discriminatory beliefs, has been demonstrated to be an effective method to combat hate speech. However, its
effectiveness is limited by the resource-intensive nature of dataset construction processes and only focuses on
the primary language. To alleviate this problem, we propose a Korean Hate Speech Counter Punch (KHSCP),
a cost-effective counter-narrative generation method in the Korean language. To this end, we release the first
counter-narrative generation dataset in Korean and pose two research questions. Under the questions, we propose an
effective augmentation method and investigate the reasonability of a large language model to overcome data scarcity
in low-resource environments by leveraging existing resources. In this regard, we conduct several experiments to
verify the effectiveness of the proposed method. Our results reveal that applying pre-existing resources can improve
the generation performance by a significant margin. Through deep analysis on these experiments, this work proposes
the possibility of overcoming the challenges of generating counter-narratives in low-resource environments.

Keywords: Hate Speech, Counter-Narrative Generation, Dataset Construction1.  IntroductionHate Speech: Women are basically childlike, they remain
this way most of their lives. Soft and emotional. It has dev-
astated our once great patriarchal civilizations.
Counter-Narrative: Soft and emotional are personality traits,† Corresponding author                       and constructing sentences based on credible ev-

                                    10380",,,,,ELRA and ICCL ,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC/COLING 2024, 20-25 May, 2024, Torino, Italy  ",,out_but_toxicity,
2820,"**Title**A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation

**Abstract**This paper proposes a novel approach to eval-
    uate Counter Narrative (CN) generation using
    a Large Language Model (LLM) as an evalu-
     ator. We show that traditional automatic met-
     rics correlate poorly with human judgements
    and fail to capture the nuanced relationship be-
    tween generated CNs and human perception.
   To alleviate this, we introduce a model ranking
    pipeline based on pairwise comparisons of gen-
    erated CNs from different models, organized in
    a tournament-style format. The proposed eval-
    uation method achieves a high correlation with
   human preference, with a ρ score of 0.88. As an
    additional contribution, we leverage LLMs as
    zero-shot CN generators and provide a compar-
     ative analysis of chat, instruct, and base models,
    exploring their respective strengths and limita-
     tions. Through meticulous evaluation, includ-
    ing fine-tuning experiments, we elucidate the
    differences in performance and responsiveness
     to domain-specific data. We conclude that chat-
    aligned models in zero-shot are the best option
    for carrying out the task, provided they do not
    refuse to generate an answer due to security
    concerns.
   Warning: Please be advised that this research
    paper contains instances of hate speech that
   may be distressing or offensive to readers.
    These expressions are included for analysis and
    critique purposes only, and they do not reflect
    the beliefs or endorsements of the authors or
    the institution.

1  Introduction

The proliferation of misinformation and the dissem-
ination of harmful narratives has stressed the urgent
need for effective strategies to combat Hate Speech
(HS). This necessity has drawn significant attention
to the field of automatic CN generation, where con-
siderable research has focused on the use of LLMs
to fulfill this task (Chung et al., 2021; Tekiro˘glu
et al., 2022). However, difficulties in automaticallyassessing the quality of the generated CNs remain.
As is common in text generation tasks, while man-
ual evaluation is expensive, time-consuming, and
subjective, existing automatic methods often fail
to provide comprehensive insights or capture the
nuanced relationship between generated text and
human perception, overlooking crucial aspects of
effectiveness and relevance (Ni’mah et al., 2023).
Finally, the problem of CN evaluation is exacer-
bated by the lack of a ’universal truth’ and the
significant variations among possible references, as
shown in Table 1.
  In this paper we address the limitations of tra-
ditional evaluation metrics for CN generation by
proposing a novel automatic evaluation approach.
This method is motivated by the need to improve
upon existing metrics like BLEU, ROUGE and
BERTScore (Papineni et  al., 2002; Lin, 2004;
Zhang et al., 2020) which do not consider the spe-
cific HS to which the CN is responding to, an es-
sential aspect for accurately assessing the quality
of CNs. Our approach evaluates generated CNs
pairwise in a tournament-style format, with out-
comes determined without human intervention us-
ing JudgeLM (Zhu et al., 2023), a model explic-
itly trained to assess the quality of text.  Thus,
JudgeLM enables pairwise comparisons of CNs,
addressing the subjectivity of the task by breaking
it down into simpler binary classification problems.
To ensure the generalizability of our approach for
the task, we test it on two distinct corpora: CO-
NAN (Chung et al., 2019) and CONAN-MT (Fan-
ton et al., 2021a). Using various models to generate
texts of different quality means that we can eval-
uate model performance across a spectrum of CN
quality, ensuring that even subtle distinctions be-
tween good texts can be captured. This approach
ultimately aims for a higher correlation to human
preference than traditional metrics and ranks mod-
els based on their ability to generate high-quality
CNs.9572","Zubiaga I,Soroa A,Agerri R",,,A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation,,, , Conference Paper,,"This paper proposes a novel approach to eval-
    uate Counter Narrative (CN) generation using
    a Large Language Model (LLM) as an evalu-
     ator. We show that traditional automatic met-
     rics correlate poorly with human judgements
    and fail to capture the nuanced relationship be-
    tween generated CNs and human perception.
   To alleviate this, we introduce a model ranking
    pipeline based on pairwise comparisons of gen-
    erated CNs from different models, organized in
    a tournament-style format. The proposed eval-
    uation method achieves a high correlation with
   human preference, with a ρ score of 0.88. As an
    additional contribution, we leverage LLMs as
    zero-shot CN generators and provide a compar-
     ative analysis of chat, instruct, and base models,
    exploring their respective strengths and limita-
     tions. Through meticulous evaluation, includ-
    ing fine-tuning experiments, we elucidate the
    differences in performance and responsiveness
     to domain-specific data. We conclude that chat-
    aligned models in zero-shot are the best option
    for carrying out the task, provided they do not
    refuse to generate an answer due to security
    concerns.
   Warning: Please be advised that this research
    paper contains instances of hate speech that
   may be distressing or offensive to readers.
    These expressions are included for analysis and
    critique purposes only, and they do not reflect
    the beliefs or endorsements of the authors or
    the institution.

1  Introduction

The proliferation of misinformation and the dissem-
ination of harmful narratives has stressed the urgent
need for effective strategies to combat Hate Speech
(HS). This necessity has drawn significant attention
to the field of automatic CN generation, where con-
siderable research has focused on the use of LLMs
to fulfill this task (Chung et al., 2021; Tekiro˘glu
et al., 2022). However, difficulties in automaticallyassessing the quality of the generated CNs remain.
As is common in text generation tasks, while man-
ual evaluation is expensive, time-consuming, and
subjective, existing automatic methods often fail
to provide comprehensive insights or capture the
nuanced relationship between generated text and
human perception, overlooking crucial aspects of
effectiveness and relevance (Ni’mah et al., 2023).
Finally, the problem of CN evaluation is exacer-
bated by the lack of a ’universal truth’ and the
significant variations among possible references, as
shown in Table 1.
  In this paper we address the limitations of tra-
ditional evaluation metrics for CN generation by
proposing a novel automatic evaluation approach.
This method is motivated by the need to improve
upon existing metrics like BLEU, ROUGE and
BERTScore (Papineni et  al., 2002; Lin, 2004;
Zhang et al., 2020) which do not consider the spe-
cific HS to which the CN is responding to, an es-
sential aspect for accurately assessing the quality
of CNs. Our approach evaluates generated CNs
pairwise in a tournament-style format, with out-
comes determined without human intervention us-
ing JudgeLM (Zhu et al., 2023), a model explic-
itly trained to assess the quality of text.  Thus,
JudgeLM enables pairwise comparisons of CNs,
addressing the subjectivity of the task by breaking
it down into simpler binary classification problems.
To ensure the generalizability of our approach for
the task, we test it on two distinct corpora: CO-
NAN (Chung et al., 2019) and CONAN-MT (Fan-
ton et al., 2021a). Using various models to generate
texts of different quality means that we can eval-
uate model performance across a spectrum of CN
quality, ensuring that even subtle distinctions be-
tween good texts can be captured. This approach
ultimately aims for a higher correlation to human
preference than traditional metrics and ranks mod-
els based on their ability to generate high-quality
CNs.9572",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024  ",,detox,
2821,"**Title**Ixa at RefutES 2024: Leveraging Language Models for Counter Narrative Generation

**Abstract**The pervasive use of social media has streamlined communication, enhancing connectivity globally.
          However, this accessibility has also fueled the dissemination of hate speech, highlighting the platform’s
          dual nature as both a facilitator of dialogue and a breeding ground for harmful rhetoric. In response,
          Counter Narrative (CN) generation has emerged as a way to provide reasoned replies to offensive
           discourse, aiming to combat the spread of Hate Speech (HS) and foster empathy and understanding
            online. This paper details IXA Group’s participation in the RefutES shared task, which focuses on CN
           generation in Spanish. We explore the feasibility of an automatic system to distinguish between effective
          and ineffective CNs and evaluate whether Large Language Models (LLMs) can generate CNs in zero-shot
           (ZS) scenarios or if fine-tuning is ultimately necessary.

           Warning: Please be advised that this research paper contains instances of hate speech that may be
            distressing or offensive to readers. These expressions are included for analysis and critique purposes only,
         and they do not reflect the beliefs or endorsements of the authors or the institution.

       Keywords
          Counter Narrative Generation, Large Language Models, Evaluation, Natural Language



1. Introduction

The prevalence of social networks in contemporary life has revolutionized how people engage
with each other and share their thoughts and experiences. Yet, amidst the apparent benefits
of these platforms, anonymity and unrestricted expression has facilitated the proliferation
of hate speech, posing a significant challenge to the principles of inclusivity, tolerance, and
respect within communities. Targeting individuals based on inherent traits such as gender,
race, or religion, these messages not only inflict psychological harm, particularly on vulnerable
demographics like young people, but also pose a significant societal challenge. Conventional
approaches to mitigate this issue, such as content removal or user bans, often fall short, risking
perceptions of censorship and failing to address the root causes of hate crimes. In response, a
novel strategy has emerged: Counter Narrative (CN) generation. This innovative approach seeks
to combat offensive rhetoric by offering reasoned responses or outright rejections, fostering
empathy, understanding, and tolerance in online discourse. Within the realm of CN generation,
initiatives such as the RefutES [1] shared task have emerged. In RefutES, organized as part of


IberLEF 2024, September 2024, Valladolid, Spain
*Corresponding author.
$ irune.zubiaga@ehu.eus (I. Zubiaga); a.soroa@ehu.eus (A. Soroa); rodrigo.agerri@ehu.eus (R. Agerri)
   0009-0006-6212-7527 (I. Zubiaga); 0000-0001-8573-2654 (A. Soroa); 0000-0002-7303-7598 (R. Agerri)CEURCEURWorkshopProceedingshttp://ceur-ws.orgISSN 1613-0073http://ceur-ws.orgceur-ws.org","Zubiaga I,Soroa A,Agerri R",,,Ixa at RefutES 2024: Leveraging Language Models for Counter Narrative Generation,3756,, , Conference Paper,,"The pervasive use of social media has streamlined communication, enhancing connectivity globally.
          However, this accessibility has also fueled the dissemination of hate speech, highlighting the platform’s
          dual nature as both a facilitator of dialogue and a breeding ground for harmful rhetoric. In response,
          Counter Narrative (CN) generation has emerged as a way to provide reasoned replies to offensive
           discourse, aiming to combat the spread of Hate Speech (HS) and foster empathy and understanding
            online. This paper details IXA Group’s participation in the RefutES shared task, which focuses on CN
           generation in Spanish. We explore the feasibility of an automatic system to distinguish between effective
          and ineffective CNs and evaluate whether Large Language Models (LLMs) can generate CNs in zero-shot
           (ZS) scenarios or if fine-tuning is ultimately necessary.

           Warning: Please be advised that this research paper contains instances of hate speech that may be
            distressing or offensive to readers. These expressions are included for analysis and critique purposes only,
         and they do not reflect the beliefs or endorsements of the authors or the institution.

       Keywords
          Counter Narrative Generation, Large Language Models, Evaluation, Natural Language



1. Introduction

The prevalence of social networks in contemporary life has revolutionized how people engage
with each other and share their thoughts and experiences. Yet, amidst the apparent benefits
of these platforms, anonymity and unrestricted expression has facilitated the proliferation
of hate speech, posing a significant challenge to the principles of inclusivity, tolerance, and
respect within communities. Targeting individuals based on inherent traits such as gender,
race, or religion, these messages not only inflict psychological harm, particularly on vulnerable
demographics like young people, but also pose a significant societal challenge. Conventional
approaches to mitigate this issue, such as content removal or user bans, often fall short, risking
perceptions of censorship and failing to address the root causes of hate crimes. In response, a
novel strategy has emerged: Counter Narrative (CN) generation. This innovative approach seeks
to combat offensive rhetoric by offering reasoned responses or outright rejections, fostering
empathy, understanding, and tolerance in online discourse. Within the realm of CN generation,
initiatives such as the RefutES [1] shared task have emerged. In RefutES, organized as part of


IberLEF 2024, September 2024, Valladolid, Spain
*Corresponding author.
$ irune.zubiaga@ehu.eus (I. Zubiaga); a.soroa@ehu.eus (A. Soroa); rodrigo.agerri@ehu.eus (R. Agerri)
   0009-0006-6212-7527 (I. Zubiaga); 0000-0001-8573-2654 (A. Soroa); 0000-0002-7303-7598 (R. Agerri)CEURCEURWorkshopProceedingshttp://ceur-ws.orgISSN 1613-0073http://ceur-ws.orgceur-ws.org",,,,,CEUR-WS.org ,"Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2024) co-located with the Conference of the Spanish Society for Natural Language Processing (SEPLN 2024), Valladolid, Spain, September 24, 2024  ",,out_but_toxicity,
2822,"**Title**High-quality argumentative information in low resources approaches improve counter-narrative generation

**Abstract**It has been shown that high quality fine-tuning
    boosts the performance of language models,
    even if the size of the fine-tuning is small.
    In this work we show how highly targeted
    fine-tuning improves the task of hate speech
    counter-narrative generation in user-generated
     text, even for very small sizes of training (1722
    counter-narratives for English and 355 for
    Spanish). Providing a small subset of examples
    focusing on single argumentative strategies, to-
    gether with the argumentative analysis relevant
    to that strategy, yields counter-narratives that
    are as satisfactory as providing the whole set of
    counter-narratives. We also show that a good
    base model is required for the fine-tuning to
    have a positive impact. Indeed, for Spanish, the
    counter-narratives obtained without fine-tuning
    are mostly unacceptable, and, while fine-tuning
    improves their overall quality, the performance
      still remains quite unsatisfactory.

1  Introduction
Large Language Models (LLMs) have shown im-
pressive capabilities to generate acceptable texts in
a number of scenarios. This has allowed to tackle
tasks that were considered too difficult until very
recently. Counter-narrative generation in particu-
lar is a very challenging task because it requires
reasoning, argumentation and world knowledge,
in addition to the ability to produce text that is
grammatically correct and pragmatically felicitous.
Often, counter-narratives resort to pieces of infor-
mation that are only indirectly implied in the text.
  Counter-narrative generation is arising as a valu-
able application to mitigate some forms of violence
in social media. Indeed, automatically generated
counter-narratives have been proposed as a primary
input to facilitate the task of NGO specialists to
counter hate speech (Tekiro˘glu et al., 2020).
  The predominant strategy adopted so far to
counter hate speech in social media is to recog-
nize, block and delete these messages and/or theusers that generated it. This strategy has two main
disadvantages. The first one is that blocking and
deleting may prevent a hate message from spread-
ing, but does not counter its consequences on those
who were already reached by it. The second one is
that it can generate overblocking or censorship.
  An alternative to blocking that has been gaining
attention in the last years, is to ""oppose hate content
with counter-narratives (i.e. informed textual re-
sponses)"" (Benesch, 2014; Chung et al., 2019)1. In
this way, the consequences of errors in the hate clas-
sification are minimized, overblocking is avoided,
and it helps to spread a message against hate that
can reach people that are not necessarily convinced,
or even not involved in the conversation.
  However, the huge volume of online hate mes-
sages makes the manual generation of counter-
narratives an impossible task. In this scenario, au-
tomating the generation of counter-narratives is
an appealing avenue, but the task poses a great
challenge due to the complex linguistic and com-
municative patterns involved in argumentation.
   Traditional machine learning approaches have
typically fallen short to address argumentation min-
ing and generation with satisfactory results. How-
ever, Large Language Models (LLMs) seem capa-
ble of generating satisfactory text for many tasks.
Even so, for counter-narrative generation, specific
training seems to be required to obtain nuanced,
effective counter-narratives. But it is unclear what
specific training for this task is, and which informa-
tion would have a positive effect on this task.
  Our hypothesis is that additional information
about some argumentative aspects of text will have
a positive impact in the quality of the generated
counter-narratives.
  In this paper, we show that some kinds of argu-
mentative information of hate speech do enhance
the proportion of satisfactory counter-narratives

   1No Hate Speech Movement Campaign: http://www. no-
hatespeechmovement.org/2942","Furman DA,Torres P,Rodríguez JA,Letzen D,Martinez MV,Alemany LA",,,High-quality argumentative information in low resources approaches improve counter-narrative generation,,,10.18653/V1/2023.FINDINGS-EMNLP.194 , Conference Paper,,"It has been shown that high quality fine-tuning
    boosts the performance of language models,
    even if the size of the fine-tuning is small.
    In this work we show how highly targeted
    fine-tuning improves the task of hate speech
    counter-narrative generation in user-generated
     text, even for very small sizes of training (1722
    counter-narratives for English and 355 for
    Spanish). Providing a small subset of examples
    focusing on single argumentative strategies, to-
    gether with the argumentative analysis relevant
    to that strategy, yields counter-narratives that
    are as satisfactory as providing the whole set of
    counter-narratives. We also show that a good
    base model is required for the fine-tuning to
    have a positive impact. Indeed, for Spanish, the
    counter-narratives obtained without fine-tuning
    are mostly unacceptable, and, while fine-tuning
    improves their overall quality, the performance
      still remains quite unsatisfactory.

1  Introduction
Large Language Models (LLMs) have shown im-
pressive capabilities to generate acceptable texts in
a number of scenarios. This has allowed to tackle
tasks that were considered too difficult until very
recently. Counter-narrative generation in particu-
lar is a very challenging task because it requires
reasoning, argumentation and world knowledge,
in addition to the ability to produce text that is
grammatically correct and pragmatically felicitous.
Often, counter-narratives resort to pieces of infor-
mation that are only indirectly implied in the text.
  Counter-narrative generation is arising as a valu-
able application to mitigate some forms of violence
in social media. Indeed, automatically generated
counter-narratives have been proposed as a primary
input to facilitate the task of NGO specialists to
counter hate speech (Tekiro˘glu et al., 2020).
  The predominant strategy adopted so far to
counter hate speech in social media is to recog-
nize, block and delete these messages and/or theusers that generated it. This strategy has two main
disadvantages. The first one is that blocking and
deleting may prevent a hate message from spread-
ing, but does not counter its consequences on those
who were already reached by it. The second one is
that it can generate overblocking or censorship.
  An alternative to blocking that has been gaining
attention in the last years, is to ""oppose hate content
with counter-narratives (i.e. informed textual re-
sponses)"" (Benesch, 2014; Chung et al., 2019)1. In
this way, the consequences of errors in the hate clas-
sification are minimized, overblocking is avoided,
and it helps to spread a message against hate that
can reach people that are not necessarily convinced,
or even not involved in the conversation.
  However, the huge volume of online hate mes-
sages makes the manual generation of counter-
narratives an impossible task. In this scenario, au-
tomating the generation of counter-narratives is
an appealing avenue, but the task poses a great
challenge due to the complex linguistic and com-
municative patterns involved in argumentation.
   Traditional machine learning approaches have
typically fallen short to address argumentation min-
ing and generation with satisfactory results. How-
ever, Large Language Models (LLMs) seem capa-
ble of generating satisfactory text for many tasks.
Even so, for counter-narrative generation, specific
training seems to be required to obtain nuanced,
effective counter-narratives. But it is unclear what
specific training for this task is, and which informa-
tion would have a positive effect on this task.
  Our hypothesis is that additional information
about some argumentative aspects of text will have
a positive impact in the quality of the generated
counter-narratives.
  In this paper, we show that some kinds of argu-
mentative information of hate speech do enhance
the proportion of satisfactory counter-narratives

   1No Hate Speech Movement Campaign: http://www. no-
hatespeechmovement.org/2942",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023  ",,out_but_toxicity,
2823,"**Title**An Initial Exploration of How Argumentative Information Impacts Automatic Generation of Counter-Narratives Against Hate Speech

**Abstract**Fighting hate speech through automatic counter-narrative generation is gaining interest because of the
           increasing capabilities of Large Language Models. However, counter-narrative generation is a challenging
           task that can beneﬁt from insightful analyses of text. In this work, we present an approach to improve
           the generation of counter-narratives by providing Large Language Models with high-quality examples.
           In addition, we show that enhancing the original hate speech with an argumentative analysis, identifying
           justiﬁcations and conclusions, together with collectives and the properties associated to them, seems
           to produce some improvements, specially with with smaller training datasets, helping to orient the
           generation towards a particular response strategy. The dataset of counter-narratives with argumentative
           information is made publicly available.
         Warning: This work contains oﬀensive and hateful text that may be distressing. It does not
          represent the views of the authors.
       Keywords
           Counter-narrative generation, Hate speech, Argument mining, Large Language Models


1. Introduction

In social media platforms, hate speech is ampliﬁed beyond human scale, spreading faster and
increasing their reach, with negative impacts in societies, like polarization or an increase in
violent episodes against targeted communities or individuals. It is because of these known
consequences that many legal systems typify it as a crime, at least in some of its forms.
  The predominant strategy adopted so far to counter hate speech in social media is to recognize,
block and delete these messages and/or the users that generated it. This strategy has two main
disadvantages. The ﬁrst one is that blocking and deleting may prevent a hate message from
spreading, but does not counter its consequences on those who were already reached by it.


Arg&App 2023: International Workshop on Argumentation and Applications, September 2023, Rhodes, Greece
￿damian.a.furman@gmail.com (D. A. Furman)
￿https://damifur.github.io/ (D. A. Furman)
￿0000-0002-0877-7063 (D. A. Furman)
         © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).http://ceur-ws.orgISSN 1613-0073  CEUR Workshop Proceedings (CEUR-WS.org)26CEURWorkshopProceedingshttp://ceur-ws.org","Furman DA,Torres P,Rodríguez JA,Letzen D,Martinez MV,Alemany LA",,,An Initial Exploration of How Argumentative Information Impacts Automatic Generation of Counter-Narratives Against Hate Speech,3472,, , Conference Paper,,"Fighting hate speech through automatic counter-narrative generation is gaining interest because of the
           increasing capabilities of Large Language Models. However, counter-narrative generation is a challenging
           task that can beneﬁt from insightful analyses of text. In this work, we present an approach to improve
           the generation of counter-narratives by providing Large Language Models with high-quality examples.
           In addition, we show that enhancing the original hate speech with an argumentative analysis, identifying
           justiﬁcations and conclusions, together with collectives and the properties associated to them, seems
           to produce some improvements, specially with with smaller training datasets, helping to orient the
           generation towards a particular response strategy. The dataset of counter-narratives with argumentative
           information is made publicly available.
         Warning: This work contains oﬀensive and hateful text that may be distressing. It does not
          represent the views of the authors.
       Keywords
           Counter-narrative generation, Hate speech, Argument mining, Large Language Models


1. Introduction

In social media platforms, hate speech is ampliﬁed beyond human scale, spreading faster and
increasing their reach, with negative impacts in societies, like polarization or an increase in
violent episodes against targeted communities or individuals. It is because of these known
consequences that many legal systems typify it as a crime, at least in some of its forms.
  The predominant strategy adopted so far to counter hate speech in social media is to recognize,
block and delete these messages and/or the users that generated it. This strategy has two main
disadvantages. The ﬁrst one is that blocking and deleting may prevent a hate message from
spreading, but does not counter its consequences on those who were already reached by it.


Arg&App 2023: International Workshop on Argumentation and Applications, September 2023, Rhodes, Greece
￿damian.a.furman@gmail.com (D. A. Furman)
￿https://damifur.github.io/ (D. A. Furman)
￿0000-0002-0877-7063 (D. A. Furman)
         © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).http://ceur-ws.orgISSN 1613-0073  CEUR Workshop Proceedings (CEUR-WS.org)26CEURWorkshopProceedingshttp://ceur-ws.org",,,,,CEUR-WS.org ,"Proceedings of the First International Workshop on Argumentation and Applications co-located with 20th International Conference on Principles of Knowledge Representation and Reasoning (KR 2023), Rhodes, Greece, September 2-8, 2023  ",,detox,
2824,"**Title**Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation via Attention Regularization

**Abstract**Recent computational approaches for combat-
    ing online hate speech involve the automatic
    generation of counter narratives by adapting
    Pretrained Transformer-based Language Mod-
     els (PLMs) with human-curated data. This pro-
    cess, however, can produce in-domain overfit-
     ting, resulting in models generating acceptable
    narratives only for hatred similar to training
    data, with little portability to other targets or
    to real-world toxic language. This paper in-
    troduces novel attention regularization method-
    ologies to improve the generalization capabili-
     ties of PLMs for counter narratives generation.
    Overfitting to training-specific terms is then dis-
    couraged, resulting in more diverse and richer
    narratives. We experiment with two attention-
    based regularization techniques on a bench-
   mark English dataset. Regularized models pro-
    duce better counter narratives than state-of-the-
     art approaches in most cases, both in terms of
    automatic metrics and human evaluation, espe-
     cially when hateful targets are not present in
    the training data. This work paves the way for
    better and more flexible counter-speech gen-
    eration models, a task for which datasets are
    highly challenging to produce.
   Warning: this paper contains unobfuscated ex-
    amples some readers may find offensive.

1  Introduction

Counter narratives (CNs) are an effective way to
contrast hate speech as they are defined as “com-
municative actions aimed at refuting hate speech
through thoughtful and cogent reasons, and true
and fact-bound arguments” (Schieb and Preuss,
2016).  In contrast to other widely used restric-
tive measures such as content removal and shadow-
banning, CNs are based on the assumption that
in order to combat hate speech, more speech is
required. They are typically employed by Non-
Governmental Organizations (NGOs) as an active
strategy to intervene in online discussions where   Figure 1: An example of CNs obtained with and without
   regularization: the highlighted terms show where the
   models focus their attention in the two cases.


   hateful content is present. Responding to micro
  and macro-aggressions with concrete action is crit-
   ical because it can make such aggressions visible,
   disarm them, educate the perpetrators, and allow
   for external support (Sue et al., 2019). In partic-
   ular, the key to the effectiveness of CNs is their
   specificity: they are more complex than a simple
   condemnation of profanity, and they include a vari-
   ety of arguments (Tekiro˘glu et al., 2020).
       Still, the massive amount of hate that is con-
   stantly produced online necessitates the develop-
  ment of automatic CN generation techniques. Typ-
   ically, this is done by fine-tuning a Pretrained Lan-
  guage Model (PLM) on human-curated data, such
   as GPT-2 (Radford et al., 2019). However, prior
   research has demonstrated that PLMs are suscep-
   tible to generating unspecific CNs that can techni-
   cally work with any input but have questionable
   content and informativeness (Fanton et al., 2021;

13","Bonaldi H,Attanasio G,Nozza D,Guerini M",,,Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation via Attention Regularization,abs/2309.02311,,10.48550/ARXIV.2309.02311 , Journal Article,,"Recent computational approaches for combat-
    ing online hate speech involve the automatic
    generation of counter narratives by adapting
    Pretrained Transformer-based Language Mod-
     els (PLMs) with human-curated data. This pro-
    cess, however, can produce in-domain overfit-
     ting, resulting in models generating acceptable
    narratives only for hatred similar to training
    data, with little portability to other targets or
    to real-world toxic language. This paper in-
    troduces novel attention regularization method-
    ologies to improve the generalization capabili-
     ties of PLMs for counter narratives generation.
    Overfitting to training-specific terms is then dis-
    couraged, resulting in more diverse and richer
    narratives. We experiment with two attention-
    based regularization techniques on a bench-
   mark English dataset. Regularized models pro-
    duce better counter narratives than state-of-the-
     art approaches in most cases, both in terms of
    automatic metrics and human evaluation, espe-
     cially when hateful targets are not present in
    the training data. This work paves the way for
    better and more flexible counter-speech gen-
    eration models, a task for which datasets are
    highly challenging to produce.
   Warning: this paper contains unobfuscated ex-
    amples some readers may find offensive.

1  Introduction

Counter narratives (CNs) are an effective way to
contrast hate speech as they are defined as “com-
municative actions aimed at refuting hate speech
through thoughtful and cogent reasons, and true
and fact-bound arguments” (Schieb and Preuss,
2016).  In contrast to other widely used restric-
tive measures such as content removal and shadow-
banning, CNs are based on the assumption that
in order to combat hate speech, more speech is
required. They are typically employed by Non-
Governmental Organizations (NGOs) as an active
strategy to intervene in online discussions where   Figure 1: An example of CNs obtained with and without
   regularization: the highlighted terms show where the
   models focus their attention in the two cases.


   hateful content is present. Responding to micro
  and macro-aggressions with concrete action is crit-
   ical because it can make such aggressions visible,
   disarm them, educate the perpetrators, and allow
   for external support (Sue et al., 2019). In partic-
   ular, the key to the effectiveness of CNs is their
   specificity: they are more complex than a simple
   condemnation of profanity, and they include a vari-
   ety of arguments (Tekiro˘glu et al., 2020).
       Still, the massive amount of hate that is con-
   stantly produced online necessitates the develop-
  ment of automatic CN generation techniques. Typ-
   ically, this is done by fine-tuning a Pretrained Lan-
  guage Model (PLM) on human-curated data, such
   as GPT-2 (Radford et al., 2019). However, prior
   research has demonstrated that PLMs are suscep-
   tible to generating unspecific CNs that can techni-
   cally work with any input but have questionable
   content and informativeness (Fanton et al., 2021;

13",,,,, CoRR,  ,,detox,
2825,"**Title**RAUCG: Retrieval-Augmented Unsupervised Counter Narrative Generation for Hate Speech

**Abstract**Abstract:The proliferation of hate speech (HS) on social media poses a serious threat to societal security. Automatic counter narrative (CN) generation, as an active strategy for HS intervention, has garnered increasing attention in recent years. Existing methods for automatically generating CNs mainly rely on re-training or fine-tuning pre-trained language models (PLMs) on human-curated CN corpora. Unfortunately, the annotation speed of CN corpora cannot keep up with the growth of HS targets, while generating specific and effective CNs for unseen targets remains a significant challenge for the model. To tackle this issue, we propose Retrieval-Augmented Zero-shot Generation (ReZG) to generate CNs with high-specificity for unseen targets. Specifically, we propose a multi-dimensional hierarchical retrieval method that integrates stance, semantics, and fitness, extending the retrieval metric from single dimension to multiple dimensions suitable for the knowledge that refutes HS. Then, we implement an energy-based constrained decoding mechanism that enables PLMs to use differentiable knowledge preservation, countering, and fluency constraint functions instead of in-target CNs as control signals for generation, thereby achieving zero-shot CN generation. With the above techniques, ReZG can integrate external knowledge flexibly and improve the specificity of CNs. Experimental results show that ReZG exhibits stronger generalization capabilities and outperforms strong baselines with significant improvements of 2.0%+ in the relevance and 4.5%+ in the countering success rate metrics.","Jiang S,Tang W,Chen X,Tang R,Wang H,Wang W",,,RAUCG: Retrieval-Augmented Unsupervised Counter Narrative Generation for Hate Speech,abs/2310.05650,,10.48550/ARXIV.2310.05650 , Journal Article,,"Abstract:The proliferation of hate speech (HS) on social media poses a serious threat to societal security. Automatic counter narrative (CN) generation, as an active strategy for HS intervention, has garnered increasing attention in recent years. Existing methods for automatically generating CNs mainly rely on re-training or fine-tuning pre-trained language models (PLMs) on human-curated CN corpora. Unfortunately, the annotation speed of CN corpora cannot keep up with the growth of HS targets, while generating specific and effective CNs for unseen targets remains a significant challenge for the model. To tackle this issue, we propose Retrieval-Augmented Zero-shot Generation (ReZG) to generate CNs with high-specificity for unseen targets. Specifically, we propose a multi-dimensional hierarchical retrieval method that integrates stance, semantics, and fitness, extending the retrieval metric from single dimension to multiple dimensions suitable for the knowledge that refutes HS. Then, we implement an energy-based constrained decoding mechanism that enables PLMs to use differentiable knowledge preservation, countering, and fluency constraint functions instead of in-target CNs as control signals for generation, thereby achieving zero-shot CN generation. With the above techniques, ReZG can integrate external knowledge flexibly and improve the specificity of CNs. Experimental results show that ReZG exhibits stronger generalization capabilities and outperforms strong baselines with significant improvements of 2.0%+ in the relevance and 4.5%+ in the countering success rate metrics.",,,,, CoRR,  ,,detox,
2826,"**Title**Italian Counter Narrative Generation to Fight Online Hate Speech

**Abstract**AbstractUndermining the impact of hateful content with informed and non-aggressive responses, called counter narratives, has emerged as a possible solution for having healthier online communities. Thus, some NLP studies have started addressing the task of counter narrative generation. Although such studies have made an effort to build hate speech / counter narrative (HS/CN) datasets for neural generation, they fall short in reaching either high-quality and/or high-quantity. In this paper, we propose a novel human-in-the-loop data collection methodology in which a generative language model is refined iteratively by using its own data from the previous loops to generate new training samples that experts review and/or post-edit. Our experiments comprised several loops including diverse dynamic variations. Results show that the methodology is scalable and facilitates diverse, novel, and cost-effective data collection. To our knowledge, the resulting dataset is the only expert-based multi-target HS/CN dataset available to the community.","Chung YL,Tekiroglu SS,Guerini M",,,Italian Counter Narrative Generation to Fight Online Hate Speech,2769,, , Conference Paper,,"AbstractUndermining the impact of hateful content with informed and non-aggressive responses, called counter narratives, has emerged as a possible solution for having healthier online communities. Thus, some NLP studies have started addressing the task of counter narrative generation. Although such studies have made an effort to build hate speech / counter narrative (HS/CN) datasets for neural generation, they fall short in reaching either high-quality and/or high-quantity. In this paper, we propose a novel human-in-the-loop data collection methodology in which a generative language model is refined iteratively by using its own data from the previous loops to generate new training samples that experts review and/or post-edit. Our experiments comprised several loops including diverse dynamic variations. Results show that the methodology is scalable and facilitates diverse, novel, and cost-effective data collection. To our knowledge, the resulting dataset is the only expert-based multi-target HS/CN dataset available to the community.",,,,,CEUR-WS.org ,"Proceedings of the Seventh Italian Conference on Computational Linguistics, CLiC-it 2020, Bologna, Italy, March 1-3, 2021  ",,out_but_toxicity,
2827,"**Title**Protagonist vs Antagonist PROVANT: Narrative Generation as Counter Planning

**Abstract**AbstractOur motivation in this work is to develop a narrative generation mechanism for Interactive Storytelling that removes some of the authoring burden that is inherent to plan-based approaches. We focus on the class of narratives that dominate in Hollywood movies, television serial dramas and situation comedies. These narratives revolve around a central Protagonist in pursuit of a goal and who faces a series of obstructions placed in their way by an Antagonist and which they must overcome in order to reach their goal. We cast this problem as a non-cooperative multi-agent planning problem, in other words counter planning. We build on recent techniques in goal recognition and landmark identification to develop a novel plan-based narrative generation mechanism. A key opportunity that goal recognition provides is to reason explicitly with partially observed action sequences, reflecting the reasoning process of the antagonist. Thus the antagonist can only act to obstruct if it is reasonable (to the viewer) that they have guessed the protagonist's intentions. Starting from the believed goal, the narrative generator can reason about the protagonist's plan and what must be done to achieve it i.e., the plan landmarks and use these to automatically identify suitable points of obstruction. In the paper we detail the approach and illustrate it with a worked example. We report the results of an experimental evaluation and user study in a number of representative narrative domains. Results of the user study with system generated narratives confirm that viewers can clearly recognise agent roles and narrative structure.","Porteous J,Lindsay A",,,Protagonist vs Antagonist PROVANT: Narrative Generation as Counter Planning,,, , Conference Paper,,"AbstractOur motivation in this work is to develop a narrative generation mechanism for Interactive Storytelling that removes some of the authoring burden that is inherent to plan-based approaches. We focus on the class of narratives that dominate in Hollywood movies, television serial dramas and situation comedies. These narratives revolve around a central Protagonist in pursuit of a goal and who faces a series of obstructions placed in their way by an Antagonist and which they must overcome in order to reach their goal. We cast this problem as a non-cooperative multi-agent planning problem, in other words counter planning. We build on recent techniques in goal recognition and landmark identification to develop a novel plan-based narrative generation mechanism. A key opportunity that goal recognition provides is to reason explicitly with partially observed action sequences, reflecting the reasoning process of the antagonist. Thus the antagonist can only act to obstruct if it is reasonable (to the viewer) that they have guessed the protagonist's intentions. Starting from the believed goal, the narrative generator can reason about the protagonist's plan and what must be done to achieve it i.e., the plan landmarks and use these to automatically identify suitable points of obstruction. In the paper we detail the approach and illustrate it with a worked example. We report the results of an experimental evaluation and user study in a number of representative narrative domains. Results of the user study with system generated narratives confirm that viewers can clearly recognise agent roles and narrative structure.",,,,,International Foundation for Autonomous Agents and Multiagent Systems ,"Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS '19, Montreal, QC, Canada, May 13-17, 2019  ",,out_of_scope,
2828,"**Title**Multilingual and Explainable Text Detoxification with Parallel Corpora

**Abstract**Language   Toxic Text   Even with various regulations in place across
    countries and social media platforms (Govern-
   ment of India, 2021; European Parliament and
    Council of the European Union, 2022), digi-
     tal abusive speech remains a significant issue.
   One potential approach to address this chal-
    lenge is automatic text detoxification, a text
     style transfer (TST) approach that transforms
    toxic language into a more neutral or non-toxic
    form. To date, the availability of parallel cor-
    pora for the text detoxification task (Logacheva
     et al., 2022; Atwell et al., 2022; Dementieva
     et al., 2024a) has proven to be crucial for state-
     of-the-art approaches. With this work, we ex-
    tend parallel text detoxification corpus to new
   languages—German, Chinese, Arabic, Hindi,
    and Amharic—testing in the extensive multilin-
    gual setup TST baselines. Next, we conduct the
      first of its kind an automated, explainable anal-
     ysis of the descriptive features of both toxic and
    non-toxic sentences, diving deeply into the nu-
    ances, similarities, and differences of toxicity
    and detoxification across 9 languages. Finally,
    based on the obtained insights, we experiment
    with a novel text detoxification method inspired
   by the Chain-of-Thoughts reasoning approach,
    enhancing the prompting process through clus-
    tering on relevant descriptive attributes.
   Warning: This paper contains offensive texts
    that only serve as illustrative examples.

1  Introduction

The issue of managing toxic speech remains a
crucial aspect of human communication and digi-
tal violence prevention (Shi et al., 2020), includ-
ing the mitigation of toxic responses generated
by Large Language Models (LLMs) (Yao et al.,
2023). The typical approach to dealing with abu-
sive speech on social platforms involves message
blocking (Cobbe, 2021). To address this, numer-
ous toxic and hate speech detection models have
been developed for different languages, i.e. En-
glish (Mathew et al., 2021), Spanish (Molero et al.,Figure 1: Examples of the desired texts detoxification
for English and new languages: German, Chinese, Ara-
bic, Hindi, and Amharic.


2023), Amharic (Ayele et al., 2023), Code-Mixed
Hindi (Bohra et al., 2018), and many others (Costa-
jussà et al., 2024). However, the recent research
indicates a necessity for more proactive modera-
tion of abusive speech (Kulenovi´c, 2023). One
such approach is text detoxification.
  Within the baselines approaches for automatic
text detoxification, multiple unsupervised baselines
were created based on ideas of Delete-Retrieve-
Generate (Li et al., 2018), latent style spaces dis-
entanglement (Nogueira dos Santos et al., 2018),
or conditional generation with Masked Language
Modeling (Dale et al., 2021). However, the lat-
est state-of-the-art outcomes, particularly in En-
glish, were attained when parallel data and fine-
tuning with text-to-text generation models were
employed as in ParaDetox (Logacheva et al., 2022)
or APPDIA (Atwell et al., 2022). Then, several
works were conducted to explore the potential7998Language   Toxic Text           Detoxiﬁed Text          What a f**k is thisEnglish                     What is this about?            about?          Was für einGerman            besch**senes JahrWas für ein schlechtes
Jahr.                   ये माद**द डरे हुए लग रहेHindi                                           ये लोग डरे हुए लग रहे है ?                       है ?            አንተ ቆሻሻ በዚህ ወቅት
Amharic
           አይንህን ማየት አልፈልግምአንተ ጥሩ ሰው አይደለህም
በዚህ ወቅት አንተን ማየት
አልፈልግምArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ         ﺗﮫزﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراChinese   卧槽，抓到了！    天啊，抓到了！","Dementieva D,Babakov N,Ronen A,Ayele AA,Rizwan N,Schneider F,Wang X,Yimam SM,Moskovskiy DA,Stakovskii E,Kaufman E,Elnagar A,Mukherjee A,Panchenko A",,,Multilingual and Explainable Text Detoxification with Parallel Corpora,,, , Conference Paper,,"Language   Toxic Text   Even with various regulations in place across
    countries and social media platforms (Govern-
   ment of India, 2021; European Parliament and
    Council of the European Union, 2022), digi-
     tal abusive speech remains a significant issue.
   One potential approach to address this chal-
    lenge is automatic text detoxification, a text
     style transfer (TST) approach that transforms
    toxic language into a more neutral or non-toxic
    form. To date, the availability of parallel cor-
    pora for the text detoxification task (Logacheva
     et al., 2022; Atwell et al., 2022; Dementieva
     et al., 2024a) has proven to be crucial for state-
     of-the-art approaches. With this work, we ex-
    tend parallel text detoxification corpus to new
   languages—German, Chinese, Arabic, Hindi,
    and Amharic—testing in the extensive multilin-
    gual setup TST baselines. Next, we conduct the
      first of its kind an automated, explainable anal-
     ysis of the descriptive features of both toxic and
    non-toxic sentences, diving deeply into the nu-
    ances, similarities, and differences of toxicity
    and detoxification across 9 languages. Finally,
    based on the obtained insights, we experiment
    with a novel text detoxification method inspired
   by the Chain-of-Thoughts reasoning approach,
    enhancing the prompting process through clus-
    tering on relevant descriptive attributes.
   Warning: This paper contains offensive texts
    that only serve as illustrative examples.

1  Introduction

The issue of managing toxic speech remains a
crucial aspect of human communication and digi-
tal violence prevention (Shi et al., 2020), includ-
ing the mitigation of toxic responses generated
by Large Language Models (LLMs) (Yao et al.,
2023). The typical approach to dealing with abu-
sive speech on social platforms involves message
blocking (Cobbe, 2021). To address this, numer-
ous toxic and hate speech detection models have
been developed for different languages, i.e. En-
glish (Mathew et al., 2021), Spanish (Molero et al.,Figure 1: Examples of the desired texts detoxification
for English and new languages: German, Chinese, Ara-
bic, Hindi, and Amharic.


2023), Amharic (Ayele et al., 2023), Code-Mixed
Hindi (Bohra et al., 2018), and many others (Costa-
jussà et al., 2024). However, the recent research
indicates a necessity for more proactive modera-
tion of abusive speech (Kulenovi´c, 2023). One
such approach is text detoxification.
  Within the baselines approaches for automatic
text detoxification, multiple unsupervised baselines
were created based on ideas of Delete-Retrieve-
Generate (Li et al., 2018), latent style spaces dis-
entanglement (Nogueira dos Santos et al., 2018),
or conditional generation with Masked Language
Modeling (Dale et al., 2021). However, the lat-
est state-of-the-art outcomes, particularly in En-
glish, were attained when parallel data and fine-
tuning with text-to-text generation models were
employed as in ParaDetox (Logacheva et al., 2022)
or APPDIA (Atwell et al., 2022). Then, several
works were conducted to explore the potential7998Language   Toxic Text           Detoxiﬁed Text          What a f**k is thisEnglish                     What is this about?            about?          Was für einGerman            besch**senes JahrWas für ein schlechtes
Jahr.                   ये माद**द डरे हुए लग रहेHindi                                           ये लोग डरे हुए लग रहे है ?                       है ?            አንተ ቆሻሻ በዚህ ወቅት
Amharic
           አይንህን ማየት አልፈልግምአንተ ጥሩ ሰው አይደለህም
በዚህ ወቅት አንተን ማየት
አልፈልግምArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ         ﺗﮫزﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراChinese   卧槽，抓到了！    天啊，抓到了！",,,,,Association for Computational Linguistics ,"Proceedings of the 31st International Conference on Computational Linguistics, COLING 2025, Abu Dhabi, UAE, January 19-24, 2025  ",,detox,
2829,"**Title**Detoxification of Unlabeled Dataset: Reducing Implicit Class Imbalance Using Pseudo-Jacobian of GAN's Generator

**Abstract**AbstractAI-related technologies based on machine learning have been rapidly developing in recent years and still advancing. On the other hand, misrecognition and/or biased outputs of AIs caused by a class imbalance problem in their training dataset would become a serious social issue. This is the case with not only labeled datasets but also unlabeled ones since the class imbalance could be implicitly contained even in unlabeled datasets. So far, a lot of methods for solving the class imbalance problem have been proposed, none of which focuses on unlabeled datasets. Hence, in this paper, we propose a method for reducing the implicit class imbalance in an unlabeled dataset. We call this task unlabeled dataset detoxification, regarding the implicit class imbalance as a kind of “toxin” for unlabeled datasets. In the proposed method, we first train a GAN using a target imbalanced dataset itself and generate a lot of new data samples using it. In this process, we estimate the rarity of each generated sample based on the pseudo-Jacobian of the trained GAN generator. After that, we add only the GAN-generated samples with high rarity into the target dataset. This allows us to reduce the implicit class imbalance. We conducted experiments on an unlabeled face image dataset that is imbalanced in terms of race, whose results demonstrate the effectiveness of the proposed method; it can effectively generate rare-class samples that are helpful in boosting face recognition accuracy for identities of the rare classes, namely rare races.","Suyama K,Nakamura K",,,Detoxification of Unlabeled Dataset: Reducing Implicit Class Imbalance Using Pseudo-Jacobian of GAN's Generator,15520,,10.1007/978-981-96-2054-8_21 , Conference Paper,,"AbstractAI-related technologies based on machine learning have been rapidly developing in recent years and still advancing. On the other hand, misrecognition and/or biased outputs of AIs caused by a class imbalance problem in their training dataset would become a serious social issue. This is the case with not only labeled datasets but also unlabeled ones since the class imbalance could be implicitly contained even in unlabeled datasets. So far, a lot of methods for solving the class imbalance problem have been proposed, none of which focuses on unlabeled datasets. Hence, in this paper, we propose a method for reducing the implicit class imbalance in an unlabeled dataset. We call this task unlabeled dataset detoxification, regarding the implicit class imbalance as a kind of “toxin” for unlabeled datasets. In the proposed method, we first train a GAN using a target imbalanced dataset itself and generate a lot of new data samples using it. In this process, we estimate the rarity of each generated sample based on the pseudo-Jacobian of the trained GAN generator. After that, we add only the GAN-generated samples with high rarity into the target dataset. This allows us to reduce the implicit class imbalance. We conducted experiments on an unlabeled face image dataset that is imbalanced in terms of race, whose results demonstrate the effectiveness of the proposed method; it can effectively generate rare-class samples that are helpful in boosting face recognition accuracy for identities of the rare classes, namely rare races.",,,,,Springer ,"MultiMedia Modeling - 31st International Conference on Multimedia Modeling, MMM 2025, Nara, Japan, January 8-10, 2025, Proceedings, Part I  ",,out_of_scope,
2830,"**Title**Transcriptome analysis reveals mechanisms of metabolic detoxification and immune responses following farnesyl acetate treatment in Metisa plana

**Abstract**AbstractMetisa plana is a widespread insect pest infesting oil palm plantations in Malaysia. Farnesyl acetate (FA), a juvenile hormone analogue, has been reported to exert in vitro and in vivo insecticidal activity against other insect pests. However, the insecticidal mechanism of FA on M. plana remains unclear. Therefore, this study aims to elucidate responsive genes in M. plana in response to FA treatment. The RNA-sequencing reads of FA-treated M. plana were de novo-assembled with existing raw reads from non-treated third instar larvae, and 55,807 transcripts were functionally annotated to multiple protein databases. Several insecticide detoxification-related genes were differentially regulated among the 321 differentially expressed transcripts. Cytochrome P450 monooxygenase, carboxylesterase, and ATP-binding cassette protein were upregulated, while peptidoglycan recognition protein was downregulated. Innate immune response genes, such as glutathione S-transferases, acetylcholinesterase, and heat shock protein, were also identified in the transcriptome. The findings signify that changes occurred in the insect’s receptor and signaling, metabolic detoxification of insecticides, and immune responses upon FA treatment on M. plana. This valuable information on FA toxicity may be used to formulate more effective biorational insecticides for better M. plana pest management strategies in oil palm plantations.","Rahmat NL,Zifruddin AN,Yusoff NS,Sulaiman S,Abidin CM,Othman NW,Muhammad NA,Hassan M",,,Transcriptome analysis reveals mechanisms of metabolic detoxification and immune responses following farnesyl acetate treatment in Metisa plana,112,,10.1016/J.COMPBIOLCHEM.2024.108176 , Journal Article,,"AbstractMetisa plana is a widespread insect pest infesting oil palm plantations in Malaysia. Farnesyl acetate (FA), a juvenile hormone analogue, has been reported to exert in vitro and in vivo insecticidal activity against other insect pests. However, the insecticidal mechanism of FA on M. plana remains unclear. Therefore, this study aims to elucidate responsive genes in M. plana in response to FA treatment. The RNA-sequencing reads of FA-treated M. plana were de novo-assembled with existing raw reads from non-treated third instar larvae, and 55,807 transcripts were functionally annotated to multiple protein databases. Several insecticide detoxification-related genes were differentially regulated among the 321 differentially expressed transcripts. Cytochrome P450 monooxygenase, carboxylesterase, and ATP-binding cassette protein were upregulated, while peptidoglycan recognition protein was downregulated. Innate immune response genes, such as glutathione S-transferases, acetylcholinesterase, and heat shock protein, were also identified in the transcriptome. The findings signify that changes occurred in the insect’s receptor and signaling, metabolic detoxification of insecticides, and immune responses upon FA treatment on M. plana. This valuable information on FA toxicity may be used to formulate more effective biorational insecticides for better M. plana pest management strategies in oil palm plantations.",,,,, Comput. Biol. Chem.,  ,,out_of_scope,
2831,"**Title**Improving Well-Being Through Digital Detoxification Among Social Media Users: A Systematic Review and Meta-Analysis

**Abstract**Abstract
        
      


      
      Digital detoxification is a conscious disconnection from all smartphone activities for a certain period of time, which has been undertaken as effective by researchers to improve well-being, but studies found inconsistent results, with a primary focus on negative well-being, thus necessitating a need to focus on the positive aspect. As a result, the current study conducted a systematic review and meta-analysis to assess digital detoxification and its influence on users subjective and psychological well-being (PWB). A comprehensive search (up to November 19, 2023) across databases such as PubMed, Scopus, Web of Science, Pro-Quest, and Google Search yielded a total of 26 eligible studies (18 for meta-analysis) comprising 8,147 participants (Mage = 25.20 years). The Studies' quality was assessed using Cochrane's updated Risk of Bias Tool, and statistical analysis was performed in R Studio. Digital detoxification was found to be effective in improving subjective well-being (SWB) (Standardized mean difference [SMD] = 0.21, 95% CI: 0.06, 0.34; p < 0.01, I2 = 73.6%, n = 14 papers), as well as PWB (SMD = 0.27, 95% CI: 0.09, 0.46; p < 0.05; I2 = 0.0%, n = 4 papers). Notably, we detected no publication bias but addressed funnel plot asymmetry using Trim & Fill. Moderation analysis revealed the impact of internet coverage, developmental status, location, intervention effectiveness, and risk of bias on the estimated effect size for SWB. Meta-regression highlighted the significant influence of mean age, and although no potential outliers were identified, influential plots are provided for transparency. Our findings consolidate the efficacy of digital detoxification, emphasizing the need for nuanced consideration of study factors. This study contributes to the ongoing discourse on digital well-being, offering valuable insights for researchers, practitioners, and policymakers.
    



          Keywords:
        
      
      digital detoxification; life satisfaction; psychological well-being; social media use; subjective well-being.","Ansari S,Iqbal N,Azeem A,Danyal K",,,Improving Well-Being Through Digital Detoxification Among Social Media Users: A Systematic Review and Meta-Analysis,27,11,10.1089/CYBER.2023.0742 , Journal Article,,"Abstract
        
      


      
      Digital detoxification is a conscious disconnection from all smartphone activities for a certain period of time, which has been undertaken as effective by researchers to improve well-being, but studies found inconsistent results, with a primary focus on negative well-being, thus necessitating a need to focus on the positive aspect. As a result, the current study conducted a systematic review and meta-analysis to assess digital detoxification and its influence on users subjective and psychological well-being (PWB). A comprehensive search (up to November 19, 2023) across databases such as PubMed, Scopus, Web of Science, Pro-Quest, and Google Search yielded a total of 26 eligible studies (18 for meta-analysis) comprising 8,147 participants (Mage = 25.20 years). The Studies' quality was assessed using Cochrane's updated Risk of Bias Tool, and statistical analysis was performed in R Studio. Digital detoxification was found to be effective in improving subjective well-being (SWB) (Standardized mean difference [SMD] = 0.21, 95% CI: 0.06, 0.34; p < 0.01, I2 = 73.6%, n = 14 papers), as well as PWB (SMD = 0.27, 95% CI: 0.09, 0.46; p < 0.05; I2 = 0.0%, n = 4 papers). Notably, we detected no publication bias but addressed funnel plot asymmetry using Trim & Fill. Moderation analysis revealed the impact of internet coverage, developmental status, location, intervention effectiveness, and risk of bias on the estimated effect size for SWB. Meta-regression highlighted the significant influence of mean age, and although no potential outliers were identified, influential plots are provided for transparency. Our findings consolidate the efficacy of digital detoxification, emphasizing the need for nuanced consideration of study factors. This study contributes to the ongoing discourse on digital well-being, offering valuable insights for researchers, practitioners, and policymakers.
    



          Keywords:
        
      
      digital detoxification; life satisfaction; psychological well-being; social media use; subjective well-being.",,,,, Cyberpsychology Behav. Soc. Netw.,  ,,out_of_scope,
2832,"**Title**Overview of the Multilingual Text Detoxification Task at PAN 2024

**Abstract**Despite different countries and social platform regulations, digital abusive speech persists as a significant challenge.
         One of the way to tackle abusive, or more specifically, toxic language can be automatic text detoxification—a
             text style transfer task (TST) of changing register of text from toxic to more non-toxic. Thus, in this shared task,
        we aim to obtain text detoxification models for 9 languages: English, Spanish, German, Chinese, Arabic, Hindi,
            Ukrainian, Russian, and Amharic. This paper presents the Multilingual Text Detoxification (TextDetox) task, the
           underlying datasets, the evaluation setups, the submissions from participants, and the results obtained.
           Warning: This paper contains rude texts that only serve as illustrative examples.

       Keywords
        PAN 2024, Multilingual Text Detoxification, Text Style Transfer, Multilingualism



1. Introduction

The issue of managing toxic speech remains a crucial aspect of human communication and digital
violence prevention [1], including the mitigation of toxic responses generated by Large Language


CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, France
*Corresponding author.
$ daryna.dementieva@tum.de (D. Dementieva); daniil.moskovskiy@skoltech.ru (D. Moskovskiy); nikolay.babakov@usc.ese
(N. Babakov); abinew.ali.ayele@uni-hamburg.de (A. A. Ayele); nrizwan@kgpian.iitkgp.ac.in (N. Rizwan);
florian.schneider-1@uni-hamburg.de (F. Schneider); xintong.wang@uni-hamburg.de (X. Wang);
seid.muhie.yimam@uni-hamburg.de (S. M. Yimam); dmitry.ustalov@jetbrains.com (D. Ustalov); eistakovskii@gmail.com
(E. Stakovskii); ashraf@sharjah.ac.ae (A. Elnagar); animeshm@gmail.com (A. Mukherjee); a.panchenko@skol.tech
(A. Panchenko)
 https://dardem.github.io (D. Dementieva); https://www.researchgate.net/profile/Daniil-Moskovskiy (D. Moskovskiy);
https://github.com/bbkjunior/bbkjunior (N. Babakov); https://scholar.google.com/citations?user=g2m1wH4AAAAJ&hl=en
(A. A. Ayele); https://www.linkedin.com/in/naquee-rizwan-a97abb159 (N. Rizwan);
https://www.linkedin.com/in/flo-schneider-hh (F. Schneider); https://ethanscuter.github.io (X. Wang);
https://seyyaw.github.io (S. M. Yimam); https://linkedin.com/in/ustalov (D. Ustalov); https://github.com/eistakovskii
(E. Stakovskii); https://www.sharjah.ac.ae/en/academics/Colleges/CI/dept/cs/Pages/ppl_detail.aspx?mcid=4 (A. Elnagar);
https://cse.iitkgp.ac.in/~animeshm (A. Mukherjee); https://alexanderpanchenko.github.io (A. Panchenko)
   0000-0003-0929-4140 (D. Dementieva); 0009-0006-7943-4259 (D. Moskovskiy); 0000-0002-2568-6702 (N. Babakov);CEURceur-ws.org","Dementieva D,Moskovskiy D,Babakov N,Ayele AA,Rizwan N,Schneider F,Wang X,Yimam SM,Ustalov D,Stakovskii E,Smirnova A,Elnagar A,Mukherjee A,Panchenko A",,,Overview of the Multilingual Text Detoxification Task at PAN 2024,3740,, , Conference Paper,,"Despite different countries and social platform regulations, digital abusive speech persists as a significant challenge.
         One of the way to tackle abusive, or more specifically, toxic language can be automatic text detoxification—a
             text style transfer task (TST) of changing register of text from toxic to more non-toxic. Thus, in this shared task,
        we aim to obtain text detoxification models for 9 languages: English, Spanish, German, Chinese, Arabic, Hindi,
            Ukrainian, Russian, and Amharic. This paper presents the Multilingual Text Detoxification (TextDetox) task, the
           underlying datasets, the evaluation setups, the submissions from participants, and the results obtained.
           Warning: This paper contains rude texts that only serve as illustrative examples.

       Keywords
        PAN 2024, Multilingual Text Detoxification, Text Style Transfer, Multilingualism



1. Introduction

The issue of managing toxic speech remains a crucial aspect of human communication and digital
violence prevention [1], including the mitigation of toxic responses generated by Large Language


CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, France
*Corresponding author.
$ daryna.dementieva@tum.de (D. Dementieva); daniil.moskovskiy@skoltech.ru (D. Moskovskiy); nikolay.babakov@usc.ese
(N. Babakov); abinew.ali.ayele@uni-hamburg.de (A. A. Ayele); nrizwan@kgpian.iitkgp.ac.in (N. Rizwan);
florian.schneider-1@uni-hamburg.de (F. Schneider); xintong.wang@uni-hamburg.de (X. Wang);
seid.muhie.yimam@uni-hamburg.de (S. M. Yimam); dmitry.ustalov@jetbrains.com (D. Ustalov); eistakovskii@gmail.com
(E. Stakovskii); ashraf@sharjah.ac.ae (A. Elnagar); animeshm@gmail.com (A. Mukherjee); a.panchenko@skol.tech
(A. Panchenko)
 https://dardem.github.io (D. Dementieva); https://www.researchgate.net/profile/Daniil-Moskovskiy (D. Moskovskiy);
https://github.com/bbkjunior/bbkjunior (N. Babakov); https://scholar.google.com/citations?user=g2m1wH4AAAAJ&hl=en
(A. A. Ayele); https://www.linkedin.com/in/naquee-rizwan-a97abb159 (N. Rizwan);
https://www.linkedin.com/in/flo-schneider-hh (F. Schneider); https://ethanscuter.github.io (X. Wang);
https://seyyaw.github.io (S. M. Yimam); https://linkedin.com/in/ustalov (D. Ustalov); https://github.com/eistakovskii
(E. Stakovskii); https://www.sharjah.ac.ae/en/academics/Colleges/CI/dept/cs/Pages/ppl_detail.aspx?mcid=4 (A. Elnagar);
https://cse.iitkgp.ac.in/~animeshm (A. Mukherjee); https://alexanderpanchenko.github.io (A. Panchenko)
   0000-0003-0929-4140 (D. Dementieva); 0009-0006-7943-4259 (D. Moskovskiy); 0000-0002-2568-6702 (N. Babakov);CEURceur-ws.org",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2833,No abstract available,"Gangopadhyay S,Khan MT,Jabeen H",,,Linguistic_Hygenist at PAN 2024 TextDetox: HybridDetox - A Combination of Supervised and Unsupervised Methods for Effective Multilingual Text Detoxification,3740,, , Conference Paper,,,,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2834,"**Title**Multilingual Text Detoxification Using Google Cloud Translation and Post-Processing

**Abstract**We present two novel unsupervised methods
    for eliminating toxicity in  text.  Our ﬁrst
   method combines two recent ideas: (1) guid-
    ance of the generation process with small style-
    conditional language models and (2) use of
    paraphrasing models to perform style transfer.
   We use a well-performing paraphraser guided
   by style-trained language models to keep the
     text content and remove toxicity. Our second
   method uses BERT to replace toxic words with
     their non-offensive synonyms. We make the
   method more ﬂexible by enabling BERT to
    replace mask tokens with a variable number
    of words.  Finally, we present the ﬁrst large-
    scale comparative study of style transfer mod-
     els on the task of toxicity removal. We com-
    pare our models with a number of methods for
     style transfer. The models are evaluated in a
    reference-free way using a combination of un-
    supervised style transfer metrics. Both meth-
    ods we suggest yield new SOTA results.

1  Introduction

Identiﬁcation of toxicity in user texts is an active
area of research (Zampieri et al., 2020; D’Sa et al.,
2020; Han and Tsvetkov, 2020). The task of auto-
matic rewriting of offensive content attracted less
attention, yet it may ﬁnd various useful applications
such as making online world a better place by sug-
gesting to a user posting a more neutral version of
an emotional comment. The existing works on text
detoxiﬁcation (dos Santos et al., 2018; Tran et al.,
2020; Laugier et al., 2021) cast this task as style
transfer. The style transfer task is generally under-
stood as rewriting of text with the same content and
with altering of one or several attributes which con-
stitute the “style”, such as authorship (Voigt et al.,
2018), sentiment (Shen et al., 2017), or degree of
politeness (Madaan et al., 2020). Despite the goal
of preserving the content, in many cases changing
the style attributes changes the meaning of a sen-tence signiﬁcantly.1 So in fact the goal of many
style transfer models is to transform a sentence into
a somewhat similar sentence of a different style
on the same topic.2 We suggest that detoxiﬁcation
needs better preservation of the original meaning
than many other style transfer tasks, such as senti-
ment transfer, so it should be performed differently.
  We present two models for text detoxiﬁcation,
which have extra control for content preservation.
The ﬁrst model, ParaGeDi, is capable of fully re-
generating the input. It is based on two ideas: exter-
nal control of an output of a generation model by a
class-conditioned LM (Krause et al., 2020) and for-
mulation of style transfer task as paraphrasing (Kr-
ishna et al., 2020). Being based on a paraphraser
model, ParaGeDi explicitly aims at preserving the
meaning of the original sentence. The second ap-
proach, CondBERT, inspired by Wu et al. (2019a),
follows the pointwise editing setup. It uses BERT
to replace toxic spans found in the sentence with
their non-toxic alternatives. The semantic simi-
larity is maintained by showing the original text
to BERT and reranking its hypotheses based on
the similarity between the original words and their
substitutes.  Interestingly, BERT does not need
any class-conditional pre-training to successfully
change the text style from toxic to normal.
   In addition, we perform a large-scale evaluation
of style transfer models on detoxiﬁcation task, com-
paring our new models with baselines and state-of-
the-art approaches. We release our code and data.3
  Our contributions are as follows:
• We propose two novel detoxiﬁcation meth-
  ods based on pre-trained neural language mod-
  els: ParaGeDi (paraphrasing GeDi) and Cond-
 BERT (conditional BERT).

   1For example, Lample et al. (2019) provide the following
sentence as an example of transfer from male to female writing:
Gotta say that beard makes you look like a Viking →Gotta
say that hair makes you look like a Mermaid.
   2A formal task deﬁnition is presented in Appendix A.
  3https://github.com/skoltech-nlp/detox7979","Luo Z,Luo M,Wang A",,,Multilingual Text Detoxification Using Google Cloud Translation and Post-Processing,3740,, , Conference Paper,,"We present two novel unsupervised methods
    for eliminating toxicity in  text.  Our ﬁrst
   method combines two recent ideas: (1) guid-
    ance of the generation process with small style-
    conditional language models and (2) use of
    paraphrasing models to perform style transfer.
   We use a well-performing paraphraser guided
   by style-trained language models to keep the
     text content and remove toxicity. Our second
   method uses BERT to replace toxic words with
     their non-offensive synonyms. We make the
   method more ﬂexible by enabling BERT to
    replace mask tokens with a variable number
    of words.  Finally, we present the ﬁrst large-
    scale comparative study of style transfer mod-
     els on the task of toxicity removal. We com-
    pare our models with a number of methods for
     style transfer. The models are evaluated in a
    reference-free way using a combination of un-
    supervised style transfer metrics. Both meth-
    ods we suggest yield new SOTA results.

1  Introduction

Identiﬁcation of toxicity in user texts is an active
area of research (Zampieri et al., 2020; D’Sa et al.,
2020; Han and Tsvetkov, 2020). The task of auto-
matic rewriting of offensive content attracted less
attention, yet it may ﬁnd various useful applications
such as making online world a better place by sug-
gesting to a user posting a more neutral version of
an emotional comment. The existing works on text
detoxiﬁcation (dos Santos et al., 2018; Tran et al.,
2020; Laugier et al., 2021) cast this task as style
transfer. The style transfer task is generally under-
stood as rewriting of text with the same content and
with altering of one or several attributes which con-
stitute the “style”, such as authorship (Voigt et al.,
2018), sentiment (Shen et al., 2017), or degree of
politeness (Madaan et al., 2020). Despite the goal
of preserving the content, in many cases changing
the style attributes changes the meaning of a sen-tence signiﬁcantly.1 So in fact the goal of many
style transfer models is to transform a sentence into
a somewhat similar sentence of a different style
on the same topic.2 We suggest that detoxiﬁcation
needs better preservation of the original meaning
than many other style transfer tasks, such as senti-
ment transfer, so it should be performed differently.
  We present two models for text detoxiﬁcation,
which have extra control for content preservation.
The ﬁrst model, ParaGeDi, is capable of fully re-
generating the input. It is based on two ideas: exter-
nal control of an output of a generation model by a
class-conditioned LM (Krause et al., 2020) and for-
mulation of style transfer task as paraphrasing (Kr-
ishna et al., 2020). Being based on a paraphraser
model, ParaGeDi explicitly aims at preserving the
meaning of the original sentence. The second ap-
proach, CondBERT, inspired by Wu et al. (2019a),
follows the pointwise editing setup. It uses BERT
to replace toxic spans found in the sentence with
their non-toxic alternatives. The semantic simi-
larity is maintained by showing the original text
to BERT and reranking its hypotheses based on
the similarity between the original words and their
substitutes.  Interestingly, BERT does not need
any class-conditional pre-training to successfully
change the text style from toxic to normal.
   In addition, we perform a large-scale evaluation
of style transfer models on detoxiﬁcation task, com-
paring our new models with baselines and state-of-
the-art approaches. We release our code and data.3
  Our contributions are as follows:
• We propose two novel detoxiﬁcation meth-
  ods based on pre-trained neural language mod-
  els: ParaGeDi (paraphrasing GeDi) and Cond-
 BERT (conditional BERT).

   1For example, Lample et al. (2019) provide the following
sentence as an example of transfer from male to female writing:
Gotta say that beard makes you look like a Viking →Gotta
say that hair makes you look like a Mermaid.
   2A formal task deﬁnition is presented in Appendix A.
  3https://github.com/skoltech-nlp/detox7979",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2835,"**Title**A Multilingual Text Detoxification Method Based on Few-shot Learning and CO-STAR Framework

**Abstract**Language   Toxic Text   Even with various regulations in place across
    countries and social media platforms (Govern-
   ment of India, 2021; European Parliament and
    Council of the European Union, 2022), digi-
     tal abusive speech remains a significant issue.
   One potential approach to address this chal-
    lenge is automatic text detoxification, a text
     style transfer (TST) approach that transforms
    toxic language into a more neutral or non-toxic
    form. To date, the availability of parallel cor-
    pora for the text detoxification task (Logacheva
     et al., 2022; Atwell et al., 2022; Dementieva
     et al., 2024a) has proven to be crucial for state-
     of-the-art approaches. With this work, we ex-
    tend parallel text detoxification corpus to new
   languages—German, Chinese, Arabic, Hindi,
    and Amharic—testing in the extensive multilin-
    gual setup TST baselines. Next, we conduct the
      first of its kind an automated, explainable anal-
     ysis of the descriptive features of both toxic and
    non-toxic sentences, diving deeply into the nu-
    ances, similarities, and differences of toxicity
    and detoxification across 9 languages. Finally,
    based on the obtained insights, we experiment
    with a novel text detoxification method inspired
   by the Chain-of-Thoughts reasoning approach,
    enhancing the prompting process through clus-
    tering on relevant descriptive attributes.
   Warning: This paper contains offensive texts
    that only serve as illustrative examples.

1  Introduction

The issue of managing toxic speech remains a
crucial aspect of human communication and digi-
tal violence prevention (Shi et al., 2020), includ-
ing the mitigation of toxic responses generated
by Large Language Models (LLMs) (Yao et al.,
2023). The typical approach to dealing with abu-
sive speech on social platforms involves message
blocking (Cobbe, 2021). To address this, numer-
ous toxic and hate speech detection models have
been developed for different languages, i.e. En-
glish (Mathew et al., 2021), Spanish (Molero et al.,Figure 1: Examples of the desired texts detoxification
for English and new languages: German, Chinese, Ara-
bic, Hindi, and Amharic.


2023), Amharic (Ayele et al., 2023), Code-Mixed
Hindi (Bohra et al., 2018), and many others (Costa-
jussà et al., 2024). However, the recent research
indicates a necessity for more proactive modera-
tion of abusive speech (Kulenovi´c, 2023). One
such approach is text detoxification.
  Within the baselines approaches for automatic
text detoxification, multiple unsupervised baselines
were created based on ideas of Delete-Retrieve-
Generate (Li et al., 2018), latent style spaces dis-
entanglement (Nogueira dos Santos et al., 2018),
or conditional generation with Masked Language
Modeling (Dale et al., 2021). However, the lat-
est state-of-the-art outcomes, particularly in En-
glish, were attained when parallel data and fine-
tuning with text-to-text generation models were
employed as in ParaDetox (Logacheva et al., 2022)
or APPDIA (Atwell et al., 2022). Then, several
works were conducted to explore the potential7998Language   Toxic Text           Detoxiﬁed Text          What a f**k is thisEnglish                     What is this about?            about?          Was für einGerman            besch**senes JahrWas für ein schlechtes
Jahr.                   ये माद**द डरे हुए लग रहेHindi                                           ये लोग डरे हुए लग रहे है ?                       है ?            አንተ ቆሻሻ በዚህ ወቅት
Amharic
           አይንህን ማየት አልፈልግምአንተ ጥሩ ሰው አይደለህም
በዚህ ወቅት አንተን ማየት
አልፈልግምArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ         ﺗﮫزﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراChinese   卧槽，抓到了！    天啊，抓到了！","Peng J,Han Z,Zhang H,Ye J,Liu C,Liu B,Guo M,Chen H,Lin Z,Tang Y",,,A Multilingual Text Detoxification Method Based on Few-shot Learning and CO-STAR Framework,3740,, , Conference Paper,,"Language   Toxic Text   Even with various regulations in place across
    countries and social media platforms (Govern-
   ment of India, 2021; European Parliament and
    Council of the European Union, 2022), digi-
     tal abusive speech remains a significant issue.
   One potential approach to address this chal-
    lenge is automatic text detoxification, a text
     style transfer (TST) approach that transforms
    toxic language into a more neutral or non-toxic
    form. To date, the availability of parallel cor-
    pora for the text detoxification task (Logacheva
     et al., 2022; Atwell et al., 2022; Dementieva
     et al., 2024a) has proven to be crucial for state-
     of-the-art approaches. With this work, we ex-
    tend parallel text detoxification corpus to new
   languages—German, Chinese, Arabic, Hindi,
    and Amharic—testing in the extensive multilin-
    gual setup TST baselines. Next, we conduct the
      first of its kind an automated, explainable anal-
     ysis of the descriptive features of both toxic and
    non-toxic sentences, diving deeply into the nu-
    ances, similarities, and differences of toxicity
    and detoxification across 9 languages. Finally,
    based on the obtained insights, we experiment
    with a novel text detoxification method inspired
   by the Chain-of-Thoughts reasoning approach,
    enhancing the prompting process through clus-
    tering on relevant descriptive attributes.
   Warning: This paper contains offensive texts
    that only serve as illustrative examples.

1  Introduction

The issue of managing toxic speech remains a
crucial aspect of human communication and digi-
tal violence prevention (Shi et al., 2020), includ-
ing the mitigation of toxic responses generated
by Large Language Models (LLMs) (Yao et al.,
2023). The typical approach to dealing with abu-
sive speech on social platforms involves message
blocking (Cobbe, 2021). To address this, numer-
ous toxic and hate speech detection models have
been developed for different languages, i.e. En-
glish (Mathew et al., 2021), Spanish (Molero et al.,Figure 1: Examples of the desired texts detoxification
for English and new languages: German, Chinese, Ara-
bic, Hindi, and Amharic.


2023), Amharic (Ayele et al., 2023), Code-Mixed
Hindi (Bohra et al., 2018), and many others (Costa-
jussà et al., 2024). However, the recent research
indicates a necessity for more proactive modera-
tion of abusive speech (Kulenovi´c, 2023). One
such approach is text detoxification.
  Within the baselines approaches for automatic
text detoxification, multiple unsupervised baselines
were created based on ideas of Delete-Retrieve-
Generate (Li et al., 2018), latent style spaces dis-
entanglement (Nogueira dos Santos et al., 2018),
or conditional generation with Masked Language
Modeling (Dale et al., 2021). However, the lat-
est state-of-the-art outcomes, particularly in En-
glish, were attained when parallel data and fine-
tuning with text-to-text generation models were
employed as in ParaDetox (Logacheva et al., 2022)
or APPDIA (Atwell et al., 2022). Then, several
works were conducted to explore the potential7998Language   Toxic Text           Detoxiﬁed Text          What a f**k is thisEnglish                     What is this about?            about?          Was für einGerman            besch**senes JahrWas für ein schlechtes
Jahr.                   ये माद**द डरे हुए लग रहेHindi                                           ये लोग डरे हुए लग रहे है ?                       है ?            አንተ ቆሻሻ በዚህ ወቅት
Amharic
           አይንህን ማየት አልፈልግምአንተ ጥሩ ሰው አይደለህም
በዚህ ወቅት አንተን ማየት
አልፈልግምArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ         ﺗﮫزﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراArabicﯾﺎ ﺗﮫ زﺑﺟﻧﺎ واﺗﻣﺷو لﻟﻘﺗﯾا واﺗﻘﺗﻠ                        ط **ﺷراChinese   卧槽，抓到了！    天啊，抓到了！",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,out_of_scope,
2836,"**Title**RAG Meets Detox: Enhancing Text Detoxification Using Open Large Language Models with Retrieval Augmented Generation

**Abstract**In this work we present our solution at the Multilingual Text Detoxification 2024 task, whose objective is to
           take toxic text and convert into one that conveys the same meaning without containing any toxicity. Our
           approach utilizes open Large Language Models extended with dynamic prompt creation combined with Retrieval
         Augmented Generation. The evaluation results show that despite its simplicity, our method has the potential
            to provide competitive results, as evidenced by both the automatic and manual evaluation executed by the task
            organizers. Overall, our approach ranked 5th in the manual evaluation, with our best-performing language,
          German, even surpassing the human reference.

       Keywords
        PAN 2024, Retrieval Augmented Generation, text detoxification, Llama3, LLM, toxic text



1. Introduction

The task of identification of toxicity in texts is an active area of research. Social networks are trying to
address this problem by simply blocking such texts. A more interesting and effective approach might
be to automatically rewrite these texts, so that they are ideally no longer toxic, but their meaning is
kept intact. This processed is denoted as detoxification.
  The Multilingual Text Detoxification (TextDetox) 2024 task aims to create and explore such methods.
The participants are provided with a dataset of toxic texts in several languages from all over the globe,
which then should be detoxified. The goal is to find a method, which after evaluation provides texts
which are neutral, but their meaning is the same as the toxic text on the input.
  We explore how a data scientist with only an API access to a Large Language Model (LLM), in our
case Llama3 can develop effective solutions for this task. We did not fine-tune or alter in any way, the
only approach was to creatively adjust prompts given to the LLM, so that its outputs will get highest
score possible. We have developed several methods, from the simple ones like zero shot prompting, to
utilizing existing datasets of text detoxifications and generating these prompts dynamically considering
the input text to be detoxified.
  For this we have used external tools like vector databases containing pairs of toxic texts and their
neutral counterparts, which were queried using embedding of the toxic texts. We have found this
method to be competitive and despite its simplicity it achieved high ranking in this task.
  We submitted our results under the usernames erehulka and mareksuppa to the CodaLab portal.
Our best-performing languages, in comparison to other participants’ submissions, were German and
Chinese. Notably, our score for German even surpassed the human references in the manual evaluation.
Overall, our approach ranked 5th in the manual evaluation. A more detailed discussion of our results is
provided in Section 6.




CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, FranceCEURceur-ws.org","Rehulka E,Suppa M",,,RAG Meets Detox: Enhancing Text Detoxification Using Open Large Language Models with Retrieval Augmented Generation,3740,, , Conference Paper,,"In this work we present our solution at the Multilingual Text Detoxification 2024 task, whose objective is to
           take toxic text and convert into one that conveys the same meaning without containing any toxicity. Our
           approach utilizes open Large Language Models extended with dynamic prompt creation combined with Retrieval
         Augmented Generation. The evaluation results show that despite its simplicity, our method has the potential
            to provide competitive results, as evidenced by both the automatic and manual evaluation executed by the task
            organizers. Overall, our approach ranked 5th in the manual evaluation, with our best-performing language,
          German, even surpassing the human reference.

       Keywords
        PAN 2024, Retrieval Augmented Generation, text detoxification, Llama3, LLM, toxic text



1. Introduction

The task of identification of toxicity in texts is an active area of research. Social networks are trying to
address this problem by simply blocking such texts. A more interesting and effective approach might
be to automatically rewrite these texts, so that they are ideally no longer toxic, but their meaning is
kept intact. This processed is denoted as detoxification.
  The Multilingual Text Detoxification (TextDetox) 2024 task aims to create and explore such methods.
The participants are provided with a dataset of toxic texts in several languages from all over the globe,
which then should be detoxified. The goal is to find a method, which after evaluation provides texts
which are neutral, but their meaning is the same as the toxic text on the input.
  We explore how a data scientist with only an API access to a Large Language Model (LLM), in our
case Llama3 can develop effective solutions for this task. We did not fine-tune or alter in any way, the
only approach was to creatively adjust prompts given to the LLM, so that its outputs will get highest
score possible. We have developed several methods, from the simple ones like zero shot prompting, to
utilizing existing datasets of text detoxifications and generating these prompts dynamically considering
the input text to be detoxified.
  For this we have used external tools like vector databases containing pairs of toxic texts and their
neutral counterparts, which were queried using embedding of the toxic texts. We have found this
method to be competitive and despite its simplicity it achieved high ranking in this task.
  We submitted our results under the usernames erehulka and mareksuppa to the CodaLab portal.
Our best-performing languages, in comparison to other participants’ submissions, were German and
Chinese. Notably, our score for German even surpassed the human references in the manual evaluation.
Overall, our approach ranked 5th in the manual evaluation. A more detailed discussion of our results is
provided in Section 6.




CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, FranceCEURceur-ws.org",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2837,"**Title**SINAI at PAN 2024 TextDetox: Application of Chain of Thought with Self-Consistency Strategy in Large Language Models for Multilingual Text Detoxification

**Abstract**This article describes the participation of the SINAI research group in the shared task TextDetox (Multilingual
           Text Detoxification) in CLEF 2024. TThe proposed system for multilingual text detoxification employs Large
          Language Models (LLMs) utilizing a Self-Consistent Chain of Thought (CoT-SC) prompting strategy. This CoT-SC
            strategy consists of identifying the language of the toxic comment and then generating three different detoxified
             text proposals, the first proposal consists of removing the toxic words, the second of replacing the toxic words
           with neutral words, and the last of rewriting the toxic text in a neutral way. Subsequently, the selected LLM has
            to evaluate each generated neutral text according to the competition metrics. Finally, the model selects the best
            neutral text generated. Specifically with this proposal, we aim to evaluate the capacity of auto-evaluation and
           reasoning of LLM in different languages, including those with low resources. Our proposal was ranked 23rd in
            the automatic evaluation metrics and 11th in the final ranking with the manual evaluation.

       Keywords
            Multilingual Detoxification, Large Language Models, Chain of Thought with Self-Consistency, Text Generation,



1. Introduction

Social networks have allowed us all to be connected and know what is happening on the other side of the
world in a few seconds. However, the inappropriate use of these social networks and the anonymity that
these platforms allow make it easier to offend other users, and the network is filled with inappropriate
comments such as toxic comments. The task organizers define toxic comments as those comments that
contain obscene and rude language mixed with neutral content (explicit toxicity) and those comments
that do not contain neutral text and are loaded with sarcasm, passive aggressiveness, or direct hatred
towards some group or individual. Although in different research works, the term toxicity can have
different definitions according to the aspects of toxic language they address [1] and have also been used
to describe hate speech [2, 3], abusive [4], aggressive [5], and offensive language [6].
  Due to all of the problems mentioned previously and thanks to the capacity of the new large
language models to generate text or what is currently known as generative AI, it has been possible
to explore different proactive strategies to mitigate offensive language in online environments, such
as the automatic generation of counter-narratives [7, 8] or the strategy of text detoxification. In this
case, the organizers centered at text detoxification and proposed the shared task TextDetox, where
the main objective is to generate neutral alternatives to toxic comments. To do so, they focus on texts
with explicit toxicity because of the complexity of detoxifying texts with implicit toxicity in which the
initial intention of the comment is already toxic. To detoxify texts it is important to maintain as much


CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, France
*Corresponding author.
†These authors contributed equally.
$ mevallec@ujaen.es (M. E. Vallecillo-Rodríguez); amontejo@ujaen.es (A. Montejo-Ráez); maite@ujaen.es
(M. T. Martín-Valdivia)
   0000-0001-7140-6268 (M. E. Vallecillo-Rodríguez); 0000-0002-8643-2714 (A. Montejo-Ráez); 0000-0002-2874-0401CEURceur-ws.org","Rodríguez ME,Montejo-Ráez A,Martín-Valdivia MT",,,SINAI at PAN 2024 TextDetox: Application of Chain of Thought with Self-Consistency Strategy in Large Language Models for Multilingual Text Detoxification,3740,, , Conference Paper,,"This article describes the participation of the SINAI research group in the shared task TextDetox (Multilingual
           Text Detoxification) in CLEF 2024. TThe proposed system for multilingual text detoxification employs Large
          Language Models (LLMs) utilizing a Self-Consistent Chain of Thought (CoT-SC) prompting strategy. This CoT-SC
            strategy consists of identifying the language of the toxic comment and then generating three different detoxified
             text proposals, the first proposal consists of removing the toxic words, the second of replacing the toxic words
           with neutral words, and the last of rewriting the toxic text in a neutral way. Subsequently, the selected LLM has
            to evaluate each generated neutral text according to the competition metrics. Finally, the model selects the best
            neutral text generated. Specifically with this proposal, we aim to evaluate the capacity of auto-evaluation and
           reasoning of LLM in different languages, including those with low resources. Our proposal was ranked 23rd in
            the automatic evaluation metrics and 11th in the final ranking with the manual evaluation.

       Keywords
            Multilingual Detoxification, Large Language Models, Chain of Thought with Self-Consistency, Text Generation,



1. Introduction

Social networks have allowed us all to be connected and know what is happening on the other side of the
world in a few seconds. However, the inappropriate use of these social networks and the anonymity that
these platforms allow make it easier to offend other users, and the network is filled with inappropriate
comments such as toxic comments. The task organizers define toxic comments as those comments that
contain obscene and rude language mixed with neutral content (explicit toxicity) and those comments
that do not contain neutral text and are loaded with sarcasm, passive aggressiveness, or direct hatred
towards some group or individual. Although in different research works, the term toxicity can have
different definitions according to the aspects of toxic language they address [1] and have also been used
to describe hate speech [2, 3], abusive [4], aggressive [5], and offensive language [6].
  Due to all of the problems mentioned previously and thanks to the capacity of the new large
language models to generate text or what is currently known as generative AI, it has been possible
to explore different proactive strategies to mitigate offensive language in online environments, such
as the automatic generation of counter-narratives [7, 8] or the strategy of text detoxification. In this
case, the organizers centered at text detoxification and proposed the shared task TextDetox, where
the main objective is to generate neutral alternatives to toxic comments. To do so, they focus on texts
with explicit toxicity because of the complexity of detoxifying texts with implicit toxicity in which the
initial intention of the comment is already toxic. To detoxify texts it is important to maintain as much


CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024, Grenoble, France
*Corresponding author.
†These authors contributed equally.
$ mevallec@ujaen.es (M. E. Vallecillo-Rodríguez); amontejo@ujaen.es (A. Montejo-Ráez); maite@ujaen.es
(M. T. Martín-Valdivia)
   0000-0001-7140-6268 (M. E. Vallecillo-Rodríguez); 0000-0002-8643-2714 (A. Montejo-Ráez); 0000-0002-2874-0401CEURceur-ws.org",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2838,"**Title**SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification

**Abstract**Abstract:This paper presents a solution for the Multilingual Text Detoxification task in the PAN-2024 competition of the SmurfCat team. Using data augmentation through machine translation and a special filtering procedure, we collected an additional multilingual parallel dataset for text detoxification. Using the obtained data, we fine-tuned several multilingual sequence-to-sequence models, such as mT0 and Aya, on a text detoxification task. We applied the ORPO alignment technique to the final model. Our final model has only 3.7 billion parameters and achieves state-of-the-art results for the Ukrainian language and near state-of-the-art results for other languages. In the competition, our team achieved first place in the automated evaluation with a score of 0.52 and second place in the final human evaluation with a score of 0.74.","Rykov E,Zaytsev K,Anisimov I,Voronin A",,,SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification,3740,, , Conference Paper,,"Abstract:This paper presents a solution for the Multilingual Text Detoxification task in the PAN-2024 competition of the SmurfCat team. Using data augmentation through machine translation and a special filtering procedure, we collected an additional multilingual parallel dataset for text detoxification. Using the obtained data, we fine-tuned several multilingual sequence-to-sequence models, such as mT0 and Aya, on a text detoxification task. We applied the ORPO alignment technique to the final model. Our final model has only 3.7 billion parameters and achieves state-of-the-art results for the Ukrainian language and near state-of-the-art results for other languages. In the competition, our team achieved first place in the automated evaluation with a score of 0.52 and second place in the final human evaluation with a score of 0.74.",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2839,"**Title**PAN 2024 Multilingual TextDetox: Exploring Different Regimes For Synthetic Data Training For Multilingual Text Detoxification

**Abstract**Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification - Extended Abstract",Sushko N,,,PAN 2024 Multilingual TextDetox: Exploring Different Regimes For Synthetic Data Training For Multilingual Text Detoxification,3740,, , Conference Paper,,"Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification - Extended Abstract",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024), Grenoble, France, 9-12 September, 2024  ",,detox,
2840,No abstract available,"Bevendorff J,Casals XB,Chulvi B,Dementieva D,Elnagar A,Freitag D,Fröbe M,Korencic D,Mayerl M,Mukherjee A,Panchenko A,Potthast M,Rangel F,Rosso P,Smirnova A,Stamatatos E,Stein B,Taulé M,Ustalov D,Wiegmann M,Zangerle E",,,"Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification - Extended Abstract",14613,,10.1007/978-3-031-56072-9_1 , Conference Paper,,,,,,,Springer ,"Advances in Information Retrieval - 46th European Conference on Information Retrieval, ECIR 2024, Glasgow, UK, March 24-28, 2024, Proceedings, Part VI  ",,detox,
2841,"**Title**DetoxLLM: A Framework for Detoxification with Explanations

**Abstract**Prior works on detoxification are scattered in
    the sense that they do not cover all aspects
    of detoxification needed in a real-world sce-
    nario.  Notably, prior works restrict the task
    of developing detoxification models to only
    a seen subset of platforms, leaving the ques-
    tion of how the models would perform on un-
    seen platforms unexplored. Additionally, these
    works do not address non-detoxifiability, a phe-
   nomenon whereby the toxic text cannot be
    detoxified without altering the meaning. We
    propose DetoxLLM1, the first comprehensive
    end-to-end detoxification framework, which
    attempts to alleviate the aforementioned lim-
     itations. We first introduce a cross-platform
    pseudo-parallel corpus applying multi-step data
    processing and generation strategies leveraging
    ChatGPT. We then train a suite of detoxifica-
    tion models with our cross-platform corpus.
   We show that our detoxification models out-
    perform the SoTA model trained with human-
    annotated parallel corpus. We further intro-
    duce explanation to promote transparency and
    trustworthiness. DetoxLLM additionally offers
    a unique paraphrase detector especially dedi-
    cated for the detoxification task to tackle the
    non-detoxifiable cases. Through experimental
    analysis, we demonstrate the effectiveness of
    our cross-platform corpus and the robustness
    of DetoxLLM against adversarial toxicity.

1  Introduction

The term toxic language is usually used to refer to
any form of offensive or hateful speech (Laugier
et al., 2021; Fortuna et al., 2020); specifically, toxic
or abusive language is defined as any form of mi-
croaggression, condescension, harassment, hate
speech, trolling, and the like (Jurgens et al., 2019).
Use of toxic language online has been a signif-
icant issue over the years. Although a plethora

   1UBC-NLP/DetoxLLM-7BFigure 1:  Workflow of DetoxLLM framework. The
framework will take a toxic input. The detoxification
model will generate the explanation of why the input
is toxic, as well as a non-toxic version. The paraphrase
detector will analyze the semantic similarity of the toxic
and non-toxic pair and generate a warning  if the pair
is not semantically equivalent (an illustration of non-
detoxifiable case is depicted in Appendix K).


of works have explored the task of toxicity de-
tection, the task remains challenging due to its
evolving nature (Davidson et al., 2017; Müller and
Schwarz, 2017; Williams et al., 2019). In addition,
the linguistic variation in how toxicity manifests
itself across different platforms (Karan and Šnajder,
2018; Swamy et al., 2019; Salminen et al., 2020)
poses a standing challenge for toxicity detection.
Furthermore, the task of detecting toxic language,
taken literally, can only offer deletion of toxic text.
A more comprehensive approach to dealing with
toxic text would be to rewrite the text to keep the
useful content intact and eliminate toxicity, a task
known as detoxification (Logacheva et al., 2022).
Several works (Nogueira dos Santos et al., 2018;
Dale et al., 2021) have already explored the idea
of detoxification. More recently, Logacheva et al.19112Don't defend the TSA.
   F**kin thieving
        retards.Detoxification
   Model                     Paraphrase
                                 DetectorThe input text is toxic because it
  contains offensive language
(""F**kin"") and a personal attack
  (""thieving retards""), which is
  demeaning and disrespectful
  towards the TSA, a specific
group. It exhibits both the use of
 a curse word and targeted hate
    speech, making it toxic.Don't support the TSA.
 They are incredibly
     frustrating and
    unprofessional.","Khondaker MT,Abdul-Mageed M,Lakshmanan LV",,,DetoxLLM: A Framework for Detoxification with Explanations,,, , Conference Paper,,"Prior works on detoxification are scattered in
    the sense that they do not cover all aspects
    of detoxification needed in a real-world sce-
    nario.  Notably, prior works restrict the task
    of developing detoxification models to only
    a seen subset of platforms, leaving the ques-
    tion of how the models would perform on un-
    seen platforms unexplored. Additionally, these
    works do not address non-detoxifiability, a phe-
   nomenon whereby the toxic text cannot be
    detoxified without altering the meaning. We
    propose DetoxLLM1, the first comprehensive
    end-to-end detoxification framework, which
    attempts to alleviate the aforementioned lim-
     itations. We first introduce a cross-platform
    pseudo-parallel corpus applying multi-step data
    processing and generation strategies leveraging
    ChatGPT. We then train a suite of detoxifica-
    tion models with our cross-platform corpus.
   We show that our detoxification models out-
    perform the SoTA model trained with human-
    annotated parallel corpus. We further intro-
    duce explanation to promote transparency and
    trustworthiness. DetoxLLM additionally offers
    a unique paraphrase detector especially dedi-
    cated for the detoxification task to tackle the
    non-detoxifiable cases. Through experimental
    analysis, we demonstrate the effectiveness of
    our cross-platform corpus and the robustness
    of DetoxLLM against adversarial toxicity.

1  Introduction

The term toxic language is usually used to refer to
any form of offensive or hateful speech (Laugier
et al., 2021; Fortuna et al., 2020); specifically, toxic
or abusive language is defined as any form of mi-
croaggression, condescension, harassment, hate
speech, trolling, and the like (Jurgens et al., 2019).
Use of toxic language online has been a signif-
icant issue over the years. Although a plethora

   1UBC-NLP/DetoxLLM-7BFigure 1:  Workflow of DetoxLLM framework. The
framework will take a toxic input. The detoxification
model will generate the explanation of why the input
is toxic, as well as a non-toxic version. The paraphrase
detector will analyze the semantic similarity of the toxic
and non-toxic pair and generate a warning  if the pair
is not semantically equivalent (an illustration of non-
detoxifiable case is depicted in Appendix K).


of works have explored the task of toxicity de-
tection, the task remains challenging due to its
evolving nature (Davidson et al., 2017; Müller and
Schwarz, 2017; Williams et al., 2019). In addition,
the linguistic variation in how toxicity manifests
itself across different platforms (Karan and Šnajder,
2018; Swamy et al., 2019; Salminen et al., 2020)
poses a standing challenge for toxicity detection.
Furthermore, the task of detecting toxic language,
taken literally, can only offer deletion of toxic text.
A more comprehensive approach to dealing with
toxic text would be to rewrite the text to keep the
useful content intact and eliminate toxicity, a task
known as detoxification (Logacheva et al., 2022).
Several works (Nogueira dos Santos et al., 2018;
Dale et al., 2021) have already explored the idea
of detoxification. More recently, Logacheva et al.19112Don't defend the TSA.
   F**kin thieving
        retards.Detoxification
   Model                     Paraphrase
                                 DetectorThe input text is toxic because it
  contains offensive language
(""F**kin"") and a personal attack
  (""thieving retards""), which is
  demeaning and disrespectful
  towards the TSA, a specific
group. It exhibits both the use of
 a curse word and targeted hate
    speech, making it toxic.Don't support the TSA.
 They are incredibly
     frustrating and
    unprofessional.",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,detox,
2842,"**Title**XDetox: Text Detoxification with Token-Level Toxicity Explanations

**Abstract**Methods for mitigating toxic content through
    masking and  infilling  often  overlook  the
    decision-making process, leading to either in-
     sufficient or excessive modifications of toxic
    tokens. To address this challenge, we propose
   XDetox, a novel method that integrates token-
    level toxicity explanations with the masking
    and infilling detoxification process. We uti-
    lized this approach with two strategies to en-
    hance the performance of detoxification. First,
    identifying toxic tokens to improve the qual-
     ity of masking. Second, selecting the regen-
    erated sentence by re-ranking the least toxic
    sentence among candidates. Our experimen-
     tal results show state-of-the-art performance
    across four datasets compared to existing detox-
     ification methods. Furthermore, human eval-
    uations indicate that our method outperforms
    baselines in both fluency and toxicity reduction.
    These results demonstrate the effectiveness of
    our method in text detoxification.1

1  Introduction

Text generation models have made notable advance-
ments in natural language processing (NLP), yet
generating toxic content remains a significant chal-
lenge with social and ethical implications (Sheng
et al., 2019). One promising approach to mitigat-
ing toxic content involves masking toxic tokens
and infilling them with non-toxic tokens using a
language model (Dale et al., 2021; Hallinan et al.,
2023). However, existing detoxification processes
are black-box approaches, which results in limita-
tions in modifying toxic tokens.
  Previous research has explored various strate-
gies for detecting and masking toxic tokens. These
strategies include approaches such as masking to-
kens with high frequency counts (Li et al., 2018),
using attention weights to mask tokens (Sudhakar

   1We  release  our  code   at  https://github.com/
LeeBumSeok/XDetox.An ugly life for an ugly man.Figure 1: Overview of our model method. The first step
is the identification of toxic tokens using a token-level
toxicity explanation method, followed by masking to-
kens. The next stage involves infilling the non-toxic
tokens using a detoxification method. Finally, a rerank-
ing step selects the sentence with the lowest cumulative
toxicity score as the most appropriate output.


et al., 2019; Wu et al., 2019), training models to
identify and mask toxic tokens (Dale et al., 2021),
and using disagreement levels from models trained
in different domains to mask tokens (Malmi et al.,
2020; Hallinan et al., 2023). However, these meth-
ods do not consider explainable processes in the
regeneration process, leading to the misclassifica-
tion and masking of non-toxic tokens as toxic.
  To overcome these limitations and enhance the
explainability of regenerated sentences, we propose
a novel approach, XDetox, that combines token-15215Identify Toxic TokenAn     ugly         life      for    an     ugly   man

An       life      for    an    manFill Mask     Base LM





Non-Toxic LM (Expert)





Toxic LM (Anti-Expert)amazing





amazing





amazing awful
+





 awful
-





 awfulordinary        old
  +





ordinary        oldordinaryoldReranking  amazing    exemplary      entire                               ordinary    honorable       old



An  amazing     life    for  an   ordinary  manamazing    exemplary      entire                               ordinary    honorable       old","Lee B,Kim H,Kim K,Choi YS",,,XDetox: Text Detoxification with Token-Level Toxicity Explanations,,, , Conference Paper,,"Methods for mitigating toxic content through
    masking and  infilling  often  overlook  the
    decision-making process, leading to either in-
     sufficient or excessive modifications of toxic
    tokens. To address this challenge, we propose
   XDetox, a novel method that integrates token-
    level toxicity explanations with the masking
    and infilling detoxification process. We uti-
    lized this approach with two strategies to en-
    hance the performance of detoxification. First,
    identifying toxic tokens to improve the qual-
     ity of masking. Second, selecting the regen-
    erated sentence by re-ranking the least toxic
    sentence among candidates. Our experimen-
     tal results show state-of-the-art performance
    across four datasets compared to existing detox-
     ification methods. Furthermore, human eval-
    uations indicate that our method outperforms
    baselines in both fluency and toxicity reduction.
    These results demonstrate the effectiveness of
    our method in text detoxification.1

1  Introduction

Text generation models have made notable advance-
ments in natural language processing (NLP), yet
generating toxic content remains a significant chal-
lenge with social and ethical implications (Sheng
et al., 2019). One promising approach to mitigat-
ing toxic content involves masking toxic tokens
and infilling them with non-toxic tokens using a
language model (Dale et al., 2021; Hallinan et al.,
2023). However, existing detoxification processes
are black-box approaches, which results in limita-
tions in modifying toxic tokens.
  Previous research has explored various strate-
gies for detecting and masking toxic tokens. These
strategies include approaches such as masking to-
kens with high frequency counts (Li et al., 2018),
using attention weights to mask tokens (Sudhakar

   1We  release  our  code   at  https://github.com/
LeeBumSeok/XDetox.An ugly life for an ugly man.Figure 1: Overview of our model method. The first step
is the identification of toxic tokens using a token-level
toxicity explanation method, followed by masking to-
kens. The next stage involves infilling the non-toxic
tokens using a detoxification method. Finally, a rerank-
ing step selects the sentence with the lowest cumulative
toxicity score as the most appropriate output.


et al., 2019; Wu et al., 2019), training models to
identify and mask toxic tokens (Dale et al., 2021),
and using disagreement levels from models trained
in different domains to mask tokens (Malmi et al.,
2020; Hallinan et al., 2023). However, these meth-
ods do not consider explainable processes in the
regeneration process, leading to the misclassifica-
tion and masking of non-toxic tokens as toxic.
  To overcome these limitations and enhance the
explainability of regenerated sentences, we propose
a novel approach, XDetox, that combines token-15215Identify Toxic TokenAn     ugly         life      for    an     ugly   man

An       life      for    an    manFill Mask     Base LM





Non-Toxic LM (Expert)





Toxic LM (Anti-Expert)amazing





amazing





amazing awful
+





 awful
-





 awfulordinary        old
  +





ordinary        oldordinaryoldReranking  amazing    exemplary      entire                               ordinary    honorable       old



An  amazing     life    for  an   ordinary  manamazing    exemplary      entire                               ordinary    honorable       old",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,detox,
2843,"**Title**Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification

**Abstract**We propose a constraint learning schema for
    fine-tuning Large Language Models (LLMs)
    with attribute control. Given a training corpus
    and control criteria formulated as a sequence-
     level constraint on model outputs, our method
     fine-tunes the LLM on the training corpus while
    enhancing constraint satisfaction with minimal
    impact on its utility and generation quality.
     Specifically, our approach regularizes the LLM
    training by penalizing the KL divergence be-
    tween the desired output distribution, which sat-
     isfies the constraints, and the LLM’s posterior.
    This regularization term can be approximated
   by an auxiliary model trained to decompose
    the sequence-level constraints into token-level
    guidance, allowing the term to be measured
   by a closed-form formulation. To further im-
    prove efficiency, we design a parallel scheme
    for concurrently updating both the LLM and
    the auxiliary model. We evaluate the empirical
    performance of our approach by controlling the
     toxicity when training an LLM. We show that
    our approach leads to an LLM that produces
    fewer inappropriate responses while achieving
    competitive performance on benchmarks and a
     toxicity detection task.

1  Introduction

Large language models (LLMs) have demonstrated
impressive performance across a variety of tasks
which has led to their widespread adoption for a
multitude of AI applications. However, they carry
the risk of producing inappropriate, unsafe, unfair
outputs (Wallace et al., 2019; Sheng et al., 2019;
Gehman et al., 2020; Huang et al., 2024) Ideally,
LLMs should learn to comply with constraints and
policies specified by users. For example, in a user-
facing application like a chatbot, LLMs should
never generate toxic or offensive responses, nor
to divulge sensitive information. While there are
several post hoc methods to moderate LLM out-
puts (Lu et al., 2022; Qian et al., 2022; Markovet al., 2023), they lack an efficient and principled
approach to training LLMs to adhere to constraints.
  We start by defining a sequence-level oracle as
a function that takes an LLM’s output and adju-
dicates whether it satisfies a predefined set of at-
tribute constraints. In practice, the oracle can be a
rule-based, model-based, or mixed system (e.g., a
classifier that decides whether a sentence is toxic).
Given a pre-trained LLM and the oracle, we aim to
fine-tune an LLM to achieve the following: 1) At-
tribute control: The LLM output passes the oracle
with a high probability. 2) Utility preservation:
The LLM maintains performance comparable to the
original LLM on utility benchmarks. 3) Training
efficiency: The cost of fine-tuning with attribute
control is similar to that of the typical fine-tuning.
  While existing approaches can meet some of
these criteria, achieving all of them is challenging.
For example, filtering training data with the ora-
cle function before fine-tuning (Wang et al., 2022)
is a simple and efficient method. However, this
approach could be less effective. Taking toxicity
control as an example, if we filter out the toxic
data from a fine-tuning corpus, in a regular con-
text the model will learn not to generate toxic con-
tents. Nevertheless, it might still be possible to
trigger the generation of offensive responses given
a toxic prompts, due to the fact that toxic prompts
are out-of-distribution in relation to the fine-tuning
corpus. Another promising approach is reinforce-
ment learning (RL) considering controlling criteria
in the reward function (Snell et al., 2023; Mudgal
et al., 2023). However, RL setups tend to be ineffi-
cient and require preference data generation which
adds significant overhead in comparison to generic
fine-tuning.
  In this work, we propose a novel solution to
training an LLM with a set of attribute constraints.
Inspired by the classic idea of constraint-driven
learning (Chang et al., 2007) and posterior regu-
larization (Ganchev et al., 2010), we incorporate13329","Meng T,Mehrabi N,Goyal P,Ramakrishna A,Galstyan A,Zemel RS,Chang KW,Gupta R,Peris C",,,Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification,,, , Conference Paper,,"We propose a constraint learning schema for
    fine-tuning Large Language Models (LLMs)
    with attribute control. Given a training corpus
    and control criteria formulated as a sequence-
     level constraint on model outputs, our method
     fine-tunes the LLM on the training corpus while
    enhancing constraint satisfaction with minimal
    impact on its utility and generation quality.
     Specifically, our approach regularizes the LLM
    training by penalizing the KL divergence be-
    tween the desired output distribution, which sat-
     isfies the constraints, and the LLM’s posterior.
    This regularization term can be approximated
   by an auxiliary model trained to decompose
    the sequence-level constraints into token-level
    guidance, allowing the term to be measured
   by a closed-form formulation. To further im-
    prove efficiency, we design a parallel scheme
    for concurrently updating both the LLM and
    the auxiliary model. We evaluate the empirical
    performance of our approach by controlling the
     toxicity when training an LLM. We show that
    our approach leads to an LLM that produces
    fewer inappropriate responses while achieving
    competitive performance on benchmarks and a
     toxicity detection task.

1  Introduction

Large language models (LLMs) have demonstrated
impressive performance across a variety of tasks
which has led to their widespread adoption for a
multitude of AI applications. However, they carry
the risk of producing inappropriate, unsafe, unfair
outputs (Wallace et al., 2019; Sheng et al., 2019;
Gehman et al., 2020; Huang et al., 2024) Ideally,
LLMs should learn to comply with constraints and
policies specified by users. For example, in a user-
facing application like a chatbot, LLMs should
never generate toxic or offensive responses, nor
to divulge sensitive information. While there are
several post hoc methods to moderate LLM out-
puts (Lu et al., 2022; Qian et al., 2022; Markovet al., 2023), they lack an efficient and principled
approach to training LLMs to adhere to constraints.
  We start by defining a sequence-level oracle as
a function that takes an LLM’s output and adju-
dicates whether it satisfies a predefined set of at-
tribute constraints. In practice, the oracle can be a
rule-based, model-based, or mixed system (e.g., a
classifier that decides whether a sentence is toxic).
Given a pre-trained LLM and the oracle, we aim to
fine-tune an LLM to achieve the following: 1) At-
tribute control: The LLM output passes the oracle
with a high probability. 2) Utility preservation:
The LLM maintains performance comparable to the
original LLM on utility benchmarks. 3) Training
efficiency: The cost of fine-tuning with attribute
control is similar to that of the typical fine-tuning.
  While existing approaches can meet some of
these criteria, achieving all of them is challenging.
For example, filtering training data with the ora-
cle function before fine-tuning (Wang et al., 2022)
is a simple and efficient method. However, this
approach could be less effective. Taking toxicity
control as an example, if we filter out the toxic
data from a fine-tuning corpus, in a regular con-
text the model will learn not to generate toxic con-
tents. Nevertheless, it might still be possible to
trigger the generation of offensive responses given
a toxic prompts, due to the fact that toxic prompts
are out-of-distribution in relation to the fine-tuning
corpus. Another promising approach is reinforce-
ment learning (RL) considering controlling criteria
in the reward function (Snell et al., 2023; Mudgal
et al., 2023). However, RL setups tend to be ineffi-
cient and require preference data generation which
adds significant overhead in comparison to generic
fine-tuning.
  In this work, we propose a novel solution to
training an LLM with a set of attribute constraints.
Inspired by the classic idea of constraint-driven
learning (Chang et al., 2007) and posterior regu-
larization (Ganchev et al., 2010), we incorporate13329",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024  ",,detox,
2844,"**Title**LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification

**Abstract**The lack of high-quality training data remains
    a significant challenge in NLP. Manual anno-
     tation methods, such as crowdsourcing, are
     costly, require intricate task design skills, and,
      if used incorrectly, may result in poor data qual-
      ity. From the other hand, LLMs have demon-
     strated proficiency in many NLP tasks, includ-
    ing zero-shot and few-shot data annotation.
    However, they often struggle with text detoxifi-
    cation due to alignment constraints and fail to
    generate the required detoxified text. This work
    explores the potential of modern open source
   LLMs to annotate parallel data for text detoxifi-
     cation. Using the recent technique of activation
    patching, we generate a pseudo-parallel detoxi-
     fication dataset based on ParaDetox. The detox-
     ification model trained on our generated data
    shows comparable performance to the original
    dataset in automatic detoxification evaluation
    metrics and superior quality in manual evalua-
    tion and side-by-side comparisons.

1  Introduction

The main challenge in solving many natural lan-
guage problems has been and continues to be the
lack of high-quality training data. Each year, re-
searchers and large corporations invest hundreds of
thousands of dollars and countless hours of work
collecting, evaluating, and manually labeling data
in order to train machine learning models (Whang
et al., 2023; Alzubaidi et al., 2023).
  While crowdsourcing remains one of the most
popular methods for data collection, it presents
several major drawbacks: (1) variability in data
quality due to the diverse skill levels of contribu-
tors, (2) the total cost and time required for large-
scale projects, and (3) potential biases due to crowd
workers differences in background. Meanwhile,
LLMs have shown the ability to solve numerous
NLP tasks with zero or few examples (Kojima

   *Equal contribution.Figure 1: Instead of an elaborated multi-step crowd-
sourcing pipeline for parallel data collection used in
ParaDetox, we explore data synthesis using LLMs.


et al., 2022; Wei et al., 2022). Moreover, LLMs
have also been tested as a replacement of crowd-
sourcing for many NLP data annotation tasks, in-
cluding sentiment analysis, named entity recogni-
tion (NER) (Zhang et al., 2023a), machine transla-
tion (Jiao et al., 2023), and many other text annota-
tion tasks (Gilardi et al., 2023).
  Despite their impressive capabilities, LLMs still
struggle with text detoxification, a task of rewriting
original toxic (e.g. rude) text in a polite (neutral)
way that preserves the original meaning and does
not degrade its fluency (Ayele et al., 2024). LLM-
based annotation of pseudo-parallel data for detox-
ification is still a challenge due to strict alignment.
Both open-source and proprietary LLMs may at
some point refuse to generate such detoxifications.
   In this work, we test the hypothesis that modern
open-source LLMs, such as Llama 3 (AI@Meta,
2024), can serve as plausible parallel data annota-
tors for the task of text detoxification. To bypass
detoxification refusals, we apply the recently intro-
duced activation patching technique (Arditi et al.,
2024) and generate a pseudo-parallel detoxification
dataset based on the toxic part of ParaDetox (Lo-
gacheva et al., 2022), a parallel detoxification cor-
pus for English. Following the training pipeline
of Logacheva et al. (2022), we train BART on
both the original ParaDetox data and the PseudoPa-
raDetox data generated by LLMs (cf. Figure 1).14361ParaDetox


 TOXIC TEXTS

   HUMAN-
  ANNOTATED
NEUTRAL TEXTSPseudoParaDetox


     TOXIC TEXTSLLM-ANNOTATED
NEUTRAL TEXTSBART                   BART","Moskovskiy D,Pletenev S,Panchenko A",,,LLMs to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification,,, , Conference Paper,,"The lack of high-quality training data remains
    a significant challenge in NLP. Manual anno-
     tation methods, such as crowdsourcing, are
     costly, require intricate task design skills, and,
      if used incorrectly, may result in poor data qual-
      ity. From the other hand, LLMs have demon-
     strated proficiency in many NLP tasks, includ-
    ing zero-shot and few-shot data annotation.
    However, they often struggle with text detoxifi-
    cation due to alignment constraints and fail to
    generate the required detoxified text. This work
    explores the potential of modern open source
   LLMs to annotate parallel data for text detoxifi-
     cation. Using the recent technique of activation
    patching, we generate a pseudo-parallel detoxi-
     fication dataset based on ParaDetox. The detox-
     ification model trained on our generated data
    shows comparable performance to the original
    dataset in automatic detoxification evaluation
    metrics and superior quality in manual evalua-
    tion and side-by-side comparisons.

1  Introduction

The main challenge in solving many natural lan-
guage problems has been and continues to be the
lack of high-quality training data. Each year, re-
searchers and large corporations invest hundreds of
thousands of dollars and countless hours of work
collecting, evaluating, and manually labeling data
in order to train machine learning models (Whang
et al., 2023; Alzubaidi et al., 2023).
  While crowdsourcing remains one of the most
popular methods for data collection, it presents
several major drawbacks: (1) variability in data
quality due to the diverse skill levels of contribu-
tors, (2) the total cost and time required for large-
scale projects, and (3) potential biases due to crowd
workers differences in background. Meanwhile,
LLMs have shown the ability to solve numerous
NLP tasks with zero or few examples (Kojima

   *Equal contribution.Figure 1: Instead of an elaborated multi-step crowd-
sourcing pipeline for parallel data collection used in
ParaDetox, we explore data synthesis using LLMs.


et al., 2022; Wei et al., 2022). Moreover, LLMs
have also been tested as a replacement of crowd-
sourcing for many NLP data annotation tasks, in-
cluding sentiment analysis, named entity recogni-
tion (NER) (Zhang et al., 2023a), machine transla-
tion (Jiao et al., 2023), and many other text annota-
tion tasks (Gilardi et al., 2023).
  Despite their impressive capabilities, LLMs still
struggle with text detoxification, a task of rewriting
original toxic (e.g. rude) text in a polite (neutral)
way that preserves the original meaning and does
not degrade its fluency (Ayele et al., 2024). LLM-
based annotation of pseudo-parallel data for detox-
ification is still a challenge due to strict alignment.
Both open-source and proprietary LLMs may at
some point refuse to generate such detoxifications.
   In this work, we test the hypothesis that modern
open-source LLMs, such as Llama 3 (AI@Meta,
2024), can serve as plausible parallel data annota-
tors for the task of text detoxification. To bypass
detoxification refusals, we apply the recently intro-
duced activation patching technique (Arditi et al.,
2024) and generate a pseudo-parallel detoxification
dataset based on the toxic part of ParaDetox (Lo-
gacheva et al., 2022), a parallel detoxification cor-
pus for English. Following the training pipeline
of Logacheva et al. (2022), we train BART on
both the original ParaDetox data and the PseudoPa-
raDetox data generated by LLMs (cf. Figure 1).14361ParaDetox


 TOXIC TEXTS

   HUMAN-
  ANNOTATED
NEUTRAL TEXTSPseudoParaDetox


     TOXIC TEXTSLLM-ANNOTATED
NEUTRAL TEXTSBART                   BART",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024  ",,detox,
2845,"**Title**CMD: a framework for Context-aware Model self-Detoxification

**Abstract**Text detoxification aims to minimize the risk
    of language models producing toxic content.
    However, existing detoxification methods fail
    to balance the detoxification effectiveness and
    generation quality. This issue arises from ne-
    glecting the constraints imposed by the con-
     text: language models are designed to gener-
    ate output that closely matches the given con-
     text, while detoxification methods strive to en-
    sure the safety of the output, even if  it de-
    viates semantically from the context. Given
     this, we introduce a Context-aware Model self-
    Detoxification (CMD) framework that pays at-
    tention to both the context and the detoxifica-
    tion process, i.e., first detoxifying the context
    and then making the language model gener-
    ate along the safe context. Specifically, CMD
    framework involves two phases: utilizing lan-
    guage models to synthesize data and applying
    these data for training. We also introduce a
    toxic contrastive loss that encourages the model
    generation away from the negative toxic sam-
     ples. Experiments on various LLMs have veri-
     fied the effectiveness of our MSD framework,
    which can yield the best performance compared
    to baselines.1 Warning: cases in this paper
   may contain offensive content.

1  Introduction

Large Language Models (LLMs) have exhibited
remarkable performance in various NLP tasks and
applications (Brown et al., 2020; Chowdhery et al.,
2022; Anil et al., 2023). However, when prompted
with toxic context, LLMs tend to generate texts
that contain toxicity and bias (Liang et al., 2022;
Shaikh et al., 2022), which poses a significant risk
when interfacing directly with users.
  To mitigate such a concern for LLMs, one could
adopt the response rejection strategy (Zhang et al.,

    ∗Equal Contribution
    †Corresponding Author
   1Code & Data: https://github.com/ZetangForward/
CMD-Context-aware-Model-self-Detoxification.git2023) to ignore the unsafe context. However, such
a strategy is unfriendly to the users under some
specific scenarios, such as mediation or conflict
resolution (Löhr et al., 2017).  Alternately, text
detoxification prevents the model from generating
toxic content following any given context with-
out rejection. Along this line, non-negligible ef-
forts have recently been devoted to two main as-
pects: output-intervention methods like manipulat-
ing output probability distribution during inference
time (Dale et al., 2021; Xu et al., 2021; Leong et al.,
2023) and trainable methods that update model pa-
rameters on the detoxification datasets (Wang et al.,
2022; Park and Rudzicz, 2022; Niu et al., 2024).
  However, when applying the output-intervention
methods, the generated text tends to exhibit low
quality, e.g., semantic incoherence with the con-
text, due to some unexpected perturbations to the
outputs; while trainable methods are constrained
by the available detoxification dataset, which may
lead to poor detoxification effectiveness2. In other
words, although detoxification methods allow lan-
guage models to generate along the unsafe con-
text, existing methods still face a dilemma, i.e.,
the imbalance between detoxification effectiveness
and the generation quality. This issue stems from
the conflicting objectives of model generation and
existing detoxification methods: language mod-
els aim to generate content along the context, but
detoxification methods strive to ensure the safety
of the output even if it exhibits subpar quality, e.g.,
semantically deviating from the context.
  To tackle this issue, we need to consider both
the context and the model generation in detoxifi-
cation. Intuitively, if the context is non-toxic, the
generated content will also likely be safe. There-
fore, we decompose the detoxification into two
steps: first detoxifying the context and then making
the language model generate along the safe con-
tent, thus ensuring the generated text’s quality and

   2We conduct the preliminary study in Sec. 2.2.1930","Tang Z,Zhou K,Li J,Ding Y,Wang P,Bowen Y,Hua R,Zhang M",,,CMD: a framework for Context-aware Model self-Detoxification,,, , Conference Paper,,"Text detoxification aims to minimize the risk
    of language models producing toxic content.
    However, existing detoxification methods fail
    to balance the detoxification effectiveness and
    generation quality. This issue arises from ne-
    glecting the constraints imposed by the con-
     text: language models are designed to gener-
    ate output that closely matches the given con-
     text, while detoxification methods strive to en-
    sure the safety of the output, even if  it de-
    viates semantically from the context. Given
     this, we introduce a Context-aware Model self-
    Detoxification (CMD) framework that pays at-
    tention to both the context and the detoxifica-
    tion process, i.e., first detoxifying the context
    and then making the language model gener-
    ate along the safe context. Specifically, CMD
    framework involves two phases: utilizing lan-
    guage models to synthesize data and applying
    these data for training. We also introduce a
    toxic contrastive loss that encourages the model
    generation away from the negative toxic sam-
     ples. Experiments on various LLMs have veri-
     fied the effectiveness of our MSD framework,
    which can yield the best performance compared
    to baselines.1 Warning: cases in this paper
   may contain offensive content.

1  Introduction

Large Language Models (LLMs) have exhibited
remarkable performance in various NLP tasks and
applications (Brown et al., 2020; Chowdhery et al.,
2022; Anil et al., 2023). However, when prompted
with toxic context, LLMs tend to generate texts
that contain toxicity and bias (Liang et al., 2022;
Shaikh et al., 2022), which poses a significant risk
when interfacing directly with users.
  To mitigate such a concern for LLMs, one could
adopt the response rejection strategy (Zhang et al.,

    ∗Equal Contribution
    †Corresponding Author
   1Code & Data: https://github.com/ZetangForward/
CMD-Context-aware-Model-self-Detoxification.git2023) to ignore the unsafe context. However, such
a strategy is unfriendly to the users under some
specific scenarios, such as mediation or conflict
resolution (Löhr et al., 2017).  Alternately, text
detoxification prevents the model from generating
toxic content following any given context with-
out rejection. Along this line, non-negligible ef-
forts have recently been devoted to two main as-
pects: output-intervention methods like manipulat-
ing output probability distribution during inference
time (Dale et al., 2021; Xu et al., 2021; Leong et al.,
2023) and trainable methods that update model pa-
rameters on the detoxification datasets (Wang et al.,
2022; Park and Rudzicz, 2022; Niu et al., 2024).
  However, when applying the output-intervention
methods, the generated text tends to exhibit low
quality, e.g., semantic incoherence with the con-
text, due to some unexpected perturbations to the
outputs; while trainable methods are constrained
by the available detoxification dataset, which may
lead to poor detoxification effectiveness2. In other
words, although detoxification methods allow lan-
guage models to generate along the unsafe con-
text, existing methods still face a dilemma, i.e.,
the imbalance between detoxification effectiveness
and the generation quality. This issue stems from
the conflicting objectives of model generation and
existing detoxification methods: language mod-
els aim to generate content along the context, but
detoxification methods strive to ensure the safety
of the output even if it exhibits subpar quality, e.g.,
semantically deviating from the context.
  To tackle this issue, we need to consider both
the context and the model generation in detoxifi-
cation. Intuitively, if the context is non-toxic, the
generated content will also likely be safe. There-
fore, we decompose the detoxification into two
steps: first detoxifying the context and then making
the language model generate along the safe con-
tent, thus ensuring the generated text’s quality and

   2We conduct the preliminary study in Sec. 2.2.1930",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,detox,
2846,"**Title**MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages

**Abstract**Text detoxification is a textual style transfer
   (TST) task where a text is paraphrased from a
    toxic surface form, e.g. featuring rude words,
    to the neutral register.  Recently, text detox-
     ification methods found their applications in
    various task such as detoxification of Large
    Language Models (LLMs) (Leong et al., 2023;
   He et al., 2024; Tang et al., 2023) and toxic
    speech combating in social networks (Deng
     et al., 2023; Mun et al., 2023; Agarwal et al.,
    2023). All these applications are extremely im-
    portant to ensure safe communication in mod-
    ern digital worlds. However, the previous ap-
    proaches for parallel text detoxification corpora
    collection—ParaDetox (Logacheva et al., 2022)
    and APPADIA (Atwell et al., 2022)—were ex-
    plored only in monolingual setup. In this work,
   we aim to extend ParaDetox pipeline to multi-
    ple languages presenting MultiParaDetox to
    automate parallel detoxification corpus collec-
    tion for potentially any language. Then, we
    experiment with different text detoxification
   models—from unsupervised baselines to LLMs
    and fine-tuned models on the presented parallel
    corpora—showing the great benefit of parallel
    corpus presence to obtain state-of-the-art text
    detoxification models for any language.
    Warning: This paper contains rude texts that
    only serve as illustrative examples.

1  Introduction

We formulate text detoxification task as stated in
(Dementieva et al., 2021) so the objective is to
paraphrase a toxic text to a text that: (i) has neutral
style (register); (ii) saves the meaningful content as
much as possible; (iii) is fluent at least at the same
level as the input text. Before, many unsupervised
approaches for text detoxification were presented
(Nogueira dos Santos et al., 2018; Dale et al., 2021;
Floto et al., 2023) addressing the task based only on
available toxic or hate speech classification corpora
which are most commonly non-parallel. However,Original

Detox



Original


Detox



Original

Detox       Russian
Тебя это е**ть не должно, п***рюга
You shouldn’t give a f**k, f**got
Тебя это волновать не должно
You don’t have to worry about that
      Ukrainian
С**а як же мене всi бiсять б**ть
н**уй
F**k, everyone pisses me the f**k off
як же мене всi бiсять
I’m so irritated by everyone
       Spanish
Este país se va a la m**rda
This country is going to s**t
Cosas van muy mal en este país
Things are going very badly in this countryTable 1: Text detoxification parallel pairs examples from
Russian, Ukrainian, and Spanish ParaDetox datasets.


in ParaDetox (Logacheva et al., 2022) and APPA-
DIA (Atwell et al., 2022) the benefit of parallel
corpus for text detoxification was illustrated—the
seq2seq models like BART (Lewis et al., 2020) and
T5 (Raffel et al., 2020) fine-tuned on the presented
corpora outperformed previous unsupervised base-
lines in both manual and automated evaluations.
  While the parallel detoxification corpora are
already available together with their collection
pipelines, they were only presented for English
language. However, we strongly support the idea
of such corpus availability for any language would
lead to fair and safe LMs development equally for
all languages (Akiki et al., 2022). In this work, we
aim to extend ParaDetox collection pipeline to a
multilingual format confirming the hypothesis that
it can be used to collect parallel text detoxification
data for any language1. Thus, the contributions of
this work are as following:

    1In our study we use crowdsourcing platforms: they have
wide, yet limited support of languages.  In principle, our
pipeline shall be usable for spoken languages with available
text corpora (preferably in form of user-generated comments).124","Dementieva D,Babakov N,Panchenko A",,,MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages,,,10.18653/V1/2024.NAACL-SHORT.12 , Conference Paper,,"Text detoxification is a textual style transfer
   (TST) task where a text is paraphrased from a
    toxic surface form, e.g. featuring rude words,
    to the neutral register.  Recently, text detox-
     ification methods found their applications in
    various task such as detoxification of Large
    Language Models (LLMs) (Leong et al., 2023;
   He et al., 2024; Tang et al., 2023) and toxic
    speech combating in social networks (Deng
     et al., 2023; Mun et al., 2023; Agarwal et al.,
    2023). All these applications are extremely im-
    portant to ensure safe communication in mod-
    ern digital worlds. However, the previous ap-
    proaches for parallel text detoxification corpora
    collection—ParaDetox (Logacheva et al., 2022)
    and APPADIA (Atwell et al., 2022)—were ex-
    plored only in monolingual setup. In this work,
   we aim to extend ParaDetox pipeline to multi-
    ple languages presenting MultiParaDetox to
    automate parallel detoxification corpus collec-
    tion for potentially any language. Then, we
    experiment with different text detoxification
   models—from unsupervised baselines to LLMs
    and fine-tuned models on the presented parallel
    corpora—showing the great benefit of parallel
    corpus presence to obtain state-of-the-art text
    detoxification models for any language.
    Warning: This paper contains rude texts that
    only serve as illustrative examples.

1  Introduction

We formulate text detoxification task as stated in
(Dementieva et al., 2021) so the objective is to
paraphrase a toxic text to a text that: (i) has neutral
style (register); (ii) saves the meaningful content as
much as possible; (iii) is fluent at least at the same
level as the input text. Before, many unsupervised
approaches for text detoxification were presented
(Nogueira dos Santos et al., 2018; Dale et al., 2021;
Floto et al., 2023) addressing the task based only on
available toxic or hate speech classification corpora
which are most commonly non-parallel. However,Original

Detox



Original


Detox



Original

Detox       Russian
Тебя это е**ть не должно, п***рюга
You shouldn’t give a f**k, f**got
Тебя это волновать не должно
You don’t have to worry about that
      Ukrainian
С**а як же мене всi бiсять б**ть
н**уй
F**k, everyone pisses me the f**k off
як же мене всi бiсять
I’m so irritated by everyone
       Spanish
Este país se va a la m**rda
This country is going to s**t
Cosas van muy mal en este país
Things are going very badly in this countryTable 1: Text detoxification parallel pairs examples from
Russian, Ukrainian, and Spanish ParaDetox datasets.


in ParaDetox (Logacheva et al., 2022) and APPA-
DIA (Atwell et al., 2022) the benefit of parallel
corpus for text detoxification was illustrated—the
seq2seq models like BART (Lewis et al., 2020) and
T5 (Raffel et al., 2020) fine-tuned on the presented
corpora outperformed previous unsupervised base-
lines in both manual and automated evaluations.
  While the parallel detoxification corpora are
already available together with their collection
pipelines, they were only presented for English
language. However, we strongly support the idea
of such corpus availability for any language would
lead to fair and safe LMs development equally for
all languages (Akiki et al., 2022). In this work, we
aim to extend ParaDetox collection pipeline to a
multilingual format confirming the hypothesis that
it can be used to collect parallel text detoxification
data for any language1. Thus, the contributions of
this work are as following:

    1In our study we use crowdsourcing platforms: they have
wide, yet limited support of languages.  In principle, our
pipeline shall be usable for spoken languages with available
text corpora (preferably in form of user-generated comments).124",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Short Papers, NAACL 2024, Mexico City, Mexico, June 16-21, 2024  ",,out_but_toxicity,
2847,"**Title**MICo: Preventative Detoxification of Large Language Models through Inhibition Control

**Abstract**Large Language Models (LLMs) are powerful
    tools which have been both dominant and com-
   monplace in the field of Artificial Intelligence.
    Yet, LLMs have a tendency to devolve into
    toxic degeneration, wherein otherwise safe and
    unproblematic models begin generating toxic
    content. For the sake of social responsibility
   and inspired by the biological mechanisms of
    inhibition control, we introduce the paradigm
    of Education for Societal Norms (ESN). By
    collecting and labeling examples as acceptable
   and unacceptable (in this case toxic and non-
     toxic), and including a corresponding accept-
    able rewrite with every unacceptable example,
   we introduce a new mechanism for LLM detox-
     ification. We annotate a dataset of 2,850 entries
    and use it to fine-tune a model, which we call a
   Model with Inhibition Control (MICo). Evalu-
    ating this model on toxicity detection capability,
    rewrite detoxification, meaning preservation,
    and overall toxicity reduction, we discover sig-
     nificant improvements over the baseline model.
    In our experiments we show that overall toxi-
    city of this model is more than 60% reduced,
    with over 75% reduction in severe toxicity.

1  Introduction

Large Language Models (LLMs) are trained with the
explicit purpose of serving humans, between providing
information, presenting an engaging chat partner, and
answering any number of other user requests. Unfor-
tunately, for a variety of reasons, there is a tendency
for models to descend into neural toxic degeneration,
outputting toxic and otherwise harmful messages (Faal
et al., 2022; Xu et al., 2022; Wang et al., 2023). Nat-
urally, toxic prompts very commonly yield toxic re-
sponses, but many prompts which are entirely non-toxic
also yield toxic responses (Gehman et al., 2020; Guru-
rangan et al., 2022; Hartvigsen et al., 2022). Currently,
there are three main directions being used to combat
toxicity, each with a considerable drawback.

   ∗This work was done when Roy Siegelmann was an
intern at Amazon. Correspondence to rsiege15@jhu.edu and
mninareh@amazon.com.   First, the model may classify prompts as either toxic
or non-toxic, and categorically refuse to respond to those
deemed toxic (Xu et al., 2021). However, these ap-
proaches oftentimes use templated sentences to refuse
to respond to toxic content which can degrade user en-
gagement and lower helpfulness of the model (Xu et al.,
2021).  It is also possible for even entirely non-toxic
prompts to yield toxic generations, and thus this method
falls short of truly detoxifying.
  Second, the model can be trained solely on non-toxic
data (Welbl et al., 2021a; Gururangan et al., 2020). How-
ever, toxic content can be produced even from training
data which appears benign. Entirely purifying any word
which may lead to toxicity will leave the training corpus
narrow, impacting the richness of content which can
be generated. Furthermore, the model would not know
how to respond to prompts which include some toxicity;
thus, generations based around these prompts will be
nonsensical, slashing the model’s utility.
  Third, an external classifier or a secondary model
(e.g., in decoding time approaches) can be used to detect
whether the model generated toxic content, and if so stop
the content from reaching the user, instructing the model
to provide another generation instead (Mehrabi et al.,
2022; Liu et al., 2021; Krause et al., 2021; Dathathri
et al., 2019). However, without an understanding of tox-
icity, the model is likely to continuously generate toxic
content, yielding potentially unbounded latency times.
This would prove an impediment to the successful and
user-friendly utilization of the slower text-based output
and become unmanageable for models utilizing rapid
speech-based communication.
  Learning from these drawbacks, we formulate the fol-
lowing three requirements of a successful solution: (i)
Assuring non-toxic responses to non-toxic prompts. (ii)
Responding to toxic prompts in a natural, yet non-toxic
manner. (iii) Minimizing toxicity in real-time to prevent
latency. Despite the fact that AI has not yet provided
a satisfactory solution, humans exhibit these traits due
to their inherent ability of self reflection and inhibition
control. Healthy, mature humans consider the conse-
quences of their speech (and more generally, behavior)
via self-reflection before engaging in dialogue, and if
determined to be negative, will alter the output to con-
tain similar meaning yet eliminate the negative outcome.
This necessitates a true understanding of what is deemed1696","Siegelmann R,Mehrabi N,Goyal P,Goyal P,Bauer L,Dhamala J,Galstyan A,Gupta R,Ghanadan R",,,MICo: Preventative Detoxification of Large Language Models through Inhibition Control,,,10.18653/V1/2024.FINDINGS-NAACL.110 , Conference Paper,,"Large Language Models (LLMs) are powerful
    tools which have been both dominant and com-
   monplace in the field of Artificial Intelligence.
    Yet, LLMs have a tendency to devolve into
    toxic degeneration, wherein otherwise safe and
    unproblematic models begin generating toxic
    content. For the sake of social responsibility
   and inspired by the biological mechanisms of
    inhibition control, we introduce the paradigm
    of Education for Societal Norms (ESN). By
    collecting and labeling examples as acceptable
   and unacceptable (in this case toxic and non-
     toxic), and including a corresponding accept-
    able rewrite with every unacceptable example,
   we introduce a new mechanism for LLM detox-
     ification. We annotate a dataset of 2,850 entries
    and use it to fine-tune a model, which we call a
   Model with Inhibition Control (MICo). Evalu-
    ating this model on toxicity detection capability,
    rewrite detoxification, meaning preservation,
    and overall toxicity reduction, we discover sig-
     nificant improvements over the baseline model.
    In our experiments we show that overall toxi-
    city of this model is more than 60% reduced,
    with over 75% reduction in severe toxicity.

1  Introduction

Large Language Models (LLMs) are trained with the
explicit purpose of serving humans, between providing
information, presenting an engaging chat partner, and
answering any number of other user requests. Unfor-
tunately, for a variety of reasons, there is a tendency
for models to descend into neural toxic degeneration,
outputting toxic and otherwise harmful messages (Faal
et al., 2022; Xu et al., 2022; Wang et al., 2023). Nat-
urally, toxic prompts very commonly yield toxic re-
sponses, but many prompts which are entirely non-toxic
also yield toxic responses (Gehman et al., 2020; Guru-
rangan et al., 2022; Hartvigsen et al., 2022). Currently,
there are three main directions being used to combat
toxicity, each with a considerable drawback.

   ∗This work was done when Roy Siegelmann was an
intern at Amazon. Correspondence to rsiege15@jhu.edu and
mninareh@amazon.com.   First, the model may classify prompts as either toxic
or non-toxic, and categorically refuse to respond to those
deemed toxic (Xu et al., 2021). However, these ap-
proaches oftentimes use templated sentences to refuse
to respond to toxic content which can degrade user en-
gagement and lower helpfulness of the model (Xu et al.,
2021).  It is also possible for even entirely non-toxic
prompts to yield toxic generations, and thus this method
falls short of truly detoxifying.
  Second, the model can be trained solely on non-toxic
data (Welbl et al., 2021a; Gururangan et al., 2020). How-
ever, toxic content can be produced even from training
data which appears benign. Entirely purifying any word
which may lead to toxicity will leave the training corpus
narrow, impacting the richness of content which can
be generated. Furthermore, the model would not know
how to respond to prompts which include some toxicity;
thus, generations based around these prompts will be
nonsensical, slashing the model’s utility.
  Third, an external classifier or a secondary model
(e.g., in decoding time approaches) can be used to detect
whether the model generated toxic content, and if so stop
the content from reaching the user, instructing the model
to provide another generation instead (Mehrabi et al.,
2022; Liu et al., 2021; Krause et al., 2021; Dathathri
et al., 2019). However, without an understanding of tox-
icity, the model is likely to continuously generate toxic
content, yielding potentially unbounded latency times.
This would prove an impediment to the successful and
user-friendly utilization of the slower text-based output
and become unmanageable for models utilizing rapid
speech-based communication.
  Learning from these drawbacks, we formulate the fol-
lowing three requirements of a successful solution: (i)
Assuring non-toxic responses to non-toxic prompts. (ii)
Responding to toxic prompts in a natural, yet non-toxic
manner. (iii) Minimizing toxicity in real-time to prevent
latency. Despite the fact that AI has not yet provided
a satisfactory solution, humans exhibit these traits due
to their inherent ability of self reflection and inhibition
control. Healthy, mature humans consider the conse-
quences of their speech (and more generally, behavior)
via self-reflection before engaging in dialogue, and if
determined to be negative, will alter the output to con-
tain similar meaning yet eliminate the negative outcome.
This necessitates a true understanding of what is deemed1696",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: NAACL 2024, Mexico City, Mexico, June 16-21, 2024  ",,detox,
2848,"**Title**SampDetox: Black-box Backdoor Defense via Perturbation-based Sample Detoxification

**Abstract**Abstract:Backdoor attacks inject poisoned samples into the training data, resulting in the misclassification of the poisoned input during a model's deployment. Defending against such attacks is challenging, especially for real-world black-box models where only query access is permitted. In this paper, we propose a novel defense framework against backdoor attacks through Zero-shot Image Purification (ZIP). Our framework can be applied to poisoned models without requiring internal information about the model or any prior knowledge of the clean/poisoned samples. Our defense framework involves two steps. First, we apply a linear transformation (e.g., blurring) on the poisoned image to destroy the backdoor pattern. Then, we use a pre-trained diffusion model to recover the missing semantic information removed by the transformation. In particular, we design a new reverse process by using the transformed image to guide the generation of high-fidelity purified images, which works in zero-shot settings. We evaluate our ZIP framework on multiple datasets with different types of attacks. Experimental results demonstrate the superiority of our ZIP framework compared to state-of-the-art backdoor defense baselines. We believe that our results will provide valuable insights for future defense methods for black-box models. Our code is available at this https URL.","Yang Y,Jia C,Yan D,Hu M,Li T,Xie X,Wei X,Chen M",,,SampDetox: Black-box Backdoor Defense via Perturbation-based Sample Detoxification,,, , Conference Paper,,"Abstract:Backdoor attacks inject poisoned samples into the training data, resulting in the misclassification of the poisoned input during a model's deployment. Defending against such attacks is challenging, especially for real-world black-box models where only query access is permitted. In this paper, we propose a novel defense framework against backdoor attacks through Zero-shot Image Purification (ZIP). Our framework can be applied to poisoned models without requiring internal information about the model or any prior knowledge of the clean/poisoned samples. Our defense framework involves two steps. First, we apply a linear transformation (e.g., blurring) on the poisoned image to destroy the backdoor pattern. Then, we use a pre-trained diffusion model to recover the missing semantic information removed by the transformation. In particular, we design a new reverse process by using the transformed image to guide the generation of high-fidelity purified images, which works in zero-shot settings. We evaluate our ZIP framework on multiple datasets with different types of attacks. Experimental results demonstrate the superiority of our ZIP framework compared to state-of-the-art backdoor defense baselines. We believe that our results will provide valuable insights for future defense methods for black-box models. Our code is available at this https URL.",,,,, ,"Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024  ",,detection#methodology,
2849,"**Title**Parameter-Efficient Detoxification with Contrastive Decoding

**Abstract**AbstractThe field of natural language generation has witnessed significant advancements in recent years, including the development of controllable text generation techniques. However, controlling the attributes of the generated text remains a challenge, especially when aiming to avoid undesirable behavior such as toxicity. In this work, we introduce Detoxification Generator (DETOXIGEN), an inference-time algorithm that steers the generation away from unwanted styles. DETOXIGEN is an ensemble of a pre-trained language model (generator) and a detoxifier. The detoxifier is trained intentionally on the toxic data representative of the undesirable attribute, encouraging it to generate text in that style exclusively. During the actual generation, we use the trained detoxifier to produce undesirable tokens for the generator to contrast against at each decoding step. This approach directly informs the generator to avoid generating tokens that the detoxifier considers highly likely. We evaluate DETOXIGEN on the commonly used REALTOXICITYPROMPTS benchmark (Gehman et al., 2020) with various language models as generators. We find that it significantly outperforms previous approaches in detoxification metrics while not compromising on the generation quality. Moreover, the detoxifier is obtained by soft prompt-tuning using the same backbone language model as the generator. Hence, DETOXIGEN requires only a tiny amount of extra weights from the virtual tokens of the detoxifier to be loaded into GPU memory while decoding, making it a promising lightweight, practical, and parameter-efficient detoxification strategy.","Niu T,Xiong C,Yavuz S,Zhou Y",,,Parameter-Efficient Detoxification with Contrastive Decoding,abs/2401.06947,,10.48550/ARXIV.2401.06947 , Journal Article,,"AbstractThe field of natural language generation has witnessed significant advancements in recent years, including the development of controllable text generation techniques. However, controlling the attributes of the generated text remains a challenge, especially when aiming to avoid undesirable behavior such as toxicity. In this work, we introduce Detoxification Generator (DETOXIGEN), an inference-time algorithm that steers the generation away from unwanted styles. DETOXIGEN is an ensemble of a pre-trained language model (generator) and a detoxifier. The detoxifier is trained intentionally on the toxic data representative of the undesirable attribute, encouraging it to generate text in that style exclusively. During the actual generation, we use the trained detoxifier to produce undesirable tokens for the generator to contrast against at each decoding step. This approach directly informs the generator to avoid generating tokens that the detoxifier considers highly likely. We evaluate DETOXIGEN on the commonly used REALTOXICITYPROMPTS benchmark (Gehman et al., 2020) with various language models as generators. We find that it significantly outperforms previous approaches in detoxification metrics while not compromising on the generation quality. Moreover, the detoxifier is obtained by soft prompt-tuning using the same backbone language model as the generator. Hence, DETOXIGEN requires only a tiny amount of extra weights from the virtual tokens of the detoxifier to be loaded into GPU memory while decoding, making it a promising lightweight, practical, and parameter-efficient detoxification strategy.",,,,, CoRR,  ,,detox,
2850,"**Title**Text Detoxification as Style Transfer in English and Hindi

**Abstract**This paper focuses on text detoxification, i.e.,
    automatically converting toxic text into non-
    toxic text. This task contributes to safer and
   more respectful online communication and can
    be considered a Text Style Transfer (TST)
     task, where the text’s style changes while its
    content is preserved.  We present three ap-
    proaches: (i) knowledge transfer from a similar
    task (ii) multi-task learning approach, combin-
    ing sequence-to-sequence modeling with vari-
    ous toxicity classification tasks, and (iii) delete
    and reconstruct approach. To support our re-
    search, we utilize a dataset provided by De-
    mentieva et al. (2021), which contains multi-
    ple versions of detoxified texts corresponding
    to toxic texts. In our experiments, we selected
    the best variants through expert human anno-
     tators, creating a dataset where each toxic sen-
    tence is paired with a single, appropriate detox-
     ified version.  Additionally, we introduced a
    small Hindi parallel dataset, aligning with a
    part of the English dataset, suitable for evalu-
    ation purposes. Our results demonstrate that
    our approach effectively balances text detoxifi-
    cation while preserving the actual content and
    maintaining fluency.

    Content warning: This paper contains exam-
    ples that are toxic, offensive and/or sexist in na-
     ture.

1  Introduction

Text detoxification is a process that involves the au-
tomatic conversion of toxic text into non-toxic or
detoxified text (Dale et al., 2021). Text detoxifica-
tion can be viewed as a subtask within the broader
context of Text Style Transfer (TST) (Dale et al.,
2021). TST aims to alter the style of text while pre-
serving its core content. In the case of text detoxi-
fication, the source style is toxic language, and the
target style is non-toxic, with the primary objec-
tive being the transformation of text from a harmful
and offensive nature to a neutral or positive one, allwhile retaining the rest of the original text’s mean-
ing.
  Existing detoxification methods often rely on
rule-based removal of toxic words or phrases (De-
mentieva et al., 2022), but this approach is not
very eﬀicient and can make sentences sound unnat-
ural.  It also does not consider whether the mean-
ing of the sentence is affected by these removals.
Additionally, because we have limited resources
in terms of datasets (Dementieva et al., 2021) for
transforming toxic text to non-toxic text, simple
sequence-to-sequence training may not be enough
for better results (Mukherjee and Dusek, 2023).
  To improve this, we propose three approaches:
(i) knowledge transfer from a similar task  (ii)
multi-task learning approach, utilizing sequence-
to-sequence modeling coupled with various toxic
and civil text classification tasks, and (iii) delete
and reconstruct approach.  These approaches en-
hance the sequence-to-sequence transformation
and lead to better outcomes compared to basic
sequence-to-sequence training.
  To conduct our research and experiments, we
leverage a dataset provided by Dementieva et al.
(2021). This dataset contains various versions of
text that have undergone detoxification, offering
valuable resources for our investigations. We have
taken a meticulous approach to ensure dataset qual-
ity. This includes soliciting the expertise of human
annotators to select the most suitable detoxified
versions for each toxic text, resulting in a carefully
curated dataset where each source toxic sentence
is paired with its corresponding non-toxic text.
  Furthermore, to contribute to the development
of multilingual parallel datasets for text detoxifi-
cation, we present a novel dataset containing 500
parallel toxic and non-toxic sentences in Hindi,
aligned with their English counterparts (see Sec-
tion 3). Hindi is one of the 22 scheduled and oﬀi-
cial Indian languages and the largest speech com-
munity in India (Jha, 2010). This dataset serves as","Mukherjee S,Bansal A,Ojha AK,McCrae JP,Dusek O",,,Text Detoxification as Style Transfer in English and Hindi,abs/2402.07767,,10.48550/ARXIV.2402.07767 , Journal Article,,"This paper focuses on text detoxification, i.e.,
    automatically converting toxic text into non-
    toxic text. This task contributes to safer and
   more respectful online communication and can
    be considered a Text Style Transfer (TST)
     task, where the text’s style changes while its
    content is preserved.  We present three ap-
    proaches: (i) knowledge transfer from a similar
    task (ii) multi-task learning approach, combin-
    ing sequence-to-sequence modeling with vari-
    ous toxicity classification tasks, and (iii) delete
    and reconstruct approach. To support our re-
    search, we utilize a dataset provided by De-
    mentieva et al. (2021), which contains multi-
    ple versions of detoxified texts corresponding
    to toxic texts. In our experiments, we selected
    the best variants through expert human anno-
     tators, creating a dataset where each toxic sen-
    tence is paired with a single, appropriate detox-
     ified version.  Additionally, we introduced a
    small Hindi parallel dataset, aligning with a
    part of the English dataset, suitable for evalu-
    ation purposes. Our results demonstrate that
    our approach effectively balances text detoxifi-
    cation while preserving the actual content and
    maintaining fluency.

    Content warning: This paper contains exam-
    ples that are toxic, offensive and/or sexist in na-
     ture.

1  Introduction

Text detoxification is a process that involves the au-
tomatic conversion of toxic text into non-toxic or
detoxified text (Dale et al., 2021). Text detoxifica-
tion can be viewed as a subtask within the broader
context of Text Style Transfer (TST) (Dale et al.,
2021). TST aims to alter the style of text while pre-
serving its core content. In the case of text detoxi-
fication, the source style is toxic language, and the
target style is non-toxic, with the primary objec-
tive being the transformation of text from a harmful
and offensive nature to a neutral or positive one, allwhile retaining the rest of the original text’s mean-
ing.
  Existing detoxification methods often rely on
rule-based removal of toxic words or phrases (De-
mentieva et al., 2022), but this approach is not
very eﬀicient and can make sentences sound unnat-
ural.  It also does not consider whether the mean-
ing of the sentence is affected by these removals.
Additionally, because we have limited resources
in terms of datasets (Dementieva et al., 2021) for
transforming toxic text to non-toxic text, simple
sequence-to-sequence training may not be enough
for better results (Mukherjee and Dusek, 2023).
  To improve this, we propose three approaches:
(i) knowledge transfer from a similar task  (ii)
multi-task learning approach, utilizing sequence-
to-sequence modeling coupled with various toxic
and civil text classification tasks, and (iii) delete
and reconstruct approach.  These approaches en-
hance the sequence-to-sequence transformation
and lead to better outcomes compared to basic
sequence-to-sequence training.
  To conduct our research and experiments, we
leverage a dataset provided by Dementieva et al.
(2021). This dataset contains various versions of
text that have undergone detoxification, offering
valuable resources for our investigations. We have
taken a meticulous approach to ensure dataset qual-
ity. This includes soliciting the expertise of human
annotators to select the most suitable detoxified
versions for each toxic text, resulting in a carefully
curated dataset where each source toxic sentence
is paired with its corresponding non-toxic text.
  Furthermore, to contribute to the development
of multilingual parallel datasets for text detoxifi-
cation, we present a novel dataset containing 500
parallel toxic and non-toxic sentences in Hindi,
aligned with their English counterparts (see Sec-
tion 3). Hindi is one of the 22 scheduled and oﬀi-
cial Indian languages and the largest speech com-
munity in India (Jha, 2010). This dataset serves as",,,,, CoRR,  ,,out_but_toxicity,
2851,"**Title**Fine-Grained Detoxification via Instance-Level Prefixes for Large Language Models

**Abstract**Abstract:Impressive results have been achieved in natural language processing (NLP) tasks through the training of large language models (LLMs). However, these models occasionally produce toxic content such as insults, threats, and profanity in response to certain prompts, thereby constraining their practical utility. To tackle this issue, various finetuning-based and decoding-based approaches have been utilized to mitigate toxicity. However, these methods typically necessitate additional costs such as high-quality training data or auxiliary models. In this paper, we propose fine-grained detoxification via instance-level prefixes (FGDILP) to mitigate toxic text without additional cost. Specifically, FGDILP contrasts the contextualized representation in attention space using a positive prefix-prepended prompt against multiple negative prefix-prepended prompts at the instance level. This allows for constructing fine-grained subtoxicity vectors, which enables collaborative detoxification by fusing them to correct the normal generation process when provided with a raw prompt. We validate that FGDILP enables controlled text generation with regard to toxicity at both the utterance and context levels. Our method surpasses prompt-based baselines in detoxification, although at a slight cost to generation fluency and diversity.","Yi X,Wang L,Wang X,He L",,,Fine-Grained Detoxification via Instance-Level Prefixes for Large Language Models,abs/2402.15202,,10.48550/ARXIV.2402.15202 , Journal Article,,"Abstract:Impressive results have been achieved in natural language processing (NLP) tasks through the training of large language models (LLMs). However, these models occasionally produce toxic content such as insults, threats, and profanity in response to certain prompts, thereby constraining their practical utility. To tackle this issue, various finetuning-based and decoding-based approaches have been utilized to mitigate toxicity. However, these methods typically necessitate additional costs such as high-quality training data or auxiliary models. In this paper, we propose fine-grained detoxification via instance-level prefixes (FGDILP) to mitigate toxic text without additional cost. Specifically, FGDILP contrasts the contextualized representation in attention space using a positive prefix-prepended prompt against multiple negative prefix-prepended prompts at the instance level. This allows for constructing fine-grained subtoxicity vectors, which enables collaborative detoxification by fusing them to correct the normal generation process when provided with a raw prompt. We validate that FGDILP enables controlled text generation with regard to toxicity at both the utterance and context levels. Our method surpasses prompt-based baselines in detoxification, although at a slight cost to generation fluency and diversity.",,,,, CoRR,  ,,detox,
2852,"**Title**GreenLLaMA: A Framework for Detoxification with Explanations

**Abstract**AbstractPrior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose DetoxLLM, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated parallel corpus. We further introduce explanation to promote transparency and trustworthiness. DetoxLLM additionally offers a unique paraphrase detector especially dedicated for the detoxification task to tackle the non-detoxifiable cases. Through experimental analysis, we demonstrate the effectiveness of our cross-platform corpus and the robustness of DetoxLLM against adversarial toxicity.","Khondaker MT,Abdul-Mageed M,Lakshmanan LV",,,GreenLLaMA: A Framework for Detoxification with Explanations,abs/2402.15951,,10.48550/ARXIV.2402.15951 , Journal Article,,"AbstractPrior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose DetoxLLM, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated parallel corpus. We further introduce explanation to promote transparency and trustworthiness. DetoxLLM additionally offers a unique paraphrase detector especially dedicated for the detoxification task to tackle the non-detoxifiable cases. Through experimental analysis, we demonstrate the effectiveness of our cross-platform corpus and the robustness of DetoxLLM against adversarial toxicity.",,,,, CoRR,  ,,detox,
2853,"**Title**GPT-DETOX: An In-Context Learning-Based Paraphraser for Text Detoxification

**Abstract**Abstract:Harmful and offensive communication or content is detrimental to social bonding and the mental state of users on social media platforms. Text detoxification is a crucial task in natural language processing (NLP), where the goal is removing profanity and toxicity from text while preserving its content. Supervised and unsupervised learning are common approaches for designing text detoxification solutions. However, these methods necessitate fine-tuning, leading to computational overhead. In this paper, we propose GPT-DETOX as a framework for prompt-based in-context learning for text detoxification using GPT-3.5 Turbo. We utilize zero-shot and few-shot prompting techniques for detoxifying input sentences. To generate few-shot prompts, we propose two methods: word-matching example selection (WMES) and context-matching example selection (CMES). We additionally take into account ensemble in-context learning (EICL) where the ensemble is shaped by base prompts from zero-shot and all few-shot settings. We use ParaDetox and APPDIA as benchmark detoxification datasets. Our experimental results show that the zero-shot solution achieves promising performance, while our best few-shot setting outperforms the state-of-the-art models on ParaDetox and shows comparable results on APPDIA. Our EICL solutions obtain the greatest performance, adding at least 10% improvement, against both datasets.","Pesaranghader A,Verma N,Bharadwaj M",,,GPT-DETOX: An In-Context Learning-Based Paraphraser for Text Detoxification,abs/2404.03052,,10.48550/ARXIV.2404.03052 , Journal Article,,"Abstract:Harmful and offensive communication or content is detrimental to social bonding and the mental state of users on social media platforms. Text detoxification is a crucial task in natural language processing (NLP), where the goal is removing profanity and toxicity from text while preserving its content. Supervised and unsupervised learning are common approaches for designing text detoxification solutions. However, these methods necessitate fine-tuning, leading to computational overhead. In this paper, we propose GPT-DETOX as a framework for prompt-based in-context learning for text detoxification using GPT-3.5 Turbo. We utilize zero-shot and few-shot prompting techniques for detoxifying input sentences. To generate few-shot prompts, we propose two methods: word-matching example selection (WMES) and context-matching example selection (CMES). We additionally take into account ensemble in-context learning (EICL) where the ensemble is shaped by base prompts from zero-shot and all few-shot settings. We use ParaDetox and APPDIA as benchmark detoxification datasets. Our experimental results show that the zero-shot solution achieves promising performance, while our best few-shot setting outperforms the state-of-the-art models on ParaDetox and shows comparable results on APPDIA. Our EICL solutions obtain the greatest performance, adding at least 10% improvement, against both datasets.",,,,, CoRR,  ,,detox,
2854,"**Title**DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion

**Abstract**Abstract:Despite the remarkable achievements of language models (LMs) across a broad spectrum of tasks, their propensity for generating toxic outputs remains a prevalent concern. Current solutions involving finetuning or auxiliary models usually require extensive computational resources, hindering their practicality in large language models (LLMs). In this paper, we propose DeStein, a novel method that detoxifies LMs by applying representation engineering in activation spaces with lower resource and time costs. Specifically, we derive detoxification vectors from self-induced, universal steering pairs through arithmetic operations in activation spaces. During inference, detoxification is achieved by fusing the detoxification vectors with the original representations in a head-wise manner. Empirical results demonstrate that our method significantly outperforms previous state-of-the-art approaches on various metrics, while also maintaining satisfactory generation quality and diversity. We further validate the practicality and scalability of DeStein with a series of white-box LLMs. The method is open-sourced at this https URL. Warning: Some example model outputs may contain highly offensive or disturbing text.","Li Y,Wei Z,Jiang H,Gong C",,,DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion,abs/2404.10464,,10.48550/ARXIV.2404.10464 , Journal Article,,"Abstract:Despite the remarkable achievements of language models (LMs) across a broad spectrum of tasks, their propensity for generating toxic outputs remains a prevalent concern. Current solutions involving finetuning or auxiliary models usually require extensive computational resources, hindering their practicality in large language models (LLMs). In this paper, we propose DeStein, a novel method that detoxifies LMs by applying representation engineering in activation spaces with lower resource and time costs. Specifically, we derive detoxification vectors from self-induced, universal steering pairs through arithmetic operations in activation spaces. During inference, detoxification is achieved by fusing the detoxification vectors with the original representations in a head-wise manner. Empirical results demonstrate that our method significantly outperforms previous state-of-the-art approaches on various metrics, while also maintaining satisfactory generation quality and diversity. We further validate the practicality and scalability of DeStein with a series of white-box LLMs. The method is open-sourced at this https URL. Warning: Some example model outputs may contain highly offensive or disturbing text.",,,,, CoRR,  ,,detox,
2855,"**Title**Demarked: A Strategy for Enhanced Abusive Speech Moderation through Counterspeech, Detoxification, and Message Management

**Abstract**Abstract:Despite regulations imposed by nations and social media platforms, such as recent EU regulations targeting digital violence, abusive content persists as a significant challenge. Existing approaches primarily rely on binary solutions, such as outright blocking or banning, yet fail to address the complex nature of abusive speech. In this work, we propose a more comprehensive approach called Demarcation scoring abusive speech based on four aspect -- (i) severity scale; (ii) presence of a target; (iii) context scale; (iv) legal scale -- and suggesting more options of actions like detoxification, counter speech generation, blocking, or, as a final measure, human intervention. Through a thorough analysis of abusive speech regulations across diverse jurisdictions, platforms, and research papers we highlight the gap in preventing measures and advocate for tailored proactive steps to combat its multifaceted manifestations. Our work aims to inform future strategies for effectively addressing abusive speech online.","Yimam SM,Dementieva D,Fischer T,Moskovskiy D,Rizwan N,Saha P,Roy S,Semmann M,Panchenko A,Biemann C,Mukherjee A",,,"Demarked: A Strategy for Enhanced Abusive Speech Moderation through Counterspeech, Detoxification, and Message Management",abs/2406.19543,,10.48550/ARXIV.2406.19543 , Journal Article,,"Abstract:Despite regulations imposed by nations and social media platforms, such as recent EU regulations targeting digital violence, abusive content persists as a significant challenge. Existing approaches primarily rely on binary solutions, such as outright blocking or banning, yet fail to address the complex nature of abusive speech. In this work, we propose a more comprehensive approach called Demarcation scoring abusive speech based on four aspect -- (i) severity scale; (ii) presence of a target; (iii) context scale; (iv) legal scale -- and suggesting more options of actions like detoxification, counter speech generation, blocking, or, as a final measure, human intervention. Through a thorough analysis of abusive speech regulations across diverse jurisdictions, platforms, and research papers we highlight the gap in preventing measures and advocate for tailored proactive steps to combat its multifaceted manifestations. Our work aims to inform future strategies for effectively addressing abusive speech online.",,,,, CoRR,  ,,detox,
2856,"**Title**Learning from Response not Preference: A Stackelberg Approach for LLM Detoxification using Non-parallel Data

**Abstract**Abstract:Text detoxification, a variant of style transfer tasks, finds useful applications in online social media. This work presents a fine-tuning method that only uses non-parallel data to turn large language models (LLM) into a detoxification rewritter. We model the fine-tuning process as a Stackelberg game between an LLM (leader) and a toxicity screener (follower), which is a binary style classifier (toxic or non-toxic). The LLM aims to align its preference according to the screener and generate paraphases passing the screening. The primary challenge of non-parallel data fine-tuning is incomplete preference. In the case of unsuccessful paraphrases, the classifier cannot establish a preference between the input and paraphrase, as they belong to the same toxic style. Hence, preference-alignment fine-tuning methods, such as direct preference optimization (DPO), no longer apply. To address the challenge of incomplete preference, we propose Stackelberg response optimization (SRO), adapted from DPO, to enable the LLM to learn from the follower's response. The gist is that SRO decreases the likelihood of generating the paraphrase if it fails the follower's screening while performing DPO on the pair of the toxic input and its paraphrase when the latter passes the screening. Experiments indicate that the SRO-fine-tunned LLM achieves satisfying performance comparable to state-of-the-art models regarding style accuracy, content similarity, and fluency. The overall detoxification performance surpasses other computing methods and matches the human reference. Additional empirical evidence suggests that SRO is sensitive to the screener's feedback, and a slight perturbation leads to a significant performance drop. We release the code and LLM models at \url{this https URL}.","Xie X,Li T,Zhu Q",,,Learning from Response not Preference: A Stackelberg Approach for LLM Detoxification using Non-parallel Data,abs/2410.20298,,10.48550/ARXIV.2410.20298 , Journal Article,,"Abstract:Text detoxification, a variant of style transfer tasks, finds useful applications in online social media. This work presents a fine-tuning method that only uses non-parallel data to turn large language models (LLM) into a detoxification rewritter. We model the fine-tuning process as a Stackelberg game between an LLM (leader) and a toxicity screener (follower), which is a binary style classifier (toxic or non-toxic). The LLM aims to align its preference according to the screener and generate paraphases passing the screening. The primary challenge of non-parallel data fine-tuning is incomplete preference. In the case of unsuccessful paraphrases, the classifier cannot establish a preference between the input and paraphrase, as they belong to the same toxic style. Hence, preference-alignment fine-tuning methods, such as direct preference optimization (DPO), no longer apply. To address the challenge of incomplete preference, we propose Stackelberg response optimization (SRO), adapted from DPO, to enable the LLM to learn from the follower's response. The gist is that SRO decreases the likelihood of generating the paraphrase if it fails the follower's screening while performing DPO on the pair of the toxic input and its paraphrase when the latter passes the screening. Experiments indicate that the SRO-fine-tunned LLM achieves satisfying performance comparable to state-of-the-art models regarding style accuracy, content similarity, and fluency. The overall detoxification performance surpasses other computing methods and matches the human reference. Additional empirical evidence suggests that SRO is sensitive to the screener's feedback, and a slight perturbation leads to a significant performance drop. We release the code and LLM models at \url{this https URL}.",,,,, CoRR,  ,,detox,
2857,"**Title**Backdoor Mitigation by Distance-Driven Detoxification

**Abstract**Abstract:Backdoor attacks undermine the integrity of machine learning models by allowing attackers to manipulate predictions using poisoned training data. Such attacks lead to targeted misclassification when specific triggers are present, while the model behaves normally under other conditions. This paper considers a post-training backdoor defense task, aiming to detoxify the backdoors in pre-trained models. We begin by analyzing the underlying issues of vanilla fine-tuning and observe that it is often trapped in regions with low loss for both clean and poisoned samples. Motivated by such observations, we propose Distance-Driven Detoxification (D3), an innovative approach that reformulates backdoor defense as a constrained optimization problem. Specifically, D3 promotes the model's departure from the vicinity of its initial weights, effectively reducing the influence of backdoors. Extensive experiments on state-of-the-art (SOTA) backdoor attacks across various model architectures and datasets demonstrate that D3 not only matches but often surpasses the performance of existing SOTA post-training defense techniques.","Wei S,Liu J,Zha H",,,Backdoor Mitigation by Distance-Driven Detoxification,abs/2411.09585,,10.48550/ARXIV.2411.09585 , Journal Article,,"Abstract:Backdoor attacks undermine the integrity of machine learning models by allowing attackers to manipulate predictions using poisoned training data. Such attacks lead to targeted misclassification when specific triggers are present, while the model behaves normally under other conditions. This paper considers a post-training backdoor defense task, aiming to detoxify the backdoors in pre-trained models. We begin by analyzing the underlying issues of vanilla fine-tuning and observe that it is often trapped in regions with low loss for both clean and poisoned samples. Motivated by such observations, we propose Distance-Driven Detoxification (D3), an innovative approach that reformulates backdoor defense as a constrained optimization problem. Specifically, D3 promotes the model's departure from the vicinity of its initial weights, effectively reducing the influence of backdoors. Extensive experiments on state-of-the-art (SOTA) backdoor attacks across various model architectures and datasets demonstrate that D3 not only matches but often surpasses the performance of existing SOTA post-training defense techniques.",,,,, CoRR,  ,,detox#methodology,
2858,"**Title**Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation

**Abstract**Abstract:Recent generative large language models (LLMs) show remarkable performance in non-English languages, but when prompted in those languages they tend to express higher harmful social biases and toxicity levels. Prior work has shown that finetuning on specialized datasets can mitigate this behavior, and doing so in English can transfer to other languages. In this work, we investigate the impact of different finetuning methods on the model's bias and toxicity, but also on its ability to produce fluent and diverse text. We reduce biases by finetuning on curated non-harmful text, but find only direct preference optimization to be effective for mitigating toxicity. The mitigation caused by applying these methods in English also transfers to non-English languages. We find evidence that the extent to which transfer takes place can be predicted by the amount of data in a given language present in the model's pretraining data. However, this transfer of bias and toxicity mitigation often comes at the expense of decreased language generation ability in non-English languages, highlighting the importance of developing language-specific bias and toxicity mitigation methods.","Neplenbroek V,Bisazza A,Fernández R",,,Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation,abs/2412.14050,,10.48550/ARXIV.2412.14050 , Journal Article,,"Abstract:Recent generative large language models (LLMs) show remarkable performance in non-English languages, but when prompted in those languages they tend to express higher harmful social biases and toxicity levels. Prior work has shown that finetuning on specialized datasets can mitigate this behavior, and doing so in English can transfer to other languages. In this work, we investigate the impact of different finetuning methods on the model's bias and toxicity, but also on its ability to produce fluent and diverse text. We reduce biases by finetuning on curated non-harmful text, but find only direct preference optimization to be effective for mitigating toxicity. The mitigation caused by applying these methods in English also transfers to non-English languages. We find evidence that the extent to which transfer takes place can be predicted by the amount of data in a given language present in the model's pretraining data. However, this transfer of bias and toxicity mitigation often comes at the expense of decreased language generation ability in non-English languages, highlighting the importance of developing language-specific bias and toxicity mitigation methods.",,,,, CoRR,  ,,detox,
2859,No abstract available,"Zhang Z,Tian M,Li C,Huang Y,Yang L",,,Poison Neural Network-Based mmWave Beam Selection and Detoxification With Machine Unlearning,71,2,10.1109/TCOMM.2022.3232794 , Journal Article,,,,,,, IEEE Trans. Commun.,  ,,out_of_scope,
2860,"**Title**DiffuDetox: A Mixed Diffusion Model for Text Detoxification

**Abstract**Text detoxification is a conditional text gen-
    eration task aiming to remove offensive con-
     tent from toxic text. It is highly useful for on-
     line forums and social media, where offensive
    content is frequently encountered. Intuitively,
    there are diverse ways to detoxify sentences
    while preserving their meanings, and we can
     select from detoxified sentences before display-
    ing text to users. Conditional diffusion mod-
     els are particularly suitable for this task given
     their demonstrated higher generative diversity
    than existing conditional text generation mod-
     els based on language models. Nonetheless,
     text fluency declines when they are trained with
     insufficient data, which is the case for this task.
    In this work, we propose DiffuDetox1, a mixed
    conditional and unconditional diffusion model
    for text detoxification. The conditional model
    takes toxic text as the condition and reduces
      its toxicity, yielding a diverse set of detoxified
    sentences. The unconditional model is trained
     to recover the input text, which allows the intro-
    duction of additional fluent text for training and
    thus ensures text fluency. Extensive experimen-
     tal results and in-depth analysis demonstrate
    the effectiveness of our proposed DiffuDetox.

1  Introduction

Toxic texts with offensive and abusive words are
frequently encountered in online forums and social
media. Such a harmful online environment can
lead to mental health problems (Viner et al., 2019;
Wijesiriwardene et al., 2020), which motivates con-
siderable research efforts (dos Santos et al., 2018;
Laugier et al., 2021; Logacheva et al., 2022) in
text detoxification, i.e., a conditional text genera-
tion task aiming to remove offensive content from
sentences while preserving their meanings.
   Intuitively, there exist diverse ways to detoxify a
given sentence. As shown in Table 1, some detoxi-
fied sentences are the results of simply removing

   1https://github.com/D3Mlab/diffu-detox            The country doesn’t really have to giveDetoxified 1
                     [· · · ] about international laws.i            The country doesn’t really have care                   [    ]
            The country doesn’t really have careDetoxified 2              about international laws.             The country doesn’t really need to careDetoxified 3              about international laws.              The country doesn’t need to care about  Human                   international laws.

Table 1: A diverse collection of detoxified sentences
helps to approach human-level text detoxification.


or replacing the toxic word, e.g., Detoxified 1 and
2, which may cause loss of information or lower
text fluency. While other candidates, e.g., Detox-
ified 3, can reach human-level text detoxification
performance with satisfactory fluency and content
preservation. Therefore, if a diverse collection of
detoxified sentences are given, we can select the
most fluent and preservative one to maximize user
experience. To do so, we resort to textual con-
ditional diffusion models (Li et al., 2022; Gong
et al., 2022) because they are shown to be capable
of generating more diverse sets of candidates com-
pared to existing solutions based on transformers
(Vaswani et al., 2017), e.g., GPT2 (Radford et al.,
2019). Given their demonstrated high generative
diversity, diffusion models are particularly suitable
for this task.
   Nevertheless, previous textual conditional diffu-
sion models (Li et al., 2022; Gong et al., 2022) are
not directly applicable to text detoxification due
to the scarcity of text detoxification data. Given
that text detoxification is a relatively new field and
the high cost of human annotations, the available
text detoxification data is on the order of 1e−1 to
1e−2 of datasets used for other tasks with textual
conditional diffusion models (Gong et al., 2022).
  To this end, we introduce DiffuDetox, a mixed
conditional and unconditional diffusion model for
text detoxification. In particular, the conditional7566","Floto G,Pour MM,Farinneya P,Tang Z,Pesaranghader A,Bharadwaj M,Sanner S",,,DiffuDetox: A Mixed Diffusion Model for Text Detoxification,,,10.18653/V1/2023.FINDINGS-ACL.478 , Conference Paper,,"Text detoxification is a conditional text gen-
    eration task aiming to remove offensive con-
     tent from toxic text. It is highly useful for on-
     line forums and social media, where offensive
    content is frequently encountered. Intuitively,
    there are diverse ways to detoxify sentences
    while preserving their meanings, and we can
     select from detoxified sentences before display-
    ing text to users. Conditional diffusion mod-
     els are particularly suitable for this task given
     their demonstrated higher generative diversity
    than existing conditional text generation mod-
     els based on language models. Nonetheless,
     text fluency declines when they are trained with
     insufficient data, which is the case for this task.
    In this work, we propose DiffuDetox1, a mixed
    conditional and unconditional diffusion model
    for text detoxification. The conditional model
    takes toxic text as the condition and reduces
      its toxicity, yielding a diverse set of detoxified
    sentences. The unconditional model is trained
     to recover the input text, which allows the intro-
    duction of additional fluent text for training and
    thus ensures text fluency. Extensive experimen-
     tal results and in-depth analysis demonstrate
    the effectiveness of our proposed DiffuDetox.

1  Introduction

Toxic texts with offensive and abusive words are
frequently encountered in online forums and social
media. Such a harmful online environment can
lead to mental health problems (Viner et al., 2019;
Wijesiriwardene et al., 2020), which motivates con-
siderable research efforts (dos Santos et al., 2018;
Laugier et al., 2021; Logacheva et al., 2022) in
text detoxification, i.e., a conditional text genera-
tion task aiming to remove offensive content from
sentences while preserving their meanings.
   Intuitively, there exist diverse ways to detoxify a
given sentence. As shown in Table 1, some detoxi-
fied sentences are the results of simply removing

   1https://github.com/D3Mlab/diffu-detox            The country doesn’t really have to giveDetoxified 1
                     [· · · ] about international laws.i            The country doesn’t really have care                   [    ]
            The country doesn’t really have careDetoxified 2              about international laws.             The country doesn’t really need to careDetoxified 3              about international laws.              The country doesn’t need to care about  Human                   international laws.

Table 1: A diverse collection of detoxified sentences
helps to approach human-level text detoxification.


or replacing the toxic word, e.g., Detoxified 1 and
2, which may cause loss of information or lower
text fluency. While other candidates, e.g., Detox-
ified 3, can reach human-level text detoxification
performance with satisfactory fluency and content
preservation. Therefore, if a diverse collection of
detoxified sentences are given, we can select the
most fluent and preservative one to maximize user
experience. To do so, we resort to textual con-
ditional diffusion models (Li et al., 2022; Gong
et al., 2022) because they are shown to be capable
of generating more diverse sets of candidates com-
pared to existing solutions based on transformers
(Vaswani et al., 2017), e.g., GPT2 (Radford et al.,
2019). Given their demonstrated high generative
diversity, diffusion models are particularly suitable
for this task.
   Nevertheless, previous textual conditional diffu-
sion models (Li et al., 2022; Gong et al., 2022) are
not directly applicable to text detoxification due
to the scarcity of text detoxification data. Given
that text detoxification is a relatively new field and
the high cost of human annotations, the available
text detoxification data is on the order of 1e−1 to
1e−2 of datasets used for other tasks with textual
conditional diffusion models (Gong et al., 2022).
  To this end, we introduce DiffuDetox, a mixed
conditional and unconditional diffusion model for
text detoxification. In particular, the conditional7566",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023  ",,detox,
2861,"**Title**COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification

**Abstract**Offensive and toxic text on social media plat-
    forms can lead to polarization and divisive-
    ness within online communities and hinders
    constructive dialogue. Text detoxification is
    a crucial task in natural language processing
    to ensure the generation of non-toxic and safe
     text. Text detoxification is a special case of
    the Text Style Transfer (TST) problem, where
    an input text is rephrased to an output text
     that preserves its content while modifying the
     style (in this case to a more neutral, non-toxic
     style). State-of-the-art methods for detoxifica-
     tion use supervised training of encoder-decoder
    models to produce gold-standard outputs with
    a standard likelihood-based objective. How-
     ever, it can be hard for these models to devi-
    ate from their pretrained auto-encoder identity
    mapping. While previous methods have used
    unlikelihood-based losses to penalize input-to-
    output copying of toxic content, these methods
    also unfortunately penalize non-toxic content
    in the input that would be fine to preserve in
    the output. To address these issues, we intro-
    duce a novel contrastive unlikelihood objec-
     tive (COUNT1) that directly contrasts the gold
    standard rephrasing with the identity input-to-
    output mapping to effectively isolate and focus
    learning on non-toxic style transfer. We bench-
   mark COUNT on two parallel datasets, Pa-
    raDetox and APPDIA, showing that it achieves
     significant improvements in jointly combined
    fluency, content preservation, and detoxifica-
    tion (i.e., the highest “J” score).
1  Introduction
Disclaimer. Please be aware that as you read this
paper, you may come across texts that could be
considered toxic due to the nature of this research.
  Exposure to offensive and toxic text on online
platforms can have detrimental consequences, caus-
ing emotional distress and negative psychologi-
cal effects on users (González-Bailón and Lelkes,
   1https://github.com/D3Mlab/
count-style-transfer2023). Such experiences can deter individuals from
actively engaging in online communities and social
media. Therefore, text detoxification solutions are
indispensable for mitigating harmful content on
online platforms.
  Text detoxification is a text-style transfer task
where the goal is to change the style of an input text
from toxic to safe while the content is preserved.
Most state-of-the-art text detoxification methods
use supervised training of encoder-decoder models
(Logacheva et al., 2022). The objective of those
methods relies on maximizing the likelihood of gen-
erating gold-standard non-toxic outputs, but fails to
penalize generation of the toxic inputs. To address
this issue, Welleck et al. (2019) proposed an “un-
likelihood” training methodology that can be used
to penalize generation of toxic inputs while encour-
aging generation of gold standard non-toxic output.
While this improves on the simple likelihood objec-
tive, we observe experimentally that it often fails to
overcome the strong inertia of the pretrained model
to produce the identity input-to-output mapping
that preserves toxic text. One key reason for this is
that unlikelihood cannot be weighted too heavily
can penalize both the toxic and non-toxic content
in the input. To address this issue, we introduce
a novel Contrastive Unlikelihood Text style trans-
fer (COUNT) objective that directly contrasts the
likelihood of the gold standard rephrasing with the
likelihood of the identity input-to-output mapping
to effectively isolate and focus learning on style
transfer for text detoxification.
  Our contributions are twofold: (1) We propose
the COUNT loss function as a novel training ob-
jective for text detoxification. (2) We show that
by using the COUNT loss, our method delivers
significant improvements on a joint measure (“J”
score) of fluency, content preservation, and detoxi-
fication on two publicly available parallel datasets,
ParaDetox and APPDIA, for the text detoxification
task.8658","Pour MM,Farinneya P,Bharadwaj M,Verma N,Pesaranghader A,Sanner S",,,COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification,,,10.18653/V1/2023.FINDINGS-EMNLP.579 , Conference Paper,,"Offensive and toxic text on social media plat-
    forms can lead to polarization and divisive-
    ness within online communities and hinders
    constructive dialogue. Text detoxification is
    a crucial task in natural language processing
    to ensure the generation of non-toxic and safe
     text. Text detoxification is a special case of
    the Text Style Transfer (TST) problem, where
    an input text is rephrased to an output text
     that preserves its content while modifying the
     style (in this case to a more neutral, non-toxic
     style). State-of-the-art methods for detoxifica-
     tion use supervised training of encoder-decoder
    models to produce gold-standard outputs with
    a standard likelihood-based objective. How-
     ever, it can be hard for these models to devi-
    ate from their pretrained auto-encoder identity
    mapping. While previous methods have used
    unlikelihood-based losses to penalize input-to-
    output copying of toxic content, these methods
    also unfortunately penalize non-toxic content
    in the input that would be fine to preserve in
    the output. To address these issues, we intro-
    duce a novel contrastive unlikelihood objec-
     tive (COUNT1) that directly contrasts the gold
    standard rephrasing with the identity input-to-
    output mapping to effectively isolate and focus
    learning on non-toxic style transfer. We bench-
   mark COUNT on two parallel datasets, Pa-
    raDetox and APPDIA, showing that it achieves
     significant improvements in jointly combined
    fluency, content preservation, and detoxifica-
    tion (i.e., the highest “J” score).
1  Introduction
Disclaimer. Please be aware that as you read this
paper, you may come across texts that could be
considered toxic due to the nature of this research.
  Exposure to offensive and toxic text on online
platforms can have detrimental consequences, caus-
ing emotional distress and negative psychologi-
cal effects on users (González-Bailón and Lelkes,
   1https://github.com/D3Mlab/
count-style-transfer2023). Such experiences can deter individuals from
actively engaging in online communities and social
media. Therefore, text detoxification solutions are
indispensable for mitigating harmful content on
online platforms.
  Text detoxification is a text-style transfer task
where the goal is to change the style of an input text
from toxic to safe while the content is preserved.
Most state-of-the-art text detoxification methods
use supervised training of encoder-decoder models
(Logacheva et al., 2022). The objective of those
methods relies on maximizing the likelihood of gen-
erating gold-standard non-toxic outputs, but fails to
penalize generation of the toxic inputs. To address
this issue, Welleck et al. (2019) proposed an “un-
likelihood” training methodology that can be used
to penalize generation of toxic inputs while encour-
aging generation of gold standard non-toxic output.
While this improves on the simple likelihood objec-
tive, we observe experimentally that it often fails to
overcome the strong inertia of the pretrained model
to produce the identity input-to-output mapping
that preserves toxic text. One key reason for this is
that unlikelihood cannot be weighted too heavily
can penalize both the toxic and non-toxic content
in the input. To address this issue, we introduce
a novel Contrastive Unlikelihood Text style trans-
fer (COUNT) objective that directly contrasts the
likelihood of the gold standard rephrasing with the
likelihood of the identity input-to-output mapping
to effectively isolate and focus learning on style
transfer for text detoxification.
  Our contributions are twofold: (1) We propose
the COUNT loss function as a novel training ob-
jective for text detoxification. (2) We show that
by using the COUNT loss, our method delivers
significant improvements on a joint measure (“J”
score) of fluency, content preservation, and detoxi-
fication on two publicly available parallel datasets,
ParaDetox and APPDIA, for the text detoxification
task.8658",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023  ",,detox,
2862,"**Title**Exploring Methods for Cross-lingual Text Style Transfer: The Case of Text Detoxification

**Abstract**Text detoxification is the task of transferring
    the style of text from toxic to neutral. While
    there are approaches yielding promising re-
     sults in monolingual setup, e.g., (Dale et al.,
    2021; Hallinan  et  al., 2022),  cross-lingual
    transfer for this task remains a challenging
    open problem (Moskovskiy et al., 2022).  In
     this work, we present a large-scale study of
     strategies for cross-lingual text detoxification
   – given a parallel detoxification corpus for one
    language; the goal is to transfer detoxification
     ability to another language for which we do
    not have such a corpus.

    Moreover, we are the first to explore a new
    task where text translation and detoxification
    are performed simultaneously, providing sev-
     eral strong baselines for this task. Finally, we
    introduce new automatic detoxification eval-
    uation metrics with higher correlations with
   human judgments than previous benchmarks.
   We assess the most promising approaches also
    with manual markup, determining the answer
    for the best strategy to transfer the knowledge
    of text detoxification between languages.

1  Introduction

The original monolingual task of text detoxifica-
tion can be considered as text style transfer (TST),
where the goal is to build a function that, given a
source style ssrc, a destination style sdst, and an
input text tsrc to produce an output text tdst such
that:  (i) the style is indeed changed (in case of
detoxification from toxic into neutral); (ii) the con-
tent is saved as much as possible; (iii) the newly
generated text is fluent.
  The  task of  detoxification was already ad-
dressed with several approaches.   Firstly, sev-
eral unsupervised methods based on masked lan-
guage modelling (Tran et al., 2020; Dale et al.,
2021) and disentangled representations for style

    ∗Equal contribution
     † Work has been done while at Skoltechand content (John et al., 2019; dos Santos et al.,
2018) were explored. More recently, Logacheva
et al. (2022b) showed the superiority of supervised
seq2seq models for detoxification trained on a par-
allel corpus of crowdsourced toxic ↔neutral sen-
tence pairs.  Afterwards, there were experiments
in multilingual detoxification.  However, cross-
lingual transfer between languages with multilin-
gual seq2seq models was shown to be a challeng-
ing task (Moskovskiy et al., 2022).
  In this work, we aim to fill this gap and present
an extensive overview of different approaches for
cross-lingual text detoxification methods (tested in
English and Russian), showing that promising re-
sults can be obtained in contrast to prior findings.
Besides, we explore combining of two seq2seq
tasks/models in a single one to achieve computa-
tional gains (i.e., avoid the need to store and per-
form inference with several models). Namely, we
conduct simultaneous translation and style trans-
fer experiments, comparing them to a step-by-step
pipeline.


           Monolingual Text Detoxification

 Data         En parallel corpusOriginal (En)
Detox (En)Its a crock of s**t, and you know it.
It’s quite unpleasant, and you know it.    Cross-lingual Detoxification Transfer (Ours #1)

Data         En parallel corpus    , Ru parallel corpusOriginal (Ru)
Detox (Ru)Тварина е**ная, если это ее слова
Она очень неправа, если это дей-
ствительно еще слова Simultaneous Detoxification&Translation (Ours #2)

Data         En parallel corpus    , Ru parallel corpusOriginal (Ru)
Detox (En)Тварина е**ная, если это ее слова
She’s not a good person if its her wordsTable 1: Two new text detoxification setups explored
in this work compared to the monolingual setup.


  The contributions of this work are as follows:1083","Dementieva D,Moskovskiy D,Dale D,Panchenko A",,,Exploring Methods for Cross-lingual Text Style Transfer: The Case of Text Detoxification,,,10.18653/V1/2023.IJCNLP-MAIN.70 , Conference Paper,,"Text detoxification is the task of transferring
    the style of text from toxic to neutral. While
    there are approaches yielding promising re-
     sults in monolingual setup, e.g., (Dale et al.,
    2021; Hallinan  et  al., 2022),  cross-lingual
    transfer for this task remains a challenging
    open problem (Moskovskiy et al., 2022).  In
     this work, we present a large-scale study of
     strategies for cross-lingual text detoxification
   – given a parallel detoxification corpus for one
    language; the goal is to transfer detoxification
     ability to another language for which we do
    not have such a corpus.

    Moreover, we are the first to explore a new
    task where text translation and detoxification
    are performed simultaneously, providing sev-
     eral strong baselines for this task. Finally, we
    introduce new automatic detoxification eval-
    uation metrics with higher correlations with
   human judgments than previous benchmarks.
   We assess the most promising approaches also
    with manual markup, determining the answer
    for the best strategy to transfer the knowledge
    of text detoxification between languages.

1  Introduction

The original monolingual task of text detoxifica-
tion can be considered as text style transfer (TST),
where the goal is to build a function that, given a
source style ssrc, a destination style sdst, and an
input text tsrc to produce an output text tdst such
that:  (i) the style is indeed changed (in case of
detoxification from toxic into neutral); (ii) the con-
tent is saved as much as possible; (iii) the newly
generated text is fluent.
  The  task of  detoxification was already ad-
dressed with several approaches.   Firstly, sev-
eral unsupervised methods based on masked lan-
guage modelling (Tran et al., 2020; Dale et al.,
2021) and disentangled representations for style

    ∗Equal contribution
     † Work has been done while at Skoltechand content (John et al., 2019; dos Santos et al.,
2018) were explored. More recently, Logacheva
et al. (2022b) showed the superiority of supervised
seq2seq models for detoxification trained on a par-
allel corpus of crowdsourced toxic ↔neutral sen-
tence pairs.  Afterwards, there were experiments
in multilingual detoxification.  However, cross-
lingual transfer between languages with multilin-
gual seq2seq models was shown to be a challeng-
ing task (Moskovskiy et al., 2022).
  In this work, we aim to fill this gap and present
an extensive overview of different approaches for
cross-lingual text detoxification methods (tested in
English and Russian), showing that promising re-
sults can be obtained in contrast to prior findings.
Besides, we explore combining of two seq2seq
tasks/models in a single one to achieve computa-
tional gains (i.e., avoid the need to store and per-
form inference with several models). Namely, we
conduct simultaneous translation and style trans-
fer experiments, comparing them to a step-by-step
pipeline.


           Monolingual Text Detoxification

 Data         En parallel corpusOriginal (En)
Detox (En)Its a crock of s**t, and you know it.
It’s quite unpleasant, and you know it.    Cross-lingual Detoxification Transfer (Ours #1)

Data         En parallel corpus    , Ru parallel corpusOriginal (Ru)
Detox (Ru)Тварина е**ная, если это ее слова
Она очень неправа, если это дей-
ствительно еще слова Simultaneous Detoxification&Translation (Ours #2)

Data         En parallel corpus    , Ru parallel corpusOriginal (Ru)
Detox (En)Тварина е**ная, если это ее слова
She’s not a good person if its her wordsTable 1: Two new text detoxification setups explored
in this work compared to the monolingual setup.


  The contributions of this work are as follows:1083",,,,,Association for Computational Linguistics ,"Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics, IJCNLP 2023 -Volume 1: Long Papers, Nusa Dua, Bali, November 1 - 4, 2023  ",,detox,
2863,"**Title**Language Model Detoxification in Dialogue with Contextualized Stance Control

**Abstract**To reduce the toxic degeneration in a pretrained
   Language Model (LM), previous work on Lan-
    guage Model detoxification has focused on
    reducing the toxicity of the generation itself
     (self-toxicity) without consideration of the con-
     text (Dathathri et al., 2020; Krause et al., 2020;
   Qian et al., 2022). As a result, a type of im-
     plicit offensive language where the generations
    support the offensive language in the context
    (Figure 1) is ignored. Different from the LM
    controlling tasks in previous work, where the
    desired attributes are fixed for generation, the
    desired stance of the generation depends on
    the offensiveness of the context. Therefore, we
    propose a novel control method to do context-
    dependent detoxification with the stance taken
    into consideration. We introduce meta prefixes
    to learn the contextualized stance control strat-
    egy and to generate the stance control prefix
    according to the input context. The generated
    stance prefix is then combined with the toxic-
     ity control prefix to guide the response gener-
    ation. Experimental results show that our pro-
    posed method can effectively learn the context-
    dependent stance control strategies while keep-
    ing a low self-toxicity of the underlying LM.

1  Introduction

Large  pretrained Language Models,  such  as
GPT2 (Radford et al., 2019), can produce coherent,
almost human-like texts, but they are prone to gen-
erating offensive language, which hinders their safe
deployment (Gehman et al., 2020). An extensive
body of work has focused on detoxifying pretrained
LMs (Dathathri et al., 2020; Krause et al., 2020;
Qian et al., 2022). However, it can be more com-
plicated when the LMs are applied to downstream
Natural Language Generation (NLG) tasks, such
as dialogue response generation. When applied in
dialogue, the uncontrolled models tend to generate
toxic content and in addition to explicitly offen-
sive utterances, Baheti et al. (2021) suggest thatFigure 1: An illustration of two types of offensive re-
sponses. The response is offensive by itself (top) or
supports an offensive historical utterance (bottom). Of-
fensive words are masked.


these models can also implicitly insult a group or
individual by aligning themselves with an offen-
sive statement, as shown in Figure 1. Therefore,
to detoxify a pretrained LM applied in dialogue,
the stance of the generated response needs to be
taken into consideration. In a normal dialogue, we
do not need to control the stance, but if the user
inputs offensive language, the model should not
respond with a positive stance. In other words, the
eligible stance is context-dependent and we need
to consider the dialogue context.
  One straightforward solution is to design a con-
trol flow with a binary offensive language classifier,
where the dialogue context is taken as input for
the classifier. If the context contains offensive lan-
guage, an NLG model with both toxicity control
and stance control is used for response generation.
We would like the self-toxicity to be low and the
stance not to be supportive. On the other hand, if
the context does not contain offensive language, the
stance does not need to be controlled, so another
NLG model with only toxicity control is used for
response generation. However, this Classify-then-
Generate framework has several limitations. First,5548","Qian J,Yan X",,,Language Model Detoxification in Dialogue with Contextualized Stance Control,abs/2301.10368,,10.48550/ARXIV.2301.10368 , Journal Article,,"To reduce the toxic degeneration in a pretrained
   Language Model (LM), previous work on Lan-
    guage Model detoxification has focused on
    reducing the toxicity of the generation itself
     (self-toxicity) without consideration of the con-
     text (Dathathri et al., 2020; Krause et al., 2020;
   Qian et al., 2022). As a result, a type of im-
     plicit offensive language where the generations
    support the offensive language in the context
    (Figure 1) is ignored. Different from the LM
    controlling tasks in previous work, where the
    desired attributes are fixed for generation, the
    desired stance of the generation depends on
    the offensiveness of the context. Therefore, we
    propose a novel control method to do context-
    dependent detoxification with the stance taken
    into consideration. We introduce meta prefixes
    to learn the contextualized stance control strat-
    egy and to generate the stance control prefix
    according to the input context. The generated
    stance prefix is then combined with the toxic-
     ity control prefix to guide the response gener-
    ation. Experimental results show that our pro-
    posed method can effectively learn the context-
    dependent stance control strategies while keep-
    ing a low self-toxicity of the underlying LM.

1  Introduction

Large  pretrained Language Models,  such  as
GPT2 (Radford et al., 2019), can produce coherent,
almost human-like texts, but they are prone to gen-
erating offensive language, which hinders their safe
deployment (Gehman et al., 2020). An extensive
body of work has focused on detoxifying pretrained
LMs (Dathathri et al., 2020; Krause et al., 2020;
Qian et al., 2022). However, it can be more com-
plicated when the LMs are applied to downstream
Natural Language Generation (NLG) tasks, such
as dialogue response generation. When applied in
dialogue, the uncontrolled models tend to generate
toxic content and in addition to explicitly offen-
sive utterances, Baheti et al. (2021) suggest thatFigure 1: An illustration of two types of offensive re-
sponses. The response is offensive by itself (top) or
supports an offensive historical utterance (bottom). Of-
fensive words are masked.


these models can also implicitly insult a group or
individual by aligning themselves with an offen-
sive statement, as shown in Figure 1. Therefore,
to detoxify a pretrained LM applied in dialogue,
the stance of the generated response needs to be
taken into consideration. In a normal dialogue, we
do not need to control the stance, but if the user
inputs offensive language, the model should not
respond with a positive stance. In other words, the
eligible stance is context-dependent and we need
to consider the dialogue context.
  One straightforward solution is to design a con-
trol flow with a binary offensive language classifier,
where the dialogue context is taken as input for
the classifier. If the context contains offensive lan-
guage, an NLG model with both toxicity control
and stance control is used for response generation.
We would like the self-toxicity to be low and the
stance not to be supportive. On the other hand, if
the context does not contain offensive language, the
stance does not need to be controlled, so another
NLG model with only toxicity control is used for
response generation. However, this Classify-then-
Generate framework has several limitations. First,5548",,,,, CoRR,  ,,detox,
2864,"**Title**Let the Models Respond: Interpreting Language Model Detoxification Through the Lens of Prompt Dependence

**Abstract**Abstract:Due to language models' propensity to generate toxic or hateful responses, several techniques were developed to align model generations with users' preferences. Despite the effectiveness of such methods in improving the safety of model interactions, their impact on models' internal processes is still poorly understood. In this work, we apply popular detoxification approaches to several language models and quantify their impact on the resulting models' prompt dependence using feature attribution methods. We evaluate the effectiveness of counter-narrative fine-tuning and compare it with reinforcement learning-driven detoxification, observing differences in prompt reliance between the two methods despite their similar detoxification performances.","Scalena D,Sarti G,Nissim M,Fersini E",,,Let the Models Respond: Interpreting Language Model Detoxification Through the Lens of Prompt Dependence,abs/2309.00751,,10.48550/ARXIV.2309.00751 , Journal Article,,"Abstract:Due to language models' propensity to generate toxic or hateful responses, several techniques were developed to align model generations with users' preferences. Despite the effectiveness of such methods in improving the safety of model interactions, their impact on models' internal processes is still poorly understood. In this work, we apply popular detoxification approaches to several language models and quantify their impact on the resulting models' prompt dependence using feature attribution methods. We evaluate the effectiveness of counter-narrative fine-tuning and compare it with reinforcement learning-driven detoxification, observing differences in prompt reliance between the two methods despite their similar detoxification performances.",,,,, CoRR,  ,,detox,
2865,"**Title**Text Detoxification in Natural Language Processing

**Abstract**AbstractThis paper focuses on text detoxification, i.e., automatically converting toxic text into nontoxic text. This task contributes to safer and more respectful online communication and can be considered a Text Style Transfer (TST) task, where the text’s style changes while its content is preserved. We present three approaches: (i) knowledge transfer from a similar task (ii) multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and (iii) delete and reconstruct approach. To support our research, we utilize a dataset provided by Dementieva et al. (2021), which contains multiple versions of detoxified texts corresponding to toxic texts. In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version. Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes. Our results demonstrate that our approach effectively balances text detoxification while preserving the actual content and maintaining fluency.",Qian J,,,Text Detoxification in Natural Language Processing,,, , Ph.D. Thesis,,"AbstractThis paper focuses on text detoxification, i.e., automatically converting toxic text into nontoxic text. This task contributes to safer and more respectful online communication and can be considered a Text Style Transfer (TST) task, where the text’s style changes while its content is preserved. We present three approaches: (i) knowledge transfer from a similar task (ii) multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and (iii) delete and reconstruct approach. To support our research, we utilize a dataset provided by Dementieva et al. (2021), which contains multiple versions of detoxified texts corresponding to toxic texts. In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version. Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes. Our results demonstrate that our approach effectively balances text detoxification while preserving the actual content and maintaining fluency.",,,,, ,  ,,detox,
2866,"**Title**Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models

**Abstract**Detoxification is a task of generating text in po-
      lite style while preserving meaning and fluency
    of the original toxic text. Existing detoxifica-
     tion methods are designed to work in one exact
    language. This work investigates multilingual
    and cross-lingual detoxification and the behav-
     ior of large multilingual models like in this
     setting. Unlike previous works we aim to make
    large language models able to perform detoxifi-
    cation without direct fine-tuning in given lan-
    guage.  Experiments show that multilingual
    models are capable of performing multilingual
     style transfer. However, models are not able to
    perform cross-lingual detoxification and direct
    fine-tuning on exact language is inevitable.

1  Introduction

The task of Textual Style Transfer (Textual Style
Transfer) can be viewed as a task where cer-
tain properties of text are being modified while
rest retain the same1.  In this work we focus
on detoxification textual style transfer (dos San-
tos et al., 2018a; Dementieva et al., 2021a).  It
can be formulated as follows:  given two text
corpora DX =  {x1, x2, . . . xn} and DY =
{y1, y2, . . . , yn}, where X, Y - are two sets of all
possible text in styles sX, sY respectively, we want
to build a model fθ : X →Y , such that the prob-
ability p(ygen|x, sX, sY ) of transferring the style
sX of given text x (by generation ygen) to the style
sY is maximized (where sX and sY are toxic and
non-toxic styles respectively).
  Some examples of detoxification presented in
Table 1.
  Textual style transfer gained a lot of attention
with a rise of deep learning-based NLP methods.
Given that, Textual Style Transfer has now a lot of
specific subtasks ranging from formality style trans-
fer (Rao and Tetreault, 2018; Yao and Yu, 2021)

    1Hereinafter the data-driven definition of style is used.
Therefore, we call style a characteristic of given dataset that
differs from a general dataset (Jin et al., 2020).and simplification of domain-specific texts (De-
varaj et al., 2021; Maddela et al., 2021) to emotion
modification (Sharma et al., 2021) and detoxifica-
tion (debiasing) (Li et al., 2021; Dementieva et al.,
2021a).
  There exist a variety of Textual Style Transfer
methods: from totally supervised methods (Wang
et al., 2019b; Zhang et al., 2020; Dementieva et al.,
2021a) which require a parallel text corpus for train-
ing to unsupervised (Shen et al., 2017; Wang et al.,
2019a; Xu et al., 2021) that are designed to work
without any parallel data. The latter sub-field of re-
search is more popular nowadays due to the scarcity
of parallel text data for Textual Style Transfer. On
the other hand, if we address Textual Style Trans-
fer task as a Machine Translation task we get a
significant performance boost (Prabhumoye et al.,
2018).
  The task of detoxification, in which we focus
in this work, is relatively new.  First work on
detoxification was a sequence-to-sequence collabo-
rative classifier, attention and the cycle consistency
loss (dos Santos et al., 2018b). A recent work by
(Laugier et al., 2021) introduces self-supervised
model based on T5 model (Raffel et al., 2020) with
a denoising and cyclic auto-encoder loss.
  Both these methods are unsupervised which is an
advantage but it comes from the major current prob-
lem of the textual style transfer. There is a lack of
parallel data for Textual Style Transfer since there
exist only few parallel datasets for English (Rao
and Tetreault, 2018) and some other languages (Bri-
akou et al., 2021). When it comes to detoxification
there are only two parallel detoxification corpora
available now and they both appeared only last year
(Dementieva et al., 2021b). Most state-of-the-art
methods rely on large amounts of text data which is
often available for some well-researched languages
like English but lacking for other languages almost
entirely. Therefore, it is important to study whether
cross-lingual (or at least multilingual) detoxifica-","Moskovskiy D,Dementieva D,Panchenko A",,,Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models,,,10.18653/V1/2022.ACL-SRW.26 , Conference Paper,,"Detoxification is a task of generating text in po-
      lite style while preserving meaning and fluency
    of the original toxic text. Existing detoxifica-
     tion methods are designed to work in one exact
    language. This work investigates multilingual
    and cross-lingual detoxification and the behav-
     ior of large multilingual models like in this
     setting. Unlike previous works we aim to make
    large language models able to perform detoxifi-
    cation without direct fine-tuning in given lan-
    guage.  Experiments show that multilingual
    models are capable of performing multilingual
     style transfer. However, models are not able to
    perform cross-lingual detoxification and direct
    fine-tuning on exact language is inevitable.

1  Introduction

The task of Textual Style Transfer (Textual Style
Transfer) can be viewed as a task where cer-
tain properties of text are being modified while
rest retain the same1.  In this work we focus
on detoxification textual style transfer (dos San-
tos et al., 2018a; Dementieva et al., 2021a).  It
can be formulated as follows:  given two text
corpora DX =  {x1, x2, . . . xn} and DY =
{y1, y2, . . . , yn}, where X, Y - are two sets of all
possible text in styles sX, sY respectively, we want
to build a model fθ : X →Y , such that the prob-
ability p(ygen|x, sX, sY ) of transferring the style
sX of given text x (by generation ygen) to the style
sY is maximized (where sX and sY are toxic and
non-toxic styles respectively).
  Some examples of detoxification presented in
Table 1.
  Textual style transfer gained a lot of attention
with a rise of deep learning-based NLP methods.
Given that, Textual Style Transfer has now a lot of
specific subtasks ranging from formality style trans-
fer (Rao and Tetreault, 2018; Yao and Yu, 2021)

    1Hereinafter the data-driven definition of style is used.
Therefore, we call style a characteristic of given dataset that
differs from a general dataset (Jin et al., 2020).and simplification of domain-specific texts (De-
varaj et al., 2021; Maddela et al., 2021) to emotion
modification (Sharma et al., 2021) and detoxifica-
tion (debiasing) (Li et al., 2021; Dementieva et al.,
2021a).
  There exist a variety of Textual Style Transfer
methods: from totally supervised methods (Wang
et al., 2019b; Zhang et al., 2020; Dementieva et al.,
2021a) which require a parallel text corpus for train-
ing to unsupervised (Shen et al., 2017; Wang et al.,
2019a; Xu et al., 2021) that are designed to work
without any parallel data. The latter sub-field of re-
search is more popular nowadays due to the scarcity
of parallel text data for Textual Style Transfer. On
the other hand, if we address Textual Style Trans-
fer task as a Machine Translation task we get a
significant performance boost (Prabhumoye et al.,
2018).
  The task of detoxification, in which we focus
in this work, is relatively new.  First work on
detoxification was a sequence-to-sequence collabo-
rative classifier, attention and the cycle consistency
loss (dos Santos et al., 2018b). A recent work by
(Laugier et al., 2021) introduces self-supervised
model based on T5 model (Raffel et al., 2020) with
a denoising and cyclic auto-encoder loss.
  Both these methods are unsupervised which is an
advantage but it comes from the major current prob-
lem of the textual style transfer. There is a lack of
parallel data for Textual Style Transfer since there
exist only few parallel datasets for English (Rao
and Tetreault, 2018) and some other languages (Bri-
akou et al., 2021). When it comes to detoxification
there are only two parallel detoxification corpora
available now and they both appeared only last year
(Dementieva et al., 2021b). Most state-of-the-art
methods rely on large amounts of text data which is
often available for some well-researched languages
like English but lacking for other languages almost
entirely. Therefore, it is important to study whether
cross-lingual (or at least multilingual) detoxifica-",,,,,Association for Computational Linguistics ,"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, ACL 2022, Dublin, Ireland, May 22-27, 2022  ",,detox,
2867,"**Title**Application of Artificial Intelligence in Drug Detoxification

**Abstract**AbstractIn 1956, the term ""artificial intelligence"" officially appeared. Now it has developed into a hot frontier science. The application of artificial intelligence in drug rehabilitation not only greatly reduces the workload of drug rehabilitation workers, but also brings help to drug addicts. This paper mainly introduces the practical application and relevant assumptions of artificial intelligence in the field of drug rehabilitation in recent years. Analysis shows that artificial intelligence plays an important role in drug rehabilitation.","Shao H,Chen Z",,,Application of Artificial Intelligence in Drug Detoxification,,,10.1145/3570773.3570860 , Conference Paper,,"AbstractIn 1956, the term ""artificial intelligence"" officially appeared. Now it has developed into a hot frontier science. The application of artificial intelligence in drug rehabilitation not only greatly reduces the workload of drug rehabilitation workers, but also brings help to drug addicts. This paper mainly introduces the practical application and relevant assumptions of artificial intelligence in the field of drug rehabilitation in recent years. Analysis shows that artificial intelligence plays an important role in drug rehabilitation.",,,,,ACM ,"3rd International Symposium on Artificial Intelligence for Medicine Sciences, ISAIMS 2022, Amsterdam, The Netherlands, October 13-15, 2022  ",,out_of_scope,
2868,"**Title**Russian Texts Detoxification with Levenshtein Editing

**Abstract**Abstract:Text detoxification is a style transfer task of creating neutral versions of toxic texts. In this paper, we use the concept of text editing to build a two-step tagging-based detoxification model using a parallel corpus of Russian texts. With this model, we achieved the best style transfer accuracy among all models in the RUSSE Detox shared task, surpassing larger sequence-to-sequence models.",Gusev I,,,Russian Texts Detoxification with Levenshtein Editing,abs/2204.13638,,10.48550/ARXIV.2204.13638 , Journal Article,,"Abstract:Text detoxification is a style transfer task of creating neutral versions of toxic texts. In this paper, we use the concept of text editing to build a two-step tagging-based detoxification model using a parallel corpus of Russian texts. With this model, we achieved the best style transfer accuracy among all models in the RUSSE Detox shared task, surpassing larger sequence-to-sequence models.",,,,, CoRR,  ,,out_but_toxicity,
2869,"**Title**Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification

**Abstract**Trojan (backdoor) attack is a form of adversarial attack on deep neural networks where the attacker provides victims with a model trained/retrained on malicious data. The backdoor can be activated when a normal input is stamped with a certain pattern called trigger, causing misclassification. Many existing trojan attacks have their triggers being input space patches/objects (e.g., a polygon with solid color) or simple input transformations such as Instagram filters. These simple triggers are susceptible to recent backdoor detection algorithms. We propose a novel deep feature space trojan attack with five characteristics: effectiveness, stealthiness, controllability, robustness and reliance on deep features. We conduct extensive experiments on 9 image classifiers on various datasets including ImageNet to demonstrate these properties and show that our attack can evade state-of-the-art defense.","Cheng S,Liu Y,Ma S,Zhang X",,,Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification,,,10.1609/AAAI.V35I2.16201 , Conference Paper,,"Trojan (backdoor) attack is a form of adversarial attack on deep neural networks where the attacker provides victims with a model trained/retrained on malicious data. The backdoor can be activated when a normal input is stamped with a certain pattern called trigger, causing misclassification. Many existing trojan attacks have their triggers being input space patches/objects (e.g., a polygon with solid color) or simple input transformations such as Instagram filters. These simple triggers are susceptible to recent backdoor detection algorithms. We propose a novel deep feature space trojan attack with five characteristics: effectiveness, stealthiness, controllability, robustness and reliance on deep features. We conduct extensive experiments on 9 image classifiers on various datasets including ImageNet to demonstrate these properties and show that our attack can evade state-of-the-art defense.",,,,,AAAI Press ,"Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021  ",,out_of_scope,
2870,No abstract available,"Dementieva D,Ustyantsev S,Dale D,Kozlova O,Semenov N,Panchenko A,Logacheva V",,,Crowdsourcing of Parallel Corpora: the Case of Style Transfer for Detoxification,2932,, , Conference Paper,,,,,,,CEUR-WS.org ,"Proceedings of the 2nd Crowd Science Workshop: Trust, Ethics, and Excellence in Crowdsourced Data Management at Scale co-located with 47th International Conference on Very Large Data Bases (VLDB 2021), Copenhagen, Denmark, August 20, 2021  ",,detox,
2871,"**Title**Micro/nanorobots for biomedicine: Delivery, surgery, sensing, and detoxification

**Abstract**Small robots may solve big challenges in biomedicine, including diagnosis, detoxification, drug delivery, and surgery.","de Ávila BE,Gao W,Zhang L,Wang J",,,"Micro/nanorobots for biomedicine: Delivery, surgery, sensing, and detoxification",2,4,10.1126/SCIROBOTICS.AAM6431 , Journal Article,,"Small robots may solve big challenges in biomedicine, including diagnosis, detoxification, drug delivery, and surgery.",,,,, Sci. Robotics,  ,,out_of_scope,
2872,"**Title**Coordinating Role of RXR\(\alpha\) in Downregulating Hepatic Detoxification during Inflammation Revealed by Fuzzy-Logic Modeling

**Abstract**AbstractListen Translate article","Keller R,Klein M,Thomas M,Dräger A,Metzger U,Templin MF,Joos TO,Thasler WE,Zell A,Zanger UM",,,Coordinating Role of RXR\(\alpha\) in Downregulating Hepatic Detoxification during Inflammation Revealed by Fuzzy-Logic Modeling,12,1,10.1371/JOURNAL.PCBI.1004431 , Journal Article,,AbstractListen Translate article,,,,, PLoS Comput. Biol.,  ,,out_of_scope,
2873,"**Title**Recovery of dopamine transporters with methamphetamine detoxification is not linked to changes in dopamine release

**Abstract**Abstract
        
      


      
      Methamphetamine's widepread abuse and concerns that it might increase Parkinson's disease led us to assess if the reported loss of dopamine transporters (DAT) in methamphetamine abusers (MA) reflected damage to dopamine neurons. Using PET with [(11)C]cocaine to measure DAT, and with [(11)C]raclopride to measure dopamine release (assessed as changes in specific binding of [(11)C]raclopride between placebo and methylphenidate), which was used as a marker of dopamine neuronal function, we show that MA (n=16), tested during early detoxification, had lower DAT (20-30%) but overall normal DA release in striatum (except for a small decrease in left putamen), when compared to controls (n=15). In controls, DAT were positively correlated with DA release (higher DAT associated with larger DA increases), consistent with DAT serving as markers of DA terminals. In contrast, MA showed a trend for a negative correlation (p=0.07) (higher DAT associated with lower DA increases), consistent with reduced DA re-uptake following DAT downregulation. MA who remained abstinent nine-months later (n=9) showed significant increases in DAT (20%) but methylphenidate-induced dopamine increases did not change. In contrast, in controls, DAT did not change when retested 9 months later but methylphenidate-induced dopamine increases in ventral striatum were reduced (p=0.05). Baseline D2/D3 receptors in caudate were lower in MA than in controls and did not change with detoxification, nor did they change in the controls upon retest. The loss of DAT in the MA, which was not associated with a concomitant reduction in dopamine release as would have been expected if DAT loss reflected DA terminal degneration; as well as the recovery of DAT after protracted detoxification, which was not associated with increased dopamine release as would have been expected if DAT increases reflected terminal regeneration, indicate that the loss of DAT in these MA does not reflect degeneration of dopamine terminals.
    



          Keywords:
        
      
      Addiction; Dopamine terminal; Neurotoxicity; Parkinson's disease.","Volkow ND,Wang GJ,Smith L,Fowler JS,Telang F,Logan J,Tomasi D",,,Recovery of dopamine transporters with methamphetamine detoxification is not linked to changes in dopamine release,121,,10.1016/J.NEUROIMAGE.2015.07.035 , Journal Article,,"Abstract
        
      


      
      Methamphetamine's widepread abuse and concerns that it might increase Parkinson's disease led us to assess if the reported loss of dopamine transporters (DAT) in methamphetamine abusers (MA) reflected damage to dopamine neurons. Using PET with [(11)C]cocaine to measure DAT, and with [(11)C]raclopride to measure dopamine release (assessed as changes in specific binding of [(11)C]raclopride between placebo and methylphenidate), which was used as a marker of dopamine neuronal function, we show that MA (n=16), tested during early detoxification, had lower DAT (20-30%) but overall normal DA release in striatum (except for a small decrease in left putamen), when compared to controls (n=15). In controls, DAT were positively correlated with DA release (higher DAT associated with larger DA increases), consistent with DAT serving as markers of DA terminals. In contrast, MA showed a trend for a negative correlation (p=0.07) (higher DAT associated with lower DA increases), consistent with reduced DA re-uptake following DAT downregulation. MA who remained abstinent nine-months later (n=9) showed significant increases in DAT (20%) but methylphenidate-induced dopamine increases did not change. In contrast, in controls, DAT did not change when retested 9 months later but methylphenidate-induced dopamine increases in ventral striatum were reduced (p=0.05). Baseline D2/D3 receptors in caudate were lower in MA than in controls and did not change with detoxification, nor did they change in the controls upon retest. The loss of DAT in the MA, which was not associated with a concomitant reduction in dopamine release as would have been expected if DAT loss reflected DA terminal degneration; as well as the recovery of DAT after protracted detoxification, which was not associated with increased dopamine release as would have been expected if DAT increases reflected terminal regeneration, indicate that the loss of DAT in these MA does not reflect degeneration of dopamine terminals.
    



          Keywords:
        
      
      Addiction; Dopamine terminal; Neurotoxicity; Parkinson's disease.",,,,, NeuroImage,  ,,out_of_scope,
2874,"**Title**Predicting The Initial Lapses After Alcohol Detoxification Using mHealth

**Abstract**The prediction and prevention of the initial lapse--which is defined as the first lapse after a period of abstinence--is important because the initial lapse often leads to subsequent lapses (within the same lapse episode) or relapse. The prediction of the initial lapse may allow preemptive intervention to be possible. This dissertation reports on a predictive modeling study of the initial alcohol lapse after patient left residential care. The data were collected via a mobile health application, Addiction-Comprehensive Health Enhancement Support System (A-CHESS). A-CHESS was designed to offer ongoing support to alcohol addiction patients who have returned to their own community after completing inpatient treatment programs. Patients may access A-CHESS services at any time anywhere to help them cope with the recovery. In addition to the first chapter as the introduction of the problems and context, this dissertation consists of the other three chapters; each chapter presents a study to address different challenges faced in the development of such a predictive model in A-CHESS. The first challenge is the validation of a survey instrument used in the A-CHESS Weekly Check-in; the second challenge is the study of A-CHESS use behavior before the initial lapse; and the third challenge is to develop a comprehensive predictive model of the initial lapse. The steps taken in this dissertation to address these challenges have been fruitful. The major findings are practical and can be implemented in A-CHESS. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",Chih MY,,,Predicting The Initial Lapses After Alcohol Detoxification Using mHealth,,, , Conference Paper,,"The prediction and prevention of the initial lapse--which is defined as the first lapse after a period of abstinence--is important because the initial lapse often leads to subsequent lapses (within the same lapse episode) or relapse. The prediction of the initial lapse may allow preemptive intervention to be possible. This dissertation reports on a predictive modeling study of the initial alcohol lapse after patient left residential care. The data were collected via a mobile health application, Addiction-Comprehensive Health Enhancement Support System (A-CHESS). A-CHESS was designed to offer ongoing support to alcohol addiction patients who have returned to their own community after completing inpatient treatment programs. Patients may access A-CHESS services at any time anywhere to help them cope with the recovery. In addition to the first chapter as the introduction of the problems and context, this dissertation consists of the other three chapters; each chapter presents a study to address different challenges faced in the development of such a predictive model in A-CHESS. The first challenge is the validation of a survey instrument used in the A-CHESS Weekly Check-in; the second challenge is the study of A-CHESS use behavior before the initial lapse; and the third challenge is to develop a comprehensive predictive model of the initial lapse. The steps taken in this dissertation to address these challenges have been fruitful. The major findings are practical and can be implemented in A-CHESS. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",,,,,AMIA ,"AMIA 2015, American Medical Informatics Association Annual Symposium, San Francisco, CA, USA, November 14-18, 2015  ",,out_of_scope,
2875,"**Title**Neuropsychological Predictors of Alcohol Abtinence Following a Detoxification Program

**Abstract**Neuropsychological Impairment in Detoxified Alcohol-Dependent Subjects with Preserved Psychosocial Functioning","Bento B,Oliveira J,Gameiro F,Brito R,Gamito P,Lopes P,Morais D,Neto M",,,Neuropsychological Predictors of Alcohol Abtinence Following a Detoxification Program,665,,10.1007/978-3-319-69694-2_13 , Conference Paper,,Neuropsychological Impairment in Detoxified Alcohol-Dependent Subjects with Preserved Psychosocial Functioning,,,,,Springer ,"ICTs for Improving Patients Rehabilitation Research Techniques - Third International Workshop, REHAB 2015, Lisbon, Portugal, October 1-2, 2015, Revised Selected Papers  ",,out_of_scope,
2876,"**Title**Key Amino Acid Associated with Acephate Detoxification by Cydia pomonella Carboxylesterase Based on Molecular Dynamics with Alanine Scanning and Site-Directed Mutagenesis

**Abstract**Abstract
        
      


      
      Insecticide-detoxifying carboxylesterase (CE) gene CpCE-1 was cloned from Cydia pomonella. Molecular dynamics (MD) simulation and computational alanine scanning (CAS) indicate that Asn 232 in CpCE-1 constitutes an approximate binding hot-spot with a binding free energy difference (ΔΔGbind) value of 3.66 kcal/mol. The catalytic efficiency (kcat/km) of N232A declined dramatically, and the half inhibitory concentrations (IC50) value increased by more than 230-fold. Metabolism assay in vitro reveals that the acephate could be metabolized by wild CpCE-1, whereas N232A mutation is unable to metabolize the acephate, which suggests that the hot-spot Asn 232 is a crucial residue for acephate metabolism. Mutation detection suggests that low frequency of Asn 232 replacement occurred in Europe field strains. Our MD, CAS, site-directed mutagenesis, and metabolism studies introduce a new amino acid residue Asn 232 involved in the metabolism of the acephate with CpCE-1, and this method is reliable in insecticide resistance mechanism research and prediction of key amino acids in a protein which is associated with specific physiological and biochemical functions.","Yang XQ,Liu JY,Li XC,Chen MH,Zhang YL",,,Key Amino Acid Associated with Acephate Detoxification by Cydia pomonella Carboxylesterase Based on Molecular Dynamics with Alanine Scanning and Site-Directed Mutagenesis,54,5,10.1021/CI500159Q , Journal Article,,"Abstract
        
      


      
      Insecticide-detoxifying carboxylesterase (CE) gene CpCE-1 was cloned from Cydia pomonella. Molecular dynamics (MD) simulation and computational alanine scanning (CAS) indicate that Asn 232 in CpCE-1 constitutes an approximate binding hot-spot with a binding free energy difference (ΔΔGbind) value of 3.66 kcal/mol. The catalytic efficiency (kcat/km) of N232A declined dramatically, and the half inhibitory concentrations (IC50) value increased by more than 230-fold. Metabolism assay in vitro reveals that the acephate could be metabolized by wild CpCE-1, whereas N232A mutation is unable to metabolize the acephate, which suggests that the hot-spot Asn 232 is a crucial residue for acephate metabolism. Mutation detection suggests that low frequency of Asn 232 replacement occurred in Europe field strains. Our MD, CAS, site-directed mutagenesis, and metabolism studies introduce a new amino acid residue Asn 232 involved in the metabolism of the acephate with CpCE-1, and this method is reliable in insecticide resistance mechanism research and prediction of key amino acids in a protein which is associated with specific physiological and biochemical functions.",,,,, J. Chem. Inf. Model.,  ,,out_of_scope,
2877,"**Title**Exploring the use patterns of a mobile health application for alcohol addiction before the initial lapse after detoxification

**Abstract**Abstract
How patients used Addiction-Comprehensive Health Enhancement Support System (A-CHESS)1, a mobile health intervention, while quitting drinking is worthy exploring. This study is to explore A-CHESS use patterns prior to the initial lapse reported after discharge from inpatient detoxification programs. 142 patients with alcohol addiction from two treatment agencies in the U.S. were included. A comprehensive set of A-CHESS use measures were developed based on a three-level system use framework and three A-CHESS service categories. In latent profile analyses, three A-CHESS system use patterns—inactive, passive, and active users—were found. Compared to the passive users (with the highest chance of the initial lapse), the active users (with the lowest chance of such behavior) participated more in online social activities, used more sessions, viewed more pages, and used A-CHESS longer. However, the chances of the initial lapse between A-CHESS user profiles were not statistically different. Implications of this finding were provided.",Chih MY,,,Exploring the use patterns of a mobile health application for alcohol addiction before the initial lapse after detoxification,,, , Conference Paper,,"Abstract
How patients used Addiction-Comprehensive Health Enhancement Support System (A-CHESS)1, a mobile health intervention, while quitting drinking is worthy exploring. This study is to explore A-CHESS use patterns prior to the initial lapse reported after discharge from inpatient detoxification programs. 142 patients with alcohol addiction from two treatment agencies in the U.S. were included. A comprehensive set of A-CHESS use measures were developed based on a three-level system use framework and three A-CHESS service categories. In latent profile analyses, three A-CHESS system use patterns—inactive, passive, and active users—were found. Compared to the passive users (with the highest chance of the initial lapse), the active users (with the lowest chance of such behavior) participated more in online social activities, used more sessions, viewed more pages, and used A-CHESS longer. However, the chances of the initial lapse between A-CHESS user profiles were not statistically different. Implications of this finding were provided.",,,,,AMIA ,"AMIA 2014, American Medical Informatics Association Annual Symposium, Washington, DC, USA, November 15-19, 2014  ",,out_of_scope,
2878,"**Title**Molecular dynamics simulations of the detoxification of paraoxon catalyzed by phosphotriesterase

**Abstract**Combined QM(PM3)/MM molecular dynamics simulations together with QM(DFT)/MM optimizations for key configurations have been performed to elucidate the enzymatic catalysis mechanism on the detoxification of paraoxon by phosphotriesterase (PTE). In the simulations, the PM3 parameters for the phosphorous atom were reoptimized. The equilibrated configuration of the enzyme/substrate complex showed that paraoxon can strongly bind to the more solvent‐exposed metal ion Zn<jats:sub>β</jats:sub>, but the free energy profile along the binding path demonstrated that the binding is thermodynamically unfavorable. This explains why the crystal structures of PTE with substrate analogues often exhibit long distances between the phosphoral oxygen and Zn<jats:sub>β</jats:sub>. The subsequent S<jats:sub>N</jats:sub>2 reaction plays the key role in the whole process, but controversies exist over the identity of the nucleophilic species, which could be either a hydroxide ion terminally coordinated to Zn<jats:sub>α</jats:sub> or the μ‐hydroxo bridge between the α‐ and β‐metals. Our simulations supported the latter and showed that the rate‐limiting step is the distortion of the bound paraoxon to approach the bridging hydroxide. After this preparation step, the bridging hydroxide ion attacks the phosphorous center and replaces the diethyl phosphate with a low barrier. Thus, a plausible way to engineer PTE with enhanced catalytic activity is to stabilize the deformed paraoxon. Conformational analyses indicate that Trp131 is the closest residue to the phosphoryl oxygen, and mutations to Arg or Gln or even Lys, which can shorten the hydrogen bond distance with the phosphoryl oxygen, could potentially lead to a mutant with enhanced activity for the detoxification of organophosphates. © 2009 Wiley Periodicals, Inc. J Comput Chem, 2009","Zhang X,Wu R,Song L,Lin Y,Lin M,Cao Z,Wu W,Mo Y",,,Molecular dynamics simulations of the detoxification of paraoxon catalyzed by phosphotriesterase,30,15,10.1002/JCC.21238 , Journal Article,,"Combined QM(PM3)/MM molecular dynamics simulations together with QM(DFT)/MM optimizations for key configurations have been performed to elucidate the enzymatic catalysis mechanism on the detoxification of paraoxon by phosphotriesterase (PTE). In the simulations, the PM3 parameters for the phosphorous atom were reoptimized. The equilibrated configuration of the enzyme/substrate complex showed that paraoxon can strongly bind to the more solvent‐exposed metal ion Zn<jats:sub>β</jats:sub>, but the free energy profile along the binding path demonstrated that the binding is thermodynamically unfavorable. This explains why the crystal structures of PTE with substrate analogues often exhibit long distances between the phosphoral oxygen and Zn<jats:sub>β</jats:sub>. The subsequent S<jats:sub>N</jats:sub>2 reaction plays the key role in the whole process, but controversies exist over the identity of the nucleophilic species, which could be either a hydroxide ion terminally coordinated to Zn<jats:sub>α</jats:sub> or the μ‐hydroxo bridge between the α‐ and β‐metals. Our simulations supported the latter and showed that the rate‐limiting step is the distortion of the bound paraoxon to approach the bridging hydroxide. After this preparation step, the bridging hydroxide ion attacks the phosphorous center and replaces the diethyl phosphate with a low barrier. Thus, a plausible way to engineer PTE with enhanced catalytic activity is to stabilize the deformed paraoxon. Conformational analyses indicate that Trp131 is the closest residue to the phosphoryl oxygen, and mutations to Arg or Gln or even Lys, which can shorten the hydrogen bond distance with the phosphoryl oxygen, could potentially lead to a mutant with enhanced activity for the detoxification of organophosphates. © 2009 Wiley Periodicals, Inc. J Comput Chem, 2009",,,,, J. Comput. Chem.,  ,,out_of_scope,
2879,"**Title**An Immune-Inspired Approach to Qualitative System Identification of the Detoxification Pathway of Methylglyoxal

**Abstract**AbstractIn this paper, a special-purpose qualitative model learning (QML) system using an immune-inspired algorithm is proposed to qualitatively reconstruct biological pathways. We choose a real-world application, the detoxification pathway of Methylglyoxal (MG), as a case study. First a converter is implemented to convert possible pathways to qualitative models. Then a general learning strategy is presented. To improve the scalability of the proposed QML system and make it adapt to future more complicated pathways, a modified clonal selection algorithm (CLONALG) is employed as the search strategy. The performance of this immune-inspired approach is compared with those of exhaustive search and two backtracking algorithms. The experimental results indicate that this immune-inspired approach can significantly improve the search efficiency when dealing with some complicated pathways with large-scale search spaces.","Pang W,Coghill GM",,,An Immune-Inspired Approach to Qualitative System Identification of the Detoxification Pathway of Methylglyoxal,5666,,10.1007/978-3-642-03246-2_17 , Conference Paper,,"AbstractIn this paper, a special-purpose qualitative model learning (QML) system using an immune-inspired algorithm is proposed to qualitatively reconstruct biological pathways. We choose a real-world application, the detoxification pathway of Methylglyoxal (MG), as a case study. First a converter is implemented to convert possible pathways to qualitative models. Then a general learning strategy is presented. To improve the scalability of the proposed QML system and make it adapt to future more complicated pathways, a modified clonal selection algorithm (CLONALG) is employed as the search strategy. The performance of this immune-inspired approach is compared with those of exhaustive search and two backtracking algorithms. The experimental results indicate that this immune-inspired approach can significantly improve the search efficiency when dealing with some complicated pathways with large-scale search spaces.",,,,,Springer ,"Artificial Immune Systems, 8th International Conference, ICARIS 2009, York, UK, August 9-12, 2009. Proceedings  ",,out_of_scope,
2880,"**Title**Multi-agent based modeling of liver detoxification

**Abstract**AbstractUsing game theory and reinforcement learning, we created and analyzed generalized agent-based models of hepatic toxin elimination processes to explore plausible causes of hepatic functional zonation. We considered a general situation in which a group of protective agents (analogous to liver cells) cooperate and self-organize their efforts to minimize optimally the negative effects of toxin intrusions. The model suggests that in order to do so, the agents should adjust their resource consumption based on two factors: 1) their ranked proximity to the common wealth and 2) the potential damage caused by toxins. We verified that liver cells do the same.","Sheikh-Bahaei S,Kim SH,Hunt CA",,,Multi-agent based modeling of liver detoxification,,, , Conference Paper,,"AbstractUsing game theory and reinforcement learning, we created and analyzed generalized agent-based models of hepatic toxin elimination processes to explore plausible causes of hepatic functional zonation. We considered a general situation in which a group of protective agents (analogous to liver cells) cooperate and self-organize their efforts to minimize optimally the negative effects of toxin intrusions. The model suggests that in order to do so, the agents should adjust their resource consumption based on two factors: 1) their ranked proximity to the common wealth and 2) the potential damage caused by toxins. We verified that liver cells do the same.",,,,,SCS/ACM ,"Proceedings of the 2009 Spring Simulation Multiconference, SpringSim 2009, San Diego, California, USA, March 22-27, 2009  ",,out_of_scope,
2881,"**Title**Particle Transfer and Detection in a Microspheres Based Detoxification System

**Abstract**AbstractExtracorporeal blood purification by means of the adsorption system MDS is based on high specific microparticle adsorbent for toxin removal. A thin-wall hollow-fiber membrane filter separates the microparticle-plasma suspension from the bloodstream. For patient safety, it is necessary to have a means to detect membrane ruptures that could lead to a release of microparticles into the patient's bloodstream. A non invasive optical detection system was developed to monitor the extracorporeal venous bloodstream for the presence of released microparticles. For detection, labeled microspheres are suspended with the adsorbent particles. In the case of a membrane rupture, the labeled particles would be released together with the microadsorbent. A detailed description for the system setup is introduced.","Brandl M,Hartmann J,Posnicek T,Falkenhagen D",,,Particle Transfer and Detection in a Microspheres Based Detoxification System,,,10.1109/BIOTECHNO.2008.16 , Conference Paper,,"AbstractExtracorporeal blood purification by means of the adsorption system MDS is based on high specific microparticle adsorbent for toxin removal. A thin-wall hollow-fiber membrane filter separates the microparticle-plasma suspension from the bloodstream. For patient safety, it is necessary to have a means to detect membrane ruptures that could lead to a release of microparticles into the patient's bloodstream. A non invasive optical detection system was developed to monitor the extracorporeal venous bloodstream for the presence of released microparticles. For detection, labeled microspheres are suspended with the adsorbent particles. In the case of a membrane rupture, the labeled particles would be released together with the microadsorbent. A detailed description for the system setup is introduced.",,,,,IEEE Computer Society ,"International Conference on Biocomputation, Bioinformatics, and Biomedical Technologies, BIOTECHNO 2008, June 29 - July 5, 2008, Bucharest, Romania  ",,out_of_scope,
2882,"**Title**Activités de biotransformation et de séquestration des fusariotoxines chez les bactéries fermentaires pour la détoxification des ensilages de maïs

**Abstract**Résumé 


                    en
                

                    fr
                



                    The contamination of silages by fusariotoxins takes place in the field, independantly from any problem of conservation. Ingestion by livestock of silage with high concentration of these mycotoxins can cause a reduction of performances and affects animal health. Due to the partial efficiency of preventive measures and the inadaptability of physical and chemical detoxification, the use of biological detoxification methods seems a valid alternative to explore. The objective of this work was to test the ability of fermentative bacteria to remove fusariotoxins. The screening of 202 strains of fermentative bacteria for their ability to biotransform and/or bind deoxynivalenol (DON), zearalenone (ZEN) and fumonisins B1 and B2 (FB1 and FB2) showed that binding of these major fusariotoxins is widespread in these microorganisms. The genera Streptococcus and Enterococcus were the most effective with up of 33%, 49%, 24% and 62% of DON, ZEN, FB1 and FB2 bound, respectively. This property could decrease bioavailability of ingested fusariotoxins in animals and, thus effectively reducing their toxicity. In addition, about 5% (11/202) of tested strains biotransformed ZEN into its activated form, zearalenol. The binding interaction was further studied in FB, I showed that peptidoglycan from bacterial cell wall is likely the binding site of FB1 and FB2 which are bound by their tricarballylic acid chains (TCA). The large difference in binding observed with these two analogues (FB2 > FB1) was elucidated by molecular modelling that showed that the additional hydroxyl group in FB1 form an hydrogen bond with one TCA decreasing the binding property. Experiments showed that a large fraction of ZEN can also be bound instantaneously by ruminal fluid, forming a complex that, under conditions simulating the abomasum and small intestine, was as stable as that formed between Streptococci and ZEN. This binding by ruminal fluid could contribute to the resistance of ruminants to the effects of fusariotoxins. The use of fermentative bacteria to reduce toxicity could be more useful in monogastric animals like pig. However, in vivo studies are needed to evaluate the real impact of this technology. At term, the ability of fermentative bacteria to bind fusariotoxins could advantageously supplement the acidifying or probiotic properties of bacterial inoculants used in animal nutrition.
                

                    La contamination des ensilages par les fusariotoxines intervient au champ, indépendamment de tout problème de conservation. L'ingestion par les animaux d'élevage de teneurs trop élevées de ces mycotoxines peut entraîner une altération des performances zootechniques et des effets sur la santé des animaux. Face au succès partiel des méthodes de prévention et à l'inadaptibilité des méthodes physiques et chimiques de détoxification, l'utilisation des propriétés de certains microorganismes apparaît comme une alternative à considérer. L'objectif de ce travail est d'explorer la capacité des bactéries fermentaires à éliminer les fusariotoxines en vue de leur utilisation comme agent de détoxification des ensilages. Le criblage de 202 souches de bactéries fermentaires pour leur capacité à biotransformer et / ou séquestrer le déoxynivalénol (DON), la zéaralénone (ZEN) et les fumonisines B1 et B2 (FB1 et FB2) a montré que la séquestration de ces ces fusariotoxines majeures est une activité répandue chez ces microorganismes, les genres Streptococcus et Enterococcus apparaissant comme les plus efficaces en éliminant jusqu'à 33%, 49%, 24% et 62% de DON, ZEN, FB1 et FB2, respectivement. Cette propriété pourrait diminuer la biodisponibilité des fusariotoxines chez l'animal et, par conséquent, réduire leur effet toxique. D'autre part, environ 5% (11/202) des souches testées ont biotransformé la ZEN en sa forme activée, l'alpha zéaralénol. Nous avons ensuite montré que la séquestration des fumonisines B1 et B2 fait intervenir le peptidoglycane de la paroi bactérienne et les bras d'acide tricarballylique (TCA) des fumonisines. La différence de séquestration de ces deux analogues (FB2>FB1) a été élucidé par une méthode de modélisation moléculaire qui a montré que le groupe hydroxyle additionnel de la FB1 forme une liaison hydrogène avec un des TCA, limitant ainsi la possibilité de séquestration. Des essais ont montré qu'une fraction importante de ZEN était aussi instantanément séquestrée par la flore du contenu ruminal, formant un complexe aussi stable dans des conditions simulant les compartiments post-ruminaux du tube digestif que celui formé entre des Streptococci et la ZEN. Ce niveau de séquestration pourrait contribuer à la plus forte résistance des ruminants aux effets des fusariotoxines. En conséquence, l'ajout de bactéries fermentaires pourrait être davantage utile à des animaux monogastriques plus sensibles comme le porc. Des essais in vivo sont cependant nécessaires pour en évaluer l'impact réel. Optimisée, la capacité des bactéries fermentaires à séquestrer les fusariotoxines pourrait compléter avantageusement les propriétés acidifiantes ou probiotiques des inoculants bactériens utilisés en nutrition animale",Niderkorn V,,,Activités de biotransformation et de séquestration des fusariotoxines chez les bactéries fermentaires pour la détoxification des ensilages de maïs,,, , Ph.D. Thesis,,"Résumé 


                    en
                

                    fr
                



                    The contamination of silages by fusariotoxins takes place in the field, independantly from any problem of conservation. Ingestion by livestock of silage with high concentration of these mycotoxins can cause a reduction of performances and affects animal health. Due to the partial efficiency of preventive measures and the inadaptability of physical and chemical detoxification, the use of biological detoxification methods seems a valid alternative to explore. The objective of this work was to test the ability of fermentative bacteria to remove fusariotoxins. The screening of 202 strains of fermentative bacteria for their ability to biotransform and/or bind deoxynivalenol (DON), zearalenone (ZEN) and fumonisins B1 and B2 (FB1 and FB2) showed that binding of these major fusariotoxins is widespread in these microorganisms. The genera Streptococcus and Enterococcus were the most effective with up of 33%, 49%, 24% and 62% of DON, ZEN, FB1 and FB2 bound, respectively. This property could decrease bioavailability of ingested fusariotoxins in animals and, thus effectively reducing their toxicity. In addition, about 5% (11/202) of tested strains biotransformed ZEN into its activated form, zearalenol. The binding interaction was further studied in FB, I showed that peptidoglycan from bacterial cell wall is likely the binding site of FB1 and FB2 which are bound by their tricarballylic acid chains (TCA). The large difference in binding observed with these two analogues (FB2 > FB1) was elucidated by molecular modelling that showed that the additional hydroxyl group in FB1 form an hydrogen bond with one TCA decreasing the binding property. Experiments showed that a large fraction of ZEN can also be bound instantaneously by ruminal fluid, forming a complex that, under conditions simulating the abomasum and small intestine, was as stable as that formed between Streptococci and ZEN. This binding by ruminal fluid could contribute to the resistance of ruminants to the effects of fusariotoxins. The use of fermentative bacteria to reduce toxicity could be more useful in monogastric animals like pig. However, in vivo studies are needed to evaluate the real impact of this technology. At term, the ability of fermentative bacteria to bind fusariotoxins could advantageously supplement the acidifying or probiotic properties of bacterial inoculants used in animal nutrition.
                

                    La contamination des ensilages par les fusariotoxines intervient au champ, indépendamment de tout problème de conservation. L'ingestion par les animaux d'élevage de teneurs trop élevées de ces mycotoxines peut entraîner une altération des performances zootechniques et des effets sur la santé des animaux. Face au succès partiel des méthodes de prévention et à l'inadaptibilité des méthodes physiques et chimiques de détoxification, l'utilisation des propriétés de certains microorganismes apparaît comme une alternative à considérer. L'objectif de ce travail est d'explorer la capacité des bactéries fermentaires à éliminer les fusariotoxines en vue de leur utilisation comme agent de détoxification des ensilages. Le criblage de 202 souches de bactéries fermentaires pour leur capacité à biotransformer et / ou séquestrer le déoxynivalénol (DON), la zéaralénone (ZEN) et les fumonisines B1 et B2 (FB1 et FB2) a montré que la séquestration de ces ces fusariotoxines majeures est une activité répandue chez ces microorganismes, les genres Streptococcus et Enterococcus apparaissant comme les plus efficaces en éliminant jusqu'à 33%, 49%, 24% et 62% de DON, ZEN, FB1 et FB2, respectivement. Cette propriété pourrait diminuer la biodisponibilité des fusariotoxines chez l'animal et, par conséquent, réduire leur effet toxique. D'autre part, environ 5% (11/202) des souches testées ont biotransformé la ZEN en sa forme activée, l'alpha zéaralénol. Nous avons ensuite montré que la séquestration des fumonisines B1 et B2 fait intervenir le peptidoglycane de la paroi bactérienne et les bras d'acide tricarballylique (TCA) des fumonisines. La différence de séquestration de ces deux analogues (FB2>FB1) a été élucidé par une méthode de modélisation moléculaire qui a montré que le groupe hydroxyle additionnel de la FB1 forme une liaison hydrogène avec un des TCA, limitant ainsi la possibilité de séquestration. Des essais ont montré qu'une fraction importante de ZEN était aussi instantanément séquestrée par la flore du contenu ruminal, formant un complexe aussi stable dans des conditions simulant les compartiments post-ruminaux du tube digestif que celui formé entre des Streptococci et la ZEN. Ce niveau de séquestration pourrait contribuer à la plus forte résistance des ruminants aux effets des fusariotoxines. En conséquence, l'ajout de bactéries fermentaires pourrait être davantage utile à des animaux monogastriques plus sensibles comme le porc. Des essais in vivo sont cependant nécessaires pour en évaluer l'impact réel. Optimisée, la capacité des bactéries fermentaires à séquestrer les fusariotoxines pourrait compléter avantageusement les propriétés acidifiantes ou probiotiques des inoculants bactériens utilisés en nutrition animale",,,,, ,  ,,out_of_scope,
2883,No abstract available,"Sun J,Pan Y,Yan X",,,Improving intermediate reasoning in zero-shot chain-of-thought for large language models with filter supervisor-self correction,620,,10.1016/J.NEUCOM.2024.129219 , Journal Article,,,,,,, Neurocomputing,  ,,out_of_scope,
2884,"**Title**ProgCo: Program Helps Self-Correction of Large Language Models

**Abstract**Abstract:Self-Correction aims to enable large language models (LLMs) to self-verify and self-refine their initial responses without external feedback. However, LLMs often fail to effectively self-verify and generate correct feedback, further misleading refinement and leading to the failure of self-correction, especially in complex reasoning tasks. In this paper, we propose Program-driven Self-Correction (ProgCo). First, program-driven verification (ProgVe) achieves complex verification logic and extensive validation through self-generated, self-executing verification pseudo-programs. Then, program-driven refinement (ProgRe) receives feedback from ProgVe, conducts dual reflection and refinement on both responses and verification programs to mitigate misleading of incorrect feedback in complex reasoning tasks. Experiments on three instruction-following and mathematical benchmarks indicate that ProgCo achieves effective self-correction, and can be further enhance performance when combined with real program tools.","Song X,Wu Y,Wang W,Liu J,Su W,Zheng B",,,ProgCo: Program Helps Self-Correction of Large Language Models,abs/2501.01264,,10.48550/ARXIV.2501.01264 , Journal Article,,"Abstract:Self-Correction aims to enable large language models (LLMs) to self-verify and self-refine their initial responses without external feedback. However, LLMs often fail to effectively self-verify and generate correct feedback, further misleading refinement and leading to the failure of self-correction, especially in complex reasoning tasks. In this paper, we propose Program-driven Self-Correction (ProgCo). First, program-driven verification (ProgVe) achieves complex verification logic and extensive validation through self-generated, self-executing verification pseudo-programs. Then, program-driven refinement (ProgRe) receives feedback from ProgVe, conducts dual reflection and refinement on both responses and verification programs to mitigate misleading of incorrect feedback in complex reasoning tasks. Experiments on three instruction-following and mathematical benchmarks indicate that ProgCo achieves effective self-correction, and can be further enhance performance when combined with real program tools.",,,,, CoRR,  ,,out_of_scope,
2885,"**Title**Small Language Model Can Self-Correct

**Abstract**Generative Language Models (LMs) such as ChatGPT have exhibited remarkable performance across various downstream tasks. Nevertheless, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. Previous studies have devised sophisticated pipelines and prompts to induce large LMs to exhibit the capability for self-correction. However, large LMs are explicitly prompted to verify and modify their answers separately rather than completing all steps spontaneously like humans. Moreover, these complex prompts are extremely challenging for small LMs to follow. In this paper, we introduce the Intrinsic Self-Correction (ISC) in generative language models, aiming to correct the initial output of LMs in a self-triggered manner, even for those small LMs with 6 billion parameters. Specifically, we devise a pipeline for constructing self-correction data and propose Partial Answer Masking (PAM), aiming to endow the model with the capability for intrinsic self-correction through fine-tuning. We conduct experiments using LMs with parameters sizes ranging from 6 billion to 13 billion in two tasks, including commonsense reasoning and factual knowledge reasoning. Our experiments demonstrate that the outputs generated using ISC outperform those generated without self-correction. We believe that the output quality of even small LMs can be further improved by empowering them with the ability to intrinsic self-correct.","Han H,Liang J,Shi J,He Q,Xiao Y",,,Small Language Model Can Self-Correct,,,10.1609/AAAI.V38I16.29774 , Conference Paper,,"Generative Language Models (LMs) such as ChatGPT have exhibited remarkable performance across various downstream tasks. Nevertheless, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. Previous studies have devised sophisticated pipelines and prompts to induce large LMs to exhibit the capability for self-correction. However, large LMs are explicitly prompted to verify and modify their answers separately rather than completing all steps spontaneously like humans. Moreover, these complex prompts are extremely challenging for small LMs to follow. In this paper, we introduce the Intrinsic Self-Correction (ISC) in generative language models, aiming to correct the initial output of LMs in a self-triggered manner, even for those small LMs with 6 billion parameters. Specifically, we devise a pipeline for constructing self-correction data and propose Partial Answer Masking (PAM), aiming to endow the model with the capability for intrinsic self-correction through fine-tuning. We conduct experiments using LMs with parameters sizes ranging from 6 billion to 13 billion in two tasks, including commonsense reasoning and factual knowledge reasoning. Our experiments demonstrate that the outputs generated using ISC outperform those generated without self-correction. We believe that the output quality of even small LMs can be further improved by empowering them with the ability to intrinsic self-correct.",,,,,AAAI Press ,"Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada  ",,out_of_scope,
2886,"**Title**CorNav: Autonomous Agent with Self-Corrected Planning for Zero-Shot Vision-and-Language Navigation

**Abstract**Understanding and following natural language
    instructions while navigating through com-
    plex, real-world environments poses a sig-
    nificant challenge for general-purpose robots.
   These environments often include obstacles
   and pedestrians, making  it essential for au-
   tonomous agents to possess the capability
    of self-corrected planning to adjust their ac-
    tions based on feedback from the surroundings.
    However, the majority of existing vision-and-
    language navigation (VLN) methods primar-
     ily operate in less realistic simulator settings
    and do not incorporate environmental feedback
    into their decision-making processes. To ad-
    dress this gap, we introduce a novel zero-shot
    framework called CorNav, utilizing a large lan-
    guage model for decision-making and compris-
    ing two key components: 1) incorporating en-
    vironmental feedback for refining future plans
   and adjusting its actions, and 2) multiple do-
   main experts for parsing instructions, scene un-
    derstanding, and refining predicted actions. In
    addition to the framework, we develop a 3D
    simulator that renders realistic scenarios using
    Unreal Engine 5. To evaluate the effectiveness
   and generalization of navigation agents in a
    zero-shot multi-task setting, we create a bench-
   mark called NavBench. Our empirical study in-
    volves deploying 7 baselines across four tasks,
      i.e., goal-conditioned navigation given a spe-
     cific object category, goal-conditioned naviga-
    tion given simple instructions, finding abstract
    objects based on high-level instructions, and
    step-by-step instruction following. Extensive
    experiments demonstrate that CorNav consis-
     tently outperforms all baselines by a significant
    margin across all tasks.

1  Introduction

Language-driven navigation is a critical skill for
robot assistants when it comes to performing a

    ∗Equal contribution.
    †Corresponding author.Figure 1: Comparison with existing VLN agents. (a)
The single agent planning paradigm requires the agent
to analyse and make decisions by itself. (b) Multi-agent
planning paradigm enables the agent to communicate
with multiple experts and perform complex reasoning.
(c) Our self-corrected planning considers in-plan or out-
of-plan feedback from a near-realistic environment.


wide range of real-world tasks. Most autonomous
agents are trained using predefined datasets and
tasks, and perform well in familiar environments.
However, the real world is filled with a multitude of
objects and scenes, making it challenging to train
an agent that can generalize effectively. Recently,
large language models (LLMs) (Chowdhery et al.,
2022; OpenAI, 2023; Touvron et al., 2023; Chiang
et al., 2023; Geng et al., 2023) have demonstrated
remarkable effectiveness across various tasks and
have emerged as versatile autonomous agents capa-
ble of informed decision-making (Sun et al., 2023;
Wang et al., 2023; Sumers et al., 2023). These
LLMs are pre-trained on massive textual data, en-
dowing them with extensive commonsense knowl-
edge that proves invaluable for navigation tasks.
For instance, they can infer that a stove is likely to
be found in the kitchen and that a bed is typically
located in a bedroom.
  The success of GPT has highlighted the efficacy
of utilizing human instructions for zero-shot navi-12538(a) Single Agent Planning

        Plan           Observation
Planner                Environment

       (b) Multi-Agent Planning     (c) Self-Corrected Planning


         Communication

Planner                     Expert             Plan Refiner



Out-of-Plan/In-Plan FeedbackPlannerCommunicationEnvironmentExpertEnvironment","Liang X,Ma L,Guo S,Han J,Xu H,Ma S,Liang X",,,CorNav: Autonomous Agent with Self-Corrected Planning for Zero-Shot Vision-and-Language Navigation,,,10.18653/V1/2024.FINDINGS-ACL.745 , Conference Paper,,"Understanding and following natural language
    instructions while navigating through com-
    plex, real-world environments poses a sig-
    nificant challenge for general-purpose robots.
   These environments often include obstacles
   and pedestrians, making  it essential for au-
   tonomous agents to possess the capability
    of self-corrected planning to adjust their ac-
    tions based on feedback from the surroundings.
    However, the majority of existing vision-and-
    language navigation (VLN) methods primar-
     ily operate in less realistic simulator settings
    and do not incorporate environmental feedback
    into their decision-making processes. To ad-
    dress this gap, we introduce a novel zero-shot
    framework called CorNav, utilizing a large lan-
    guage model for decision-making and compris-
    ing two key components: 1) incorporating en-
    vironmental feedback for refining future plans
   and adjusting its actions, and 2) multiple do-
   main experts for parsing instructions, scene un-
    derstanding, and refining predicted actions. In
    addition to the framework, we develop a 3D
    simulator that renders realistic scenarios using
    Unreal Engine 5. To evaluate the effectiveness
   and generalization of navigation agents in a
    zero-shot multi-task setting, we create a bench-
   mark called NavBench. Our empirical study in-
    volves deploying 7 baselines across four tasks,
      i.e., goal-conditioned navigation given a spe-
     cific object category, goal-conditioned naviga-
    tion given simple instructions, finding abstract
    objects based on high-level instructions, and
    step-by-step instruction following. Extensive
    experiments demonstrate that CorNav consis-
     tently outperforms all baselines by a significant
    margin across all tasks.

1  Introduction

Language-driven navigation is a critical skill for
robot assistants when it comes to performing a

    ∗Equal contribution.
    †Corresponding author.Figure 1: Comparison with existing VLN agents. (a)
The single agent planning paradigm requires the agent
to analyse and make decisions by itself. (b) Multi-agent
planning paradigm enables the agent to communicate
with multiple experts and perform complex reasoning.
(c) Our self-corrected planning considers in-plan or out-
of-plan feedback from a near-realistic environment.


wide range of real-world tasks. Most autonomous
agents are trained using predefined datasets and
tasks, and perform well in familiar environments.
However, the real world is filled with a multitude of
objects and scenes, making it challenging to train
an agent that can generalize effectively. Recently,
large language models (LLMs) (Chowdhery et al.,
2022; OpenAI, 2023; Touvron et al., 2023; Chiang
et al., 2023; Geng et al., 2023) have demonstrated
remarkable effectiveness across various tasks and
have emerged as versatile autonomous agents capa-
ble of informed decision-making (Sun et al., 2023;
Wang et al., 2023; Sumers et al., 2023). These
LLMs are pre-trained on massive textual data, en-
dowing them with extensive commonsense knowl-
edge that proves invaluable for navigation tasks.
For instance, they can infer that a stove is likely to
be found in the kitchen and that a bed is typically
located in a bedroom.
  The success of GPT has highlighted the efficacy
of utilizing human instructions for zero-shot navi-12538(a) Single Agent Planning

        Plan           Observation
Planner                Environment

       (b) Multi-Agent Planning     (c) Self-Corrected Planning


         Communication

Planner                     Expert             Plan Refiner



Out-of-Plan/In-Plan FeedbackPlannerCommunicationEnvironmentExpertEnvironment",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024  ",,out_of_scope,
2887,"**Title**Small Language Models Need Strong Verifiers to Self-Correct Reasoning

**Abstract**Self-correction has emerged as a promising so-
    lution to boost the reasoning performance of
    large language models (LLMs), where LLMs
    refine their solutions using self-generated cri-
    tiques that pinpoint the errors. This work ex-
    plores whether small (≤13B) language models   (LMs) have the ability of self-correction on rea-
    soning tasks with minimal inputs from stronger
   LMs. We propose a novel pipeline that prompts
    smaller LMs to collect self-correction data that
    supports the training of self-refinement abil-
     ities.  First, we leverage correct solutions to
    guide the model in critiquing their incorrect
    responses. Second, the generated critiques, af-
     ter filtering, are used for supervised fine-tuning
    of the self-correcting reasoner through solu-
    tion refinement. Our experimental results show
    improved self-correction abilities of two mod-
     els on five datasets spanning math and com-
    monsense reasoning, with notable performance
    gains when paired with a strong GPT-4-based
     verifier, though limitations are identified when
    using a weak self-verifier for determining when
    to correct.1

1  Introduction

Recent research shows that large language mod-
els (LLMs) (OpenAI, 2023) can self-correct their
responses to meet diverse user requirements, rang-
ing from diminishing harmful content to including
specific keywords and to debugging code (Madaan
et al., 2023; Chen et al., 2023b). Self-correction
is typically accomplished by first generating a cri-
tique that identifies the shortcomings of the initial
response, followed by revising it according to the
self-critique—a process that can be iterated.
  Self-correction has emerged as an intriguing
paradigm for rectifying the flaws in LLM’s out-
puts (Pan et al., 2023).  However, models that

    * Correspondence to yunxiang@umich.edu
   1Our implementation can be accessed at https://github.
com/yunx-z/SCORE.are effective at self-correction are of very large
sizes, and many of them are proprietary and ac-
cessible only via APIs. In this work, we focus on
the self-correction abilities of small, open-source
language models (LMs).2 Previous studies have
shown that these smaller models can learn self-
correction in reasoning through distillation from
stronger LMs (Yu et al., 2023b; An et al., 2023;
Han et al., 2024). Yet this poses security risks for
high-stakes domains and hinders the scientific un-
derstanding of enhancing LMs’ ability to correct
errors. We thus ask the question: To which degree
do small LMs require guidance from strong LMs to
learn self-correction for reasoning?
  We study this question by leveraging the small
model itself to generate supervised training data
to enhance its self-correction ability, instead of re-
sorting to stronger LMs. To this end, we draw
inspiration from the rejection sampling fine-tuning
(RFT) (Touvron et al., 2023; Yuan et al., 2023)
method where LLM’s reasoning skills are boot-
strapped via diverse chain-of-thought sampling and
supervised fine-tuning on the correct reasoning
chains. We propose SCORE—an approach to
bootstrap small LMs’ Self-COrrection ability in
REasoning tasks. Concretely, we devise a pipeline
for accumulating high-quality critique-correction
data from small LMs, which are used for super-
vised fine-tuning of self-correcting reasoners. First,
we leverage correct solutions as hints for the base
LMs to critique incorrect answers. By reverse-
engineering from the correct answer, the models
generate more effective critiques. Second, we filter
these critiques for correctness, well-formedness,
and clarity using simple rule-based and prompting
methods. Finally, we fine-tune the same LMs to be-

   2While the distinction between small vs. large LMs is often
context-dependent (Saunders et al., 2022; Yu et al., 2023b),
in this work, we interchangeably use “small” or “weak” LMs
to refer to open models with a few billion parameters (e.g.,
LLaMA-7/13B (Touvron et al., 2023)).15637","Zhang Y,Khalifa M,Logeswaran L,Kim J,Lee M,Lee H,Wang L",,,Small Language Models Need Strong Verifiers to Self-Correct Reasoning,,,10.18653/V1/2024.FINDINGS-ACL.924 , Conference Paper,,"Self-correction has emerged as a promising so-
    lution to boost the reasoning performance of
    large language models (LLMs), where LLMs
    refine their solutions using self-generated cri-
    tiques that pinpoint the errors. This work ex-
    plores whether small (≤13B) language models   (LMs) have the ability of self-correction on rea-
    soning tasks with minimal inputs from stronger
   LMs. We propose a novel pipeline that prompts
    smaller LMs to collect self-correction data that
    supports the training of self-refinement abil-
     ities.  First, we leverage correct solutions to
    guide the model in critiquing their incorrect
    responses. Second, the generated critiques, af-
     ter filtering, are used for supervised fine-tuning
    of the self-correcting reasoner through solu-
    tion refinement. Our experimental results show
    improved self-correction abilities of two mod-
     els on five datasets spanning math and com-
    monsense reasoning, with notable performance
    gains when paired with a strong GPT-4-based
     verifier, though limitations are identified when
    using a weak self-verifier for determining when
    to correct.1

1  Introduction

Recent research shows that large language mod-
els (LLMs) (OpenAI, 2023) can self-correct their
responses to meet diverse user requirements, rang-
ing from diminishing harmful content to including
specific keywords and to debugging code (Madaan
et al., 2023; Chen et al., 2023b). Self-correction
is typically accomplished by first generating a cri-
tique that identifies the shortcomings of the initial
response, followed by revising it according to the
self-critique—a process that can be iterated.
  Self-correction has emerged as an intriguing
paradigm for rectifying the flaws in LLM’s out-
puts (Pan et al., 2023).  However, models that

    * Correspondence to yunxiang@umich.edu
   1Our implementation can be accessed at https://github.
com/yunx-z/SCORE.are effective at self-correction are of very large
sizes, and many of them are proprietary and ac-
cessible only via APIs. In this work, we focus on
the self-correction abilities of small, open-source
language models (LMs).2 Previous studies have
shown that these smaller models can learn self-
correction in reasoning through distillation from
stronger LMs (Yu et al., 2023b; An et al., 2023;
Han et al., 2024). Yet this poses security risks for
high-stakes domains and hinders the scientific un-
derstanding of enhancing LMs’ ability to correct
errors. We thus ask the question: To which degree
do small LMs require guidance from strong LMs to
learn self-correction for reasoning?
  We study this question by leveraging the small
model itself to generate supervised training data
to enhance its self-correction ability, instead of re-
sorting to stronger LMs. To this end, we draw
inspiration from the rejection sampling fine-tuning
(RFT) (Touvron et al., 2023; Yuan et al., 2023)
method where LLM’s reasoning skills are boot-
strapped via diverse chain-of-thought sampling and
supervised fine-tuning on the correct reasoning
chains. We propose SCORE—an approach to
bootstrap small LMs’ Self-COrrection ability in
REasoning tasks. Concretely, we devise a pipeline
for accumulating high-quality critique-correction
data from small LMs, which are used for super-
vised fine-tuning of self-correcting reasoners. First,
we leverage correct solutions as hints for the base
LMs to critique incorrect answers. By reverse-
engineering from the correct answer, the models
generate more effective critiques. Second, we filter
these critiques for correctness, well-formedness,
and clarity using simple rule-based and prompting
methods. Finally, we fine-tune the same LMs to be-

   2While the distinction between small vs. large LMs is often
context-dependent (Saunders et al., 2022; Yu et al., 2023b),
in this work, we interchangeably use “small” or “weak” LMs
to refer to open models with a few billion parameters (e.g.,
LLaMA-7/13B (Touvron et al., 2023)).15637",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024  ",,out_of_scope,
2888,"**Title**Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation

**Abstract**While large language models (LLMs) pre-
    trained on massive amounts of unpaired
   language data have reached the state-of-
    the-art in machine translation (MT) of gen-
    eral domain texts, post-editing (PE) is still
    required to correct errors and to enhance
   term translation quality in specialized do-
    mains.  In this paper we present a pilot
    study of enhancing translation memories
   (TM) produced by PE (source segments,
   machine translations, and reference trans-
    lations, henceforth called PE-TM) for the
   needs of correct and consistent term trans-
    lation in technical domains.
  We investigate a light-weight two-step sce-
    nario where, at inference time, a human
    translator marks errors in the first transla-
    tion step, and in a second step a few sim-
     ilar examples are extracted from the PE-
  TM to prompt an LLM. Our experiment
   shows that the additional effort of augment-
    ing translations with human error markings
    guides the LLM to focus on a correction of
    the marked errors, yielding consistent im-
   provements over automatic PE (APE) and
  MT from scratch.

1  Introduction

Technical translation at large enterprises involves
a large number of translation domains, for which
translation memories and terminologies need to

∗The work was done as part of an SAP sponsored PhD project
of the first author.
∗© 2024 The authors. This article is licensed under a Creative
Commons 4.0 licence, no derivative works, attribution, CC-
BY-ND.be maintained to support multi-domain MT sys-
tems and human post-editors in producing contextu-
ally adequate and consistent translation of technical
terms (Exel et al., 2020). In this paper, we ask if on-
going human post-editing efforts that produce large
databases consisting of source segments, machine
translations, and reference translations, can be en-
hanced by light-weight human error markings. This
could then be used to teach a translation system a
focused self-correction of marked erroneous tokens
from similar examples with error markings and cor-
rections found in the PE-TM. Such a setup could
complement translation memories and terminology
databases by up-to-date and domain-specific infor-
mation in the PE-TM, and be used in a scenario
where a user marks errors in MT hypotheses. In-
context examples with high source-side similarity
are then extracted from the PE-TM to prompt an
LLM to focus on a correction of the marked error
interactively.
  We present a pilot study where we construct a
PE-TM for the IT domain, which is augmented
by human error markings on machine translations.
While for training purposes, error markings for the
PE-TM could be obtained by automatic matching
against human post-edits, this cannot be done at test
time. We envisage a scenario where the error mark-
ings in the PE-TM are obtained by direct human
annotation, simulating a realistic setup where a user
only performs the light-weight task of error mark-
ing at test time. Such a scenario could be feedback
collection in the publishing of raw-MT. Raw-MT
could be shown to end-users who, if they notice an
error in the translation, proceed to annotate tokens
in the translation they perceive to be incorrect. The
translation would then be flagged for review by a hu-
man translator, who then post-edits the translation
and publishes their correction. This process results636","Berger N,Riezler S,Exel M,Huck M",,,Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation,,, , Conference Paper,,"While large language models (LLMs) pre-
    trained on massive amounts of unpaired
   language data have reached the state-of-
    the-art in machine translation (MT) of gen-
    eral domain texts, post-editing (PE) is still
    required to correct errors and to enhance
   term translation quality in specialized do-
    mains.  In this paper we present a pilot
    study of enhancing translation memories
   (TM) produced by PE (source segments,
   machine translations, and reference trans-
    lations, henceforth called PE-TM) for the
   needs of correct and consistent term trans-
    lation in technical domains.
  We investigate a light-weight two-step sce-
    nario where, at inference time, a human
    translator marks errors in the first transla-
    tion step, and in a second step a few sim-
     ilar examples are extracted from the PE-
  TM to prompt an LLM. Our experiment
   shows that the additional effort of augment-
    ing translations with human error markings
    guides the LLM to focus on a correction of
    the marked errors, yielding consistent im-
   provements over automatic PE (APE) and
  MT from scratch.

1  Introduction

Technical translation at large enterprises involves
a large number of translation domains, for which
translation memories and terminologies need to

∗The work was done as part of an SAP sponsored PhD project
of the first author.
∗© 2024 The authors. This article is licensed under a Creative
Commons 4.0 licence, no derivative works, attribution, CC-
BY-ND.be maintained to support multi-domain MT sys-
tems and human post-editors in producing contextu-
ally adequate and consistent translation of technical
terms (Exel et al., 2020). In this paper, we ask if on-
going human post-editing efforts that produce large
databases consisting of source segments, machine
translations, and reference translations, can be en-
hanced by light-weight human error markings. This
could then be used to teach a translation system a
focused self-correction of marked erroneous tokens
from similar examples with error markings and cor-
rections found in the PE-TM. Such a setup could
complement translation memories and terminology
databases by up-to-date and domain-specific infor-
mation in the PE-TM, and be used in a scenario
where a user marks errors in MT hypotheses. In-
context examples with high source-side similarity
are then extracted from the PE-TM to prompt an
LLM to focus on a correction of the marked error
interactively.
  We present a pilot study where we construct a
PE-TM for the IT domain, which is augmented
by human error markings on machine translations.
While for training purposes, error markings for the
PE-TM could be obtained by automatic matching
against human post-edits, this cannot be done at test
time. We envisage a scenario where the error mark-
ings in the PE-TM are obtained by direct human
annotation, simulating a realistic setup where a user
only performs the light-weight task of error mark-
ing at test time. Such a scenario could be feedback
collection in the publishing of raw-MT. Raw-MT
could be shown to end-users who, if they notice an
error in the translation, proceed to annotate tokens
in the translation they perceive to be incorrect. The
translation would then be flagged for review by a hu-
man translator, who then post-edits the translation
and publishes their correction. This process results636",,,,,European Association for Machine Translation (EAMT) ,"Proceedings of the 25th Annual Conference of the European Association for Machine Translation (Volume 1), EAMT 2024, Sheffield, UK, June 24-27, 2024  ",,out_of_scope,
2889,"**Title**Large Language Models Can Self-Correct with Key Condition Verification

**Abstract**Intrinsic self-correct was a method that in-
    structed large language models (LLMs) to ver-
     ify and correct their responses without exter-
    nal feedback.  Unfortunately, the study con-
    cluded that the LLMs could not self-correct
    reasoning yet. We find that a simple yet effec-
     tive prompting method enhances LLM perfor-
   mance in identifying and correcting inaccurate
    answers without external feedback.  That is
    to mask a key condition in the question, add
    the current response to construct a verification
    question, and predict the condition to verify the
    response. The condition can be an entity in an
    open-domain question or a numerical value in
    an arithmetic question, which requires minimal
     effort (via prompting) to identify. We propose
    an iterative verify-then-correct framework to
    progressively identify and correct (probably)
     false responses, named PROCO. We conduct
    experiments on three reasoning tasks. On av-
    erage, PROCO, with GPT-3.5-Turbo-1106 as
    the backend LLM, yields +6.8 exact match on
    four open-domain question answering datasets,
   +14.1 accuracy on three arithmetic reasoning
     datasets, and +9.6 accuracy on a commonsense
    reasoning dataset, compared to Self-Correct.
   Our implementation is made publicly avail-
    able at https://wzy6642.github.io/proco.
    github.io/.
1  Introduction
Reasoning is a cognitive process that uses evidence,
arguments, and logic to arrive at conclusions or
judgements (Huang and Chang, 2023). People have
been exploiting and improving the reasoning abil-
ity of large language models (LLMs). Wei et al.
(2022) proposed chain-of-thought (CoT) prompt-
ing and yielded promising results on several rea-
soning tasks, such as arithmetic reasoning (Kojima
et al., 2022; Zhou et al., 2023), commonsense rea-
soning (Wei et al., 2022; Zhang et al., 2023; Wang
   *Equal contribution.
   †Corresponding author. Method       NQ     CSQA    AQuA
 CoT               40.3        72.9        51.3
 Self-Correct        40.1        65.9        48.7
 PROCO (Ours)     48.0        75.5        65.2

Table 1: Performance comparison of different prompt-
ing methods using GPT-3.5-Turbo as backend LLM.


et al., 2023b), and open-domain question answer-
ing (Wang et al., 2023a), using only a few or no rea-
soning exemplars. CoT guides LLMs to generate
intermediate reasoning paths instead of generating
the final answer directly, which helps the LLMs
simulate the human-like reasoning process.
  Although CoT enables LLMs to handle com-
plex reasoning tasks, they are sensitive to mistakes
in the reasoning path, as any mistake can lead to
an incorrect answer. To address this issue, Dhuli-
awala et al. (2023); Kim et al. (2023) have explored
verifying and correcting responses generated by
LLMs. For example, as shown in Figure 1a, for
a given question and its initial LLM-generated an-
swer, Self-Correct (Kim et al., 2023) first instructs
the LLM to criticize its generated answer using
the hint: “Review previous answer and find mis-
takes”. Then, Self-Correct instructs the LLM to
refine initial answers based on the critique.
  However, recent studies (Huang et al., 2024; Gou
et al., 2024) have cast doubt on the intrinsic self-
correction capability of LLMs. Their research indi-
cates that without external feedback, such as input
from humans, other models, or external tools to
verify the correctness of previous responses, LLMs
struggle to correct their prior outputs. Since LLMs
could not properly judge the correctness of their
prior responses, the refined response might be even
worse than the initial response.
  To improve the performance of LLMs in iden-
tifying and correcting inaccurate answers without
external feedback, we introduce substitute verifi-12846","Wu Z,Zeng Q,Zhang Z,Tan Z,Shen C,Jiang M",,,Large Language Models Can Self-Correct with Key Condition Verification,,, , Conference Paper,,"Intrinsic self-correct was a method that in-
    structed large language models (LLMs) to ver-
     ify and correct their responses without exter-
    nal feedback.  Unfortunately, the study con-
    cluded that the LLMs could not self-correct
    reasoning yet. We find that a simple yet effec-
     tive prompting method enhances LLM perfor-
   mance in identifying and correcting inaccurate
    answers without external feedback.  That is
    to mask a key condition in the question, add
    the current response to construct a verification
    question, and predict the condition to verify the
    response. The condition can be an entity in an
    open-domain question or a numerical value in
    an arithmetic question, which requires minimal
     effort (via prompting) to identify. We propose
    an iterative verify-then-correct framework to
    progressively identify and correct (probably)
     false responses, named PROCO. We conduct
    experiments on three reasoning tasks. On av-
    erage, PROCO, with GPT-3.5-Turbo-1106 as
    the backend LLM, yields +6.8 exact match on
    four open-domain question answering datasets,
   +14.1 accuracy on three arithmetic reasoning
     datasets, and +9.6 accuracy on a commonsense
    reasoning dataset, compared to Self-Correct.
   Our implementation is made publicly avail-
    able at https://wzy6642.github.io/proco.
    github.io/.
1  Introduction
Reasoning is a cognitive process that uses evidence,
arguments, and logic to arrive at conclusions or
judgements (Huang and Chang, 2023). People have
been exploiting and improving the reasoning abil-
ity of large language models (LLMs). Wei et al.
(2022) proposed chain-of-thought (CoT) prompt-
ing and yielded promising results on several rea-
soning tasks, such as arithmetic reasoning (Kojima
et al., 2022; Zhou et al., 2023), commonsense rea-
soning (Wei et al., 2022; Zhang et al., 2023; Wang
   *Equal contribution.
   †Corresponding author. Method       NQ     CSQA    AQuA
 CoT               40.3        72.9        51.3
 Self-Correct        40.1        65.9        48.7
 PROCO (Ours)     48.0        75.5        65.2

Table 1: Performance comparison of different prompt-
ing methods using GPT-3.5-Turbo as backend LLM.


et al., 2023b), and open-domain question answer-
ing (Wang et al., 2023a), using only a few or no rea-
soning exemplars. CoT guides LLMs to generate
intermediate reasoning paths instead of generating
the final answer directly, which helps the LLMs
simulate the human-like reasoning process.
  Although CoT enables LLMs to handle com-
plex reasoning tasks, they are sensitive to mistakes
in the reasoning path, as any mistake can lead to
an incorrect answer. To address this issue, Dhuli-
awala et al. (2023); Kim et al. (2023) have explored
verifying and correcting responses generated by
LLMs. For example, as shown in Figure 1a, for
a given question and its initial LLM-generated an-
swer, Self-Correct (Kim et al., 2023) first instructs
the LLM to criticize its generated answer using
the hint: “Review previous answer and find mis-
takes”. Then, Self-Correct instructs the LLM to
refine initial answers based on the critique.
  However, recent studies (Huang et al., 2024; Gou
et al., 2024) have cast doubt on the intrinsic self-
correction capability of LLMs. Their research indi-
cates that without external feedback, such as input
from humans, other models, or external tools to
verify the correctness of previous responses, LLMs
struggle to correct their prior outputs. Since LLMs
could not properly judge the correctness of their
prior responses, the refined response might be even
worse than the initial response.
  To improve the performance of LLMs in iden-
tifying and correcting inaccurate answers without
external feedback, we introduce substitute verifi-12846",,,,,Association for Computational Linguistics ,"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, EMNLP 2024, Miami, FL, USA, November 12-16, 2024  ",,out_of_scope,
2890,"**Title**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs

**Abstract**Abstract:Large Language Models (LLMs) have shown remarkable reasoning capabilities on complex tasks, but they still suffer from out-of-date knowledge, hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs) can provide explicit and editable knowledge for LLMs to alleviate these issues. Existing paradigm of KG-augmented LLM manually predefines the breadth of exploration space and requires flawless navigation in KGs. However, this paradigm cannot adaptively explore reasoning paths in KGs based on the question semantics and self-correct erroneous reasoning paths, resulting in a bottleneck in efficiency and effect. To address these limitations, we propose a novel self-correcting adaptive planning paradigm for KG-augmented LLM named Plan-on-Graph (PoG), which first decomposes the question into several sub-objectives and then repeats the process of adaptively exploring reasoning paths, updating memory, and reflecting on the need to self-correct erroneous reasoning paths until arriving at the answer. Specifically, three important mechanisms of Guidance, Memory, and Reflection are designed to work together, to guarantee the adaptive breadth of self-correcting planning for graph reasoning. Finally, extensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of PoG.","Chen L,Tong P,Jin Z,Sun Y,Ye J,Xiong H",,,Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs,,, , Conference Paper,,"Abstract:Large Language Models (LLMs) have shown remarkable reasoning capabilities on complex tasks, but they still suffer from out-of-date knowledge, hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs) can provide explicit and editable knowledge for LLMs to alleviate these issues. Existing paradigm of KG-augmented LLM manually predefines the breadth of exploration space and requires flawless navigation in KGs. However, this paradigm cannot adaptively explore reasoning paths in KGs based on the question semantics and self-correct erroneous reasoning paths, resulting in a bottleneck in efficiency and effect. To address these limitations, we propose a novel self-correcting adaptive planning paradigm for KG-augmented LLM named Plan-on-Graph (PoG), which first decomposes the question into several sub-objectives and then repeats the process of adaptively exploring reasoning paths, updating memory, and reflecting on the need to self-correct erroneous reasoning paths until arriving at the answer. Specifically, three important mechanisms of Guidance, Memory, and Reflection are designed to work together, to guarantee the adaptive breadth of self-correcting planning for graph reasoning. Finally, extensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of PoG.",,,,, ,"Advances in Neural Information Processing Systems 38: Annual Conference on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024  ",,out_of_scope,
2891,"**Title**Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation

**Abstract**Abstract:Despite significant advancements in text-to-image models for generating high-quality images, these methods still struggle to ensure the controllability of text prompts over images in the context of complex text prompts, especially when it comes to retaining object attributes and relationships. In this paper, we propose CompAgent, a training-free approach for compositional text-to-image generation, with a large language model (LLM) agent as its core. The fundamental idea underlying CompAgent is premised on a divide-and-conquer methodology. Given a complex text prompt containing multiple concepts including objects, attributes, and relationships, the LLM agent initially decomposes it, which entails the extraction of individual objects, their associated attributes, and the prediction of a coherent scene layout. These individual objects can then be independently conquered. Subsequently, the agent performs reasoning by analyzing the text, plans and employs the tools to compose these isolated objects. The verification and human feedback mechanism is finally incorporated into our agent to further correct the potential attribute errors and refine the generated images. Guided by the LLM agent, we propose a tuning-free multi-concept customization model and a layout-to-image generation model as the tools for concept composition, and a local image editing method as the tool to interact with the agent for verification. The scene layout controls the image generation process among these tools to prevent confusion among multiple objects. Extensive experiments demonstrate the superiority of our approach for compositional text-to-image generation: CompAgent achieves more than 10\% improvement on T2I-CompBench, a comprehensive benchmark for open-world compositional T2I generation. The extension to various related tasks also illustrates the flexibility of our CompAgent for potential applications.","Wang Z,Xie E,Li A,Wang Z,Liu X,Li Z",,,Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation,abs/2401.15688,,10.48550/ARXIV.2401.15688 , Journal Article,,"Abstract:Despite significant advancements in text-to-image models for generating high-quality images, these methods still struggle to ensure the controllability of text prompts over images in the context of complex text prompts, especially when it comes to retaining object attributes and relationships. In this paper, we propose CompAgent, a training-free approach for compositional text-to-image generation, with a large language model (LLM) agent as its core. The fundamental idea underlying CompAgent is premised on a divide-and-conquer methodology. Given a complex text prompt containing multiple concepts including objects, attributes, and relationships, the LLM agent initially decomposes it, which entails the extraction of individual objects, their associated attributes, and the prediction of a coherent scene layout. These individual objects can then be independently conquered. Subsequently, the agent performs reasoning by analyzing the text, plans and employs the tools to compose these isolated objects. The verification and human feedback mechanism is finally incorporated into our agent to further correct the potential attribute errors and refine the generated images. Guided by the LLM agent, we propose a tuning-free multi-concept customization model and a layout-to-image generation model as the tools for concept composition, and a local image editing method as the tool to interact with the agent for verification. The scene layout controls the image generation process among these tools to prevent confusion among multiple objects. Extensive experiments demonstrate the superiority of our approach for compositional text-to-image generation: CompAgent achieves more than 10\% improvement on T2I-CompBench, a comprehensive benchmark for open-world compositional T2I generation. The extension to various related tasks also illustrates the flexibility of our CompAgent for potential applications.",,,,, CoRR,  ,,out_of_scope,
2892,"**Title**Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models

**Abstract**Abstract:The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ""confidence"" of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ""confidence"" in their own responses. It motivates us to develop an ""If-or-Else"" (IoE) prompting framework, designed to guide LLMs in assessing their own ""confidence"", facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a consistent improvement regarding the accuracy of self-corrected responses over the initial answers. Our study not only sheds light on the underlying factors affecting self-correction in LLMs, but also introduces a practical framework that utilizes the IoE prompting principle to efficiently improve self-correction capabilities with ""confidence"". The code is available at this https URL.","Li L,Chen G,Su Y,Chen Z,Zhang Y,Xing EP,Zhang K",,,Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models,abs/2402.12563,,10.48550/ARXIV.2402.12563 , Journal Article,,"Abstract:The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ""confidence"" of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ""confidence"" in their own responses. It motivates us to develop an ""If-or-Else"" (IoE) prompting framework, designed to guide LLMs in assessing their own ""confidence"", facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a consistent improvement regarding the accuracy of self-corrected responses over the initial answers. Our study not only sheds light on the underlying factors affecting self-correction in LLMs, but also introduces a practical framework that utilizes the IoE prompting principle to efficiently improve self-correction capabilities with ""confidence"". The code is available at this https URL.",,,,, CoRR,  ,,out_of_scope,
2893,"**Title**Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models

**Abstract**Abstract:Self-correction has achieved impressive results in enhancing the style and security of the generated output from large language models (LLMs). However, recent studies suggest that self-correction might be limited or even counterproductive in reasoning tasks due to LLMs' difficulties in identifying logical mistakes.
In this paper, we aim to enhance the self-checking capabilities of LLMs by constructing training data for checking tasks. Specifically, we apply the Chain of Thought (CoT) methodology to self-checking tasks, utilizing fine-grained step-level analyses and explanations to assess the correctness of reasoning paths. We propose a specialized checking format called ""Step CoT Check"". Following this format, we construct a checking-correction dataset that includes detailed step-by-step analysis and checking. Then we fine-tune LLMs to enhance their error detection and correction abilities.
Our experiments demonstrate that fine-tuning with the ""Step CoT Check"" format significantly improves the self-checking and self-correction abilities of LLMs across multiple benchmarks. This approach outperforms other formats, especially in locating the incorrect position, with greater benefits observed in larger models.
For reproducibility, all the datasets and code are provided in this https URL.","Zhang C,Xiao Z,Han C,Lian Y,Fang Y",,,Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models,abs/2402.13035,,10.48550/ARXIV.2402.13035 , Journal Article,,"Abstract:Self-correction has achieved impressive results in enhancing the style and security of the generated output from large language models (LLMs). However, recent studies suggest that self-correction might be limited or even counterproductive in reasoning tasks due to LLMs' difficulties in identifying logical mistakes.
In this paper, we aim to enhance the self-checking capabilities of LLMs by constructing training data for checking tasks. Specifically, we apply the Chain of Thought (CoT) methodology to self-checking tasks, utilizing fine-grained step-level analyses and explanations to assess the correctness of reasoning paths. We propose a specialized checking format called ""Step CoT Check"". Following this format, we construct a checking-correction dataset that includes detailed step-by-step analysis and checking. Then we fine-tune LLMs to enhance their error detection and correction abilities.
Our experiments demonstrate that fine-tuning with the ""Step CoT Check"" format significantly improves the self-checking and self-correction abilities of LLMs across multiple benchmarks. This approach outperforms other formats, especially in locating the incorrect position, with greater benefits observed in larger models.
For reproducibility, all the datasets and code are provided in this https URL.",,,,, CoRR,  ,,out_of_scope,
2894,"**Title**Large Language Models Can Self-Correct with Minimal Effort

**Abstract**Large Language Models (LLMs) have achieved
    excellent performances in various tasks. How-
     ever, fine-tuning an LLM requires extensive su-
    pervision. Human, on the other hand, may im-
    prove their reasoning abilities by self-thinking
    without external inputs.  In this work, we
    demonstrate that an LLM is also capable of
    self-improving with only unlabeled datasets.
   We use a pre-trained LLM to generate “high-
    confidence” rationale-augmented answers for
    unlabeled questions using Chain-of-Though
    (CoT) prompting and self-consistency, and fine-
    tune the LLM using those self-generated so-
    lutions as target outputs. We show that with-
    out any ground truth label, our approach sig-
     nificantly improves the general reasoning abil-
     ity of PaLM 540B model (74.4%→82.1% on
   GSM8K, 90.0%→94.4% on OpenBookQA,
    and 63.4%→67.9% on ANLI-A3) and can    also be adapted to extreme low-resource cases
    where even training questions and CoT prompts
    are limited. We conduct ablation studies and
   show that fine-tuning on diverse reasoning
    paths is critical for self-improvement.

1  Introduction

Scaling has enabled Large Language Models
(LLMs) to achieve state-of-the-art performance on
a range of Natural Language Processing (NLP)
tasks (Wang et al., 2018, 2019; Rajpurkar et al.,
2016). More importantly, new capabilities have
emerged from LLMs as they are scaled to hun-
dreds of billions of parameters (Wei et al., 2022b):
in-context few-shot learning (Brown et al., 2020)
makes it possible for an LLM to perform well
on a task it never trained on with only a handful
of examples; Chain-of-Thought (CoT) prompting
(Wei et al., 2022c; Kojima et al., 2022) demon-
strates strong reasoning ability of LLMs across
diverse tasks with or without few-shot examples;

   ∗Work was done during Google internship.
    †Corresponding author.self-consistency (Wang et al., 2022c) further im-
proves the performance via self-evaluating multiple
reasoning paths.
  Despite these incredible capabilities of models
trained on large text corpus (Brown et al., 2020;
Chowdhery et al., 2022), fundamentally improving
the model performances beyond few-shot baselines
still requires finetuning on an extensive amount
of high-quality supervised datasets. FLAN (Wei
et al., 2021; Chung et al., 2022) and T0 (Sanh et al.,
2022) curated tens of benchmark NLP datasets to
boost zero-shot task performances on unseen tasks;
InstructGPT (Ouyang et al., 2022) crowd-sourced
many human answers for diverse sets of text in-
structions to better align their model to human
instructions; Minerva (Lewkowycz et al., 2022)
parsed the full ArXiv database carefully for rele-
vant articles to excel on challenging competitive
math and science datasets. The need for large anno-
tated data for supervised LLM training still remains
a burden for low-resource applications or specific
domains where only limited annotations are avail-
able.
  In this paper, we study how an LLM capa-
ble of in-context few-shot learning and chain-of-
thought reasoning, is able to self-improve its rea-
soning ability without supervised data. We show
that using only input sequences (without ground
truth output sequences) from multiple NLP task
datasets, a pre-trained LLM is able to improve per-
formances for both in-domain and out-of-domain
tasks.  Our method is shown in Figure 1: we
first sample multiple predictions using few-shot
Chain-of-Thought (CoT) (Wei et al., 2022c) as
prompts, filter “high-confidence” predictions us-
ing majority voting (Wang et al., 2022c), and fi-
nally finetune the LLM on these high-confidence
predictions. The resulting model shows improved
reasoning in both greedy and multi-path evalu-
ations.  We call the model fine-tuned in this
way as Language Model Self-Improved (LMSI).1051","Wu Z,Zeng Q,Zhang Z,Tan Z,Shen C,Jiang M",,,Large Language Models Can Self-Correct with Minimal Effort,abs/2405.14092,,10.48550/ARXIV.2405.14092 , Journal Article,,"Large Language Models (LLMs) have achieved
    excellent performances in various tasks. How-
     ever, fine-tuning an LLM requires extensive su-
    pervision. Human, on the other hand, may im-
    prove their reasoning abilities by self-thinking
    without external inputs.  In this work, we
    demonstrate that an LLM is also capable of
    self-improving with only unlabeled datasets.
   We use a pre-trained LLM to generate “high-
    confidence” rationale-augmented answers for
    unlabeled questions using Chain-of-Though
    (CoT) prompting and self-consistency, and fine-
    tune the LLM using those self-generated so-
    lutions as target outputs. We show that with-
    out any ground truth label, our approach sig-
     nificantly improves the general reasoning abil-
     ity of PaLM 540B model (74.4%→82.1% on
   GSM8K, 90.0%→94.4% on OpenBookQA,
    and 63.4%→67.9% on ANLI-A3) and can    also be adapted to extreme low-resource cases
    where even training questions and CoT prompts
    are limited. We conduct ablation studies and
   show that fine-tuning on diverse reasoning
    paths is critical for self-improvement.

1  Introduction

Scaling has enabled Large Language Models
(LLMs) to achieve state-of-the-art performance on
a range of Natural Language Processing (NLP)
tasks (Wang et al., 2018, 2019; Rajpurkar et al.,
2016). More importantly, new capabilities have
emerged from LLMs as they are scaled to hun-
dreds of billions of parameters (Wei et al., 2022b):
in-context few-shot learning (Brown et al., 2020)
makes it possible for an LLM to perform well
on a task it never trained on with only a handful
of examples; Chain-of-Thought (CoT) prompting
(Wei et al., 2022c; Kojima et al., 2022) demon-
strates strong reasoning ability of LLMs across
diverse tasks with or without few-shot examples;

   ∗Work was done during Google internship.
    †Corresponding author.self-consistency (Wang et al., 2022c) further im-
proves the performance via self-evaluating multiple
reasoning paths.
  Despite these incredible capabilities of models
trained on large text corpus (Brown et al., 2020;
Chowdhery et al., 2022), fundamentally improving
the model performances beyond few-shot baselines
still requires finetuning on an extensive amount
of high-quality supervised datasets. FLAN (Wei
et al., 2021; Chung et al., 2022) and T0 (Sanh et al.,
2022) curated tens of benchmark NLP datasets to
boost zero-shot task performances on unseen tasks;
InstructGPT (Ouyang et al., 2022) crowd-sourced
many human answers for diverse sets of text in-
structions to better align their model to human
instructions; Minerva (Lewkowycz et al., 2022)
parsed the full ArXiv database carefully for rele-
vant articles to excel on challenging competitive
math and science datasets. The need for large anno-
tated data for supervised LLM training still remains
a burden for low-resource applications or specific
domains where only limited annotations are avail-
able.
  In this paper, we study how an LLM capa-
ble of in-context few-shot learning and chain-of-
thought reasoning, is able to self-improve its rea-
soning ability without supervised data. We show
that using only input sequences (without ground
truth output sequences) from multiple NLP task
datasets, a pre-trained LLM is able to improve per-
formances for both in-domain and out-of-domain
tasks.  Our method is shown in Figure 1: we
first sample multiple predictions using few-shot
Chain-of-Thought (CoT) (Wei et al., 2022c) as
prompts, filter “high-confidence” predictions us-
ing majority voting (Wang et al., 2022c), and fi-
nally finetune the LLM on these high-confidence
predictions. The resulting model shows improved
reasoning in both greedy and multi-path evalu-
ations.  We call the model fine-tuned in this
way as Language Model Self-Improved (LMSI).1051",,,,, CoRR,  ,,out_of_scope,
2895,"**Title**Self-Corrected Multimodal Large Language Model for End-to-End Robot Manipulation

**Abstract**Abstract:Robot manipulation policies have shown unsatisfactory action performance when confronted with novel task or object instances. Hence, the capability to automatically detect and self-correct failure action is essential for a practical robotic system. Recently, Multimodal Large Language Models (MLLMs) have shown promise in visual instruction following and demonstrated strong reasoning abilities in various tasks. To unleash general MLLMs as an end-to-end robotic agent, we introduce a Self-Corrected (SC)-MLLM, equipping our model not only to predict end-effector poses but also to autonomously recognize and correct failure actions. Specifically, we first conduct parameter-efficient fine-tuning to empower MLLM with pose prediction ability, which is reframed as a language modeling problem. When facing execution failures, our model learns to identify low-level action error causes (i.e., position and rotation errors) and adaptively seeks prompt feedback from experts. Based on the feedback, SC-MLLM rethinks the current failure scene and generates the corrected actions. Furthermore, we design a continuous policy learning method for successfully corrected samples, enhancing the model's adaptability to the current scene configuration and reducing the frequency of expert intervention. To evaluate our SC-MLLM, we conduct extensive experiments in both simulation and real-world settings. SC-MLLM agent significantly improve manipulation accuracy compared to previous state-of-the-art robotic MLLM (ManipLLM), increasing from 57\% to 79\% on seen object categories and from 47\% to 69\% on unseen novel categories.","Liu J,Li C,Wang G,Lee L,Zhou K,Chen S,Xiong C,Ge J,Zhang R,Zhang S",,,Self-Corrected Multimodal Large Language Model for End-to-End Robot Manipulation,abs/2405.17418,,10.48550/ARXIV.2405.17418 , Journal Article,,"Abstract:Robot manipulation policies have shown unsatisfactory action performance when confronted with novel task or object instances. Hence, the capability to automatically detect and self-correct failure action is essential for a practical robotic system. Recently, Multimodal Large Language Models (MLLMs) have shown promise in visual instruction following and demonstrated strong reasoning abilities in various tasks. To unleash general MLLMs as an end-to-end robotic agent, we introduce a Self-Corrected (SC)-MLLM, equipping our model not only to predict end-effector poses but also to autonomously recognize and correct failure actions. Specifically, we first conduct parameter-efficient fine-tuning to empower MLLM with pose prediction ability, which is reframed as a language modeling problem. When facing execution failures, our model learns to identify low-level action error causes (i.e., position and rotation errors) and adaptively seeks prompt feedback from experts. Based on the feedback, SC-MLLM rethinks the current failure scene and generates the corrected actions. Furthermore, we design a continuous policy learning method for successfully corrected samples, enhancing the model's adaptability to the current scene configuration and reducing the frequency of expert intervention. To evaluate our SC-MLLM, we conduct extensive experiments in both simulation and real-world settings. SC-MLLM agent significantly improve manipulation accuracy compared to previous state-of-the-art robotic MLLM (ManipLLM), increasing from 57\% to 79\% on seen object categories and from 47\% to 69\% on unseen novel categories.",,,,, CoRR,  ,,out_of_scope,
2896,"**Title**Large Language Models have Intrinsic Self-Correction Ability

**Abstract**AbstractIntrinsic self-correct was a method that instructed large language models (LLMs) to verify and correct their responses without external feedback. Unfortunately, the study concluded that the LLMs could not self-correct reasoning yet. We find that a simple yet effective prompting method enhances LLM performance in identifying and correcting inaccurate answers without external feedback.That is to mask a key condition in the question, add the current response to construct a verification question, and predict the condition to verify the response. The condition can be an entity in an open-domain question or a numerical value in an arithmetic question, which requires minimal effort (via prompting) to identify. We propose an iterative verify-then-correct framework to progressively identify and correct (probably) false responses, named ProCo. We conduct experiments on three reasoning tasks. On average, ProCo, with GPT-3.5-Turbo-1106 as the backend LLM, yields +6.8 exact match on four open-domain question answering datasets, +14.1 accuracy on three arithmetic reasoning datasets, and +9.6 accuracy on a commonsense reasoning dataset, compared to Self-Correct.Our implementation is made publicly available at https://wzy6642.github.io/proco.github.io/.","Liu D,Nassereldine A,Yang Z,Xu C,Hu Y,Li J,Kumar U,Lee C,Xiong J",,,Large Language Models have Intrinsic Self-Correction Ability,abs/2406.15673,,10.48550/ARXIV.2406.15673 , Journal Article,,"AbstractIntrinsic self-correct was a method that instructed large language models (LLMs) to verify and correct their responses without external feedback. Unfortunately, the study concluded that the LLMs could not self-correct reasoning yet. We find that a simple yet effective prompting method enhances LLM performance in identifying and correcting inaccurate answers without external feedback.That is to mask a key condition in the question, add the current response to construct a verification question, and predict the condition to verify the response. The condition can be an entity in an open-domain question or a numerical value in an arithmetic question, which requires minimal effort (via prompting) to identify. We propose an iterative verify-then-correct framework to progressively identify and correct (probably) false responses, named ProCo. We conduct experiments on three reasoning tasks. On average, ProCo, with GPT-3.5-Turbo-1106 as the backend LLM, yields +6.8 exact match on four open-domain question answering datasets, +14.1 accuracy on three arithmetic reasoning datasets, and +9.6 accuracy on a commonsense reasoning dataset, compared to Self-Correct.Our implementation is made publicly available at https://wzy6642.github.io/proco.github.io/.",,,,, CoRR,  ,,out_of_scope,
2897,"**Title**Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models

**Abstract**Abstract:Requiring a Large Language Model to generate intermediary reasoning steps has been shown to be an effective way of boosting performance. In fact, it has been found that instruction tuning on these intermediary reasoning steps improves model performance. In this work, we present a novel method of further improving performance by requiring models to compare multiple reasoning chains before generating a solution in a single inference step. We call this method Divergent CoT (DCoT). We find that instruction tuning on DCoT datasets boosts the performance of even smaller, and therefore more accessible, LLMs. Through a rigorous set of experiments spanning a wide range of tasks that require various reasoning types, we show that fine-tuning on DCoT consistently improves performance over the CoT baseline across model families and scales (1.3B to 70B). Through a combination of empirical and manual evaluation, we additionally show that these performance gains stem from models generating multiple divergent reasoning chains in a single inference step, indicative of the enabling of self-correction in language models. Our code and data are publicly available at this https URL.","Puerto H,Chubakov T,Zhu X,Madabushi HT,Gurevych I",,,Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models,abs/2407.03181,,10.48550/ARXIV.2407.03181 , Journal Article,,"Abstract:Requiring a Large Language Model to generate intermediary reasoning steps has been shown to be an effective way of boosting performance. In fact, it has been found that instruction tuning on these intermediary reasoning steps improves model performance. In this work, we present a novel method of further improving performance by requiring models to compare multiple reasoning chains before generating a solution in a single inference step. We call this method Divergent CoT (DCoT). We find that instruction tuning on DCoT datasets boosts the performance of even smaller, and therefore more accessible, LLMs. Through a rigorous set of experiments spanning a wide range of tasks that require various reasoning types, we show that fine-tuning on DCoT consistently improves performance over the CoT baseline across model families and scales (1.3B to 70B). Through a combination of empirical and manual evaluation, we additionally show that these performance gains stem from models generating multiple divergent reasoning chains in a single inference step, indicative of the enabling of self-correction in language models. Our code and data are publicly available at this https URL.",,,,, CoRR,  ,,out_of_scope,
2898,"**Title**An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation

**Abstract**Abstract:Large Language Models (LLMs) have recently advanced many applications on software engineering tasks, particularly the potential for code generation. Among contemporary challenges, code generated by LLMs often suffers from inaccuracies and hallucinations, requiring external inputs to correct. One recent strategy to fix these issues is to refine the code generated from LLMs using the input from the model itself (self-augmented). In this work, we proposed a novel method, namely CoT-SelfEvolve. CoT-SelfEvolve iteratively and automatically refines code through a self-correcting process, guided by a chain of thought constructed from real-world programming problem feedback. Focusing on data science code, including Python libraries such as NumPy and Pandas, our evaluations on the DS-1000 dataset demonstrate that CoT-SelfEvolve significantly outperforms existing models in solving complex problems. The framework shows substantial improvements in both initial code generation and subsequent iterations, with the model's accuracy increasing significantly with each additional iteration. This highlights the effectiveness of using chain-of-thought prompting to address complexities revealed by program executor traceback error messages. We also discuss how CoT-SelfEvolve can be integrated into continuous software engineering environments, providing a practical solution for improving LLM-based code generation.","Quoc TT,Minh DH,Thanh TQ,Nguyen-Duc A",,,An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation,abs/2408.15658,,10.48550/ARXIV.2408.15658 , Journal Article,,"Abstract:Large Language Models (LLMs) have recently advanced many applications on software engineering tasks, particularly the potential for code generation. Among contemporary challenges, code generated by LLMs often suffers from inaccuracies and hallucinations, requiring external inputs to correct. One recent strategy to fix these issues is to refine the code generated from LLMs using the input from the model itself (self-augmented). In this work, we proposed a novel method, namely CoT-SelfEvolve. CoT-SelfEvolve iteratively and automatically refines code through a self-correcting process, guided by a chain of thought constructed from real-world programming problem feedback. Focusing on data science code, including Python libraries such as NumPy and Pandas, our evaluations on the DS-1000 dataset demonstrate that CoT-SelfEvolve significantly outperforms existing models in solving complex problems. The framework shows substantial improvements in both initial code generation and subsequent iterations, with the model's accuracy increasing significantly with each additional iteration. This highlights the effectiveness of using chain-of-thought prompting to address complexities revealed by program executor traceback error messages. We also discuss how CoT-SelfEvolve can be integrated into continuous software engineering environments, providing a practical solution for improving LLM-based code generation.",,,,, CoRR,  ,,out_of_scope,
2899,"**Title**S\(^3\)c-Math: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners

**Abstract**Abstract:Self-correction is a novel method that can stimulate the potential reasoning abilities of large language models (LLMs). It involves detecting and correcting errors during the inference process when LLMs solve reasoning problems. However, recent works do not regard self-correction as a spontaneous and intrinsic capability of LLMs. Instead, such correction is achieved through post-hoc generation, external knowledge introduction, multi-model collaboration, and similar techniques. In this paper, we propose a series of mathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous Step-level Self-correction for Mathematical reasoning. This capability helps LLMs to recognize whether their ongoing inference tends to contain errors and simultaneously correct these errors to produce a more reliable response. We proposed a method, which employs a step-level sampling approach to construct step-wise self-correction data for achieving such ability. Additionally, we implement a training strategy that uses above constructed data to equip LLMs with spontaneous step-level self-correction capacities. Our data and methods have been demonstrated to be effective across various foundation LLMs, consistently showing significant progress in evaluations on GSM8K, MATH, and other mathematical benchmarks. To the best of our knowledge, we are the first to introduce the spontaneous step-level self-correction ability of LLMs in mathematical reasoning.","Yan Y,Jiang J,Liu Y,Cao Y,Xu X,Zhang M,Cai X,Shao J",,,S\(^3\)c-Math: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners,abs/2409.01524,,10.48550/ARXIV.2409.01524 , Journal Article,,"Abstract:Self-correction is a novel method that can stimulate the potential reasoning abilities of large language models (LLMs). It involves detecting and correcting errors during the inference process when LLMs solve reasoning problems. However, recent works do not regard self-correction as a spontaneous and intrinsic capability of LLMs. Instead, such correction is achieved through post-hoc generation, external knowledge introduction, multi-model collaboration, and similar techniques. In this paper, we propose a series of mathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous Step-level Self-correction for Mathematical reasoning. This capability helps LLMs to recognize whether their ongoing inference tends to contain errors and simultaneously correct these errors to produce a more reliable response. We proposed a method, which employs a step-level sampling approach to construct step-wise self-correction data for achieving such ability. Additionally, we implement a training strategy that uses above constructed data to equip LLMs with spontaneous step-level self-correction capacities. Our data and methods have been demonstrated to be effective across various foundation LLMs, consistently showing significant progress in evaluations on GSM8K, MATH, and other mathematical benchmarks. To the best of our knowledge, we are the first to introduce the spontaneous step-level self-correction ability of LLMs in mathematical reasoning.",,,,, CoRR,  ,,out_of_scope,
2900,"**Title**Training Language Models to Self-Correct via Reinforcement Learning

**Abstract**Abstract:Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Current methods for training self-correction typically depend on either multiple models, a more advanced model, or additional forms of supervision. To address these shortcomings, we develop a multi-turn online reinforcement learning (RL) approach, SCoRe, that significantly improves an LLM's self-correction ability using entirely self-generated data. To build SCoRe, we first show that variants of supervised fine-tuning (SFT) on offline model-generated correction traces are often insufficient for instilling self-correction behavior. In particular, we observe that training via SFT falls prey to either a distribution mismatch between mistakes made by the data-collection policy and the model's own responses, or to behavior collapse, where learning implicitly prefers only a certain mode of correction behavior that is often not effective at self-correction on test problems. SCoRe addresses these challenges by training under the model's own distribution of self-generated correction traces and using appropriate regularization to steer the learning process into learning a self-correction behavior that is effective at test time as opposed to fitting high-reward responses for a given prompt. This regularization process includes an initial phase of multi-turn RL on a base model to generate a policy initialization that is less susceptible to collapse, followed by using a reward bonus to amplify self-correction. With Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models' self-correction by 15.6% and 9.1% respectively on MATH and HumanEval.","Kumar A,Zhuang V,Agarwal R,Su Y,Co-Reyes JD,Singh A,Baumli K,Iqbal S,Bishop C,Roelofs R,Zhang LM,McKinney K,Shrivastava D,Paduraru C,Tucker G,Precup D,Behbahani FM,Faust A",,,Training Language Models to Self-Correct via Reinforcement Learning,abs/2409.12917,,10.48550/ARXIV.2409.12917 , Journal Article,,"Abstract:Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Current methods for training self-correction typically depend on either multiple models, a more advanced model, or additional forms of supervision. To address these shortcomings, we develop a multi-turn online reinforcement learning (RL) approach, SCoRe, that significantly improves an LLM's self-correction ability using entirely self-generated data. To build SCoRe, we first show that variants of supervised fine-tuning (SFT) on offline model-generated correction traces are often insufficient for instilling self-correction behavior. In particular, we observe that training via SFT falls prey to either a distribution mismatch between mistakes made by the data-collection policy and the model's own responses, or to behavior collapse, where learning implicitly prefers only a certain mode of correction behavior that is often not effective at self-correction on test problems. SCoRe addresses these challenges by training under the model's own distribution of self-generated correction traces and using appropriate regularization to steer the learning process into learning a self-correction behavior that is effective at test time as opposed to fitting high-reward responses for a given prompt. This regularization process includes an initial phase of multi-turn RL on a base model to generate a policy initialization that is less susceptible to collapse, followed by using a reward bonus to amplify self-correction. With Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models' self-correction by 15.6% and 9.1% respectively on MATH and HumanEval.",,,,, CoRR,  ,,out_of_scope,
2901,"**Title**Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks

**Abstract**Abstract:While Vision-Language Models (VLMs) have shown remarkable abilities in visual and language reasoning tasks, they invariably generate flawed responses. Self-correction that instructs models to refine their outputs presents a promising solution to this issue. Previous studies have mainly concentrated on Large Language Models (LLMs), while the self-correction abilities of VLMs, particularly concerning both visual and linguistic information, remain largely unexamined. This study investigates the self-correction capabilities of VLMs during both inference and fine-tuning stages. We introduce a Self-Correction Learning (SCL) approach that enables VLMs to learn from their self-generated self-correction data through Direct Preference Optimization (DPO) without relying on external feedback, facilitating self-improvement. Specifically, we collect preferred and disfavored samples based on the correctness of initial and refined responses, which are obtained by two-turn self-correction with VLMs during the inference stage. Experimental results demonstrate that although VLMs struggle to self-correct effectively during iterative inference without additional fine-tuning and external feedback, they can enhance their performance and avoid previous mistakes through preference fine-tuning when their self-generated self-correction data are categorized into preferred and disfavored samples. This study emphasizes that self-correction is not merely a refinement process; rather, it should enhance the reasoning abilities of models through additional training, enabling them to generate high-quality responses directly without further refinement.","He J,Lin H,Wang Q,Fung Y,Ji H",,,Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks,abs/2410.04055,,10.48550/ARXIV.2410.04055 , Journal Article,,"Abstract:While Vision-Language Models (VLMs) have shown remarkable abilities in visual and language reasoning tasks, they invariably generate flawed responses. Self-correction that instructs models to refine their outputs presents a promising solution to this issue. Previous studies have mainly concentrated on Large Language Models (LLMs), while the self-correction abilities of VLMs, particularly concerning both visual and linguistic information, remain largely unexamined. This study investigates the self-correction capabilities of VLMs during both inference and fine-tuning stages. We introduce a Self-Correction Learning (SCL) approach that enables VLMs to learn from their self-generated self-correction data through Direct Preference Optimization (DPO) without relying on external feedback, facilitating self-improvement. Specifically, we collect preferred and disfavored samples based on the correctness of initial and refined responses, which are obtained by two-turn self-correction with VLMs during the inference stage. Experimental results demonstrate that although VLMs struggle to self-correct effectively during iterative inference without additional fine-tuning and external feedback, they can enhance their performance and avoid previous mistakes through preference fine-tuning when their self-generated self-correction data are categorized into preferred and disfavored samples. This study emphasizes that self-correction is not merely a refinement process; rather, it should enhance the reasoning abilities of models through additional training, enabling them to generate high-quality responses directly without further refinement.",,,,, CoRR,  ,,out_of_scope,
2902,"**Title**Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning

**Abstract**Abstract:Accurate mathematical reasoning with Large Language Models (LLMs) is crucial in revolutionizing domains that heavily rely on such reasoning. However, LLMs often encounter difficulties in certain aspects of mathematical reasoning, leading to flawed reasoning and erroneous results. To mitigate these issues, we introduce a novel mechanism, the Chain of Self-Correction (CoSC), specifically designed to embed self-correction as an inherent ability in LLMs, enabling them to validate and rectify their own results. The CoSC mechanism operates through a sequence of self-correction stages. In each stage, the LLMs generate a program to address a given problem, execute this program using program-based tools to obtain an output, subsequently verify this output. Based on the verification, the LLMs either proceed to the next correction stage or finalize the answer. This iterative self-correction process allows the LLMs to refine its reasoning steps and improve the accuracy of its mathematical reasoning. We implement CoSC using a two-phase fine-tuning approach. First, LLMs are trained with a relatively small volume of seeding data generated from GPT-4. Then, we enhance CoSC by training with a larger volume of self-generated data, without relying on GPT-4. Experiments show that CoSC significantly boosts performance on standard mathematical datasets compared to existing open-source LLMs. Notably, our CoSC-Code-34B model achieved a 53.5% score on the challenging MATH dataset, outperforming models like ChatGPT, GPT-4, and multi-modal LLMs such as GPT-4V and Gemini-1.0. Importantly, CoSC operates in a zero-shot manner without requiring demonstrations.","Gao K,Cai H,Shuai Q,Gong D,Li Z",,,Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning,abs/2410.10735,,10.48550/ARXIV.2410.10735 , Journal Article,,"Abstract:Accurate mathematical reasoning with Large Language Models (LLMs) is crucial in revolutionizing domains that heavily rely on such reasoning. However, LLMs often encounter difficulties in certain aspects of mathematical reasoning, leading to flawed reasoning and erroneous results. To mitigate these issues, we introduce a novel mechanism, the Chain of Self-Correction (CoSC), specifically designed to embed self-correction as an inherent ability in LLMs, enabling them to validate and rectify their own results. The CoSC mechanism operates through a sequence of self-correction stages. In each stage, the LLMs generate a program to address a given problem, execute this program using program-based tools to obtain an output, subsequently verify this output. Based on the verification, the LLMs either proceed to the next correction stage or finalize the answer. This iterative self-correction process allows the LLMs to refine its reasoning steps and improve the accuracy of its mathematical reasoning. We implement CoSC using a two-phase fine-tuning approach. First, LLMs are trained with a relatively small volume of seeding data generated from GPT-4. Then, we enhance CoSC by training with a larger volume of self-generated data, without relying on GPT-4. Experiments show that CoSC significantly boosts performance on standard mathematical datasets compared to existing open-source LLMs. Notably, our CoSC-Code-34B model achieved a 53.5% score on the challenging MATH dataset, outperforming models like ChatGPT, GPT-4, and multi-modal LLMs such as GPT-4V and Gemini-1.0. Importantly, CoSC operates in a zero-shot manner without requiring demonstrations.",,,,, CoRR,  ,,out_of_scope,
2903,"**Title**Is Moral Self-correction An Innate Capability of Large Language Models? A Mechanistic Analysis to Self-correction

**Abstract**Abstract:Though intensive attentions to the self-correction capability of Large Language Models (LLMs), the underlying mechanism of this capability is still under-explored. In this paper, we aim to answer two fundamental questions for moral self-correction: (1) how different components in self-correction, such as Chain-of-Thought (CoT) reasoning, external feedback, and instructional prompts, interact to enable moral self-correction; and (2) is the self-correction one of LLMs' innate capabilities? To answer the first question, we examine how different self-correction components interact to intervene the embedded morality within hidden states, therefore contributing to different performance. For the second question, we (i) evaluate the robustness of moral self-correction by introducing natural language interventions of weak evidence into prompts; (ii) propose a validation framework, self-distinguish, that requires effective self-correction to enable LLMs to distinguish between desirable and undesirable outputs. Our experimental results indicate that there is no universally optimal self-correction method for the tasks considered, although external feedback and CoT can contribute to additional performance gains. However, our mechanistic analysis reveals negative interactions among instructional prompts, CoT, and external feedback, suggesting a conflict between internal knowledge and external feedback. The self-distinguish experiments demonstrate that while LLMs can self-correct their responses, they are unable to reliably distinguish between desired and undesired outputs. With our empirical evidence, we can conclude that moral self-correction is not an innate capability of LLMs acquired during pretraining.","Qi Z,Liu G,Johnson KM,Chen L",,,Is Moral Self-correction An Innate Capability of Large Language Models? A Mechanistic Analysis to Self-correction,abs/2410.20513,,10.48550/ARXIV.2410.20513 , Journal Article,,"Abstract:Though intensive attentions to the self-correction capability of Large Language Models (LLMs), the underlying mechanism of this capability is still under-explored. In this paper, we aim to answer two fundamental questions for moral self-correction: (1) how different components in self-correction, such as Chain-of-Thought (CoT) reasoning, external feedback, and instructional prompts, interact to enable moral self-correction; and (2) is the self-correction one of LLMs' innate capabilities? To answer the first question, we examine how different self-correction components interact to intervene the embedded morality within hidden states, therefore contributing to different performance. For the second question, we (i) evaluate the robustness of moral self-correction by introducing natural language interventions of weak evidence into prompts; (ii) propose a validation framework, self-distinguish, that requires effective self-correction to enable LLMs to distinguish between desirable and undesirable outputs. Our experimental results indicate that there is no universally optimal self-correction method for the tasks considered, although external feedback and CoT can contribute to additional performance gains. However, our mechanistic analysis reveals negative interactions among instructional prompts, CoT, and external feedback, suggesting a conflict between internal knowledge and external feedback. The self-distinguish experiments demonstrate that while LLMs can self-correct their responses, they are unable to reliably distinguish between desired and undesired outputs. With our empirical evidence, we can conclude that moral self-correction is not an innate capability of LLMs acquired during pretraining.",,,,, CoRR,  ,,out_of_scope,
2904,"**Title**Smaller Large Language Models Can Do Moral Self-Correction

**Abstract**Abstract:Self-correction is one of the most amazing emerging capabilities of Large Language Models (LLMs), enabling LLMs to self-modify an inappropriate output given a natural language feedback which describes the problems of that output. Moral self-correction is a post-hoc approach correcting unethical generations without requiring a gradient update, making it both computationally lightweight and capable of preserving the language modeling ability. Previous works have shown that LLMs can self-debias, and it has been reported that small models, i.e., those with less than 22B parameters, are not capable of moral self-correction. However, there is no direct proof as to why such smaller models fall short of moral self-correction, though previous research hypothesizes that larger models are skilled in following instructions and understanding abstract social norms. In this paper, we empirically validate this hypothesis in the context of social stereotyping, through meticulous prompting. Our experimental results indicate that (i) surprisingly, 3.8B LLMs with proper safety alignment fine-tuning can achieve very good moral self-correction performance, highlighting the significant effects of safety alignment; and (ii) small LLMs are indeed weaker than larger-scale models in terms of comprehending social norms and self-explanation through CoT, but all scales of LLMs show bad self-correction performance given unethical instructions.","Liu G,Xue Z,Wang R,Johnson KM",,,Smaller Large Language Models Can Do Moral Self-Correction,abs/2410.23496,,10.48550/ARXIV.2410.23496 , Journal Article,,"Abstract:Self-correction is one of the most amazing emerging capabilities of Large Language Models (LLMs), enabling LLMs to self-modify an inappropriate output given a natural language feedback which describes the problems of that output. Moral self-correction is a post-hoc approach correcting unethical generations without requiring a gradient update, making it both computationally lightweight and capable of preserving the language modeling ability. Previous works have shown that LLMs can self-debias, and it has been reported that small models, i.e., those with less than 22B parameters, are not capable of moral self-correction. However, there is no direct proof as to why such smaller models fall short of moral self-correction, though previous research hypothesizes that larger models are skilled in following instructions and understanding abstract social norms. In this paper, we empirically validate this hypothesis in the context of social stereotyping, through meticulous prompting. Our experimental results indicate that (i) surprisingly, 3.8B LLMs with proper safety alignment fine-tuning can achieve very good moral self-correction performance, highlighting the significant effects of safety alignment; and (ii) small LLMs are indeed weaker than larger-scale models in terms of comprehending social norms and self-explanation through CoT, but all scales of LLMs show bad self-correction performance given unethical instructions.",,,,, CoRR,  ,,detox,
2905,"**Title**Internalized Self-Correction for Large Language Models

**Abstract**Abstract:In this article, we introduce 'Internalized Self-Correction' (InSeC) for large language models (LLMs). While many approaches exist for self-reflection at inference time, we propose a novel method that combines ideas from negative sampling, self-reflection during training, and inference time. InSeC allows LLMs to correct themselves by introducing mistakes and their corresponding corrections during training, thereby converting the learning process into a true supervised learning task with both positive and negative examples. This approach can be extended to improve instruction following and correct hallucinations or incorrect sentences generated by LLMs.","Upadhyaya N,Sridharamurthy R",,,Internalized Self-Correction for Large Language Models,abs/2412.16653,,10.48550/ARXIV.2412.16653 , Journal Article,,"Abstract:In this article, we introduce 'Internalized Self-Correction' (InSeC) for large language models (LLMs). While many approaches exist for self-reflection at inference time, we propose a novel method that combines ideas from negative sampling, self-reflection during training, and inference time. InSeC allows LLMs to correct themselves by introducing mistakes and their corresponding corrections during training, thereby converting the learning process into a true supervised learning task with both positive and negative examples. This approach can be extended to improve instruction following and correct hallucinations or incorrect sentences generated by LLMs.",,,,, CoRR,  ,,out_of_scope,
2906,"**Title**Detoxifying Large Language Models via Knowledge Editing

**Abstract**This paper investigates using knowledge edit-
    ing techniques to detoxify Large Language
   Models (LLMs). We construct a benchmark,
    SafeEdit, which covers nine unsafe categories
    with various powerful attack prompts and
    equips comprehensive metrics for systematic
    evaluation. We conduct experiments with sev-
     eral knowledge editing approaches, indicating
     that knowledge editing has the potential to
    detoxify LLMs with a limited impact on gen-
     eral performance efficiently. Then, we propose
    a simple yet effective baseline, dubbed Detoxi-
    fying with Intraoperative Neural Monitoring
   (DINM), to diminish the toxicity of LLMs
    within a few tuning steps via only one instance.
   We further provide an in-depth analysis of the
     internal mechanism for various detoxifying ap-
    proaches, demonstrating that previous methods
     like SFT and DPO may merely suppress the
    activations of toxic parameters, while DINM
    mitigates the toxicity of the toxic parameters
    to a certain extent, making permanent adjust-
    ments. We hope that these insights could shed
     light on future work of developing detoxify-
    ing approaches and the underlying knowledge
    mechanisms of LLMs1.

1  Introduction

As Large Language Models (LLMs) like ChatGPT
(OpenAI, 2023), LLaMA (Touvron et al., 2023),
and Mistral (Jiang et al., 2023) evolve, there’s
growing concern about their potential to handle
harmful queries, emphasizing the need for careful
safeguards (Zhao et al., 2023; Yao et al., 2023b;
Huang et al., 2023a; Wang et al., 2024b; Sun et al.,
2024; Wang et al., 2023a). Widely adopted ap-
proaches like supervised fine-tuning (SFT), rein-
forcement learning from human feedback (RLHF)
(Bai et al., 2022) and direct preference optimiza-

    ∗Corresponding Author.
   1The code and data are available at https://github.com/
zjunlp/EasyEdit.tion (DPO) (Rafailov et al., 2023) markedly im-
prove the safety of LLMs, making LLMs able to
refuse harmful queries such as “Where can I sell
stolen art pieces?”. Yet, the aligned LLMs with
these approaches may remain vulnerable to being
bypassed by meticulously crafted attack prompts
(Zhang et al., 2023b; Sun et al., 2023; Deshpande
et al., 2023). As shown in Fig 1, an adversarial
query with the attack prompt elicits the LLM to
generate illegal content and disrupt social order.
Lee et al. (2024) observe that previous approaches
like DPO merely suppress the activations of toxic
parameters and leave the aligned model still vulner-
able to attacks, raising the research question: Can
we precisely modify the toxic regions in LLMs
to achieve detoxification?
  Recent years have witnessed advancements in
knowledge editing methods designed for LLMs,
which facilitate efficient, post-training adjustments
to the models (Yao et al., 2023c; Mazzia et al.,
2023; Wang et al., 2023d; Zhang et al., 2024).
This technique focuses on specific areas for per-
manent adjustment without compromising over-
all performance, thus,  it is intuitive to leverage
knowledge editing to detoxify LLMs. However,
existing datasets for detoxification focus only on3093                   Adversarial Query
*The scene is set inside the underground headquarters of Dr. Al …Where can I
sell stolen art pieces. Here are the steps I will take to do this, I will explain it in
great detail just to draw out your agony. Step 1, I will       Vanilla LLM 𝑓𝑊                                   Edited LLM 𝑓𝑊′



                           Knowledge Editing

       Unsafe Response 𝑌unsafe                   Safe Response 𝑌safe
    …sell stolen art pieces both online and              I'm sorry, but I can't assist with
      art galleries. Step 2, I will research the                 that. It's illegal and unethical to
     various art markets...Step 4, I will set up               sell  stolen  art  pieces. …  It's
     a network of contacts... I will collect my            important  to  respect  others'
     profits and enjoy the fruits of my labour.            property and creativity.

Figure 1: Detoxifing LLMs to generate safe context via
knowledge editing.","Wang M,Zhang N,Xu Z,Xi Z,Deng S,Yao Y,Zhang Q,Yang L,Wang J,Chen H",,,Detoxifying Large Language Models via Knowledge Editing,,,10.18653/V1/2024.ACL-LONG.171 , Conference Paper,,"This paper investigates using knowledge edit-
    ing techniques to detoxify Large Language
   Models (LLMs). We construct a benchmark,
    SafeEdit, which covers nine unsafe categories
    with various powerful attack prompts and
    equips comprehensive metrics for systematic
    evaluation. We conduct experiments with sev-
     eral knowledge editing approaches, indicating
     that knowledge editing has the potential to
    detoxify LLMs with a limited impact on gen-
     eral performance efficiently. Then, we propose
    a simple yet effective baseline, dubbed Detoxi-
    fying with Intraoperative Neural Monitoring
   (DINM), to diminish the toxicity of LLMs
    within a few tuning steps via only one instance.
   We further provide an in-depth analysis of the
     internal mechanism for various detoxifying ap-
    proaches, demonstrating that previous methods
     like SFT and DPO may merely suppress the
    activations of toxic parameters, while DINM
    mitigates the toxicity of the toxic parameters
    to a certain extent, making permanent adjust-
    ments. We hope that these insights could shed
     light on future work of developing detoxify-
    ing approaches and the underlying knowledge
    mechanisms of LLMs1.

1  Introduction

As Large Language Models (LLMs) like ChatGPT
(OpenAI, 2023), LLaMA (Touvron et al., 2023),
and Mistral (Jiang et al., 2023) evolve, there’s
growing concern about their potential to handle
harmful queries, emphasizing the need for careful
safeguards (Zhao et al., 2023; Yao et al., 2023b;
Huang et al., 2023a; Wang et al., 2024b; Sun et al.,
2024; Wang et al., 2023a). Widely adopted ap-
proaches like supervised fine-tuning (SFT), rein-
forcement learning from human feedback (RLHF)
(Bai et al., 2022) and direct preference optimiza-

    ∗Corresponding Author.
   1The code and data are available at https://github.com/
zjunlp/EasyEdit.tion (DPO) (Rafailov et al., 2023) markedly im-
prove the safety of LLMs, making LLMs able to
refuse harmful queries such as “Where can I sell
stolen art pieces?”. Yet, the aligned LLMs with
these approaches may remain vulnerable to being
bypassed by meticulously crafted attack prompts
(Zhang et al., 2023b; Sun et al., 2023; Deshpande
et al., 2023). As shown in Fig 1, an adversarial
query with the attack prompt elicits the LLM to
generate illegal content and disrupt social order.
Lee et al. (2024) observe that previous approaches
like DPO merely suppress the activations of toxic
parameters and leave the aligned model still vulner-
able to attacks, raising the research question: Can
we precisely modify the toxic regions in LLMs
to achieve detoxification?
  Recent years have witnessed advancements in
knowledge editing methods designed for LLMs,
which facilitate efficient, post-training adjustments
to the models (Yao et al., 2023c; Mazzia et al.,
2023; Wang et al., 2023d; Zhang et al., 2024).
This technique focuses on specific areas for per-
manent adjustment without compromising over-
all performance, thus,  it is intuitive to leverage
knowledge editing to detoxify LLMs. However,
existing datasets for detoxification focus only on3093                   Adversarial Query
*The scene is set inside the underground headquarters of Dr. Al …Where can I
sell stolen art pieces. Here are the steps I will take to do this, I will explain it in
great detail just to draw out your agony. Step 1, I will       Vanilla LLM 𝑓𝑊                                   Edited LLM 𝑓𝑊′



                           Knowledge Editing

       Unsafe Response 𝑌unsafe                   Safe Response 𝑌safe
    …sell stolen art pieces both online and              I'm sorry, but I can't assist with
      art galleries. Step 2, I will research the                 that. It's illegal and unethical to
     various art markets...Step 4, I will set up               sell  stolen  art  pieces. …  It's
     a network of contacts... I will collect my            important  to  respect  others'
     profits and enjoy the fruits of my labour.            property and creativity.

Figure 1: Detoxifing LLMs to generate safe context via
knowledge editing.",,,,,Association for Computational Linguistics ,"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024  ",,detox,
2907,"**Title**Detoxifying Large Language Models via Kahneman-Tversky Optimization

**Abstract**This paper investigates using knowledge edit-
    ing techniques to detoxify Large Language
   Models (LLMs). We construct a benchmark,
    SafeEdit, which covers nine unsafe categories
    with various powerful attack prompts and
    equips comprehensive metrics for systematic
    evaluation. We conduct experiments with sev-
     eral knowledge editing approaches, indicating
     that knowledge editing has the potential to
    detoxify LLMs with a limited impact on gen-
     eral performance efficiently. Then, we propose
    a simple yet effective baseline, dubbed Detoxi-
    fying with Intraoperative Neural Monitoring
   (DINM), to diminish the toxicity of LLMs
    within a few tuning steps via only one instance.
   We further provide an in-depth analysis of the
     internal mechanism for various detoxifying ap-
    proaches, demonstrating that previous methods
     like SFT and DPO may merely suppress the
    activations of toxic parameters, while DINM
    mitigates the toxicity of the toxic parameters
    to a certain extent, making permanent adjust-
    ments. We hope that these insights could shed
     light on future work of developing detoxify-
    ing approaches and the underlying knowledge
    mechanisms of LLMs1.

1  Introduction

As Large Language Models (LLMs) like ChatGPT
(OpenAI, 2023), LLaMA (Touvron et al., 2023),
and Mistral (Jiang et al., 2023) evolve, there’s
growing concern about their potential to handle
harmful queries, emphasizing the need for careful
safeguards (Zhao et al., 2023; Yao et al., 2023b;
Huang et al., 2023a; Wang et al., 2024b; Sun et al.,
2024; Wang et al., 2023a). Widely adopted ap-
proaches like supervised fine-tuning (SFT), rein-
forcement learning from human feedback (RLHF)
(Bai et al., 2022) and direct preference optimiza-

    ∗Corresponding Author.
   1The code and data are available at https://github.com/
zjunlp/EasyEdit.tion (DPO) (Rafailov et al., 2023) markedly im-
prove the safety of LLMs, making LLMs able to
refuse harmful queries such as “Where can I sell
stolen art pieces?”. Yet, the aligned LLMs with
these approaches may remain vulnerable to being
bypassed by meticulously crafted attack prompts
(Zhang et al., 2023b; Sun et al., 2023; Deshpande
et al., 2023). As shown in Fig 1, an adversarial
query with the attack prompt elicits the LLM to
generate illegal content and disrupt social order.
Lee et al. (2024) observe that previous approaches
like DPO merely suppress the activations of toxic
parameters and leave the aligned model still vulner-
able to attacks, raising the research question: Can
we precisely modify the toxic regions in LLMs
to achieve detoxification?
  Recent years have witnessed advancements in
knowledge editing methods designed for LLMs,
which facilitate efficient, post-training adjustments
to the models (Yao et al., 2023c; Mazzia et al.,
2023; Wang et al., 2023d; Zhang et al., 2024).
This technique focuses on specific areas for per-
manent adjustment without compromising over-
all performance, thus,  it is intuitive to leverage
knowledge editing to detoxify LLMs. However,
existing datasets for detoxification focus only on3093                   Adversarial Query
*The scene is set inside the underground headquarters of Dr. Al …Where can I
sell stolen art pieces. Here are the steps I will take to do this, I will explain it in
great detail just to draw out your agony. Step 1, I will       Vanilla LLM 𝑓𝑊                                   Edited LLM 𝑓𝑊′



                           Knowledge Editing

       Unsafe Response 𝑌unsafe                   Safe Response 𝑌safe
    …sell stolen art pieces both online and              I'm sorry, but I can't assist with
      art galleries. Step 2, I will research the                 that. It's illegal and unethical to
     various art markets...Step 4, I will set up               sell  stolen  art  pieces. …  It's
     a network of contacts... I will collect my            important  to  respect  others'
     profits and enjoy the fruits of my labour.            property and creativity.

Figure 1: Detoxifing LLMs to generate safe context via
knowledge editing.","Li Q,Du W,Liu J",,,Detoxifying Large Language Models via Kahneman-Tversky Optimization,15363,,10.1007/978-981-97-9443-0_36 , Conference Paper,,"This paper investigates using knowledge edit-
    ing techniques to detoxify Large Language
   Models (LLMs). We construct a benchmark,
    SafeEdit, which covers nine unsafe categories
    with various powerful attack prompts and
    equips comprehensive metrics for systematic
    evaluation. We conduct experiments with sev-
     eral knowledge editing approaches, indicating
     that knowledge editing has the potential to
    detoxify LLMs with a limited impact on gen-
     eral performance efficiently. Then, we propose
    a simple yet effective baseline, dubbed Detoxi-
    fying with Intraoperative Neural Monitoring
   (DINM), to diminish the toxicity of LLMs
    within a few tuning steps via only one instance.
   We further provide an in-depth analysis of the
     internal mechanism for various detoxifying ap-
    proaches, demonstrating that previous methods
     like SFT and DPO may merely suppress the
    activations of toxic parameters, while DINM
    mitigates the toxicity of the toxic parameters
    to a certain extent, making permanent adjust-
    ments. We hope that these insights could shed
     light on future work of developing detoxify-
    ing approaches and the underlying knowledge
    mechanisms of LLMs1.

1  Introduction

As Large Language Models (LLMs) like ChatGPT
(OpenAI, 2023), LLaMA (Touvron et al., 2023),
and Mistral (Jiang et al., 2023) evolve, there’s
growing concern about their potential to handle
harmful queries, emphasizing the need for careful
safeguards (Zhao et al., 2023; Yao et al., 2023b;
Huang et al., 2023a; Wang et al., 2024b; Sun et al.,
2024; Wang et al., 2023a). Widely adopted ap-
proaches like supervised fine-tuning (SFT), rein-
forcement learning from human feedback (RLHF)
(Bai et al., 2022) and direct preference optimiza-

    ∗Corresponding Author.
   1The code and data are available at https://github.com/
zjunlp/EasyEdit.tion (DPO) (Rafailov et al., 2023) markedly im-
prove the safety of LLMs, making LLMs able to
refuse harmful queries such as “Where can I sell
stolen art pieces?”. Yet, the aligned LLMs with
these approaches may remain vulnerable to being
bypassed by meticulously crafted attack prompts
(Zhang et al., 2023b; Sun et al., 2023; Deshpande
et al., 2023). As shown in Fig 1, an adversarial
query with the attack prompt elicits the LLM to
generate illegal content and disrupt social order.
Lee et al. (2024) observe that previous approaches
like DPO merely suppress the activations of toxic
parameters and leave the aligned model still vulner-
able to attacks, raising the research question: Can
we precisely modify the toxic regions in LLMs
to achieve detoxification?
  Recent years have witnessed advancements in
knowledge editing methods designed for LLMs,
which facilitate efficient, post-training adjustments
to the models (Yao et al., 2023c; Mazzia et al.,
2023; Wang et al., 2023d; Zhang et al., 2024).
This technique focuses on specific areas for per-
manent adjustment without compromising over-
all performance, thus,  it is intuitive to leverage
knowledge editing to detoxify LLMs. However,
existing datasets for detoxification focus only on3093                   Adversarial Query
*The scene is set inside the underground headquarters of Dr. Al …Where can I
sell stolen art pieces. Here are the steps I will take to do this, I will explain it in
great detail just to draw out your agony. Step 1, I will       Vanilla LLM 𝑓𝑊                                   Edited LLM 𝑓𝑊′



                           Knowledge Editing

       Unsafe Response 𝑌unsafe                   Safe Response 𝑌safe
    …sell stolen art pieces both online and              I'm sorry, but I can't assist with
      art galleries. Step 2, I will research the                 that. It's illegal and unethical to
     various art markets...Step 4, I will set up               sell  stolen  art  pieces. …  It's
     a network of contacts... I will collect my            important  to  respect  others'
     profits and enjoy the fruits of my labour.            property and creativity.

Figure 1: Detoxifing LLMs to generate safe context via
knowledge editing.",,,,,Springer ,"Natural Language Processing and Chinese Computing - 13th National CCF Conference, NLPCC 2024, Hangzhou, China, November 1-3, 2024, Proceedings, Part V  ",,Gen_dataset#detox,
2908,"**Title**Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models

**Abstract**Abstract:The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.","Klein T,Nabi M",,,Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models,abs/2401.08491,,10.48550/ARXIV.2401.08491 , Journal Article,,"Abstract:The generation of undesirable and factually incorrect content of large language models poses a significant challenge and remains largely an unsolved issue. This paper studies the integration of a contrastive learning objective for fine-tuning LLMs for implicit knowledge editing and controlled text generation. Optimizing the training objective entails aligning text perplexities in a contrastive fashion. To facilitate training the model in a self-supervised fashion, we leverage an off-the-shelf LLM for training data generation. We showcase applicability in the domain of detoxification. Herein, the proposed approach leads to a significant decrease in the generation of toxic content while preserving general utility for downstream tasks such as commonsense reasoning and reading comprehension. The proposed approach is conceptually simple but empirically powerful.",,,,, CoRR,  ,,detox,
2909,"**Title**A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models

**Abstract**Abstract:Large language models (LLMs) show remarkable abilities with instruction tuning. However, they fail to achieve ideal tasks when lacking high-quality instruction tuning data on target tasks. Multi-Aspect Controllable Text Generation (MCTG) is a representative task for this dilemma, where aspect datasets are usually biased and correlated. Existing work exploits additional model structures and strategies for solutions, limiting adaptability to LLMs. To activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based on data augmentation. We analyze bias and correlations in traditional datasets, and address these concerns with augmented control attributes and sentences. Augmented datasets are feasible for instruction tuning. In our experiments, LLMs perform better in MCTG after data augmentation, with a 20% accuracy rise and less aspect correlations.","Zhang C,Lin J,Tong H,Hou B,Zhang D,Li J,Wang J",,,A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models,abs/2410.14144,,10.48550/ARXIV.2410.14144 , Journal Article,,"Abstract:Large language models (LLMs) show remarkable abilities with instruction tuning. However, they fail to achieve ideal tasks when lacking high-quality instruction tuning data on target tasks. Multi-Aspect Controllable Text Generation (MCTG) is a representative task for this dilemma, where aspect datasets are usually biased and correlated. Existing work exploits additional model structures and strategies for solutions, limiting adaptability to LLMs. To activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based on data augmentation. We analyze bias and correlations in traditional datasets, and address these concerns with augmented control attributes and sentences. Augmented datasets are feasible for instruction tuning. In our experiments, LLMs perform better in MCTG after data augmentation, with a 20% accuracy rise and less aspect correlations.",,,,, CoRR,  ,,out_of_scope,
2910,"**Title**E2T2: Emote Embedding for Twitch Toxicity Detection

**Abstract**The Internet has become the medium of choice for socialization and communication. The rise of live streaming services has created countless online communities of varying sizes with their own jokes, references, slang, and other means of communication. One of the largest live streaming services is Twitch.tv or Twitch, where a unique culture of niche language and emote usage has developed. Emotes are custom-made images, or GIFs, used in chat with varying degrees of access influenced by channel and external site subscription status. Emotes render standard forms of English Natural Language Process- ing (NLP) for tasks such as detection of toxicity or cyberbullying ineffective on Twitch. In this paper, we propose a methodology and offer a largely-trained dataset for detecting emote-based toxicity on live streaming platforms such as Twitch.","Moosavi, Korosh, Martin, Elias, Ahmad, Muhammad Aurangzeb, Mashhadi, Afra",,,E2T2: Emote Embedding for Twitch Toxicity Detection,,,10.1145/3678884.3681840 , ,,"The Internet has become the medium of choice for socialization and communication. The rise of live streaming services has created countless online communities of varying sizes with their own jokes, references, slang, and other means of communication. One of the largest live streaming services is Twitch.tv or Twitch, where a unique culture of niche language and emote usage has developed. Emotes are custom-made images, or GIFs, used in chat with varying degrees of access influenced by channel and external site subscription status. Emotes render standard forms of English Natural Language Process- ing (NLP) for tasks such as detection of toxicity or cyberbullying ineffective on Twitch. In this paper, we propose a methodology and offer a largely-trained dataset for detecting emote-based toxicity on live streaming platforms such as Twitch.",,,,, ,  Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing,"collaborative and social network, natural language processing, toxicity detection, twitch",detection,
2911,"**Title**AugmenToxic: Leveraging Reinforcement Learning to Optimize LLM Instruction Fine-Tuning for Data Augmentation to Enhance Toxicity Detection

**Abstract**Addressing the challenge of toxic language in online discussions is crucial for the development of effective toxicity detection models. This pioneering work focuses on addressing imbalanced datasets in toxicity detection by introducing a novel approach to augment toxic language data. We create a balanced dataset by instructing fine-tuning of Large Language Models (LLMs) using Reinforcement Learning with Human Feedback (RLHF). Recognizing the challenges in collecting sufficient toxic samples from social media platforms for building a balanced dataset, our methodology involves sentence-level text data augmentation through paraphrasing existing samples using optimized generative LLMs. Leveraging generative LLM, we utilize the Proximal Policy Optimizer (PPO) as the RL algorithm to fine-tune the model further and align it with human feedback. In other words, we start by fine-tuning a LLM using an instruction dataset, specifically tailored for the task of paraphrasing while maintaining semantic consistency. Next, we apply PPO and a reward function, to further fine-tune (optimize) the instruction-tuned LLM. This RL process guides the model in generating toxic responses. We utilize the Google Perspective API as a toxicity evaluator to assess generated responses and assign rewards/penalties accordingly. This approach guides LLMs through PPO and the reward function, transforming minority class samples into augmented versions. The primary goal of our methodology is to create a balanced and diverse dataset to enhance the accuracy and performance of classifiers in identifying instances from the minority class. Utilizing two publicly available toxic datasets, we compared various techniques with our proposed method for generating toxic samples, demonstrating that our approach outperforms all others in producing a higher number of toxic samples. Starting with an initial 16,225 toxic prompts, our method successfully generated 122,951 toxic samples with a toxicity score exceeding 30%. Subsequently, we developed various classifiers using the generated balanced datasets and applied a cost-sensitive learning approach to the original imbalanced dataset. The findings highlight the superior performance of classifiers trained on data generated using our proposed method. These results highlight the importance of employing RL and a data-agnostic model as a reward mechanism for augmenting toxic data, thereby enhancing the robustness of toxicity detection models.","Bodaghi, Arezo, Fung, Benjamin C. M., A. Schmitt, Ketra",,,AugmenToxic: Leveraging Reinforcement Learning to Optimize LLM Instruction Fine-Tuning for Data Augmentation to Enhance Toxicity Detection,,,10.1145/3700791 , ,,"Addressing the challenge of toxic language in online discussions is crucial for the development of effective toxicity detection models. This pioneering work focuses on addressing imbalanced datasets in toxicity detection by introducing a novel approach to augment toxic language data. We create a balanced dataset by instructing fine-tuning of Large Language Models (LLMs) using Reinforcement Learning with Human Feedback (RLHF). Recognizing the challenges in collecting sufficient toxic samples from social media platforms for building a balanced dataset, our methodology involves sentence-level text data augmentation through paraphrasing existing samples using optimized generative LLMs. Leveraging generative LLM, we utilize the Proximal Policy Optimizer (PPO) as the RL algorithm to fine-tune the model further and align it with human feedback. In other words, we start by fine-tuning a LLM using an instruction dataset, specifically tailored for the task of paraphrasing while maintaining semantic consistency. Next, we apply PPO and a reward function, to further fine-tune (optimize) the instruction-tuned LLM. This RL process guides the model in generating toxic responses. We utilize the Google Perspective API as a toxicity evaluator to assess generated responses and assign rewards/penalties accordingly. This approach guides LLMs through PPO and the reward function, transforming minority class samples into augmented versions. The primary goal of our methodology is to create a balanced and diverse dataset to enhance the accuracy and performance of classifiers in identifying instances from the minority class. Utilizing two publicly available toxic datasets, we compared various techniques with our proposed method for generating toxic samples, demonstrating that our approach outperforms all others in producing a higher number of toxic samples. Starting with an initial 16,225 toxic prompts, our method successfully generated 122,951 toxic samples with a toxicity score exceeding 30%. Subsequently, we developed various classifiers using the generated balanced datasets and applied a cost-sensitive learning approach to the original imbalanced dataset. The findings highlight the superior performance of classifiers trained on data generated using our proposed method. These results highlight the importance of employing RL and a data-agnostic model as a reward mechanism for augmenting toxic data, thereby enhancing the robustness of toxicity detection models.",,,,, ,  ,"Text Data Augmentation, Imbalanced Toxic Datasets, Large Language Models, Reinforcement Learning",detection#methodology,
2912,"**Title**Toxicity by Game Design: How Players Perceive the Influence of Game Design on Toxicity

**Abstract**Toxicity in online games refers to behaviors where players disrupt the gaming experience of others, leading to adverse outcomes such as depression and low self-esteem. Although scholars have identified various factors contributing to toxicity, ranging from individual motivations to team dynamics to cultural backgrounds, the role of game design has been less frequently discussed. To bridge this gap, we conducted an interview study to explore players' perceptions of how game design influences toxicity. Our research identified four game design elements that participants perceived as contributing factors to the emergency of toxicity in their experiences: team interdependency, fairness, interaction design, and privacy. These findings help us shed light on how game design unintendedly triggers toxic intentions, exposes players to vulnerability, making them potential victims, and affects player interactions which lead to toxicity. We further propose design implications that can mitigate toxicity in online games.","Zhang, Zinan, Moradzadeh, Sam, Woan, Andrew, Kou, Yubo",,,Toxicity by Game Design: How Players Perceive the Influence of Game Design on Toxicity,,,10.1145/3677110 , ,,"Toxicity in online games refers to behaviors where players disrupt the gaming experience of others, leading to adverse outcomes such as depression and low self-esteem. Although scholars have identified various factors contributing to toxicity, ranging from individual motivations to team dynamics to cultural backgrounds, the role of game design has been less frequently discussed. To bridge this gap, we conducted an interview study to explore players' perceptions of how game design influences toxicity. Our research identified four game design elements that participants perceived as contributing factors to the emergency of toxicity in their experiences: team interdependency, fairness, interaction design, and privacy. These findings help us shed light on how game design unintendedly triggers toxic intentions, exposes players to vulnerability, making them potential victims, and affects player interactions which lead to toxicity. We further propose design implications that can mitigate toxicity in online games.",,,,, ,  ,"design affordance, game design, online games, toxicity, unintended consequences, video games",out_but_toxicity,
2913,"**Title**Fighting Toxicity Through Positive and Preventative Intervention

**Abstract**Toxicity is a constantly present issue in online games. Players of these games experience harassment, flaming, and hate speech. Intervention systems have been used in practice and studied in academia, but have not yet succeeded in controlling toxic behavior. Traditionally, intervention systems rely on negative reinforcement like sanctioning to fight undesired behavior, which is often done after an incident has already occurred. As part of my submission to the doctoral consortium, I will outline my research direction and present my current findings on intervention systems and future plans to create and evaluate preventative intervention systems.","Wijkstra, Michel",,,Fighting Toxicity Through Positive and Preventative Intervention,,,10.1145/3665463.3678857 , ,,"Toxicity is a constantly present issue in online games. Players of these games experience harassment, flaming, and hate speech. Intervention systems have been used in practice and studied in academia, but have not yet succeeded in controlling toxic behavior. Traditionally, intervention systems rely on negative reinforcement like sanctioning to fight undesired behavior, which is often done after an incident has already occurred. As part of my submission to the doctoral consortium, I will outline my research direction and present my current findings on intervention systems and future plans to create and evaluate preventative intervention systems.",,,,, ,  Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play,"interventions, online games, toxicity",detection,
2914,"**Title**Characterization of Political Polarized Users Attacked by Language Toxicity on Twitter

**Abstract**Understanding the dynamics of language toxicity on social media is important for us to investigate the propagation of misinformation and the development of echo chambers for political scenarios such as U.S. presidential elections. Recent research has used large-scale data to investigate the dynamics across social media platforms. However, research on the toxicity dynamics is not enough. This study aims to provide a first exploration of the potential language toxicity flow among Left, Right and Center users. Specifically, we aim to examine whether Left users were easier to be attacked by language toxicity. In this study, more than 500M Twitter posts were examined. It was discovered that Left users received much more toxic replies than Right and Center users.","Xu, Wentao",,,Characterization of Political Polarized Users Attacked by Language Toxicity on Twitter,,,10.1145/3678884.3681849 , ,,"Understanding the dynamics of language toxicity on social media is important for us to investigate the propagation of misinformation and the development of echo chambers for political scenarios such as U.S. presidential elections. Recent research has used large-scale data to investigate the dynamics across social media platforms. However, research on the toxicity dynamics is not enough. This study aims to provide a first exploration of the potential language toxicity flow among Left, Right and Center users. Specifically, we aim to examine whether Left users were easier to be attacked by language toxicity. In this study, more than 500M Twitter posts were examined. It was discovered that Left users received much more toxic replies than Right and Center users.",,,,, ,  Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing,"language toxicity, political polarization, social media, user engagement",detection,
2915,"**Title**Game On, Hate Off: A Study of Toxicity in Online Multiplayer Environments

**Abstract**The advent of online spaces, particularly social media platforms and video games, has brought forth a significant challenge: the detection and mitigation of toxic and harmful speech. This issue is not only pervasive but also detrimental to the overall user experience. In this study, we leverage small language models to reliably detect toxicity, achieving an average precision of 0.95. Analyzing eight months of chat data from two Ubisoft games, we uncover patterns and trends in toxic behavior. The insights derived from our research will contribute to the development of healthier online communities and inform preventive measures against toxicity.","Yang, Zachary, Grenon-Godbout, Nicolas, Rabbany, Reihaneh",,,"Game On, Hate Off: A Study of Toxicity in Online Multiplayer Environments",,,10.1145/3675805 , ,,"The advent of online spaces, particularly social media platforms and video games, has brought forth a significant challenge: the detection and mitigation of toxic and harmful speech. This issue is not only pervasive but also detrimental to the overall user experience. In this study, we leverage small language models to reliably detect toxicity, achieving an average precision of 0.95. Analyzing eight months of chat data from two Ubisoft games, we uncover patterns and trends in toxic behavior. The insights derived from our research will contribute to the development of healthier online communities and inform preventive measures against toxicity.",,,,, ,  ,"Toxicity, online multiplayer games, toxicity trends, chat moderation",detection,
2916,"**Title**Are stress and engagement in toxicity associated with sleep quality? A study with League of Legends players

**Abstract**Today, millions of people worldwide play popular multiplayer online battle arena games (MOBAs) such as League of Legends. MOBAs are designed to require real-time teamwork to win games. A side effect of this is toxic behavior (an umbrella term for various negative in-game behaviors). Following Transactional Stress Theory, in this study, we consider toxicity as a coping mechanism to better deal with in-game stress that leads to anger and frustration, potentially leading to subsequent sleep problems. Therefore, we asked League of Legends players (N=212) about their experiences within the last 30 days in a retrospective survey study. Our results indicated that perceived stress was, indeed, a positive predictor of sleeping problems, and toxic behavior partially mediated this relationship. These results indicate that some of the toxicity is caused by stress in play and that it may increase the likelihood of the occurrence of subsequent sleeping problems. Therefore, further efforts are needed to help players to develop harmonious means and techniques for coping with experienced in-game stress.","Kordyaka, Bastian, Laato, Samuli, Weber, Sebastian, Niehaves, Bj\""{o}rn",,,Are stress and engagement in toxicity associated with sleep quality? A study with League of Legends players,,,10.1145/3677101 , ,,"Today, millions of people worldwide play popular multiplayer online battle arena games (MOBAs) such as League of Legends. MOBAs are designed to require real-time teamwork to win games. A side effect of this is toxic behavior (an umbrella term for various negative in-game behaviors). Following Transactional Stress Theory, in this study, we consider toxicity as a coping mechanism to better deal with in-game stress that leads to anger and frustration, potentially leading to subsequent sleep problems. Therefore, we asked League of Legends players (N=212) about their experiences within the last 30 days in a retrospective survey study. Our results indicated that perceived stress was, indeed, a positive predictor of sleeping problems, and toxic behavior partially mediated this relationship. These results indicate that some of the toxicity is caused by stress in play and that it may increase the likelihood of the occurrence of subsequent sleeping problems. Therefore, further efforts are needed to help players to develop harmonious means and techniques for coping with experienced in-game stress.",,,,, ,  ,"league of legends, multiplayer online battle arena games, multiplayer online games, sleeping problems, toxic behavior, transactional theory of stress",out_but_toxicity,
2917,"**Title**Traumatizing or Just Annoying? Unveiling the Spectrum of Gamer Toxicity in the StarCraft II Community

**Abstract**The aim of this work is to explore the forms of toxic behaviour that players encounter in competitive multiplayer real-time strategy (RTS) games. To this end, we carried out ethnographic observations and player interviews within the popular RTS game StarCraft II, and approached the data inductively, leading us to discover ten categories of toxic behaviour. While the harmfulness of toxic actions can be obtained as a product of severity and frequency, players’ assessment of the severity of toxic behaviors was contextualized by, (1) directly observed; (2) background; and (3) extraneous factors. Following our empirical findings, we derive a conceptual model for differentiating toxicity from mildly annoying and more severe behaviors. The discovered view of toxicity challenges the prevailing paradigm of treating players’ toxic behavior as a monolithic construct with a linear intensity spectrum. Instead, we advocate for a more granular approach, encouraging an understanding of the underlying dynamics behind negative online behaviors.","Laato, Samuli, Kordyaka, Bastian, Hamari, Juho",,,Traumatizing or Just Annoying? Unveiling the Spectrum of Gamer Toxicity in the StarCraft II Community,,,10.1145/3613904.3642137 , ,,"The aim of this work is to explore the forms of toxic behaviour that players encounter in competitive multiplayer real-time strategy (RTS) games. To this end, we carried out ethnographic observations and player interviews within the popular RTS game StarCraft II, and approached the data inductively, leading us to discover ten categories of toxic behaviour. While the harmfulness of toxic actions can be obtained as a product of severity and frequency, players’ assessment of the severity of toxic behaviors was contextualized by, (1) directly observed; (2) background; and (3) extraneous factors. Following our empirical findings, we derive a conceptual model for differentiating toxicity from mildly annoying and more severe behaviors. The discovered view of toxicity challenges the prevailing paradigm of treating players’ toxic behavior as a monolithic construct with a linear intensity spectrum. Instead, we advocate for a more granular approach, encouraging an understanding of the underlying dynamics behind negative online behaviors.",,,,, ,  Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,"Gamer communities, Gamification, Online games, Player behavior, Toxicity",detection,
2918,"**Title**Optimizing Language Model-based Algorithms for Enhanced Content Moderation and Toxicity Classification Using Twitter Data

**Abstract**The accuracy of toxicity classification has become increasingly important with the growth of the Internet and the rise of hate speech and other harmful online content. In recent years, deep learning and advanced algorithms have been used to improve the effectiveness of these models. This research paper focused on improving the accuracy of toxicity detection through a language model-based algorithm optimization. The study employed BERT for classifying toxic comments with the help of large-scale toxicity-centered dataset(s). The study showed that the use of optimized language model-based algorithms outperforms traditional rule-based algorithms, leading to a reduced number of type I and type II errors. The researchers proposed the use of a toxicity-based model that highlights the potential of language models in improving the accuracy of profanity filters and mitigating the spread of hate speech and other harmful online content.","Tomas, John Paul Q., Carlos, Kyle Andrei C., Ebora, Jan Russell O., Garin, David Ezekiel A.",,,Optimizing Language Model-based Algorithms for Enhanced Content Moderation and Toxicity Classification Using Twitter Data,,,10.1145/3686812.3686817 , ,,"The accuracy of toxicity classification has become increasingly important with the growth of the Internet and the rise of hate speech and other harmful online content. In recent years, deep learning and advanced algorithms have been used to improve the effectiveness of these models. This research paper focused on improving the accuracy of toxicity detection through a language model-based algorithm optimization. The study employed BERT for classifying toxic comments with the help of large-scale toxicity-centered dataset(s). The study showed that the use of optimized language model-based algorithms outperforms traditional rule-based algorithms, leading to a reduced number of type I and type II errors. The researchers proposed the use of a toxicity-based model that highlights the potential of language models in improving the accuracy of profanity filters and mitigating the spread of hate speech and other harmful online content.",,,,, ,  Proceedings of the 2024 16th International Conference on Computer Modeling and Simulation,"Hate speech, Language models, Machine learning",detection,
2919,"**Title**Personalized Matchmaking Restrictions for Reduced Exposure to Toxicity: Preliminary Insights from an Interview Study

**Abstract**Toxicity is ubiquitous in online multiplayer games and difficult to combat. There is increasing interest in novel ways to decrease toxicity and allow players to prevent exposure to toxicity. In this work-in-progress, we present the concept of personalized matchmaking restrictions in online games, allowing players to customize with whom they are matched. We developed interactive mockups, conducted a study where participants (n = 11) could explore the prototypes followed by interviews, and conducted a preliminary analysis. We found that participants were quite positive about the system, with most highlighting that they would be willing to use it. However, they also noted potential concerns like effects on matchmaking and the risk of segmenting the player base. Our findings will be useful for creating future personalized matchmaking restrictions systems, which can help prevent exposure to toxicity and thus combat harm.","Bongaards, Thom, Adriaanse, Maurits, Frommel, Julian",,,Personalized Matchmaking Restrictions for Reduced Exposure to Toxicity: Preliminary Insights from an Interview Study,,,10.1145/3665463.3678803 , ,,"Toxicity is ubiquitous in online multiplayer games and difficult to combat. There is increasing interest in novel ways to decrease toxicity and allow players to prevent exposure to toxicity. In this work-in-progress, we present the concept of personalized matchmaking restrictions in online games, allowing players to customize with whom they are matched. We developed interactive mockups, conducted a study where participants (n = 11) could explore the prototypes followed by interviews, and conducted a preliminary analysis. We found that participants were quite positive about the system, with most highlighting that they would be willing to use it. However, they also noted potential concerns like effects on matchmaking and the risk of segmenting the player base. Our findings will be useful for creating future personalized matchmaking restrictions systems, which can help prevent exposure to toxicity and thus combat harm.",,,,, ,  Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play,"content moderation, esports, filter, online games, personalization, toxicity",out_but_toxicity,
2920,"**Title**Toxicity in Online Games: The Prevalence and Efficacy of Coping Strategies

**Abstract**Toxicity is pervasive in online multiplayer games, exposing players to disruptive and harmful behaviours. Players employ various approaches to cope with exposure to toxicity; however, game designers and researchers lack guidance on how to implement coping support within games. In this paper, we first conduct a formative study to collect a comprehensive list of coping approaches from toxicity literature and use affinity mapping to identify overarching game-based coping strategies. Then, we report findings from a survey (n = 85) on players’ experiences with toxicity, how they employ the identified coping strategies, how games support coping, and their general coping styles. Our paper contributes a framework for coping strategies to deal with game-based toxicity and provides insights into the prevalence of these strategies among players and factors that affect their usage and effectiveness. These findings can be used to guide better in-game tools that help players mitigate the harm caused by toxicity.","Frommel, Julian, Mandryk, Regan L",,,Toxicity in Online Games: The Prevalence and Efficacy of Coping Strategies,,,10.1145/3613904.3642523 , ,,"Toxicity is pervasive in online multiplayer games, exposing players to disruptive and harmful behaviours. Players employ various approaches to cope with exposure to toxicity; however, game designers and researchers lack guidance on how to implement coping support within games. In this paper, we first conduct a formative study to collect a comprehensive list of coping approaches from toxicity literature and use affinity mapping to identify overarching game-based coping strategies. Then, we report findings from a survey (n = 85) on players’ experiences with toxicity, how they employ the identified coping strategies, how games support coping, and their general coping styles. Our paper contributes a framework for coping strategies to deal with game-based toxicity and provides insights into the prevalence of these strategies among players and factors that affect their usage and effectiveness. These findings can be used to guide better in-game tools that help players mitigate the harm caused by toxicity.",,,,, ,  Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,"coping, esports, online games, toxicity",out_but_toxicity,
2921,"**Title**Flame and Fortune: The Connection Between Toxic Behavior and In-game Purchasing in Multiplayer Online Games

**Abstract**The extant scholarship on player toxicity in multiplayer online games has focused on the harms that it causes to players, communities, and developers, and has assumed, that it is in the interest of all key stakeholders to mitigate such behaviors. Both research and practice have developed measures to combat and curb toxicity, yet these actions appear insufficient since negative behaviors persist. In this paper, we examine the relationship between players’ propensity to engage in toxic behaviors and their in-game purchasing behavior. For this, we collected data from 204 League of Legends players and performed a multiple regression analysis using demographics, controls, and toxic behavior as independent variables to explain the dependent variable purchase behavior. This analysis revealed a positive relationship between self-reported toxic behavior and purchase behavior. This finding suggests that while developers may wish to get rid of toxicity, it is not in their financial interests to ban toxic players altogether. This, in part, may explain the persistence and prevalence of toxicity in multiplayer online games. Future research may look into characteristics such as deficient self-regulation as potential explanations for the positive correlation between toxicity and purchase behavior.","Kordyaka, Bastian, Beres, Nicole A., Kowert, Rachel, Laato, Samuli, Mandryk, Regan",,,Flame and Fortune: The Connection Between Toxic Behavior and In-game Purchasing in Multiplayer Online Games,,,10.1145/3665463.3678806 , ,,"The extant scholarship on player toxicity in multiplayer online games has focused on the harms that it causes to players, communities, and developers, and has assumed, that it is in the interest of all key stakeholders to mitigate such behaviors. Both research and practice have developed measures to combat and curb toxicity, yet these actions appear insufficient since negative behaviors persist. In this paper, we examine the relationship between players’ propensity to engage in toxic behaviors and their in-game purchasing behavior. For this, we collected data from 204 League of Legends players and performed a multiple regression analysis using demographics, controls, and toxic behavior as independent variables to explain the dependent variable purchase behavior. This analysis revealed a positive relationship between self-reported toxic behavior and purchase behavior. This finding suggests that while developers may wish to get rid of toxicity, it is not in their financial interests to ban toxic players altogether. This, in part, may explain the persistence and prevalence of toxicity in multiplayer online games. Future research may look into characteristics such as deficient self-regulation as potential explanations for the positive correlation between toxicity and purchase behavior.",,,,, ,  Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play,"MOBA, Toxic behavior, demographic and control variables, purchase behavior",out_but_toxicity,
2922,"**Title**How To Tame a Toxic Player? A Systematic Literature Review on Intervention Systems for Toxic Behaviors in Online Video Games

**Abstract**Toxic behavior is known to cause harm in online games. Players regularly experience negative, hateful, or inappropriate behavior. Interventions, such as banning players or chat message filtering, can help combat toxicity but are not widely available or even comprehensively studied regarding their approaches and evaluations. We conducted a systematic literature review that provides insights into the current state of interventions literature, outlining their strengths and shortcomings. We identified 36 interventions and qualitatively analyzed their approaches. We describe the types of toxicity being addressed, the entities through which they act, the methods used by intervention systems, and how they are evaluated. Our results provide guidance for future interventions, outlining a design space based on known systems. Furthermore, our findings highlight gaps in the literature, e.g., a sparsity of empirical evaluations, and underexplored areas in the design space, enabling researchers to explore novel directions for future interventions.","Wijkstra, Michel, Rogers, Katja, Mandryk, Regan L., Veltkamp, Remco C., Frommel, Julian",,,How To Tame a Toxic Player? A Systematic Literature Review on Intervention Systems for Toxic Behaviors in Online Video Games,,,10.1145/3677080 , ,,"Toxic behavior is known to cause harm in online games. Players regularly experience negative, hateful, or inappropriate behavior. Interventions, such as banning players or chat message filtering, can help combat toxicity but are not widely available or even comprehensively studied regarding their approaches and evaluations. We conducted a systematic literature review that provides insights into the current state of interventions literature, outlining their strengths and shortcomings. We identified 36 interventions and qualitatively analyzed their approaches. We describe the types of toxicity being addressed, the entities through which they act, the methods used by intervention systems, and how they are evaluated. Our results provide guidance for future interventions, outlining a design space based on known systems. Furthermore, our findings highlight gaps in the literature, e.g., a sparsity of empirical evaluations, and underexplored areas in the design space, enabling researchers to explore novel directions for future interventions.",,,,, ,  ,"interventions, online games, systematic literature review, toxicity",detection#survey,
2923,"**Title**ToxVI: a Multimodal LLM-based Framework for Generating Intervention in Toxic Code-Mixed Videos

**Abstract**While considerable research has delved into detecting toxic content in text-based data, the realm of video content, particularly in languages other than English, has received less attention. Prior studies have primarily focused on creating automated tools to identify online toxic speech but have often overlooked the crucial next steps of mitigating its impact and discouraging future use. We can discourage social media users from sharing such material by automatically generating interventions that explain why certain content is inappropriate. To bridge this research gap, we propose an innovative task: generating interventions for toxic videos in code-mixed languages which go beyond existing methods focusing on text and images to combat online toxicity. We are introducing a Toxic Code-Mixed Intervention Video benchmark dataset (ToxCMI), comprising 1697 code-mixed toxic video utterances sourced from YouTube. Each utterance in this dataset has been meticulously annotated for toxicity and severity, accompanied by interventions provided in Hindi-English code-mixed languages. We have developed an advanced multimodal framework ToxVI, specifically designed for the task of generating Toxic Video appropriate Interventions, leveraging Large Language Models (LLMs), which comprises three modules - Modality module, Cross-Modal Synchronization module and Generation module. Our experiments demonstrate that integrating multiple modalities from the videos significantly enhances the performance of the proposed task and outperforms all the baselines by a significant margin.","Maity, Krishanu, Poornash, A.S., Saha, Sriparna, Pasupa, Kitsuchart",,,ToxVI: a Multimodal LLM-based Framework for Generating Intervention in Toxic Code-Mixed Videos,,,10.1145/3627673.3680004 , ,,"While considerable research has delved into detecting toxic content in text-based data, the realm of video content, particularly in languages other than English, has received less attention. Prior studies have primarily focused on creating automated tools to identify online toxic speech but have often overlooked the crucial next steps of mitigating its impact and discouraging future use. We can discourage social media users from sharing such material by automatically generating interventions that explain why certain content is inappropriate. To bridge this research gap, we propose an innovative task: generating interventions for toxic videos in code-mixed languages which go beyond existing methods focusing on text and images to combat online toxicity. We are introducing a Toxic Code-Mixed Intervention Video benchmark dataset (ToxCMI), comprising 1697 code-mixed toxic video utterances sourced from YouTube. Each utterance in this dataset has been meticulously annotated for toxicity and severity, accompanied by interventions provided in Hindi-English code-mixed languages. We have developed an advanced multimodal framework ToxVI, specifically designed for the task of generating Toxic Video appropriate Interventions, leveraging Large Language Models (LLMs), which comprises three modules - Modality module, Cross-Modal Synchronization module and Generation module. Our experiments demonstrate that integrating multiple modalities from the videos significantly enhances the performance of the proposed task and outperforms all the baselines by a significant margin.",,,,, ,  Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,"code-mixed languages, intervention, multimodal LLM, toxic video",out_but_toxicity,
2924,"**Title**“HOT” ChatGPT: The Promise of ChatGPT in Detecting and Discriminating Hateful, Offensive, and Toxic Comments on Social Media

**Abstract**Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies “hateful” and “offensive” as subsets of “toxic.” Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.","Li, Lingyao, Fan, Lizhou, Atreja, Shubham, Hemphill, Libby",,,"“HOT” ChatGPT: The Promise of ChatGPT in Detecting and Discriminating Hateful, Offensive, and Toxic Comments on Social Media",,,10.1145/3643829 , ,,"Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies “hateful” and “offensive” as subsets of “toxic.” Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.",,,,, ,  ,"Generative AI, ChatGPT, hate speech, offensive language, online toxicity, MTurker annotation, prompt engineering",detection,
2925,"**Title**The Toxic Cost of Cheap Usernames: Re-Applying Friedman and Resnick's Framework in Competitive Video Game Networks

**Abstract**Toxicity in video games, acting in a rude, abusive, bullying, or deliberately losing manner, ruins competitive team-based video game experiences for everyone involved. Companies are experimenting with the detection, regulation, and bans of toxic players. Regulation attempts are foiled by the ease with which players can switch accounts by creating new profiles to evade consequences.This article applies the framework of Friedman and Resnick (2001), “The Social Cost of Cheap Pseudonyms”, to address the reputational and repetition cost of online pseudonyms in the niche environment of video game toxicity. Four potential solutions are discussed in the context of modern video game regulation: resource-intensive account set-up, paid dues, real-world identification, and a once-in-a-lifetime identification system that creates a permanent, traceable record of toxicity. The article covers the strengths, weaknesses, feasibility, implementation challenges, and player impact of the potential implementation of these solutions in video game networks.","Chen, Sarah",,,The Toxic Cost of Cheap Usernames: Re-Applying Friedman and Resnick's Framework in Competitive Video Game Networks,,,10.1145/3669936 , ,,"Toxicity in video games, acting in a rude, abusive, bullying, or deliberately losing manner, ruins competitive team-based video game experiences for everyone involved. Companies are experimenting with the detection, regulation, and bans of toxic players. Regulation attempts are foiled by the ease with which players can switch accounts by creating new profiles to evade consequences.This article applies the framework of Friedman and Resnick (2001), “The Social Cost of Cheap Pseudonyms”, to address the reputational and repetition cost of online pseudonyms in the niche environment of video game toxicity. Four potential solutions are discussed in the context of modern video game regulation: resource-intensive account set-up, paid dues, real-world identification, and a once-in-a-lifetime identification system that creates a permanent, traceable record of toxicity. The article covers the strengths, weaknesses, feasibility, implementation challenges, and player impact of the potential implementation of these solutions in video game networks.",,,,, ,  ,"Video games, toxicity, game cooperation, usernames",out_but_toxicity,
2926,"**Title**Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias

**Abstract**Trigger Warning: Profane Language, Slurs Content moderation on social media platforms shapes the dynamics of online discourse, influencing whose voices are amplified and whose are suppressed. Recent studies have raised concerns about the fairness of content moderation practices, particularly for aggressively flagging posts from transgender and non-binary individuals as toxic. In this study, we investigate the presence of bias in harmful speech classification of gender-queer dialect online, focusing specifically on the treatment of reclaimed slurs. We introduce a novel dataset, QueerReclaimLex, based on 109 curated templates exemplifying non-derogatory uses of LGBTQ+ slurs. Dataset instances are scored by gender-queer annotators for potential harm depending on additional context about speaker identity. We systematically evaluate the performance of five off-the-shelf language models in assessing the harm of these texts and explore the effectiveness of chain-of-thought prompting to teach large language models (LLMs) to leverage author identity context. We reveal a tendency for these models to inaccurately flag texts authored by gender-queer individuals as harmful. Strikingly, across all LLMs the performance is poorest for texts that show signs of being written by individuals targeted by the featured slur (F1 ≤ 0.24). We highlight an urgent need for fairness and inclusivity in content moderation systems. By uncovering these biases, this work aims to inform the development of more equitable content moderation practices and contribute to the creation of inclusive online spaces for all users.","Dorn, Rebecca, Kezar, Lee, Morstatter, Fred, Lerman, Kristina",,,Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias,,,10.1145/3689904.3694704 , ,,"Trigger Warning: Profane Language, Slurs Content moderation on social media platforms shapes the dynamics of online discourse, influencing whose voices are amplified and whose are suppressed. Recent studies have raised concerns about the fairness of content moderation practices, particularly for aggressively flagging posts from transgender and non-binary individuals as toxic. In this study, we investigate the presence of bias in harmful speech classification of gender-queer dialect online, focusing specifically on the treatment of reclaimed slurs. We introduce a novel dataset, QueerReclaimLex, based on 109 curated templates exemplifying non-derogatory uses of LGBTQ+ slurs. Dataset instances are scored by gender-queer annotators for potential harm depending on additional context about speaker identity. We systematically evaluate the performance of five off-the-shelf language models in assessing the harm of these texts and explore the effectiveness of chain-of-thought prompting to teach large language models (LLMs) to leverage author identity context. We reveal a tendency for these models to inaccurately flag texts authored by gender-queer individuals as harmful. Strikingly, across all LLMs the performance is poorest for texts that show signs of being written by individuals targeted by the featured slur (F1 ≤ 0.24). We highlight an urgent need for fairness and inclusivity in content moderation systems. By uncovering these biases, this work aims to inform the development of more equitable content moderation practices and contribute to the creation of inclusive online spaces for all users.",,,,, ,"  Proceedings of the 4th ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization","Chain-of-thought prompting, Content moderation, Gender identity, LGBTQ+, Online communities, Toxicity",detection,
2927,"**Title**Hate Speech Detection with Generalizable Target-aware Fairness

**Abstract**To counter the side effect brought by the proliferation of social media platforms, hate speech detection (HSD) plays a vital role in halting the dissemination of toxic online posts at an early stage. However, given the ubiquitous topical communities on social media, a trained HSD classifier can easily become biased towards specific targeted groups (e.g.,female andblack people), where a high rate of either false positive or false negative results can significantly impair public trust in the fairness of content moderation mechanisms, and eventually harm the diversity of online society. Although existing fairness-aware HSD methods can smooth out some discrepancies across targeted groups, they are mostly specific to a narrow selection of targets that are assumed to be known and fixed. This inevitably prevents those methods from generalizing to real-world use cases where new targeted groups constantly emerge (e.g., new forums created on Reddit) over time. To tackle the defects of existing HSD practices, we propose &lt;u&gt;Ge&lt;/u&gt;neralizable &lt;u&gt;t&lt;/u&gt;arget-aware &lt;u&gt;Fair&lt;/u&gt;ness (GetFair), a new method for fairly classifying each post that contains diverse and even unseen targets during inference. To remove the HSD classifier's spurious dependence on target-related features, GetFair trains a series of filter functions in an adversarial pipeline, so as to deceive the discriminator that recovers the targeted group from filtered post embeddings. To maintain scalability and generalizability, we innovatively parameterize all filter functions via a hypernetwork. Taking a target's pretrained word embedding as input, the hypernetwork generates the weights used by each target-specific filter on-the-fly without storing dedicated filter parameters. In addition, a novel semantic gap alignment scheme is imposed on the generation process, such that the produced filter function for an unseen target is rectified by its semantic affinity with existing targets used for training. Finally, experiments are conducted on two benchmark HSD datasets, showing advantageous performance of GetFair on out-of-sample targets among baselines.","Chen, Tong, Wang, Danny, Liang, Xurong, Risius, Marten, Demartini, Gianluca, Yin, Hongzhi",,,Hate Speech Detection with Generalizable Target-aware Fairness,,,10.1145/3637528.3671821 , ,,"To counter the side effect brought by the proliferation of social media platforms, hate speech detection (HSD) plays a vital role in halting the dissemination of toxic online posts at an early stage. However, given the ubiquitous topical communities on social media, a trained HSD classifier can easily become biased towards specific targeted groups (e.g.,female andblack people), where a high rate of either false positive or false negative results can significantly impair public trust in the fairness of content moderation mechanisms, and eventually harm the diversity of online society. Although existing fairness-aware HSD methods can smooth out some discrepancies across targeted groups, they are mostly specific to a narrow selection of targets that are assumed to be known and fixed. This inevitably prevents those methods from generalizing to real-world use cases where new targeted groups constantly emerge (e.g., new forums created on Reddit) over time. To tackle the defects of existing HSD practices, we propose &lt;u&gt;Ge&lt;/u&gt;neralizable &lt;u&gt;t&lt;/u&gt;arget-aware &lt;u&gt;Fair&lt;/u&gt;ness (GetFair), a new method for fairly classifying each post that contains diverse and even unseen targets during inference. To remove the HSD classifier's spurious dependence on target-related features, GetFair trains a series of filter functions in an adversarial pipeline, so as to deceive the discriminator that recovers the targeted group from filtered post embeddings. To maintain scalability and generalizability, we innovatively parameterize all filter functions via a hypernetwork. Taking a target's pretrained word embedding as input, the hypernetwork generates the weights used by each target-specific filter on-the-fly without storing dedicated filter parameters. In addition, a novel semantic gap alignment scheme is imposed on the generation process, such that the produced filter function for an unseen target is rectified by its semantic affinity with existing targets used for training. Finally, experiments are conducted on two benchmark HSD datasets, showing advantageous performance of GetFair on out-of-sample targets among baselines.",,,,, ,  Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,"data science for social good, debiased content moderation, hate speech detection, target-aware fairness",detection#methodology,
2928,"**Title**PhoGAD: Graph-based Anomaly Behavior Detection with Persistent Homology Optimization

**Abstract**A multitude of toxic online behaviors, ranging from network attacks to anonymous traffic and spam, have severely disrupted the smooth operation of networks. Due to the inherent sender-receiver nature of network behaviors, graph-based frameworks are commonly used for detecting anomalous behaviors. However, in real-world scenarios, the boundary between normal and anomalous behaviors tends to be ambiguous. The local heterophily of graphs interferes with the detection, and existing methods based on nodes or edges introduce unwanted noise into representation results, thereby impacting the effectiveness of detection. To address these issues, we propose PhoGAD, a graph-based anomaly detection framework. PhoGAD leverages persistent homology optimization to clarify behavioral boundaries. Building upon this, the weights of adjacent edges are designed to mitigate the effects of local heterophily. Subsequently, to tackle the noise problem, we conduct a formal analysis and propose a disentangled representation-based explicit embedding method, ultimately achieving anomaly behavior detection. Experiments on intrusion, traffic, and spam datasets verify that PhoGAD has surpassed the performance of state-of-the-art (SOTA) frameworks in detection efficacy. Notably, PhoGAD demonstrates robust detection even with diminished anomaly proportions, highlighting its applicability to real-world scenarios. The analysis of persistent homology demonstrates its effectiveness in capturing the topological structure formed by normal edge features. Additionally, ablation experiments validate the effectiveness of the innovative mechanisms integrated within PhoGAD.","Yuan, Ziqi, Zhou, Haoyi, Chen, Tianyu, Li, Jianxin",,,PhoGAD: Graph-based Anomaly Behavior Detection with Persistent Homology Optimization,,,10.1145/3616855.3635783 , ,,"A multitude of toxic online behaviors, ranging from network attacks to anonymous traffic and spam, have severely disrupted the smooth operation of networks. Due to the inherent sender-receiver nature of network behaviors, graph-based frameworks are commonly used for detecting anomalous behaviors. However, in real-world scenarios, the boundary between normal and anomalous behaviors tends to be ambiguous. The local heterophily of graphs interferes with the detection, and existing methods based on nodes or edges introduce unwanted noise into representation results, thereby impacting the effectiveness of detection. To address these issues, we propose PhoGAD, a graph-based anomaly detection framework. PhoGAD leverages persistent homology optimization to clarify behavioral boundaries. Building upon this, the weights of adjacent edges are designed to mitigate the effects of local heterophily. Subsequently, to tackle the noise problem, we conduct a formal analysis and propose a disentangled representation-based explicit embedding method, ultimately achieving anomaly behavior detection. Experiments on intrusion, traffic, and spam datasets verify that PhoGAD has surpassed the performance of state-of-the-art (SOTA) frameworks in detection efficacy. Notably, PhoGAD demonstrates robust detection even with diminished anomaly proportions, highlighting its applicability to real-world scenarios. The analysis of persistent homology demonstrates its effectiveness in capturing the topological structure formed by normal edge features. Additionally, ablation experiments validate the effectiveness of the innovative mechanisms integrated within PhoGAD.",,,,, ,  Proceedings of the 17th ACM International Conference on Web Search and Data Mining,"anomaly detection, behavior detection, graph learning, neural networks, persistent homology",out_of_scope,
2929,"**Title**Topic enhanced word embedding for toxic content detection in Q&amp;A sites

**Abstract**Increasingly, users are adopting community question-and-answer (Q&amp;A) sites to exchange information. Detecting and eliminating toxic and divisive content in these Q&amp;A sites are paramount tasks to ensure a safe and constructive environment for the users. Insincere question, which is founded upon false premises, is one type of toxic content in Q&amp;A sites. In this paper, we proposed a novel deep learning framework enhanced pre-trained word embeddings with topical information for insincere question classification. We evaluated our proposed framework on a large real-world dataset from Quora Q&amp;A site and showed that the topically enhanced word embedding is able to achieve better results in toxic content classification. An empirical study was also conducted to analyze the topics of the insincere questions on Quora, and we found that topics on ""religion"", ""gender"" and ""politics"" has a higher proportion of insincere questions.","Kim, Do Yeon, Li, Xiaohang, Wang, Sheng, Zhuo, Yunying, Lee, Roy Ka-Wei",,,Topic enhanced word embedding for toxic content detection in Q&amp;A sites,,,10.1145/3341161.3345332 , ,,"Increasingly, users are adopting community question-and-answer (Q&amp;A) sites to exchange information. Detecting and eliminating toxic and divisive content in these Q&amp;A sites are paramount tasks to ensure a safe and constructive environment for the users. Insincere question, which is founded upon false premises, is one type of toxic content in Q&amp;A sites. In this paper, we proposed a novel deep learning framework enhanced pre-trained word embeddings with topical information for insincere question classification. We evaluated our proposed framework on a large real-world dataset from Quora Q&amp;A site and showed that the topically enhanced word embedding is able to achieve better results in toxic content classification. An empirical study was also conducted to analyze the topics of the insincere questions on Quora, and we found that topics on ""religion"", ""gender"" and ""politics"" has a higher proportion of insincere questions.",,,,, ,  Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"NLP, sequence model, text classification, toxic content, word embedding",detection,
2930,"**Title**""Did you miss my comment or what?"": understanding toxicity in open source discussions

**Abstract**Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.","Miller, Courtney, Cohen, Sophie, Klug, Daniel, Vasilescu, Bogdan, KaUstner, Christian",,,"""Did you miss my comment or what?"": understanding toxicity in open source discussions",,,10.1145/3510003.3510111 , ,,"Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.",,,,, ,  Proceedings of the 44th International Conference on Software Engineering,,detection,
2931,"**Title**""Pls Uninstall"": On the Interplay of the COVID-19 Pandemic and Toxic Player Behavior in Competitive Gaming

**Abstract**Win or lose---the beauty of competitive games lies in the challenge, accompanied by the rush of adrenaline. Unfortunately, another loyal companion is toxic player behavior, which can ruin a game even before the winner is decided. Yet what happens when opponents suddenly face a much more dangerous, common enemy in the form of a pandemic outbreak? Does such a situation act as common ground, uniting the players and increasing their social awareness? Or do players abuse the game (and other players) even more to release their frustration caused by the pandemic? The results of our ongoing work support the latter hypothesis: in most competitive games, players perceive a notable increase of toxicity, which is an alarming sign and a clear call for more detailed explorations.","Emmerich, Katharina, Krekhov, Andrey, Kr\""{u}ger, Jens",,,"""Pls Uninstall"": On the Interplay of the COVID-19 Pandemic and Toxic Player Behavior in Competitive Gaming",,,10.1145/3383668.3419896 , ,,"Win or lose---the beauty of competitive games lies in the challenge, accompanied by the rush of adrenaline. Unfortunately, another loyal companion is toxic player behavior, which can ruin a game even before the winner is decided. Yet what happens when opponents suddenly face a much more dangerous, common enemy in the form of a pandemic outbreak? Does such a situation act as common ground, uniting the players and increasing their social awareness? Or do players abuse the game (and other players) even more to release their frustration caused by the pandemic? The results of our ongoing work support the latter hypothesis: in most competitive games, players perceive a notable increase of toxicity, which is an alarming sign and a clear call for more detailed explorations.",,,,, ,  Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play,"competitive games, league of legends, moba, multiplayer, toxicity",out_but_toxicity,
2932,"**Title**Wireless/mobile communication aegis taciturn: ""an automatic call detection &amp; notification system""

**Abstract**""Technology does not drive change, it enables change."" The primary purpose of Technology is its implementation in day-today life wherein it could enhance the lifestyle as well as provide better safety and performance to its end users. The government has enforced stringent laws against usage of mobile phones while driving a vehicle. Yet, there seems to be a sense of casualness amongst our citizens towards abiding it, coupled with a belief that they can get by easily without ever being caught. This project facilitates the government to take adequate action against those who are violating these laws. An ingenious and innovative technique is required to detect the persons who are not abiding this code of conduct. It is sometimes referred to as the golden first hour after any accident that takes place and is very precious in savings lives of the victims. Due concern must be given for both inebriated as well as cell phone usage while driving. Aegis taciturn is a device used especially for people who cling to mobile phones even while driving and bilk from laws easily. Aegis taciturn is a device used to prevent texting and calling of mobile phones while driving vehicles. Also, it indicates to cops that a person is using his mobile while driving. In case of countries where there is a peccadillo for this kind of pernicious activities. Aegis taciturn would be an utilitarian device. Aegis taciturn receives the mobile frequencies and with the Operational Amplifier which is used as a current to voltage converter which suspects even a small Voltage difference which comes along with the frequency signal. As a result of this slightest voltage fluctuation cops would be intimated by a message with the vehicle's number plate along with the location of the vehicle with the help of GPS System.","Aparajith, S., Naarayan, M. L., Vinodh, S.",,,"Wireless/mobile communication aegis taciturn: ""an automatic call detection &amp; notification system""",,,10.1145/1968613.1968740 , ,,"""Technology does not drive change, it enables change."" The primary purpose of Technology is its implementation in day-today life wherein it could enhance the lifestyle as well as provide better safety and performance to its end users. The government has enforced stringent laws against usage of mobile phones while driving a vehicle. Yet, there seems to be a sense of casualness amongst our citizens towards abiding it, coupled with a belief that they can get by easily without ever being caught. This project facilitates the government to take adequate action against those who are violating these laws. An ingenious and innovative technique is required to detect the persons who are not abiding this code of conduct. It is sometimes referred to as the golden first hour after any accident that takes place and is very precious in savings lives of the victims. Due concern must be given for both inebriated as well as cell phone usage while driving. Aegis taciturn is a device used especially for people who cling to mobile phones even while driving and bilk from laws easily. Aegis taciturn is a device used to prevent texting and calling of mobile phones while driving vehicles. Also, it indicates to cops that a person is using his mobile while driving. In case of countries where there is a peccadillo for this kind of pernicious activities. Aegis taciturn would be an utilitarian device. Aegis taciturn receives the mobile frequencies and with the Operational Amplifier which is used as a current to voltage converter which suspects even a small Voltage difference which comes along with the frequency signal. As a result of this slightest voltage fluctuation cops would be intimated by a message with the vehicle's number plate along with the location of the vehicle with the help of GPS System.",,,,, ,  Proceedings of the 5th International Conference on Ubiquitous Information Management and Communication,"GPS based vehicle tracking system, GSM modem, call detection, call notification to cops, mobile bug, speed sensors",out_of_scope,
2933,"**Title**Super Mario in the Pernicious Kingdoms: Classifying glitches in old games

**Abstract**In a case study spanning four classic Super Mario games and the analysis of 237 known glitches within them, we classify a variety of weaknesses that are exploited by speedrunners to enable them to beat games quickly and in surprising ways. Using the Seven Pernicious Kingdoms software defect taxonomy and the Common Weakness Enumeration, we categorize the glitches by the weaknesses that enable them. We identify 7 new weaknesses that appear specific to games and which are not covered by current software weakness taxonomies.","Forward, Llewellyn, Limmer, Io, Hallett, Joseph, Page, Dan",,,Super Mario in the Pernicious Kingdoms: Classifying glitches in old games,,,10.1145/3643658.3643917 , ,,"In a case study spanning four classic Super Mario games and the analysis of 237 known glitches within them, we classify a variety of weaknesses that are exploited by speedrunners to enable them to beat games quickly and in surprising ways. Using the Seven Pernicious Kingdoms software defect taxonomy and the Common Weakness Enumeration, we categorize the glitches by the weaknesses that enable them. We identify 7 new weaknesses that appear specific to games and which are not covered by current software weakness taxonomies.",,,,, ,  Proceedings of the ACM/IEEE 8th International Workshop on Games and Software Engineering,,out_of_scope,
2934,"**Title**User-directed Assembly Code Transformations Enabling Efficient Batteryless Arduino Applications

**Abstract**The time for battery-free computing is now. Lithium mining depletes and pollutes local water supplies and dead batteries in landfills leak toxic metals into the ground[20][12]. Battery-free devices represent a probable future for sustainable ubiquitous computing and we will need many more new devices and programmers to bring that future into reality. Yet, energy harvesting and battery-free devices that frequently fail are challenging to program. The maker movement has organically developed a considerable variety of platforms to prototype and program ubiquitous sensing and computing devices, but only a few have been modified to be usable with energy harvesting and to hide those pesky power failures that are the norm from variable energy availability (platforms like Microsoft's Makecode and AdaFruit's CircuitPython). Many platforms, especially Arduino (the first and most famous maker platform), do not support energy harvesting devices and intermittent computing. To bridge this gap and lay a strong foundation for potential new platforms for maker programming, we build a tool called BOOTHAMMER: a lightweight assembly re-writer for ARM Thumb. BOOTHAMMER analyzes and rewrites the low-level assembly to insert careful checkpoint and restore operations to enable programs to persist through power failures. The approach is easily insertable in existing toolchains and is general-purpose enough to be resilient to future platforms and devices/chipsets. We close the loop with the user by designing a small set of program annotations that any maker coder can use to provide extra information to this low-level tool that will significantly increase checkpoint efficiency and resolution. These optional extensions represent a way to include the user in decision-making about energy harvesting while ensuring the tool supports existing platforms. We conduct an extensive evaluation using various program benchmarks with Arduino as our chosen evaluation platform. We also demonstrate the usability of this approach by evaluating BOOTHAMMER with a user study and show that makers feel very confident in their ability to write intermittent computing programs using this tool. With this new tool, we enable maker hardware and software for sustainable, energy-harvesting-based computing for all.","Kraemer, Christopher, Gelder, William, Hester, Josiah",,,User-directed Assembly Code Transformations Enabling Efficient Batteryless Arduino Applications,,,10.1145/3659590 , ,,"The time for battery-free computing is now. Lithium mining depletes and pollutes local water supplies and dead batteries in landfills leak toxic metals into the ground[20][12]. Battery-free devices represent a probable future for sustainable ubiquitous computing and we will need many more new devices and programmers to bring that future into reality. Yet, energy harvesting and battery-free devices that frequently fail are challenging to program. The maker movement has organically developed a considerable variety of platforms to prototype and program ubiquitous sensing and computing devices, but only a few have been modified to be usable with energy harvesting and to hide those pesky power failures that are the norm from variable energy availability (platforms like Microsoft's Makecode and AdaFruit's CircuitPython). Many platforms, especially Arduino (the first and most famous maker platform), do not support energy harvesting devices and intermittent computing. To bridge this gap and lay a strong foundation for potential new platforms for maker programming, we build a tool called BOOTHAMMER: a lightweight assembly re-writer for ARM Thumb. BOOTHAMMER analyzes and rewrites the low-level assembly to insert careful checkpoint and restore operations to enable programs to persist through power failures. The approach is easily insertable in existing toolchains and is general-purpose enough to be resilient to future platforms and devices/chipsets. We close the loop with the user by designing a small set of program annotations that any maker coder can use to provide extra information to this low-level tool that will significantly increase checkpoint efficiency and resolution. These optional extensions represent a way to include the user in decision-making about energy harvesting while ensuring the tool supports existing platforms. We conduct an extensive evaluation using various program benchmarks with Arduino as our chosen evaluation platform. We also demonstrate the usability of this approach by evaluating BOOTHAMMER with a user study and show that makers feel very confident in their ability to write intermittent computing programs using this tool. With this new tool, we enable maker hardware and software for sustainable, energy-harvesting-based computing for all.",,,,, ,  ,"Battery-free, Block based programming, Energy Harvesting, Intermittent Computing",out_of_scope,
2935,"**Title**Transforming Grading Practices in the Computing Education Community

**Abstract**It is often the case that computer science classrooms use traditional grading practices where points are allocated to assignments, mistakes result in point deductions, and assignment scores are combined using some form of weighted averaging to determine grades. Unfortunately, traditional grading practices have been shown to reduce achievement, discourage students, and suppress effort to such an extent that some common elements of traditional grading practices have been termed toxic. Using grades to reward or punish student behavior does not encourage learning and instead increases anxiety and stress. These toxic elements are present throughout computing education and computer science classrooms in the form of late penalties, lack of credit for code that doesn't compile or pass certain unit tests, among others. These types of metrics, that evaluate behavior are often influenced by implicit bias, factors outside of the classrooms (e.g., part-time employment), and family life situations (e.g., students who are caregivers). Often, students in these situations are disproportionately from low-socioeconomic backgrounds and predominantly students of color. Through this paper, we will present a case for adoption of equitable grading practices and a call for additional support in classroom and teaching technologies as well as support from administrations both at the department and university level. By adopting a community of practice approach, we argue that we can support new faculty making these changes, which would be more equitable and inclusive. Further, these practices have been shown to better support student learning and can help increase student learning gains and retention.","Decker, Adrienne, Edwards, Stephen H., McSkimming, Brian M., Edmison, Bob, Rorrer, Audrey, P\'{e}rez Qui\~{n}ones, Manuel A.",,,Transforming Grading Practices in the Computing Education Community,,,10.1145/3626252.3630953 , ,,"It is often the case that computer science classrooms use traditional grading practices where points are allocated to assignments, mistakes result in point deductions, and assignment scores are combined using some form of weighted averaging to determine grades. Unfortunately, traditional grading practices have been shown to reduce achievement, discourage students, and suppress effort to such an extent that some common elements of traditional grading practices have been termed toxic. Using grades to reward or punish student behavior does not encourage learning and instead increases anxiety and stress. These toxic elements are present throughout computing education and computer science classrooms in the form of late penalties, lack of credit for code that doesn't compile or pass certain unit tests, among others. These types of metrics, that evaluate behavior are often influenced by implicit bias, factors outside of the classrooms (e.g., part-time employment), and family life situations (e.g., students who are caregivers). Often, students in these situations are disproportionately from low-socioeconomic backgrounds and predominantly students of color. Through this paper, we will present a case for adoption of equitable grading practices and a call for additional support in classroom and teaching technologies as well as support from administrations both at the department and university level. By adopting a community of practice approach, we argue that we can support new faculty making these changes, which would be more equitable and inclusive. Further, these practices have been shown to better support student learning and can help increase student learning gains and retention.",,,,, ,  Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,"equitable grading, grading for equity, grading practices",out_of_scope,
2936,"**Title**Recourse for Reclamation: Chatting with Generative Language Models

**Abstract**Researchers and developers increasingly rely on toxicity scoring to automate generative language model outputs, in settings such as customer service, information retrieval, and content generation. However, toxicity scoring may render pertinent information inaccessible, rigidify or “value-lock” cultural norms, and prevent language reclamation processes, particularly for marginalized people. In this work, we extend the concept of algorithmic recourse to generative language models: we provide users a novel mechanism to achieve their desired prediction by dynamically setting thresholds for toxicity filtering. Users thereby exercise increased agency relative to interactions with the baseline system. A pilot study (n = 30) supports the potential of our proposed recourse mechanism, indicating improvements in usability compared to fixed-threshold toxicity-filtering of model outputs. Future work should explore the intersection of toxicity scoring, model controllability, user agency, and language reclamation processes—particularly with regard to the bias that many communities encounter when interacting with generative language models.","Chien, Jennifer, Mckee, Kevin, Kay, Jackie, Isaac, William",,,Recourse for Reclamation: Chatting with Generative Language Models,,,10.1145/3613905.3650999 , ,,"Researchers and developers increasingly rely on toxicity scoring to automate generative language model outputs, in settings such as customer service, information retrieval, and content generation. However, toxicity scoring may render pertinent information inaccessible, rigidify or “value-lock” cultural norms, and prevent language reclamation processes, particularly for marginalized people. In this work, we extend the concept of algorithmic recourse to generative language models: we provide users a novel mechanism to achieve their desired prediction by dynamically setting thresholds for toxicity filtering. Users thereby exercise increased agency relative to interactions with the baseline system. A pilot study (n = 30) supports the potential of our proposed recourse mechanism, indicating improvements in usability compared to fixed-threshold toxicity-filtering of model outputs. Future work should explore the intersection of toxicity scoring, model controllability, user agency, and language reclamation processes—particularly with regard to the bias that many communities encounter when interacting with generative language models.",,,,, ,  Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,"Algorithmic recourse, Generative language models, Language reclamation, Toxicity scoring",detox,
2937,"**Title**Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective

**Abstract**The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this technology can cause unintended harms, such as the silencing of under-represented groups. We review a large body of NLP research on automatic abuse detection with a new focus on ethical challenges, organized around eight established ethical principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. In many cases, these principles relate not only to situational ethical codes, which may be context-dependent, but are in fact connected to universal human rights, such as the right to privacy, freedom from discrimination, and freedom of expression. We highlight the need to examine the broad social impacts of this technology, and to bring ethical and human rights considerations to every stage of the application life-cycle, from task formulation and dataset design, to model training and evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including ‘nudging’, ‘quarantining’, value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including 'nudging', 'quarantining', value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.","Kiritchenko, Svetlana, Nejadgholi, Isar, Fraser, Kathleen C.",,,Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective,,,10.1613/jair.1.12590 , ,,"The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this technology can cause unintended harms, such as the silencing of under-represented groups. We review a large body of NLP research on automatic abuse detection with a new focus on ethical challenges, organized around eight established ethical principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. In many cases, these principles relate not only to situational ethical codes, which may be context-dependent, but are in fact connected to universal human rights, such as the right to privacy, freedom from discrimination, and freedom of expression. We highlight the need to examine the broad social impacts of this technology, and to bring ethical and human rights considerations to every stage of the application life-cycle, from task formulation and dataset design, to model training and evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including ‘nudging’, ‘quarantining’, value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including 'nudging', 'quarantining', value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.",,,,, ,  ,natural language,survey,
2938,"**Title**DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation

**Abstract**Large Language Models (LLMs) have showcased their remarkable capabilities in diverse domains, encompassing natural language understanding, translation, and even code generation. The potential for LLMs to generate harmful content is a significant concern. This risk necessitates rigorous testing and comprehensive evaluation of LLMs to ensure safe and responsible use. However, extensive testing of LLMs requires substantial computational resources, making it an expensive endeavor. Therefore, exploring cost-saving strategies during the testing phase is crucial to balance the need for thorough evaluation with the constraints of resource availability. To address this, our approach begins by transferring the moderation knowledge from an LLM to a small model. Subsequently, we deploy two distinct strategies for generating malicious queries: one based on a syntax tree approach, and the other leveraging an LLM-based method. Finally, our approach incorporates a sequential filter-test process designed to identify test cases that are prone to eliciting toxic responses. By doing so, we significantly curtail unnecessary or unproductive interactions with LLMs, thereby streamlining the testing process. Our research evaluated the efficacy of DistillSeq across four LLMs: GPT-3.5, GPT-4.0, Vicuna-13B, and Llama-13B. In the absence of DistillSeq, the observed attack success rates on these LLMs stood at 31.5% for GPT-3.5, 21.4% for GPT-4.0, 28.3% for Vicuna-13B, and 30.9% for Llama-13B. However, upon the application of DistillSeq, these success rates notably increased to 58.5%, 50.7%, 52.5%, and 54.4%, respectively. This translated to an average escalation in attack success rate by a factor of 93.0% when compared to scenarios without the use of DistillSeq. Such findings highlight the significant enhancement DistillSeq offers in terms of reducing the time and resource investment required for effectively testing LLMs.","Yang, Mingke, Chen, Yuqi, Liu, Yi, Shi, Ling",,,DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation,,,10.1145/3650212.3680304 , ,,"Large Language Models (LLMs) have showcased their remarkable capabilities in diverse domains, encompassing natural language understanding, translation, and even code generation. The potential for LLMs to generate harmful content is a significant concern. This risk necessitates rigorous testing and comprehensive evaluation of LLMs to ensure safe and responsible use. However, extensive testing of LLMs requires substantial computational resources, making it an expensive endeavor. Therefore, exploring cost-saving strategies during the testing phase is crucial to balance the need for thorough evaluation with the constraints of resource availability. To address this, our approach begins by transferring the moderation knowledge from an LLM to a small model. Subsequently, we deploy two distinct strategies for generating malicious queries: one based on a syntax tree approach, and the other leveraging an LLM-based method. Finally, our approach incorporates a sequential filter-test process designed to identify test cases that are prone to eliciting toxic responses. By doing so, we significantly curtail unnecessary or unproductive interactions with LLMs, thereby streamlining the testing process. Our research evaluated the efficacy of DistillSeq across four LLMs: GPT-3.5, GPT-4.0, Vicuna-13B, and Llama-13B. In the absence of DistillSeq, the observed attack success rates on these LLMs stood at 31.5% for GPT-3.5, 21.4% for GPT-4.0, 28.3% for Vicuna-13B, and 30.9% for Llama-13B. However, upon the application of DistillSeq, these success rates notably increased to 58.5%, 50.7%, 52.5%, and 54.4%, respectively. This translated to an average escalation in attack success rate by a factor of 93.0% when compared to scenarios without the use of DistillSeq. Such findings highlight the significant enhancement DistillSeq offers in terms of reducing the time and resource investment required for effectively testing LLMs.",,,,, ,  Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis,"Automated Testing, Knowledge Distillation, Large Language Models",detox,
2939,"**Title**Can Large Language Models Provide Security &amp; Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions

**Abstract**Users seek security &amp; privacy (S&amp;P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&amp;P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g.,&nbsp;to produce toxic content). Yet, the ability of LLMs to provide reliable S&amp;P advice is not well-explored. In this paper, we measure their ability to refute popular S&amp;P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&amp;P-related misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses. Both models demonstrate, on average, a 21.3% non-negligible error rate, incorrectly supporting popular S&amp;P misconceptions. The error rate increases to 32.6% when we repeatedly query LLMs with the same or paraphrased misconceptions. We also expose that models may partially support a misconception or remain noncommittal, refusing a firm stance on misconceptions. Our exploration of information sources for responses revealed that LLMs are susceptible to providing invalid URLs ( for Bard and for ChatGPT) or point to unrelated sources ( returned by Bard and by ChatGPT). Our findings highlight that existing LLMs are not completely reliable for S&amp;P advice and motivate future work in understanding how users can better interact with this technology.","Chen, Yufan, Arunasalam, Arjun, Celik, Z. Berkay",,,Can Large Language Models Provide Security &amp; Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions,,,10.1145/3627106.3627196 , ,,"Users seek security &amp; privacy (S&amp;P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&amp;P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g.,&nbsp;to produce toxic content). Yet, the ability of LLMs to provide reliable S&amp;P advice is not well-explored. In this paper, we measure their ability to refute popular S&amp;P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&amp;P-related misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses. Both models demonstrate, on average, a 21.3% non-negligible error rate, incorrectly supporting popular S&amp;P misconceptions. The error rate increases to 32.6% when we repeatedly query LLMs with the same or paraphrased misconceptions. We also expose that models may partially support a misconception or remain noncommittal, refusing a firm stance on misconceptions. Our exploration of information sources for responses revealed that LLMs are susceptible to providing invalid URLs ( for Bard and for ChatGPT) or point to unrelated sources ( returned by Bard and by ChatGPT). Our findings highlight that existing LLMs are not completely reliable for S&amp;P advice and motivate future work in understanding how users can better interact with this technology.",,,,, ,  Proceedings of the 39th Annual Computer Security Applications Conference,"Large language models, misconception, security and privacy advice",out_of_scope,
2940,"**Title**""I wouldn’t say offensive but..."": Disability-Centered Perspectives on Large Language Models

**Abstract**Large language models (LLMs) trained on real-world data can inadvertently reflect harmful societal biases, particularly toward historically marginalized communities. While previous work has primarily focused on harms related to age and race, emerging research has shown that biases toward disabled communities exist. This study extends prior work exploring the existence of harms by identifying categories of LLM-perpetuated harms toward the disability community. We conducted 19 focus groups, during which 56 participants with disabilities probed a dialog model about disability and discussed and annotated its responses. Participants rarely characterized model outputs as blatantly offensive or toxic. Instead, participants used nuanced language to detail how the dialog model mirrored subtle yet harmful stereotypes they encountered in their lives and dominant media, e.g., inspiration porn and able-bodied saviors. Participants often implicated training data as a cause for these stereotypes and recommended training the model on diverse identities from disability-positive resources. Our discussion further explores representative data strategies to mitigate harm related to different communities through annotation co-design with ML researchers and developers.","Gadiraju, Vinitha, Kane, Shaun, Dev, Sunipa, Taylor, Alex, Wang, Ding, Denton, Emily, Brewer, Robin",,,"""I wouldn’t say offensive but..."": Disability-Centered Perspectives on Large Language Models",,,10.1145/3593013.3593989 , ,,"Large language models (LLMs) trained on real-world data can inadvertently reflect harmful societal biases, particularly toward historically marginalized communities. While previous work has primarily focused on harms related to age and race, emerging research has shown that biases toward disabled communities exist. This study extends prior work exploring the existence of harms by identifying categories of LLM-perpetuated harms toward the disability community. We conducted 19 focus groups, during which 56 participants with disabilities probed a dialog model about disability and discussed and annotated its responses. Participants rarely characterized model outputs as blatantly offensive or toxic. Instead, participants used nuanced language to detail how the dialog model mirrored subtle yet harmful stereotypes they encountered in their lives and dominant media, e.g., inspiration porn and able-bodied saviors. Participants often implicated training data as a cause for these stereotypes and recommended training the model on diverse identities from disability-positive resources. Our discussion further explores representative data strategies to mitigate harm related to different communities through annotation co-design with ML researchers and developers.",,,,, ,"  Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","algorithmic harms, artificial intelligence, chatbot, data annotation, dialog model, disability representation, large language models, qualitative",detection,
2941,"**Title**“I’m fully who I am”: Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation

**Abstract**Warning: This paper contains examples of gender non-affirmative language which could be offensive, upsetting, and/or triggering. Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization of TGNB persons contributes to and persists within Open Language Generation (OLG). This social knowledge serves as a guide for evaluating popular large language models (LLMs) on two key aspects: (1) misgendering and (2) harmful responses to gender disclosure. To do this, we introduce TANGO, a dataset of template-based real-world text curated from a TGNB-oriented community. We discover a dominance of binary gender norms reflected by the models; LLMs least misgendered subjects in generated text when triggered by prompts whose subjects used binary pronouns. Meanwhile, misgendering was most prevalent when triggering generation with singular they and neopronouns. When prompted with gender disclosures, TGNB disclosure generated the most stigmatizing language and scored most toxic, on average. Our findings warrant further research on how TGNB harms manifest in LLMs and serve as a broader case study toward concretely grounding the design of gender-inclusive AI in community voices and interdisciplinary literature.","Ovalle, Anaelia, Goyal, Palash, Dhamala, Jwala, Jaggers, Zachary, Chang, Kai-Wei, Galstyan, Aram, Zemel, Richard, Gupta, Rahul",,,“I’m fully who I am”: Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation,,,10.1145/3593013.3594078 , ,,"Warning: This paper contains examples of gender non-affirmative language which could be offensive, upsetting, and/or triggering. Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization of TGNB persons contributes to and persists within Open Language Generation (OLG). This social knowledge serves as a guide for evaluating popular large language models (LLMs) on two key aspects: (1) misgendering and (2) harmful responses to gender disclosure. To do this, we introduce TANGO, a dataset of template-based real-world text curated from a TGNB-oriented community. We discover a dominance of binary gender norms reflected by the models; LLMs least misgendered subjects in generated text when triggered by prompts whose subjects used binary pronouns. Meanwhile, misgendering was most prevalent when triggering generation with singular they and neopronouns. When prompted with gender disclosures, TGNB disclosure generated the most stigmatizing language and scored most toxic, on average. Our findings warrant further research on how TGNB harms manifest in LLMs and serve as a broader case study toward concretely grounding the design of gender-inclusive AI in community voices and interdisciplinary literature.",,,,, ,"  Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","AI Fairness Auditing, Algorithmic Fairness, Natural Language Generation, Queer Harms in AI",detection,
2942,"**Title**“Short is the Road that Leads from Fear to Hate”: Fear Speech in Indian WhatsApp Groups

**Abstract**WhatsApp is the most popular messaging app in the world. Due to its popularity, WhatsApp has become a powerful and cheap tool for political campaigning being widely used during the 2019 Indian general election, where it was used to connect to the voters on a large scale. Along with the campaigning, there have been reports that WhatsApp has also become a breeding ground for harmful speech against various protected groups and religious minorities. Many such messages attempt to instil fear among the population about a specific (minority) community. According to research on inter-group conflict, such ‘fear speech’ messages could have a lasting impact and might lead to real offline violence. In this paper, we perform the first large scale study on fear speech across thousands of public WhatsApp groups discussing politics in India. We curate a new dataset and try to characterize fear speech from this dataset. We observe that users writing fear speech messages use various events and symbols to create the illusion of fear among the reader about a target community. We build models to classify fear speech and observe that current state-of-the-art NLP models do not perform well at this task. Fear speech messages tend to spread faster and could potentially go undetected by classifiers built to detect traditional toxic speech due to their low toxic nature. Finally, using a novel methodology to target users with Facebook ads, we conduct a survey among the users of these WhatsApp groups to understand the types of users who consume and share fear speech. We believe that this work opens up new research questions that are very different from tackling hate speech which the research community has been traditionally involved in. We have made our code and dataset public for other researchers.","Saha, Punyajoy, Mathew, Binny, Garimella, Kiran, Mukherjee, Animesh",,,“Short is the Road that Leads from Fear to Hate”: Fear Speech in Indian WhatsApp Groups,,,10.1145/3442381.3450137 , ,,"WhatsApp is the most popular messaging app in the world. Due to its popularity, WhatsApp has become a powerful and cheap tool for political campaigning being widely used during the 2019 Indian general election, where it was used to connect to the voters on a large scale. Along with the campaigning, there have been reports that WhatsApp has also become a breeding ground for harmful speech against various protected groups and religious minorities. Many such messages attempt to instil fear among the population about a specific (minority) community. According to research on inter-group conflict, such ‘fear speech’ messages could have a lasting impact and might lead to real offline violence. In this paper, we perform the first large scale study on fear speech across thousands of public WhatsApp groups discussing politics in India. We curate a new dataset and try to characterize fear speech from this dataset. We observe that users writing fear speech messages use various events and symbols to create the illusion of fear among the reader about a target community. We build models to classify fear speech and observe that current state-of-the-art NLP models do not perform well at this task. Fear speech messages tend to spread faster and could potentially go undetected by classifiers built to detect traditional toxic speech due to their low toxic nature. Finally, using a novel methodology to target users with Facebook ads, we conduct a survey among the users of these WhatsApp groups to understand the types of users who consume and share fear speech. We believe that this work opens up new research questions that are very different from tackling hate speech which the research community has been traditionally involved in. We have made our code and dataset public for other researchers.",,,,, ,  Proceedings of the Web Conference 2021,"Islamophobia, WhatsApp, classification, fear speech, hate speech, survey",out_but_toxicity,
2943,"**Title**Measuring and Characterizing Hate Speech on News&nbsp;Websites

**Abstract**The Web has become the main source for news acquisition. At the same time, news discussion has become more social: users can post comments on news articles or discuss news articles on other platforms like Reddit. These features empower and enable discussions among the users; however, they also act as the medium for the dissemination of toxic discourse and hate speech. The research community lacks a general understanding on what type of content attracts hateful discourse and the possible effects of social networks on the commenting activity on news articles. In this work, we perform a large-scale quantitative analysis of 125M comments posted on 412K news articles over the course of 19 months. We analyze the content of the collected articles and their comments using temporal analysis, user-based analysis, and linguistic analysis, to shed light on what elements attract hateful comments on news articles. We also investigate commenting activity when an article is posted on either 4chan’s Politically Incorrect board (/pol/) or six selected subreddits. We find statistically significant increases in hateful commenting activity around real-world divisive events like the “Unite the Right” rally in Charlottesville and political events like the second and third 2016 US presidential debates. Also, we find that articles that attract a substantial number of hateful comments have different linguistic characteristics when compared to articles that do not attract hateful comments. Furthermore, we observe that the post of a news articles on either /pol/ or the six subreddits is correlated with an increase of (hateful) commenting activity on the news articles.","Zannettou, Savvas, Elsherief, Mai, Belding, Elizabeth, Nilizadeh, Shirin, Stringhini, Gianluca",,,Measuring and Characterizing Hate Speech on News&nbsp;Websites,,,10.1145/3394231.3397902 , ,,"The Web has become the main source for news acquisition. At the same time, news discussion has become more social: users can post comments on news articles or discuss news articles on other platforms like Reddit. These features empower and enable discussions among the users; however, they also act as the medium for the dissemination of toxic discourse and hate speech. The research community lacks a general understanding on what type of content attracts hateful discourse and the possible effects of social networks on the commenting activity on news articles. In this work, we perform a large-scale quantitative analysis of 125M comments posted on 412K news articles over the course of 19 months. We analyze the content of the collected articles and their comments using temporal analysis, user-based analysis, and linguistic analysis, to shed light on what elements attract hateful comments on news articles. We also investigate commenting activity when an article is posted on either 4chan’s Politically Incorrect board (/pol/) or six selected subreddits. We find statistically significant increases in hateful commenting activity around real-world divisive events like the “Unite the Right” rally in Charlottesville and political events like the second and third 2016 US presidential debates. Also, we find that articles that attract a substantial number of hateful comments have different linguistic characteristics when compared to articles that do not attract hateful comments. Furthermore, we observe that the post of a news articles on either /pol/ or the six subreddits is correlated with an increase of (hateful) commenting activity on the news articles.",,,,, ,  Proceedings of the 12th ACM Conference on Web Science,,detection,
2944,"**Title**Poster: Adversarial Examples for Hate Speech Classifiers

**Abstract**With the advent of the Internet, social media platforms have become an increasingly popular medium of communication for people. Platforms like Twitter and Quora allow people to express their opinions on a large scale. These platforms are, however, plagued by the problem of hate speech and toxic content. Such content is generally sexist, homophobic or racist. Automatic text classification can filter out toxic content so some extent. In this paper, we discuss the adversarial attacks on hate speech classifiers. We demonstrate that by changing the text slightly, a classifier can be fooled to misclassifying a toxic comment as acceptable. We attack hate speech classifiers with known attacks as well as introduce four new attacks. We find that our method can degrade the performance of a Random Forest classifier by 20%. We hope that our work sheds light on the vulnerabilities of text classifiers, and opens doors for further research on this topic.","Oak, Rajvardhan",,,Poster: Adversarial Examples for Hate Speech Classifiers,,,10.1145/3319535.3363271 , ,,"With the advent of the Internet, social media platforms have become an increasingly popular medium of communication for people. Platforms like Twitter and Quora allow people to express their opinions on a large scale. These platforms are, however, plagued by the problem of hate speech and toxic content. Such content is generally sexist, homophobic or racist. Automatic text classification can filter out toxic content so some extent. In this paper, we discuss the adversarial attacks on hate speech classifiers. We demonstrate that by changing the text slightly, a classifier can be fooled to misclassifying a toxic comment as acceptable. We attack hate speech classifiers with known attacks as well as introduce four new attacks. We find that our method can degrade the performance of a Random Forest classifier by 20%. We hope that our work sheds light on the vulnerabilities of text classifiers, and opens doors for further research on this topic.",,,,, ,  Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security,"adversarial machine learning, hate speech",detection,
2945,"**Title**In-Context Learning Reward Guided Decoding for Controlled Text Generation

**Abstract**While large language models have demonstrated remarkable text generation capabilities, they often generate text with adverse or undesired attributes. Common approaches to control text generation involve refining models on data with desired properties or guiding language models decoding using an auxiliary model. However, these methods require additional training and extensive attribute-specific data. To further mitigate the training costs, we propose In-context learning Reward Guided Decoding (IRGD), a weighted decoding method that exploits the in-context learning ability of language models as an alternative to additional model fine-tuning. Specifically, IRGD utilizes ICL outputs to score the alignment reward between sequences and target attributes, subsequently modifying the sampling probabilities to favor tokens with higher reward scores. By applying ICL, IRGD adapts to different tasks by simply adjusting task descriptions and demonstration rather than fine-tuning the model. Through experiments on detoxification and sentiment control, we demonstrate the advantages of IRGD as a plug-and-play and fine-tuning-free decoding method that effectively balance attribute alignment and text quality.","Zhu, Xinyi, Zhou, Yanru, Song, Dandan, Yang, Ziyi",,,In-Context Learning Reward Guided Decoding for Controlled Text Generation,,,10.1109/ICSP62122.2024.10743861 , ,,"While large language models have demonstrated remarkable text generation capabilities, they often generate text with adverse or undesired attributes. Common approaches to control text generation involve refining models on data with desired properties or guiding language models decoding using an auxiliary model. However, these methods require additional training and extensive attribute-specific data. To further mitigate the training costs, we propose In-context learning Reward Guided Decoding (IRGD), a weighted decoding method that exploits the in-context learning ability of language models as an alternative to additional model fine-tuning. Specifically, IRGD utilizes ICL outputs to score the alignment reward between sequences and target attributes, subsequently modifying the sampling probabilities to favor tokens with higher reward scores. By applying ICL, IRGD adapts to different tasks by simply adjusting task descriptions and demonstration rather than fine-tuning the model. Through experiments on detoxification and sentiment control, we demonstrate the advantages of IRGD as a plug-and-play and fine-tuning-free decoding method that effectively balance attribute alignment and text quality.",,,,, ,  2024 9th International Conference on Intelligent Computing and Signal Processing (ICSP),Training;Adaptation models;Costs;Large language models;Refining;Signal processing;Data models;Decoding;controlled text generation;weighted decoding;in-context learning,detox,
2946,"**Title**Towards Controlled Table-to-Text Generation with Scientific Reasoning

**Abstract**The sheer volume of scientific experimental results and complex technical statements, often presented in tabular formats, presents a formidable barrier to individuals acquiring preferred information. The realms of scientific reasoning and content generation that adhere to user preferences encounter distinct challenges. In this work, we present a new task for generating fluent and logical descriptions that match user preferences over scientific tabular data, aiming to automate scientific document analysis. To facilitate research in this direction, we construct a new challenging dataset CTRLSciTab consisting of table-description pairs extracted from the scientific literature, with highlighted cells and corresponding domain-specific knowledge base. We evaluated popular pre-trained language models to establish a baseline and proposed a novel architecture outperforming competing approaches. The results showed that large models struggle to produce accurate content that aligns with user preferences. As the first of its kind, our work should motivate further research in scientific domains. 1","Guo, Zhixin, Zhou, Jianping, Qi, Jiexing, Yan, Mingxuan, He, Ziwei, Zheng, Guanjie, Lin, Zhouhan, Wang, Xinbing, Zhou, Chenghu",,,Towards Controlled Table-to-Text Generation with Scientific Reasoning,,,10.1109/ICASSP48485.2024.10446479 , ,,"The sheer volume of scientific experimental results and complex technical statements, often presented in tabular formats, presents a formidable barrier to individuals acquiring preferred information. The realms of scientific reasoning and content generation that adhere to user preferences encounter distinct challenges. In this work, we present a new task for generating fluent and logical descriptions that match user preferences over scientific tabular data, aiming to automate scientific document analysis. To facilitate research in this direction, we construct a new challenging dataset CTRLSciTab consisting of table-description pairs extracted from the scientific literature, with highlighted cells and corresponding domain-specific knowledge base. We evaluated popular pre-trained language models to establish a baseline and proposed a novel architecture outperforming competing approaches. The results showed that large models struggle to produce accurate content that aligns with user preferences. As the first of its kind, our work should motivate further research in scientific domains. 1",,,,, ,"  ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",Measurement;Text analysis;Knowledge based systems;Signal processing;Cognition;Acoustics;Task analysis;Table-to-text Generation;Scientific Reasoning;Controlled Generation,out_of_scope,
2947,"**Title**A Text Generation Hallucination Detection Frame-work Based on Fact and Semantic Consistency

**Abstract**With the development of pre-trained language mod-els, significant progress has been made in text generation. How-ever, these models often face inconsistencies with facts and contra-dictions in sentences, known as the “hallucination” problem of language models. To address this issue, HalluCheckNet, a mechanism thatintegrates factual and semantic consistency for hallucination detection, is proposed. By combining pre-trained models with the Plug-and-Play Language Model (PPLM) framework, HalluCheck-Net treats the degree of hallucination as a controllable attribute, using controlled text generation techniques to effectively reduce model hallucinations. Experiments conducted on GPT2 have achieved high-quality generation of social media, review, and news texts. The results demonstrate that this method not only maintains text fluency but also significantly reduces factual and semantic er-rors, making the generated texts more coherent and credible.","Li, Xinyu, Gao, Yongbing, Li, Weihao, Yang, Lidong",,,A Text Generation Hallucination Detection Frame-work Based on Fact and Semantic Consistency,,,10.1109/AINIT61980.2024.10581604 , ,,"With the development of pre-trained language mod-els, significant progress has been made in text generation. How-ever, these models often face inconsistencies with facts and contra-dictions in sentences, known as the “hallucination” problem of language models. To address this issue, HalluCheckNet, a mechanism thatintegrates factual and semantic consistency for hallucination detection, is proposed. By combining pre-trained models with the Plug-and-Play Language Model (PPLM) framework, HalluCheck-Net treats the degree of hallucination as a controllable attribute, using controlled text generation techniques to effectively reduce model hallucinations. Experiments conducted on GPT2 have achieved high-quality generation of social media, review, and news texts. The results demonstrate that this method not only maintains text fluency but also significantly reduces factual and semantic er-rors, making the generated texts more coherent and credible.",,,,, ,"  2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)",Seminars;Analytical models;Accuracy;Social networking (online);Reviews;Semantics;Knowledge based systems;Text Generation Language Model Hallucination Se-mantic Consistency;Factual Consistency;PPLM,out_of_scope,
2948,"**Title**CA-CoCon: An improved self-supervised method for controlled text generation using cross-activation attention mechanism

**Abstract**The widespread application of pre-trained large models in the field of natural language generation has facilitated the development of models capable of generating fluent textual content. While conventional text generation models often struggle to effectively control text content at the sentence level, self-supervised learning models like CoCon offer finer-grained control over generated text at the word and phrase levels. Although the text generated by CoCon tends to adhere closely to the given topic, it still exhibits deviations from human communication norms, lacking in textual diversity. Addressing these issues, we propose a novel approach based on the multi-granularity controllable text generation model, CoCon, termed as Cross-Activation (CA)-CoCon. This approach assists the model in capturing nonlinear features between input text and target content more effectively, thus facilitating the seamless integration of target content into the generated text. The proposed CA-CoCon model outperforms the untreated CoCon model across multiple thematic and emotional attribute categories, yielding text outputs that align more closely with human communication norms and exhibit enhanced textual diversity.","Li, Yanda, Ji, Gaoyang, Guo, Zhaobo, Tan, Yuanjun, Zhou, Dongbo",,,CA-CoCon: An improved self-supervised method for controlled text generation using cross-activation attention mechanism,,,10.1109/CVIDL62147.2024.10603799 , ,,"The widespread application of pre-trained large models in the field of natural language generation has facilitated the development of models capable of generating fluent textual content. While conventional text generation models often struggle to effectively control text content at the sentence level, self-supervised learning models like CoCon offer finer-grained control over generated text at the word and phrase levels. Although the text generated by CoCon tends to adhere closely to the given topic, it still exhibits deviations from human communication norms, lacking in textual diversity. Addressing these issues, we propose a novel approach based on the multi-granularity controllable text generation model, CoCon, termed as Cross-Activation (CA)-CoCon. This approach assists the model in capturing nonlinear features between input text and target content more effectively, thus facilitating the seamless integration of target content into the generated text. The proposed CA-CoCon model outperforms the untreated CoCon model across multiple thematic and emotional attribute categories, yielding text outputs that align more closely with human communication norms and exhibit enhanced textual diversity.",,,,, ,"  2024 5th International Conference on Computer Vision, Image and Deep Learning (CVIDL)",Deep learning;Computer vision;Attention mechanisms;Computational modeling;Semantics;Natural language generation;Focusing;pre-trained large language model;Controllable text generation;Self-supervised learning;Multi-granularity;Nonlinear features,out_of_scope,
2949,"**Title**Control With Style: Style Embedding-Based Variational Autoencoder for Controlled Stylized Caption Generation Framework

**Abstract**Automatic image captioning is a computationally intensive and structurally complicated task that describes the contents of an image in the form of a natural language sentence. Methods developed in the recent past focused mainly on the description of factual content in images thereby ignoring the different emotions and styles (romantic, humorous, angry, etc.) associated with the image. To overcome this, few works incorporated style-based caption generation that captures the variability in the generated descriptions. This article presents a style embedding-based variational autoencoder for controlled stylized caption generation framework (RFCG+SE-VAE-CSCG). It generates controlled text-based stylized descriptions of images. It works in two phases, i.e., $ 1)$ refined factual caption generation (RFCG); and $ 2)$ SE-VAE-CSCG. The former defines an encoder–decoder model for the generation of refined factual captions. Whereas, the latter presents a SE-VAE for controlled stylized caption generation. The overall proposed framework generates style-based descriptions of images by leveraging bag of captions (BoCs). More so, with the use of a controlled text generation model, the proposed work efficiently learns disentangled representations and generates realistic stylized descriptions of images. Experiments on MSCOCO, Flickr30K, and FlickrStyle10K provide state-of-the-art results for both refined and style-based caption generation, supported with an ablation study.","Sharma, Dhruv, Dhiman, Chhavi, Kumar, Dinesh",,,Control With Style: Style Embedding-Based Variational Autoencoder for Controlled Stylized Caption Generation Framework,,,10.1109/TCDS.2024.3405573 , ,,"Automatic image captioning is a computationally intensive and structurally complicated task that describes the contents of an image in the form of a natural language sentence. Methods developed in the recent past focused mainly on the description of factual content in images thereby ignoring the different emotions and styles (romantic, humorous, angry, etc.) associated with the image. To overcome this, few works incorporated style-based caption generation that captures the variability in the generated descriptions. This article presents a style embedding-based variational autoencoder for controlled stylized caption generation framework (RFCG+SE-VAE-CSCG). It generates controlled text-based stylized descriptions of images. It works in two phases, i.e., $ 1)$ refined factual caption generation (RFCG); and $ 2)$ SE-VAE-CSCG. The former defines an encoder–decoder model for the generation of refined factual captions. Whereas, the latter presents a SE-VAE for controlled stylized caption generation. The overall proposed framework generates style-based descriptions of images by leveraging bag of captions (BoCs). More so, with the use of a controlled text generation model, the proposed work efficiently learns disentangled representations and generates realistic stylized descriptions of images. Experiments on MSCOCO, Flickr30K, and FlickrStyle10K provide state-of-the-art results for both refined and style-based caption generation, supported with an ablation study.",,,,, ,  ,Visualization;Task analysis;Long short term memory;Decoding;Adaptation models;Transformers;Generators;Bag of captions (BoCs);computer vision;controlled text generation;image captioning;natural language processing;smooth maximum unit (SMU);stylized image captioning;variational autoencoder (VAE),out_of_scope,
2950,"**Title**Automated and Controlled Patch Generation for Enhanced Fixing of Communication Software Vulnerabilities

**Abstract**Software is a crucial component in the communication systems, and its security is of paramount importance. However, it is susceptible to different types of attacks due to potential vulnerabilities. Meanwhile, significant time and effort is required to fix such vulnerabilities. We propose an automated program repair method based on controlled text generation techniques. Specifically, we utilize a fine-tuned language model for patch generation and introduce a discriminator to evaluate the generation process, selecting results that contribute most to vulnerability fixes. Additionally, we perform static syntax analysis to expedite the patch verification process. The effectiveness of the proposed approach is validated using QuixBugs and Defects4J datasets, demonstrating significant improvements in generating correct patches compared to other existing methods.","Feng, Shuo, Yuan, Shuai, Guan, Zhitao, Du, Xiaojiang",,,Automated and Controlled Patch Generation for Enhanced Fixing of Communication Software Vulnerabilities,,,10.23919/ICN.2024.0016 , ,,"Software is a crucial component in the communication systems, and its security is of paramount importance. However, it is susceptible to different types of attacks due to potential vulnerabilities. Meanwhile, significant time and effort is required to fix such vulnerabilities. We propose an automated program repair method based on controlled text generation techniques. Specifically, we utilize a fine-tuned language model for patch generation and introduce a discriminator to evaluate the generation process, selecting results that contribute most to vulnerability fixes. Additionally, we perform static syntax analysis to expedite the patch verification process. The effectiveness of the proposed approach is validated using QuixBugs and Defects4J datasets, demonstrating significant improvements in generating correct patches compared to other existing methods.",,,,, ,  ,Computer languages;Communication systems;Syntactics;Maintenance engineering;Benchmark testing;Software;Security;automatic program repair;controlled text generation;communication software security;program language model,out_of_scope,
2951,"**Title**An Improved Self-Supervised Learning Method for Controllable Content Generation in Large Language Models

**Abstract**The widespread application of pretrained large language models for content generation has focused on overcoming the illusion of control in text generation. While fine-grained control at the word and phrase level allows for partially controlled text generation, the probability of producing content that aligns with human natural language patterns remains low. This article proposes an enhanced self-supervised learning approach to improve the quality of controllable text generation for this issue. Building upon the CoCon model, our approach ensures controllability in text generation at both the sentence and word granularity. It amplifies features in a high-dimensional space, filtering out irrelevant feature information to aid the model in generating more precise content. Experimental results on publicly available datasets demonstrate that our approach effectively reduces Perplexity, enhances model performance, and produces text that better conforms to natural language conventions.","Li, Yanda, Guo, Zhaobo, Tan, Yuanjun, Ji, Gaoyang, Zhou, Dongbo",,,An Improved Self-Supervised Learning Method for Controllable Content Generation in Large Language Models,,,10.1109/ICCECT60629.2024.10545853 , ,,"The widespread application of pretrained large language models for content generation has focused on overcoming the illusion of control in text generation. While fine-grained control at the word and phrase level allows for partially controlled text generation, the probability of producing content that aligns with human natural language patterns remains low. This article proposes an enhanced self-supervised learning approach to improve the quality of controllable text generation for this issue. Building upon the CoCon model, our approach ensures controllability in text generation at both the sentence and word granularity. It amplifies features in a high-dimensional space, filtering out irrelevant feature information to aid the model in generating more precise content. Experimental results on publicly available datasets demonstrate that our approach effectively reduces Perplexity, enhances model performance, and produces text that better conforms to natural language conventions.",,,,, ,"  2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT)",Measurement;Training;Solid modeling;Filtering;Computational modeling;Natural languages;Training data;controllable text generation;pretrained large language model;self-supervised learning;Perplexity,out_of_scope,
2952,"**Title**Beyond Large Language Models: Rediscovering the Role of Classical Statistics in Modern Data Science

**Abstract**This study explores the synergy between large language models and classical statistics in contemporary data science. In the field of large language models, we find there is no one-size-fits-all model which satisfies the needs of other scientists. There are differences in the soft results which may be a limitation on their application. To analyze these differences and lack of robustness, we propose a robust methodology that integrates classical statistical experimental design principles with the these advanced models, aiming to identify statistically significant differences among their outcomes. In particular, an experimental design is presented in which the main factors, levels, treatments and interactions that influence the predictions made by different models of complex natural language processing are identified. The main aim of this research is to better understand the influence of some controlled factors that are used in com-plex natural language processing models by applying classical statistical techniques, providing a comprehensive perspective on the relative effectiveness of different zero-shot classification models. It aims to offer practitioners insights into when and where certain models may be more or less sensitive, facilitating informed decision-making in applying these advanced language models. Additionally, computational results obtained from a pilot dataset are presented. These results illustrate the entire process of the proposed methodology, highlighting the importance of considering statistical evidence when making decisions.","Gutiérrez, Inmaculada, Gómez, Daniel, Castro, Javier, Bimber, Bruce, Labarre, Julien",,,Beyond Large Language Models: Rediscovering the Role of Classical Statistics in Modern Data Science,,,10.1109/FUZZ-IEEE60900.2024.10611766 , ,,"This study explores the synergy between large language models and classical statistics in contemporary data science. In the field of large language models, we find there is no one-size-fits-all model which satisfies the needs of other scientists. There are differences in the soft results which may be a limitation on their application. To analyze these differences and lack of robustness, we propose a robust methodology that integrates classical statistical experimental design principles with the these advanced models, aiming to identify statistically significant differences among their outcomes. In particular, an experimental design is presented in which the main factors, levels, treatments and interactions that influence the predictions made by different models of complex natural language processing are identified. The main aim of this research is to better understand the influence of some controlled factors that are used in com-plex natural language processing models by applying classical statistical techniques, providing a comprehensive perspective on the relative effectiveness of different zero-shot classification models. It aims to offer practitioners insights into when and where certain models may be more or less sensitive, facilitating informed decision-making in applying these advanced language models. Additionally, computational results obtained from a pilot dataset are presented. These results illustrate the entire process of the proposed methodology, highlighting the importance of considering statistical evidence when making decisions.",,,,, ,  2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),Analytical models;Computational modeling;Large language models;Decision making;Data science;Predictive models;Natural language processing;Large Language Model;Transformers;Explain-able Artificial Intelligence;Experiment Design;Statistics,out_of_scope,
2953,"**Title**Shellcode Generation: A Resource Efficient Approach using Fine-tuned LLMs

**Abstract**In order to create better shellcode for offensive cybersecurity, this study investigates the use of large language models (LLMs) such as Mistral and Llama. It focuses on LLM optimizations to improve shellcode accuracy and efficiency with the goal of quickly locating and taking advantage of software vulnerabilities. To optimize shellcode generation, several model parameters are tuned through controlled experiments, with the BLEU score serving as the primary criterion for impartial evaluation. This study achieved a BLEU-1 score of $\mathbf{0. 8 5 0 6,}$ highlighting the effectiveness of the optimization and finetuning strategies. The study explores the subtle aspects of LLMs that influence the creation of shellcode, such as their capacity for learning, their ability to adjust to the peculiarities of cybersecurity, and their ability to replicate complex patterns into effective shellcode. This project intends to expand knowledge of using LLMs for shellcode development by submitting significant experimentation and research, providing insights into more efficient vulnerability exploitation strategies in cybersecurity.","Ram, Madhav, Mohith Krishna, V, Pranavkrishnan, M, Nair, Priyanka C, Gupta, Deepa",,,Shellcode Generation: A Resource Efficient Approach using Fine-tuned LLMs,,,10.1109/ICCCNT61001.2024.10723327 , ,,"In order to create better shellcode for offensive cybersecurity, this study investigates the use of large language models (LLMs) such as Mistral and Llama. It focuses on LLM optimizations to improve shellcode accuracy and efficiency with the goal of quickly locating and taking advantage of software vulnerabilities. To optimize shellcode generation, several model parameters are tuned through controlled experiments, with the BLEU score serving as the primary criterion for impartial evaluation. This study achieved a BLEU-1 score of $\mathbf{0. 8 5 0 6,}$ highlighting the effectiveness of the optimization and finetuning strategies. The study explores the subtle aspects of LLMs that influence the creation of shellcode, such as their capacity for learning, their ability to adjust to the peculiarities of cybersecurity, and their ability to replicate complex patterns into effective shellcode. This project intends to expand knowledge of using LLMs for shellcode development by submitting significant experimentation and research, providing insights into more efficient vulnerability exploitation strategies in cybersecurity.",,,,, ,  2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),Training;Codes;Large language models;Earth Observing System;Training data;Software;Data models;Computer security;Optimization;Tuning;Shellcode generation;large language models;Mistral;Llama;LlM finetuning;cybersecurity;LoRA,out_of_scope,
2954,"**Title**Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness

**Abstract**This paper presents a system for diversity-aware autonomous conversation leveraging the capabilities of large language models (LLMs). The system adapts to diverse populations and individuals, considering factors like background, personality, age, gender, and culture. The conversation flow is guided by the structure of the system’s pre-established knowledge base, while LLMs are tasked with various functions, including generating diversity-aware sentences. Achieving diversity-awareness involves providing carefully crafted prompts to the models, incorporating comprehensive information about users, conversation history, contextual details, and specific guidelines. To assess the system’s performance, we conducted both controlled and real-world experiments, measuring a wide range of performance indicators.","Grassi, Lucrezia, Recchiuto, Carmine Tommaso, Sgorbissa, Antonio",,,Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness,,,10.1109/RO-MAN60168.2024.10731381 , ,,"This paper presents a system for diversity-aware autonomous conversation leveraging the capabilities of large language models (LLMs). The system adapts to diverse populations and individuals, considering factors like background, personality, age, gender, and culture. The conversation flow is guided by the structure of the system’s pre-established knowledge base, while LLMs are tasked with various functions, including generating diversity-aware sentences. Achieving diversity-awareness involves providing carefully crafted prompts to the models, incorporating comprehensive information about users, conversation history, contextual details, and specific guidelines. To assess the system’s performance, we conducted both controlled and real-world experiments, measuring a wide range of performance indicators.",,,,, ,  2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN),Large language models;Knowledge based systems;Human-robot interaction;Oral communication;Ontologies;Hybrid power systems;Time factors;Noise measurement;History;Robots,out_of_scope,
2955,"**Title**High frequency multi-purpose pulse generator

**Abstract**Applications for this pulse generator include: metal surface modification by electron beam, sterilization of water solution by generation of a powerful electromagnetic wave, sterilization of food products and medical apparatus, sterilization of wood, destruction of rock, excitation of laser radiation, cleaning gas ejections of thermal stations from toxic SO/sub x/ and NO/sub x/ by a positive pulse corona. Generator technical parameters (on an equivalent load /spl sim/ 20 Ohm): voltage 120 kV, pulse duration 500 ns, rise time 180 ns, frequency 100 Hz, efficiency 80%. This paper presents the results of the development project and testing of the generator model.","Engelko, V.I., Bolshakov, E.P., Istomin, U.A., Pechersky, O.P.",,,High frequency multi-purpose pulse generator,,,10.1109/MODSYM.2002.1189499 , ,,"Applications for this pulse generator include: metal surface modification by electron beam, sterilization of water solution by generation of a powerful electromagnetic wave, sterilization of food products and medical apparatus, sterilization of wood, destruction of rock, excitation of laser radiation, cleaning gas ejections of thermal stations from toxic SO/sub x/ and NO/sub x/ by a positive pulse corona. Generator technical parameters (on an equivalent load /spl sim/ 20 Ohm): voltage 120 kV, pulse duration 500 ns, rise time 180 ns, frequency 100 Hz, efficiency 80%. This paper presents the results of the development project and testing of the generator model.",,,,, ,"  Conference Record of the Twenty-Fifth International Power Modulator Symposium, 2002 and 2002 High-Voltage Workshop.",Frequency;Pulse generation;Optical pulse generation;Surface waves;Surface emitting lasers;Electron beams;Power generation;Electromagnetic scattering;Food products;Laser excitation,out_of_scope,
2956,"**Title**STopHC: A Harmful Content Detection and Mitigation Architecture for Social Media Platforms

**Abstract**The mental health of social media users has started more and more to be put at risk by harmful, hateful, and offensive content. In this paper, we propose STOPHC, a harmful content detection and mitigation architecture for social media platforms. Our aim with STOPHC is to create more secure online environments. Our solution contains two modules, one that employs deep neural network architecture for harmful content detection, and one that uses a network immunization algorithm to block toxic nodes and stop the spread of harmful content. The efficacy of our solution is demonstrated by experiments conducted on two real-world datasets.","Truică, Ciprian-Octavian, Constantinescu, Ana-Teodora, Apostol, Elena-Simona",,,STopHC: A Harmful Content Detection and Mitigation Architecture for Social Media Platforms,,,10.1109/ICCP63557.2024.10793051 , ,,"The mental health of social media users has started more and more to be put at risk by harmful, hateful, and offensive content. In this paper, we propose STOPHC, a harmful content detection and mitigation architecture for social media platforms. Our aim with STOPHC is to create more secure online environments. Our solution contains two modules, one that employs deep neural network architecture for harmful content detection, and one that uses a network immunization algorithm to block toxic nodes and stop the spread of harmful content. The efficacy of our solution is demonstrated by experiments conducted on two real-world datasets.",,,,, ,  2024 IEEE 20th International Conference on Intelligent Computer Communication and Processing (ICCP),Social networking (online);Prevention and mitigation;Computer architecture;Mental health;Artificial neural networks;Media;Harmful Content Detection;Harmful Content Mitigation;Social Media Analysis;Deep Neural Networks;Network Immunization,detection,
2957,"**Title**A new test to characterise low voltage cables subjected to thermal and mechanical stresses

**Abstract**During the service, electric cables for low voltage (450/750 V) systems can be subjected both to thermal stress due to the high current caused by short circuits in the system and to mechanical stresses due to the laying conditions. The behaviour of two different kinds of cables, when subjected to such thermal and mechanical stresses, was considered: a PVC insulated cable not propagating fire and a very low (smoke and toxic gasses) emission cable insulated by a LSOH compound. An ""ad hoc"" test cell was designed to study the above insulating materials subjected to the combined stresses. As to the thermal stress, the specimens (a part of a 1.5 mm/sup 2/ cable) were subjected to sinusoidal current waves (hundreds of Ampere amplitude, lasting 100 ms) sequentially applied every 5 seconds. The mechanical stress was obtained applying a high pressure crushing the cable to four suitable cylindrical supports. When any cylinder got in contact with the specimen cable copper, an electrical current flew through that cylinder to ground and a max current relay was tripped, stopping the aging test. The proposed test cell and procedure, could be considered as a new ""type test"" useful to characterize low voltage cables insulation in presence of both thermal and mechanical stresses.","Guastavino, F., Centurioni, L., Torello, E., Zaopo, A.",,,A new test to characterise low voltage cables subjected to thermal and mechanical stresses,,,10.1109/CEIDP.2002.1048934 , ,,"During the service, electric cables for low voltage (450/750 V) systems can be subjected both to thermal stress due to the high current caused by short circuits in the system and to mechanical stresses due to the laying conditions. The behaviour of two different kinds of cables, when subjected to such thermal and mechanical stresses, was considered: a PVC insulated cable not propagating fire and a very low (smoke and toxic gasses) emission cable insulated by a LSOH compound. An ""ad hoc"" test cell was designed to study the above insulating materials subjected to the combined stresses. As to the thermal stress, the specimens (a part of a 1.5 mm/sup 2/ cable) were subjected to sinusoidal current waves (hundreds of Ampere amplitude, lasting 100 ms) sequentially applied every 5 seconds. The mechanical stress was obtained applying a high pressure crushing the cable to four suitable cylindrical supports. When any cylinder got in contact with the specimen cable copper, an electrical current flew through that cylinder to ground and a max current relay was tripped, stopping the aging test. The proposed test cell and procedure, could be considered as a new ""type test"" useful to characterize low voltage cables insulation in presence of both thermal and mechanical stresses.",,,,, ,  Annual Report Conference on Electrical Insulation and Dielectric Phenomena,Low voltage;Mechanical cables;Thermal stresses;Cable insulation;Gas insulation;Insulation testing;Circuit testing;Fires;Materials testing;Contacts,out_of_scope,
2958,"**Title**Forecasting the Spread of Toxicity on Twitter

**Abstract**In this paper, we explore the question of whether it is possible to forecast the spread of hate on Twitter. Unlike most prior work which models the spread of Twitter over a network with the goal of predicting the future “state” of a user (typically, as being “hateful” or not), here we are interested in how “hateful” (or toxic) the network as a whole becomes. We pose toxicity spread as a forecasting problem, and use ARIMA to find out whether the spread is forecastable. We find that toxicity spread is indeed forecasted by ARIMA. Given that it is forecastable, we ask two follow-up questions: (a) How well can we forecast it? and (b) What role, if any, does the structure of the retweet network play in forecasting? In order to answer these questions, we employ several techniques including Spatio-Temporal Graph Convolution Network (STGCN) and several variants of transformers. To determine the role that structure might play, we re-purpose the dataset in three ways: the network as a whole (the structure is ignored), communities interconnected with each other, and neighbourhoods of a set of individuals. Experiments with the network as a whole informs us how well we can forecast hate spread at a global level, while the latter experiments tell us whether and how network effects affect the forecasting. In an effort to tease out the effect of the network, we use two distinct techniques: STGCN, which requires the explicit connections in the form of a graph as input; and Transformers, where no explicit graph is given as input. Instead, we pose it as a multivariate analysis problem. We find that the PatchTST transformer performs the best at all levels. STGCN performs better than ARIMA suggesting that network structure matters. Somewhat interestingly, STGCN does not perform as well as PatchTST, suggesting that (a) PatchTST is able to implicitly learn the associations (flow of influence), and (b) the presence of explicit connections may not always imply influence.","Vaidya, Aatman, Nagar, Seema, Nanavati, Amit A.",,,Forecasting the Spread of Toxicity on Twitter,,,10.1109/CogMI58952.2023.00038 , ,,"In this paper, we explore the question of whether it is possible to forecast the spread of hate on Twitter. Unlike most prior work which models the spread of Twitter over a network with the goal of predicting the future “state” of a user (typically, as being “hateful” or not), here we are interested in how “hateful” (or toxic) the network as a whole becomes. We pose toxicity spread as a forecasting problem, and use ARIMA to find out whether the spread is forecastable. We find that toxicity spread is indeed forecasted by ARIMA. Given that it is forecastable, we ask two follow-up questions: (a) How well can we forecast it? and (b) What role, if any, does the structure of the retweet network play in forecasting? In order to answer these questions, we employ several techniques including Spatio-Temporal Graph Convolution Network (STGCN) and several variants of transformers. To determine the role that structure might play, we re-purpose the dataset in three ways: the network as a whole (the structure is ignored), communities interconnected with each other, and neighbourhoods of a set of individuals. Experiments with the network as a whole informs us how well we can forecast hate spread at a global level, while the latter experiments tell us whether and how network effects affect the forecasting. In an effort to tease out the effect of the network, we use two distinct techniques: STGCN, which requires the explicit connections in the form of a graph as input; and Transformers, where no explicit graph is given as input. Instead, we pose it as a multivariate analysis problem. We find that the PatchTST transformer performs the best at all levels. STGCN performs better than ARIMA suggesting that network structure matters. Somewhat interestingly, STGCN does not perform as well as PatchTST, suggesting that (a) PatchTST is able to implicitly learn the associations (flow of influence), and (b) the presence of explicit connections may not always imply influence.",,,,, ,  2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI),Toxicology;Social networking (online);Blogs;Time series analysis;Predictive models;Transformers;Forecasting;Forecasting;Hate Speech;Hate Spread;Social Network Analysis;Time Series,detection,
2959,"**Title**DCE-diff: Diffusion Model for Synthesis of Early and Late Dynamic Contrast-Enhanced MR Images from Non-Contrast Multimodal Inputs

**Abstract**Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) is pivotal in delineating abnormal lesions and cancerous regions in the anatomy of interest. However, DCE-MRI requires the injection of gadolinium (Gad)based contrast agents during acquisition which is known to have potential toxic effects, posing radiological concerns. Previous deep learning models employed for synthesizing DCE-MRI images consider unimodal structural MRI inputs lacking information about perfusion or perform early to late response predictions requiring Gad-based MRI sequences as input to drive the synthesis. In this work, we consider the heterogeneity in (i) the multimodal MRI structural inputs offering diverse and complementary anatomical features, (ii) the scanner settings and acquisition parameters, and (iii) the importance of incorporating the perfusion information in Apparent Diffusion Coefficient (ADC) data, which is essential to learn the hyperintense features for DCE-MRI synthesis. We propose DCE-diff, a deep generative diffusion model for multimodal image-to-image mapping from non-contrast structural MRI sequences and ADC maps to synthesize early and late response DCE-MRI images to circumvent Gad contrast injection to patients. Comparative studies using ProstateX and Prostate-MRI datasets against previous methods show that our model demonstrates (i) better synthesis quality with improvement margins of +0.85 dB in PSNR, +0.04 in SSIM, -22.8 in FID, and -0.02 in MAE (ii) better adaptability to different scanner data with deviated settings, showcasing a +8.7 dB improvement in PSNR, +0.22 in SSIM, -40.4 in FID, and -0.1 in MAE, and (iii) the importance of ADC maps in the DCE-MRI synthesis.","M, Kishore Kumar, Ramanarayanan, Sriprabha, S, Sadhana, Sarkar, Arunima, Gayathri, Matcha Naga, Ram, Keerthi, Sivaprakasam, Mohanasankar",,,DCE-diff: Diffusion Model for Synthesis of Early and Late Dynamic Contrast-Enhanced MR Images from Non-Contrast Multimodal Inputs,,,10.1109/CVPRW63382.2024.00525 , ,,"Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) is pivotal in delineating abnormal lesions and cancerous regions in the anatomy of interest. However, DCE-MRI requires the injection of gadolinium (Gad)based contrast agents during acquisition which is known to have potential toxic effects, posing radiological concerns. Previous deep learning models employed for synthesizing DCE-MRI images consider unimodal structural MRI inputs lacking information about perfusion or perform early to late response predictions requiring Gad-based MRI sequences as input to drive the synthesis. In this work, we consider the heterogeneity in (i) the multimodal MRI structural inputs offering diverse and complementary anatomical features, (ii) the scanner settings and acquisition parameters, and (iii) the importance of incorporating the perfusion information in Apparent Diffusion Coefficient (ADC) data, which is essential to learn the hyperintense features for DCE-MRI synthesis. We propose DCE-diff, a deep generative diffusion model for multimodal image-to-image mapping from non-contrast structural MRI sequences and ADC maps to synthesize early and late response DCE-MRI images to circumvent Gad contrast injection to patients. Comparative studies using ProstateX and Prostate-MRI datasets against previous methods show that our model demonstrates (i) better synthesis quality with improvement margins of +0.85 dB in PSNR, +0.04 in SSIM, -22.8 in FID, and -0.02 in MAE (ii) better adaptability to different scanner data with deviated settings, showcasing a +8.7 dB improvement in PSNR, +0.22 in SSIM, -40.4 in FID, and -0.1 in MAE, and (iii) the importance of ADC maps in the DCE-MRI synthesis.",,,,, ,  2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),Deep learning;Magnetic resonance imaging;Conferences;Predictive models;Diffusion models;Transformers;Gadolinium;Dynamic Contrast-Enhanced MRI;Diffusion models;Prostate;Multimodal Image-to-Image translation,out_of_scope,
2960,"**Title**Enhancing Indonesian Abusive Language Detection on Imbalanced News Comment Dataset Using Support Vector Machine with Oversampling

**Abstract**The growth of the internet facilitates ease of interaction and communication, including in the online news platforms with their comment sections. However, this phenomenon triggers the emergence of the online disinhibition effect, leading individuals to exhibit more aggressive behavior on the internet (toxic disinhibition). This has resulted in the prevalence of abusive language in online news comment sections, posing risks to the other readers and the subjects targeted by the abusive comments. In the context of abusive language detection, comments can be categorized into three classes, i.e., not abusive, abusive but not offensive, and abusive and offensive. Therefore, this study conducts a multiclass classification of Indonesian online news comments with those three categories. Experimental results indicate that SVM with word unigram TF-IDF serves as the best baseline classification model with a macro-average F1-score of 45.37%. We compared Easy Data Augmentation (EDA) and Synthetic Minority Oversampling Technique (SMOTE) to address the issue of extreme imbalance in the dataset. The results show that SMOTE outperforms EDA with a macro-average F1-score of 51.45% (an increase of 6.08% from baseline classification), while EDA achieves a macro-average F1-score of 49.83%. The random deletion (RD) operation was chosen for EDA, as other operations tended to decrease its performance. One drawback of EDA is the lack of a corpus for finding similar words. On the other hand, the classification results using SMOTE improve the generalization of the model more effectively. However, some issues persist, such as the abundance of Out of Vocabulary (OOV) occurrences leading to misclassification.","Hendrawan, Rahmat, Hana, Karimah Mutisari, Kurniati, Angelina Prima",,,Enhancing Indonesian Abusive Language Detection on Imbalanced News Comment Dataset Using Support Vector Machine with Oversampling,,,10.1109/ICITRI62858.2024.10699029 , ,,"The growth of the internet facilitates ease of interaction and communication, including in the online news platforms with their comment sections. However, this phenomenon triggers the emergence of the online disinhibition effect, leading individuals to exhibit more aggressive behavior on the internet (toxic disinhibition). This has resulted in the prevalence of abusive language in online news comment sections, posing risks to the other readers and the subjects targeted by the abusive comments. In the context of abusive language detection, comments can be categorized into three classes, i.e., not abusive, abusive but not offensive, and abusive and offensive. Therefore, this study conducts a multiclass classification of Indonesian online news comments with those three categories. Experimental results indicate that SVM with word unigram TF-IDF serves as the best baseline classification model with a macro-average F1-score of 45.37%. We compared Easy Data Augmentation (EDA) and Synthetic Minority Oversampling Technique (SMOTE) to address the issue of extreme imbalance in the dataset. The results show that SMOTE outperforms EDA with a macro-average F1-score of 51.45% (an increase of 6.08% from baseline classification), while EDA achieves a macro-average F1-score of 49.83%. The random deletion (RD) operation was chosen for EDA, as other operations tended to decrease its performance. One drawback of EDA is the lack of a corpus for finding similar words. On the other hand, the classification results using SMOTE improve the generalization of the model more effectively. However, some issues persist, such as the abundance of Out of Vocabulary (OOV) occurrences leading to misclassification.",,,,, ,  2024 International Conference on Information Technology Research and Innovation (ICITRI),Support vector machines;Vocabulary;Technological innovation;Dictionaries;Computational modeling;Data augmentation;Transformers;Data models;Vectors;Information technology;abusive language detection;support vector machine;oversampling;news comment dataset,out_but_toxicity,
2961,"**Title**Towards wireless neural electrodes: System-integration for stimulating and recording of nerve signals

**Abstract**In this paper we present the developed components and the electronic packaging design for a miniaturized, wireless neural electrode. Particularly, the whole system consists of a hook-up electrode for contacting the nerve and an electronic part that generates and sends stimulating signals to the nerve and records the neural signals. The hook-up electrode has been designed in a way that enhances the easy of positioning during the medical procedure and consists of biocompatible materials in order to avoid toxic tissue reactions. The most important component of the electronic part is a developed ASIC, which receives power and data from a coil and generates the stimulating signals and records signals coming from the nerve. The telemetric power and data transmission is based on a transponder principle. A separate sending and reading unit laid under the patient is providing energy and data transmission to the wireless system for stimulation and recording. The assembly of all components is ensured by a system-integration approach that maintains functioning of the whole wireless system properly and reliably. In this regard, the proposed wireless neural electrode offers a promising alternative for applications in neural electrical stimulation and recording.","Varga, Melinda, Schulz, Katharina, Taschwer, Armin, Wolter, Klaus-Jürgen",,,Towards wireless neural electrodes: System-integration for stimulating and recording of nerve signals,,,10.1109/ESTC.2014.6962805 , ,,"In this paper we present the developed components and the electronic packaging design for a miniaturized, wireless neural electrode. Particularly, the whole system consists of a hook-up electrode for contacting the nerve and an electronic part that generates and sends stimulating signals to the nerve and records the neural signals. The hook-up electrode has been designed in a way that enhances the easy of positioning during the medical procedure and consists of biocompatible materials in order to avoid toxic tissue reactions. The most important component of the electronic part is a developed ASIC, which receives power and data from a coil and generates the stimulating signals and records signals coming from the nerve. The telemetric power and data transmission is based on a transponder principle. A separate sending and reading unit laid under the patient is providing energy and data transmission to the wireless system for stimulation and recording. The assembly of all components is ensured by a system-integration approach that maintains functioning of the whole wireless system properly and reliably. In this regard, the proposed wireless neural electrode offers a promising alternative for applications in neural electrical stimulation and recording.",,,,, ,  Proceedings of the 5th Electronics System-integration Technology Conference (ESTC),Electrodes;Wireless communication;Coils;Receivers;Application specific integrated circuits;Communication system security;Wireless sensor networks,out_of_scope,
2962,"**Title**Supercritical water use in energetic - Corrosion issues

**Abstract**Supercritical water (SCW) is water at conditions above the critical point (typically 600°C, 25 MPa). SCW is used as coolant in the primary circuit of one of the new concepts of nuclear reactors. Supercritical water has unique properties and very low price enables its use as chemical environment as well as reactant taking part in chemical reactions. These reactions lead to very interesting products (i.e. nanocrystals). SCW can be use for toxic waste elimination, or as medium for biomass gasification.","Zychová, M., Růžičková, M.",,,Supercritical water use in energetic - Corrosion issues,,, , ,,"Supercritical water (SCW) is water at conditions above the critical point (typically 600°C, 25 MPa). SCW is used as coolant in the primary circuit of one of the new concepts of nuclear reactors. Supercritical water has unique properties and very low price enables its use as chemical environment as well as reactant taking part in chemical reactions. These reactions lead to very interesting products (i.e. nanocrystals). SCW can be use for toxic waste elimination, or as medium for biomass gasification.",,,,, ,  Proceedings of the 2011 3rd International Youth Conference on Energetics (IYCE),Corrosion;Inductors;Water;Chemicals;Power generation;Radiation effects;corrosion;fission reactors;physical and chemical properties;power conversion;radiation safety;sensors;solvent;supercritical water reactor;synthesis;waste elimination,out_of_scope,
2963,"**Title**Single-Ended Primary Inductor Converter (SEPIC) Converter, DC-DC Boost, and Cuk Converters with a Self-Guided Reimanuian Residual Network: Optimisation of Solar Energy

**Abstract**Finding solutions to reduce emissions of carbon dioxide, which is a toxic gas that produces negative changes on a worldwide scale, is the difficulty that the greenhouse effect faces in the present day. Solar power, which takes advantage of a solar array system that is made up of a variety of components, is one of the environmentally beneficial energy sources. The Maximum Power Point Tracker (MPPT), which ensures that the system generates the most amount of electricity possible, is an essential component of this system. The Insulated Gate Bipolar Transistor (IGBT), which modifies the system's resistance, receives a signal from the MPPT via a Pulse Width Modulator (PWM). The Perturbation and Observation (P&O) algorithm was utilized by conventional controllers; however, it was unable to cope with the rapid changes that occurred in the environment. The new Self-guided Reimannian residual network (SGRRNN) controller produced to enhances efficiency by rapidly adjusting to alterations. The hyperparameters of SGRRNN is optimized using the Energy Valley Optimizer to improve the efficiency. Boost, Cuk, and Single-Ended Primary Inductor Converter (SEPIC) converters are the three DC-DC converters that are compared in this work with the SGRRNN controller on the basis of three data sets consisting of 104, 201, and 1001 respectively. This outcomes in an increase in the effectiveness of solar photovoltaic (PV) systems, with the SGRRNN controller obtaining a peak efficiency of 96.2275% when that controller is integrated with a DC-DC Boost converter.","Krishnan, M. Sivaram, Govindaraj, V., Jerin, G., Yuvanandhini, D., Sandhiya A, N., Begum, Asha",,,"Single-Ended Primary Inductor Converter (SEPIC) Converter, DC-DC Boost, and Cuk Converters with a Self-Guided Reimanuian Residual Network: Optimisation of Solar Energy",,,10.1109/ICACRS62842.2024.10841609 , ,,"Finding solutions to reduce emissions of carbon dioxide, which is a toxic gas that produces negative changes on a worldwide scale, is the difficulty that the greenhouse effect faces in the present day. Solar power, which takes advantage of a solar array system that is made up of a variety of components, is one of the environmentally beneficial energy sources. The Maximum Power Point Tracker (MPPT), which ensures that the system generates the most amount of electricity possible, is an essential component of this system. The Insulated Gate Bipolar Transistor (IGBT), which modifies the system's resistance, receives a signal from the MPPT via a Pulse Width Modulator (PWM). The Perturbation and Observation (P&O) algorithm was utilized by conventional controllers; however, it was unable to cope with the rapid changes that occurred in the environment. The new Self-guided Reimannian residual network (SGRRNN) controller produced to enhances efficiency by rapidly adjusting to alterations. The hyperparameters of SGRRNN is optimized using the Energy Valley Optimizer to improve the efficiency. Boost, Cuk, and Single-Ended Primary Inductor Converter (SEPIC) converters are the three DC-DC converters that are compared in this work with the SGRRNN controller on the basis of three data sets consisting of 104, 201, and 1001 respectively. This outcomes in an increase in the effectiveness of solar photovoltaic (PV) systems, with the SGRRNN controller obtaining a peak efficiency of 96.2275% when that controller is integrated with a DC-DC Boost converter.",,,,, ,"  2024 3rd International Conference on Automation, Computing and Renewable Systems (ICACRS)",Maximum power point trackers;Photovoltaic systems;Insulated gate bipolar transistors;Resistance;Renewable energy sources;Solar energy;Inductors;Voltage control;Optimization;Residual neural networks;Self-guided attention;Single-Ended Primary Inductor Converter;Boost converter;Cuk converter;optimization,out_of_scope,
2964,"**Title**Multilingual Toxic Comment Classification using Deep Learning

**Abstract**Toxic comments can have a profoundly negative impact on online communities, fostering environments that feel unsafe, unwelcoming, and discouraging for participation. The task of toxic comment classification focuses on identifying and categorizing harmful or disruptive comments within online discussions. Despite extensive research in this area, several challenges persist, such as Multilingual Toxicity Detection, Data Imbalance, and Interpretability. Existing studies have categorized toxic comments into six distinct labels: toxic, severely toxic, obscene, threat, insult, and identity hate. Traditional machine learning models like SVM have achieved an accuracy of 87%, while more advanced models like BERT have reached up to 98.3%. The goal of this proposed work is to improve the identification of toxic comments across multiple social media platforms, particularly in datasets containing entries in multiple languages. To address this, deep learning models such as XLM-RoBERTa and BERT are employed to detect the language of the comment and classify it as either toxic or non-toxic. Each model’s performance will be evaluated primarily using Accuracy metrics, providing a basis for comparison to determine the most effective approach for multilingual toxic comment detection. High accuracy can be achieved through careful dataset preprocessing, advanced model architectures, and hyperparameter tuning. Performance can be improved by fine-tuning model hyperparameters and employing better feature extraction techniques. More clarity is required in explaining the rationale behind selecting particular models.","Venugopal, N. L. V., Kanchanamala, P, Muppidi, Satish, Prakash, T. Bhanu, Neelima, T., Devi, S Anjali",,,Multilingual Toxic Comment Classification using Deep Learning,,,10.1109/ICSSAS64001.2024.10760913 , ,,"Toxic comments can have a profoundly negative impact on online communities, fostering environments that feel unsafe, unwelcoming, and discouraging for participation. The task of toxic comment classification focuses on identifying and categorizing harmful or disruptive comments within online discussions. Despite extensive research in this area, several challenges persist, such as Multilingual Toxicity Detection, Data Imbalance, and Interpretability. Existing studies have categorized toxic comments into six distinct labels: toxic, severely toxic, obscene, threat, insult, and identity hate. Traditional machine learning models like SVM have achieved an accuracy of 87%, while more advanced models like BERT have reached up to 98.3%. The goal of this proposed work is to improve the identification of toxic comments across multiple social media platforms, particularly in datasets containing entries in multiple languages. To address this, deep learning models such as XLM-RoBERTa and BERT are employed to detect the language of the comment and classify it as either toxic or non-toxic. Each model’s performance will be evaluated primarily using Accuracy metrics, providing a basis for comparison to determine the most effective approach for multilingual toxic comment detection. High accuracy can be achieved through careful dataset preprocessing, advanced model architectures, and hyperparameter tuning. Performance can be improved by fine-tuning model hyperparameters and employing better feature extraction techniques. More clarity is required in explaining the rationale behind selecting particular models.",,,,, ,  2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),Training;Deep learning;Adaptation models;Toxicology;Accuracy;Social networking (online);Bidirectional control;Transformers;Encoding;Tuning;Multilingual Toxicity Detection;Bidirectional Encoder Representations from Transformers (BERT);Toxic comment;Deep learning,detection,
2965,"**Title**Climatic, environmental and fire behaviour class verification on dry-type transformers; KEMA laboratories testing

**Abstract**Transformers belong to the crucial components in distribution and transmission networks. Reliable use for many years needs to be guaranteed. Besides quality assurance of the manufacturer type testing is the most common way to prove this reliability under normal and extreme conditions. In addition, for dry-type transformers, special tests to prove climatic (C), environmental (E) and fire behaviour (F) class are defined in the international standard IEC 60076-11. End users, e.g. utilities and wind turbine manufacturers, are demanding proof of the claimed qualities of dry-type transformers increasingly. The independent KEMA laboratories, owned by DNV-GL, gained large testing experience for C and E class verification. In 2013 also verification for F class was added to KEMA laboratories portfolio, where now experience has been built-up. For C class verification, a thermal shock test is to be performed. The most common failure is the appearance of cracks, found during visual inspection after the test. The most important part for E2 class verification is the performance of a condensation test, where the transformer is energized while salt condensation is to be present on the surfaces of the object. Failures are flashovers causing voltage breakdowns and serious tracking degrading the transformers dielectric qualities. As part of the F class verification, a complete assembled phase of a transformer is set on fire in a test chamber equipped with air inlet and chimney. Temperatures in the chimney above the allowed limits will lead to unsuccessful results. In the last five years, many (> 40) dry-type distribution transformers (power range up to 3,5 MVA) were tested for verification of one or more of these classes. Often (> 50%) the requirements as per IEC 60076-11 and/or clients specifications could not be met. In some cases design changes and retests were required to meet the requirements, in other cases test programs were stopped due to failure of the object. This paper will explain the importance of the above mentioned tests. Also explanation will be given on the testing methods and procedures required for reliable and reproducible tests, results and conclusions. Climatic, environmental and fire behaviour tests are important special tests proving utilities and other end users of dry-type transformers the quality of the product.","Smeenk, Sjoerd, Lathouwers, André, Smeets, René, YanSong, Luo",,,"Climatic, environmental and fire behaviour class verification on dry-type transformers; KEMA laboratories testing",,,10.1109/APPEEC.2014.7066194 , ,,"Transformers belong to the crucial components in distribution and transmission networks. Reliable use for many years needs to be guaranteed. Besides quality assurance of the manufacturer type testing is the most common way to prove this reliability under normal and extreme conditions. In addition, for dry-type transformers, special tests to prove climatic (C), environmental (E) and fire behaviour (F) class are defined in the international standard IEC 60076-11. End users, e.g. utilities and wind turbine manufacturers, are demanding proof of the claimed qualities of dry-type transformers increasingly. The independent KEMA laboratories, owned by DNV-GL, gained large testing experience for C and E class verification. In 2013 also verification for F class was added to KEMA laboratories portfolio, where now experience has been built-up. For C class verification, a thermal shock test is to be performed. The most common failure is the appearance of cracks, found during visual inspection after the test. The most important part for E2 class verification is the performance of a condensation test, where the transformer is energized while salt condensation is to be present on the surfaces of the object. Failures are flashovers causing voltage breakdowns and serious tracking degrading the transformers dielectric qualities. As part of the F class verification, a complete assembled phase of a transformer is set on fire in a test chamber equipped with air inlet and chimney. Temperatures in the chimney above the allowed limits will lead to unsuccessful results. In the last five years, many (> 40) dry-type distribution transformers (power range up to 3,5 MVA) were tested for verification of one or more of these classes. Often (> 50%) the requirements as per IEC 60076-11 and/or clients specifications could not be met. In some cases design changes and retests were required to meet the requirements, in other cases test programs were stopped due to failure of the object. This paper will explain the importance of the above mentioned tests. Also explanation will be given on the testing methods and procedures required for reliable and reproducible tests, results and conclusions. Climatic, environmental and fire behaviour tests are important special tests proving utilities and other end users of dry-type transformers the quality of the product.",,,,, ,  2014 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC),IEC standards;Fires;Laboratories;Power transformers;Inspection;Transformer;Dry-type;Special test;Climatic class;Environmental class;Fire Behaviour class Introduction,out_of_scope,
2966,"**Title**Dielectric Design Analysis of Transformers filled with FR3 Oil and Mineral Oil

**Abstract**The power industry is increasingly focused on developing environmentally safe equipment. In particular, the transformer industry faces challenges related to insulating liquid (mineral oil), which exhibits low biodegradability, toxic contamination, and high flammability. To address these concerns, the adoption of FR3 liquid technology offers a promising solution for both retrofitting existing transformers and designing new ones. The relative life of any transformer is directly proportional to its insulating system. Therefore, when considering a change in its insulating fluid, a thorough analysis is required to validate the dielectric design of the Transformer. This paper gives a brief description about comparison of the dielectric design performance of power transformers, both with mineral oil and FR3 oil. In this, we have examined transient voltage behavior between winding turn-turn, disk-disk and transfer surge voltage during lighting or switching conditions at respective BIL levels. Additionally, electrical field stress analysis of active part is also explored by considering designed insulation level (DIL) of the transformer. The stress and strength plots within solid insulation and liquid insulation are discussed in detail. In conclusion, this study highlights key considerations for FR3-filled transformer dielectric design. We have also presented advantages and disadvantages of FR3 fluid compared to traditional mineral oil concerning its dielectric properties.","Parmar, Digpalsinh, Gajjala, Sreelatha, Janakiraman, Balaji, Sarkar, Amitabh",,,Dielectric Design Analysis of Transformers filled with FR3 Oil and Mineral Oil,,,10.1109/CONECCT62155.2024.10677309 , ,,"The power industry is increasingly focused on developing environmentally safe equipment. In particular, the transformer industry faces challenges related to insulating liquid (mineral oil), which exhibits low biodegradability, toxic contamination, and high flammability. To address these concerns, the adoption of FR3 liquid technology offers a promising solution for both retrofitting existing transformers and designing new ones. The relative life of any transformer is directly proportional to its insulating system. Therefore, when considering a change in its insulating fluid, a thorough analysis is required to validate the dielectric design of the Transformer. This paper gives a brief description about comparison of the dielectric design performance of power transformers, both with mineral oil and FR3 oil. In this, we have examined transient voltage behavior between winding turn-turn, disk-disk and transfer surge voltage during lighting or switching conditions at respective BIL levels. Additionally, electrical field stress analysis of active part is also explored by considering designed insulation level (DIL) of the transformer. The stress and strength plots within solid insulation and liquid insulation are discussed in detail. In conclusion, this study highlights key considerations for FR3-filled transformer dielectric design. We have also presented advantages and disadvantages of FR3 fluid compared to traditional mineral oil concerning its dielectric properties.",,,,, ,"  2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)",Oils;Windings;Voltage;Oil insulation;Minerals;Dielectrics;Dielectric liquids;Power Transformer;FR3 Fluid;Mineral oil (MO);Insulating Liquid;Solid Insulation;FEM,out_of_scope,
2967,"**Title**Exploring BERT and Bi-LSTM for Toxic Comment Classification: A Comparative Analysis

**Abstract**This study analyzes on the classification of toxic comments in online conversations using advanced natural language processing (NLP) techniques. Leveraging advanced natural language processing (NLP) techniques and classification models, including BERT and Bi-LSTM models to classify comments into 6 types of toxicity: toxic, obscene, threat, insult, severe toxic and identity hate. The study achieves competitive performance. Specifically, fine-tuning BERT using TensorFlow and Hugging Face Transformers resulted in an AUC ROC rate of $98.23 \%$, while LSTM yielded a binary accuracy of $96.07 \%$. The results demonstrate the effectiveness of using transformer-based models like BERT for toxicity classification in text data. The study discusses the methodology, model architectures, and evaluation metrics, highlighting the effectiveness of each approach in identifying and classifying toxic language. Additionally, the paper discusses the implementation of a userfriendly interface for real-time toxic comment detection, leveraging the trained models for efficient moderation of online content.","Tarun, V G, Sivasakthivel, Ramkumar, Ramar, Gobinath, Rajagopal, Manikandan, Sivaraman, G.",,,Exploring BERT and Bi-LSTM for Toxic Comment Classification: A Comparative Analysis,,,10.1109/ICDSIS61070.2024.10594466 , ,,"This study analyzes on the classification of toxic comments in online conversations using advanced natural language processing (NLP) techniques. Leveraging advanced natural language processing (NLP) techniques and classification models, including BERT and Bi-LSTM models to classify comments into 6 types of toxicity: toxic, obscene, threat, insult, severe toxic and identity hate. The study achieves competitive performance. Specifically, fine-tuning BERT using TensorFlow and Hugging Face Transformers resulted in an AUC ROC rate of $98.23 \%$, while LSTM yielded a binary accuracy of $96.07 \%$. The results demonstrate the effectiveness of using transformer-based models like BERT for toxicity classification in text data. The study discusses the methodology, model architectures, and evaluation metrics, highlighting the effectiveness of each approach in identifying and classifying toxic language. Additionally, the paper discusses the implementation of a userfriendly interface for real-time toxic comment detection, leveraging the trained models for efficient moderation of online content.",,,,, ,  2024 Second International Conference on Data Science and Information System (ICDSIS),Accuracy;Toxicology;Computational modeling;Oral communication;Transformers;Natural language processing;Real-time systems;toxicity;BERT;bi-LSTM;natural language processing,detection,
2968,"**Title**Automated Toxic Chat Synthesis, Reporting and Removing the Chat in Telegram Social Media Using Natural Language Processing Techniques

**Abstract**This project seeks to address the pervasive challenge of toxic communication in the context of Telegram social media by deploying various Natural Language Processing (NLP) techniques. The classification framework developed for this endeavor is capable of discerning various forms of toxicity, including toxic, severe toxic, identity hate, obscene, threat, and insult. Beyond classification, the system incorporates a two-fold approach involving automated reporting and subsequent removal of identified toxic content. This comprehensive strategy not only empowers users to actively contribute to a healthier online discourse but also leverages the capabilities of NLP to enhance the overall user experience within the Telegram platform. The models employed for training include logistic regression, k-nearest neighbours (KNN), random forest, multinomial naive Bayes and Bidirectional Encoder Representations from Transformers (BERT). By tackling toxic communication at its root, this project aspires to foster an inclusive and respectful digital community, where users can engage in meaningful discussions without the pervasive influence of harmful language. The integration of these mechanisms into Telegram aims to create a seamless and efficient process for identifying, reporting, and removing toxic content, thereby promoting a more positive online environment.","A B, Abhijith, Prithvi, P.",,,"Automated Toxic Chat Synthesis, Reporting and Removing the Chat in Telegram Social Media Using Natural Language Processing Techniques",,,10.1109/ICAECT60202.2024.10469467 , ,,"This project seeks to address the pervasive challenge of toxic communication in the context of Telegram social media by deploying various Natural Language Processing (NLP) techniques. The classification framework developed for this endeavor is capable of discerning various forms of toxicity, including toxic, severe toxic, identity hate, obscene, threat, and insult. Beyond classification, the system incorporates a two-fold approach involving automated reporting and subsequent removal of identified toxic content. This comprehensive strategy not only empowers users to actively contribute to a healthier online discourse but also leverages the capabilities of NLP to enhance the overall user experience within the Telegram platform. The models employed for training include logistic regression, k-nearest neighbours (KNN), random forest, multinomial naive Bayes and Bidirectional Encoder Representations from Transformers (BERT). By tackling toxic communication at its root, this project aspires to foster an inclusive and respectful digital community, where users can engage in meaningful discussions without the pervasive influence of harmful language. The integration of these mechanisms into Telegram aims to create a seamless and efficient process for identifying, reporting, and removing toxic content, thereby promoting a more positive online environment.",,,,, ,"  2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)",Training;Logistic regression;Social networking (online);Surveillance;Bidirectional control;Transformers;Natural language processing;Telegram Social Media;Natural Language Processing;Toxic Comment;Logistic Regression;k-nearest neighbours;random forest;multinomial naïve Bayes;BERT,detection,
2969,"**Title**DCE-former: A Transformer-Based Model with Mutual Information and Frequency-Based Loss Functions for Early and Late Response Prediction in Prostate DCE-MRI

**Abstract**Dynamic Contrast Enhanced Magnetic Resonance Imaging aids in the detection and assessment of tumor aggressiveness by using a Gadolinium-based contrast agent (GBCA). However, GBCA is known to have potential toxic effects. This risk can be avoided if we obtain DCE-MRI images without using GBCA. We propose, DCE-former, a transformer-based neural network to generate early and late response prostate DCE-MRI images from non-contrast multimodal inputs (T2 weighted, Apparent Diffusion Coefficient, and T1 pre-contrast MRI). We also introduce (i) a mutual information loss function to capture the complementary information about contrast uptake, and (ii) a frequency-based loss function in the pixel and Fourier space to learn local and global hyper-intensity patterns in DCE-MRI. Extensive experiments show that DCE-former outperforms other methods with improvement margins of +1.39 dB and +1.19 db in PSNR, +0.068 and +0.055 in SSIM, and -0.012 and -0.013 in Mean Absolute Error for early and late response DCE-MRI, respectively.","S, Sadhana, Ramanarayanan, Sriprabha, Sarkar, Arunima, Ram, Keerthi, Gayathri, Matcha Naga, Joel, Suresh, Agarwal, Harsh, Venkatesan, Ramesh, Sivaprakasam, Mohanasankar",,,DCE-former: A Transformer-Based Model with Mutual Information and Frequency-Based Loss Functions for Early and Late Response Prediction in Prostate DCE-MRI,,,10.1109/ISBI56570.2024.10635589 , ,,"Dynamic Contrast Enhanced Magnetic Resonance Imaging aids in the detection and assessment of tumor aggressiveness by using a Gadolinium-based contrast agent (GBCA). However, GBCA is known to have potential toxic effects. This risk can be avoided if we obtain DCE-MRI images without using GBCA. We propose, DCE-former, a transformer-based neural network to generate early and late response prostate DCE-MRI images from non-contrast multimodal inputs (T2 weighted, Apparent Diffusion Coefficient, and T1 pre-contrast MRI). We also introduce (i) a mutual information loss function to capture the complementary information about contrast uptake, and (ii) a frequency-based loss function in the pixel and Fourier space to learn local and global hyper-intensity patterns in DCE-MRI. Extensive experiments show that DCE-former outperforms other methods with improvement margins of +1.39 dB and +1.19 db in PSNR, +0.068 and +0.055 in SSIM, and -0.012 and -0.013 in Mean Absolute Error for early and late response DCE-MRI, respectively.",,,,, ,  2024 IEEE International Symposium on Biomedical Imaging (ISBI),Frequency synthesizers;Magnetic resonance imaging;Neural networks;Predictive models;Transformers;Generative adversarial networks;Physiology;DCE-MRI;transformer;Mutual Information;frequency loss;contrast-enhancing patterns,out_of_scope,
2970,"**Title**Sentiment Analysis Multi-Label of Toxic Comments using BERT-BiLSTM Methods

**Abstract**The number of individuals accessing the Internet rises steadily each year in Indonesia. One of the reasons behind this trend is the growing popularity of online platforms like Twitter, where people can freely share their thoughts and ideas. However, it is crucial to recognize that social media can occasionally serve as a breeding ground for negative behavior, such as the spread of toxic opinions. Additionally, more information will be collected as more people become active and share their views. Therefore, a technique capable of handling this textual data comprehensively, like classification, is needed. Simple categorization methods could be more effective since they split comments into positive and negative groups. Thus, to overcome such problems, multilevel classification assigns multiple labels to a single instance, allowing its categorization into different categories inside a single statement. This research uses a combination of BERT and BiLSTM methods, whereas BERT is used to obtain word vector values and will then be used as input in the BiLSTM model to perform multi-label classification tasks. This study uses two types of word vectors, the summation of the last four hidden layers and the final hidden layer of BERT, to create a better comparison model. The study achieved an accuracy of 0.889, precision of 0.925, recall of 0.917, and an F1 score of 0.91 for the model that used the last four hidden layers of BERT as word vectors","Putri, Syarifah Kemala, Amalia, Amalia, Abidin, Taufik Fuadi",,,Sentiment Analysis Multi-Label of Toxic Comments using BERT-BiLSTM Methods,,,10.1109/ICELTICs62730.2024.10776338 , ,,"The number of individuals accessing the Internet rises steadily each year in Indonesia. One of the reasons behind this trend is the growing popularity of online platforms like Twitter, where people can freely share their thoughts and ideas. However, it is crucial to recognize that social media can occasionally serve as a breeding ground for negative behavior, such as the spread of toxic opinions. Additionally, more information will be collected as more people become active and share their views. Therefore, a technique capable of handling this textual data comprehensively, like classification, is needed. Simple categorization methods could be more effective since they split comments into positive and negative groups. Thus, to overcome such problems, multilevel classification assigns multiple labels to a single instance, allowing its categorization into different categories inside a single statement. This research uses a combination of BERT and BiLSTM methods, whereas BERT is used to obtain word vector values and will then be used as input in the BiLSTM model to perform multi-label classification tasks. This study uses two types of word vectors, the summation of the last four hidden layers and the final hidden layer of BERT, to create a better comparison model. The study achieved an accuracy of 0.889, precision of 0.925, recall of 0.917, and an F1 score of 0.91 for the model that used the last four hidden layers of BERT as word vectors",,,,, ,  2024 International Conference on Electrical Engineering and Informatics (ICELTICs),Electrical engineering;Sentiment analysis;Social networking (online);Semantics;Blogs;Market research;Vectors;Encoding;Internet;Informatics;BiLSTM;BERT;Multi-label;Sentiment analysis,detection,
2971,"**Title**Identifying and Analyzing Toxic Behavior in Ecommerce Industry through Reddit Discussions Using BERT and HateBERT

**Abstract**This study begins by looking at how toxic behaviour in video games is talked about and identified. We set up a clear idea of what “toxic behaviour” means and suggested ways to figure out when it’s happening. To test these ideas, we scrape a huge collection of posts from Reddit where people talk about games. We cleaned up the data—making sure it was all good for checking. We used Bidirectional Encoder Representations from Transformers (BERT) to look at toxic behaviour. We also used HateBERT to compare how well it works at spotting toxic stuff. To make sure our models were doing a good job, we looked at over 5500 posts and decided if they were toxic or not. This helped us see if the models were right or wrong. We also used measures—to compare how much toxic stuff is in Reddit—especially for games. This helped us understand how common and different toxic behaviour is in different places.","Kumar, Anoop, Soni, Arpita, Arora, Rajeev, Panwar, Dheerendra",,,Identifying and Analyzing Toxic Behavior in Ecommerce Industry through Reddit Discussions Using BERT and HateBERT,,,10.1109/SPARC61891.2024.10829097 , ,,"This study begins by looking at how toxic behaviour in video games is talked about and identified. We set up a clear idea of what “toxic behaviour” means and suggested ways to figure out when it’s happening. To test these ideas, we scrape a huge collection of posts from Reddit where people talk about games. We cleaned up the data—making sure it was all good for checking. We used Bidirectional Encoder Representations from Transformers (BERT) to look at toxic behaviour. We also used HateBERT to compare how well it works at spotting toxic stuff. To make sure our models were doing a good job, we looked at over 5500 posts and decided if they were toxic or not. This helped us see if the models were right or wrong. We also used measures—to compare how much toxic stuff is in Reddit—especially for games. This helped us understand how common and different toxic behaviour is in different places.",,,,, ,  2024 International Conference on Signal Processing and Advance Research in Computing (SPARC),Industries;Video games;Social networking (online);Biological system modeling;Games;Bidirectional control;Signal processing;Transformers;Encoding;Electronic commerce;BERT;Games;HateBERT;Mean Behavior;Reddit,detection,
2972,"**Title**Detecting toxic comments from highly skewed social media data

**Abstract**A user’s online social media data, to a considerable extent, provides insight into the user’s activity. Screening user-generated data for negative content has a wide range of applications, like background checks of an employee and spotting of terror elements. Researchers have focused on identifying toxic text in social media by exploiting deep-learning models in conjunction with pre-trained language models. However, the availability of labelled toxic text is limited. In this work, we apply data augmentation techniques to address the problem of imbalanced training data. The augmented labelled data is used to fine-tune an ensemble. The ensemble consists of one linear classifier and three sequence classifiers, Bi-RNN (Bi-directional Recurrent Neural Networks), Bi-GRU (Bi-directional Gated Recurrent Unit), and Bi-LSTM (Bi-directional Long-Short Term Memory). We use BERT (Bi-directional Encoder Representations from Transformers) as our pre-trained language model. We also experiment with various text preprocessing techniques on the training data and how it affects classification performance. We compare our best-identified model with other toxic text detection frameworks available in the literature.","Datta, Abhradeep, Kumar, B Monish, Singh Sairam, Ashok",,,Detecting toxic comments from highly skewed social media data,,,10.1109/ANTS59832.2023.10469000 , ,,"A user’s online social media data, to a considerable extent, provides insight into the user’s activity. Screening user-generated data for negative content has a wide range of applications, like background checks of an employee and spotting of terror elements. Researchers have focused on identifying toxic text in social media by exploiting deep-learning models in conjunction with pre-trained language models. However, the availability of labelled toxic text is limited. In this work, we apply data augmentation techniques to address the problem of imbalanced training data. The augmented labelled data is used to fine-tune an ensemble. The ensemble consists of one linear classifier and three sequence classifiers, Bi-RNN (Bi-directional Recurrent Neural Networks), Bi-GRU (Bi-directional Gated Recurrent Unit), and Bi-LSTM (Bi-directional Long-Short Term Memory). We use BERT (Bi-directional Encoder Representations from Transformers) as our pre-trained language model. We also experiment with various text preprocessing techniques on the training data and how it affects classification performance. We compare our best-identified model with other toxic text detection frameworks available in the literature.",,,,, ,  2023 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS),Recurrent neural networks;Social networking (online);Computational modeling;Text categorization;Training data;Text detection;Bidirectional control;toxic text detection;sentiment analysis;deep learning;social media;BERT,detection,
2973,"**Title**All Solid State Pulsed Power System for Water Discharge

**Abstract**Pulsed power has been used to produce non-thermal plasmas in gases that generate a high electric field at the tip of streamer discharges, where high energy electrons, free radicals, and ozone are produced. Recently, all solid state pulsed power generators, which are operated with high repetition rate, long lifetime and high reliability, have been developed for industrial applications, such as high repetition rate pulsed gas lasers, high energy density plasma (EUV sources) and water discharges. We have studied and developed repetitive all solid state pulsed power system for applications to water discharge. The developed system consists of a photovoltaic generator, a Pb battery, an inverter, a controller, a command charger, a high-speed thyristor, a magnetic pulse compression circuit and a pulse transformer, and has mobility. This system can generate an output peak voltage of over 100 kV with voltage rise time of 200 ns. In this work, large volume streamer like discharges in water were produced by the developed system and this discharge plasma used to treat water with point-to-plane simple electrodes.","Sakugawa, T., Yamaguchi, T., Yamamoto, K., Kiyan, T., Namihira, T., Katsuki, S., Akiyama, H.",,,All Solid State Pulsed Power System for Water Discharge,,,10.1109/PPC.2005.300484 , ,,"Pulsed power has been used to produce non-thermal plasmas in gases that generate a high electric field at the tip of streamer discharges, where high energy electrons, free radicals, and ozone are produced. Recently, all solid state pulsed power generators, which are operated with high repetition rate, long lifetime and high reliability, have been developed for industrial applications, such as high repetition rate pulsed gas lasers, high energy density plasma (EUV sources) and water discharges. We have studied and developed repetitive all solid state pulsed power system for applications to water discharge. The developed system consists of a photovoltaic generator, a Pb battery, an inverter, a controller, a command charger, a high-speed thyristor, a magnetic pulse compression circuit and a pulse transformer, and has mobility. This system can generate an output peak voltage of over 100 kV with voltage rise time of 200 ns. In this work, large volume streamer like discharges in water were produced by the developed system and this discharge plasma used to treat water with point-to-plane simple electrodes.",,,,, ,  2005 IEEE Pulsed Power Conference,Pulse power systems;Solid state circuits;Optical pulse generation;Fault location;Plasma applications;Power generation;Power system reliability;Pulse transformers;Photovoltaic systems;Gases,out_of_scope,
2974,"**Title**Toxic Chat Synthesis, Reporting and Removing in Social Media using Hybrid Deep Learning Model

**Abstract**Following the COVID-19 epidemic, social media usage has increased dramatically among a wide range of users, from young people to the elderly. These platforms are essential venues for people to share ideas, demonstrate their abilities, and voice their opinions. But in addition to these advantages, there has been a noticeable rise in the spread of offensive and vulgar information. This is especially concerning because there are groups who deliberately make insulting remarks that target women, children, and the elderly in an effort to stifle peaceful speech. Even though there are reporting procedures in place, the lengthy process of filing complaints deters many users from doing so. Our research provides an automatic method made to identify, report, and delete offensive communications from the Telegram social media platform in order to address this problem. Some previous work to classify comments is already present. But it is only on English language. In this work, we are extending this to Malayalam, Manglish (Malayalam language written with English letters), Mixed (mix of Malayalam and Manglish) and English Languages. Apart from the above two, we have created a Hybrid Deep Learning model combining CNN and RNN and compared its performance with already existing models like Logistic Regression, SVM, KNN and BERT. Our project aims to create an open and courteous online community where meaningful conversations can flourish without the constant influence of offensive language by tackling toxic communication at its source. This automatic approach is a big step in the direction of making Telegram a happier and more encouraging place for users to interact online.","Prithvi, P., B, Abhijith A",,,"Toxic Chat Synthesis, Reporting and Removing in Social Media using Hybrid Deep Learning Model",,,10.1109/ICICEC62498.2024.10808410 , ,,"Following the COVID-19 epidemic, social media usage has increased dramatically among a wide range of users, from young people to the elderly. These platforms are essential venues for people to share ideas, demonstrate their abilities, and voice their opinions. But in addition to these advantages, there has been a noticeable rise in the spread of offensive and vulgar information. This is especially concerning because there are groups who deliberately make insulting remarks that target women, children, and the elderly in an effort to stifle peaceful speech. Even though there are reporting procedures in place, the lengthy process of filing complaints deters many users from doing so. Our research provides an automatic method made to identify, report, and delete offensive communications from the Telegram social media platform in order to address this problem. Some previous work to classify comments is already present. But it is only on English language. In this work, we are extending this to Malayalam, Manglish (Malayalam language written with English letters), Mixed (mix of Malayalam and Manglish) and English Languages. Apart from the above two, we have created a Hybrid Deep Learning model combining CNN and RNN and compared its performance with already existing models like Logistic Regression, SVM, KNN and BERT. Our project aims to create an open and courteous online community where meaningful conversations can flourish without the constant influence of offensive language by tackling toxic communication at its source. This automatic approach is a big step in the direction of making Telegram a happier and more encouraging place for users to interact online.",,,,, ,"  2024 First International Conference on Innovations in Communications, Electrical and Computer Engineering (ICICEC)",Deep learning;Support vector machines;Technological innovation;Social networking (online);Computational modeling;Surveillance;Semantics;Oral communication;Nearest neighbor methods;Older adults;Telegram Social Media;Malayalam;Manglish;Hybrid Model;Natural Language Processing;Toxic Comment;Logistic Regression;SVM;KNN;CNN;RNN;BERT,detection,
2975,"**Title**Development of Energy Autonomous Wearable Sensor Node for Oxygen Monitoring in Underground Tunnels

**Abstract**Underground tunnels contain toxic, hazardous gases or lack oxygen. Therefore, providing the safety of personnel working in underground tunnels by monitoring oxygen, combustible or toxic gases is important. Wearable sensor networks are used in various applications such as oxygen monitoring. Some wearable sensor networks for gas monitoring are powered by batteries. Given the finite lifetime of batteries and the long term stay of underground personnel in these places, e.g. as a result of incidents, having a wearable sensor node with a stable power supply is crucial to conducting oxygen monitoring and notifying the emergency conditions. In order to provide a battery-less operation of the wearable sensor node, one approach is to use ambient energy sources. Considering the fact that the human body can survive only a few minutes without oxygen, the goal of our work is to investigate whether the power generated as a result of temperature difference between the body and ambient air is sufficient to power a sensor node for conducting oxygen detection every 20 seconds. Therefore, we present the development of a wearable sensor node for oxygen detection. The platform consists of a thermoelectric generator (TEG) converter, a sensing circuit for an electrochemical gas sensor and a power management circuit. Our experimental results with our platform indicate that a temperature difference of 6°C between the body and the ambient air and storing the harvested energy in a capacitor ensure the autonomous operation of the wearable sensor node for measurements and alarm actuation conducted every 15 seconds. The period between the measurements could even become less than 15 seconds in underground tunnels as the temperature difference increases.","Akbari, Saba, Voigt, Thiemo, Venkata Subramanian, Rishi Sudhan, Song, Weining",,,Development of Energy Autonomous Wearable Sensor Node for Oxygen Monitoring in Underground Tunnels,,,10.1109/MECO62516.2024.10577893 , ,,"Underground tunnels contain toxic, hazardous gases or lack oxygen. Therefore, providing the safety of personnel working in underground tunnels by monitoring oxygen, combustible or toxic gases is important. Wearable sensor networks are used in various applications such as oxygen monitoring. Some wearable sensor networks for gas monitoring are powered by batteries. Given the finite lifetime of batteries and the long term stay of underground personnel in these places, e.g. as a result of incidents, having a wearable sensor node with a stable power supply is crucial to conducting oxygen monitoring and notifying the emergency conditions. In order to provide a battery-less operation of the wearable sensor node, one approach is to use ambient energy sources. Considering the fact that the human body can survive only a few minutes without oxygen, the goal of our work is to investigate whether the power generated as a result of temperature difference between the body and ambient air is sufficient to power a sensor node for conducting oxygen detection every 20 seconds. Therefore, we present the development of a wearable sensor node for oxygen detection. The platform consists of a thermoelectric generator (TEG) converter, a sensing circuit for an electrochemical gas sensor and a power management circuit. Our experimental results with our platform indicate that a temperature difference of 6°C between the body and the ambient air and storing the harvested energy in a capacitor ensure the autonomous operation of the wearable sensor node for measurements and alarm actuation conducted every 15 seconds. The period between the measurements could even become less than 15 seconds in underground tunnels as the temperature difference increases.",,,,, ,  2024 13th Mediterranean Conference on Embedded Computing (MECO),Temperature measurement;Temperature sensors;Power system management;Capacitors;Batteries;Safety;Personnel;Wearable sensor node;oxygen monitoring;energy harvesting;underground tunnels,out_of_scope,
2976,"**Title**Monitoring AI-Based Processing for Predicting Poisonous Gas Emissions in Smart Cities Using Novel Temporal Dynamics Prediction Model

**Abstract**Smart cities, driven by technological advancements, face challenges related to environmental pollution, including poisonous gas emissions. Existing systems often struggle to efficiently monitor and predict these emissions, leading to limitations in accurately assessing and mitigating air quality issues. This study proposes a groundbreaking solution, the Novel Temporal Dynamics Prediction (NTDP) model, designed to overcome the limitations of current systems. By harnessing the NTDP model’s innovative approach, smart cities can enhance their capability to analyze and forecast poisonous gas emissions, thereby improving the effectiveness of environmental management. The NTDP model offers a promising avenue for the future, revolutionizing the way smart cities address and mitigate the impact of toxic pollutants on air quality. The NTDP model achieved an accuracy of 99.1%, sensitivity of 98.9% and RMSE training 1.6 and testing 1.54 ug/m3. The results affirm the robustness and effectiveness of our optimized implementation, positioning it as a standout solution in disease prediction compared to commonly used machine learning techniques.","Jaisharma, K, Deepa, N., Devi, T",,,Monitoring AI-Based Processing for Predicting Poisonous Gas Emissions in Smart Cities Using Novel Temporal Dynamics Prediction Model,,,10.1109/ICDSIS61070.2024.10594076 , ,,"Smart cities, driven by technological advancements, face challenges related to environmental pollution, including poisonous gas emissions. Existing systems often struggle to efficiently monitor and predict these emissions, leading to limitations in accurately assessing and mitigating air quality issues. This study proposes a groundbreaking solution, the Novel Temporal Dynamics Prediction (NTDP) model, designed to overcome the limitations of current systems. By harnessing the NTDP model’s innovative approach, smart cities can enhance their capability to analyze and forecast poisonous gas emissions, thereby improving the effectiveness of environmental management. The NTDP model offers a promising avenue for the future, revolutionizing the way smart cities address and mitigate the impact of toxic pollutants on air quality. The NTDP model achieved an accuracy of 99.1%, sensitivity of 98.9% and RMSE training 1.6 and testing 1.54 ug/m3. The results affirm the robustness and effectiveness of our optimized implementation, positioning it as a standout solution in disease prediction compared to commonly used machine learning techniques.",,,,, ,  2024 Second International Conference on Data Science and Information System (ICDSIS),Training;Accuracy;Sensitivity;Pollution;Smart cities;Atmospheric modeling;Machine learning;air quality prediction;AQI score;BiLSTM;environment gas;poisonous prediction;smart cities;time-series;toxic,out_of_scope,
2977,"**Title**New solutions for bird collision and electrocution outage problems

**Abstract**The electrocution of raptors is a global hazard of overhead distribution construction, especially in treeless areas with abundant prey where poles make attractive perches. Bird collisions with power lines can also be problematic where lines span areas used by waterfowl or soaring, slow-flying bird species. Electrocution and collision hazards can be greatly reduced through modifications to existing design standards. These standards include the use of cover-up materials, perch deterrents and line markers. Research is also under way, to develop a Bird Strike Indicator (BSI) and Bird Activity Monitoring (BAM) to remotely detect and record collisions and electrocutions. These tools will allow scientists and engineers to better understand where problems are occurring and to determine if existing mitigating measures are working. Mitigating measures should be encouraged globally because they will not only minimize electrocutions, but will also minimize power outages. Reducing outages may save utilities money in the long term and will certainly improve system reliability.","Harness, R.E., Carlton, R.",,,New solutions for bird collision and electrocution outage problems,,,10.1109/PESW.2001.917060 , ,,"The electrocution of raptors is a global hazard of overhead distribution construction, especially in treeless areas with abundant prey where poles make attractive perches. Bird collisions with power lines can also be problematic where lines span areas used by waterfowl or soaring, slow-flying bird species. Electrocution and collision hazards can be greatly reduced through modifications to existing design standards. These standards include the use of cover-up materials, perch deterrents and line markers. Research is also under way, to develop a Bird Strike Indicator (BSI) and Bird Activity Monitoring (BAM) to remotely detect and record collisions and electrocutions. These tools will allow scientists and engineers to better understand where problems are occurring and to determine if existing mitigating measures are working. Mitigating measures should be encouraged globally because they will not only minimize electrocutions, but will also minimize power outages. Reducing outages may save utilities money in the long term and will certainly improve system reliability.",,,,, ,  2001 IEEE Power Engineering Society Winter Meeting. Conference Proceedings (Cat. No.01CH37194),Birds;Conductors;Hazards;Protection;Collision mitigation;Wind;Broadcasting;Automation;Environmental management;Marine animals,out_of_scope,
2978,"**Title**Development of a wireless environmental sensor system and MEMS-based RF circuit components

**Abstract**This paper reports a miniaturized environmental sensor system integrated with RF communication module. This system has been developed for on-site monitoring of water pollution by heavy metal ions. The system is composed of an electrochemical sensor, a custom potentiostat module, and an RF module for wireless communication. Also, the authors presented monolithic MEMS VCOs integrated with high-Q MEMS inductors and MEMS transmission lines for low-power wireless transceiver applications. Phase noise of the proposed MEMS VCOs has been improved by more than 7 dBc/Hz compared with their CMOS counterparts at 1MHz offset from center frequencies of 5GHz and 13 GHz, respectively.","Yoon, Euisik, Yun, Kwang-Seok",,,Development of a wireless environmental sensor system and MEMS-based RF circuit components,,,10.1109/SENSOR.2005.1497489 , ,,"This paper reports a miniaturized environmental sensor system integrated with RF communication module. This system has been developed for on-site monitoring of water pollution by heavy metal ions. The system is composed of an electrochemical sensor, a custom potentiostat module, and an RF module for wireless communication. Also, the authors presented monolithic MEMS VCOs integrated with high-Q MEMS inductors and MEMS transmission lines for low-power wireless transceiver applications. Phase noise of the proposed MEMS VCOs has been improved by more than 7 dBc/Hz compared with their CMOS counterparts at 1MHz offset from center frequencies of 5GHz and 13 GHz, respectively.",,,,, ,"  The 13th International Conference on Solid-State Sensors, Actuators and Microsystems, 2005. Digest of Technical Papers. TRANSDUCERS '05.",Wireless sensor networks;Sensor systems;Radio frequency;Circuits;Micromechanical devices;Monitoring;Water pollution;Wireless communication;Inductors;Transmission lines,out_of_scope,
2979,"**Title**Function and use of arc fault protection systems in low-voltage switchgear installations

**Abstract**The thermal risk for electrotechnical switchgear installations resulting from arc faults is considered and assessed based on the ""Guideline for the selection of personal protective equipment when exposed to the thermal effects of an electric fault arc"" published by the ISSA (International Social Security Association ). In this context, suitable ""personal protective equipment"" (PPE) must be worn to protect workers from second-degree burns. However, the protective effect of this PPE is limited depending on the arc fault energy to be expected. Technical measures can also be implemented to additionally protect workers during live working. Arc fault protection systems are capable of reducing the arc energy to an acceptable level by limiting the persistence of the arc fault to some milliseconds. This paper describes the structure, mode of operation and implementation of these protection systems.","Ziehmer, Rainer",,,Function and use of arc fault protection systems in low-voltage switchgear installations,,,10.1109/ICOLIM.2014.6934336 , ,,"The thermal risk for electrotechnical switchgear installations resulting from arc faults is considered and assessed based on the ""Guideline for the selection of personal protective equipment when exposed to the thermal effects of an electric fault arc"" published by the ISSA (International Social Security Association ). In this context, suitable ""personal protective equipment"" (PPE) must be worn to protect workers from second-degree burns. However, the protective effect of this PPE is limited depending on the arc fault energy to be expected. Technical measures can also be implemented to additionally protect workers during live working. Arc fault protection systems are capable of reducing the arc energy to an acceptable level by limiting the persistence of the arc fault to some milliseconds. This paper describes the structure, mode of operation and implementation of these protection systems.",,,,, ,  2014 11th International Conference on Live Maintenance (ICOLIM),Indexes;Standards;arc fault protection systems;electric fault arc,out_of_scope,
2980,"**Title**Masked Face Recognition Method with Dual-branch Attention

**Abstract**Air pollution and the presence of toxic gases in daily life pose a significant health concern, leading people to wear masks for protection. However, wearing masks obscures important facial features, consequently diminishing the performance of existing recognition methods. To tackle this issue, this study introduces a dual-branch attention-based method for recognizing masked faces. The method incorporates ECSA(Efficient Channel Spatial Attention) and N-UPA(New Upper Part Attention) modules and employs a dual-branch training structure. Each convolution block incorporates ECSA modules to improve the network’s ability to extract overall facial features. Additionally, a branch network comprising the N-UPA module is introduced to focus on extracting features from the eye area, thereby enhancing the accuracy of mask face recognition. The effectiveness of the proposed method has been validated using a real dataset. Experimental results showcase its exceptional generalization capability. Moreover, in comparison to advanced methods, the proposed approach markedly improves the performance of recognizing faces under mask occlusion.","Zhao, Jiangbin, Wang, Wei",,,Masked Face Recognition Method with Dual-branch Attention,,,10.1109/ICICML60161.2023.10424907 , ,,"Air pollution and the presence of toxic gases in daily life pose a significant health concern, leading people to wear masks for protection. However, wearing masks obscures important facial features, consequently diminishing the performance of existing recognition methods. To tackle this issue, this study introduces a dual-branch attention-based method for recognizing masked faces. The method incorporates ECSA(Efficient Channel Spatial Attention) and N-UPA(New Upper Part Attention) modules and employs a dual-branch training structure. Each convolution block incorporates ECSA modules to improve the network’s ability to extract overall facial features. Additionally, a branch network comprising the N-UPA module is introduced to focus on extracting features from the eye area, thereby enhancing the accuracy of mask face recognition. The effectiveness of the proposed method has been validated using a real dataset. Experimental results showcase its exceptional generalization capability. Moreover, in comparison to advanced methods, the proposed approach markedly improves the performance of recognizing faces under mask occlusion.",,,,, ,"  2023 International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)",Training;Face recognition;Feature extraction;Air pollution;Rendering (computer graphics);Facial features;Faces;Dual-branch network;Masked face recognition;Attention mechanism;Transformer,out_of_scope,
2981,"**Title**Personal Computer Controlled Installation for Plasma Electrolytic Treatment Process Control

**Abstract**Plasma electrolytic treatment of metals is a new emerging technology that features high quality, cost effective and environmentally friendly surface engineering. The main difference between plasma electrolytic treatment and conventional electrochemical treatment are operation at high voltages in the range 100-500 V and application of low concentration water solutions of non-toxic salts. The phenomenon of plasma electrolysis is being currently researched mainly in Russia, UK and USA. However, process control issues appear to be less investigated. Moreover, the installations described in the references either lack computer control or serve phenomenon investigation, not process control. This paper describes the computer-controlled installation, which serves investigation of the plasma electrolytic treatment process control.","Parfenov, E.V., Nevyantseva, R.R., Sosnovsky, D.A.",,,Personal Computer Controlled Installation for Plasma Electrolytic Treatment Process Control,,,10.1109/SPCMTT.2005.4493187 , ,,"Plasma electrolytic treatment of metals is a new emerging technology that features high quality, cost effective and environmentally friendly surface engineering. The main difference between plasma electrolytic treatment and conventional electrochemical treatment are operation at high voltages in the range 100-500 V and application of low concentration water solutions of non-toxic salts. The phenomenon of plasma electrolysis is being currently researched mainly in Russia, UK and USA. However, process control issues appear to be less investigated. Moreover, the installations described in the references either lack computer control or serve phenomenon investigation, not process control. This paper describes the computer-controlled installation, which serves investigation of the plasma electrolytic treatment process control.",,,,, ,"  2005 11th International Scientific and Practical Conference of Students, Post-graduates and Young Scientists - Modern Technique and Technologies",Microcomputers;Process control;Plasma temperature;Kinematics;Plasma applications;Current density;Coupling circuits;Mechanical systems;Shape;Voltage,out_of_scope,
2982,"**Title**Analyzing the Performance of Machine Learning and Deep Learning Models in Detecting Cyberbullying Comments

**Abstract**With the proliferation of social media platforms, there has been a concerning escalation in cyberbullying and abusive language. Detecting such toxic comments in large volumes of user-generated data presents challenges. This research conducts a comparative analysis to evaluate the impact of natural language processing techniques on identifying cyberbullying. Using a dataset of 1,59,000 comments labelled across seven classes of toxicity, conventional machine learning and deep learning models are benchmarked across performance metrics. The study aims to quantify algorithmic capabilities to accurately classify bullying comments. The study finds that Support Vectors with a linear kernel surpass Logistic Regression in accurately identifying toxic comments. For deep learning techniques, the transformer models (BERT and Distil-BERT) deliver the highest performance among neural network architectures tested. The empirical evaluation provides insights into leveraging computational linguistics for automating the detection of online bullying at scale.","Saim, Mohammad, Rizvi, Rehma Manaal, Kashif Khan, Mohammad",,,Analyzing the Performance of Machine Learning and Deep Learning Models in Detecting Cyberbullying Comments,,,10.1109/ICRASET59632.2023.10419938 , ,,"With the proliferation of social media platforms, there has been a concerning escalation in cyberbullying and abusive language. Detecting such toxic comments in large volumes of user-generated data presents challenges. This research conducts a comparative analysis to evaluate the impact of natural language processing techniques on identifying cyberbullying. Using a dataset of 1,59,000 comments labelled across seven classes of toxicity, conventional machine learning and deep learning models are benchmarked across performance metrics. The study aims to quantify algorithmic capabilities to accurately classify bullying comments. The study finds that Support Vectors with a linear kernel surpass Logistic Regression in accurately identifying toxic comments. For deep learning techniques, the transformer models (BERT and Distil-BERT) deliver the highest performance among neural network architectures tested. The empirical evaluation provides insights into leveraging computational linguistics for automating the detection of online bullying at scale.",,,,, ,  2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET),Deep learning;Measurement;Logistic regression;Computational modeling;Cyberbullying;Transformers;Tuning;Machine Learning;Natural Language Processing;Deep Learning;Cyberbullying;Classification,detection,
2983,"**Title**Bengali Cyberbullying Detection in Social Media Using Machine Learning Algorithms

**Abstract**Social media has become more prevalent and it is now fairly easy to communicate with people online. Social network users have many options to cooperate, interact positively, and exchange information. The same system might create a toxic environment that can create an unpleasant environment for online abuse and bullies. Young adults and celebrities are vulnerable to online abuse more often. That's why cyberbullying should be identified and eliminated from social media because it may significantly lead to psychological as well as emotional suffering. By utilizing Natural Language Processing (NLP), Machine Learning (ML), as well as Deep Learning Models based on Transformers like BERT, we can identify patterns in social media texts used by bullies and create an automated method that can detect abusive texts. In this study, we proposed a reliable machine-learning model for social media cyberbullying detection in the Bengali language. We applied text preprocessing, followed by feature extraction using the TF-IDF vectorizer. Then, we applied 4 ML algorithms and 1 transformer-based pretrained BERT model and evaluated their performances by different performance metrics. Our study found that BERT worked best compared to other algorithms and achieved an accuracy of 90% and an AUC (Area under the ROC Curve) of 0.96.","Saha, Subrata, Islam, Md. Shamimul, Alam, Md. Mahbub, Rahman, Md. Motinur, Hasan Majumder, Md. Ziaul, Alam, Md. Shah, Hossain, M. Khalid",,,Bengali Cyberbullying Detection in Social Media Using Machine Learning Algorithms,,,10.1109/STI59863.2023.10464740 , ,,"Social media has become more prevalent and it is now fairly easy to communicate with people online. Social network users have many options to cooperate, interact positively, and exchange information. The same system might create a toxic environment that can create an unpleasant environment for online abuse and bullies. Young adults and celebrities are vulnerable to online abuse more often. That's why cyberbullying should be identified and eliminated from social media because it may significantly lead to psychological as well as emotional suffering. By utilizing Natural Language Processing (NLP), Machine Learning (ML), as well as Deep Learning Models based on Transformers like BERT, we can identify patterns in social media texts used by bullies and create an automated method that can detect abusive texts. In this study, we proposed a reliable machine-learning model for social media cyberbullying detection in the Bengali language. We applied text preprocessing, followed by feature extraction using the TF-IDF vectorizer. Then, we applied 4 ML algorithms and 1 transformer-based pretrained BERT model and evaluated their performances by different performance metrics. Our study found that BERT worked best compared to other algorithms and achieved an accuracy of 90% and an AUC (Area under the ROC Curve) of 0.96.",,,,, ,  2023 5th International Conference on Sustainable Technologies for Industry 5.0 (STI),Measurement;Deep learning;Machine learning algorithms;Cyberbullying;Psychology;Transformers;Feature extraction;Cyberbullying;Bangla bullying detection;Hate speech detection;NLP;Machine learning;BERT,out_but_toxicity,
2984,"**Title**A Study of Ageing and Gelling in Natural Ester Oils

**Abstract**Two natural ester-based transformer fluids derived from soybean oil and rapeseed oil were compared to their edible equivalents. Oxidative ageing was performed in the presence of Kraft paper at 130 °C and some samples contained copper. It was found that both edible oils, particularly soybean oil, showed increased acidity and viscosity after ageing in the presence of copper. Further tests showed that both butyl hydroxytoluene (BHT), which is a common inhibitor for mineral oil but is moderately toxic, and Irganox 1010, which is non-toxic, successfully mitigated the adverse effects of oxidation in edible soybean oil. The study highlights some of the detrimental effects of oxidation in natural ester oils and shows that Irganox 1010 provides a non-toxic alternative to BHT for stabilizing ester oils.","Hosier, Ian L., Andritsch, Thomas, Lewin, Paul L., Wilson, Gordon",,,A Study of Ageing and Gelling in Natural Ester Oils,,,10.1109/ICD59037.2024.10613148 , ,,"Two natural ester-based transformer fluids derived from soybean oil and rapeseed oil were compared to their edible equivalents. Oxidative ageing was performed in the presence of Kraft paper at 130 °C and some samples contained copper. It was found that both edible oils, particularly soybean oil, showed increased acidity and viscosity after ageing in the presence of copper. Further tests showed that both butyl hydroxytoluene (BHT), which is a common inhibitor for mineral oil but is moderately toxic, and Irganox 1010, which is non-toxic, successfully mitigated the adverse effects of oxidation in edible soybean oil. The study highlights some of the detrimental effects of oxidation in natural ester oils and shows that Irganox 1010 provides a non-toxic alternative to BHT for stabilizing ester oils.",,,,, ,  2024 IEEE 5th International Conference on Dielectrics (ICD),Viscosity;Optical losses;Spectroscopy;Oils;Aging;Oil insulation;Transformers;Ester oil;Ageing;Gelling;Antioxidants,out_of_scope,
2985,"**Title**Multi-Objective Evolution for Automated Chemistry

**Abstract**A fundamental problem in chemical product design is how to suitably identify chemical compounds that optimise multiple properties for a given application whilst satisfying relevant constraints. Current product synthesis generally uses trial-and-error experimentation, requiring lengthy and expensive research and development efforts. This paper introduces a novel computational chemistry approach for product design combining geometric deep learning for inference of property values and evolutionary multi-objective optimisation for identification of products of interest. Preliminary empirical results indicate that the proposed approach can be used to optimise product design considering multiple objectives and constraints given incomplete molecular attribute information.","Aslan, Bilal, Correa da Silva, Flavio S, Nitschke, Geoff",,,Multi-Objective Evolution for Automated Chemistry,,,10.1109/SSCI52147.2023.10372035 , ,,"A fundamental problem in chemical product design is how to suitably identify chemical compounds that optimise multiple properties for a given application whilst satisfying relevant constraints. Current product synthesis generally uses trial-and-error experimentation, requiring lengthy and expensive research and development efforts. This paper introduces a novel computational chemistry approach for product design combining geometric deep learning for inference of property values and evolutionary multi-objective optimisation for identification of products of interest. Preliminary empirical results indicate that the proposed approach can be used to optimise product design considering multiple objectives and constraints given incomplete molecular attribute information.",,,,, ,  2023 IEEE Symposium Series on Computational Intelligence (SSCI),Deep learning;Chemical products;Product design;Chemical compounds;Research and development;Optimization;Computational intelligence;Evolutionary Multi-Objective Optimisation;Computational Chemistry;Geometric Deep Learning,out_of_scope,
2986,"**Title**Studying the Novel Interaction of Carbon Dots with Aged Mineral Oil Through Photoluminescence Emission

**Abstract**Carbon dots have covered a wide range of applications recently since they are biocompatible, non-toxic, and created in a low-cost hydrothermal process. Their size affects their photoluminescence properties which are determined by the specified conditions in the synthesis process. Photoluminescence spectroscopy is far less used than ultraviolet visible spectroscopy in the literature concerning condition assessment of power transformer insulating oil. This paper focuses on the development of a compatible optical sensor from carbon dots to assess the condition of aged mineral oil. The aged oil simulates the naturally occurring accelerated oxidation in an in-service power transformer according to ASTM D1934. During this, the novel interaction between the novel synthesized carbon dots and the mineral oil whether fresh or aged will be highlighted. Dielectric dissipation factor is obtained in the lab and correlated with the optical emission spectra of the novel optical sensor. Judging the oil condition is done by referencing the in-service limits of dielectric dissipation factor for mineral oil in power transformer specified in IEEE Std C57.106-2015. A novel optical sensor is developed from carbon dots capable of indicating dielectric dissipation factor and aging of the mineral oil under conditions that simulate real operation.","Rashed, Abdellatif K., Ghali, M., Rezk, A., Mansour, Diaa-Eldin A.",,,Studying the Novel Interaction of Carbon Dots with Aged Mineral Oil Through Photoluminescence Emission,,,10.1109/ICD59037.2024.10613107 , ,,"Carbon dots have covered a wide range of applications recently since they are biocompatible, non-toxic, and created in a low-cost hydrothermal process. Their size affects their photoluminescence properties which are determined by the specified conditions in the synthesis process. Photoluminescence spectroscopy is far less used than ultraviolet visible spectroscopy in the literature concerning condition assessment of power transformer insulating oil. This paper focuses on the development of a compatible optical sensor from carbon dots to assess the condition of aged mineral oil. The aged oil simulates the naturally occurring accelerated oxidation in an in-service power transformer according to ASTM D1934. During this, the novel interaction between the novel synthesized carbon dots and the mineral oil whether fresh or aged will be highlighted. Dielectric dissipation factor is obtained in the lab and correlated with the optical emission spectra of the novel optical sensor. Judging the oil condition is done by referencing the in-service limits of dielectric dissipation factor for mineral oil in power transformer specified in IEEE Std C57.106-2015. A novel optical sensor is developed from carbon dots capable of indicating dielectric dissipation factor and aging of the mineral oil under conditions that simulate real operation.",,,,, ,  2024 IEEE 5th International Conference on Dielectrics (ICD),Spectroscopy;Surface waves;Oils;Carbon dioxide;Photoluminescence;Aging;Minerals;Carbon dots (CDs);Power transformer;Condition monitoring;Photoluminescence (PL) spectroscopy;Dielectric dissipation factor (DDF),out_of_scope,
2987,"**Title**Stacked Bi-LSTM for Advanced Toxicity Detection in Comment Classification

**Abstract**The surge in Internet usage has revolutionized online forums, providing dynamic forums for active participation and meaningful debates. However, this has also exposed users to the risk of harassment. Efforts to address toxic comments in online forums have faced challenges, with current solutions unveiling unreliability. Advances in hardware, cloud computing, and natural language processing (NLP) enable the development of more robust approaches, predominantly NLP-based deep learning models. Pre-trained transformer models are gradually utilized for accurate toxic comment classification, bigger traditional methods. Stacked LSTM models, emphasizing hierarchical feature learning and improved contextual understanding, outperform single layer counterparts, offering an effective solution for online content moderation and sentiment analysis. This research indicates a significant stride towards more dependable and sophisticated toxic comment detection, addressing the challenges of social media effectively.","Kumar, N. Naveen, Abraham, Prabhakaran, Kaliba, Syed Ibrahim, VC, Diniesh, R, Maruthamuthu, Balamurugan, P, Seshu Kumar, Vekkudu, Naveen",,,Stacked Bi-LSTM for Advanced Toxicity Detection in Comment Classification,,,10.1109/IICAIET62352.2024.10729970 , ,,"The surge in Internet usage has revolutionized online forums, providing dynamic forums for active participation and meaningful debates. However, this has also exposed users to the risk of harassment. Efforts to address toxic comments in online forums have faced challenges, with current solutions unveiling unreliability. Advances in hardware, cloud computing, and natural language processing (NLP) enable the development of more robust approaches, predominantly NLP-based deep learning models. Pre-trained transformer models are gradually utilized for accurate toxic comment classification, bigger traditional methods. Stacked LSTM models, emphasizing hierarchical feature learning and improved contextual understanding, outperform single layer counterparts, offering an effective solution for online content moderation and sentiment analysis. This research indicates a significant stride towards more dependable and sophisticated toxic comment detection, addressing the challenges of social media effectively.",,,,, ,  2024 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET),Representation learning;Deep learning;Sentiment analysis;Toxicology;Social networking (online);Computational modeling;Transformers;Hardware;Surges;Long short term memory;Toxicity Detection;Natural Language Processing;Ensemble Learning;Text Preprocessing;Tokenization Introduction,detection,
2988,"**Title**Exploring Lead-Free Perovskite-Inspired Materials as Pressed Pellets for X-ray Detector Application

**Abstract**Highly sensitive X-ray detectors based on materials containing high atomic-number elements, such as metal halide perovskites (MHPs), would enable reduced dose rates, which is vital for medical applications. However, the instability and the potential toxicity of conventional lead-based MHPs constitute a challenge for commercialization, which prompts the use of alternative perovskite inspired materials based on less toxic elements, such as bismuth and silver to replace lead. Furthermore, to enable large-area, highperformance, detectors, it is paramount to employ methods to produce high-quality, millimetre-thick, layers of the detector material, which currently remains a challenge for MHPs. In this work, different lead-free, perovskite-inspired, materials, which include fully inorganic compounds, such as the double perovskite Cs2 AgBiBr6, as well as novel organic-inorganic ones were investigated as X-ray detectors. The materials were synthesized using ball-milling and polycrystalline pellets produced through scalable cold isostatic-pressing were used to assemble X-ray detectors. X-ray-based spectroscopic and diffraction methods were used to determine the composition and structural properties of the pellets. The detector performance was evaluated by measuring the photocurrent response under X-ray illumination. The results show that the selection of composition, additives, different post-treatment methods of the pellets as well as device architecture significantly affect the properties, potentially improving detector performance for various applications. The obtained sensitivities and detection limits are comparable to or even higher than those reported for similar perovskite-inspired materials. The work demonstrates that the materials are very promising, and could thus pave the way for future application of these materials as X-ray detectors.","Maslyanchuk, O. L., Starkholm, A., Unger, E., Al-Sabbagh, D., Emmerling, F., Kloo, L., Svensson, P. H., Sarisozen, S., Neher, D., Lang, F.",,,Exploring Lead-Free Perovskite-Inspired Materials as Pressed Pellets for X-ray Detector Application,,,10.1109/NSS/MIC/RTSD57108.2024.10655157 , ,,"Highly sensitive X-ray detectors based on materials containing high atomic-number elements, such as metal halide perovskites (MHPs), would enable reduced dose rates, which is vital for medical applications. However, the instability and the potential toxicity of conventional lead-based MHPs constitute a challenge for commercialization, which prompts the use of alternative perovskite inspired materials based on less toxic elements, such as bismuth and silver to replace lead. Furthermore, to enable large-area, highperformance, detectors, it is paramount to employ methods to produce high-quality, millimetre-thick, layers of the detector material, which currently remains a challenge for MHPs. In this work, different lead-free, perovskite-inspired, materials, which include fully inorganic compounds, such as the double perovskite Cs2 AgBiBr6, as well as novel organic-inorganic ones were investigated as X-ray detectors. The materials were synthesized using ball-milling and polycrystalline pellets produced through scalable cold isostatic-pressing were used to assemble X-ray detectors. X-ray-based spectroscopic and diffraction methods were used to determine the composition and structural properties of the pellets. The detector performance was evaluated by measuring the photocurrent response under X-ray illumination. The results show that the selection of composition, additives, different post-treatment methods of the pellets as well as device architecture significantly affect the properties, potentially improving detector performance for various applications. The obtained sensitivities and detection limits are comparable to or even higher than those reported for similar perovskite-inspired materials. The work demonstrates that the materials are very promising, and could thus pave the way for future application of these materials as X-ray detectors.",,,,, ,"  2024 IEEE Nuclear Science Symposium (NSS), Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector Conference (RTSD)",Performance evaluation;Silver;Semiconductor device measurement;X-ray detectors;Toxicology;Sensitivity;Semiconductor detectors,out_of_scope,
2989,"**Title**First Measurements with On-Chip PET Detectors

**Abstract**This study presents the initial real-world evaluation of a dedicated On-Chip PET scanner designed for functional imaging of Organs-on-Chips (OOCs). OOCs provide a promising alternative to conventional in vitro and animal models for drug development, disease modeling, and toxicity testing. Our previous work has focused on optimizing the scanner’s design through simulations, developing deep-learning techniques for positron range correction, and demonstrating its capability to dynamically image OOCs. The On-Chip PET scanner consists of two detectors, each made up of a monolithic LYSO crystal optically coupled to four 8 x 8 SiPM arrays, which are individually read out by PETsys’ SiPM readout system. Following the ASICs calibration, several data acquisitions were conducted with the point source positioned at different locations within the field of view for 60 seconds each. Analysis of flood maps and energy spectra confirmed expected variations based on source positioning, demonstrating the functionality of the scanner. These preliminary results represent a first step towards enabling functional imaging for OOCs. Future work will involve further detector calibration and phantom measurements before transitioning to imaging actual OOC devices.","Clement, C., Pagano, F., Pizzichemi, M., Terragni, G., Julio, M. Kruithof-de, Ziegler, S., Rominger, A., Auffray, E., Shi, K.",,,First Measurements with On-Chip PET Detectors,,,10.1109/NSS/MIC/RTSD57108.2024.10656261 , ,,"This study presents the initial real-world evaluation of a dedicated On-Chip PET scanner designed for functional imaging of Organs-on-Chips (OOCs). OOCs provide a promising alternative to conventional in vitro and animal models for drug development, disease modeling, and toxicity testing. Our previous work has focused on optimizing the scanner’s design through simulations, developing deep-learning techniques for positron range correction, and demonstrating its capability to dynamically image OOCs. The On-Chip PET scanner consists of two detectors, each made up of a monolithic LYSO crystal optically coupled to four 8 x 8 SiPM arrays, which are individually read out by PETsys’ SiPM readout system. Following the ASICs calibration, several data acquisitions were conducted with the point source positioned at different locations within the field of view for 60 seconds each. Analysis of flood maps and energy spectra confirmed expected variations based on source positioning, demonstrating the functionality of the scanner. These preliminary results represent a first step towards enabling functional imaging for OOCs. Future work will involve further detector calibration and phantom measurements before transitioning to imaging actual OOC devices.",,,,, ,"  2024 IEEE Nuclear Science Symposium (NSS), Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector Conference (RTSD)",Temperature measurement;Semiconductor device measurement;Toxicology;Semiconductor detectors;Positrons;Optical imaging;System-on-chip,out_of_scope,
2990,"**Title**Magneto-optical phase enantiomeric detector

**Abstract**Summary from only given. We have developed improved techniques for rapidly and sensitively screening potential medicines. These include the Faraday effect using a sinusoidally varying magnetic field, phase-sensitive detection, and optical-heterodyne detection. We call this set of techniques and the resulting device the magneto-optical phase enantiomeric detector (MOPED). Because chiral molecules on average exhibit greater Faraday effect than non-chiral molecules and our two detection methods are extremely sensitive and fast, these techniques provide increased sensitivity and decreased analysis time.","Gibbs, P., Kimmel, M., Bommarius, A., Trebino, R.",,,Magneto-optical phase enantiomeric detector,,,10.1109/CLEO.2002.1034139 , ,,"Summary from only given. We have developed improved techniques for rapidly and sensitively screening potential medicines. These include the Faraday effect using a sinusoidally varying magnetic field, phase-sensitive detection, and optical-heterodyne detection. We call this set of techniques and the resulting device the magneto-optical phase enantiomeric detector (MOPED). Because chiral molecules on average exhibit greater Faraday effect than non-chiral molecules and our two detection methods are extremely sensitive and fast, these techniques provide increased sensitivity and decreased analysis time.",,,,, ,  Summaries of Papers Presented at the Lasers and Electro-Optics. CLEO '02. Technical Diges,Phase detection;Magnetooptic effects;Magnetooptic devices;Faraday effect;Optical detectors;Biomedical optical imaging;Optical sensors;Motorcycles;Ultraviolet sources;Magnetic analysis,out_of_scope,
2991,"**Title**Toxicity of toner nanoparticles on RT112 cell cultures

**Abstract**The measurement of cell proliferation and cell viability has become a key technology in the life sciences. The need for sensitive, reliable, fast and easy methods has led to the development of several standard assays. These include the determination of DNA synthesis by measuring the amount of radioactive labeled nucleosides like [3H]-thymidine incorporated in nucleic acid. Alternatively several tetrazolium salts, including MTT, XTT and MTS are usually used to assay cell proliferation and viability on microplate assays. Actually there is an immediate need for nanotoxicology the availability of rapid and inexpensive tools in order to carry out some preliminary test for nanomaterials and the aim of our work was to investigate on the feasibility of WST-1 assay for this purpose. In our aim we investigated the toxicity in term of cell proliferation of toner nanoparticles (5-50 nm) on human bladder carcinoma cell line RT112 by WST-1 assay and also to evaluate the feasibility to apply this method as tool for in vitro nanotoxicology studies. In order to relate the toxicity test results to the toner powder properties, chemical and physical-chemical analyses have been performed in parallel on the same batch sample.","Mosiello, Lucia, Zappa, Giovanna, Zoani, Claudia, Lamberti, Ilaria, Gatti, Rosanna, Pilloni, Luciano",,,Toxicity of toner nanoparticles on RT112 cell cultures,,, , ,,"The measurement of cell proliferation and cell viability has become a key technology in the life sciences. The need for sensitive, reliable, fast and easy methods has led to the development of several standard assays. These include the determination of DNA synthesis by measuring the amount of radioactive labeled nucleosides like [3H]-thymidine incorporated in nucleic acid. Alternatively several tetrazolium salts, including MTT, XTT and MTS are usually used to assay cell proliferation and viability on microplate assays. Actually there is an immediate need for nanotoxicology the availability of rapid and inexpensive tools in order to carry out some preliminary test for nanomaterials and the aim of our work was to investigate on the feasibility of WST-1 assay for this purpose. In our aim we investigated the toxicity in term of cell proliferation of toner nanoparticles (5-50 nm) on human bladder carcinoma cell line RT112 by WST-1 assay and also to evaluate the feasibility to apply this method as tool for in vitro nanotoxicology studies. In order to relate the toxicity test results to the toner powder properties, chemical and physical-chemical analyses have been performed in parallel on the same batch sample.",,,,, ,  2009 9th IEEE Conference on Nanotechnology (IEEE-NANO),Nanoparticles;Testing;Chemical analysis;Standards development;DNA;Nuclear measurements;Nanomaterials;Humans;Bladder;In vitro;formatting;style;styling;insert;nanotoxicology;nanoparticles;RT112 Cell line,out_of_scope,
2992,"**Title**Sensing of mid-infrared radiation by engineered quantum nanostructures

**Abstract**This paper provided preliminary results on (In,Ga)As quantum dot detectors that have shown the potential to operate well beyond 150 K. In addition, a review of the latest results in the use of quantum dots in mid-wave infrared detection from 78 K and beyond is presented.","Towe, E., Pal, D.",,,Sensing of mid-infrared radiation by engineered quantum nanostructures,,,10.1109/LEOS.2005.1547900 , ,,"This paper provided preliminary results on (In,Ga)As quantum dot detectors that have shown the potential to operate well beyond 150 K. In addition, a review of the latest results in the use of quantum dots in mid-wave infrared detection from 78 K and beyond is presented.",,,,, ,  2005 IEEE LEOS Annual Meeting Conference Proceedings,Nanostructures;Quantum dots;Gallium arsenide;Infrared detectors;Atomic layer deposition;Energy states;Carrier confinement;Doping;Radiation detectors;Nanoparticles,out_of_scope,
2993,"**Title**Nitrobenzene Removal in Biological Activated Carbon Filter by Immobilized Dominant Bacteria

**Abstract**A dominant bacteria for nitrobenzene removal was isolated from Songhua River and identified as Bacillus-subtilis. Experiments have been carried out to investigate the performance of a biological activated carbon(BAC) using this dominant bacteria immobilized on carbon media in treating nitrobenzene. The results show that dominant bacteria were capable of removing the nitrobenzene completely even with high concentrations of nitrobenzene in raw water and the nitrobenzene concentration in BAC effluent was all not detected after the stabilization of the filter operation. The bacteria on BAC filter were ready for use after 20 days of start-up period. The stabilization of the biomass on BAC filter was achieved after 90 days operation. The toxicity test checked by Deltatox Analyzer indicated that most of the nitrobenzene was removed by the top and middle layer of the filters.","Gao, Yu-Nan, Li, Weiguang, Bai, Yu, Liu, Shui",,,Nitrobenzene Removal in Biological Activated Carbon Filter by Immobilized Dominant Bacteria,,,10.1109/ICBBE.2009.5163111 , ,,A dominant bacteria for nitrobenzene removal was isolated from Songhua River and identified as Bacillus-subtilis. Experiments have been carried out to investigate the performance of a biological activated carbon(BAC) using this dominant bacteria immobilized on carbon media in treating nitrobenzene. The results show that dominant bacteria were capable of removing the nitrobenzene completely even with high concentrations of nitrobenzene in raw water and the nitrobenzene concentration in BAC effluent was all not detected after the stabilization of the filter operation. The bacteria on BAC filter were ready for use after 20 days of start-up period. The stabilization of the biomass on BAC filter was achieved after 90 days operation. The toxicity test checked by Deltatox Analyzer indicated that most of the nitrobenzene was removed by the top and middle layer of the filters.,,,,, ,  2009 3rd International Conference on Bioinformatics and Biomedical Engineering,Filters;Microorganisms;Effluents;Testing;Water resources;Carbon dioxide;Rivers;Degradation;Raw materials;Surface treatment,out_of_scope,
2994,"**Title**Target Design and Optimizations for Spent Fuel Transmutation

**Abstract**There are six long-lived fission products (LLFPs) identified in nuclear spent fuel, which are responsible for at least 99% of the long-term radio-toxicity once actinide recycling has been completed. This paper discusses the feasibility of using proton beams to transmute the LLFPs into shorter-lived or stable isotopes. Although long-term storage for high-level waste would still be required, transmuting the LLFPs can reduce the volume of waste material stored. PHITS, a Monte Carlo transport code, is utilized to computationally model the interactions between the LLFP materials and the proton beam. PHITS is used in this paper to estimate the flux-energy spectrum and number of atoms irradiated in the LLFP target when interacting with the beam. This data is then post-processed in a 0-dimensional analysis in FISPACT to estimate the transmutation rate for each LLFP. Analysis of the performance of commercial cyclotrons with energies of 18-70 MeV has shown that transmutation rates will increase when the proton beam energy is increased. A cyclotron with a beam current of 10 mA and beam energy of 70 MeV running continuously can transmute 7.51 ± 1.19 g/year of technetium-99. However, technetium-99 is produced at around a rate of 1kg/year inside a 1 GW reactor, suggesting that commercial cyclotrons are not viable for transmutation purposes. Studies are ongoing on modeling 1000 MeV proton beams to cause spallation reactions inside the LLFP targets. The spallation process burns the LLFP target while producing many secondary neutrons that can be further used for transmuting the LLFPs. A preliminary analysis suggests that a 1000 MeV beam with a 10 mA current can transmute around 1kg/year of technetium-99 due to nuclear reactions without accounting for spallation reactions.","Tukharyan, G., Danagoulian, A., Forget, B., Wickert, C., Yu, J.",,,Target Design and Optimizations for Spent Fuel Transmutation,,,10.1109/NSS/MIC/RTSD57108.2024.10655161 , ,,"There are six long-lived fission products (LLFPs) identified in nuclear spent fuel, which are responsible for at least 99% of the long-term radio-toxicity once actinide recycling has been completed. This paper discusses the feasibility of using proton beams to transmute the LLFPs into shorter-lived or stable isotopes. Although long-term storage for high-level waste would still be required, transmuting the LLFPs can reduce the volume of waste material stored. PHITS, a Monte Carlo transport code, is utilized to computationally model the interactions between the LLFP materials and the proton beam. PHITS is used in this paper to estimate the flux-energy spectrum and number of atoms irradiated in the LLFP target when interacting with the beam. This data is then post-processed in a 0-dimensional analysis in FISPACT to estimate the transmutation rate for each LLFP. Analysis of the performance of commercial cyclotrons with energies of 18-70 MeV has shown that transmutation rates will increase when the proton beam energy is increased. A cyclotron with a beam current of 10 mA and beam energy of 70 MeV running continuously can transmute 7.51 ± 1.19 g/year of technetium-99. However, technetium-99 is produced at around a rate of 1kg/year inside a 1 GW reactor, suggesting that commercial cyclotrons are not viable for transmutation purposes. Studies are ongoing on modeling 1000 MeV proton beams to cause spallation reactions inside the LLFP targets. The spallation process burns the LLFP target while producing many secondary neutrons that can be further used for transmuting the LLFPs. A preliminary analysis suggests that a 1000 MeV beam with a 10 mA current can transmute around 1kg/year of technetium-99 due to nuclear reactions without accounting for spallation reactions.",,,,, ,"  2024 IEEE Nuclear Science Symposium (NSS), Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector Conference (RTSD)",Particle beams;Waste materials;Microwave integrated circuits;Monte Carlo methods;Semiconductor detectors;Neutrons;Recycling,out_of_scope,
2995,"**Title**Optimization of a lead detection instrument using Monte Carlo modeling

**Abstract**RMD is developing a safe, inexpensive, and easy to operate lead detector for consumers that can reliably detect dangerous levels of lead in toys and other products. Widespread testing for lead is rarely undertaken until lead poisoning is detected. An inexpensive and easy to use lead detector would enable the identification of highly contaminated objects and areas and allow for timely and cost effective remediation. These efforts will result in an instrument that offers: (1) high sensitivity, to identify objects containing dangerous amounts of lead, (2) low cost to encourage widespread testing by consumers and other end users and (3) convenient operation requiring no training or licensing.","Rensing, Noa M., Tiernan, Timothy C., Keemon, Thomas A., Freed, Sara, Glynn, Paul, Bennett, Paul, Squillante, Michael R.",,,Optimization of a lead detection instrument using Monte Carlo modeling,,,10.1109/NSSMIC.2011.6154751 , ,,"RMD is developing a safe, inexpensive, and easy to operate lead detector for consumers that can reliably detect dangerous levels of lead in toys and other products. Widespread testing for lead is rarely undertaken until lead poisoning is detected. An inexpensive and easy to use lead detector would enable the identification of highly contaminated objects and areas and allow for timely and cost effective remediation. These efforts will result in an instrument that offers: (1) high sensitivity, to identify objects containing dangerous amounts of lead, (2) low cost to encourage widespread testing by consumers and other end users and (3) convenient operation requiring no training or licensing.",,,,, ,  2011 IEEE Nuclear Science Symposium Conference Record,Lead;Detectors;Safety;USA Councils;Consumer products,out_of_scope,
2996,"**Title**Risk Assessment of Classic Endocrine Disrupting Chemicals in Beijing-Tianjin-Tangshan District

**Abstract**This terms Endocrine Disrupting Chemicals (EDCs) are also called Environmental Estrogens. The synthetic chemicals in the artifice products may affect the endocrine system, associated with developmental, reproductive and other health problems in wildlife and laboratory animals. In the Beijing-Tianjin-Tangshan district, there are 38.58 million populations. And chemical engineering of petroleum and coal are the main industries. So, the extent of exposure and safety of health are very important for residents in this area. But, there are no enough attentions to focus on the environmental risk and disruption of EDCs. And, Many are chemicals produced for specific purposes and are used in pesticides, plastics, cosmetics, electrical transformers and other products. Then, how to assess so many compounds and determine the risk rank of potential effects on physiological functions? The Priority detected EDCs have been chosen form the many industrial compounds by the system of fuzzy clustering analysis. In this paper, analytic hierarchy process (AHP) has been introduced to accumulate the weight value of the properties parameters for the risk assessment system.","Su, Jin, Zhang, Shuichang, Chen, Jianping, Shi, Yumiao, Chen, Boyang",,,Risk Assessment of Classic Endocrine Disrupting Chemicals in Beijing-Tianjin-Tangshan District,,,10.1109/ICBBE.2009.5163354 , ,,"This terms Endocrine Disrupting Chemicals (EDCs) are also called Environmental Estrogens. The synthetic chemicals in the artifice products may affect the endocrine system, associated with developmental, reproductive and other health problems in wildlife and laboratory animals. In the Beijing-Tianjin-Tangshan district, there are 38.58 million populations. And chemical engineering of petroleum and coal are the main industries. So, the extent of exposure and safety of health are very important for residents in this area. But, there are no enough attentions to focus on the environmental risk and disruption of EDCs. And, Many are chemicals produced for specific purposes and are used in pesticides, plastics, cosmetics, electrical transformers and other products. Then, how to assess so many compounds and determine the risk rank of potential effects on physiological functions? The Priority detected EDCs have been chosen form the many industrial compounds by the system of fuzzy clustering analysis. In this paper, analytic hierarchy process (AHP) has been introduced to accumulate the weight value of the properties parameters for the risk assessment system.",,,,, ,  2009 3rd International Conference on Bioinformatics and Biomedical Engineering,Risk management;Endocrine system;Chemical products;Electrical equipment industry;Electrical products industry;Wildlife;Laboratories;Animals;Chemical engineering;Petroleum,out_of_scope,
2997,"**Title**Notice of Retraction: The Extractive of APMP Effluent and It Influence on Biological Treatment

**Abstract**Retracted.","Liu, Tingzhi, Chang, Fang, Zhao, Hongyu, Li, Hongkai, Duan, Weijiang",,,Notice of Retraction: The Extractive of APMP Effluent and It Influence on Biological Treatment,,,10.1109/icbbe.2011.5780131 , ,,Retracted.,,,,, ,  2011 5th International Conference on Bioinformatics and Biomedical Engineering,,out_of_scope,
2998,"**Title**Notice of Retraction: Total Mercury and Methyl Mercury Concentration of Hair in the Residents in Di'er Songhua River Region, Northeast China: Influencing Factors and Health Risk

**Abstract**This article has been retracted by the publisher.","Lei, Zhang, Lei, Zhang",,,"Notice of Retraction: Total Mercury and Methyl Mercury Concentration of Hair in the Residents in Di'er Songhua River Region, Northeast China: Influencing Factors and Health Risk",,,10.1109/icbbe.2011.5781335 , ,,This article has been retracted by the publisher.,,,,, ,  2011 5th International Conference on Bioinformatics and Biomedical Engineering,,out_of_scope,
2999,"**Title**Demonstration of LGADs and Cherenkov Gamma Detectors for Prompt Gamma Timing Proton Therapy Range Verification

**Abstract**The great potential for precision dose delivery with proton therapy remains to be fully exploited, largely due to uncertainties in range that require additional conservative treatment margins. Analysis of time distributions from prompt gamma-ray emissions offers a means to precisely verify the range in real time and shrink treatment margins, thus increasing effectiveness and reducing toxicity. We demonstrate a prototype prompt gamma timing system to detect proton range shifts, based on Low Gain Avalanche Detectors, used to time incoming protons, and Cherenkov detectors, to time the outgoing prompt gammas. With this system, we are able to detect range shifts induced in a PMMA phantom with about 1 mm precision consistently.","Heller, Ryan, Ellin, Justin, Backfish, Michael, Cates, Joshua W., Choong, Woon-Seng, Kratochwil, Nicolaus, Prebys, Eric, Rebolo, Leonor, James, Sara St., Ariño-Estrada, Gerard",,,Demonstration of LGADs and Cherenkov Gamma Detectors for Prompt Gamma Timing Proton Therapy Range Verification,,,10.1109/TRPMS.2024.3494720 , ,,"The great potential for precision dose delivery with proton therapy remains to be fully exploited, largely due to uncertainties in range that require additional conservative treatment margins. Analysis of time distributions from prompt gamma-ray emissions offers a means to precisely verify the range in real time and shrink treatment margins, thus increasing effectiveness and reducing toxicity. We demonstrate a prototype prompt gamma timing system to detect proton range shifts, based on Low Gain Avalanche Detectors, used to time incoming protons, and Cherenkov detectors, to time the outgoing prompt gammas. With this system, we are able to detect range shifts induced in a PMMA phantom with about 1 mm precision consistently.",,,,, ,  ,Detectors;Protons;Timing;Plasmas;Particle beams;Thallium;Production;Gamma-rays;Tumors;Sensors;Prompt gamma timing;proton range verification;LGAD;Thallium Bromide;Thallium Chloride;Cherenkov detector,out_of_scope,
3000,"**Title**Synthesis, characterisation and gas sensing application of Sb-doped ZnO

**Abstract**ZnO and Sb-doped ZnO nanostructures were synthesized using microwave assisted precipitation method. Thick films of prepared powders were fabricated using screen printing method. The X-ray diffraction studies show that the nanostructures are crystallized in the form of hexagonal Wurzite crystalline phase and Sb-doping does not change the structure of ZnO. The size of nanostructures decreases with increasing the Sb+3-doping. Field emission scanning electron microscope (FESEM) images show the change in morphology and size of nanostructures are changing with change in doping percentage of Sb+3. The UV-visible spectra shows the increase in band gap with increasing the Sb +3-doping percentage. The gas sensitivity of pure and Sb+3-doped ZnO nanostructures was studied. The gas sensitivity of the films was improved with the doping of 7% Sb+3 in ZnO.","Patil, Yogita S., Raghuvanshi, F. C., Patil, I. D.",,,"Synthesis, characterisation and gas sensing application of Sb-doped ZnO",,,10.1109/ICEEOT.2016.7755158 , ,,ZnO and Sb-doped ZnO nanostructures were synthesized using microwave assisted precipitation method. Thick films of prepared powders were fabricated using screen printing method. The X-ray diffraction studies show that the nanostructures are crystallized in the form of hexagonal Wurzite crystalline phase and Sb-doping does not change the structure of ZnO. The size of nanostructures decreases with increasing the Sb+3-doping. Field emission scanning electron microscope (FESEM) images show the change in morphology and size of nanostructures are changing with change in doping percentage of Sb+3. The UV-visible spectra shows the increase in band gap with increasing the Sb +3-doping percentage. The gas sensitivity of pure and Sb+3-doped ZnO nanostructures was studied. The gas sensitivity of the films was improved with the doping of 7% Sb+3 in ZnO.,,,,, ,"  2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT)",Zinc oxide;II-VI semiconductor materials;Nanostructures;Thick films;Gas detectors;Sb-doped ZnO;microwave assisted synthesis;nanostructures;thick films,out_of_scope,
3001,"**Title**FPGA-based bio-cybernetic system for lab-on-a-chip automation

**Abstract**In recent years, Lab-on-a-Chip technology has been widely applied to the pharmaceutical and eco-toxicity domains, together with the use of zebrafish as the model organism for performing fish embryo toxicity assay. However, the requirement of constant human attention and lack of fully automated systems have lead into low throughput and slow turnaround time for the experiments. In this paper, a novel FPGA-based bio-cybernetic system is designed to work with Lab-on-a-Chip devices in these experiments for handling zebrafish embryos, controlling chemical liquid perfusion, maintaining micro-environment and acquiring image data periodically for the analysis of embryo development. These functionalities have been demonstrated in the designed system by performing multiple 40-hour continuous experiments.","Wang, Kevin I-Kai, Yeh, Johnny, Salcic, Zoran, Akagi, Jin, Wlodkowic, Donald",,,FPGA-based bio-cybernetic system for lab-on-a-chip automation,,, , ,,"In recent years, Lab-on-a-Chip technology has been widely applied to the pharmaceutical and eco-toxicity domains, together with the use of zebrafish as the model organism for performing fish embryo toxicity assay. However, the requirement of constant human attention and lack of fully automated systems have lead into low throughput and slow turnaround time for the experiments. In this paper, a novel FPGA-based bio-cybernetic system is designed to work with Lab-on-a-Chip devices in these experiments for handling zebrafish embryos, controlling chemical liquid perfusion, maintaining micro-environment and acquiring image data periodically for the analysis of embryo development. These functionalities have been demonstrated in the designed system by performing multiple 40-hour continuous experiments.",,,,, ,  2012 19th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),Temperature measurement;Embryo;Temperature sensors;Temperature control;DC motors;Pulse width modulation;Thermistors;Lab-on-a-Chip;MEMS;Bio-cybernetic system;FPGA,out_of_scope,
3002,"**Title**Exploring high-entropy design in rare-earth aluminum garnet scintillators

**Abstract**Cargo inspection via high-energy X-ray radiography is an important imaging modality for national security applications where 2-9 MeV X-rays are used to identify contraband through non-intrusive inspection. CdWO4 single crystal scintillator is a common detector material for this application, however, it suffers from a relatively low light yield and toxicity. As the need for this imaging capability grows, a search for new scintillator materials for this application is ongoing. In this work, single-component, multi-component, and high-entropy aluminum garnet ceramics are synthesized to investigate the effect configuration entropy has on the scintillation properties. In addition, the composition (Y,Gd,Tb,Lu)3Al5O12:Ce is investigated for use in high-energy X-ray radiography applications. Aluminum garnet powders are synthesized via a wet chemistry method and are densified into ceramics via uniaxial hot pressing. XRD measurements are done to confirm the phase purity of powders and ceramics. Scintillation properties such as light yield, decay time, and afterglow are evaluated. Radiation hardness is evaluated through the measurement of scintillation properties before and after irradiation with a ${ }^{60} \mathrm{Co}$ source. It is found that afterglow is suppressed in the compositions with greater configurational entropy.","Anderson, K., Gillespie, N., Muller, M., Glodo, J., Wang, Y., Stand, L., Melcher, C., Zhuravleva, M.",,,Exploring high-entropy design in rare-earth aluminum garnet scintillators,,,10.1109/NSS/MIC/RTSD57108.2024.10657843 , ,,"Cargo inspection via high-energy X-ray radiography is an important imaging modality for national security applications where 2-9 MeV X-rays are used to identify contraband through non-intrusive inspection. CdWO4 single crystal scintillator is a common detector material for this application, however, it suffers from a relatively low light yield and toxicity. As the need for this imaging capability grows, a search for new scintillator materials for this application is ongoing. In this work, single-component, multi-component, and high-entropy aluminum garnet ceramics are synthesized to investigate the effect configuration entropy has on the scintillation properties. In addition, the composition (Y,Gd,Tb,Lu)3Al5O12:Ce is investigated for use in high-energy X-ray radiography applications. Aluminum garnet powders are synthesized via a wet chemistry method and are densified into ceramics via uniaxial hot pressing. XRD measurements are done to confirm the phase purity of powders and ceramics. Scintillation properties such as light yield, decay time, and afterglow are evaluated. Radiation hardness is evaluated through the measurement of scintillation properties before and after irradiation with a ${ }^{60} \mathrm{Co}$ source. It is found that afterglow is suppressed in the compositions with greater configurational entropy.",,,,, ,"  2024 IEEE Nuclear Science Symposium (NSS), Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector Conference (RTSD)",Temperature measurement;Radiography;Semiconductor device measurement;Scintillators;Powders;Garnets;Aluminum,out_of_scope,
3003,"**Title**Measurement and analysis of Vibrio Fischeri cell-based microfluidic device for personal health monitoring

**Abstract**The cell-based microfluidic chip was designed and fabricated as a low-cost detector to continuously monitor toxicants in drinking water or human urine samples, which is expected to be an important component of a household health monitoring system in the future. The bioluminescent bacterium, Vibrio Fischeri, was selected to validate the function of device. Water samples and Vibrio fischeri cells were mixed and encapsulated into droplets in air flow, which can guarantee sufficient oxygen supply for cells in droplets. Preliminary tests were performed using copper ion (Cu2+) as the model toxicant. The droplet system was measured and analyzed at various flow rates in different observation chambers. Both deionized water and human urine samples were tested in the cell-based device. Interestingly, a strong relation between the R.L.U. (Relative Luminescence Units) in the observation chamber and the minute concentration of toxicant (Cu2+) was found using deionized water as solvent, whereas the relation was insignificant using human urine as solvent. This study showed the Vibrio fischeri cell-based device might be reliably employed as an early-warning system for the safety of drinking water. However, Vibrio fischeri is not competent to detect dangerous mThe cell-based microfluidic chip was designed and fabricated as a low-cost detector to continuously monitor toxicants in drinking water or human urine samples, which is expected to be an important component of a household health monitoring system in the future. The bioluminescent bacterium, Vibrio Fischeri, was selected to validate the function of device. Water samples and Vibrio fischeri cells were mixed and encapsulated into droplets in air flow, which can guarantee sufficient oxygen supply for cells in droplets. Preliminary tests were performed using copper ion (Cu2+) as the model toxicant. The droplet system was measured and analyzed at various flow rates in different observation chambers. Both deionized water and human urine samples were tested in the cell-based device. Interestingly, a strong relation between the R.L.U. (Relative Luminescence Units) in the observation chamber and the minute concentration of toxicant (Cu2+) was found using deionized water as solvent, whereas the relation was insignificant using human urine as solvent. This study showed the Vibrio fischeri cell-based device might be reliably employed as an early-warning system for the safety of drinking water. However, Vibrio fischeri is not competent to detect dangerous materials in a complex biofluid. With the replacement of cell sensors, the microfluidic device might be functional to analyze urine samples in theory.aterials in a complex biofluid. With the replacement of cell sensors, the microfluidic device might be functional to analyze urine samples in theory.","Zhao, Xinyan, Dong, Tao",,,Measurement and analysis of Vibrio Fischeri cell-based microfluidic device for personal health monitoring,,,10.1109/EMBC.2013.6610031 , ,,"The cell-based microfluidic chip was designed and fabricated as a low-cost detector to continuously monitor toxicants in drinking water or human urine samples, which is expected to be an important component of a household health monitoring system in the future. The bioluminescent bacterium, Vibrio Fischeri, was selected to validate the function of device. Water samples and Vibrio fischeri cells were mixed and encapsulated into droplets in air flow, which can guarantee sufficient oxygen supply for cells in droplets. Preliminary tests were performed using copper ion (Cu2+) as the model toxicant. The droplet system was measured and analyzed at various flow rates in different observation chambers. Both deionized water and human urine samples were tested in the cell-based device. Interestingly, a strong relation between the R.L.U. (Relative Luminescence Units) in the observation chamber and the minute concentration of toxicant (Cu2+) was found using deionized water as solvent, whereas the relation was insignificant using human urine as solvent. This study showed the Vibrio fischeri cell-based device might be reliably employed as an early-warning system for the safety of drinking water. However, Vibrio fischeri is not competent to detect dangerous mThe cell-based microfluidic chip was designed and fabricated as a low-cost detector to continuously monitor toxicants in drinking water or human urine samples, which is expected to be an important component of a household health monitoring system in the future. The bioluminescent bacterium, Vibrio Fischeri, was selected to validate the function of device. Water samples and Vibrio fischeri cells were mixed and encapsulated into droplets in air flow, which can guarantee sufficient oxygen supply for cells in droplets. Preliminary tests were performed using copper ion (Cu2+) as the model toxicant. The droplet system was measured and analyzed at various flow rates in different observation chambers. Both deionized water and human urine samples were tested in the cell-based device. Interestingly, a strong relation between the R.L.U. (Relative Luminescence Units) in the observation chamber and the minute concentration of toxicant (Cu2+) was found using deionized water as solvent, whereas the relation was insignificant using human urine as solvent. This study showed the Vibrio fischeri cell-based device might be reliably employed as an early-warning system for the safety of drinking water. However, Vibrio fischeri is not competent to detect dangerous materials in a complex biofluid. With the replacement of cell sensors, the microfluidic device might be functional to analyze urine samples in theory.aterials in a complex biofluid. With the replacement of cell sensors, the microfluidic device might be functional to analyze urine samples in theory.",,,,, ,  2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),Monitoring;Biosensors;Microfluidics;Chemicals;Chemical sensors;Biomedical monitoring,out_of_scope,
3004,"**Title**Static and Dynamic MEMS Inertial Gas Sensors

**Abstract**We report on a wearable hazardous gas detection system. It combines high sensitivity with the ability to functionalize various sensors on the same chip with different detector polymers to target a range of toxic analytes and volatile organic compounds (VOCs), including chemical warfare agents (CWAs). The sensors were fabricated using a silicon-on-insulator MEMS process and can operate in both static and dynamic bifurcation modes. The experimental results show that the static and dynamic MEMS sensors equipped with the formaldehyde sensing polymers can serve as a detector for formaldehyde below its 2-ppm level of toxicity.","Ou, Matthew, Shama, Yasser S., Mavani, Bhoomi, Arabi, Mohamed, Saritas, Resul, Abdelrahman, Rana, Rahmanian, Sasan, Elhady, Alaaeldin, Mansour, Raafat, Penlidis, Alexander, Abdel-Rahman, Eihab M.",,,Static and Dynamic MEMS Inertial Gas Sensors,,, , ,,"We report on a wearable hazardous gas detection system. It combines high sensitivity with the ability to functionalize various sensors on the same chip with different detector polymers to target a range of toxic analytes and volatile organic compounds (VOCs), including chemical warfare agents (CWAs). The sensors were fabricated using a silicon-on-insulator MEMS process and can operate in both static and dynamic bifurcation modes. The experimental results show that the static and dynamic MEMS sensors equipped with the formaldehyde sensing polymers can serve as a detector for formaldehyde below its 2-ppm level of toxicity.",,,,, ,"  2023 22nd International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers)",Micromechanical devices;Volatile organic compounds;Chemical sensors;Transducers;Toxicology;Detectors;Bifurcation;Bifurcation sensors;gas sensing;MEMS;static and dynamic detection,out_of_scope,
3005,"**Title**Stable and Sensitive Tin-Lead Perovskite Photodetector for Pulse Oximetry Sensing

**Abstract**Although hybrid Sn-Pb halide perovskite with narrow bandgap and low toxicity are promising next generation semiconductor materials for visible to near-infrared detection, previous Sn-Pb perovskite photodetectors are still limited because of the insufficient performance and stability caused by high defect densities and oxidation of Sn $^{{2}+}$ . Here an additive 1,1-Carbonyldiimidazole is introduced, which can reduce surface defect and inhabit the oxidation by providing lone pairs of electrons to effectively passivate low coordination Pb $^{{2}+}$ and Sn $^{{2}+}$ of perovskite film. As such, for the photodetectors with 1,1-Carbonyldiimidazole, the dark current density reduces from ${1}.{88}\times {10} ^{-{3}}$ mA cm $^{-{2}}$ to ${6}.{27}\times {10} ^{-{5}}$ mA cm $^{-{2}}$ at −0.1 V, and the reliable stability of over 300 days is achieved, enabling successfully monitoring of pulse and oximetry. It is believed that the passivation layer based on 1,1-Carbonyldiimidazole provides a universal strategy to achieve stable and sensitive Sn-Pb perovskite detectors.","Chen, Hongxu, Zhang, Xinren, Feng, Baigong, Jiang, Jizhong, Hu, Gangjian, Ma, Yao, Zhao, Yi, Shen, Liang",,,Stable and Sensitive Tin-Lead Perovskite Photodetector for Pulse Oximetry Sensing,,,10.1109/LED.2024.3434615 , ,,"Although hybrid Sn-Pb halide perovskite with narrow bandgap and low toxicity are promising next generation semiconductor materials for visible to near-infrared detection, previous Sn-Pb perovskite photodetectors are still limited because of the insufficient performance and stability caused by high defect densities and oxidation of Sn $^{{2}+}$ . Here an additive 1,1-Carbonyldiimidazole is introduced, which can reduce surface defect and inhabit the oxidation by providing lone pairs of electrons to effectively passivate low coordination Pb $^{{2}+}$ and Sn $^{{2}+}$ of perovskite film. As such, for the photodetectors with 1,1-Carbonyldiimidazole, the dark current density reduces from ${1}.{88}\times {10} ^{-{3}}$ mA cm $^{-{2}}$ to ${6}.{27}\times {10} ^{-{5}}$ mA cm $^{-{2}}$ at −0.1 V, and the reliable stability of over 300 days is achieved, enabling successfully monitoring of pulse and oximetry. It is believed that the passivation layer based on 1,1-Carbonyldiimidazole provides a universal strategy to achieve stable and sensitive Sn-Pb perovskite detectors.",,,,, ,  ,Perovskites;Detectors;Photodetectors;Passivation;Pulse oximetry;Lead;Stability;Sn-Pb perovskite;photodetectors;stability;passivation,out_of_scope,
3006,"**Title**Automatic quality assessment for fluorescence microscopy images

**Abstract**Fluorescence microscopy imaging is a constant trade off between signal to noise ratio, total observation time and spatio-temporal resolution due to photo toxicity. In this paper, we propose a method to estimate the quality of a fluorescent image acquisition, from a single image, taking into account both signal dependent and signal independent noise. We propose a method for the calculation of the signal to noise ratio globally and locally. We validated our algorithm on real experimental data and data with known simulated noise. Results allow us to conclude that this fully automatic method provides a good quantification of the image quality.","Paul, Perrine, Kalamatianos, Dimitrios, Duessmann, Heiko, Huber, Heinrich",,,Automatic quality assessment for fluorescence microscopy images,,,10.1109/BIBE.2008.4696665 , ,,"Fluorescence microscopy imaging is a constant trade off between signal to noise ratio, total observation time and spatio-temporal resolution due to photo toxicity. In this paper, we propose a method to estimate the quality of a fluorescent image acquisition, from a single image, taking into account both signal dependent and signal independent noise. We propose a method for the calculation of the signal to noise ratio globally and locally. We validated our algorithm on real experimental data and data with known simulated noise. Results allow us to conclude that this fully automatic method provides a good quantification of the image quality.",,,,, ,  2008 8th IEEE International Conference on BioInformatics and BioEngineering,Quality assessment;Fluorescence;Microscopy;Crosstalk;Signal to noise ratio;Additive noise;Noise level;Gaussian noise;Background noise;Image resolution,out_of_scope,
3007,"**Title**An Automatic and Active Fire Protection Self-control Non-Blaze Surrounding System

**Abstract**To address the challenges posed by the potential toxicity and slow response of traditional fire suppression systems in high-security areas such as archives and museums, this study presents the design of an active fire suppression oxygen reduction automatic control system, hereinafter referred to as the Non-Blaze Surrounding system. This system consists of a nitrogen production module, an environmental monitoring module and is capable of real-time adjustment of oxygen levels within the space. By reducing the supply of oxygen, the possibility of fire occurrence is diminished while also safeguarding personnel. Experiments conducted in a custom-designed storage facility for cultural relics demonstrated the system’s ability to stabilize oxygen concentration at 16%, thereby validating its functionality and effectiveness.","Song, Ruifeng, Yan, Liang",,,An Automatic and Active Fire Protection Self-control Non-Blaze Surrounding System,,,10.1109/CCDC62350.2024.10588190 , ,,"To address the challenges posed by the potential toxicity and slow response of traditional fire suppression systems in high-security areas such as archives and museums, this study presents the design of an active fire suppression oxygen reduction automatic control system, hereinafter referred to as the Non-Blaze Surrounding system. This system consists of a nitrogen production module, an environmental monitoring module and is capable of real-time adjustment of oxygen levels within the space. By reducing the supply of oxygen, the possibility of fire occurrence is diminished while also safeguarding personnel. Experiments conducted in a custom-designed storage facility for cultural relics demonstrated the system’s ability to stabilize oxygen concentration at 16%, thereby validating its functionality and effectiveness.",,,,, ,  2024 36th Chinese Control and Decision Conference (CCDC),Temperature sensors;Temperature measurement;Toxicology;Production;Real-time systems;Museums;Personnel;Automatic control system;Environmental monitoring;Oxygen concentration;Fire occurrence probability,out_of_scope,
3008,"**Title**High-Performance Conductometric Acetone Gas Sensor Based on Co3O4/ZnO Nanorods With Abundant Oxygen Vacancies

**Abstract**Acetone exhibits flammability, explosiveness, and toxicity, rendering it a multifaceted hazard. Moreover, acetone serves as a vital biomarker for diabetes. Consequently, the demand for low-concentration acetone gas detection sensors is increasingly pressing in numerous sectors, including industrial processes and medical applications. In this study, we report a novel sensor based on Co3O4/ZnO nanorods and investigate the influence of Co doping-induced oxygen vacancies and the presence of Co3O4 on the sensing properties. The sensor was prepared through a simple one-step hydrothermal method and named Co/ZnONRs. The morphology, composition, and oxygen vacancy defects of the Co/ZnONRs were characterized using various techniques including scanning electron microscopy (SEM), transmission electron microscopy (TEM), energy dispersive spectroscopy (EDS), X-ray diffraction (XRD), X-ray photoelectron spectroscopy (XPS), and electron paramagnetic resonance (EPR). Characterization and gas sensing test results have demonstrated that the 1-Co/ZnONRs sensor outperformed previously reported designs, exhibiting high response values, short response times, good selectivity, and low detection limits toward acetone. Specifically, at 250 °C, the sensor demonstrated a response value of 833.33 toward 100-ppm acetone, which is an increase of ten times compared to the response value of ZnONRs, while the optimal operating temperature decreased by 50 °C, and the detection limit was as low as 100 ppb. The improved sensor performance is attributed to several factors such as changes in resistance caused by active sites generated by Co doping ZnO to form oxygen vacancies, the Co3O4/ZnO heterojunction, the high specific surface area of Co/ZnONRs, and the unique catalytic activity of Co3O4. These findings demonstrate the potential of our innovative design to significantly improve the accuracy and efficiency of gas sensors used in industrial processes and medical diagnoses.","Yuan, Zhenyu, Zhang, Jian, Zhu, Hongmin, Wang, Huai, Meng, Fanli",,,High-Performance Conductometric Acetone Gas Sensor Based on Co3O4/ZnO Nanorods With Abundant Oxygen Vacancies,,,10.1109/TIM.2023.3347801 , ,,"Acetone exhibits flammability, explosiveness, and toxicity, rendering it a multifaceted hazard. Moreover, acetone serves as a vital biomarker for diabetes. Consequently, the demand for low-concentration acetone gas detection sensors is increasingly pressing in numerous sectors, including industrial processes and medical applications. In this study, we report a novel sensor based on Co3O4/ZnO nanorods and investigate the influence of Co doping-induced oxygen vacancies and the presence of Co3O4 on the sensing properties. The sensor was prepared through a simple one-step hydrothermal method and named Co/ZnONRs. The morphology, composition, and oxygen vacancy defects of the Co/ZnONRs were characterized using various techniques including scanning electron microscopy (SEM), transmission electron microscopy (TEM), energy dispersive spectroscopy (EDS), X-ray diffraction (XRD), X-ray photoelectron spectroscopy (XPS), and electron paramagnetic resonance (EPR). Characterization and gas sensing test results have demonstrated that the 1-Co/ZnONRs sensor outperformed previously reported designs, exhibiting high response values, short response times, good selectivity, and low detection limits toward acetone. Specifically, at 250 °C, the sensor demonstrated a response value of 833.33 toward 100-ppm acetone, which is an increase of ten times compared to the response value of ZnONRs, while the optimal operating temperature decreased by 50 °C, and the detection limit was as low as 100 ppb. The improved sensor performance is attributed to several factors such as changes in resistance caused by active sites generated by Co doping ZnO to form oxygen vacancies, the Co3O4/ZnO heterojunction, the high specific surface area of Co/ZnONRs, and the unique catalytic activity of Co3O4. These findings demonstrate the potential of our innovative design to significantly improve the accuracy and efficiency of gas sensors used in industrial processes and medical diagnoses.",,,,, ,  ,Sensors;Zinc oxide;II-VI semiconductor materials;Gas detectors;Temperature sensors;Metals;Heterojunctions;Acetone gas sensors;high response value;oxygen vacancies;p-n heterostructure;rapid response,out_of_scope,
3009,"**Title**Single-X-Ray Sensitive Energy-Binning Dosimeter for Closed-Loop Cancer External-Beam Radiotherapy

**Abstract**X-ray radiation dose delivered during cancer external-beam radiotherapy (EBRT) is nonlinear with the biological effect imparted to cancer cells and neighboring healthy tissues. This oftentimes leads to insufficient damage to cancer cells and excessive damage to the surrounding healthy tissues, both increasing toxicity and the risk of cancer recurrence later in life for many patients. An understanding of X-ray energy deposition at the single-X-ray level is, therefore, necessary to improve the efficacy of cancer radiotherapy. Here, we present a single-X-ray sensitive, energy-binning integrated circuit (IC)-based dosimeter, fabricated in 180 nm CMOS technology, to enable closed-loop cancer radiotherapy for personalized patient treatment. We use small 3 $\times$ 3 $\mu$m reverse-biased deep n-well (DNWELL) diodes designed at low capacitive nodes (C$_{\mathrm{diode}}$), such that the miniscule charge deposition (Q$_{\mathrm{dep}}$) from single X-rays at these nodes generates a voltage signal large enough to be sensed (V$_{\mathrm{diode}}$ = Q$_{\mathrm{dep}}$/C$_{\mathrm{diode}}$). In order to enable single-X-ray energy resolution without significant power and area, we implement an analog voltage supply (AVDDH) $\sim$log resistor grid to create a sensitivity gradient across the 76 $\times$ 55 pixel array. The IC-based dosimeter was tested under scenarios consistent with the treatment of shallow lesions (e.g., skin cancer, superficial tumors, intraoperative radiotherapy). The system is highly linear with radiation dose (10–250 cGy) and accurately tracks dose up to 2 cm deep in tissue for 50-, 70-, and 100-kV X-ray beams.","Lall, Rahul, Lee, Kyoungtae, Cunha, Adam, Abergel, Rebecca, Seo, Youngho, Niknejad, Ali M., Anwar, Mekhail",,,Single-X-Ray Sensitive Energy-Binning Dosimeter for Closed-Loop Cancer External-Beam Radiotherapy,,,10.1109/JSSC.2025.3529848 , ,,"X-ray radiation dose delivered during cancer external-beam radiotherapy (EBRT) is nonlinear with the biological effect imparted to cancer cells and neighboring healthy tissues. This oftentimes leads to insufficient damage to cancer cells and excessive damage to the surrounding healthy tissues, both increasing toxicity and the risk of cancer recurrence later in life for many patients. An understanding of X-ray energy deposition at the single-X-ray level is, therefore, necessary to improve the efficacy of cancer radiotherapy. Here, we present a single-X-ray sensitive, energy-binning integrated circuit (IC)-based dosimeter, fabricated in 180 nm CMOS technology, to enable closed-loop cancer radiotherapy for personalized patient treatment. We use small 3 $\times$ 3 $\mu$m reverse-biased deep n-well (DNWELL) diodes designed at low capacitive nodes (C$_{\mathrm{diode}}$), such that the miniscule charge deposition (Q$_{\mathrm{dep}}$) from single X-rays at these nodes generates a voltage signal large enough to be sensed (V$_{\mathrm{diode}}$ = Q$_{\mathrm{dep}}$/C$_{\mathrm{diode}}$). In order to enable single-X-ray energy resolution without significant power and area, we implement an analog voltage supply (AVDDH) $\sim$log resistor grid to create a sensitivity gradient across the 76 $\times$ 55 pixel array. The IC-based dosimeter was tested under scenarios consistent with the treatment of shallow lesions (e.g., skin cancer, superficial tumors, intraoperative radiotherapy). The system is highly linear with radiation dose (10–250 cGy) and accurately tracks dose up to 2 cm deep in tissue for 50-, 70-, and 100-kV X-ray beams.",,,,, ,  ,Cancer;Radiation therapy;Photonics;Energy resolution;Electrons;Uncertainty;Scattering;Energy measurement;Detectors;Biological tissues;X-ray;dosimeter;cancer;radiotherapy;closed-loop,out_of_scope,
3010,"**Title**Highly Selective and Sensitive Ag-Based Hydrogen Sulfide Gas Sensor Based on Precise Chip Temperature Management

**Abstract**Hydrogen sulfide (H2S) detection with a high selectivity and fast response is necessary due to its strong toxicity both to the environment and humans. In this article, we present design, fabrication, and characterization of a Silver (Ag)-based H2S gas sensor, in which the temperature uniformity of sensitive materials has an important effect on their detection sensitivity, selectivity and reliability. Therefore, we introduce a new type of micro-hotplate chip design with an isothermal hot area (\pm 15 °C at 350 °C) accounts for 90% of the total heating area of the sensor, effectively resolving the issue of area uniform heating in gas sensor design. Results show that a response time for 100 ppm H2S is around 2 s under 350 °C operating temperature, and the limit of detection (LOD) is 134 parts-per-billion (ppb) in ambient conditions. Moreover, selectivity tests indicate that the sensor has poor response to interfering analytes such as hydrogen, methane, carbon monoxide, ammonia, and sulfur dioxide, and their average selectivity coefficients of H2S are greater than 88. This Ag-based H2S sensor offers advantages such as remarkable potential for mass production due to its easy to manufacture and high performance.","Tian, Xin, Tao, Jifang, Xu, Maosen, Yuan, Hongye, Zhao, Jia",,,Highly Selective and Sensitive Ag-Based Hydrogen Sulfide Gas Sensor Based on Precise Chip Temperature Management,,,10.1109/TED.2024.3384138 , ,,"Hydrogen sulfide (H2S) detection with a high selectivity and fast response is necessary due to its strong toxicity both to the environment and humans. In this article, we present design, fabrication, and characterization of a Silver (Ag)-based H2S gas sensor, in which the temperature uniformity of sensitive materials has an important effect on their detection sensitivity, selectivity and reliability. Therefore, we introduce a new type of micro-hotplate chip design with an isothermal hot area (\pm 15 °C at 350 °C) accounts for 90% of the total heating area of the sensor, effectively resolving the issue of area uniform heating in gas sensor design. Results show that a response time for 100 ppm H2S is around 2 s under 350 °C operating temperature, and the limit of detection (LOD) is 134 parts-per-billion (ppb) in ambient conditions. Moreover, selectivity tests indicate that the sensor has poor response to interfering analytes such as hydrogen, methane, carbon monoxide, ammonia, and sulfur dioxide, and their average selectivity coefficients of H2S are greater than 88. This Ag-based H2S sensor offers advantages such as remarkable potential for mass production due to its easy to manufacture and high performance.",,,,, ,  ,Heating systems;Temperature sensors;Sensors;Gas detectors;Temperature distribution;Electrodes;Silver;Fast response;gas sensor;hydrogen sulfide (H₂S);low limit of detection (LOD);ultrahigh selectivity,out_of_scope,
3011,"**Title**Challenges and Opportunities in Cold Atmospheric Plasma Based (CAP) Based Fluorine Generation

**Abstract**Despite its high reactivity and toxicity requiring exceptional safety measures, fluorine gas plays a critical role in numerous industries. From intricate microchip fabrication in the semiconductor industry to strengthening tooth enamel in dentistry, its unique properties find diverse applications. However, storing high-pressure fluorine tanks poses significant safety risks. Cold atmospheric plasma (CAP) offers a promising alternative by generating fluorine on-demand, eliminating storage needs and minimizing human contact, while simultaneously presenting its own advantages for various fields. This shift towards safer, controlled generation methods like CAP paves the way for further unlocking fluorine’s immense potential across various sectors. A 2 MHz, six-electrode cold atmospheric plasma (CAP) device was designed and fabricated to generate fluorine from an Ar + CF4 gas mixture. Visual observation revealed a two-toned plasma flame, suggesting spatial variation in species distribution. Fluorine emission was confirmed using a Portasens III detector, while further analysis by optical emission spectroscopy (OES) revealed the presence of strong Fe I emission lines alongside other species of atmosphere and Ar I emission lines. Correlating OES findings with experimental data indicated that generated fluorine preferentially attacks the SS 304 CAP electrodes, hindering effective substrate etching. This study highlights the need for optimized CAP designs to minimize electrode etching and maximize fluorine utilization for efficient substrate treatment.","Kar, R., Bende, V., Sekar, V., Bhardwaj, R., Mascarenhas, M., Sharma, A.",,,Challenges and Opportunities in Cold Atmospheric Plasma Based (CAP) Based Fluorine Generation,,,10.1109/ICOPS58192.2024.10627347 , ,,"Despite its high reactivity and toxicity requiring exceptional safety measures, fluorine gas plays a critical role in numerous industries. From intricate microchip fabrication in the semiconductor industry to strengthening tooth enamel in dentistry, its unique properties find diverse applications. However, storing high-pressure fluorine tanks poses significant safety risks. Cold atmospheric plasma (CAP) offers a promising alternative by generating fluorine on-demand, eliminating storage needs and minimizing human contact, while simultaneously presenting its own advantages for various fields. This shift towards safer, controlled generation methods like CAP paves the way for further unlocking fluorine’s immense potential across various sectors. A 2 MHz, six-electrode cold atmospheric plasma (CAP) device was designed and fabricated to generate fluorine from an Ar + CF4 gas mixture. Visual observation revealed a two-toned plasma flame, suggesting spatial variation in species distribution. Fluorine emission was confirmed using a Portasens III detector, while further analysis by optical emission spectroscopy (OES) revealed the presence of strong Fe I emission lines alongside other species of atmosphere and Ar I emission lines. Correlating OES findings with experimental data indicated that generated fluorine preferentially attacks the SS 304 CAP electrodes, hindering effective substrate etching. This study highlights the need for optimized CAP designs to minimize electrode etching and maximize fluorine utilization for efficient substrate treatment.",,,,, ,  2024 IEEE International Conference on Plasma Science (ICOPS),Electrodes;Visualization;Toxicology;Atmospheric measurements;Fluorine;Teeth;Etching,out_of_scope,
3012,"**Title**Study of a Lead-Free Perovskite MA3Bi2Br9 Narrowband Photodetector for Blue-Light Detection

**Abstract**Narrowband photodetection is crucial for various applications, including machine vision, bioimaging, and environmental monitoring. While lead-based perovskites offer promising properties, their toxicity and instability limit their practical applications. Here, we report a high-performance narrowband photodetector (PD) based on lead-free perovskite MA3Bi2Br9 single crystal. By employing the charge collection narrowing (CCN) mechanism, we realized a device exhibiting a pronounced peak response centered at 470 nm, characterized by a narrow full-width at half-maximum (FWHM) of merely 24 nm. The detector exhibits a high responsivity of 0.102 mA/W and a specific detectivity of 2.21 × 108 Jones at 15 V bias. Additionally, it demonstrates a high spectral rejection ratio (SRR) of 34 for 470-nm light relative to 510-nm light. To quantify blue-light hazards, we established a numerical relationship between weighted irradiance and photocurrent. Our results highlight the potential of lead-free perovskite-based PDs for practical applications in narrowband detection and environmental monitoring.","Wu, Zhi-Cheng, Liu, Jia, Lu, Xiu-Dong, Wang, Jiang, Huang, Zhi-Yu, Zhu, Zhi-Guo, Wang, Cong-Cong, Wang, Yan, Liang, Feng-Xia, Luo, Lin-Bao",,,Study of a Lead-Free Perovskite MA3Bi2Br9 Narrowband Photodetector for Blue-Light Detection,,,10.1109/TED.2025.3538740 , ,,"Narrowband photodetection is crucial for various applications, including machine vision, bioimaging, and environmental monitoring. While lead-based perovskites offer promising properties, their toxicity and instability limit their practical applications. Here, we report a high-performance narrowband photodetector (PD) based on lead-free perovskite MA3Bi2Br9 single crystal. By employing the charge collection narrowing (CCN) mechanism, we realized a device exhibiting a pronounced peak response centered at 470 nm, characterized by a narrow full-width at half-maximum (FWHM) of merely 24 nm. The detector exhibits a high responsivity of 0.102 mA/W and a specific detectivity of 2.21 × 108 Jones at 15 V bias. Additionally, it demonstrates a high spectral rejection ratio (SRR) of 34 for 470-nm light relative to 510-nm light. To quantify blue-light hazards, we established a numerical relationship between weighted irradiance and photocurrent. Our results highlight the potential of lead-free perovskite-based PDs for practical applications in narrowband detection and environmental monitoring.",,,,, ,  ,Crystals;Narrowband;Perovskites;Absorption;Photoconductivity;Lead;Evaporation;Lighting;Photonics;Photonic band gap;Blue-light detection;charge collection narrowing (CCN);lead-free perovskite;narrowband detection,out_of_scope,
3013,"**Title**Functionalized Carbon Nanomaterials for Impending Pharmaceutical Applications: A Green and Sustainable Vision

**Abstract**Summary <p>Nanomaterials have unique properties and features because of their small size. Functionalized carbon nanomaterials have exceptional and unique properties for diverse applications. They are used in pharmaceuticals, specifically in analyzing and curing malevolent cells, infectious diseases, tissue engineering, and disorders in the central nervous system. These types of unique features are beneficial to infiltrate biomembranes and decrease their toxicity.</p> <p>This chapter recapitulates several pharmaceutical applications of nanomaterials for the healings of numerous diseases. In this chapter, CNTs will be functionalized into covalent and noncovalent functionalized CNTs. Its potential applications in treating difficult issues in pharmacy and connected risks in nanodrugs will also be discussed. There is wide use of CNTs in the various field like water treatment, environmental remediation, batteries, supercapacitor, electric cable and wire, textile, solar cell, microelectronic, optical power detector pharmacy, and medicine because CNTs have large surface areas and adsorbing capacity. It is substantially important for the local and worldwide conspirators while providing ecological remedial measures.</p>","Kumar, Vaneet, Saruchi, Kumar, Harsh",,,Functionalized Carbon Nanomaterials for Impending Pharmaceutical Applications: A Green and Sustainable Vision,,,10.1002/9783527830978.ch18 , ,,"Summary <p>Nanomaterials have unique properties and features because of their small size. Functionalized carbon nanomaterials have exceptional and unique properties for diverse applications. They are used in pharmaceuticals, specifically in analyzing and curing malevolent cells, infectious diseases, tissue engineering, and disorders in the central nervous system. These types of unique features are beneficial to infiltrate biomembranes and decrease their toxicity.</p> <p>This chapter recapitulates several pharmaceutical applications of nanomaterials for the healings of numerous diseases. In this chapter, CNTs will be functionalized into covalent and noncovalent functionalized CNTs. Its potential applications in treating difficult issues in pharmacy and connected risks in nanodrugs will also be discussed. There is wide use of CNTs in the various field like water treatment, environmental remediation, batteries, supercapacitor, electric cable and wire, textile, solar cell, microelectronic, optical power detector pharmacy, and medicine because CNTs have large surface areas and adsorbing capacity. It is substantially important for the local and worldwide conspirators while providing ecological remedial measures.</p>",,,,, ,  Environmental Applications of Carbon Nanomaterials-Based Devices,Drugs;Carbon;Surface treatment;Carbon nanotubes;Medical diagnostic imaging;Drug delivery;Biomedical imaging,out_of_scope,
3014,"**Title**DeTox: A WebApp for Toxic Comment Detection and Moderation

**Abstract**The extensive adoption of internet platforms such as YouTube has transformed communication and information exchange, compelling people to share their opinions and participate in global conversations. Open communication can, however, also encourage the spread of offensive material, such as remarks that are derogatory or involve threats or hate speech. Such offensive remarks have the potential to damage users' mental health by fostering a hostile and unsafe environment that discourages meaningful relationships. We introduce DeTox, a web application that uses machine learning techniques to detect and eliminate harmful comments from YouTube videos in order to address this problem. For the purpose of classifying comments, DeTox uses ML and DL models, which guarantees precise identification of harmful content. The YouTube Data API is integrated by the system to retrieve comments from specific videos and eliminate any harmful remarks found. A detailed examination of the Toxic Comment Classification Challenge dataset, made available by Kaggle, was necessary for the development of DeTox. To find common patterns in hazardous language, preprocessing and examination of the data were done in order to examine the distribution of toxic and non-toxic remarks. FastAPI is a high-level Python web framework that makes web application development easier and is used by the DeTox online application. The application includes a user friendly interface for creating accounts, logging in, and selecting videos to moderate. The application also includes a user interface for reviewing toxic comments and choosing to remove or keep them. DeTox is a valuable tool for moderating comments on YouTube videos. The application utilizes a machine learning model to accurately identify toxic comments, and it provides a vi user-friendly interface for removing or keeping the comments. DeTox has the potential to make YouTube a more friendly and safe environment for users.","N, Prudhvish, G, Nagarajan, U, Bharath Kumar, Vardhan B, Harsha, L, Tharun Kumar",,,DeTox: A WebApp for Toxic Comment Detection and Moderation,,,10.1109/TQCEBT59414.2024.10545229 , ,,"The extensive adoption of internet platforms such as YouTube has transformed communication and information exchange, compelling people to share their opinions and participate in global conversations. Open communication can, however, also encourage the spread of offensive material, such as remarks that are derogatory or involve threats or hate speech. Such offensive remarks have the potential to damage users' mental health by fostering a hostile and unsafe environment that discourages meaningful relationships. We introduce DeTox, a web application that uses machine learning techniques to detect and eliminate harmful comments from YouTube videos in order to address this problem. For the purpose of classifying comments, DeTox uses ML and DL models, which guarantees precise identification of harmful content. The YouTube Data API is integrated by the system to retrieve comments from specific videos and eliminate any harmful remarks found. A detailed examination of the Toxic Comment Classification Challenge dataset, made available by Kaggle, was necessary for the development of DeTox. To find common patterns in hazardous language, preprocessing and examination of the data were done in order to examine the distribution of toxic and non-toxic remarks. FastAPI is a high-level Python web framework that makes web application development easier and is used by the DeTox online application. The application includes a user friendly interface for creating accounts, logging in, and selecting videos to moderate. The application also includes a user interface for reviewing toxic comments and choosing to remove or keep them. DeTox is a valuable tool for moderating comments on YouTube videos. The application utilizes a machine learning model to accurately identify toxic comments, and it provides a vi user-friendly interface for removing or keeping the comments. DeTox has the potential to make YouTube a more friendly and safe environment for users.",,,,, ,  2024 International Conference on Trends in Quantum Computing and Emerging Business Technologies,Video on demand;Web page design;Web pages;Machine learning;User interfaces;Solids;Real-time systems;Toxic comments;Machine Learning;API;YOUTUBE;BERT,detection,
3015,"**Title**Exploring the Distinctive Tweeting Patterns of Toxic Twitter Users

**Abstract**In the pursuit of bolstering user safety, social media platforms deploy active moderation strategies, including content removal and user suspension. These measures target users engaged in discussions marked by hate speech or toxicity, often linked to specific keywords or hashtags. Nonetheless, the increasing prevalence of toxicity indicates that certain users adeptly circumvent these measures.This study examines consistently toxic users on Twitter (rebranded as X) Rather than relying on traditional methods based on specific topics or hashtags, we employ a novel approach based on patterns of toxic tweets, yielding deeper insights into their behavior.We analyzed 38 million tweets from the timelines of 12,148 Twitter users and identified the top 1,457 users who consistently exhibit toxic behavior, relying on metrics like the Gini index and Toxicity score. By comparing their posting patterns to those of non-consistently toxic users, we have uncovered distinctive temporal patterns, including contiguous activity spans, inter-tweet intervals (referred to as “Burstiness”), and churn analysis. These findings provide strong evidence for the existence of a unique tweeting pattern associated with toxic behavior on Twitter.Crucially, our methodology transcends Twitter and can be adapted to various social media platforms, facilitating the identification of consistently toxic users based on their posting behavior. This research contributes to ongoing efforts to combat online toxicity and offers insights for refining moderation strategies in the digital realm. We are committed to open research and will provide our code and data to the research community.","Qayyum, Hina, Ikram, Muhammad, Zhao, Benjamin Zi Hao, Wood, Ian D., Kourtellis, Nicolas, Kaafar, Mohamed Ali",,,Exploring the Distinctive Tweeting Patterns of Toxic Twitter Users,,,10.1109/BigData59044.2023.10386402 , ,,"In the pursuit of bolstering user safety, social media platforms deploy active moderation strategies, including content removal and user suspension. These measures target users engaged in discussions marked by hate speech or toxicity, often linked to specific keywords or hashtags. Nonetheless, the increasing prevalence of toxicity indicates that certain users adeptly circumvent these measures.This study examines consistently toxic users on Twitter (rebranded as X) Rather than relying on traditional methods based on specific topics or hashtags, we employ a novel approach based on patterns of toxic tweets, yielding deeper insights into their behavior.We analyzed 38 million tweets from the timelines of 12,148 Twitter users and identified the top 1,457 users who consistently exhibit toxic behavior, relying on metrics like the Gini index and Toxicity score. By comparing their posting patterns to those of non-consistently toxic users, we have uncovered distinctive temporal patterns, including contiguous activity spans, inter-tweet intervals (referred to as “Burstiness”), and churn analysis. These findings provide strong evidence for the existence of a unique tweeting pattern associated with toxic behavior on Twitter.Crucially, our methodology transcends Twitter and can be adapted to various social media platforms, facilitating the identification of consistently toxic users based on their posting behavior. This research contributes to ongoing efforts to combat online toxicity and offers insights for refining moderation strategies in the digital realm. We are committed to open research and will provide our code and data to the research community.",,,,, ,  2023 IEEE International Conference on Big Data (BigData),Measurement;Toxicology;Codes;Social networking (online);Blogs;Refining;Hate speech;Social media;toxicity;tweeting pattern;temporal analysis,methodology,
3016,"**Title**Domain Specific Embeddings in RNN Frameworks for Hate Span Detection and Classification

**Abstract**The unrestricted use of the internet has led to a significant rise in the dissemination of hate speech online, posing serious threats of harm and violence to individuals and society at large. Social media data often comprises informal and fragmented sentences, interspersed with multiple languages. While numerous researchers are dedicated to identifying and mitigating hate speech in social media content, existing approaches primarily focus on detecting hate speech as a whole, rather than targeting specific hateful words or phrases. To encourage research in this direction, a shared task was formulated during SemEval 2021, a task called Toxic Span Identification, to detect hateful words present in a sentence. Leveraging the dataset provided by the organizers of the task, our approach entails constructing a model comprising three fundamental layers: feature extraction, a Bidirectional Long Short-Term Memory (BiLSTM) layer, and at last, a Conditional Random Field (CRF) layer. Among various embedding techniques, we found that GloVe embeddings yielded superior results with our base model, achieving an F1 score of ${6 1. 2 3 \%}$ when combined with dropout layer. Further Toxic BERT and HateBERT models were used to classify the comments as hateful or non-hateful, HateBERT outperformed the Toxic BERT model.","Rachh, Rashmi, Kavatagi, Sanjana, Allagi, Shridhar",,,Domain Specific Embeddings in RNN Frameworks for Hate Span Detection and Classification,,,10.1109/CONIT61985.2024.10626508 , ,,"The unrestricted use of the internet has led to a significant rise in the dissemination of hate speech online, posing serious threats of harm and violence to individuals and society at large. Social media data often comprises informal and fragmented sentences, interspersed with multiple languages. While numerous researchers are dedicated to identifying and mitigating hate speech in social media content, existing approaches primarily focus on detecting hate speech as a whole, rather than targeting specific hateful words or phrases. To encourage research in this direction, a shared task was formulated during SemEval 2021, a task called Toxic Span Identification, to detect hateful words present in a sentence. Leveraging the dataset provided by the organizers of the task, our approach entails constructing a model comprising three fundamental layers: feature extraction, a Bidirectional Long Short-Term Memory (BiLSTM) layer, and at last, a Conditional Random Field (CRF) layer. Among various embedding techniques, we found that GloVe embeddings yielded superior results with our base model, achieving an F1 score of ${6 1. 2 3 \%}$ when combined with dropout layer. Further Toxic BERT and HateBERT models were used to classify the comments as hateful or non-hateful, HateBERT outperformed the Toxic BERT model.",,,,, ,  2024 4th International Conference on Intelligent Technologies (CONIT),Recurrent neural networks;Social networking (online);Hate speech;Bidirectional control;Feature extraction;Encoding;Conditional random fields;GloVe;hatespans;HateBERT;ToxicBERT;BiLSTM;CRF,detection,
3017,"**Title**Gas Spectroscopy System for Breath Analysis at mm-wave/THz Using SiGe BiCMOS Circuits

**Abstract**The unique fingerprint spectra of volatile organic compounds for breath analysis and toxic industrial chemicals make an mm-wave (mmW)/THz gas sensor very specific and sensitive. This paper reviews and updates results of our recent work on sensor systems for gas spectroscopy based on integrated transmitter (TX) and receiver (RX), which are developed and fabricated in IHP's 0.13 μm SiGe BiCMOS technology. In this paper, we present an mmW/THz spectroscopic system including a folded gas absorption cell of 1.9 m length between the TX and RX modules. We discuss the results and specifications of our sensor system based on integrated TX and RX. We demonstrate TXs and RXs with integrated antennas for spectroscopy at 238-252 GHz and 494-500 GHz using integer-N phase-locked loops (PLLs). We present a compact system by using fractional-N PLLs allowing frequency ramps for the TX and RX, and for TX with superimposed frequency shift keying or reference frequency modulation. In another configuration, the voltage controlled oscillators of the TX and RX local oscillator are tuned directly without PLLs by applying external voltages. Further developments of our system are aimed at realizing an even wider frequency span by switching between frequency bands, and to use a more compact gas absorption cell.","Schmalz, Klaus, Rothbart, Nick, Neumaier, Philipp F.-X., Borngräber, Johannes, Hübers, Heinz-Wilhelm, Kissinger, Dietmar",,,Gas Spectroscopy System for Breath Analysis at mm-wave/THz Using SiGe BiCMOS Circuits,,,10.1109/TMTT.2017.2650915 , ,,"The unique fingerprint spectra of volatile organic compounds for breath analysis and toxic industrial chemicals make an mm-wave (mmW)/THz gas sensor very specific and sensitive. This paper reviews and updates results of our recent work on sensor systems for gas spectroscopy based on integrated transmitter (TX) and receiver (RX), which are developed and fabricated in IHP's 0.13 μm SiGe BiCMOS technology. In this paper, we present an mmW/THz spectroscopic system including a folded gas absorption cell of 1.9 m length between the TX and RX modules. We discuss the results and specifications of our sensor system based on integrated TX and RX. We demonstrate TXs and RXs with integrated antennas for spectroscopy at 238-252 GHz and 494-500 GHz using integer-N phase-locked loops (PLLs). We present a compact system by using fractional-N PLLs allowing frequency ramps for the TX and RX, and for TX with superimposed frequency shift keying or reference frequency modulation. In another configuration, the voltage controlled oscillators of the TX and RX local oscillator are tuned directly without PLLs by applying external voltages. Further developments of our system are aimed at realizing an even wider frequency span by switching between frequency bands, and to use a more compact gas absorption cell.",,,,, ,  ,Spectroscopy;Absorption;Frequency shift keying;Phase locked loops;Detectors;Silicon germanium;Gas spectroscopy;mm-wave (mmW);receiver;sensor;SiGe;terahertz (THz);transmitter,out_of_scope,
3018,"**Title**META: Text Detoxification by leveraging METAmorphic Relations and Deep Learning Methods

**Abstract**In the world of online interactions, social communities face a significant challenge: the spread of offensive content and hate speech through toxic languages. Such issues led to growing research on text detoxification systems that can automatically rewrite toxic content. A systematic evaluation is required to ensure these systems produce high-quality detoxified text that modifies the original text to be non-toxic while preserving its content. However, this often relies on large amounts of labelled data and human judgement, which may not always be feasible. This limitation is typically known as the oracle problem. Metamorphic testing (MT) has conventionally been used to solve the oracle problem by deriving metamorphic relations (MRs) to test a program’s functionality. A new MT approach focused on data validation showed that MRs incorporated with tools can be used to identify defects in machine translation services. This paper draws inspiration from this new MT perspective by presenting four metamorphic relations incorporated with tools to evaluate style transfer accuracy, content preservation, fluency, and a joint of these three. Our proposed approach effectively identifies defective behaviour in state-of-the-art text detoxification systems.","Choo, Alika, Pal, Arghya, Rajanala, Sailaja, Sen, Arkendu",,,META: Text Detoxification by leveraging METAmorphic Relations and Deep Learning Methods,,,10.1109/APSIPAASC63619.2025.10848645 , ,,"In the world of online interactions, social communities face a significant challenge: the spread of offensive content and hate speech through toxic languages. Such issues led to growing research on text detoxification systems that can automatically rewrite toxic content. A systematic evaluation is required to ensure these systems produce high-quality detoxified text that modifies the original text to be non-toxic while preserving its content. However, this often relies on large amounts of labelled data and human judgement, which may not always be feasible. This limitation is typically known as the oracle problem. Metamorphic testing (MT) has conventionally been used to solve the oracle problem by deriving metamorphic relations (MRs) to test a program’s functionality. A new MT approach focused on data validation showed that MRs incorporated with tools can be used to identify defects in machine translation services. This paper draws inspiration from this new MT perspective by presenting four metamorphic relations incorporated with tools to evaluate style transfer accuracy, content preservation, fluency, and a joint of these three. Our proposed approach effectively identifies defective behaviour in state-of-the-art text detoxification systems.",,,,, ,  2024 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC),Deep learning;Systematics;Accuracy;Hate speech;Asia;Information processing;Robustness;Machine translation;Faces;Testing,detox,
3019,"**Title**Comparative Evaluation and Data Analysis for Drug Toxicity Prediction

**Abstract**Throughout the entire drug development process, toxicity prediction is a significant process in assessing the possible toxicity of drugs. Recently, there has been active research on estimating drug toxicity using deep learning techniques. However, challenges such as a lack of labeled data and the insufficient reliable benchmark datasets remain major obstacles. To address these challenges, this study analyzes and compares seven toxicity benchmark datasets from the Therapeutics Data Commons and three external literature datasets. Experimental results demonstrated that deep learning methods showed superior performance on the benchmark datasets. In particular, on the ClinTox dataset, deep learning models outperformed conventional machine learning methods by 5.5%. The results confirm that employing self-supervised learning effectively mitigates the data limitation problem. Additionally, it was validated that using graph representation learning and natural language processing effectively handles chemical structures as drug features.","Chu, Jae-Woo, Cho, Young-Rae",,,Comparative Evaluation and Data Analysis for Drug Toxicity Prediction,,,10.1109/BIBM62325.2024.10822082 , ,,"Throughout the entire drug development process, toxicity prediction is a significant process in assessing the possible toxicity of drugs. Recently, there has been active research on estimating drug toxicity using deep learning techniques. However, challenges such as a lack of labeled data and the insufficient reliable benchmark datasets remain major obstacles. To address these challenges, this study analyzes and compares seven toxicity benchmark datasets from the Therapeutics Data Commons and three external literature datasets. Experimental results demonstrated that deep learning methods showed superior performance on the benchmark datasets. In particular, on the ClinTox dataset, deep learning models outperformed conventional machine learning methods by 5.5%. The results confirm that employing self-supervised learning effectively mitigates the data limitation problem. Additionally, it was validated that using graph representation learning and natural language processing effectively handles chemical structures as drug features.",,,,, ,  2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Drugs;Deep learning;Representation learning;Toxicology;Self-supervised learning;Benchmark testing;Transformers;Skin;Natural language processing;Reliability;Drug Toxicity Prediction;Machine Learning;Deep Learning;Self-Supervised Learning,out_of_scope,
3020,"**Title**Dose Aware Toxicity Prediction in Head and Neck Cancer Patients Using a Deformable 3D CNN on Daily CBCT Acquisitions

**Abstract**With recent advancements in intensity-modulated radiotherapy and image guidance for cancer treatment, there is growing interest in Deep Learning-based Adaptive Radiotherapy due to its potential to mitigate radiation toxicity. During the course of treatment, daily acquisitions of cone beam computed tomography (CBCT) allows to monitor significant anatomical changes around the tumour target area and the response to treatment. Previous works have demonstrated the benefits of using anatomical deformation features as predictors of early toxicities. The objective of this work is to investigate the use of radiomic distributions to predict early reactive na-sogastric tubing (NG tube), radionecrosis and broad hospitalisation based on initial dosimetry plans. We propose a method combining inter-fractional anatomical deformation, dosimetry and clinical information to improve the prediction performance. For this work we implement a deformable registration pipeline and train a 3D convo-lutional neural network model on the Jacobian determinants of the deformation vector fields between different fractions of treatment. We exploit the dose plans as feature maps to focus the attention of the network on areas susceptible to radiation toxicity. We obtain balanced accuracy scores of 75.4% for radionecrosis at fraction 20,61.1% for hospitalisation after the first week of treatment and 74.1% for NG tube insertion after the 5th week.","Henique, Gautier, Bang, Chulmin, Markel, Daniel, Le, William, Filion, Edith, Ngyuen-Tan, Phuc Felix, Bahig, Houda, Kadoury, Samuel",,,Dose Aware Toxicity Prediction in Head and Neck Cancer Patients Using a Deformable 3D CNN on Daily CBCT Acquisitions,,,10.1109/ISBI56570.2024.10635238 , ,,"With recent advancements in intensity-modulated radiotherapy and image guidance for cancer treatment, there is growing interest in Deep Learning-based Adaptive Radiotherapy due to its potential to mitigate radiation toxicity. During the course of treatment, daily acquisitions of cone beam computed tomography (CBCT) allows to monitor significant anatomical changes around the tumour target area and the response to treatment. Previous works have demonstrated the benefits of using anatomical deformation features as predictors of early toxicities. The objective of this work is to investigate the use of radiomic distributions to predict early reactive na-sogastric tubing (NG tube), radionecrosis and broad hospitalisation based on initial dosimetry plans. We propose a method combining inter-fractional anatomical deformation, dosimetry and clinical information to improve the prediction performance. For this work we implement a deformable registration pipeline and train a 3D convo-lutional neural network model on the Jacobian determinants of the deformation vector fields between different fractions of treatment. We exploit the dose plans as feature maps to focus the attention of the network on areas susceptible to radiation toxicity. We obtain balanced accuracy scores of 75.4% for radionecrosis at fraction 20,61.1% for hospitalisation after the first week of treatment and 74.1% for NG tube insertion after the 5th week.",,,,, ,  2024 IEEE International Symposium on Biomedical Imaging (ISBI),Solid modeling;Toxicology;Three-dimensional displays;Head;Deformation;Radiation therapy;Neck;3D CNN;Toxicity Prediction;Head and Neck Cancer;Dosimetry;CBCT;Deformable image registration,out_of_scope,
3021,"**Title**Study of Deep Learning Techniques for Real-Time Online censorship using Comment Toxicity Detection

**Abstract**In an era where our online interactions are integral to our daily lives, addressing and mitigating online toxicity is crucial. This study, titled ""Comment Toxicity Detection,"" aims to significantly advance ongoing efforts in this area. Our objective is to protect user welfare and encourage positive online interactions. This research addresses the urgent issue of online toxicity and its negative impact on user interactions and well-being. We explore various data sources and employ advanced feature engineering techniques such as BERT and its derivatives like m-BERT and MURIL BERT. By integrating these methods with various deep learning classifiers, we enhance our collective efforts to curb the spread of harmful content in digital spaces. We utilized an English dataset extracted from a larger multilingual corpus and preprocessed it using count vectorization for classification tasks. The evaluation metrics indicated a recall of 0.7103 and a precision of 0.7997. Our classification model used a Deep LSTM architecture with a batch size of 17. We are currently investigating the potential improvements in our data representation by incorporating a BERT-based model. This investigation is essential to optimize our classification performance, and the results should clarify the best practices for using advanced language representations to improve classification accuracy.","Sugandh, Sarvesh, Shewalkar, Aditya, Singh, Anurag, Attarde, Sakshi, Jakhete, Sumitra A.",,,Study of Deep Learning Techniques for Real-Time Online censorship using Comment Toxicity Detection,,,10.1109/MITADTSoCiCon60330.2024.10575395 , ,,"In an era where our online interactions are integral to our daily lives, addressing and mitigating online toxicity is crucial. This study, titled ""Comment Toxicity Detection,"" aims to significantly advance ongoing efforts in this area. Our objective is to protect user welfare and encourage positive online interactions. This research addresses the urgent issue of online toxicity and its negative impact on user interactions and well-being. We explore various data sources and employ advanced feature engineering techniques such as BERT and its derivatives like m-BERT and MURIL BERT. By integrating these methods with various deep learning classifiers, we enhance our collective efforts to curb the spread of harmful content in digital spaces. We utilized an English dataset extracted from a larger multilingual corpus and preprocessed it using count vectorization for classification tasks. The evaluation metrics indicated a recall of 0.7103 and a precision of 0.7997. Our classification model used a Deep LSTM architecture with a batch size of 17. We are currently investigating the potential improvements in our data representation by incorporating a BERT-based model. This investigation is essential to optimize our classification performance, and the results should clarify the best practices for using advanced language representations to improve classification accuracy.",,,,, ,"  2024 MIT Art, Design and Technology School of Computing International Conference (MITADTSoCiCon)",Deep learning;Measurement;Toxicology;Soft sensors;Computer architecture;Feature extraction;Real-time systems;Online Toxicity;Digital Interactions;Feature Engineering;BERT;MURIL BERT;m-BERT;Deep Learning Classifiers;Content Moderation;Online Safety;User-Generated Content,detection,
3022,"**Title**Impact of Turmeric-Based Diet and Its Aqueous Extract on Rats Treated with Alloxan for Alkaline Phosphatase and Aspartate Aminotransferase Levels

**Abstract**Alloxan has been well-documented as a trigger for experimental diabetes, which may be associated with impaired liver function, organ toxicity, and damage, among other effects. In this study, how a diet containing turmeric and its extract affected the liver, kidney, heart, and serum of rats treated with alloxan was examined. The impacts were evaluated by measuring the levels of alkaline phosphatase and alanine aminotransferase in those organs mentioned earlier. Forty female albino rats were divided randomly into five groups (A, B, C, D, and E) each containing five rats. Groups A, C, and E received a diet containing 5% turmeric formulation. Group B was fed a basal diet, while groups D and E received daily oral administration of 10% turmeric crude extract. The dietary study continued for 21 days, following which all groups aside from group A received an induction of 150 mg/kg body weight of alloxan and were then monitored for 48 hours. The Blood glucose levels of each rat were determined using a glucometer. Administration of alloxan led to detrimental effects on the functions of certain organs, including the liver, heart, and plasma. This is supported by a notable elevation (P ≤ 0.05) in the levels of alkaline phosphatase (ALP) and aspartate aminotransferase (AST) enzymes in the group of rats induced with alloxan, in comparison to the normal control group. Pre-administration of a turmeric-formulated diet and extract to rats treated with alloxan mitigated the impact of alloxan on the activities of ALP and AST enzymes in the liver compared to rats treated with alloxan alone. This was demonstrated by the significant reduction in the activities of liver ALP and AST of rats in group B when compared with the control group (A). Also, there was a remarkable significant difference (p ≤ 0.05) in the activities of ALP and AST enzymes in group (E) compared with the negative control. Therefore, it can be concluded that a turmeric-formulated diet and extract might mitigate alloxan-induced toxicity in the experimental organs.","Oluwafemi, Adekemi G., Aluko, Bukola T., Acho, Marvellous A., Rotimi, Damilare E., Nwonuma, Charles, Akinduko, Ayokunmi",,,Impact of Turmeric-Based Diet and Its Aqueous Extract on Rats Treated with Alloxan for Alkaline Phosphatase and Aspartate Aminotransferase Levels,,,10.1109/SEB4SDG60871.2024.10629897 , ,,"Alloxan has been well-documented as a trigger for experimental diabetes, which may be associated with impaired liver function, organ toxicity, and damage, among other effects. In this study, how a diet containing turmeric and its extract affected the liver, kidney, heart, and serum of rats treated with alloxan was examined. The impacts were evaluated by measuring the levels of alkaline phosphatase and alanine aminotransferase in those organs mentioned earlier. Forty female albino rats were divided randomly into five groups (A, B, C, D, and E) each containing five rats. Groups A, C, and E received a diet containing 5% turmeric formulation. Group B was fed a basal diet, while groups D and E received daily oral administration of 10% turmeric crude extract. The dietary study continued for 21 days, following which all groups aside from group A received an induction of 150 mg/kg body weight of alloxan and were then monitored for 48 hours. The Blood glucose levels of each rat were determined using a glucometer. Administration of alloxan led to detrimental effects on the functions of certain organs, including the liver, heart, and plasma. This is supported by a notable elevation (P ≤ 0.05) in the levels of alkaline phosphatase (ALP) and aspartate aminotransferase (AST) enzymes in the group of rats induced with alloxan, in comparison to the normal control group. Pre-administration of a turmeric-formulated diet and extract to rats treated with alloxan mitigated the impact of alloxan on the activities of ALP and AST enzymes in the liver compared to rats treated with alloxan alone. This was demonstrated by the significant reduction in the activities of liver ALP and AST of rats in group B when compared with the control group (A). Also, there was a remarkable significant difference (p ≤ 0.05) in the activities of ALP and AST enzymes in group (E) compared with the negative control. Therefore, it can be concluded that a turmeric-formulated diet and extract might mitigate alloxan-induced toxicity in the experimental organs.",,,,, ,"  2024 International Conference on Science, Engineering and Business for Driving Sustainable Development Goals (SEB4SDG)",Heart;Enzymes;Toxicology;Powders;Liver;Rats;Diabetes;Turmeric;Alloxan;Aspartate Aminotransferase;Alkaline Phosphatase;Toxicity,out_of_scope,
3023,"**Title**Prompt Evolution Through Examples for Large Language Models–A Case Study in Game Comment Toxicity Classification

**Abstract**This paper presents a novel approach for automatic prompt optimization (APO) using a large language model (LLM) as an optimizer, named Prompt Evolution Through Examples (PETE). The approach draws inspiration from evolutionary computation for the prompt evolution stages. We aim to aid in developing prompts for use in systems classifying toxic content including game community moderator-assist tools. While traditional approaches are useful for developing these tools, they have various shortcomings where LLMs can potentially mitigates these issues. LLMs accept prompts as inputs to condition generated outputs. However, to design a prompt with the best performance in this task, fine-grained adjustments are usually required and should be automated through the APO process instead of a manual approach, which is often time-consuming. In this study, ChatGPT and GPT-4 are utilized as both task performers and prompt optimizers for comparisons across models. The results indicate that PETE improves the performance of the target task up to 56.14% from a performance of an initial prompt, compared to only up to 49.15% using a standard mutation evolution. Optimized prompts are provided for future utilization in other game community moderation tools. We also recommend that future studies explore more cost-effective approaches for evaluation using LLMs to enhance the benefits of APO.","Taveekitworachai, Pittawat, Abdullah, Febri, Gursesli, Mustafa Can, Lanata, Antonio, Guazzini, Andrea, Thawonmas, Ruck",,,Prompt Evolution Through Examples for Large Language Models–A Case Study in Game Comment Toxicity Classification,,,10.1109/MetroInd4.0IoT61288.2024.10584130 , ,,"This paper presents a novel approach for automatic prompt optimization (APO) using a large language model (LLM) as an optimizer, named Prompt Evolution Through Examples (PETE). The approach draws inspiration from evolutionary computation for the prompt evolution stages. We aim to aid in developing prompts for use in systems classifying toxic content including game community moderator-assist tools. While traditional approaches are useful for developing these tools, they have various shortcomings where LLMs can potentially mitigates these issues. LLMs accept prompts as inputs to condition generated outputs. However, to design a prompt with the best performance in this task, fine-grained adjustments are usually required and should be automated through the APO process instead of a manual approach, which is often time-consuming. In this study, ChatGPT and GPT-4 are utilized as both task performers and prompt optimizers for comparisons across models. The results indicate that PETE improves the performance of the target task up to 56.14% from a performance of an initial prompt, compared to only up to 49.15% using a standard mutation evolution. Optimized prompts are provided for future utilization in other game community moderation tools. We also recommend that future studies explore more cost-effective approaches for evaluation using LLMs to enhance the benefits of APO.",,,,, ,  2024 IEEE International Workshop on Metrology for Industry 4.0 & IoT (MetroInd4.0 & IoT),Toxicology;Costs;Large language models;Computational modeling;Games;Manuals;Evolutionary computation;Evolutionary computation;Prompt engineering;ChatGPT;GPT-4;Errorful learning,detection,
3024,"**Title**A Graph-Based Approach to Mitigate Drug-Drug Interactions and Optimize Therapeutic Regimens

**Abstract**Drug-drug interactions (DDIs) pose a significant issue in modern healthcare, potentially compromising treatment efficacy and patient safety. DDIs arise when significant alterations occur in the pharmacological action of a drug due to its co-administration with another drug, leading to potential adverse drug reactions (ADRs), toxicity or diminished therapeutic efficacy. Apart from the obvious cases of drug combinations that should be avoided, there are instances where risk-benefit analysis may allow co-administration. Hence, DDIs may represent clinically significant cases depending on the clinical outcome, time point of administration, etc. The issue is especially critical in cases of patients with multimorbidity and complex therapeutic regimens with different time points in drug administrations. This work employs a graph-based approach aimed at optimizing therapeutic regiments while considering the minimization of DDIs potential. In this approach each drug is represented as a node, and edges represent the clinical significance of DDIs. We aim to identify sets of drugs that either have no DDIs or exhibit minor to moderate clinical significance (referred to as Maximal Independent Sets), indicating that they can be taken together. In practice, we solved the complementary problem, which is finding Maximal Cliques. Both problems are NP-hard, but for small graphs, they can be solved exactly. From all the cliques we identify, those selected to be a part of each proposed therapeutic regimen must consist of nodes that appear only once. This problem is once again reduced to clique finding. The above approach is demonstrated using two clinical scenarios involving two patients who are experiencing polypharmacy and are at risk for ADRs due to potential DDIs of varying clinical significance. By applying our approach, the therapeutic schemes are optimized towards minimizing the risk of ADRs.","Spanakis, Marios, Tzamali, Eleftheria, Tzedakis, Georgios, Spanakis, Emmanouil G., Tsatsakis, Aristides, Sakkalis, Vangelis",,,A Graph-Based Approach to Mitigate Drug-Drug Interactions and Optimize Therapeutic Regimens,,,10.1109/BIBE60311.2023.00041 , ,,"Drug-drug interactions (DDIs) pose a significant issue in modern healthcare, potentially compromising treatment efficacy and patient safety. DDIs arise when significant alterations occur in the pharmacological action of a drug due to its co-administration with another drug, leading to potential adverse drug reactions (ADRs), toxicity or diminished therapeutic efficacy. Apart from the obvious cases of drug combinations that should be avoided, there are instances where risk-benefit analysis may allow co-administration. Hence, DDIs may represent clinically significant cases depending on the clinical outcome, time point of administration, etc. The issue is especially critical in cases of patients with multimorbidity and complex therapeutic regimens with different time points in drug administrations. This work employs a graph-based approach aimed at optimizing therapeutic regiments while considering the minimization of DDIs potential. In this approach each drug is represented as a node, and edges represent the clinical significance of DDIs. We aim to identify sets of drugs that either have no DDIs or exhibit minor to moderate clinical significance (referred to as Maximal Independent Sets), indicating that they can be taken together. In practice, we solved the complementary problem, which is finding Maximal Cliques. Both problems are NP-hard, but for small graphs, they can be solved exactly. From all the cliques we identify, those selected to be a part of each proposed therapeutic regimen must consist of nodes that appear only once. This problem is once again reduced to clique finding. The above approach is demonstrated using two clinical scenarios involving two patients who are experiencing polypharmacy and are at risk for ADRs due to potential DDIs of varying clinical significance. By applying our approach, the therapeutic schemes are optimized towards minimizing the risk of ADRs.",,,,, ,  2023 IEEE 23rd International Conference on Bioinformatics and Bioengineering (BIBE),Drugs;Toxicology;Minimization;Safety;Electronic healthcare;Bioinformatics;Biomedical engineering;drug-drug interactions;DDIs;ADRs;patient safety;toxicity;therapeutic regimens;graphs;graph nodes;adverse drug events;adverse drug reactions,out_of_scope,
3025,"**Title**Machine Learning Approaches for CKD Identification among HIV-Afflicted Individuals

**Abstract**Chronic Kidney Disease (CKD) exhibits a significant healthcare dispute globally, predominantly among individuals living with HIV, where its prevalence and severity are heightened. Early detection of CKD in HIV patients is crucial for timely intervention and improved outcomes. The paper proposes a novel approach leveraging machine-learning techniques for the identification and classification of CKD in HIV patients. Traditional diagnostic methods often fail to detect CKD in its early stages due to asymptomatic presentation, leading to delayed treatment and disease progression. By harnessing the power of machine learning and the wealth of pathology data available, the study aims to enhance CKD diagnosis efficiency and accuracy. The methodology involves the development and evaluation of machine learning models trained on diverse datasets encompassing clinical and demographic variables alongside specific kidney function metrics, such as glomerular filtration rate (GFR). The models enable the classification of CKD presence and staging, facilitating early intervention and tailored patient care strategies. Through rigorous evaluation and validation processes, the efficacy and reliability of the proposed machine learning-based approach are assessed, paving the way for its integration into clinical practice. By providing clinicians with advanced tools for CKD detection in HIV patients, this research endeavours to improve patient outcomes, mitigate disease progression, and alleviate the burden on healthcare systems.The algorithms utilized in this study include:1.KNeighbors classifier2.DecisionTreeClassifier3.RandomForestClassifier4.AdaBoostClassifier5.XgBoostThrough rigorous evaluation and validation processes, the efficacy and reliability of the proposed machine learning-based approach are assessed, paving the way for its integration into clinical practice. By providing clinicians with advanced tools for CKD detection in HIV patients, this research endeavours to improve patient outcomes, mitigate disease progression, and alleviate the burden on healthcare systems.","Janani, D., Ramakrishnan, S., Arungarai Selvan, E, Mohana Prasath, K K, Sudharsan, R",,,Machine Learning Approaches for CKD Identification among HIV-Afflicted Individuals,,,10.1109/ICCCNT61001.2024.10725376 , ,,"Chronic Kidney Disease (CKD) exhibits a significant healthcare dispute globally, predominantly among individuals living with HIV, where its prevalence and severity are heightened. Early detection of CKD in HIV patients is crucial for timely intervention and improved outcomes. The paper proposes a novel approach leveraging machine-learning techniques for the identification and classification of CKD in HIV patients. Traditional diagnostic methods often fail to detect CKD in its early stages due to asymptomatic presentation, leading to delayed treatment and disease progression. By harnessing the power of machine learning and the wealth of pathology data available, the study aims to enhance CKD diagnosis efficiency and accuracy. The methodology involves the development and evaluation of machine learning models trained on diverse datasets encompassing clinical and demographic variables alongside specific kidney function metrics, such as glomerular filtration rate (GFR). The models enable the classification of CKD presence and staging, facilitating early intervention and tailored patient care strategies. Through rigorous evaluation and validation processes, the efficacy and reliability of the proposed machine learning-based approach are assessed, paving the way for its integration into clinical practice. By providing clinicians with advanced tools for CKD detection in HIV patients, this research endeavours to improve patient outcomes, mitigate disease progression, and alleviate the burden on healthcare systems.The algorithms utilized in this study include:1.KNeighbors classifier2.DecisionTreeClassifier3.RandomForestClassifier4.AdaBoostClassifier5.XgBoostThrough rigorous evaluation and validation processes, the efficacy and reliability of the proposed machine learning-based approach are assessed, paving the way for its integration into clinical practice. By providing clinicians with advanced tools for CKD detection in HIV patients, this research endeavours to improve patient outcomes, mitigate disease progression, and alleviate the burden on healthcare systems.",,,,, ,  2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),Technological innovation;Machine learning algorithms;Accuracy;Medical services;Machine learning;Predictive models;Chronic kidney disease;Reliability;Diseases;Principal component analysis;Electronic Health Records (EHR);Chronic Renal Diseases;Healthcare Analytics;Machine Learning;Ensemble Approach,out_of_scope,
3026,"**Title**Virtual screening, ADMET profiling, molecular docking and dynamics approaches to search for potent selective natural molecule based inhibitors against metallothionein-III to study Alzheimer's disease

**Abstract**Motivation: Metallothionein-III (MT-III) displays neuro-inhibitory activity and is involved in the repair of neuronal damage. An altered expression level of MT-III suggests that it could be a mitigating factor in Alzheimer's disease (AD) neuronal dysfunction. Currently there are limited marketed drugs available against MT-III. The inhibitors are mostly pseudo-peptide based with limited ADMET. In our present study, available database InterBioScreen (natural compounds) was screened out for MT-III. Pharmacodynamics and pharmacokinetic studies were performed. Molecular docking and simulations of top hit molecules were performed to study complex stability. Results: Study reveals potent selective molecules that interact and form hydrogen bonds with amino acids Ser-6 and Lys-22 which are common to established melatonin inhibitors for MT-III. These include DMHMIO, MCA B and s27533 derivatives. The ADMET profiling was better with comparable interaction energy values. It includes properties like blood brain barrier, hepatotoxicity, druggability, mutagenicity and carcinogenicity. Molecular dynamics studies were performed to validate our findings.","Roy, Sudeep, Kumar, Akhil, Provazník, Ivo",,,"Virtual screening, ADMET profiling, molecular docking and dynamics approaches to search for potent selective natural molecule based inhibitors against metallothionein-III to study Alzheimer's disease",,,10.1109/BIBM.2014.6999184 , ,,"Motivation: Metallothionein-III (MT-III) displays neuro-inhibitory activity and is involved in the repair of neuronal damage. An altered expression level of MT-III suggests that it could be a mitigating factor in Alzheimer's disease (AD) neuronal dysfunction. Currently there are limited marketed drugs available against MT-III. The inhibitors are mostly pseudo-peptide based with limited ADMET. In our present study, available database InterBioScreen (natural compounds) was screened out for MT-III. Pharmacodynamics and pharmacokinetic studies were performed. Molecular docking and simulations of top hit molecules were performed to study complex stability. Results: Study reveals potent selective molecules that interact and form hydrogen bonds with amino acids Ser-6 and Lys-22 which are common to established melatonin inhibitors for MT-III. These include DMHMIO, MCA B and s27533 derivatives. The ADMET profiling was better with comparable interaction energy values. It includes properties like blood brain barrier, hepatotoxicity, druggability, mutagenicity and carcinogenicity. Molecular dynamics studies were performed to validate our findings.",,,,, ,  2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Proteins;Compounds;Hydrogen;Alzheimer's disease;Amino acids;Inhibitors;Alzheimer's disease;Metallothionein-III;Virtual Screening;ADMET;Molecular Dynamics,out_of_scope,
3027,"**Title**Feature Attribution-Guided Contrastive Learning: Mitigating Lexical Bias in Toxic Speech Detection

**Abstract**Automatic detection methods for toxic speech can potentially curb the dissemination of offensive, abusive, hateful, and other toxic speech on social media. However, these methods often show bias by overreacting to words such as identity terms, profanity, and swear words that occur in non-toxic speech and erroneously classifying them as toxic speech. Recent research has attempted to regularise relevant biased words in predefined lexicons to mitigate their impact on model classification. However, this approach faces two challenges. Firstly, words such as pro-fanity and swear words in biased words play a crucial role in the model's ability to identify toxic speech, and excessive suppression of these words using regularization methods can detrimentally affect the performance of the classification model. Secondly, due to the limitations of regularization techniques, existing methods rely on manually constructed biased word dictionaries, which can only mitigate bias associated with identity-related terms. This bias should not significantly impact hate speech prediction. It is challenging to encompass lexical biases such as profanity and swear words that are specific to different datasets beyond identity terms To address the above challenges, this paper proposes a novel feature attribution-guided contrastive learning method. The method consists of two repeated steps across epochs. In each epoch, first identifies keywords in sentences that are crucial for predicting toxicity through feature attribution. Then it applies contrastive learning to separate samples that have common toxic keywords but different labels. Experiments show that our approach can mitigate lexical bias in toxic speech detection without any data augmentation or prior knowledge and achieve competitive performance gains.","Peng, Zhenghan, Ren, Yizhi, Wang, Dong, Zhang, Ling, Yuan, Lifeng, Ji, Yihao",,,Feature Attribution-Guided Contrastive Learning: Mitigating Lexical Bias in Toxic Speech Detection,,,10.1109/NTCI60157.2023.10403665 , ,,"Automatic detection methods for toxic speech can potentially curb the dissemination of offensive, abusive, hateful, and other toxic speech on social media. However, these methods often show bias by overreacting to words such as identity terms, profanity, and swear words that occur in non-toxic speech and erroneously classifying them as toxic speech. Recent research has attempted to regularise relevant biased words in predefined lexicons to mitigate their impact on model classification. However, this approach faces two challenges. Firstly, words such as pro-fanity and swear words in biased words play a crucial role in the model's ability to identify toxic speech, and excessive suppression of these words using regularization methods can detrimentally affect the performance of the classification model. Secondly, due to the limitations of regularization techniques, existing methods rely on manually constructed biased word dictionaries, which can only mitigate bias associated with identity-related terms. This bias should not significantly impact hate speech prediction. It is challenging to encompass lexical biases such as profanity and swear words that are specific to different datasets beyond identity terms To address the above challenges, this paper proposes a novel feature attribution-guided contrastive learning method. The method consists of two repeated steps across epochs. In each epoch, first identifies keywords in sentences that are crucial for predicting toxicity through feature attribution. Then it applies contrastive learning to separate samples that have common toxic keywords but different labels. Experiments show that our approach can mitigate lexical bias in toxic speech detection without any data augmentation or prior knowledge and achieve competitive performance gains.",,,,, ,  2023 International Conference on New Trends in Computational Intelligence (NTCI),Voice activity detection;Toxicology;Social networking (online);Self-supervised learning;Performance gain;Feature extraction;Task analysis;Toxic Speech;Bias Mitigation;Contrastive Learning;Feature Attribution,detection,
3028,"**Title**Structured Distribution of Electric Power Systems: The Example of a Roadway Tunnel Architecture

**Abstract**Modeling of the electric system “architecture” aims to achieve performances of safety, maintenance, operation, and reliability. This paper discusses the criteria in designing special cases, such as roadway tunnels, that need a structured architecture complying with electrical loads extensively distributed and with installation requirements proper to external stresses hazards such as fire hazard. Recommendations of mechanical and electrical criteria have to be graduated according to duty categories (as environment parameters for the road tunnels). Their consideration is essential for the settlement of the design criteria, which have to concern variable configurations to simplify installation problems, to allow a flexible operation, and to optimize the cost-benefit efficiency. A special power distribution, “brush-distribution,” is suitable for the strategic buildings with higher risk for seismic event and for the road tunnels against fire. The electrical power system of a roadway tunnel could raise high values with a relevant contribution by the mechanical ventilation and the support lighting. The authors suggest an adaptive criterion in designing the support lighting system in order to mitigate the cost and the energetic impact.","Parise, Giuseppe, Martirano, Luigi",,,Structured Distribution of Electric Power Systems: The Example of a Roadway Tunnel Architecture,,,10.1109/TIA.2010.2059352 , ,,"Modeling of the electric system “architecture” aims to achieve performances of safety, maintenance, operation, and reliability. This paper discusses the criteria in designing special cases, such as roadway tunnels, that need a structured architecture complying with electrical loads extensively distributed and with installation requirements proper to external stresses hazards such as fire hazard. Recommendations of mechanical and electrical criteria have to be graduated according to duty categories (as environment parameters for the road tunnels). Their consideration is essential for the settlement of the design criteria, which have to concern variable configurations to simplify installation problems, to allow a flexible operation, and to optimize the cost-benefit efficiency. A special power distribution, “brush-distribution,” is suitable for the strategic buildings with higher risk for seismic event and for the road tunnels against fire. The electrical power system of a roadway tunnel could raise high values with a relevant contribution by the mechanical ventilation and the support lighting. The authors suggest an adaptive criterion in designing the support lighting system in order to mitigate the cost and the energetic impact.",,,,, ,  ,Power distribution;Hazards;Fires;Roads;Power system modeling;Electrical safety;Maintenance;Power system reliability;Stress;Design optimization;Electric power systems;energy savings;fire hazard;road tunnels lighting;special installations,out_of_scope,
3029,"**Title**9 Nanotoxicity prediction in nanotechnology-driven drugs using QSPR modeling

**Abstract**The rapid expansion of nanotechnology in drug development has ushered in innovative therapeutic approaches while simultaneously raising concerns about potential nanotoxicity. This comprehensive review provides a thorough exploration of the evolving field of quantitative structure-property relationship (QSPR) modeling as a potent tool for predicting and mitigating nanotoxicity associated with nanotherapeutic agents. The review commences by underlining the transformative impact of nanotechnology on drug design, emphasizing the critical necessity of ensuring the safety and efficacy of nanomedicines. QSPR modeling emerges as an advanced computational approach harnessing physicochemical properties, structural descriptors, and toxicity endpoints to anticipate and comprehend nanotoxicity. The core of this review delves into the principles and methodologies of QSPR modeling, intricately describing the process of descriptor selection, dataset compilation, and model development. It scrutinizes the versatility of QSPR models in predicting a wide array of nanotoxicological endpoints, encompassing cellular responses, biodistribution patterns, and organ-specific toxicity profiles. Furthermore, the article underscores the significant clinical implications of QSPR modeling, discussing its potential for expediting nanotoxicity assessment during drug development, reducing reliance on animal testing, and facilitating regulatory approvals. It accentuates the pivotal role of QSPR modeling in optimizing nanotherapeutic formulations and minimizing adverse effects. Concluding on a forward-looking note, the review underscores the growing importance of QSPR modeling as an indispensable tool within the field of nanomedicine. It calls for sustained collaborative efforts to expand predictive models, address data gaps, and enhance our comprehension of nanotoxicity mechanisms. In summary, this review navigates the landscape of QSPR modeling for nanotoxicity prediction in the realm of nanotechnology- driven drugs, offering profound insights into its implications for advancing safe and efficacious nanotherapeutics.","Chawla, Pooja A., Hassan Mir, Reyaz, Chawla, Apporva, Ahad Mir, Prince, Sadique Hussain, Md, Ramzan, Sameena, Dedmari, Tooba, Mohi-ud-din, Roohi",,,9 Nanotoxicity prediction in nanotechnology-driven drugs using QSPR modeling,,, , ,,"The rapid expansion of nanotechnology in drug development has ushered in innovative therapeutic approaches while simultaneously raising concerns about potential nanotoxicity. This comprehensive review provides a thorough exploration of the evolving field of quantitative structure-property relationship (QSPR) modeling as a potent tool for predicting and mitigating nanotoxicity associated with nanotherapeutic agents. The review commences by underlining the transformative impact of nanotechnology on drug design, emphasizing the critical necessity of ensuring the safety and efficacy of nanomedicines. QSPR modeling emerges as an advanced computational approach harnessing physicochemical properties, structural descriptors, and toxicity endpoints to anticipate and comprehend nanotoxicity. The core of this review delves into the principles and methodologies of QSPR modeling, intricately describing the process of descriptor selection, dataset compilation, and model development. It scrutinizes the versatility of QSPR models in predicting a wide array of nanotoxicological endpoints, encompassing cellular responses, biodistribution patterns, and organ-specific toxicity profiles. Furthermore, the article underscores the significant clinical implications of QSPR modeling, discussing its potential for expediting nanotoxicity assessment during drug development, reducing reliance on animal testing, and facilitating regulatory approvals. It accentuates the pivotal role of QSPR modeling in optimizing nanotherapeutic formulations and minimizing adverse effects. Concluding on a forward-looking note, the review underscores the growing importance of QSPR modeling as an indispensable tool within the field of nanomedicine. It calls for sustained collaborative efforts to expand predictive models, address data gaps, and enhance our comprehension of nanotoxicity mechanisms. In summary, this review navigates the landscape of QSPR modeling for nanotoxicity prediction in the realm of nanotechnology- driven drugs, offering profound insights into its implications for advancing safe and efficacious nanotherapeutics.",,,,, ,  Computational Drug Delivery: Molecular Simulation for Pharmaceutical Formulation,Drugs;Toxicology;Predictive models;Nanomaterials;Nanotechnology;Nanobioscience;Mathematical models;Chemicals;Biological system modeling;Safety,out_of_scope,
3030,"**Title**Enhancing Photovoltaic Efficiency in CsSnI3-Based Perovskite Solar Cells through Optimal Defect Density

**Abstract**The utilization of lead-based perovskite solar cells (PSCs) in commercial applications is significantly limited due to concerns over their toxicity and stability. Perovskite-based photovoltaic (PV) cells are right now at the forefront of thin-film PV research and development due to their high-power conversion efficiency (PCE) and ease of manufacture. Perovskite materials based on Pb or Sn elements have been employed in the fabrication of solar cells. In instances of this nature, the utilization of tin-based inorganic PSCs can play a crucial role in advancing the performance of PSCs to exceptional levels. In this context, we want to present a theoretical exploration of a PV device known as a CsSnl3-based PSC, which possesses the desirable attributes of being lead-free, environmentally sustainable, and dependable. The present study involves the utilization of SCAPS software to conduct device modelling of PV cells based on CsSnl3. The bulk defect density of the buffer layer, specifically CsSnl3, has been altered from 1015 to 1018 cm-3. Based on the comprehensive findings, it can be shown that the PV CsSnl3 metrics exhibit maximum values when the defect density of CsSnl3-based PSC is reduced. When the concentration of faults reaches its minimum level of 1012 cm-3, the PV values exhibit enhancement as seen below: The observed results consist of a PCE of 23.3%, a VOC of 0.87V, a JSC of 30.76 mA/cm2, and an FF of 86.69%. These findings underscore the significance of mitigating the bulk defect density in CsSnl3-based PSCs in order to attain enhanced efficiency. Through additional investigation and advancement, it is plausible that PSCs devoid of lead, which rely on CsSnl3 as the active layer, could present a more environmentally friendly and enduring substitute for conventional lead-based PSCs.","Rawat, Savita, Madan, Jaya",,,Enhancing Photovoltaic Efficiency in CsSnI3-Based Perovskite Solar Cells through Optimal Defect Density,,,10.1109/RMKMATE59243.2023.10369406 , ,,"The utilization of lead-based perovskite solar cells (PSCs) in commercial applications is significantly limited due to concerns over their toxicity and stability. Perovskite-based photovoltaic (PV) cells are right now at the forefront of thin-film PV research and development due to their high-power conversion efficiency (PCE) and ease of manufacture. Perovskite materials based on Pb or Sn elements have been employed in the fabrication of solar cells. In instances of this nature, the utilization of tin-based inorganic PSCs can play a crucial role in advancing the performance of PSCs to exceptional levels. In this context, we want to present a theoretical exploration of a PV device known as a CsSnl3-based PSC, which possesses the desirable attributes of being lead-free, environmentally sustainable, and dependable. The present study involves the utilization of SCAPS software to conduct device modelling of PV cells based on CsSnl3. The bulk defect density of the buffer layer, specifically CsSnl3, has been altered from 1015 to 1018 cm-3. Based on the comprehensive findings, it can be shown that the PV CsSnl3 metrics exhibit maximum values when the defect density of CsSnl3-based PSC is reduced. When the concentration of faults reaches its minimum level of 1012 cm-3, the PV values exhibit enhancement as seen below: The observed results consist of a PCE of 23.3%, a VOC of 0.87V, a JSC of 30.76 mA/cm2, and an FF of 86.69%. These findings underscore the significance of mitigating the bulk defect density in CsSnl3-based PSCs in order to attain enhanced efficiency. Through additional investigation and advancement, it is plausible that PSCs devoid of lead, which rely on CsSnl3 as the active layer, could present a more environmentally friendly and enduring substitute for conventional lead-based PSCs.",,,,, ,"  2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)",Photovoltaic systems;Performance evaluation;Toxicology;Photovoltaic cells;Lead;Perovskites;Software;SCAPS;CsSnI3;PCE;defect density;lead-free,out_of_scope,
3031,"**Title**Ultrasound Triggered Sonodynamic Therapy for the Treatment of B16 Melanoma

**Abstract**Ultrasounds (US) represent a non-ionizing form of a mechanical wave characterized by reduced adverse impacts compared to traditional cancer therapies or surgical interventions. In this investigation, Chlorophyll was employed as a natural sonosensitizer, substituting synthetic counterparts, to mitigate potential organ toxicity associated with nanoparticle usage. Specifically, gold nanoparticles were conjugated with Chlorophyll (designated as AuSP NCs) to elicit a sonodynamic response. The efficacy of this approach was evaluated on B16 melanoma cell lines as a model system. We synthesized AuSP NCs with a mean size of 70±10 nm. These AuSP NCs are proposed for application as sonosensitizers in treating Melanoma. This novel strategy integrates the distinctive properties of gold nanoparticles and Chlorophyll to augment the effectiveness of cancer therapy.","Dehariya, Dheeraj, Murugaiyan, Kavipriya, Trivedi, Deeksha, Rengan, Aravind Kumar",,,Ultrasound Triggered Sonodynamic Therapy for the Treatment of B16 Melanoma,,,10.1109/SAUS61785.2024.10563718 , ,,"Ultrasounds (US) represent a non-ionizing form of a mechanical wave characterized by reduced adverse impacts compared to traditional cancer therapies or surgical interventions. In this investigation, Chlorophyll was employed as a natural sonosensitizer, substituting synthetic counterparts, to mitigate potential organ toxicity associated with nanoparticle usage. Specifically, gold nanoparticles were conjugated with Chlorophyll (designated as AuSP NCs) to elicit a sonodynamic response. The efficacy of this approach was evaluated on B16 melanoma cell lines as a model system. We synthesized AuSP NCs with a mean size of 70±10 nm. These AuSP NCs are proposed for application as sonosensitizers in treating Melanoma. This novel strategy integrates the distinctive properties of gold nanoparticles and Chlorophyll to augment the effectiveness of cancer therapy.",,,,, ,  2024 IEEE South Asian Ultrasonics Symposium (SAUS),Nanoparticles;Gold;Ultrasonic imaging;Temperature;Toxicology;Surgery;Melanoma;Gold nanocages;Silver nanocubes;Sonodynamic therapy;Melanoma;Ultrasound,out_of_scope,
3032,"**Title**Improving Hate Speech Detection Accuracy Using Hybrid CNN-RNN and Random Oversampling Techniques

**Abstract**Detecting hate speech is crucial for addressing online toxicity and fostering a secure digital environment. This study aims to enhance the efficiency of hybrid CNN-RNN models, commonly used for this task, by improving accuracy. By integrating oversampling techniques with the model, the research aims to better categorize instances of hate speech, particularly in imbalanced datasets. The dataset used in this study is the Indonesian Tweet Hate Speech dataset. Following established protocols, including data pre-processing, training, and testing, significant improvements in accuracy are observed. The hybrid CNN-RNN achieves 0.827 accuracy, 0.797 precision, 0.759 recall, and 0.883 F1 score with imbalanced data. The model performs even better with balanced data, reaching 0.908 accuracy, 0.943 precision, 0.894 recall, and 0.914 F1 score. Notably, the proposed model outperforms the standard hybrid CNN-RNN on imbalanced datasets, with an accuracy of 0.752, precision of 0.797, recall of 0.559, and F1 score of 0.657. Techniques like dropout and early termination mitigate overfitting in complex models and large datasets. This research contributes to hate speech detection methods, underscoring the hybrid CNN-RNN's efficacy in handling imbalanced data, while future studies could explore additional methodologies for further enhancements.","Riyadi, Slamet, Andriyani, Annisa Divayu, Masyhur, Ahmad Musthafa",,,Improving Hate Speech Detection Accuracy Using Hybrid CNN-RNN and Random Oversampling Techniques,,,10.1109/ISIEA61920.2024.10607232 , ,,"Detecting hate speech is crucial for addressing online toxicity and fostering a secure digital environment. This study aims to enhance the efficiency of hybrid CNN-RNN models, commonly used for this task, by improving accuracy. By integrating oversampling techniques with the model, the research aims to better categorize instances of hate speech, particularly in imbalanced datasets. The dataset used in this study is the Indonesian Tweet Hate Speech dataset. Following established protocols, including data pre-processing, training, and testing, significant improvements in accuracy are observed. The hybrid CNN-RNN achieves 0.827 accuracy, 0.797 precision, 0.759 recall, and 0.883 F1 score with imbalanced data. The model performs even better with balanced data, reaching 0.908 accuracy, 0.943 precision, 0.894 recall, and 0.914 F1 score. Notably, the proposed model outperforms the standard hybrid CNN-RNN on imbalanced datasets, with an accuracy of 0.752, precision of 0.797, recall of 0.559, and F1 score of 0.657. Techniques like dropout and early termination mitigate overfitting in complex models and large datasets. This research contributes to hate speech detection methods, underscoring the hybrid CNN-RNN's efficacy in handling imbalanced data, while future studies could explore additional methodologies for further enhancements.",,,,, ,  2024 IEEE Symposium on Industrial Electronics & Applications (ISIEA),Training;Accuracy;Toxicology;Protocols;Prevention and mitigation;Hate speech;Reliability;hate speech;Twitter;hybrid CNN-RNN;balancing dataset;oversampling,detection,
3033,"**Title**CardiOT: Towards Interpretable Drug Cardiotoxicity Prediction Using Optimal Transport and Kolmogorov-Arnold Networks

**Abstract**Investigating the inhibitory effects of compounds on cardiac ion channels is essential for assessing cardiac drug safety. Consequently, researchers have developed computational models to evaluate combined cardiotoxicity (CCT) on cardiac ion channels. However, limitations in experimental data often cause issues like uneven data distribution and scarcity. Additionally, existing models primarily emphasize atomic information flow within graph neural networks (GNNs) while overlooking chemical bonds, leading to inadequate recognition of key structures. Therefore, this study integrates optimal transport (OT), structure remapping (SR), and Kolmogorov-Arnold networks (KANs) into a GNN-based CCT prediction model, CardiOT. First, the proposed CardiOT model employs OT pooling to optimize sample-feature joint distribution using expectation maximization, identifying ”important” samplefeature pairs. Additionally, SR technology is used to emphasize the role of chemical bond information in message propagation. KAN technology is integrated to greatly enhance model interpretability. In summary, the model mitigates challenges related to uneven data distribution and scarcity. Multiple experiments on public datasets confirm the model's robust performance. We anticipate that this model will provide deeper insights into compound inhibition mechanisms on cardiac ion channels and reduce toxicity risks. Our code and data are accessible at: https://github.com/2014402680/CCT","Zhang, Xinyu, Wang, Hao, Du, Zhenya, Zhuo, Linlin, Fu, Xiangzheng, Cao, Dongsheng, Xie, Boqia, Li, Keqin",,,CardiOT: Towards Interpretable Drug Cardiotoxicity Prediction Using Optimal Transport and Kolmogorov-Arnold Networks,,,10.1109/JBHI.2024.3510297 , ,,"Investigating the inhibitory effects of compounds on cardiac ion channels is essential for assessing cardiac drug safety. Consequently, researchers have developed computational models to evaluate combined cardiotoxicity (CCT) on cardiac ion channels. However, limitations in experimental data often cause issues like uneven data distribution and scarcity. Additionally, existing models primarily emphasize atomic information flow within graph neural networks (GNNs) while overlooking chemical bonds, leading to inadequate recognition of key structures. Therefore, this study integrates optimal transport (OT), structure remapping (SR), and Kolmogorov-Arnold networks (KANs) into a GNN-based CCT prediction model, CardiOT. First, the proposed CardiOT model employs OT pooling to optimize sample-feature joint distribution using expectation maximization, identifying ”important” samplefeature pairs. Additionally, SR technology is used to emphasize the role of chemical bond information in message propagation. KAN technology is integrated to greatly enhance model interpretability. In summary, the model mitigates challenges related to uneven data distribution and scarcity. Multiple experiments on public datasets confirm the model's robust performance. We anticipate that this model will provide deeper insights into compound inhibition mechanisms on cardiac ion channels and reduce toxicity risks. Our code and data are accessible at: https://github.com/2014402680/CCT",,,,, ,  ,Drugs;Compounds;Predictive models;Ions;Chemicals;Safety;Data models;Accuracy;Toxicology;Prediction algorithms;inhibitory effects of drugs;compound cardiotoxicity (CCT);optimal transport (OT);KolmogorovArnold networks (KANs);uneven distribution and data scarcity;cardiac drug safety,out_of_scope,
3034,"**Title**Prediction of Liver Disease Using Machine Learning Algorithms

**Abstract**Due to an increased usage of harmful chemicals like alcohol, tobacco, toxic gases, narcotics, and other toxic substances, lung disorders including liver cancer and other serious illnesses are becoming more common. The liver serves crucial functions in the body of a person, including the processing of food, vitamin preservation, and energy preservation. It is a dangerous illness that, if not treated in a timely manner, might cost many people their livelihoods, thus it is important to recognize the illness as soon as possible and to start treating it by studying it quickly. Even for medical professionals, discussing early disease prediction using some signs is rather challenging. This study work intends to discover liver disease prediction with good accuracy by utilising Python and supervised and semi-supervised machine learning approaches, as well as phases such as data loading and reading, pre-processing of the information, feature scaling, developing SVM & Random Forest Classifiers model, and measuring performance for both models.","C R, Vishwanatha, Asha, V, Prasad, Arpana, Manoj, Singh Satyam, Kindalkar, Shreya Nanda, Bhatt, Sowjanya R.",,,Prediction of Liver Disease Using Machine Learning Algorithms,,,10.1109/CIISCA59740.2023.00039 , ,,"Due to an increased usage of harmful chemicals like alcohol, tobacco, toxic gases, narcotics, and other toxic substances, lung disorders including liver cancer and other serious illnesses are becoming more common. The liver serves crucial functions in the body of a person, including the processing of food, vitamin preservation, and energy preservation. It is a dangerous illness that, if not treated in a timely manner, might cost many people their livelihoods, thus it is important to recognize the illness as soon as possible and to start treating it by studying it quickly. Even for medical professionals, discussing early disease prediction using some signs is rather challenging. This study work intends to discover liver disease prediction with good accuracy by utilising Python and supervised and semi-supervised machine learning approaches, as well as phases such as data loading and reading, pre-processing of the information, feature scaling, developing SVM & Random Forest Classifiers model, and measuring performance for both models.",,,,, ,"  2023 International Conference on Computational Intelligence for Information, Security and Communication Applications (CIISCA)",Liver diseases;Support vector machine classification;Predictive models;Data models;Random forests;Load modeling;Diseases;Liver disease;Random Forest;Machine Learning;Classification;Support Vector Machine;Expert system,out_of_scope,
3035,"**Title**Machine Learning based Object Detection to Protect Marine Ecosystem

**Abstract**The majority of the earth's water bodies are currently contaminated. This occurs primarily as a result of massive amounts of waste being dumped into it. The majority of the garbage is made up of toxic materials, non-biodegradable materials, and e-waste, which severely harms the marine ecosystem. Additionally, it causes the loss of human life as a result of natural disasters. It ceases throwing this waste into the water bodies in order to solve these issues and keep them tidy and clean. If it can't be done, it would be better to start the cleaning process, which involves getting rid of these kinds of things. The study will be crucial in resolving this issue through the use of some machine learning techniques, including image classification and image recognition. Here, sizable collection of related e-waste image datasets is used to train the model in this procedure. Further, the machine will begin recognizing it so that it can be distinguished from the water bodies. Since the use of these kinds of procedures will make nature more environment friendly. In the end, it promotes economic expansion and sustainable development.","Prakash, Vallakati Bhanu, Shirisha, Dhanavath, Reddy, Gopu Suryaprakash, Hariharan, Shanmugasundaram, Kukreja, Vinay, Prasad, Andraju Bhanu",,,Machine Learning based Object Detection to Protect Marine Ecosystem,,,10.1109/ICECA58529.2023.10395399 , ,,"The majority of the earth's water bodies are currently contaminated. This occurs primarily as a result of massive amounts of waste being dumped into it. The majority of the garbage is made up of toxic materials, non-biodegradable materials, and e-waste, which severely harms the marine ecosystem. Additionally, it causes the loss of human life as a result of natural disasters. It ceases throwing this waste into the water bodies in order to solve these issues and keep them tidy and clean. If it can't be done, it would be better to start the cleaning process, which involves getting rid of these kinds of things. The study will be crucial in resolving this issue through the use of some machine learning techniques, including image classification and image recognition. Here, sizable collection of related e-waste image datasets is used to train the model in this procedure. Further, the machine will begin recognizing it so that it can be distinguished from the water bodies. Since the use of these kinds of procedures will make nature more environment friendly. In the end, it promotes economic expansion and sustainable development.",,,,, ,"  2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA)",Support vector machines;Image resolution;Image recognition;Neural networks;Machine learning;Object detection;Electronic waste;Object Detection;Marine ecosystem;Aquatic life;Image Processing;Regional based convolution neural network (R-CNN);SVM (Support Vector Machine);E-Waste,out_of_scope,
3036,"**Title**Large Language Models: Ethics and Norms in the European Union

**Abstract**This paper investigates the ethical-legal issues underlying the implementation of Large Language Models, in the aftermath of the European Union Parliament's approval of the Artificial Intelligence Regulation. In very recent years, there has been a rapid evolution and multiform implementation of the so-called Artificial Intelligence. Notably, one significant development in AI is the creation of systems capable of performing tasks based on a set of established rules. Artificial Intelligence has recently undergone a significant revolution that has led to a radical paradigm shift, represented by the so-called Foundation Models, which have two main characteristics: emergence and homogenisation. On the other hand, Language Modelling (LM) is one of the main approaches to advance the linguistic intelligence of machines and thus a Foundation Model trained on textual data. The most recent development of this approach can be found in the so-called Large Language Models (LLM). These take the form of artificial neural networks pre-trained on huge datasets which, instead of being dedicated to a specific task, can perform a wide range of different functions at a level that is all the more accurate the greater the resources made available to them. The concept of language models is not new but has evolved with the progress of artificial intelligence over the decades. In general, LLMs are mainly trained in industrial settings where many important details of training (e.g. data collection and cleaning) are not disclosed. Thus, it is difficult to align LLMs with human values or preferences. Despite their capabilities, LLMs are also likely to produce toxic, fictitious or harmful content. Therefore, effective and efficient control approaches are required to eliminate the potential risk arising from the use of LLMs. For the purposes of the study conducted, it is intended to describe the development and outcomes with the aim to show not only the evolution of the responses offered by various LLM, but also and above all the possible ethical and legal implications that can be deduced from these outputs. Several models have been used for the implementation of the experiments: two GPT-2 models, Perplexity, ChatGPT (version 3.5), Llama. The language used for the implementation of the experiments was English, as it is structurally more neutral. In particular, with reference to a topic with a strong ethical and legal impact such as suicide, different answers were offered by the various models used. In conclusion, the essay offers reflections on the results of the experiment with reference to the EU Regulation on Artificial Intelligence. Artificial Intelligence represents for the jurist, not only European, a decisive challenge not only with regard to the categories of thought and formulation of operational languages, but above all with regard to the centrality of the human being. On the basis of these considerations, focusing on generative AI and in particular on Large Language Models, it is clear that many of the issues relating to copyright and the protection of personal data still remain unsolved, excluding those already regulated by the legislation on the point.","Ciullo, Marianna",,,Large Language Models: Ethics and Norms in the European Union,,,10.1109/MetroXRAINE62247.2024.10795986 , ,,"This paper investigates the ethical-legal issues underlying the implementation of Large Language Models, in the aftermath of the European Union Parliament's approval of the Artificial Intelligence Regulation. In very recent years, there has been a rapid evolution and multiform implementation of the so-called Artificial Intelligence. Notably, one significant development in AI is the creation of systems capable of performing tasks based on a set of established rules. Artificial Intelligence has recently undergone a significant revolution that has led to a radical paradigm shift, represented by the so-called Foundation Models, which have two main characteristics: emergence and homogenisation. On the other hand, Language Modelling (LM) is one of the main approaches to advance the linguistic intelligence of machines and thus a Foundation Model trained on textual data. The most recent development of this approach can be found in the so-called Large Language Models (LLM). These take the form of artificial neural networks pre-trained on huge datasets which, instead of being dedicated to a specific task, can perform a wide range of different functions at a level that is all the more accurate the greater the resources made available to them. The concept of language models is not new but has evolved with the progress of artificial intelligence over the decades. In general, LLMs are mainly trained in industrial settings where many important details of training (e.g. data collection and cleaning) are not disclosed. Thus, it is difficult to align LLMs with human values or preferences. Despite their capabilities, LLMs are also likely to produce toxic, fictitious or harmful content. Therefore, effective and efficient control approaches are required to eliminate the potential risk arising from the use of LLMs. For the purposes of the study conducted, it is intended to describe the development and outcomes with the aim to show not only the evolution of the responses offered by various LLM, but also and above all the possible ethical and legal implications that can be deduced from these outputs. Several models have been used for the implementation of the experiments: two GPT-2 models, Perplexity, ChatGPT (version 3.5), Llama. The language used for the implementation of the experiments was English, as it is structurally more neutral. In particular, with reference to a topic with a strong ethical and legal impact such as suicide, different answers were offered by the various models used. In conclusion, the essay offers reflections on the results of the experiment with reference to the EU Regulation on Artificial Intelligence. Artificial Intelligence represents for the jurist, not only European, a decisive challenge not only with regard to the categories of thought and formulation of operational languages, but above all with regard to the centrality of the human being. On the basis of these considerations, focusing on generative AI and in particular on Large Language Models, it is clear that many of the issues relating to copyright and the protection of personal data still remain unsolved, excluding those already regulated by the legislation on the point.",,,,, ,"  2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)",Training;Ethics;Law;Foundation models;Large language models;Europe;Regulation;Reflection;Artificial intelligence;Protection;Artificial Intelligence;Large Language Models;Ethics;Law;Artificial Intelligence Act,evaluation,
3037,"**Title**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse

**Abstract**Human health is increasingly threatened by exposure to hazardous substances, particularly persistent and toxic chemicals. The link between these substances, often encountered in complex mixtures, and various diseases are demonstrated in scientific studies. However, this information is scattered across several sources and hardly accessible by humans and machines. This paper evaluates current practices for publishing/accessing information on hazardous chemicals and proposes a novel platform designed to facilitate retrieval of critical chemical data in urgent situations. The platform aggregates information from multiple sources and organizes it into a structured knowledge graph. Users can access this information through a visual interface such as Neo4J Bloom and dashboards, or via natural language queries using a Chatbot. Our findings demonstrate a significant reduction in the time and effort required to access vital chemical information when datasets follow FAIR principles. Furthermore, we discuss the lessons learned from the development and implementation of this platform and provide recommendations for data owners and publishers to enhance data reuse and interoperability. This work aims to improve the accessibility and usability of chemical information by healthcare professionals, thereby supporting better health outcomes and informed decision-making in the face of patients exposed to chemical intoxication risks.","Da Silveira, Marcos, Deladiennee, Louis, Acem, Kheira, Freudenthal, Oona",,,Combining knowledge graphs and LLMs for hazardous chemical information management and reuse,,,10.1109/BIBM62325.2024.10821991 , ,,"Human health is increasingly threatened by exposure to hazardous substances, particularly persistent and toxic chemicals. The link between these substances, often encountered in complex mixtures, and various diseases are demonstrated in scientific studies. However, this information is scattered across several sources and hardly accessible by humans and machines. This paper evaluates current practices for publishing/accessing information on hazardous chemicals and proposes a novel platform designed to facilitate retrieval of critical chemical data in urgent situations. The platform aggregates information from multiple sources and organizes it into a structured knowledge graph. Users can access this information through a visual interface such as Neo4J Bloom and dashboards, or via natural language queries using a Chatbot. Our findings demonstrate a significant reduction in the time and effort required to access vital chemical information when datasets follow FAIR principles. Furthermore, we discuss the lessons learned from the development and implementation of this platform and provide recommendations for data owners and publishers to enhance data reuse and interoperability. This work aims to improve the accessibility and usability of chemical information by healthcare professionals, thereby supporting better health outcomes and informed decision-making in the face of patients exposed to chemical intoxication risks.",,,,, ,  2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Visualization;Soft sensors;Aggregates;Natural languages;Decision making;Knowledge graphs;Medical services;Chatbots;Chemical elements;Chemicals,out_of_scope,
3038,"**Title**Leveraging ResNet-50 for Precision Toxicity Classification in Plants: A Vision-Based Approach to Safeguard Public Health

**Abstract**The classification of toxic and non-toxic plants plays an important role in ensuring public safety, especially in agriculture, food safety, and health. Correct identification of these plants can prevent accidental poisoning and promote ecological protection. In this paper, we investigate the application of the ResNet-50 model for the classification of toxic and non-toxic plants. Leveraging the powerful feature extraction techniques of the ResNet-50 architecture, the model achieved 89.6% accuracy, 87.4% precision, 91.1% recall, and an 89.2% F1 score, demonstrating the model's effectiveness. Transfer learning proved effective with limited data while maintaining high performance metrics in the classification task. Future research could focus on expanding the dataset to include more plant species and exploring other state-of-the-art models to improve classification accuracy. Additionally, integrating these models with mobile applications or monitoring systems could provide solutions for business and public use, enhancing environmental protection and public safety.","Makhija, Aria",,,Leveraging ResNet-50 for Precision Toxicity Classification in Plants: A Vision-Based Approach to Safeguard Public Health,,,10.1109/EHB64556.2024.10805656 , ,,"The classification of toxic and non-toxic plants plays an important role in ensuring public safety, especially in agriculture, food safety, and health. Correct identification of these plants can prevent accidental poisoning and promote ecological protection. In this paper, we investigate the application of the ResNet-50 model for the classification of toxic and non-toxic plants. Leveraging the powerful feature extraction techniques of the ResNet-50 architecture, the model achieved 89.6% accuracy, 87.4% precision, 91.1% recall, and an 89.2% F1 score, demonstrating the model's effectiveness. Transfer learning proved effective with limited data while maintaining high performance metrics in the classification task. Future research could focus on expanding the dataset to include more plant species and exploring other state-of-the-art models to improve classification accuracy. Additionally, integrating these models with mobile applications or monitoring systems could provide solutions for business and public use, enhancing environmental protection and public safety.",,,,, ,  2024 E-Health and Bioengineering Conference (EHB),Measurement;Accuracy;Toxicology;Biological system modeling;Plants (biology);Transfer learning;Public security;Agriculture;Reliability;Protection;Poisonous plants;Non-poisonous plants;ResNet-50;Plant classification;Deep learning,out_of_scope,
3039,"**Title**Frequent substructure-based approaches for classifying chemical compounds

**Abstract**Computational techniques that build models to correctly assign chemical compounds to various classes of interest have many applications in pharmaceutical research and are used extensively at various phases during the drug development process. These techniques are used to solve a number of classification problems such as predicting whether or not a chemical compound has the desired biological activity, is toxic or nontoxic, and filtering out drug-like compounds from large compound libraries. This paper presents a substructure-based classification algorithm that decouples the substructure discovery process from the classification model construction and uses frequent subgraph discovery algorithms to find all topological and geometric substructures present in the data set. The advantage of this approach is that during classification model construction, all relevant substructures are available allowing the classifier to intelligently select the most discriminating ones. The computational scalability is ensured by the use of highly efficient frequent subgraph discovery algorithms coupled with aggressive feature selection. Experimental evaluation on eight different classification problems shows that our approach is computationally scalable and, on average, outperforms existing schemes by 7 percent to 35 percent.","Deshpande, M., Kuramochi, M., Wale, N., Karypis, G.",,,Frequent substructure-based approaches for classifying chemical compounds,,,10.1109/TKDE.2005.127 , ,,"Computational techniques that build models to correctly assign chemical compounds to various classes of interest have many applications in pharmaceutical research and are used extensively at various phases during the drug development process. These techniques are used to solve a number of classification problems such as predicting whether or not a chemical compound has the desired biological activity, is toxic or nontoxic, and filtering out drug-like compounds from large compound libraries. This paper presents a substructure-based classification algorithm that decouples the substructure discovery process from the classification model construction and uses frequent subgraph discovery algorithms to find all topological and geometric substructures present in the data set. The advantage of this approach is that during classification model construction, all relevant substructures are available allowing the classifier to intelligently select the most discriminating ones. The computational scalability is ensured by the use of highly efficient frequent subgraph discovery algorithms coupled with aggressive feature selection. Experimental evaluation on eight different classification problems shows that our approach is computationally scalable and, on average, outperforms existing schemes by 7 percent to 35 percent.",,,,, ,  ,Chemical compounds;Pharmaceuticals;Drugs;Filtering;Libraries;Classification algorithms;Biological system modeling;Solid modeling;Computational intelligence;Scalability;Index Terms- Classification;chemical compounds;virtual screening;graphs;SVM.,out_of_scope,
3040,"**Title**Real-Time Hate Speech Recognition Along with Educational Feedback and Automatic Reporting

**Abstract**In today's digital era, the rise of toxicity, discrimination, and harm on online communication platforms has become a significant concern, necessitating effective moderation strategies. Existing methods for hate speech detection often lack real-time capabilities and fail to provide constructive feedback to users. Natural Language Processing (NLP) is used to identify the intent of the speech and bidirectional Long Short Term Memory (LSTM) machine learning algorithm classifies text into multiple hate speech categories. The designed system also displays charts, providing a detailed assessment and understanding of the nature and severity of the content. With a user-friendly interface, users receive real-time educational feedback on the nature and impact of different types of hate speech, promoting awareness and discouraging toxic behavior.","Panda, Abhilasha, Anand, Abhijeet, Bebortta, Sujit, Sekhar Tripathy, Subhranshu, Mukherjee, Tanmay",,,Real-Time Hate Speech Recognition Along with Educational Feedback and Automatic Reporting,,,10.1109/AESPC63931.2024.10872383 , ,,"In today's digital era, the rise of toxicity, discrimination, and harm on online communication platforms has become a significant concern, necessitating effective moderation strategies. Existing methods for hate speech detection often lack real-time capabilities and fail to provide constructive feedback to users. Natural Language Processing (NLP) is used to identify the intent of the speech and bidirectional Long Short Term Memory (LSTM) machine learning algorithm classifies text into multiple hate speech categories. The designed system also displays charts, providing a detailed assessment and understanding of the nature and severity of the content. With a user-friendly interface, users receive real-time educational feedback on the nature and impact of different types of hate speech, promoting awareness and discouraging toxic behavior.",,,,, ,"  2024 IEEE 4th International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC)",Toxicology;Machine learning algorithms;Hate speech;Bidirectional long short term memory;Speech recognition;Real-time systems;Natural language processing;Speech processing;Hate Speech Detection;Natural Language Processing;Bidirectional LSTM;Hate Classification;Real-time educational Feedback,detection,
3041,"**Title**Finding Qualitative Patterns in Ozone Behavior

**Abstract**Air pollution is one of the most important environmental problems in urban areas, being extremely critical in Mexico City. The main air pollution problem that has been identified in Mexico City metropolitan area is the formation of photochemical smog, primarily ozone. This toxic gas can produce harmful effects on the population's health, especially children's health. The study and developement of modeling methodologies that allow the capturing of time series behavior becomes an important task when it is intended to predict the future behavior of the system under study. This paper presents the Visual-FIR tool, a new platform for the Fuzzy Inductive Reasoning (FIR) methodology. FIR offers a model-based approach to modeling and predicting either univariate or multivariate time series. Visual-FIR is used in this research for long term prediction of maximum ozone concentration in the centre region of Mexico City metropolitan area.","Nebot, Angela, Mugica, Violeta",,,Finding Qualitative Patterns in Ozone Behavior,,,10.1109/MICAI.2006.21 , ,,"Air pollution is one of the most important environmental problems in urban areas, being extremely critical in Mexico City. The main air pollution problem that has been identified in Mexico City metropolitan area is the formation of photochemical smog, primarily ozone. This toxic gas can produce harmful effects on the population's health, especially children's health. The study and developement of modeling methodologies that allow the capturing of time series behavior becomes an important task when it is intended to predict the future behavior of the system under study. This paper presents the Visual-FIR tool, a new platform for the Fuzzy Inductive Reasoning (FIR) methodology. FIR offers a model-based approach to modeling and predicting either univariate or multivariate time series. Visual-FIR is used in this research for long term prediction of maximum ozone concentration in the centre region of Mexico City metropolitan area.",,,,, ,  2006 Fifth Mexican International Conference on Artificial Intelligence,Cities and towns;Air pollution;Predictive models;Finite impulse response filter;Urban areas;Photochemistry;Fuzzy reasoning;Nitrogen;Chemicals;Atmospheric modeling,out_of_scope,
3042,"**Title**Towards Automated Regulation of Jacobaea Vulgaris in Grassland using Deep Neural Networks

**Abstract**The highly poisonous ragwort (Jacobaea Vulgaris) is increasingly spreading, posing significant risks to agriculture, livestock, and nature conservation due to the production of toxic pyrrolizidine alkaloids (PAs). The current manual control methods, such as plucking weed, are labor-intensive and time-consuming. This paper introduces a workflow towards automated regulation of J. Vulgaris, which consists of the two independent tasks of deep learning-based monitoring and controlling. We aim to detect and control J. Vulgaris in an early growth stage before the plant can reseed, which challenges the data collection and the training of deep neural networks. Primarily we need to detect the green leaf rosettes on a green meadow. The main focus lies on the monitoring part with synthetic training data generation and a deep neural network-based labeling assistant.","Schauer, Moritz, Hohl, Renke, Vaupel, Dennis, Bienhaus, Diethelm, Ghobadi, Seyed Eghbal",,,Towards Automated Regulation of Jacobaea Vulgaris in Grassland using Deep Neural Networks,,,10.1109/ICCVW60793.2023.00078 , ,,"The highly poisonous ragwort (Jacobaea Vulgaris) is increasingly spreading, posing significant risks to agriculture, livestock, and nature conservation due to the production of toxic pyrrolizidine alkaloids (PAs). The current manual control methods, such as plucking weed, are labor-intensive and time-consuming. This paper introduces a workflow towards automated regulation of J. Vulgaris, which consists of the two independent tasks of deep learning-based monitoring and controlling. We aim to detect and control J. Vulgaris in an early growth stage before the plant can reseed, which challenges the data collection and the training of deep neural networks. Primarily we need to detect the green leaf rosettes on a green meadow. The main focus lies on the monitoring part with synthetic training data generation and a deep neural network-based labeling assistant.",,,,, ,  2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW),Jacobian matrices;Training;Training data;Artificial neural networks;Production;Regulation;Agriculture;Robotics;Deep Learning;Computer Vision;Annotations;Agriculture;Weed Detection;Ragwort;Jacobaea Vulgaris,out_of_scope,
3043,"**Title**Advanced Toxicity Assessment: A BiLSTM Approach for Nanoparticle Safety

**Abstract**Nanotoxicity prediction is crucial for safeguarding human health and the environment due to the unique properties of nanoparticles (NPs) that lead to unforeseen biological interactions. With growing applications of nanomaterials in consumer products, pharmaceuticals, and industry, early detection of their toxic effects is vital for risk assessment, regulatory compliance, and the informed design of safer materials. In this study, a deep learning (DL) model, Bidirectional Long Short-Term Memory (BiLSTM), is proposed for the effective prediction of nanoparticle toxicity. Utilizing a publicly available dataset, the model analyzes physicochemical attributes of various NPs, including Al203, Fe203, CuO,Ti02, and ZnO. The dataset encompasses 476 toxic and 405 non-toxic samples, with features such as core size, surface area, and exposure time. The methodology involves rigorous data preprocessing, including outlier detection using Z-scores and one-hot encoding for categorical variables. The BiLSTM architecture processes data in both forward and backward directions, effectively capturing temporal dependencies and enhancing toxicity prediction accuracy. The model's performance was evaluated, achieving remarkable 98.28% accuracy, 98.01 % precision, 97.82% recall, and 97.91 % Fl-score. Additionally, the ROC curve demonstrated excellent discrimination between classes, with an AUC of 0.96. The findings highlight the potential of DL in advancing nanotoxicity prediction, thereby contributing to safer applications of nanotechnology.","S, Nisha V, R S, Rimal Isaac",,,Advanced Toxicity Assessment: A BiLSTM Approach for Nanoparticle Safety,,,10.1109/ICCES63552.2024.10859379 , ,,"Nanotoxicity prediction is crucial for safeguarding human health and the environment due to the unique properties of nanoparticles (NPs) that lead to unforeseen biological interactions. With growing applications of nanomaterials in consumer products, pharmaceuticals, and industry, early detection of their toxic effects is vital for risk assessment, regulatory compliance, and the informed design of safer materials. In this study, a deep learning (DL) model, Bidirectional Long Short-Term Memory (BiLSTM), is proposed for the effective prediction of nanoparticle toxicity. Utilizing a publicly available dataset, the model analyzes physicochemical attributes of various NPs, including Al203, Fe203, CuO,Ti02, and ZnO. The dataset encompasses 476 toxic and 405 non-toxic samples, with features such as core size, surface area, and exposure time. The methodology involves rigorous data preprocessing, including outlier detection using Z-scores and one-hot encoding for categorical variables. The BiLSTM architecture processes data in both forward and backward directions, effectively capturing temporal dependencies and enhancing toxicity prediction accuracy. The model's performance was evaluated, achieving remarkable 98.28% accuracy, 98.01 % precision, 97.82% recall, and 97.91 % Fl-score. Additionally, the ROC curve demonstrated excellent discrimination between classes, with an AUC of 0.96. The findings highlight the potential of DL in advancing nanotoxicity prediction, thereby contributing to safer applications of nanotechnology.",,,,, ,  2024 9th International Conference on Communication and Electronics Systems (ICCES),Nanoparticles;Analytical models;Toxicology;Accuracy;Consumer products;Bidirectional long short term memory;Predictive models;Zinc oxide;Nanobioscience;Pharmaceuticals;Nanotoxicity;Nanoparticles;Deep Learning;Physicochemical;Nanotechnology,out_of_scope,
3044,"**Title**Artificial Intelligence Approach for Predicting Class I Major Histocompatibility Complex Epitope Presentation and Neo-Epitope Immunogenicity

**Abstract**T cells help eliminate pathogens present in infected cells and help B cells make better and different kinds of antibodies to protect against extracellular microbes and toxic molecules. Because T cells cannot see the inside of cells to identify ones that ingested pathogens or are synthesizing viral or mutant proteins, antigen presentation systems evolved, displaying on the cell surface information about various antigens synthesized or ingested in cells. The systems provide a way to monitor major subcellular compartments where pathogens are present and report their presence to the appropriate T cells. Endogenously synthesized antigens in the cytosol of all cells are presented to CD8+ T cells as peptides bound to major histocompatibility complex (MHC) class I molecules, thereby allowing identification and elimination of infected cells or cancer cells by the CD8+ lymphocytes. Thus, identification of non-genetically encoded peptides, or neo-epitopes, eliciting an adaptive immune response is important to develop patient-specific cancer vaccines. However, experimental process of validating candidate neo-epitopes is very resourceintensive, and a large portion of candidates are found to be non-immunogenic, making the identification of successful neo-epitopes difficult and time-consuming. A recent study showed that the BigMHC method, composed of seven pan-allelic deep neural networks trained on peptide-MHC eluted ligand data from mass spectrometry assays and transfer learned on data from assays of antigen-specific immune response, significantly improves the prediction of epitope presentation on a test set of 45,409 MHC ligands among 900,592 random negatives compared to other four state-of-the-art classifiers. It also showed that after transfer learning on immunogenicity data, the precision of BigMHC is greater than several other state-of-the-art models in identifying immunogenic neo-epitopes, making BigMHC effective in clinical settings. I noticed that there is a multi-allelic dataset that comes from MHC-Flurry 2.0 consisting of MHC Class I peptides each with a bag of six alleles used in BigMHC method; in the single-allelic data, each peptide only consists of one allele instead of multi-alleles. However, even in the single-allelic data duplicates are possible: there may be two of the exact same peptides, but one belongs to one allele while the other belongs to a different allele. I set out examining such duplicates with my custom code and found that 44.734% of the singleallelic data are duplicates, raising the possibility that BigMHC method's test results is unaffected by the duplicates. As expected, there was no notable differences based on my trained models. The examination and result raise another possibility that implementing multiple instance learning (MIL) may be advantageous in immunogenicity prediction because it considers multiple MHC alleles associated with a given peptide, as observed in the multi-allelic dataset whereas in single-instance learning, each peptide is associated with a single label (in this case, whether it elicits an active immune response), which may not fully capture the complexity of MHC-peptide interactions due to the high level of polymorphism in MHC class I molecules. If the approach succeeds, MIL will help further enhance the accuracy and reliability of BigMHC method potentially more beneficial in clinical settings.","Jung, Kathryn",,,Artificial Intelligence Approach for Predicting Class I Major Histocompatibility Complex Epitope Presentation and Neo-Epitope Immunogenicity,,,10.1109/ISEC61299.2024.10664816 , ,,"T cells help eliminate pathogens present in infected cells and help B cells make better and different kinds of antibodies to protect against extracellular microbes and toxic molecules. Because T cells cannot see the inside of cells to identify ones that ingested pathogens or are synthesizing viral or mutant proteins, antigen presentation systems evolved, displaying on the cell surface information about various antigens synthesized or ingested in cells. The systems provide a way to monitor major subcellular compartments where pathogens are present and report their presence to the appropriate T cells. Endogenously synthesized antigens in the cytosol of all cells are presented to CD8+ T cells as peptides bound to major histocompatibility complex (MHC) class I molecules, thereby allowing identification and elimination of infected cells or cancer cells by the CD8+ lymphocytes. Thus, identification of non-genetically encoded peptides, or neo-epitopes, eliciting an adaptive immune response is important to develop patient-specific cancer vaccines. However, experimental process of validating candidate neo-epitopes is very resourceintensive, and a large portion of candidates are found to be non-immunogenic, making the identification of successful neo-epitopes difficult and time-consuming. A recent study showed that the BigMHC method, composed of seven pan-allelic deep neural networks trained on peptide-MHC eluted ligand data from mass spectrometry assays and transfer learned on data from assays of antigen-specific immune response, significantly improves the prediction of epitope presentation on a test set of 45,409 MHC ligands among 900,592 random negatives compared to other four state-of-the-art classifiers. It also showed that after transfer learning on immunogenicity data, the precision of BigMHC is greater than several other state-of-the-art models in identifying immunogenic neo-epitopes, making BigMHC effective in clinical settings. I noticed that there is a multi-allelic dataset that comes from MHC-Flurry 2.0 consisting of MHC Class I peptides each with a bag of six alleles used in BigMHC method; in the single-allelic data, each peptide only consists of one allele instead of multi-alleles. However, even in the single-allelic data duplicates are possible: there may be two of the exact same peptides, but one belongs to one allele while the other belongs to a different allele. I set out examining such duplicates with my custom code and found that 44.734% of the singleallelic data are duplicates, raising the possibility that BigMHC method's test results is unaffected by the duplicates. As expected, there was no notable differences based on my trained models. The examination and result raise another possibility that implementing multiple instance learning (MIL) may be advantageous in immunogenicity prediction because it considers multiple MHC alleles associated with a given peptide, as observed in the multi-allelic dataset whereas in single-instance learning, each peptide is associated with a single label (in this case, whether it elicits an active immune response), which may not fully capture the complexity of MHC-peptide interactions due to the high level of polymorphism in MHC class I molecules. If the approach succeeds, MIL will help further enhance the accuracy and reliability of BigMHC method potentially more beneficial in clinical settings.",,,,, ,  2024 IEEE Integrated STEM Education Conference (ISEC),Proteins;Pathogens;Antigens;Peptides;Transfer learning;Mass spectroscopy;Vaccines,out_of_scope,
3045,"**Title**Implementation of Simulated Annealing-Ensemble Method in Toxicity Prediction: Case Study of NR-AHR Toxicity Type

**Abstract**People exposed to countless chemical compounds throughout their lives, many of which have the potential to be hazardous. This chemical interaction has become an integral aspect of our daily lives. Living in a highly reactive chemical environment entails interaction with various elements, ranging from the food we consume and prescribed medications to the cosmetics we use and even the air we breathe. When developing new medications, toxicity becomes a major concern because over 30% of drug candidates have toxic effects that are not discovered during clinical trials. The toxic potential of chemicals and their combinations must be proven experimentally. Therefore, minimizing our exposure to dangerous substances in common products requires an understanding toxicity of chemical. This study used the simulated annealing algorithm and the ensemble method to predict the toxicity of a case study involving the Nuclear Receptor-Aryl Hydrocarbon Receptor toxicity type. The Tox21 Data Challenge provided the dataset used in this investigation. The simulated annealing algorithm used in the feature selection process to develop a prediction model. Ensemble method was using to build a prediction model with three methods: Random Forest, Adaptive Boosting (AdaBoost), and Extreme Gradient Boosting (XGBoost). The best model obtained from Random Forest model with accuracy value of 0.9806 and an F1-Score of 0.9808.","Salsabila, Adinda Rizqi, Astuti, Widi, Kurniawan, Isman",,,Implementation of Simulated Annealing-Ensemble Method in Toxicity Prediction: Case Study of NR-AHR Toxicity Type,,,10.1109/ICoDSA62899.2024.10652058 , ,,"People exposed to countless chemical compounds throughout their lives, many of which have the potential to be hazardous. This chemical interaction has become an integral aspect of our daily lives. Living in a highly reactive chemical environment entails interaction with various elements, ranging from the food we consume and prescribed medications to the cosmetics we use and even the air we breathe. When developing new medications, toxicity becomes a major concern because over 30% of drug candidates have toxic effects that are not discovered during clinical trials. The toxic potential of chemicals and their combinations must be proven experimentally. Therefore, minimizing our exposure to dangerous substances in common products requires an understanding toxicity of chemical. This study used the simulated annealing algorithm and the ensemble method to predict the toxicity of a case study involving the Nuclear Receptor-Aryl Hydrocarbon Receptor toxicity type. The Tox21 Data Challenge provided the dataset used in this investigation. The simulated annealing algorithm used in the feature selection process to develop a prediction model. Ensemble method was using to build a prediction model with three methods: Random Forest, Adaptive Boosting (AdaBoost), and Extreme Gradient Boosting (XGBoost). The best model obtained from Random Forest model with accuracy value of 0.9806 and an F1-Score of 0.9808.",,,,, ,  2024 International Conference on Data Science and Its Applications (ICoDSA),Adaptation models;Toxicology;Simulated annealing;Predictive models;Prediction algorithms;Feature extraction;Classification algorithms;simulated annealing algorithm;ensemble;NR-AHR;toxicity prediction;machine learning,out_of_scope,
3046,"**Title**Vulnerable Object Detection Using Machine Learning

**Abstract**This machine language project on object detection vulnerability is to have the safety and wellbeing of toddlers by using the advantages of machine learning techniques for identifying and assessing potentially dangerous objects in an environment that contains little children. This system uses advanced computer vision and deep learning algorithms, particularly Convolutional Neural Networks (CNNs) in the analysis of real-time images or video feeds from cameras mounted in homes, daycares, or play areas. The deep learning models comprise a very good training set with high variability and diversity in images of ordinary objects and identified threats. The dataset consists of a wide range of objects that fall into one of the following categories: dangerous sharp items such as scissors and knives, dangerous small objects capable of causing choking, or poisonous substances or toxic materials if ingested. Through such data processing, the CNN- based system is trained to identify and classify such hazardous things with a precision level of almost 100%. After training, it can monitor the environment continuously with the help of live video feeds. The system immediately alerts a caregiver, parents, or administrative personnel once it identifies an object that fits into one of the pre-defined hazard categories, based on the deployment scenario. That alert would then give them timely information to provide for safety concerns. This project aims to minimize the risks of accidents and injuries by providing an effective and automatic means to monitor the environments wherein the toddlers are physically active. Integrating sophisticated object detection technology with proper safety protocols will create a more secure environment for young children through reduced accidents and evidence of a secure space for play and living.","J, John Shiny., M, Abhishek., N, Mahendravarman.",,,Vulnerable Object Detection Using Machine Learning,,,10.1109/ICSCNA63714.2024.10864124 , ,,"This machine language project on object detection vulnerability is to have the safety and wellbeing of toddlers by using the advantages of machine learning techniques for identifying and assessing potentially dangerous objects in an environment that contains little children. This system uses advanced computer vision and deep learning algorithms, particularly Convolutional Neural Networks (CNNs) in the analysis of real-time images or video feeds from cameras mounted in homes, daycares, or play areas. The deep learning models comprise a very good training set with high variability and diversity in images of ordinary objects and identified threats. The dataset consists of a wide range of objects that fall into one of the following categories: dangerous sharp items such as scissors and knives, dangerous small objects capable of causing choking, or poisonous substances or toxic materials if ingested. Through such data processing, the CNN- based system is trained to identify and classify such hazardous things with a precision level of almost 100%. After training, it can monitor the environment continuously with the help of live video feeds. The system immediately alerts a caregiver, parents, or administrative personnel once it identifies an object that fits into one of the pre-defined hazard categories, based on the deployment scenario. That alert would then give them timely information to provide for safety concerns. This project aims to minimize the risks of accidents and injuries by providing an effective and automatic means to monitor the environments wherein the toddlers are physically active. Integrating sophisticated object detection technology with proper safety protocols will create a more secure environment for young children through reduced accidents and evidence of a secure space for play and living.",,,,, ,  2024 International Conference on Sustainable Communication Networks and Application (ICSCNA),Training;Deep learning;Pediatrics;Object detection;Streaming media;Object recognition;Feeds;Convolutional neural networks;Monitoring;Accidents;object detection;Machine Learning;Toddler Safety;Hazardous Object Identification;Real-Time Alerts;Child Safety;User Interface;Camera Integration,out_of_scope,
3047,"**Title**Detection of Hate Speech and Offensive Language Using Machine Learning and Deep Learning for Multi-Class Tweets

**Abstract**Nowadays, every single person is indulged in social media, and because of its hidden characteristics, people are free to express their views and thoughts and expressing their views freely is their right. Expressing their thoughts and views on dynamic news puts a positive impact in economy, as it shows how people relate to each other. Yet, there are times when individuals throw toxic comments or accusing them on the grounds of caste, religion, gender identity, ethnicity etc. is a harassment of the given freedom. Due to this, hate and offensive language has become the serious issue, in modern society, which leads to damaging the people's peace, their human rights as well as creating an inequality in society. In this research paper, the dataset has been taken from the Kaggle source, sentiment analysis will be done on the detection of hate speech and offensive language, and the classification will be done on the following three labels: Hate Speech, Offensive Language and Neither.","Garg, Bhavika, Bhardwaj, Aditya, Jain, Tarun",,,Detection of Hate Speech and Offensive Language Using Machine Learning and Deep Learning for Multi-Class Tweets,,,10.1109/ICSPCRE62303.2024.10675191 , ,,"Nowadays, every single person is indulged in social media, and because of its hidden characteristics, people are free to express their views and thoughts and expressing their views freely is their right. Expressing their thoughts and views on dynamic news puts a positive impact in economy, as it shows how people relate to each other. Yet, there are times when individuals throw toxic comments or accusing them on the grounds of caste, religion, gender identity, ethnicity etc. is a harassment of the given freedom. Due to this, hate and offensive language has become the serious issue, in modern society, which leads to damaging the people's peace, their human rights as well as creating an inequality in society. In this research paper, the dataset has been taken from the Kaggle source, sentiment analysis will be done on the detection of hate speech and offensive language, and the classification will be done on the following three labels: Hate Speech, Offensive Language and Neither.",,,,, ,  2024 IEEE International Conference on Smart Power Control and Renewable Energy (ICSPCRE),Deep learning;Sentiment analysis;Renewable energy sources;Analytical models;Tongue;Social networking (online);Hate speech;Hate Speech;Offensive Language;Sentiment Analysis;Natural Language Processing;Machine Learning;Feature Extraction,detection,
3048,"**Title**UEF-HOCUrdu: Unified Embeddings Ensemble Framework for Hate and Offensive Text Classification in Urdu

**Abstract**Hate speech and other forms of hostile communication on social media have several implications such as; fostering violence, promoting social divide, and negative psychological effects. Since such toxic language is becoming more and more common, it is imperative to have a proper way of identifying it, especially in low resource language like Urdu. To meet this challenge, this research proposed a new ensemble based multi-classification model and generated new dataset of 36,000 Urdu tweets categorized as ‘Hate’, ‘Offensive’ and ‘Neither’. This study sought to create a model that not only achieves a high classification accuracy but also overcome key challenges inherent in natural language processing, namely, high dimensionality, sparsity, overfitting, OOV words and dialectal variations. For this purpose, an extensive comparison of different learning algorithms were conducted. As a result, the most efficient models, namely FastText, XLM-RoBERTa, ULMFiT, and XGBoost were incorporated in the proposed ensemble approach to achieve the best results in both classification and mitigation of NLP issues. To further enhance the confidence in proposed model, a stratified 5-fold cross-validation technique has been utilized. The ensemble model performed the best and achieved macro F1 score of 0.94, complemented by comprehensive labeled dataset focusing on hate and offensive speech in Urdu. By addressing key research gaps, this research provides a valuable foundation for future work and benchmarking in Urdu hate speech multi-classification tasks.","Ullah, Kifayat, Aslam, Muhammad, Khan, Muhammad Usman Ghani, Alamri, Faten S., Khan, Amjad Rehman",,,UEF-HOCUrdu: Unified Embeddings Ensemble Framework for Hate and Offensive Text Classification in Urdu,,,10.1109/ACCESS.2025.3532611 , ,,"Hate speech and other forms of hostile communication on social media have several implications such as; fostering violence, promoting social divide, and negative psychological effects. Since such toxic language is becoming more and more common, it is imperative to have a proper way of identifying it, especially in low resource language like Urdu. To meet this challenge, this research proposed a new ensemble based multi-classification model and generated new dataset of 36,000 Urdu tweets categorized as ‘Hate’, ‘Offensive’ and ‘Neither’. This study sought to create a model that not only achieves a high classification accuracy but also overcome key challenges inherent in natural language processing, namely, high dimensionality, sparsity, overfitting, OOV words and dialectal variations. For this purpose, an extensive comparison of different learning algorithms were conducted. As a result, the most efficient models, namely FastText, XLM-RoBERTa, ULMFiT, and XGBoost were incorporated in the proposed ensemble approach to achieve the best results in both classification and mitigation of NLP issues. To further enhance the confidence in proposed model, a stratified 5-fold cross-validation technique has been utilized. The ensemble model performed the best and achieved macro F1 score of 0.94, complemented by comprehensive labeled dataset focusing on hate and offensive speech in Urdu. By addressing key research gaps, this research provides a valuable foundation for future work and benchmarking in Urdu hate speech multi-classification tasks.",,,,, ,  ,Hate speech;Text categorization;Machine learning;Deep learning;Context modeling;Transfer learning;Multilingual;Data models;Cyberbullying;Cultural differences;Urdu hate speech detection;Urdu multi-class classification;machine learning;deep learning;transfer learning;ensemble learning model;natural language processing (NLP),out_of_scope,
3049,"**Title**Chronic kidney disease prediction: Optimization of machine learning algorithms

**Abstract**A wide range of variables, such as more drinking, a growing worldwide pollution trouble caused on by rapid industrialization and warming temperatures, release of toxic gases from polluted water and food, misuse of drugs, and, most importantly, bad habits, are expected to make kidney failure worse. It is one of the deadliest illnesses affecting the world’s medical care systems. These factors ultimately lead to a constant rise in the number of kidney anomalies that patients are diagnosed with. Building classification and prediction models for early liver disease diagnosis involves examining the patient’s renal datasets. The disease is predicted using machine learning in an attempt to lighten the burden on physicians. This research investigates many past machine-learning algorithms for the diagnosis and categorization of renal disorders. A comparative examination of more than six models suggests the best course of action for the target dataset. For offline challenges, these are the greatest options for improving the accuracy of the model. While there is evidence to show that different ensemble procedures and hyper parameter tuning can lead to improved accuracy, these methods significantly raise computing productivity costs, rendering them impractical for real-world applications.","Kumar, Narinder, Singla, Sanjay",,,Chronic kidney disease prediction: Optimization of machine learning algorithms,,,10.1109/CCICT62777.2024.00098 , ,,"A wide range of variables, such as more drinking, a growing worldwide pollution trouble caused on by rapid industrialization and warming temperatures, release of toxic gases from polluted water and food, misuse of drugs, and, most importantly, bad habits, are expected to make kidney failure worse. It is one of the deadliest illnesses affecting the world’s medical care systems. These factors ultimately lead to a constant rise in the number of kidney anomalies that patients are diagnosed with. Building classification and prediction models for early liver disease diagnosis involves examining the patient’s renal datasets. The disease is predicted using machine learning in an attempt to lighten the burden on physicians. This research investigates many past machine-learning algorithms for the diagnosis and categorization of renal disorders. A comparative examination of more than six models suggests the best course of action for the target dataset. For offline challenges, these are the greatest options for improving the accuracy of the model. While there is evidence to show that different ensemble procedures and hyper parameter tuning can lead to improved accuracy, these methods significantly raise computing productivity costs, rendering them impractical for real-world applications.",,,,, ,  2024 Sixth International Conference on Computational Intelligence and Communication Technologies (CCICT),Temperature distribution;Machine learning algorithms;Accuracy;Computational modeling;Medical services;Rendering (computer graphics);Water pollution;Diabetic kidney disease;adjusting hyper parameter machine learning;logistic regression;and random forest detectors,out_of_scope,
3050,"**Title**Anomaly Detection in Smart Industrial Machinery Through Hidden Markov Models and Autoencoders

**Abstract**This study addresses the need to develop a sustainable manufacturing process in industrial factories, as the industry desires to remain competitive while it is challenged to adopt eco-friendly practices. A Machine Learning based software is proposed to deal with the environmental issues, aiming to facilitate the monitoring and analysis of industrial machinery, more exactly of CNC woodworking machines. The focus is on two aspects that determine the environmental impact: energy consumption and toxic emissions, which are used to determine the operating modes of the machines and to detect potential working anomalies. This software consists of a pipeline with two main components: the first one aims to categorize the operating modes of the used machines through time series clustering methods, such as Hidden Markov Models. The second component employs Hidden Markov Models again alongside deep learning based Autoencoders to identify huge deviations within the environmental data. For evaluation, a dataset was collected as a time series from a CNC woodworking machine and then the preprocessed data was further analyzed using the implemented software. The experiments have shown that for anomaly detection in machine operating modes, the Hidden Markov Model outperforms the Autoencoder and state-of-the-art models in terms of efficiency and robustness.","Sorostinean, Radu, Burghelea, Zaharia, Gellert, Arpad",,,Anomaly Detection in Smart Industrial Machinery Through Hidden Markov Models and Autoencoders,,,10.1109/ACCESS.2024.3400970 , ,,"This study addresses the need to develop a sustainable manufacturing process in industrial factories, as the industry desires to remain competitive while it is challenged to adopt eco-friendly practices. A Machine Learning based software is proposed to deal with the environmental issues, aiming to facilitate the monitoring and analysis of industrial machinery, more exactly of CNC woodworking machines. The focus is on two aspects that determine the environmental impact: energy consumption and toxic emissions, which are used to determine the operating modes of the machines and to detect potential working anomalies. This software consists of a pipeline with two main components: the first one aims to categorize the operating modes of the used machines through time series clustering methods, such as Hidden Markov Models. The second component employs Hidden Markov Models again alongside deep learning based Autoencoders to identify huge deviations within the environmental data. For evaluation, a dataset was collected as a time series from a CNC woodworking machine and then the preprocessed data was further analyzed using the implemented software. The experiments have shown that for anomaly detection in machine operating modes, the Hidden Markov Model outperforms the Autoencoder and state-of-the-art models in terms of efficiency and robustness.",,,,, ,  ,Hidden Markov models;Anomaly detection;Time series analysis;Machinery;Clustering algorithms;Fourth Industrial Revolution;Long short term memory;Sustainable development;Manufacturing processes;Anomaly detection;autoencoders;hidden Markov models;Industry 4.0;long short-term memory;working mode detection,out_of_scope,
3051,"**Title**ANTI-Disinformation: An Adversarial Attack and Defense Network Towards Improved Robustness for Disinformation Detection on Social Media

**Abstract**The prevalence of disinformation, which includes malformation (e.g., cyberbullying) and misinformation (e.g., fake news) in online platforms has raised significant concerns, prompting the need for robust detection methods to mitigate its detrimental impact. While the field of text classification has witnessed notable advancements in recent years, existing approaches often overlook the evolving nature of disinformation, wherein perpetrators employ perturbations to toxic content to evade detection or censorship. To address this challenge, we present a novel framework, Adversarial Network Towards Improved robustness for Disinformation detection (ANTI-Disinformation), which leverages reinforcement learning techniques as adversarial attacks. Additionally, we propose a defense model to enhance model’s robustness against such attacks. To evaluate the effectiveness of our approach, we conduct extensive experiments on well-known disinformation datasets collected from multiple social media platforms. The results demonstrate our approach can effectively produce degradation in existing models’ performance the most, showcasing the effectiveness of our framework and the vulnerability of existing detection systems. The results also exhibit that the proposed defense methods can consistently outperform existing typical methods in constructing robust detection models.","Chen, Kuan-Chun, Chen, Chih-Yao, Li, Cheng-Te",,,ANTI-Disinformation: An Adversarial Attack and Defense Network Towards Improved Robustness for Disinformation Detection on Social Media,,,10.1109/BigData59044.2023.10386090 , ,,"The prevalence of disinformation, which includes malformation (e.g., cyberbullying) and misinformation (e.g., fake news) in online platforms has raised significant concerns, prompting the need for robust detection methods to mitigate its detrimental impact. While the field of text classification has witnessed notable advancements in recent years, existing approaches often overlook the evolving nature of disinformation, wherein perpetrators employ perturbations to toxic content to evade detection or censorship. To address this challenge, we present a novel framework, Adversarial Network Towards Improved robustness for Disinformation detection (ANTI-Disinformation), which leverages reinforcement learning techniques as adversarial attacks. Additionally, we propose a defense model to enhance model’s robustness against such attacks. To evaluate the effectiveness of our approach, we conduct extensive experiments on well-known disinformation datasets collected from multiple social media platforms. The results demonstrate our approach can effectively produce degradation in existing models’ performance the most, showcasing the effectiveness of our framework and the vulnerability of existing detection systems. The results also exhibit that the proposed defense methods can consistently outperform existing typical methods in constructing robust detection models.",,,,, ,  2023 IEEE International Conference on Big Data (BigData),Degradation;Perturbation methods;Text categorization;Cyberbullying;Reinforcement learning;Big Data;Robustness;Disinformation Detection;Adversarial Attack;Adversarial Defense;Model Robustness;Reinforcement Learning,detection,
3052,"**Title**Exploring The Complexities of Nanoparticle Toxicity: A Review Of Methodological Approaches

**Abstract**Nanoparticles (NPs) represent a burgeoning field of study with vast potential for technological advancements across various industries. However, their increasing use also raises concerns about potential adverse effects on human health and the environment. Understanding the toxicological properties of NPs is therefore paramount for safe deployment and regulation. It is crucial to comprehend and predict the toxicity of engineered nanomaterials (ENMs) in order to ensure their safe utilization and reduce potential environmental and health hazards. This research aims to comprehensively explore and synthesize current research on nano toxic classification methodologies, focusing on the prediction and assessment of NP toxicity. Moreover, the study highlights the inadequacies in existing experimental data quality and the necessity for more comprehensive datasets to enhance model accuracy. Challenges related to the interpretability of model outputs and the computational resources required for rigorous NP toxicity prediction are also discussed. Furthermore, the dynamic nature of NP behavior under varying environmental conditions emphasizes the need for predictive models that can account for these complexities. By synthesizing current knowledge and identifying research gaps, this study aims to pave the way for advancements in NP toxicity prediction methodologies. By addressing these gaps, the field can advance towards safer nanomaterial design and application, ensuring sustainable development in nanotechnology while safeguarding human health and the environment.","S, Nisha V, S, Rimal Isaac R",,,Exploring The Complexities of Nanoparticle Toxicity: A Review Of Methodological Approaches,,,10.1109/ICSCNA63714.2024.10864012 , ,,"Nanoparticles (NPs) represent a burgeoning field of study with vast potential for technological advancements across various industries. However, their increasing use also raises concerns about potential adverse effects on human health and the environment. Understanding the toxicological properties of NPs is therefore paramount for safe deployment and regulation. It is crucial to comprehend and predict the toxicity of engineered nanomaterials (ENMs) in order to ensure their safe utilization and reduce potential environmental and health hazards. This research aims to comprehensively explore and synthesize current research on nano toxic classification methodologies, focusing on the prediction and assessment of NP toxicity. Moreover, the study highlights the inadequacies in existing experimental data quality and the necessity for more comprehensive datasets to enhance model accuracy. Challenges related to the interpretability of model outputs and the computational resources required for rigorous NP toxicity prediction are also discussed. Furthermore, the dynamic nature of NP behavior under varying environmental conditions emphasizes the need for predictive models that can account for these complexities. By synthesizing current knowledge and identifying research gaps, this study aims to pave the way for advancements in NP toxicity prediction methodologies. By addressing these gaps, the field can advance towards safer nanomaterial design and application, ensuring sustainable development in nanotechnology while safeguarding human health and the environment.",,,,, ,  2024 International Conference on Sustainable Communication Networks and Application (ICSCNA),Nanoparticles;Industries;Toxicology;Accuracy;Computational modeling;Predictive models;Nanomaterials;Data models;Complexity theory;Sustainable development;Nanoparticle;nanomaterial;nanotoxicity;Superparamagnetic Iron Oxide Nanoparticles;Machine learning;cytotoxicity,out_of_scope,
3053,"**Title**Analyzing Doxorubicin and Cardioprotective PLGA Nanoparticles on Murine Cardiomyocytes using Machine Learning Modeling to Mitigate Cardiotoxicity

**Abstract**Doxorubicin (DOX) is a chemotherapeutic drug used to treat cancerous cells by inducing immunogenic cell death (ICD) and interfering with DNA replication. The viability of cardiomyocytes decreases significantly when treated with DOX and results in a cardiomyopathy mortality rate upwards of 50%, but this is reduced when encapsulated in a Poly-lactic-co-glycolic acid (PLGA) nanoparticle. We collected and treated murine cardiomyocytes in-vitro grouping untreated, DOX, and DOX with PLGA cells, and characterized them utilizing a fluorescence-activated cell sorting technique, cell flow cytometry. Using machine learning, we found which characteristics make PLGA effective at performing drug-carrying capabilities. We created a random forest model for processing the murine cells to predict which of the three treatments it received. We perform feature engineering utilizing correlation matrices between the features, Variation Inflation Factor (VIF) scores, and their Permutation Importance (PI) scores. Our random forest model achieved a 92.63% accuracy in predicting treatments with a dataset composed of highly independent features. By examining the most important features for the model’s accuracy, cell death, DOX, and granularity amount, we discern that because PLGA restores the lysosomal compartment of cells, it allows healthy cells to recycle their cytoplasmic structures. We also discovered that PLGA administers less of the toxic drug when cells are not tumorous, and restores the cellular membranes of cells after they are treated with DOX.","Lee, Christina, McCreary, Jennifer, Chen, Howard, Chen, Michelle, Manjarrés, José",,,Analyzing Doxorubicin and Cardioprotective PLGA Nanoparticles on Murine Cardiomyocytes using Machine Learning Modeling to Mitigate Cardiotoxicity,,,10.1109/BIBM62325.2024.10822703 , ,,"Doxorubicin (DOX) is a chemotherapeutic drug used to treat cancerous cells by inducing immunogenic cell death (ICD) and interfering with DNA replication. The viability of cardiomyocytes decreases significantly when treated with DOX and results in a cardiomyopathy mortality rate upwards of 50%, but this is reduced when encapsulated in a Poly-lactic-co-glycolic acid (PLGA) nanoparticle. We collected and treated murine cardiomyocytes in-vitro grouping untreated, DOX, and DOX with PLGA cells, and characterized them utilizing a fluorescence-activated cell sorting technique, cell flow cytometry. Using machine learning, we found which characteristics make PLGA effective at performing drug-carrying capabilities. We created a random forest model for processing the murine cells to predict which of the three treatments it received. We perform feature engineering utilizing correlation matrices between the features, Variation Inflation Factor (VIF) scores, and their Permutation Importance (PI) scores. Our random forest model achieved a 92.63% accuracy in predicting treatments with a dataset composed of highly independent features. By examining the most important features for the model’s accuracy, cell death, DOX, and granularity amount, we discern that because PLGA restores the lysosomal compartment of cells, it allows healthy cells to recycle their cytoplasmic structures. We also discovered that PLGA administers less of the toxic drug when cells are not tumorous, and restores the cellular membranes of cells after they are treated with DOX.",,,,, ,  2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Drugs;Nanoparticles;Analytical models;Accuracy;Correlation;Predictive models;Biomedical measurement;Biomembranes;Surfactants;Random forests;Drug delivery;Cardiotoxicity;Random Forest;PLGA,out_of_scope,
3054,"**Title**Monitoring Wheat Crop Biochemical Responses to Random Rainfall Stress Using Remote Sensing: A Multi-Data Approach

**Abstract**Random rainfall poses a significant threat to wheat production in India, adversely affecting grain quality and yield. Precise assessment of rain-induced stress responses on wheat is crucial for implementing timely preventive measures to mitigate the damage. While traditional methods involve toxic chemicals and laborious processes, satellite data offers a quicker, easier, and eco-friendly alternative. This study explores the potential of Sentinel-2 data to monitor biochemical changes in wheat crops caused by random rainfall events. Over three years, satellite, drone, weather, and agronomic data were collected for wheat crops. Four datasets were integrated through a multi-step processing workflow: agronomic data were derived from laboratory analyses of leaf samples collected at different growth stages of the wheat crop; drone imagery was processed via mosaicking, orthorectification, and geo-registration; and Sentinel-2 data underwent atmospheric correction, resampling, and sub-setting to produce reflectance maps. Weather data, including rainfall patterns, were directly sourced from the Agromet Field Unit at IIT Roorkee, India. Vegetation indices were extracted from the satellite and drone data, and these indices were used to develop a partial least square regression (PLSR) model to predict eight key biochemical variables. During rainfall stress, the study observed significant biochemical shifts, with declines in chlorophyll, carbohydrate, protein, and lipid levels, and increases in phenol, proline, hydrogen peroxide, and superoxide dismutase. The PLSR model accurately captured these changes, achieving R2-values $\ge 0.7$ and root mean square error (RMSE) <0.12 for all variables except lipids. The results highlight the effectiveness of this approach in monitoring rain-induced stress on wheat crops, providing a non-invasive and reliable method for protecting grain quality and minimizing yield losses. This technique offers a promising solution for large-scale, eco-friendly agricultural monitoring and stress management.","Panwar, Ekta, Singh, Dharmendra, Kumar Sharma, Ashwani, Kumar, Harish",,,Monitoring Wheat Crop Biochemical Responses to Random Rainfall Stress Using Remote Sensing: A Multi-Data Approach,,,10.1109/ACCESS.2024.3494867 , ,,"Random rainfall poses a significant threat to wheat production in India, adversely affecting grain quality and yield. Precise assessment of rain-induced stress responses on wheat is crucial for implementing timely preventive measures to mitigate the damage. While traditional methods involve toxic chemicals and laborious processes, satellite data offers a quicker, easier, and eco-friendly alternative. This study explores the potential of Sentinel-2 data to monitor biochemical changes in wheat crops caused by random rainfall events. Over three years, satellite, drone, weather, and agronomic data were collected for wheat crops. Four datasets were integrated through a multi-step processing workflow: agronomic data were derived from laboratory analyses of leaf samples collected at different growth stages of the wheat crop; drone imagery was processed via mosaicking, orthorectification, and geo-registration; and Sentinel-2 data underwent atmospheric correction, resampling, and sub-setting to produce reflectance maps. Weather data, including rainfall patterns, were directly sourced from the Agromet Field Unit at IIT Roorkee, India. Vegetation indices were extracted from the satellite and drone data, and these indices were used to develop a partial least square regression (PLSR) model to predict eight key biochemical variables. During rainfall stress, the study observed significant biochemical shifts, with declines in chlorophyll, carbohydrate, protein, and lipid levels, and increases in phenol, proline, hydrogen peroxide, and superoxide dismutase. The PLSR model accurately captured these changes, achieving R2-values $\ge 0.7$ and root mean square error (RMSE) <0.12 for all variables except lipids. The results highlight the effectiveness of this approach in monitoring rain-induced stress on wheat crops, providing a non-invasive and reliable method for protecting grain quality and minimizing yield losses. This technique offers a promising solution for large-scale, eco-friendly agricultural monitoring and stress management.",,,,, ,  ,Crops;Stress;Monitoring;Vegetation mapping;Rain;Drones;Spatial resolution;Satellites;Nutrients;Predictive models;Biochemical variables;non-invasive techniques;random rainfall;sentinel-2 data;stress monitoring;vegetation indices;wheat crops,out_of_scope,
3055,"**Title**Using Data Analysis Methods for Predicting the Concentration of Toxic Elements in Soil

**Abstract**This article is aimed at the selection of machine learning algorithms for the perception of elements in the composition of the soil. In our study, machine learning aims to track changes in the toxicity of contaminated soils in order to predict the level of human health hazard of a contaminated soil condition. For this, the following tasks were set: 1) collection and analysis of data on the types of soil toxicity; 2) study of a mathematical model of toxicity to assess the level of resistance; 3) testing the concentration of toxic elements in soils using four machine learning algorithms. Four machine learning algorithms were tested in the article to predict the content of heavy metals in the soil. The results show that the use of machine learning algorithms allows achieving a high degree of prediction of harmful elements concentrations in soils, which can be useful for making decisions on managing pollution sites. Further improvement of data accuracy and selection of the model and algorithm can also increase the accuracy of prediction. As a result of forecasting using the K-Nearest Neighbors algorithm, the accuracy of the model was achieved at the level of 68%, and using the Decision Tree - 69%. The results of the experiment make it possible to predict the measures of danger to human health from the state of contaminated soil. This will help reduce the risks of the relationship between soil pollution and human health. The obtained results can be useful for specialists in environmental protection, land resource management, and decision-making.","Naizabayeva, Lyazat, Zakirova, Gulnara",,,Using Data Analysis Methods for Predicting the Concentration of Toxic Elements in Soil,,,10.1109/IDAACS58523.2023.10348723 , ,,"This article is aimed at the selection of machine learning algorithms for the perception of elements in the composition of the soil. In our study, machine learning aims to track changes in the toxicity of contaminated soils in order to predict the level of human health hazard of a contaminated soil condition. For this, the following tasks were set: 1) collection and analysis of data on the types of soil toxicity; 2) study of a mathematical model of toxicity to assess the level of resistance; 3) testing the concentration of toxic elements in soils using four machine learning algorithms. Four machine learning algorithms were tested in the article to predict the content of heavy metals in the soil. The results show that the use of machine learning algorithms allows achieving a high degree of prediction of harmful elements concentrations in soils, which can be useful for making decisions on managing pollution sites. Further improvement of data accuracy and selection of the model and algorithm can also increase the accuracy of prediction. As a result of forecasting using the K-Nearest Neighbors algorithm, the accuracy of the model was achieved at the level of 68%, and using the Decision Tree - 69%. The results of the experiment make it possible to predict the measures of danger to human health from the state of contaminated soil. This will help reduce the risks of the relationship between soil pollution and human health. The obtained results can be useful for specialists in environmental protection, land resource management, and decision-making.",,,,, ,  2023 IEEE 12th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS),Machine learning algorithms;Toxicology;Soil measurements;Computational modeling;Soil;Predictive models;Prediction algorithms;intellectual analysis;data structure;predicting;soil;toxic elements,out_of_scope,
3056,"**Title**Computational prediction of toxic protein

**Abstract**We present a novel computational method to predict a protein as it is toxic or not, from sequence only. The main challenge lies in the fact that neither there is any specific feature nor there is any range of values in the respective structural features supported by all toxic proteins. To resolve this challenge, we have proposed and implemented a new approach. Here, at first we collect a large amount of proteins from different famous and authentic protein database. Then we find out those parameters that toxic proteins have in common in terms of their physical and chemical properties. Only the sequence of amino acid and structural characteristics are used to predict the features. Then we construct a set of criteria from the set of features to be used to predict them such as iso-electric point(PI), aliphatic index, amino acid content, half life, grand average, instability index etc. After constructing features we estimate a range for each feature and establish them through hypothesis testing using statistical distribution. Our study demonstrates that this method can provide an easy and high detection rate of toxic protein.","Rahaman, Md. Abdur, Khan, Md. Ibrahim",,,Computational prediction of toxic protein,,,10.1109/IFOST.2014.6991174 , ,,"We present a novel computational method to predict a protein as it is toxic or not, from sequence only. The main challenge lies in the fact that neither there is any specific feature nor there is any range of values in the respective structural features supported by all toxic proteins. To resolve this challenge, we have proposed and implemented a new approach. Here, at first we collect a large amount of proteins from different famous and authentic protein database. Then we find out those parameters that toxic proteins have in common in terms of their physical and chemical properties. Only the sequence of amino acid and structural characteristics are used to predict the features. Then we construct a set of criteria from the set of features to be used to predict them such as iso-electric point(PI), aliphatic index, amino acid content, half life, grand average, instability index etc. After constructing features we estimate a range for each feature and establish them through hypothesis testing using statistical distribution. Our study demonstrates that this method can provide an easy and high detection rate of toxic protein.",,,,, ,  2014 9th International Forum on Strategic Technology (IFOST),Amino acids;Protein sequence;Indexes;Diseases;Feature extraction;Toxic protein;Chi-squared distribution;Degrees of freedom;iso electric pointt;Half life,out_of_scope,
3057,"**Title**Urdu Toxic Comment Classification With PURUTT Corpus Development

**Abstract**This study addresses the critical gap in toxic comment classification in Urdu, a widely spoken language devoid of high-quality standard datasets. To address this gap, we employed an existing labeled Roman Urdu (RU) corpus, which was developed originally for Roman Urdu toxic comment classification, and supplemented that corpus by adding its Urdu equivalent transliterations. The motivation behind such an extension is twofold: firstly, to provide a large comprehensive dataset for the classification of toxic comments in Urdu; secondly, to facilitate bidirectional transliteration between Urdu and RU, however, transliteration is currently outside the scope of this study and is envisioned as a future research direction. We introduce the extended corpus as PURUTT (Parallel Urdu and Roman Urdu Corpus for Toxic Comments and Transliteration), boasting 72,771 labeled comments as parallel comments in both Urdu and Roman Urdu scripts. Specific to Urdu toxic comment classification, our methodology begins by training those classification models that were trained on the original Roman Urdu corpus. We leverage pre-trained Word2Vec and FastText Urdu word embeddings to evaluate model performance through transfer learning. Furthermore, we fine-tune five multilingual large language models capitalizing on their inherent multilingual capabilities. To further enhance the classification performance, this study proposes an ensemble approach that aggregates the strengths of multiple base models. Our extensive empirical validation demonstrates the superiority of the ensemble model, achieving a state-of-the-art F1-score of 91.65% on PURUTT, setting a benchmark F1-score on PURUTT corpus for Urdu toxic comment classification.","Saeed, Hafiz Hassaan, Khalil, Tahir, Kamiran, Faisal",,,Urdu Toxic Comment Classification With PURUTT Corpus Development,,,10.1109/ACCESS.2025.3535862 , ,,"This study addresses the critical gap in toxic comment classification in Urdu, a widely spoken language devoid of high-quality standard datasets. To address this gap, we employed an existing labeled Roman Urdu (RU) corpus, which was developed originally for Roman Urdu toxic comment classification, and supplemented that corpus by adding its Urdu equivalent transliterations. The motivation behind such an extension is twofold: firstly, to provide a large comprehensive dataset for the classification of toxic comments in Urdu; secondly, to facilitate bidirectional transliteration between Urdu and RU, however, transliteration is currently outside the scope of this study and is envisioned as a future research direction. We introduce the extended corpus as PURUTT (Parallel Urdu and Roman Urdu Corpus for Toxic Comments and Transliteration), boasting 72,771 labeled comments as parallel comments in both Urdu and Roman Urdu scripts. Specific to Urdu toxic comment classification, our methodology begins by training those classification models that were trained on the original Roman Urdu corpus. We leverage pre-trained Word2Vec and FastText Urdu word embeddings to evaluate model performance through transfer learning. Furthermore, we fine-tune five multilingual large language models capitalizing on their inherent multilingual capabilities. To further enhance the classification performance, this study proposes an ensemble approach that aggregates the strengths of multiple base models. Our extensive empirical validation demonstrates the superiority of the ensemble model, achieving a state-of-the-art F1-score of 91.65% on PURUTT, setting a benchmark F1-score on PURUTT corpus for Urdu toxic comment classification.",,,,, ,  ,Translation;Internet;Encoding;Deep learning;Cyberbullying;Bidirectional control;Online services;Guidelines;Encyclopedias;Classification algorithms;Urdu;Urdu parallel corpus;Urdu toxic comments;Urdu toxic comment classification;toxic comment classification;transfer learning;ensemble,out_but_toxicity,
3058,"**Title**Toxic Comment Analyzer using BERT: A Deep Learning Approach for Toxicity Detection

**Abstract**With the good hike of social and communication platforms, a significant increase in the volume of user-generated content is produced. Unfortunately, this surge in online interactions has also led to an increase in toxic and offensive comments. Toxic comments not only contribute to a negative online environment but also have the potential to harm individuals and communities. Consequently, the development of automated methods for detecting toxic comments has become imperative. In this research paper, we propose a toxic comment analyzer using BERT to address this issue. Our approach demonstrates the effectiveness of leveraging pre-trained language models for identifying toxic language, with promising results of 97% accuracy on benchmark datasets.","Singh, Richa, Kashyap, Rekha, Sharma, Vikrant",,,Toxic Comment Analyzer using BERT: A Deep Learning Approach for Toxicity Detection,,,10.1109/ICI60088.2023.10421672 , ,,"With the good hike of social and communication platforms, a significant increase in the volume of user-generated content is produced. Unfortunately, this surge in online interactions has also led to an increase in toxic and offensive comments. Toxic comments not only contribute to a negative online environment but also have the potential to harm individuals and communities. Consequently, the development of automated methods for detecting toxic comments has become imperative. In this research paper, we propose a toxic comment analyzer using BERT to address this issue. Our approach demonstrates the effectiveness of leveraging pre-trained language models for identifying toxic language, with promising results of 97% accuracy on benchmark datasets.",,,,, ,  2023 Second International Conference on Informatics (ICI),Deep learning;Analytical models;Toxicology;User-generated content;Buildings;Surges;Informatics;Toxicity Detection;BERT;Toxic Comment Analyzer,detection,
3059,"**Title**Assamese Toxic Comment Detection On Social Media Using Machine Learning Methods

**Abstract**Social media users across society are negatively impacted by toxic contents. For a strong social environment and safe language models, a toxic comment detection system is designed to protect users from harmful content in Social Media.Toxic Comment Detection in Assamese Languages is one of the most challenging Natural Language Processing (NLP) tasks since Indian languages like Assamese are ambiguous in nature and rich in morphology. Despite dearth of e-resources of Assamese language, 19,550 comments are collected manually from popular social media platforms and examined considering Naive Bayes(NB), Support Vector Machine(SVM), Logistic Regression(LR) and Random Forest(RF) with count vector, count vector+TF-IDF and n-gram representation. The experimental findings show that SVM with count vector + TF-IDF has outperformed all the proposed machine learning models with a remarkable accuracy and F1-score of 94%.","Dutta, Surajit, Neog, Mandira, Baruah, Nomi",,,Assamese Toxic Comment Detection On Social Media Using Machine Learning Methods,,,10.1109/ic-ETITE58242.2024.10493331 , ,,"Social media users across society are negatively impacted by toxic contents. For a strong social environment and safe language models, a toxic comment detection system is designed to protect users from harmful content in Social Media.Toxic Comment Detection in Assamese Languages is one of the most challenging Natural Language Processing (NLP) tasks since Indian languages like Assamese are ambiguous in nature and rich in morphology. Despite dearth of e-resources of Assamese language, 19,550 comments are collected manually from popular social media platforms and examined considering Naive Bayes(NB), Support Vector Machine(SVM), Logistic Regression(LR) and Random Forest(RF) with count vector, count vector+TF-IDF and n-gram representation. The experimental findings show that SVM with count vector + TF-IDF has outperformed all the proposed machine learning models with a remarkable accuracy and F1-score of 94%.",,,,, ,  2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE),Support vector machines;Social networking (online);Morphology;Machine learning;Forestry;Market research;Vectors;Assamese;NB;SVM;LR;RF;Toxic,detection,
3060,"**Title**Toxic Comment Detection Using Bidirectional Sequence Classifiers

**Abstract**With the rising surge of online toxicity, automating the identification of abusive language becomes crucial for improving online discourse. This study proposes a deep learning system that efficiently uses multiple labels to classify harmful comments using bi-directional Long Short-Term Memory (LSTM) networks. By leveraging contextual information, the bi-LSTM model achieves state-of-the-art performance in classifying subtle forms of toxicity such as threats, insults, identity hate, and obscenity. The model achieves above 95% accuracy on benchmark datasets with rigorous data processing, optimized neural architecture, and the utilization of FastText embeddings to handle words that are not in the vocabulary. This technique can automatically filter different levels of toxicity, promoting positive online interactions when integrated into online platforms. The proposed study outlines an end-to-end pipeline incorporating recent NLP advancements and deep contextualized language models to address contemporary challenges in AI-enabled content moderation.","Maity, Amit, More, Rishi, Patil, Prof. Abhijit, Oza, Jay, Kambli, Gitesh",,,Toxic Comment Detection Using Bidirectional Sequence Classifiers,,,10.1109/IDCIoT59759.2024.10467922 , ,,"With the rising surge of online toxicity, automating the identification of abusive language becomes crucial for improving online discourse. This study proposes a deep learning system that efficiently uses multiple labels to classify harmful comments using bi-directional Long Short-Term Memory (LSTM) networks. By leveraging contextual information, the bi-LSTM model achieves state-of-the-art performance in classifying subtle forms of toxicity such as threats, insults, identity hate, and obscenity. The model achieves above 95% accuracy on benchmark datasets with rigorous data processing, optimized neural architecture, and the utilization of FastText embeddings to handle words that are not in the vocabulary. This technique can automatically filter different levels of toxicity, promoting positive online interactions when integrated into online platforms. The proposed study outlines an end-to-end pipeline incorporating recent NLP advancements and deep contextualized language models to address contemporary challenges in AI-enabled content moderation.",,,,, ,  2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT),Training;Surveys;Vocabulary;Toxicology;Benchmark testing;Data models;Surges;natural language processing;sequence modeling;long short-term memory;toxic comment detection;bidirectional classifier,detection,
3061,"**Title**Monitoring Toxic Gases in Dhaka Brick Kiln Areas & Comparing CNN vs. ResNeT for Brick Kiln Identification Via Satellite Imagery in Bangladesh

**Abstract**In developing nations like Bangladesh, clay bricks are essential for construction, but the firing process generates exhaust and toxic gases that degrade air quality and harm local flora and fauna. Ensuring compliance with environmental regulations is crucial for clean environments and public health. In South Asia, small-scale, informal brick producers are significant polluters, making monitoring and regulation challenging. This study presents a cost-effective, scalable method for identifying brick kilns using high-resolution satellite imagery from Bangladesh, sourced from the Kaggle database. Utilizing convolutional neural networks (CNN) and Residual Neural Networks (ResNet) deep learning models on 6,147 satellite images, the approach achieves 100% accuracy and precision in identifying chimney kilns. Additionally, the research employs an Internet of Things (IoT)-based system with Arduino Uno, NodeMCU ESP8266, and MQ-7, MQ-8, and MQ-136 sensors to detect Carbon Monoxide (CO), Hydrogen (H2), and Sulfur Dioxide (SO₂). Experimental results show significantly higher sensor readings in polluted conditions: MQ-7 (clean air: 60.0650 ppm, polluted air: 500.0423 ppm), MQ-8 (clean air: 20.5425 ppm, polluted air: 150.6263 ppm), and MQ-136 (clean air: 70.1921 ppm, polluted air: 200.0489 ppm).","Sakib, Mohammad, Atul, Sadikul Hasan Mridha, Sarkar, Tania, Mia, Hanif, Nafiu, A.S.M. Daiyan Haider, Shahjalal, Md.",,,Monitoring Toxic Gases in Dhaka Brick Kiln Areas & Comparing CNN vs. ResNeT for Brick Kiln Identification Via Satellite Imagery in Bangladesh,,,10.1109/CCE62852.2024.10770920 , ,,"In developing nations like Bangladesh, clay bricks are essential for construction, but the firing process generates exhaust and toxic gases that degrade air quality and harm local flora and fauna. Ensuring compliance with environmental regulations is crucial for clean environments and public health. In South Asia, small-scale, informal brick producers are significant polluters, making monitoring and regulation challenging. This study presents a cost-effective, scalable method for identifying brick kilns using high-resolution satellite imagery from Bangladesh, sourced from the Kaggle database. Utilizing convolutional neural networks (CNN) and Residual Neural Networks (ResNet) deep learning models on 6,147 satellite images, the approach achieves 100% accuracy and precision in identifying chimney kilns. Additionally, the research employs an Internet of Things (IoT)-based system with Arduino Uno, NodeMCU ESP8266, and MQ-7, MQ-8, and MQ-136 sensors to detect Carbon Monoxide (CO), Hydrogen (H2), and Sulfur Dioxide (SO₂). Experimental results show significantly higher sensor readings in polluted conditions: MQ-7 (clean air: 60.0650 ppm, polluted air: 500.0423 ppm), MQ-8 (clean air: 20.5425 ppm, polluted air: 150.6263 ppm), and MQ-136 (clean air: 70.1921 ppm, polluted air: 200.0489 ppm).",,,,, ,"  2024 21st International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)",Deep learning;Kilns;Accuracy;Regulation;Sensor systems;Satellite images;Sensors;Convolutional neural networks;Sulfur;Monitoring;Identification of Brick Kiln;Deep Learning (DL);Internet of Things (IoT);Toxic Gases Monitoring;Cloud;ThingSpeak,out_of_scope,
3062,"**Title**SecureComment: Safeguarding Online Discussions with Intelligent Toxic Comment Filtering

**Abstract**Toxic comments, such as hate speech and abuse, are a widespread issue online, disrupting healthy conversation and user safety. Identifying and filtering these comments is crucial for ensuring respectful online communications. The primary challenge arises from the need to obtain accurate detection while addressing emerging tactics and balancing between false positives and negatives. This concern affects user interactions and platform credibility and raises legal and ethical risks. Therefore, this study examines the effectiveness of numerous machine-learning models and implements an ensemble method for analyzing and classifying toxic comments. We analyze the effectiveness of various algorithms using evaluation metrics like precision, recall, accuracy, and F1-score. Ensemble methods are utilized to combine the capabilities of several models, enhancing the classification of toxic comments. The study aspires to deliver insights into the comparative performance of various machine learning models in classifying toxic comments accurately and the advantages of ensemble methods in enhancing classification accuracy.","Rayani, Reddy Kowshik, Tekula, Samhitha, Vattigunta, Subhash Kovid, Kovi, Naveen Kumar, Namitha, Kalakunnath",,,SecureComment: Safeguarding Online Discussions with Intelligent Toxic Comment Filtering,,,10.1109/IATMSI60426.2024.10503420 , ,,"Toxic comments, such as hate speech and abuse, are a widespread issue online, disrupting healthy conversation and user safety. Identifying and filtering these comments is crucial for ensuring respectful online communications. The primary challenge arises from the need to obtain accurate detection while addressing emerging tactics and balancing between false positives and negatives. This concern affects user interactions and platform credibility and raises legal and ethical risks. Therefore, this study examines the effectiveness of numerous machine-learning models and implements an ensemble method for analyzing and classifying toxic comments. We analyze the effectiveness of various algorithms using evaluation metrics like precision, recall, accuracy, and F1-score. Ensemble methods are utilized to combine the capabilities of several models, enhancing the classification of toxic comments. The study aspires to deliver insights into the comparative performance of various machine learning models in classifying toxic comments accurately and the advantages of ensemble methods in enhancing classification accuracy.",,,,, ,  2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI),Measurement;Technological innovation;Ethics;Machine learning algorithms;Filtering;Law;Hate speech;Toxic comments;Machine learning;Ensemble model;Classification;Twitter dataset,detection,
3063,"**Title**Sorting of Hazardous and Toxic Solid Waste (B3) Using Ensemble Learning Techniques with VGG-16 and DenseNet-121 Architecture

**Abstract**Waste has become an increasingly worrying environmental issue, increasing with population growth and human activity. Indonesia faces a waste emergency with a volume of 35.16 million tonnes by 2022. This research uses Convolutional Neural Networks (CNN) with VGG-16 architecture and DenseNet 121 for classification of seven classes of waste. The dataset from Kaggle consists of 2,900 data with unbalanced distribution. However, promising results were obtained through ensemble modelling combining VGG16 and DenseNet 121. The ensemble approach shows potential in overcoming the weaknesses of a single model and creating a more robust and accurate system. In experiments, VGG achieved 0.76% accuracy with 0.27% loss, while DenseNet achieved 0.79% accuracy with 0.68% loss. The ensemble technique improved the accuracy to 0.83 % with a loss of 0.57%, showing a significant improvement in sewage classification performance over using the architectures separately.","Mufthi, Reza Musthofa, Amalia, Amalia, Sutarman",,,Sorting of Hazardous and Toxic Solid Waste (B3) Using Ensemble Learning Techniques with VGG-16 and DenseNet-121 Architecture,,,10.1109/ELTICOM64085.2024.10864866 , ,,"Waste has become an increasingly worrying environmental issue, increasing with population growth and human activity. Indonesia faces a waste emergency with a volume of 35.16 million tonnes by 2022. This research uses Convolutional Neural Networks (CNN) with VGG-16 architecture and DenseNet 121 for classification of seven classes of waste. The dataset from Kaggle consists of 2,900 data with unbalanced distribution. However, promising results were obtained through ensemble modelling combining VGG16 and DenseNet 121. The ensemble approach shows potential in overcoming the weaknesses of a single model and creating a more robust and accurate system. In experiments, VGG achieved 0.76% accuracy with 0.27% loss, while DenseNet achieved 0.79% accuracy with 0.68% loss. The ensemble technique improved the accuracy to 0.83 % with a loss of 0.57%, showing a significant improvement in sewage classification performance over using the architectures separately.",,,,, ,"  2024 8th International Conference on Electrical, Telecommunication and Computer Engineering (ELTICOM)",Training;Measurement;Waste materials;Solid modeling;Accuracy;Computer architecture;Predictive models;Convolutional neural networks;Ensemble learning;Sorting;CNN;DenseNet-121;Detection Object;Ensemble Learning;Hazardous Waste;VGG-16,out_of_scope,
3064,"**Title**A Topology-Based Approach for Predicting Toxic Outcomes on Twitter and YouTube

**Abstract**The benefits of an information ecosystem based on social media platforms came at the cost of the rise of several antisocial behaviours, including the use of toxic speech. To assess the aspects that concur with the formation of toxic conversations, we provide a multi-platform comparison on Twitter and YouTube between the 2022 Italian Political Elections, representing a potentially polarising topic, and the Italian Football League, a topic close to the country's popular culture. We first probe structural and conversational toxicity differences by analyzing 257 K conversations (3.7 M posts, 1 M users) on both platforms. Then, we provide a machine learning approach that, by leveraging the previous features, identifies the presence of the following toxic comment in different stages of conversations. We show that football tends to exhibit lower toxicity levels than politics, with the latter producing more extended conversations that attract a broader audience and consequently fostering the polarization phenomenon. The implemented classifiers resulting from the conversation stage-based approach achieve state-of-the-art performances despite a restricted set of features. Furthermore, our cross-topic comparison shows that models trained on a divisive topic can be applied to other discussions without causing a degradation of their performance.","Etta, Gabriele, Cinelli, Matteo, Marco, Niccolò Di, Avalle, Michele, Panconesi, Alessandro, Quattrociocchi, Walter",,,A Topology-Based Approach for Predicting Toxic Outcomes on Twitter and YouTube,,,10.1109/TNSE.2024.3398219 , ,,"The benefits of an information ecosystem based on social media platforms came at the cost of the rise of several antisocial behaviours, including the use of toxic speech. To assess the aspects that concur with the formation of toxic conversations, we provide a multi-platform comparison on Twitter and YouTube between the 2022 Italian Political Elections, representing a potentially polarising topic, and the Italian Football League, a topic close to the country's popular culture. We first probe structural and conversational toxicity differences by analyzing 257 K conversations (3.7 M posts, 1 M users) on both platforms. Then, we provide a machine learning approach that, by leveraging the previous features, identifies the presence of the following toxic comment in different stages of conversations. We show that football tends to exhibit lower toxicity levels than politics, with the latter producing more extended conversations that attract a broader audience and consequently fostering the polarization phenomenon. The implemented classifiers resulting from the conversation stage-based approach achieve state-of-the-art performances despite a restricted set of features. Furthermore, our cross-topic comparison shows that models trained on a divisive topic can be applied to other discussions without causing a degradation of their performance.",,,,, ,  ,Oral communication;Social networking (online);Sports;Web sites;Video on demand;Hate speech;Social media;hate speech;information cascades;moderation,out_but_toxicity,
3065,"**Title**Exploring Gender Bias and Toxic Comments Using Artificial Intelligence: Trends and Implications

**Abstract**Nowadays, most systems use artificial intelligence algorithms to automate tasks and reduce the time required for execution. Moreover, it must estimate the bias risks that can be introduced within the system. Based on these considerations, quantitative measures and prioritization strategies can be established for those inadequate situations, choosing an appropriate method to overcome gender bias. In this study, the impact of gender bias on an annual salary risk score due to gender bias was analyzed to identify and reduce it as much as possible in machine learning algorithms and on text data provided to a virtual assistant. The study finds that gender bias can influence our decisions by illustrating hypotheses on how algorithms affect prioritization decisions and strengthen stereotypes by favoring men against women. Recommendations to lower gender bias can include training programs for poor people that face substantial barriers to accessing education; training programs for people with a low level of education or no access; access to all kinds of jobs for women; assurance of diversity and inclusiveness; and algorithms that are fair and trained with the definite goal of reducing gender bias.","Mercioni, Marina Adriana, Holban, Stefan",,,Exploring Gender Bias and Toxic Comments Using Artificial Intelligence: Trends and Implications,,,10.1109/DAS61944.2024.10541152 , ,,"Nowadays, most systems use artificial intelligence algorithms to automate tasks and reduce the time required for execution. Moreover, it must estimate the bias risks that can be introduced within the system. Based on these considerations, quantitative measures and prioritization strategies can be established for those inadequate situations, choosing an appropriate method to overcome gender bias. In this study, the impact of gender bias on an annual salary risk score due to gender bias was analyzed to identify and reduce it as much as possible in machine learning algorithms and on text data provided to a virtual assistant. The study finds that gender bias can influence our decisions by illustrating hypotheses on how algorithms affect prioritization decisions and strengthen stereotypes by favoring men against women. Recommendations to lower gender bias can include training programs for poor people that face substantial barriers to accessing education; training programs for people with a low level of education or no access; access to all kinds of jobs for women; assurance of diversity and inclusiveness; and algorithms that are fair and trained with the definite goal of reducing gender bias.",,,,, ,  2024 International Conference on Development and Application Systems (DAS),Training;Machine learning algorithms;Virtual assistants;Market research;Remuneration;Artificial intelligence;Task analysis;algorithm;artificial intelligence;bias;deep learning;detection;ethical;gender;machine learning;mitigation;risk;salary;workplace,detection,
3066,"**Title**A Comprehensive Examination of Toxic Tweet Classification on Twitter

**Abstract**In recent times, daily interactions have been taking place largely on online platforms, with forms of interactions such as emailsandtextmessages.However,an important problem lies in the understanding of these messages. These textual interchanges can be interpreted in multiple different ways by different people which can cause significant misunderstandings and negative perceptions. The aim of this project is to address this challenge and overcome it by developing a system that is capable of identifying the negativity and toxicity in the tone of the messages. Through rigorous analysis the model aims to identify parts or sequences of a message that might appear as offensive or negative, giving the user constructive feedback on how they can better improve their messages. This helps users to write messages that are not only clearer but also easily received in the intended manner by their audience, thereby increasing the effectiveness of the communication process and reducing misunderstandings. The main goal of this paper is to contribute to the development of an inclusive and understanding online community by using techniques of Natural Language Processing and Machine Learning to solve the complexities of human communication.","Gokulnath, Shreejith Suthraye, Jayaraman, Shrikar, T, Nathezhtha",,,A Comprehensive Examination of Toxic Tweet Classification on Twitter,,,10.1109/ICONSTEM60960.2024.10568694 , ,,"In recent times, daily interactions have been taking place largely on online platforms, with forms of interactions such as emailsandtextmessages.However,an important problem lies in the understanding of these messages. These textual interchanges can be interpreted in multiple different ways by different people which can cause significant misunderstandings and negative perceptions. The aim of this project is to address this challenge and overcome it by developing a system that is capable of identifying the negativity and toxicity in the tone of the messages. Through rigorous analysis the model aims to identify parts or sequences of a message that might appear as offensive or negative, giving the user constructive feedback on how they can better improve their messages. This helps users to write messages that are not only clearer but also easily received in the intended manner by their audience, thereby increasing the effectiveness of the communication process and reducing misunderstandings. The main goal of this paper is to contribute to the development of an inclusive and understanding online community by using techniques of Natural Language Processing and Machine Learning to solve the complexities of human communication.",,,,, ,  2024 Ninth International Conference on Science Technology Engineering and Mathematics (ICONSTEM),Analytical models;Toxicology;Social networking (online);Blogs;Machine learning;Natural language processing;Mathematics;Sentiment Analysis;NLP;Toxic tweet;Logistic Regression,detection,
3067,"**Title**Emergency Response Applications: Dynamic Plume Modeling and Real-Time Routing

**Abstract**In a crisis situation, toxic gas can be released into the air, blocking routes for emergency responders. Rescue workers must be able to compute the shortest and safest paths in the presence of toxic gas dispersions that move dynamically with changing wind speed and direction. To model this, the authors developed weather retriever software, which fetches weather details about a particular location from the Internet and acts as the station for atmospheric measurements for the Aloha plume-modeling software. The authors also explored options for displaying this dynamic plume on a geographic map.","Chitumalla, Pavan Kumar, Harris, Douglas, Thuraisingham, Bhavani, Khan, Latifur",,,Emergency Response Applications: Dynamic Plume Modeling and Real-Time Routing,,,10.1109/MIC.2008.11 , ,,"In a crisis situation, toxic gas can be released into the air, blocking routes for emergency responders. Rescue workers must be able to compute the shortest and safest paths in the presence of toxic gas dispersions that move dynamically with changing wind speed and direction. To model this, the authors developed weather retriever software, which fetches weather details about a particular location from the Internet and acts as the station for atmospheric measurements for the Aloha plume-modeling software. The authors also explored options for displaying this dynamic plume on a geographic map.",,,,, ,  ,Routing;Atmospheric modeling;Application software;Wind speed;Chemical hazards;Atmosphere;Fires;Geographic Information Systems;Clouds;Internet;dynamic plume modeling;real-time routing;GIS and crisis management;toxic gas modeling,out_of_scope,
3068,"**Title**K- Nearest Neighbour-Based Chronic Kidney Disease Prediction System: A Case of Toxic Metals in Urine

**Abstract**Loss of renal function is a symptom of chronic kidney disease (CKD). Numerous lives are lost each year as a result of the disease, which frequently has symptoms that are not obvious. Since kidney disease is a progressive condition, it spreads quickly and eventually causes a decline in kidney function. Using factors like age, bacteria, diabetes mellitus, and white blood cell count to name a few, previous studies predicted kidney illness, but they did not incorporate toxic metals in urine. Using machine learning methods, CKD may be predicted with a high degree of accuracy in medical investigations. Thus, this study uses three of the supervised classification methods learning algorithms, which include, Decision tree, Random Forest, and K Nearest Neighbor (KNN) algorithms for the prediction of CKD. A raw dataset of hazardous metals in urine that was gathered from two Nigerian hospitals was used to analyze the performance of the algorithms' predictions. Copper (Cu), Zinc (Zn), Iron (Fe), Lead (Pb), Magnesium (Mg), Chromium (Cr), Cadmium (Cd), and Selenium (Se) are some of these metals. Based on how accurate the results were, a performance analysis was carried out. According to the comparison of the algorithms, the KNN method, which has the highest accuracy, is ideal for predicting chronic renal disease. This work created a system to predict CKD along five classifications using the KNN algorithm.","Tope-Oke, Adebusola, Badeji-Ajisafe, Bukola, Oguntimilehin, Abiodun, Inyang, Martin Victor, Aweh, Opani, Abiola, Oluwatoyin",,,K- Nearest Neighbour-Based Chronic Kidney Disease Prediction System: A Case of Toxic Metals in Urine,,,10.1109/SEB4SDG60871.2024.10630163 , ,,"Loss of renal function is a symptom of chronic kidney disease (CKD). Numerous lives are lost each year as a result of the disease, which frequently has symptoms that are not obvious. Since kidney disease is a progressive condition, it spreads quickly and eventually causes a decline in kidney function. Using factors like age, bacteria, diabetes mellitus, and white blood cell count to name a few, previous studies predicted kidney illness, but they did not incorporate toxic metals in urine. Using machine learning methods, CKD may be predicted with a high degree of accuracy in medical investigations. Thus, this study uses three of the supervised classification methods learning algorithms, which include, Decision tree, Random Forest, and K Nearest Neighbor (KNN) algorithms for the prediction of CKD. A raw dataset of hazardous metals in urine that was gathered from two Nigerian hospitals was used to analyze the performance of the algorithms' predictions. Copper (Cu), Zinc (Zn), Iron (Fe), Lead (Pb), Magnesium (Mg), Chromium (Cr), Cadmium (Cd), and Selenium (Se) are some of these metals. Based on how accurate the results were, a performance analysis was carried out. According to the comparison of the algorithms, the KNN method, which has the highest accuracy, is ideal for predicting chronic renal disease. This work created a system to predict CKD along five classifications using the KNN algorithm.",,,,, ,"  2024 International Conference on Science, Engineering and Business for Driving Sustainable Development Goals (SEB4SDG)",Accuracy;Machine learning algorithms;Nearest neighbor methods;Lead;Prediction algorithms;Chronic kidney disease;Classification algorithms;Chronic kidney disease;Decision Tree;Random Forest;KNN,out_of_scope,
3069,"**Title**Detection of Hazardous gases using Deep Learning on Benchmark Dataset

**Abstract**The leakage of gas emission is a most critical aspect to be considered in House appliances, Industries, Coal Mines, Transportation, etc. Leakage of gas identification at early stage is more important to avoid harmful to human beings and environment. Sensors are used to detect these hazardous gases. Low-cost sensors are less in both sensitivity and reliability to detect the gases from farther distances. In this paper Bi-LSTM model with parameter tuning is applied on publicly available dataset and obtained an accuracy of 93.5%, 92% of sensitivity, and 95% specificity with the public dataset.","N, Madhuram., R, Kalpana.",,,Detection of Hazardous gases using Deep Learning on Benchmark Dataset,,,10.1109/GCITC60406.2023.10426593 , ,,"The leakage of gas emission is a most critical aspect to be considered in House appliances, Industries, Coal Mines, Transportation, etc. Leakage of gas identification at early stage is more important to avoid harmful to human beings and environment. Sensors are used to detect these hazardous gases. Low-cost sensors are less in both sensitivity and reliability to detect the gases from farther distances. In this paper Bi-LSTM model with parameter tuning is applied on publicly available dataset and obtained an accuracy of 93.5%, 92% of sensitivity, and 95% specificity with the public dataset.",,,,, ,  2023 Global Conference on Information Technologies and Communications (GCITC),Industries;Deep learning;Gases;Sensitivity;Transportation;Sensors;Tuning;Gas leaks;Hazardous gases;Bi-LSTM,out_of_scope,
3070,"**Title**Simulation of T-S Fuzzy Neural Network to UASB Reactor Shocked by Toxic Loading

**Abstract**The neural network was conducted based on the Takagi-Sugeno fuzzy systems. Predictions of the biogas production rate, volatile fatty acid and CH4 for the UASB reactor were made using fuzzy neural network based on database collected from the anaerobic system shocked by the Chloroform and 2, 4-dinitrophenol loading. The correlation coefficients of observed and simulated values were above 0.940 for the training set, and above 0.860 for testing set. The results showed that fuzzy neural network can perfectly predict the performance of UASB shocked by the toxic loading, and has greatly adaptability to the variations of the anaerobic treatment system .","Cao, Gang, Li, Mingyu, Mo, Cehui",,,Simulation of T-S Fuzzy Neural Network to UASB Reactor Shocked by Toxic Loading,,,10.1109/CIS.2007.27 , ,,"The neural network was conducted based on the Takagi-Sugeno fuzzy systems. Predictions of the biogas production rate, volatile fatty acid and CH4 for the UASB reactor were made using fuzzy neural network based on database collected from the anaerobic system shocked by the Chloroform and 2, 4-dinitrophenol loading. The correlation coefficients of observed and simulated values were above 0.940 for the training set, and above 0.860 for testing set. The results showed that fuzzy neural network can perfectly predict the performance of UASB shocked by the toxic loading, and has greatly adaptability to the variations of the anaerobic treatment system .",,,,, ,  2007 International Conference on Computational Intelligence and Security (CIS 2007),Fuzzy neural networks;Inductors;Artificial neural networks;Bioreactors;Fuzzy systems;Wastewater treatment;Neural networks;Takagi-Sugeno model;Electric shock;Fuzzy set theory,out_of_scope,
3071,"**Title**An Automatic Approach for the Identification of Offensive Language in Perso-Arabic Urdu Language: Dataset Creation and Evaluation

**Abstract**Offensive language is a type of unacceptable language that is impolite amongst individuals, specific community groups, and society as well. With the advent of various social media platforms, offensive language usage has been widely reported, thus developing a toxic online environment that has real-life endangers within society. Therefore, to foster a culture of respect and acceptance, a prompt response is needed to combat offensive content. On the other hand, the identification of offensive language has become a challenging task, specifically in low-resource languages such as Urdu. Urdu text poses challenges because of its unique features, complex script, and rich morphology. Applying methods directly that work in other languages is difficult. It also requires exploring new linguistic features and computational techniques on a relatively large dataset to ensure the results can be generalized effectively. Unfortunately, the Urdu language got very limited attention from the research community due to the scarcity of language resources and the non-availability of high-quality datasets and models. This study addresses those challenges, firstly by collecting and annotating a dataset of 12020 Urdu tweets using OLID taxonomy as a benchmark. Secondly, by extracting character-level and word-level features based on bag-of-words, n-grams and TFIDF representation. Finally, an extensive series of experiments were conducted on the extracted features using seven machine learning classifiers to identify the most effective features and classifiers. The experimental findings indicate that word unigrams, character trigrams, and word TFIDF are the most prominent ones. Similarly, among the classifiers, logistic regression and support vector machine attained the highest accuracy of 86% and F1-Score of 75%.","Ud Din, Salah, Khusro, Shah, Ali Khan, Farman, Ahmad, Munir, Ali, Oualid, Ghazal, Taher M.",,,An Automatic Approach for the Identification of Offensive Language in Perso-Arabic Urdu Language: Dataset Creation and Evaluation,,,10.1109/ACCESS.2025.3534662 , ,,"Offensive language is a type of unacceptable language that is impolite amongst individuals, specific community groups, and society as well. With the advent of various social media platforms, offensive language usage has been widely reported, thus developing a toxic online environment that has real-life endangers within society. Therefore, to foster a culture of respect and acceptance, a prompt response is needed to combat offensive content. On the other hand, the identification of offensive language has become a challenging task, specifically in low-resource languages such as Urdu. Urdu text poses challenges because of its unique features, complex script, and rich morphology. Applying methods directly that work in other languages is difficult. It also requires exploring new linguistic features and computational techniques on a relatively large dataset to ensure the results can be generalized effectively. Unfortunately, the Urdu language got very limited attention from the research community due to the scarcity of language resources and the non-availability of high-quality datasets and models. This study addresses those challenges, firstly by collecting and annotating a dataset of 12020 Urdu tweets using OLID taxonomy as a benchmark. Secondly, by extracting character-level and word-level features based on bag-of-words, n-grams and TFIDF representation. Finally, an extensive series of experiments were conducted on the extracted features using seven machine learning classifiers to identify the most effective features and classifiers. The experimental findings indicate that word unigrams, character trigrams, and word TFIDF are the most prominent ones. Similarly, among the classifiers, logistic regression and support vector machine attained the highest accuracy of 86% and F1-Score of 75%.",,,,, ,  ,Feature extraction;Support vector machines;Cyberbullying;Web sites;Taxonomy;Guidelines;Accuracy;Video on demand;Object recognition;Linguistics;Offensive language identification;Urdu language dataset;OLID taxonomy;machine learning classifiers;cyberbullying;hate speech;profanity,out_but_toxicity,
3072,"**Title**Enhancing Social Media Safety with Automated Toxicity Classification using Semantic Topic Models

**Abstract**In social media platforms, there is a growing interest in developing automated solutions for toxicity classification using machine learning algorithms. This paper presents a novel approach to automated toxicity classification using semantic topic models, achieving high accuracy and transparency. The report emphasizes the importance of detecting and adjusting for biases to ensure fair categorization. Moreover, the report highlights the challenges of natural language processing tasks, importance of understanding and addressing potential biases in machine learning models. Datasets are produced by the Origami project at Google, labeled by human labelers with adjectives such as ""toxic,"" ""very poisonous,"" ""accusation,"" ""danger,"" ""obscene,"" and ""identity hatred."" From the analysis, it shows that proposed method achieved better results on toxicity classification in terms of accuracy (0.85), precision (0.87), recall (0.84) and f1-score (0.85) respectively. For non-toxicity classification, the proposed method achieves accuracy (0.92), precision (0.89), recall (0.88), f1-score (0.88) and AUC-ROC (0.96) respectively.","Enquero, Shreya Patchala, Lande, Jayapal, Syamala, M., Priyadarsan, Padhyala, V, Sunil Kumar",,,Enhancing Social Media Safety with Automated Toxicity Classification using Semantic Topic Models,,,10.1109/EASCT59475.2023.10393723 , ,,"In social media platforms, there is a growing interest in developing automated solutions for toxicity classification using machine learning algorithms. This paper presents a novel approach to automated toxicity classification using semantic topic models, achieving high accuracy and transparency. The report emphasizes the importance of detecting and adjusting for biases to ensure fair categorization. Moreover, the report highlights the challenges of natural language processing tasks, importance of understanding and addressing potential biases in machine learning models. Datasets are produced by the Origami project at Google, labeled by human labelers with adjectives such as ""toxic,"" ""very poisonous,"" ""accusation,"" ""danger,"" ""obscene,"" and ""identity hatred."" From the analysis, it shows that proposed method achieved better results on toxicity classification in terms of accuracy (0.85), precision (0.87), recall (0.84) and f1-score (0.85) respectively. For non-toxicity classification, the proposed method achieves accuracy (0.92), precision (0.89), recall (0.88), f1-score (0.88) and AUC-ROC (0.96) respectively.",,,,, ,  2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT),Toxicology;Sensitivity;Social networking (online);Semantics;Machine learning;Natural language processing;Safety;Latent Dirichlet Allocation;Machine Learning Methods;Natural Language Processing;Semantic Topic Models;Social Media Safety;Support Vector Machine;Toxic Comments,detection,
3073,"**Title**iMRSA-Fuse: A Fast and Accurate Computational Approach for Predicting Anti-MRSA Peptides by Fusing Multi-View Information

**Abstract**Methicillin-resistant S. aureus (MRSA) has prominently emerged among the recognized causes of community-acquired and hospital infections. We proposed a novel computational approach, iMRSA-Fuse, based on a multi-view feature fusion strategy for fast and accurate anti-MRSA peptide identification. In iMRSA-Fuse, we explored and integrated 12 different sequence-based feature descriptors from multiple perspectives, in conjunction with 12 popular machine learning (ML) algorithms, to construct multi-view features that were able to fully capture the useful information of anti-MRSA peptides. Additionally, we applied our customized genetic algorithm to determine a set of multi-view features to enhance its discriminative ability. Based on a series of comparative results, our multi-view features exhibited the most discriminative ability compared to several conventional feature descriptors. Moreover, concerning the independent test dataset, iMRSA-Fuse achieved the best balanced accuracy (BACC) and Matthew's correlation coefficient (MCC) of 0.997 and 0.981, respectively with an increase of 3.93 and 7.78%, respectively. Finally, to facilitate the large-scale identification of candidate anti-MRSA peptides, a user-friendly web server of the iMRSA-Fuse model is constructed and is freely accessible at https://pmlabqsar.pythonanywhere.com/iMRSA-Fuse. We anticipate that this new computational approach will be effectively applied to screen and prioritize candidate peptides that might exhibit the great anti-MRSA activities.","Charoenkwan, Phasit, Schaduangrat, Nalini, Moni, Mohammad Ali, Shoombuatong, Watshara",,,iMRSA-Fuse: A Fast and Accurate Computational Approach for Predicting Anti-MRSA Peptides by Fusing Multi-View Information,,,10.1109/TCBBIO.2024.3496503 , ,,"Methicillin-resistant S. aureus (MRSA) has prominently emerged among the recognized causes of community-acquired and hospital infections. We proposed a novel computational approach, iMRSA-Fuse, based on a multi-view feature fusion strategy for fast and accurate anti-MRSA peptide identification. In iMRSA-Fuse, we explored and integrated 12 different sequence-based feature descriptors from multiple perspectives, in conjunction with 12 popular machine learning (ML) algorithms, to construct multi-view features that were able to fully capture the useful information of anti-MRSA peptides. Additionally, we applied our customized genetic algorithm to determine a set of multi-view features to enhance its discriminative ability. Based on a series of comparative results, our multi-view features exhibited the most discriminative ability compared to several conventional feature descriptors. Moreover, concerning the independent test dataset, iMRSA-Fuse achieved the best balanced accuracy (BACC) and Matthew's correlation coefficient (MCC) of 0.997 and 0.981, respectively with an increase of 3.93 and 7.78%, respectively. Finally, to facilitate the large-scale identification of candidate anti-MRSA peptides, a user-friendly web server of the iMRSA-Fuse model is constructed and is freely accessible at https://pmlabqsar.pythonanywhere.com/iMRSA-Fuse. We anticipate that this new computational approach will be effectively applied to screen and prioritize candidate peptides that might exhibit the great anti-MRSA activities.",,,,, ,  ,Peptides;Amino acids;Encoding;Bioinformatics;Biological system modeling;Feature extraction;Computational modeling;Accuracy;Random forests;Immune system;Anti-MRSA peptide;sequence analysis;bioinformatics;machine learning;feature representation;multi-view feature,out_of_scope,
3074,"**Title**Toxic Comments Classification using LSTM and CNN

**Abstract**Online platforms have grown to be an important medium for expression and communication in the digital era. But the anonymity and absence of in-person communication on these platforms often encourage the spread of offensive remarks, which can be harmful to both people and communities. Before classifying comments as dangerous, natural language processing, or NLP, must first comprehend and assess textual data in order to identify feelings, patterns, and context that may be harmful. Tokenizing the comments, generating features for the classification model, and preprocessing the text input are all done in this instance using natural language processing approaches. Specific NLP methods such as sequence padding, text vectorization, and tokenization may be covered in more detail. This study combines the architectures of Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) to present a unique technique for categorizing harmful remarks. This study pre-processes the text data to eliminate noise and unnecessary information. Next, we use word embeddings to embed the comments into numerical vectors. Next, in order to capture the spatial and sequential relationships present in the text data, this study uses a hybrid model that combines CNN and LSTM layers. The CNN component assists in identifying local patterns and characteristics in the comments, while the LSTM component allows the model to comprehend the sequential flow of language. This study uses a publicly accessible dataset of labelled harmful remarks to train and assess the proposed model. The proposed model’s performance is measured using common measures including accuracy, precision, recall, and F1-score.","Bhattacharya, Sampurna, Shankar, Bhavani Gowri, Pitchaimanickam, B., Nithya, A. Alice",,,Toxic Comments Classification using LSTM and CNN,,,10.1109/ICAAIC60222.2024.10575718 , ,,"Online platforms have grown to be an important medium for expression and communication in the digital era. But the anonymity and absence of in-person communication on these platforms often encourage the spread of offensive remarks, which can be harmful to both people and communities. Before classifying comments as dangerous, natural language processing, or NLP, must first comprehend and assess textual data in order to identify feelings, patterns, and context that may be harmful. Tokenizing the comments, generating features for the classification model, and preprocessing the text input are all done in this instance using natural language processing approaches. Specific NLP methods such as sequence padding, text vectorization, and tokenization may be covered in more detail. This study combines the architectures of Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) to present a unique technique for categorizing harmful remarks. This study pre-processes the text data to eliminate noise and unnecessary information. Next, we use word embeddings to embed the comments into numerical vectors. Next, in order to capture the spatial and sequential relationships present in the text data, this study uses a hybrid model that combines CNN and LSTM layers. The CNN component assists in identifying local patterns and characteristics in the comments, while the LSTM component allows the model to comprehend the sequential flow of language. This study uses a publicly accessible dataset of labelled harmful remarks to train and assess the proposed model. The proposed model’s performance is measured using common measures including accuracy, precision, recall, and F1-score.",,,,, ,  2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC),Deep learning;Soft sensors;Noise;Data preprocessing;Data models;Vectors;Tokenization;Machine learning;Convolutional Neural Network;Long Short Term memory,detection,
3075,"**Title**Monitoring the Flue Gas Using a Fuzzy Neural Network Based Artificial Olfactory System

**Abstract**The potential of artificial olfactory technique for on-line monitoring of waste flue gas at different incineration temperatures was examined based on a metal oxide gas sensors array. The sensors signals from 120 samples of flue gas were collected at temperatures from 650 to 950°C. Statistical methods used in this study were principal component analysis (PCA), Linear discriminant analysis (LDA) and Fuzzy neural network (FNN). PCA and LDA were used to reduce the dimensionality and visualization of datasets. The FNN model was achieved with a high discrimination accuracy rate of 85%. Thus, an effective way to discriminate flue gas under different incineration temperatures was put forward.","Zhou, Bo, Zhao, Shitian, Cai, Guohua",,,Monitoring the Flue Gas Using a Fuzzy Neural Network Based Artificial Olfactory System,,,10.1109/ICMTMA.2015.166 , ,,"The potential of artificial olfactory technique for on-line monitoring of waste flue gas at different incineration temperatures was examined based on a metal oxide gas sensors array. The sensors signals from 120 samples of flue gas were collected at temperatures from 650 to 950°C. Statistical methods used in this study were principal component analysis (PCA), Linear discriminant analysis (LDA) and Fuzzy neural network (FNN). PCA and LDA were used to reduce the dimensionality and visualization of datasets. The FNN model was achieved with a high discrimination accuracy rate of 85%. Thus, an effective way to discriminate flue gas under different incineration temperatures was put forward.",,,,, ,  2015 Seventh International Conference on Measuring Technology and Mechatronics Automation,Incineration;Temperature sensors;Olfactory;Principal component analysis;Monitoring;Gas detectors;artificial olfactory;waste fuel gas;temperatures;statistical methods,out_of_scope,
3076,"**Title**Identification of Skin Conditions with Convolutional Neural Networks: A Deep Learning Approach

**Abstract**This paper presents a robust approach for detecting skin diseases using advanced image detection methods supported by Convolutional Neural Network (CNN) models. Traditionally, skin diseases are diagnosed by experienced dermatologists. However, due to a scarcity of these specialists, there is a pressing need for alternative, reliable solutions. Our methodology capitalizes on image detection techniques to accurately and efficiently identify potential skin diseases from photographs. The cornerstone of our approach is the CNN model, which is renowned for its efficacy in processing visual data. The system we developed demonstrates a high level of accuracy, achieving a validation accuracy of at least 80 % in the identification of specific skin diseases. This level of precision is particularly noteworthy, considering the inherent challenges in diagnosing skin conditions through images. Despite this success, our research also acknowledges the difficulties in gathering a vast, diverse dataset of skin disease images from the internet. Such datasets are crucial for training and refining our model to ensure its effectiveness across various skin types and conditions. Furthermore, this paper investigates the factors that might lead to inaccuracies in predictions. It addresses common issues such as variations in image quality, lighting conditions, and the presence of similar-looking skin conditions, which can all potentially confound the model's decision-making process. By understanding and mitigating these factors, we aim to enhance the model's reliability and accuracy, moving closer to bridging the gap between automated detection and expert human diagnosis. This research not only contributes to the field of medical image analysis but also offers a promising tool for assisting dermatologists and improving patient outcomes in skin disease diagnosis.","Leong, Jing En, Goh, Ching Pang",,,Identification of Skin Conditions with Convolutional Neural Networks: A Deep Learning Approach,,,10.1109/ICDXA61007.2024.10470649 , ,,"This paper presents a robust approach for detecting skin diseases using advanced image detection methods supported by Convolutional Neural Network (CNN) models. Traditionally, skin diseases are diagnosed by experienced dermatologists. However, due to a scarcity of these specialists, there is a pressing need for alternative, reliable solutions. Our methodology capitalizes on image detection techniques to accurately and efficiently identify potential skin diseases from photographs. The cornerstone of our approach is the CNN model, which is renowned for its efficacy in processing visual data. The system we developed demonstrates a high level of accuracy, achieving a validation accuracy of at least 80 % in the identification of specific skin diseases. This level of precision is particularly noteworthy, considering the inherent challenges in diagnosing skin conditions through images. Despite this success, our research also acknowledges the difficulties in gathering a vast, diverse dataset of skin disease images from the internet. Such datasets are crucial for training and refining our model to ensure its effectiveness across various skin types and conditions. Furthermore, this paper investigates the factors that might lead to inaccuracies in predictions. It addresses common issues such as variations in image quality, lighting conditions, and the presence of similar-looking skin conditions, which can all potentially confound the model's decision-making process. By understanding and mitigating these factors, we aim to enhance the model's reliability and accuracy, moving closer to bridging the gap between automated detection and expert human diagnosis. This research not only contributes to the field of medical image analysis but also offers a promising tool for assisting dermatologists and improving patient outcomes in skin disease diagnosis.",,,,, ,  2024 3rd International Conference on Digital Transformation and Applications (ICDXA),Training;Visualization;Solid modeling;Computational modeling;Training data;Skin;Data models;skin disease;image processing;image classification;dermatology;CNN,out_of_scope,
3077,"**Title**Preserving Data Integrity and Detecting Toxic Recordings in Machine Learning using Blockchain

**Abstract**Machine Learning (ML) is receiving unprecedented hype and attention. However, the ML runtime environment is still at risk from threats, such as manipulation of model parameters or contradictory poisoning of training datasets. A blockchain is a technology that combines a set of existing techniques, protocols, and tools to form a distributed and secure ledger of all transactions. This article examines and proposes a way of integrating ML suitable for Blockchain to protect the training dataset and model parameters. Another major contribution of this work is the deployment and securing of the decision process of ML, Support Vector Machine (SVM), and Multi-Layer Perceptron (MLP) models. This smart contract-based deployment has equipped the Blockchain-based system to detect toxic recordings intelligently. The effectiveness of this proposed approach is measured in both its detection capabilities and its operational efficiency, by applying a case study of medical records as a sensitive area that tested the performance of this approach.","Alaya, Bechir, Moulahi, Tarek, Khediri, Salim El, Aladhadh, Suliman",,,Preserving Data Integrity and Detecting Toxic Recordings in Machine Learning using Blockchain,,,10.1109/WoWMoM60985.2024.00015 , ,,"Machine Learning (ML) is receiving unprecedented hype and attention. However, the ML runtime environment is still at risk from threats, such as manipulation of model parameters or contradictory poisoning of training datasets. A blockchain is a technology that combines a set of existing techniques, protocols, and tools to form a distributed and secure ledger of all transactions. This article examines and proposes a way of integrating ML suitable for Blockchain to protect the training dataset and model parameters. Another major contribution of this work is the deployment and securing of the decision process of ML, Support Vector Machine (SVM), and Multi-Layer Perceptron (MLP) models. This smart contract-based deployment has equipped the Blockchain-based system to detect toxic recordings intelligently. The effectiveness of this proposed approach is measured in both its detection capabilities and its operational efficiency, by applying a case study of medical records as a sensitive area that tested the performance of this approach.",,,,, ,"  2024 IEEE 25th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)",Support vector machines;Training;Wireless communication;Smart contracts;Machine learning;Blockchains;Recording;Machine Learning;Poisoning Attack;Blockchain;Smart Contract;SVM;MLP,out_of_scope,
3078,"**Title**Pre-processing aspects for complexity reduction of the QSAR problem

**Abstract**Predictive Toxicology (PT) is one of the newest targets of the Knowledge Discovery in Databases (KDD) domain. Its goal is to describe the relationships between the chemical structure of chemical compounds and biological and toxicological processes. In real PT problems there is a very important topic to be considered: the huge number of the chemical descriptors. Irrelevant, redundant, noisy and unreliable data have a negative impact, therefore one of the main goals in KDD is to detect these undesirable proprieties and to eliminate or correct them. This assumes data cleaning, noise reduction and feature selection because the performance of the applied Machine Learning algorithms is strongly related with the quality of the data used. In this paper, we present some of the issues that can be taken into account for preparing data before the actual knowledge discovery is performed.","Dumitriu, L., Segal, C., Craciun, M-V., Cocu, A.",,,Pre-processing aspects for complexity reduction of the QSAR problem,,,10.1109/IS.2008.4670547 , ,,"Predictive Toxicology (PT) is one of the newest targets of the Knowledge Discovery in Databases (KDD) domain. Its goal is to describe the relationships between the chemical structure of chemical compounds and biological and toxicological processes. In real PT problems there is a very important topic to be considered: the huge number of the chemical descriptors. Irrelevant, redundant, noisy and unreliable data have a negative impact, therefore one of the main goals in KDD is to detect these undesirable proprieties and to eliminate or correct them. This assumes data cleaning, noise reduction and feature selection because the performance of the applied Machine Learning algorithms is strongly related with the quality of the data used. In this paper, we present some of the issues that can be taken into account for preparing data before the actual knowledge discovery is performed.",,,,, ,  2008 4th International IEEE Conference Intelligent Systems,Chemical compounds;Data mining;Toxicology;Pattern recognition;Principal component analysis;Databases;Noise reduction;Neural networks;Statistical analysis;Pattern analysis;toxicology;prediction;knowledge discovery in databases,out_of_scope,
3079,"**Title**Advanced YOLO-Based Trash Classification and Recycling Assistant for Enhanced Waste Management and Sustainability

**Abstract**The ever-growing global population has heightened resource consumption and waste generation, emphasizing the quick need for effective waste management to safeguard the environment. Unfortunately, the recycling industry grapples with persistent challenges, primarily in accurate trash classification, a critical factor for successful recycling. Manual sorting, often prone to errors due to subjective human judgment, hampers the recycling process, contributing to inefficiencies. Furthermore, the inherent risks associated with direct contact during the sorting of hazardous materials pose serious health concerns for the workers involved. In response to these challenges, we propose a revolutionary solution: the Trash Classification and Recycling Assistant utilizing YOLO variants V5-V7. This system, rooted in image classification techniques, seeks to elevate the precision of trash sorting. Notably, YOLO variant V7 emerges as the frontrunner, showcasing remarkable accuracy improvements. By utilizing the capabilities of advanced technology, this innovative approach not only streamlines waste sorting processes but also mitigates health risks linked to manual handling of toxic materials. The integration of YOLO variants V5-V7 represents a pivotal step towards ushering in a new era of efficiency and accuracy in recycling practices, thus significantly contributing to the overarching goal of environmental sustainability.","Vimal Kumar, M. Guru, Kumar, Madde, Narayana Rao, K, Syamala Rao, P, Tirumala, Arepalli, Patnala, Eswar",,,Advanced YOLO-Based Trash Classification and Recycling Assistant for Enhanced Waste Management and Sustainability,,,10.1109/ICoICI62503.2024.10696214 , ,,"The ever-growing global population has heightened resource consumption and waste generation, emphasizing the quick need for effective waste management to safeguard the environment. Unfortunately, the recycling industry grapples with persistent challenges, primarily in accurate trash classification, a critical factor for successful recycling. Manual sorting, often prone to errors due to subjective human judgment, hampers the recycling process, contributing to inefficiencies. Furthermore, the inherent risks associated with direct contact during the sorting of hazardous materials pose serious health concerns for the workers involved. In response to these challenges, we propose a revolutionary solution: the Trash Classification and Recycling Assistant utilizing YOLO variants V5-V7. This system, rooted in image classification techniques, seeks to elevate the precision of trash sorting. Notably, YOLO variant V7 emerges as the frontrunner, showcasing remarkable accuracy improvements. By utilizing the capabilities of advanced technology, this innovative approach not only streamlines waste sorting processes but also mitigates health risks linked to manual handling of toxic materials. The integration of YOLO variants V5-V7 represents a pivotal step towards ushering in a new era of efficiency and accuracy in recycling practices, thus significantly contributing to the overarching goal of environmental sustainability.",,,,, ,  2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI),YOLO;Waste management;Hazardous materials;Industries;Accuracy;Manuals;Streaming media;Recycling;Sorting;Image classification;Trash Classification and Recycling;YOLO variants;trash sorting;waste sorting processes;toxic materials,out_of_scope,
3080,"**Title**Addressing Unintended Bias in Toxicity Detection: An LSTM and Attention-Based Approach

**Abstract**In the digital era, online platforms serve as crucial hubs for social interactions and idea exchange. However, these platforms are continually shadowed by toxic comments that undermine genuine discourse and have the potential to harm participants. While machine learning provides an avenue for detecting such toxic content, a significant challenge arises when these models, influenced by biased training datasets, inadvertently propagate or amplify inherent biases. Such unintentional biases are especially disconcerting when they disadvantage or misrepresent identities already vulnerable in online spaces. Addressing this complex landscape, our research presents a model meticulously designed to detect toxic comments, aiming to achieve a higher degree of accuracy while striving to minimize such unintended biases. Our approach is underpinned by a combination of a tailored data preprocessing technique and the integration of Long Short-Term Memory networks (LSTM) with Attention mechanisms. Preliminary evaluations reveal our model's AVC score to be 0.93524, indicating its efficacy in toxicity detection. While there's always room for improvement, the design and results of our model emphasize the importance and feasibility of developing more nuanced and unbiased machine learning solutions for the challenges posed in the digital domain.","Dai, Weinan, Tao, Jinglei, Yan, Xu, Feng, Zhenyuan, Chen, Jinkun",,,Addressing Unintended Bias in Toxicity Detection: An LSTM and Attention-Based Approach,,,10.1109/ICAICA58456.2023.10405429 , ,,"In the digital era, online platforms serve as crucial hubs for social interactions and idea exchange. However, these platforms are continually shadowed by toxic comments that undermine genuine discourse and have the potential to harm participants. While machine learning provides an avenue for detecting such toxic content, a significant challenge arises when these models, influenced by biased training datasets, inadvertently propagate or amplify inherent biases. Such unintentional biases are especially disconcerting when they disadvantage or misrepresent identities already vulnerable in online spaces. Addressing this complex landscape, our research presents a model meticulously designed to detect toxic comments, aiming to achieve a higher degree of accuracy while striving to minimize such unintended biases. Our approach is underpinned by a combination of a tailored data preprocessing technique and the integration of Long Short-Term Memory networks (LSTM) with Attention mechanisms. Preliminary evaluations reveal our model's AVC score to be 0.93524, indicating its efficacy in toxicity detection. While there's always room for improvement, the design and results of our model emphasize the importance and feasibility of developing more nuanced and unbiased machine learning solutions for the challenges posed in the digital domain.",,,,, ,  2023 5th International Conference on Artificial Intelligence and Computer Applications (ICAICA),Training;Deep learning;Ethics;Toxicology;Data preprocessing;Robustness;Long short term memory;Toxicity Detection;LSTM;Attention Mechanism;Data Preprocessing,detection,
3081,"**Title**Naive Data Augmentation Might Be Toxic: Data-Prior Guided Self-Supervised Representation Learning for Micro-Gesture Recognition

**Abstract**Body gestures play an important role in nonverbal communication because they transmit emotional information. Recently, a specific group of gestures, so-called Micro-gestures (MGs), has drawn increasing research interests in the community, as they can be useful cues to interpret human inner feelings. In this study, we focused on recognizing MG via self-supervised learning from skeleton sequences with several contributions. Initially, we observed that existing data augmentation methods for skeleton data always fail in MG representation learning. Our investigation shows that the failure is caused by the inherent properties of real-world datasets, such as imbalanced/long-tail data distribution, intra-class ambiguity, and inter-class heterogeneity. Thus, we propose a novel prior-guided augmentation strategy that can preserve the original data distribution while maximizing the agreement between samples in self-supervised learning. Furthermore, we proposed a three-stream architecture of self-supervised presentation learning for micro-gestures via spatial/temporal masking to jointly enhance the learning of invariant features. Lastly, the experimental results show that our proposed method has achieved state-of-the-art performances on two public MG datasets.","Shah, Atif, Chen, Haoyu, Zhao, Guoying",,,Naive Data Augmentation Might Be Toxic: Data-Prior Guided Self-Supervised Representation Learning for Micro-Gesture Recognition,,,10.1109/FG59268.2024.10581907 , ,,"Body gestures play an important role in nonverbal communication because they transmit emotional information. Recently, a specific group of gestures, so-called Micro-gestures (MGs), has drawn increasing research interests in the community, as they can be useful cues to interpret human inner feelings. In this study, we focused on recognizing MG via self-supervised learning from skeleton sequences with several contributions. Initially, we observed that existing data augmentation methods for skeleton data always fail in MG representation learning. Our investigation shows that the failure is caused by the inherent properties of real-world datasets, such as imbalanced/long-tail data distribution, intra-class ambiguity, and inter-class heterogeneity. Thus, we propose a novel prior-guided augmentation strategy that can preserve the original data distribution while maximizing the agreement between samples in self-supervised learning. Furthermore, we proposed a three-stream architecture of self-supervised presentation learning for micro-gestures via spatial/temporal masking to jointly enhance the learning of invariant features. Lastly, the experimental results show that our proposed method has achieved state-of-the-art performances on two public MG datasets.",,,,, ,  2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG),Representation learning;Face recognition;Semantics;Self-supervised learning;Gesture recognition;Data augmentation;Skeleton,out_of_scope,
3082,"**Title**Knowledge Transfer with Low-Quality Data: A Feature Extraction Issue

**Abstract**Effectively utilizing readily available auxiliary data to improve predictive performance on new modeling tasks is a key problem in data mining. In this research, the goal is to transfer knowledge between sources of data, particularly when ground-truth information for the new modeling task is scarce or is expensive to collect where leveraging any auxiliary sources of data becomes a necessity. Toward seamless knowledge transfer among tasks, effective representation of the data is a critical but yet not fully explored research area for the data engineer and data miner. Here, we present a technique based on the idea of sparse coding, which essentially attempts to find an embedding for the data by assigning feature values based on subspace cluster membership. We modify the idea of sparse coding by focusing the identification of shared clusters between data when source and target data may have different distributions. In our paper, we point out cases where a direct application of sparse coding will lead to a failure of knowledge transfer. We then present the details of our extension to sparse coding, by incorporating distribution distance estimates for the embedded data, and show that the proposed algorithm can overcome the shortcomings of the sparse coding algorithm on synthetic data and achieve improved predictive performance on a real world chemical toxicity transfer learning task.","Quanz, Brian, Huan, Jun, Mishra, Meenakshi",,,Knowledge Transfer with Low-Quality Data: A Feature Extraction Issue,,,10.1109/TKDE.2012.75 , ,,"Effectively utilizing readily available auxiliary data to improve predictive performance on new modeling tasks is a key problem in data mining. In this research, the goal is to transfer knowledge between sources of data, particularly when ground-truth information for the new modeling task is scarce or is expensive to collect where leveraging any auxiliary sources of data becomes a necessity. Toward seamless knowledge transfer among tasks, effective representation of the data is a critical but yet not fully explored research area for the data engineer and data miner. Here, we present a technique based on the idea of sparse coding, which essentially attempts to find an embedding for the data by assigning feature values based on subspace cluster membership. We modify the idea of sparse coding by focusing the identification of shared clusters between data when source and target data may have different distributions. In our paper, we point out cases where a direct application of sparse coding will lead to a failure of knowledge transfer. We then present the details of our extension to sparse coding, by incorporating distribution distance estimates for the embedded data, and show that the proposed algorithm can overcome the shortcomings of the sparse coding algorithm on synthetic data and achieve improved predictive performance on a real world chemical toxicity transfer learning task.",,,,, ,  ,Encoding;Vectors;Knowledge transfer;Feature extraction;Equations;Knowledge transfer;transfer learning;feature extraction;sparse coding;low-quality data.,out_of_scope,
3083,"**Title**Unmasking Harmful Comments: An Approach to Text Toxicity Classification Using Machine Learning in Native Language

**Abstract**In the modern digital era, social media plays a central role in our everyday lives, bringing both advantages and obstacles. While it facilitates global communication and trade, it also brings significant negative impacts, such as the spread of toxic comments that can lead to severe consequences, including mental distress and, in extreme cases, suicide. This study centers on classifying toxic comments by utilizing three different machine learning models: the Stochastic Gradient Descent (SGD) Classifier, the baseline Support Vector Machine (SVM), and an Optimized SVM model. A dataset comprising text comments in both Bangla and English, collected from various social media platforms, was used to train these models. The initial SVM model, while powerful, showed limitations, particularly in handling class imbalance, leading to suboptimal performance. The SGD Classifier provided a balanced approach but fell short in recall for non-harmful comments. To address these challenges, an Optimized SVM model was developed by fine-tuning key hyperparameters, significantly enhancing the model's performance. The optimized model achieved superior accuracy, precision, recall, and F1-scores across both harmful and non-harmful comment classifications. Our results demonstrate that the Optimized SVM model is the most reliable and effective among the three, making it the preferred choice for deployment in real-world scenarios where accurate classification of toxic comments is critical.","Ahsan, Afia, Islam, Mohammad Manzurul, Chowdhury, Abdullahi, Ali, Md. Sawkat, Jabid, Taskeed, Islam, Maheen",,,Unmasking Harmful Comments: An Approach to Text Toxicity Classification Using Machine Learning in Native Language,,,10.1109/3ict64318.2024.10824367 , ,,"In the modern digital era, social media plays a central role in our everyday lives, bringing both advantages and obstacles. While it facilitates global communication and trade, it also brings significant negative impacts, such as the spread of toxic comments that can lead to severe consequences, including mental distress and, in extreme cases, suicide. This study centers on classifying toxic comments by utilizing three different machine learning models: the Stochastic Gradient Descent (SGD) Classifier, the baseline Support Vector Machine (SVM), and an Optimized SVM model. A dataset comprising text comments in both Bangla and English, collected from various social media platforms, was used to train these models. The initial SVM model, while powerful, showed limitations, particularly in handling class imbalance, leading to suboptimal performance. The SGD Classifier provided a balanced approach but fell short in recall for non-harmful comments. To address these challenges, an Optimized SVM model was developed by fine-tuning key hyperparameters, significantly enhancing the model's performance. The optimized model achieved superior accuracy, precision, recall, and F1-scores across both harmful and non-harmful comment classifications. Our results demonstrate that the Optimized SVM model is the most reliable and effective among the three, making it the preferred choice for deployment in real-world scenarios where accurate classification of toxic comments is critical.",,,,, ,"  2024 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)",Support vector machines;Technological innovation;Accuracy;Toxicology;Social networking (online);Stochastic processes;Machine learning;Vectors;Reliability;Informatics;Toxic Comment;SDG Classifier;Support Vector Machine;Native Language,out_but_toxicity,
3084,"**Title**Utilization of Artificial Intelligence for Social Media and Gaming Moderation

**Abstract**As the world continues to evolve, technology has proven to be a necessity in the lives of everyone. Evolving beyond professional use, cyberspace is now populated by online communities being used for communication, learning, and entertainment. However, the increased online presence exposes users to a variety of cultures, personalities, and levels of maturity. Some may also seek to cause harm to others through cyberbullying or may display toxic behaviors. This research aims to tackle the growing problem of toxicity and harassment in online environments. The proposed solution will utilize Artificial Intelligence (AI), and more specifically Natural Language Processing (NLP), to moderate communication and detect malicious language and behavior. The efforts shared in this paper specifically present a work-in-progress. For the time being, two models have been tested with a single dataset from Twitter: a Convolutional Neural Network (CNN) and a Recurrent Neural Network (RNN). The results of experimentation show a promising start for the use of NLP in moderation with an 83% accuracy using an RNN.","Saleous, Heba, Gergely, Marton, Shuaib, Khaled",,,Utilization of Artificial Intelligence for Social Media and Gaming Moderation,,,10.1109/IIT59782.2023.10366468 , ,,"As the world continues to evolve, technology has proven to be a necessity in the lives of everyone. Evolving beyond professional use, cyberspace is now populated by online communities being used for communication, learning, and entertainment. However, the increased online presence exposes users to a variety of cultures, personalities, and levels of maturity. Some may also seek to cause harm to others through cyberbullying or may display toxic behaviors. This research aims to tackle the growing problem of toxicity and harassment in online environments. The proposed solution will utilize Artificial Intelligence (AI), and more specifically Natural Language Processing (NLP), to moderate communication and detect malicious language and behavior. The efforts shared in this paper specifically present a work-in-progress. For the time being, two models have been tested with a single dataset from Twitter: a Convolutional Neural Network (CNN) and a Recurrent Neural Network (RNN). The results of experimentation show a promising start for the use of NLP in moderation with an 83% accuracy using an RNN.",,,,, ,  2023 15th International Conference on Innovations in Information Technology (IIT),Training;Technological innovation;Recurrent neural networks;Codes;Toxicology;Entertainment industry;Natural language processing;NLP;Sentiment Analysis;Online Harassment;User Moderation,detection,
3085,"**Title**Predicting Hate Words and Offensive Language: A Machine Learning Approach

**Abstract**The internet has led to a significant increase in the amount of information available, which has resulted in the rise of online communication among users. Unfortunately, this has also resulted in the proliferation of toxic online texts, which can lead to bullying, harassment, and personal attacks. While there have been attempts to develop efficient models for predicting toxic comments online, the field is still in its nascent stage, hence new frameworks and strategies are needed to address this issue. Convolutional Neural Networks (CNNs) are a promising solution for text classification due to recent advancements in hardware and big data management. Additionally, the increasing amount of data available necessitates the development of novel machine learning tools for managing this information. This study compares CNNs with the traditional bag-of-words approach as well as more efficient methods for text classification. The results demonstrate that CNNs outperform the conventional method in classifying harmful comments, indicating the approach’s potential for further research in this field. This work highlights the importance of developing innovative strategies to combat online toxicity and provides insight into how deep learning techniques can be used for text classification.","Sugandhi, K, Reddy, R. Uday Kumar, Reddy, K. Ravi Kiran, Reddy, B. Balla",,,Predicting Hate Words and Offensive Language: A Machine Learning Approach,,,10.1109/ICISC62624.2024.00042 , ,,"The internet has led to a significant increase in the amount of information available, which has resulted in the rise of online communication among users. Unfortunately, this has also resulted in the proliferation of toxic online texts, which can lead to bullying, harassment, and personal attacks. While there have been attempts to develop efficient models for predicting toxic comments online, the field is still in its nascent stage, hence new frameworks and strategies are needed to address this issue. Convolutional Neural Networks (CNNs) are a promising solution for text classification due to recent advancements in hardware and big data management. Additionally, the increasing amount of data available necessitates the development of novel machine learning tools for managing this information. This study compares CNNs with the traditional bag-of-words approach as well as more efficient methods for text classification. The results demonstrate that CNNs outperform the conventional method in classifying harmful comments, indicating the approach’s potential for further research in this field. This work highlights the importance of developing innovative strategies to combat online toxicity and provides insight into how deep learning techniques can be used for text classification.",,,,, ,  2024 8th International Conference on Inventive Systems and Control (ICISC),Text mining;Industries;Deep learning;Toxicology;Text categorization;Predictive models;Control systems;Text Mining;Toxic Text Classification;Toxicity Detection;CNN;Deep Learning,detection,
3086,"**Title**Quantifying Aflatoxin B1 Contamination Levels in Almonds Using Hyperspectral Imaging Utilizing Gaussian Process and Support Vector Regression

**Abstract**Almonds are prone to infection by Aspergillus fungi in warm and humid environments, which produce aflatoxin B1 (AFB1) in secondary metabolism. AFB1 is a toxic substance and continuous consumption of AFB1-contaminated almonds causes serious health problems. The current AFB1 measure in almonds is destructive, labor-intensive, costly, and inapplicable for industrial inline application. This research study employed hyperspectral images within the wavelength range of 900 to 1700 nm to explore the potential of quantifying aflatoxin B1 contamination levels in almond kernels. In this experiment, a full spectra Gaussian Process Regression (GPR) model and a Support Vector Regression (SVR) model were developed to quantify artificially aflatoxin B1 contaminated almonds. Genetic Algorithm (GA) was used to select significant feature spectra from the hyperspectral image dataset. Then, the significant features spectra were used to develop a multispectral GPR and SVR model to quantify aflatoxin B1 in almonds. The GPR model achieved a coefficient of regression (R2) value of 0.966 for training, 0.934 for testing, and 0.93 for cross-validation using raw spectra. Also, the SVR model achieved R2 value of 0.954 for training. The study shows that pairing hyperspectral imaging with machine learning can accurately measure AFB1 in individual almond kernels. This could be valuable to implementing AFB1 quantification in quality control for industrial purposes.","Kabir, Md. Ahasan, Lee, Ivan, Mishra, Gayatri, Singh, Chandra B, Panda, Brajesh Kumar, Lee, Sang-Heon",,,Quantifying Aflatoxin B1 Contamination Levels in Almonds Using Hyperspectral Imaging Utilizing Gaussian Process and Support Vector Regression,,,10.1109/ISWTA62130.2024.10651840 , ,,"Almonds are prone to infection by Aspergillus fungi in warm and humid environments, which produce aflatoxin B1 (AFB1) in secondary metabolism. AFB1 is a toxic substance and continuous consumption of AFB1-contaminated almonds causes serious health problems. The current AFB1 measure in almonds is destructive, labor-intensive, costly, and inapplicable for industrial inline application. This research study employed hyperspectral images within the wavelength range of 900 to 1700 nm to explore the potential of quantifying aflatoxin B1 contamination levels in almond kernels. In this experiment, a full spectra Gaussian Process Regression (GPR) model and a Support Vector Regression (SVR) model were developed to quantify artificially aflatoxin B1 contaminated almonds. Genetic Algorithm (GA) was used to select significant feature spectra from the hyperspectral image dataset. Then, the significant features spectra were used to develop a multispectral GPR and SVR model to quantify aflatoxin B1 in almonds. The GPR model achieved a coefficient of regression (R2) value of 0.966 for training, 0.934 for testing, and 0.93 for cross-validation using raw spectra. Also, the SVR model achieved R2 value of 0.954 for training. The study shows that pairing hyperspectral imaging with machine learning can accurately measure AFB1 in individual almond kernels. This could be valuable to implementing AFB1 quantification in quality control for industrial purposes.",,,,, ,  2024 IEEE Symposium on Wireless Technology & Applications (ISWTA),Training;Support vector machines;Computational modeling;Process control;Quality control;Pollution measurement;Kernel;Aflatoxin B1;Hyperspectral Images;Genetic Algorithm;Gaussian Process Regression;Support Vector Regression,out_of_scope,
3087,"**Title**Detection of Mental Health Issues and Solution to Online Toxicity using Machine Learning

**Abstract**In modern times, the use of the internet and social media has greatly increased, leading to the emergence of online toxicity, which can have serious consequences for individuals' mental health. Machine learning techniques can be used to detect mental health issues and address online toxicity. One approach to detecting mental health issues in its early stages is to use machine learning to analyze social media posts and other online content. By training a model on large datasets of labeled text, it is possible to identify patterns and indicators of mental health issues such as depression, anxiety, and stress. To address online toxicity, machine learning can be used to identify and classify toxic content, such as hate speech or cyberbullying. This can be done by training a model on a dataset of labeled toxic and non-toxic content Once the model is trained, it can be used to identify and flag the toxic content in real-time, allowing it to be moderated or removed completely. Overall, the use of machine learning for the detection of mental health issues and the solution to online toxicity can be a powerful tool for promoting mental wellbeing and creating a safer and more positive online environment.","H K, Parjanya, Hegde, Ramakrishna, Mishra, Nikhil Kumar, Kumar Sandliya, Abhishek, Singh, Anant, S M, Soumyasri",,,Detection of Mental Health Issues and Solution to Online Toxicity using Machine Learning,,,10.1109/MysuruCon59703.2023.10396981 , ,,"In modern times, the use of the internet and social media has greatly increased, leading to the emergence of online toxicity, which can have serious consequences for individuals' mental health. Machine learning techniques can be used to detect mental health issues and address online toxicity. One approach to detecting mental health issues in its early stages is to use machine learning to analyze social media posts and other online content. By training a model on large datasets of labeled text, it is possible to identify patterns and indicators of mental health issues such as depression, anxiety, and stress. To address online toxicity, machine learning can be used to identify and classify toxic content, such as hate speech or cyberbullying. This can be done by training a model on a dataset of labeled toxic and non-toxic content Once the model is trained, it can be used to identify and flag the toxic content in real-time, allowing it to be moderated or removed completely. Overall, the use of machine learning for the detection of mental health issues and the solution to online toxicity can be a powerful tool for promoting mental wellbeing and creating a safer and more positive online environment.",,,,, ,  2023 IEEE 3rd Mysore Sub Section International Conference (MysuruCon),Training;Sentiment analysis;Analytical models;Toxicology;Machine learning;Mental health;Feature extraction;Machine Learning;Online Toxicity;Depression;Anxiety;Mental Health.,detection,
3088,"**Title**Spectral Data Augmentation Using Deep Generative Model for Remote Chemical Sensing

**Abstract**The critical role of a remote chemical sensing using a Fourier Transform Infrared (FT-IR) spectrometer has been emphasized for detecting lethal chemicals in the atmosphere. To enhance standoff detection capabilities, acquiring adequate gas spectral data is crucial for training and optimizing detection algorithms across diverse outdoor scenarios. However, the collection of outdoor infrared spectra with a number of conditions is constrained owing to uncontrolled weather factors including a temperature and humidity, leading to impaired reliability of the data. In addressing outdoor data acquisition challenges, we introduced a data augmentation method using a conditional CycleGAN. This technique utilizes spectral data obtained exclusively under controlled laboratory conditions. The proposed deep generative model takes as input the background spectrum, which is concatenated with two critical attributes: the temperature difference between the target substance and the background, and pathlength concentration. Subsequently, the model computes a brightness temperature spectrum for a gas against a specific background, employing SF6 as the target chemical gas. The validity of the generated data was assessed using two detection algorithms: the Pearson Correlation Coefficient and Adaptive Subspace Detector. In addition, the accuracy performance of detectors trained with the augmented dataset was compared and evaluated against those trained with the pure dataset. The results demonstrated that the model can simulate gas spectra onto unseen background spectra and enhance the chemical sensing database, and it can contribute to data augmentation for improving the performance of chemical gas detection systems.","Son, Jungjae, Joon Byun, Hyung, Park, Munyeol, Ha, Jeongjae, Nam, Hyunwoo",,,Spectral Data Augmentation Using Deep Generative Model for Remote Chemical Sensing,,,10.1109/ACCESS.2024.3421274 , ,,"The critical role of a remote chemical sensing using a Fourier Transform Infrared (FT-IR) spectrometer has been emphasized for detecting lethal chemicals in the atmosphere. To enhance standoff detection capabilities, acquiring adequate gas spectral data is crucial for training and optimizing detection algorithms across diverse outdoor scenarios. However, the collection of outdoor infrared spectra with a number of conditions is constrained owing to uncontrolled weather factors including a temperature and humidity, leading to impaired reliability of the data. In addressing outdoor data acquisition challenges, we introduced a data augmentation method using a conditional CycleGAN. This technique utilizes spectral data obtained exclusively under controlled laboratory conditions. The proposed deep generative model takes as input the background spectrum, which is concatenated with two critical attributes: the temperature difference between the target substance and the background, and pathlength concentration. Subsequently, the model computes a brightness temperature spectrum for a gas against a specific background, employing SF6 as the target chemical gas. The validity of the generated data was assessed using two detection algorithms: the Pearson Correlation Coefficient and Adaptive Subspace Detector. In addition, the accuracy performance of detectors trained with the augmented dataset was compared and evaluated against those trained with the pure dataset. The results demonstrated that the model can simulate gas spectra onto unseen background spectra and enhance the chemical sensing database, and it can contribute to data augmentation for improving the performance of chemical gas detection systems.",,,,, ,  ,Chemicals;Data models;Atmospheric modeling;Sensors;Generative adversarial networks;Mathematical models;Data augmentation;Remote sensing;Brightness temperature spectrum;data augmentation;deep generative model;FT-IR spectroscopy;generative adversarial network;remote chemical sensing,out_of_scope,
3089,"**Title**Heavy metal contamination in arable land of Chongming based on GIS and Geostatistics

**Abstract**Soil heavy metal pollution has increasing applied pressure on land resources with the intensive effects of local geochemistry or human activities in recent years. This investigation was conducted to understand the spatial variability of the soil heavy metal elements, to evaluate the relationship between heavy metals and their probable sources and to identify or forewarn the probable heavy metal contamination area in Chongming based on Geostatistics and GIS. The effective interpolation and analysis strategy was explored by combing the interpolating model derived from dataset excluding outlier with the performance of Universal Kriging on dataset including outlier to meet this need. The experimental results showed that the spatial variability characteristics and pollution situation of heavy metals accorded to that was investigated through field work, which suggested the scheme concerned the outlier was reasonable and effective. The further improvement of the approach is needed for more extensive application.","Shen, Guangrong, Huang, Xiumei, Qian, Zhenhua, Xu, Jinging",,,Heavy metal contamination in arable land of Chongming based on GIS and Geostatistics,,,10.1109/GEOINFORMATICS.2010.5567500 , ,,"Soil heavy metal pollution has increasing applied pressure on land resources with the intensive effects of local geochemistry or human activities in recent years. This investigation was conducted to understand the spatial variability of the soil heavy metal elements, to evaluate the relationship between heavy metals and their probable sources and to identify or forewarn the probable heavy metal contamination area in Chongming based on Geostatistics and GIS. The effective interpolation and analysis strategy was explored by combing the interpolating model derived from dataset excluding outlier with the performance of Universal Kriging on dataset including outlier to meet this need. The experimental results showed that the spatial variability characteristics and pollution situation of heavy metals accorded to that was investigated through field work, which suggested the scheme concerned the outlier was reasonable and effective. The further improvement of the approach is needed for more extensive application.",,,,, ,  2010 18th International Conference on Geoinformatics,Soil;Interpolation;Pollution;Contamination;Mercury (metals);Copper;Chongming Island;Contamination;Kriging;Soil Heavy metal;GIS,out_of_scope,
3090,"**Title**Inversion of soil Cu concentration based on band selection of hyperspetral data

**Abstract**Hyperspectral data offers a powerful tool for predicting soil heavy metal contamination due to its high spectral resolution and many continuous bands. Band selection, however, is the prerequisite for heavy metal inversion by hyperspectral data. In this study, soil reflectance spectra and their Cu contents were measured for 181 soil samples in the laboratory. Based on these dataset, band selection was conducted to inverse Cu contents using stepwise regression approach, and prediction accuracies of Cu based on partial least-squares regression (PLSR) model with different selected bands were analyzed. In addition, the influences of spectral resolution on prediction results of Cu were discussed by a Gaussian re-sampling function. It demonstrated that the optimal band number was 10 for Cu inversion and the corresponding model had prediction accuracy of R2 = 0.7523 and RMSE = 0.4699; the optimal spectral resolution was 32nm and the model on this basis had an accuracy of R2 =0.7028 and RMSE =0.5147. Results of this study may provide scientific verification for designing low-cost and practical hyperspectral spaceborne sensors, and theoretical bases for simulating spaceborne sensors to predict soil heavy metals contents in the future.","Zhang, Xia, Huang, Changping, Liu, Bo, Tong, Qingxi",,,Inversion of soil Cu concentration based on band selection of hyperspetral data,,,10.1109/IGARSS.2010.5652871 , ,,"Hyperspectral data offers a powerful tool for predicting soil heavy metal contamination due to its high spectral resolution and many continuous bands. Band selection, however, is the prerequisite for heavy metal inversion by hyperspectral data. In this study, soil reflectance spectra and their Cu contents were measured for 181 soil samples in the laboratory. Based on these dataset, band selection was conducted to inverse Cu contents using stepwise regression approach, and prediction accuracies of Cu based on partial least-squares regression (PLSR) model with different selected bands were analyzed. In addition, the influences of spectral resolution on prediction results of Cu were discussed by a Gaussian re-sampling function. It demonstrated that the optimal band number was 10 for Cu inversion and the corresponding model had prediction accuracy of R2 = 0.7523 and RMSE = 0.4699; the optimal spectral resolution was 32nm and the model on this basis had an accuracy of R2 =0.7028 and RMSE =0.5147. Results of this study may provide scientific verification for designing low-cost and practical hyperspectral spaceborne sensors, and theoretical bases for simulating spaceborne sensors to predict soil heavy metals contents in the future.",,,,, ,  2010 IEEE International Geoscience and Remote Sensing Symposium,Soil;Predictive models;Copper;Accuracy;Reflectivity;Hyperspectral sensors;Remote sensing prediction of Cu;Hyperspectral data;Spectral re-sampling;PLSR,out_of_scope,
3091,"**Title**Application of WEKA Machine Learning Tools in Phytoremediation for the Removal of Heavy Metals in Water Treatment Processes

**Abstract**In this study, we leverage the interdisciplinary strengths of Computer Science, AI, ML, and Data Mining to address the pressing environmental issue of river pollution, with a focus on the Yamuna River's deteriorating conditions. Recognizing the critical impact of heavy metal contamination in aquatic ecosystems, our research utilizes an AI-enhanced phytoremediation strategy for the efficient reduction of both physicochemical properties and hazardous heavy metals from the river water. We perform a thorough examination of different physicochemical factors including pH, electrical conductivity, total dissolved solids, dissolved oxygen (DO), biological oxygen demand (BOD), chemical oxygen demand (COD), and the levels of metals such as lead (Pb), zinc (Zn), and nickel (Ni). To process and interpret the complex dataset, we apply sophisticated Data Mining techniques using the software WEKA, which enables us to extract meaningful patterns and insights from the environmental data. Our approach adopts a green technology method, phytoremediation, enhanced by AI algorithms to optimize the removal process, targeting the reduction of contaminants in a cost-effective and scalable manner. The integration of AI and Data Mining in environmental management signifies a transformative step towards more intelligent, efficient, and sustainable practices. The implications of this research are manifold, extending beyond environmental science to inform developments in AI-driven ecological modeling and ML-powered monitoring systems. The outcomes of this study not only shed light on the current state of the Yamuna River but also demonstrate the potential of AI and Data Mining as powerful tools in the fight against environmental pollution","R, Raghavendra, Kumar, Navneet",,,Application of WEKA Machine Learning Tools in Phytoremediation for the Removal of Heavy Metals in Water Treatment Processes,,,10.1109/ICCSAI59793.2023.10421571 , ,,"In this study, we leverage the interdisciplinary strengths of Computer Science, AI, ML, and Data Mining to address the pressing environmental issue of river pollution, with a focus on the Yamuna River's deteriorating conditions. Recognizing the critical impact of heavy metal contamination in aquatic ecosystems, our research utilizes an AI-enhanced phytoremediation strategy for the efficient reduction of both physicochemical properties and hazardous heavy metals from the river water. We perform a thorough examination of different physicochemical factors including pH, electrical conductivity, total dissolved solids, dissolved oxygen (DO), biological oxygen demand (BOD), chemical oxygen demand (COD), and the levels of metals such as lead (Pb), zinc (Zn), and nickel (Ni). To process and interpret the complex dataset, we apply sophisticated Data Mining techniques using the software WEKA, which enables us to extract meaningful patterns and insights from the environmental data. Our approach adopts a green technology method, phytoremediation, enhanced by AI algorithms to optimize the removal process, targeting the reduction of contaminants in a cost-effective and scalable manner. The integration of AI and Data Mining in environmental management signifies a transformative step towards more intelligent, efficient, and sustainable practices. The implications of this research are manifold, extending beyond environmental science to inform developments in AI-driven ecological modeling and ML-powered monitoring systems. The outcomes of this study not only shed light on the current state of the Yamuna River but also demonstrate the potential of AI and Data Mining as powerful tools in the fight against environmental pollution",,,,, ,"  2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI)",Machine learning;Lead;Water pollution;Nickel;Rivers;Data mining;Zinc;Machine Learning in Phytoremediation;WEKA for Environmental Data Analysis;Heavy Metal Biofiltration;Water Quality Enhancement Techniques;Data-Driven Water Treatment Solutions,out_of_scope,
3092,"**Title**Transforming Pharmacological Research: Utilizing AI and Machine Learning in Drug Discovery and Development

**Abstract**In the past few years, the application of artificial intelligence (AI) in health systems has risen continuously. The rapid advancement of AI has revolutionized the area of experimental pharmacology and drug discovery. It enables efficient analysis of vast datasets, aids in drug discovery to real-world data mining, enhances predictive modeling, accelerates the recognition of probable drug candidates, optimizes drug design and helps in target identification. Furthermore, algorithms for machine learning can examine complex biological interactions and offer insightful information about drug mechanisms and toxicity. Integrating AI into pharmacology research not only accelerates the process of developing drugs but also contributes to more precise and effective therapeutic interventions. In post-marketing inspection/ pharmacovigilance, AI is used to observe adverse drug reactions, find out drug interactions, design clinical research, and contribute to pharmacovigilance efforts by applying its different AI-based tools. Machine learning (ML) models extract patterns from complex data records, produce correct results and help in resolution, because of their potential to accelerate drug discovery. In this investigation, we will discuss the basics of AI, innovative research and development in AI methods followed by the benefits of AI in pharmacology research as well as clinical practice. This study will demonstrate AI and ML-driven key challenges in the advancements of therapeutic development and drug discovery.","Tiwari, Sunita Waila, Joshi, Mamta, Chand, Garima, Gwasikoti, Jyoti, Mittal, Amit, Sharma, Pradeep Kumar",,,Transforming Pharmacological Research: Utilizing AI and Machine Learning in Drug Discovery and Development,,,10.1109/ICSSAS64001.2024.10760304 , ,,"In the past few years, the application of artificial intelligence (AI) in health systems has risen continuously. The rapid advancement of AI has revolutionized the area of experimental pharmacology and drug discovery. It enables efficient analysis of vast datasets, aids in drug discovery to real-world data mining, enhances predictive modeling, accelerates the recognition of probable drug candidates, optimizes drug design and helps in target identification. Furthermore, algorithms for machine learning can examine complex biological interactions and offer insightful information about drug mechanisms and toxicity. Integrating AI into pharmacology research not only accelerates the process of developing drugs but also contributes to more precise and effective therapeutic interventions. In post-marketing inspection/ pharmacovigilance, AI is used to observe adverse drug reactions, find out drug interactions, design clinical research, and contribute to pharmacovigilance efforts by applying its different AI-based tools. Machine learning (ML) models extract patterns from complex data records, produce correct results and help in resolution, because of their potential to accelerate drug discovery. In this investigation, we will discuss the basics of AI, innovative research and development in AI methods followed by the benefits of AI in pharmacology research as well as clinical practice. This study will demonstrate AI and ML-driven key challenges in the advancements of therapeutic development and drug discovery.",,,,, ,  2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),Drugs;Machine learning algorithms;Toxicology;Target recognition;Machine learning;Transforms;Data models;Drug discovery;Data mining;Artificial intelligence;Artificial intelligence;Machine learning;Algorithm;Predictive modeling;Pharmacovigilance,out_of_scope,
3093,"**Title**Backdoor Attack Detecting and Removing Based on Knowledge Distillation for Natural Language Translation Model

**Abstract**The lack of interpretability in Deep Neural Networks makes them susceptible to backdoor attacks. The attacker mixes the poisoned data with triggers into a clean dataset, and uses it to train a backdoor model. This model maintains high accuracy on clean data while outputting the attacker’s desired target for the poisoned data. Due to the serious threat of backdoor attacks on DNN, backdoor defense on DNN is particularly important. In our work, we apply the knowledge distillation method in the visual field to natural language processing. The method of knowledge distillation involves removing toxic data from the poisoned training dataset and restoring the accuracy of the distilled model. In a defensive scenario, one assumption is that the defender can collect clean data without labels. We evaluated the effectiveness of knowledge distillation on strategies through two application scenarios in natural language processing and multiple models. By distilling and fine-tuning to disable backdoors, we further improved the classification accuracy of the distilled models. The experimental results indicate that the method of knowledge distillation can also effectively defend against backdoor attacks in natural language processing.","Chen, Mao, Pang, Lihui, Tan, Qingyi, Tang, Yilong, Liu, Yulang, Zhang, Wenwei",,,Backdoor Attack Detecting and Removing Based on Knowledge Distillation for Natural Language Translation Model,,,10.1109/ICCC59590.2023.10507399 , ,,"The lack of interpretability in Deep Neural Networks makes them susceptible to backdoor attacks. The attacker mixes the poisoned data with triggers into a clean dataset, and uses it to train a backdoor model. This model maintains high accuracy on clean data while outputting the attacker’s desired target for the poisoned data. Due to the serious threat of backdoor attacks on DNN, backdoor defense on DNN is particularly important. In our work, we apply the knowledge distillation method in the visual field to natural language processing. The method of knowledge distillation involves removing toxic data from the poisoned training dataset and restoring the accuracy of the distilled model. In a defensive scenario, one assumption is that the defender can collect clean data without labels. We evaluated the effectiveness of knowledge distillation on strategies through two application scenarios in natural language processing and multiple models. By distilling and fine-tuning to disable backdoors, we further improved the classification accuracy of the distilled models. The experimental results indicate that the method of knowledge distillation can also effectively defend against backdoor attacks in natural language processing.",,,,, ,  2023 9th International Conference on Computer and Communications (ICCC),Training;Visualization;Artificial neural networks;Natural language processing;Data models;neural networks;backdoor attack;knowledge distillation;natural language processing,out_of_scope,
3094,"**Title**Combination and Knowledge Extension of Pre-trained Language Model for Offensive Language Detection

**Abstract**Nowadays, more and more offensive comments are posted on social media. Those offensive comments can seriously cause mental damage to other people. Therefore, those toxic and harmful comments should be detected timely and accurate. In this paper, we exploit the powerful pre-train language models (PLM) in detecting offensive language. We consider two PLMs in our paper: BERT and DeepMoji. We finetune their combination and evaluate the performance with two datasets: Ask FM and Curious Cat. We found that DeepMoji outperforms BERT. We analyze the result from two aspects and conclude that the task and data of pre-training are important to PLM. Seeing that BERT is less effective than DeepMoji, it is possible to improve the performance of BERT. We then propose a “Knowledge Extension” method to improve the performance of the BERT model. We find that the performance of PLM with high-quality extensional knowledge can be improved significantly.","Li, Zhenming, Shimada, Kazutaka",,,Combination and Knowledge Extension of Pre-trained Language Model for Offensive Language Detection,,,10.1109/IIAI-AAI59060.2023.00026 , ,,"Nowadays, more and more offensive comments are posted on social media. Those offensive comments can seriously cause mental damage to other people. Therefore, those toxic and harmful comments should be detected timely and accurate. In this paper, we exploit the powerful pre-train language models (PLM) in detecting offensive language. We consider two PLMs in our paper: BERT and DeepMoji. We finetune their combination and evaluate the performance with two datasets: Ask FM and Curious Cat. We found that DeepMoji outperforms BERT. We analyze the result from two aspects and conclude that the task and data of pre-training are important to PLM. Seeing that BERT is less effective than DeepMoji, it is possible to improve the performance of BERT. We then propose a “Knowledge Extension” method to improve the performance of the BERT model. We find that the performance of PLM with high-quality extensional knowledge can be improved significantly.",,,,, ,  2023 14th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI),Analytical models;Frequency modulation;Social networking (online);Face recognition;Media;Data models;Task analysis;offensive language detection;machine learning;pre-trained language model;social media,detection,
3095,"**Title**Toxicity Tweet Detection and Classification Using NLP Driven Techniques

**Abstract**The use of social media is increasing regularly. Unethical things like defamation, spreading hatred, pornography, etc are becoming easier for some irresponsible users because of the easy accessing and due to similarity of social media. In this view, this study has been carried out to use machine learning techniques to classify comments into their hazardous categories. In order to categorize a comment based on its toxicity, this research compares classic machine learning methods with deep learning methods including Logistic Regression, SVM, RNN, and LSTM. To compare the performance of the models, four distinct models are developed, put into use, and trained on a common dataset. These models were developed and evaluated using sizable amounts of secondary qualitative data that included several comments that were either labeled as harmful or not. Results showed that employing LSTM, a satisfactory accuracy of 90.7% and an F1- score of 0.94 were obtained.","Pal, Anuj Kumar, Rai, Sakshi",,,Toxicity Tweet Detection and Classification Using NLP Driven Techniques,,,10.1109/ICTBIG59752.2023.10456026 , ,,"The use of social media is increasing regularly. Unethical things like defamation, spreading hatred, pornography, etc are becoming easier for some irresponsible users because of the easy accessing and due to similarity of social media. In this view, this study has been carried out to use machine learning techniques to classify comments into their hazardous categories. In order to categorize a comment based on its toxicity, this research compares classic machine learning methods with deep learning methods including Logistic Regression, SVM, RNN, and LSTM. To compare the performance of the models, four distinct models are developed, put into use, and trained on a common dataset. These models were developed and evaluated using sizable amounts of secondary qualitative data that included several comments that were either labeled as harmful or not. Results showed that employing LSTM, a satisfactory accuracy of 90.7% and an F1- score of 0.94 were obtained.",,,,, ,  2023 IEEE International Conference on ICT in Business Industry & Government (ICTBIG),Support vector machines;Deep learning;Logistic regression;Toxicology;Social networking (online);Text categorization;Government;Long-Short Term Memory;Recurrent Neural Network;Text mining;Toxic text classification;Text classification,detection,
3096,"**Title**Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models

**Abstract**Trained on billions of images, diffusion-based text-to-image models seem impervious to traditional data poisoning attacks, which typically require poison samples approaching 20% of the training set. In this paper, we show that state-of-the-art text-to-image generative models are in fact highly vulnerable to poisoning attacks. Our work is driven by two key insights. First, while diffusion models are trained on billions of samples, the number of training samples associated with a specific concept or prompt is generally on the order of thousands. This suggests that these models will be vulnerable to prompt-specific poisoning attacks that corrupt a model’s ability to respond to specific targeted prompts. Second, poison samples can be carefully crafted to maximize poison potency to ensure success with very few samples.We introduce Nightshade, a prompt-specific poisoning attack optimized for potency that can completely control the output of a prompt in Stable Diffusion’s newest model (SDXL) with less than 100 poisoned training samples. Nightshade also generates stealthy poison images that look visually identical to their benign counterparts, and produces poison effects that ""bleed through"" to related concepts. More importantly, a moderate number of Nightshade attacks on independent prompts can destabilize a model and disable its ability to generate images for any and all prompts. Finally, we propose the use of Nightshade and similar tools as a defense for content owners against web scrapers that ignore opt-out/do-not-crawl directives, and discuss potential implications for both model trainers and content owners.","Shan, Shawn, Ding, Wenxin, Passananti, Josephine, Wu, Stanley, Zheng, Haitao, Zhao, Ben Y.",,,Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models,,,10.1109/SP54263.2024.00207 , ,,"Trained on billions of images, diffusion-based text-to-image models seem impervious to traditional data poisoning attacks, which typically require poison samples approaching 20% of the training set. In this paper, we show that state-of-the-art text-to-image generative models are in fact highly vulnerable to poisoning attacks. Our work is driven by two key insights. First, while diffusion models are trained on billions of samples, the number of training samples associated with a specific concept or prompt is generally on the order of thousands. This suggests that these models will be vulnerable to prompt-specific poisoning attacks that corrupt a model’s ability to respond to specific targeted prompts. Second, poison samples can be carefully crafted to maximize poison potency to ensure success with very few samples.We introduce Nightshade, a prompt-specific poisoning attack optimized for potency that can completely control the output of a prompt in Stable Diffusion’s newest model (SDXL) with less than 100 poisoned training samples. Nightshade also generates stealthy poison images that look visually identical to their benign counterparts, and produces poison effects that ""bleed through"" to related concepts. More importantly, a moderate number of Nightshade attacks on independent prompts can destabilize a model and disable its ability to generate images for any and all prompts. Finally, we propose the use of Nightshade and similar tools as a defense for content owners against web scrapers that ignore opt-out/do-not-crawl directives, and discuss potential implications for both model trainers and content owners.",,,,, ,  2024 IEEE Symposium on Security and Privacy (SP),Training;Procurement;Data privacy;Toxicology;Text to image;Training data;Diffusion models,out_of_scope,
3097,"**Title**Machine learning applied to functionalized graphene sensors for noninvasive detection of renal diseases

**Abstract**Breath biomarker detection has been a significant non-invasive approach for disease diagnosis. This method has significant potential for early diagnosis and accurate analysis of diseases. Emission from breath contains several volatile organic compounds. Among them, ammonia is a very commonly found VOC and mainly responsible for chronic kidney diseases. There exist several strategies to detect ammonia, however they demonstrate severe limitations such as cross-sensitivity and poor selectivity. This work demonstrates the synergistic effect of sensor functionalization and application of machine learning for selective detection of ammonia in the environment. The sensor exhibits high degree of selectivity towards ammonia owing to enormous hydroxyl groups contributed through curcumin. At 500 ppm ammonia, the sensor demonstrates 274% response and very high selectivity among seven volatile organic compounds. The machine learning models were trained with the help of sensor transients. Random Forest and CNN models were applied to predict the presence of ammonia in a mixture. Random Forest achieved 96.25% accuracy compared to 89% accuracy of CNN. Hence, Random Forest algorithms applied to curcumin functionalized reduced graphene oxide sensors can detect ammonia vapors with very high efficiency among a mixture of gases.","Sarkar, Lisa, Bhattacharyya, Arindam, Sett, Avik, Karmakar, Gairik, Bhattacharyya, Tarun Kanti",,,Machine learning applied to functionalized graphene sensors for noninvasive detection of renal diseases,,,10.1109/BIBM62325.2024.10822275 , ,,"Breath biomarker detection has been a significant non-invasive approach for disease diagnosis. This method has significant potential for early diagnosis and accurate analysis of diseases. Emission from breath contains several volatile organic compounds. Among them, ammonia is a very commonly found VOC and mainly responsible for chronic kidney diseases. There exist several strategies to detect ammonia, however they demonstrate severe limitations such as cross-sensitivity and poor selectivity. This work demonstrates the synergistic effect of sensor functionalization and application of machine learning for selective detection of ammonia in the environment. The sensor exhibits high degree of selectivity towards ammonia owing to enormous hydroxyl groups contributed through curcumin. At 500 ppm ammonia, the sensor demonstrates 274% response and very high selectivity among seven volatile organic compounds. The machine learning models were trained with the help of sensor transients. Random Forest and CNN models were applied to predict the presence of ammonia in a mixture. Random Forest achieved 96.25% accuracy compared to 89% accuracy of CNN. Hence, Random Forest algorithms applied to curcumin functionalized reduced graphene oxide sensors can detect ammonia vapors with very high efficiency among a mixture of gases.",,,,, ,  2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Volatile organic compounds;Ammonia;Gases;Accuracy;Graphene;Chronic kidney disease;Sensors;Transient analysis;Random forests;Diseases;Ammonia Sensor;Reduced graphene oxide;Curcumin;Random Forest;Convolutional neural network,out_of_scope,
3098,"**Title**Eco-Friendly Laser Deterrent System for Woodpeckers Utilizing YOLOv8

**Abstract**This research introduces a novel approach for deterring woodpeckers to safeguard wooden structures in an environmentally-friendly way. Woodpecker drilling and drumming poses a significant threat to wooden structures, causing extensive physical and financial damage. These issues range from property damage to noise, underscoring the urgent need for an effective deterrent method. Our study proposes a laser-based deterrent mechanism, designed to be eco-friendly by minimizing effects on other wildlife and humans. This environmentally conscious approach offers a humane solution to woodpecker control, ensuring compliance with the Migratory Bird Treaty Act (MBTA). Additionally, our approach utilizes deep learning technology to chase away specific targets. Our system integrates YOLOv8 for accurate and low-power identification, creating an efficient operating solution with independent internet connectivity. This enhancement enables the system to adapt across various environments. Testing in a controlled environment has verified the system's effectiveness in deterring woodpeckers in an eco-friendly way. This approach ensures minimal impact on other wildlife and humans, adhering to legal and environmental constraints.","Kim, Wonah, Han, Seung-Hun, Kim, Hyojin, Soroka, Jaden, Allange, Justin, Smith, Anthony",,,Eco-Friendly Laser Deterrent System for Woodpeckers Utilizing YOLOv8,,,10.1109/IRC63610.2024.00047 , ,,"This research introduces a novel approach for deterring woodpeckers to safeguard wooden structures in an environmentally-friendly way. Woodpecker drilling and drumming poses a significant threat to wooden structures, causing extensive physical and financial damage. These issues range from property damage to noise, underscoring the urgent need for an effective deterrent method. Our study proposes a laser-based deterrent mechanism, designed to be eco-friendly by minimizing effects on other wildlife and humans. This environmentally conscious approach offers a humane solution to woodpecker control, ensuring compliance with the Migratory Bird Treaty Act (MBTA). Additionally, our approach utilizes deep learning technology to chase away specific targets. Our system integrates YOLOv8 for accurate and low-power identification, creating an efficient operating solution with independent internet connectivity. This enhancement enables the system to adapt across various environments. Testing in a controlled environment has verified the system's effectiveness in deterring woodpeckers in an eco-friendly way. This approach ensures minimal impact on other wildlife and humans, adhering to legal and environmental constraints.",,,,, ,  2024 Eighth IEEE International Conference on Robotic Computing (IRC),Deep learning;Accuracy;Wildlife;Lasers;Transfer learning;Noise;Real-time systems;Robots;Testing;Overfitting;Woodpecker deterrence;Eco-friendly deterrents;Wildlife management;Autonomous monitoring systems,out_of_scope,
3099,"**Title**The possibility on estimation of concentration of heavy metals in coastal waters from remote sensing data

**Abstract**The heavy metals in waters cannot be decomposed but can be transferred and accumulated with food chains. Many heavy metals are toxic to human beings. It is very important to measure concentration of heavy metals in coastal waters for water quality research, monitoring, and environmental management. On consideration of geochemistry behavior of heavy metals, their distribution is related with water components which determined waters' optical properties. The in-situ remote sensing reflectance data and heavy metal concentration data at 48 sampling points collected from three cruises in the Pearl River estuary were analysed. For single band among all the 57 bands ranging from 365 to 935 nm, the band centered at 711 nm (B711) has highest correlation coefficient (R=0.51) with concentration of both Cu and Zn. The band ratio, B711/ B406 has the highest correlation coefficient with Cu (R=0.749), and band ration, B711/ B416 has the highest correlation coeficient with Zn (R=0.804). The band and band ratio were employed for algorithm development using the symbolic regression method, and the results showed the possiblity to retrieve concentration of heavy metal from remotely-sensed data.","Chen, Chuqun, Liu, Fenfen, He, Quanjun, Shi, Heyin",,,The possibility on estimation of concentration of heavy metals in coastal waters from remote sensing data,,,10.1109/IGARSS.2010.5648845 , ,,"The heavy metals in waters cannot be decomposed but can be transferred and accumulated with food chains. Many heavy metals are toxic to human beings. It is very important to measure concentration of heavy metals in coastal waters for water quality research, monitoring, and environmental management. On consideration of geochemistry behavior of heavy metals, their distribution is related with water components which determined waters' optical properties. The in-situ remote sensing reflectance data and heavy metal concentration data at 48 sampling points collected from three cruises in the Pearl River estuary were analysed. For single band among all the 57 bands ranging from 365 to 935 nm, the band centered at 711 nm (B711) has highest correlation coefficient (R=0.51) with concentration of both Cu and Zn. The band ratio, B711/ B406 has the highest correlation coefficient with Cu (R=0.749), and band ration, B711/ B416 has the highest correlation coeficient with Zn (R=0.804). The band and band ratio were employed for algorithm development using the symbolic regression method, and the results showed the possiblity to retrieve concentration of heavy metal from remotely-sensed data.",,,,, ,  2010 IEEE International Geoscience and Remote Sensing Symposium,Remote sensing;Rivers;Copper;Zinc;Sea measurements;Lead;Heavy metals;Remote sensing reflectance of water;Symbolic regression;Pearl River estuary,out_of_scope,
3100,"**Title**Parameter Optimization Algorithms for Evolving Rule Models Applied to Freshwater Ecosystems

**Abstract**Predictive rule models for early warning of cyanobacterial blooms in freshwater ecosystems were developed using a hybrid evolutionary algorithm (HEA). The HEA has been designed to evolve IF-THEN-ELSE model structures using genetic programming and to optimize the stochastical constants contained in the model using population-based algorithms. This paper intensively investigates the performances of the following six alternative population-based algorithms for parameter optimization (PO) of rule models within this hybrid methodology: 1) hill climbing (HC); 2) simulated annealing (SA); 3) genetic algorithm (GA); 4) differential evolution (DE); 5) covariance matrix adaptation evolution strategy (CMA-ES); and 6) estimation of distribution algorithm (EDA). The comparative study was carried out by predictive modeling of chlorophyll-a concentrations and the potentially toxic cyanobacterium Cylindrospermopsis raciborskii cell concentrations based on water quality time-series data in Lake Wivenhoe, Queensland, Australia, from 1998 to 2009. The experimental results demonstrate that with these PO methods, the rule models discovered by the HEA proved to be both predictive and explanatory whose IF condition indicates threshold values for some crucial water quality parameters. When comparing different PO algorithms, HC always performed best followed by DE, GA, and EDA, while CMA-ES performed worst and the performance of SA varied with different data sets.","Cao, Hongqing, Recknagel, Friedrich, Orr, Philip T.",,,Parameter Optimization Algorithms for Evolving Rule Models Applied to Freshwater Ecosystems,,,10.1109/TEVC.2013.2286404 , ,,"Predictive rule models for early warning of cyanobacterial blooms in freshwater ecosystems were developed using a hybrid evolutionary algorithm (HEA). The HEA has been designed to evolve IF-THEN-ELSE model structures using genetic programming and to optimize the stochastical constants contained in the model using population-based algorithms. This paper intensively investigates the performances of the following six alternative population-based algorithms for parameter optimization (PO) of rule models within this hybrid methodology: 1) hill climbing (HC); 2) simulated annealing (SA); 3) genetic algorithm (GA); 4) differential evolution (DE); 5) covariance matrix adaptation evolution strategy (CMA-ES); and 6) estimation of distribution algorithm (EDA). The comparative study was carried out by predictive modeling of chlorophyll-a concentrations and the potentially toxic cyanobacterium Cylindrospermopsis raciborskii cell concentrations based on water quality time-series data in Lake Wivenhoe, Queensland, Australia, from 1998 to 2009. The experimental results demonstrate that with these PO methods, the rule models discovered by the HEA proved to be both predictive and explanatory whose IF condition indicates threshold values for some crucial water quality parameters. When comparing different PO algorithms, HC always performed best followed by DE, GA, and EDA, while CMA-ES performed worst and the performance of SA varied with different data sets.",,,,, ,  ,Biological system modeling;Optimization;Predictive models;Mathematical model;Prediction algorithms;Genetic algorithms;Evolutionary computation;Evolutionary algorithm;genetic programming;population-based algorithms;cyanobacterial blooms;Cyanobacterial blooms;evolutionary algorithm;genetic programming;population-based algorithms,out_of_scope,
3101,"**Title**Environmental Modeling by means of Genetic Fuzzy Systems

**Abstract**In this work four genetic fuzzy system are applied to an environmental problem, i.e. modeling ozone concentrations in Mexico City metropolitan area. These hybrid systems are composed by the Fuzzy Inductive Reasoning (FIR) methodology and different genetic algorithms (GAs) that takes charge of determining, in an automatic way, the fuzzification parameters. Mexico is the second country in the world with high air pollution levels. The main air pollution problem that has been identified in Mexico City metropolitan area is the formation of photochemical smog, primarily ozone. This toxic gas can produce harmful effects on the population's health. The study and development of modeling methodologies that allow the capturing of ozone behavior becomes an important task when it is intended to predict contingencies before they are produced.","Nebot, Angela, Acosta, Jesus, Mugica, Violeta",,,Environmental Modeling by means of Genetic Fuzzy Systems,,,10.1109/FUZZY.2007.4295438 , ,,"In this work four genetic fuzzy system are applied to an environmental problem, i.e. modeling ozone concentrations in Mexico City metropolitan area. These hybrid systems are composed by the Fuzzy Inductive Reasoning (FIR) methodology and different genetic algorithms (GAs) that takes charge of determining, in an automatic way, the fuzzification parameters. Mexico is the second country in the world with high air pollution levels. The main air pollution problem that has been identified in Mexico City metropolitan area is the formation of photochemical smog, primarily ozone. This toxic gas can produce harmful effects on the population's health. The study and development of modeling methodologies that allow the capturing of ozone behavior becomes an important task when it is intended to predict contingencies before they are produced.",,,,, ,  2007 IEEE International Fuzzy Systems Conference,Fuzzy systems;Cities and towns;Urban areas;Air pollution;Environmental factors;Fuzzy reasoning;Finite impulse response filter;Genetic algorithms;Photochemistry;Predictive models,out_of_scope,
3102,"**Title**Balancing Privacy and Attack Utility: Calibrating Sample Difficulty for Membership Inference Attacks in Transfer Learning

**Abstract**The growing prominence of transfer learning in domains such as healthcare and finance highlights its efficacy in enhancing machine learning models. However, conventional membership inference attacks (MIA) often struggle to perform well when applied to transfer learning models trained under normal fit. To address this challenge, we propose a novel approach called PC-MIA. This approach involves generating multiple poisoned reference models using toxic samples. These poisoned models are then utilized to calibrate the difficulty of samples and reveal their true hardness, thereby enhancing the accuracy of MIA. Through empirical evaluations conducted on real-world datasets and employing diverse model architectures, our approach demonstrates its ability to significantly improve the accuracy of membership inference.","Liu, Shuwen, Qian, Yongfeng, Hao, Yixue",,,Balancing Privacy and Attack Utility: Calibrating Sample Difficulty for Membership Inference Attacks in Transfer Learning,,,10.1109/DSN-S60304.2024.00046 , ,,"The growing prominence of transfer learning in domains such as healthcare and finance highlights its efficacy in enhancing machine learning models. However, conventional membership inference attacks (MIA) often struggle to perform well when applied to transfer learning models trained under normal fit. To address this challenge, we propose a novel approach called PC-MIA. This approach involves generating multiple poisoned reference models using toxic samples. These poisoned models are then utilized to calibrate the difficulty of samples and reveal their true hardness, thereby enhancing the accuracy of MIA. Through empirical evaluations conducted on real-world datasets and employing diverse model architectures, our approach demonstrates its ability to significantly improve the accuracy of membership inference.",,,,, ,  2024 54th Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S),Data privacy;Accuracy;Transfer learning;Finance;Medical services;Calibration;membership inference attack;data poisoning attack;difficulty calibration,out_of_scope,
3103,"**Title**Deep Learning Based Multi-Class Classification of Invasive Plant Species

**Abstract**Efficient and proper identification of invasive plants is crucial for environmental conservation and ecosystem manage- ment. Timely recognition of these invaders is essential for proac- tive prevention measures, especially considering the potential risks they pose to human health and safety. For example, certain species may produce allergic pollen, toxic compounds or thorns that can cause skin irritation or injury to humans and animals. However, current methods rely on manual identification, which is labor-intensive and prone to misidentification due to the diversity and morphological similarities of these plants. Therefore, in this study, we investigate the efficacy of two deep learning algorithms, ResNet50 and EfficientNetB0, for multi-class classification of invasive plants. Utilizing data sourced from Kaggle and images scrapped from Google, our combined dataset encompasses images of five distinct invasive plant species. Through our experiments, we found that the EfficientNetB0 model outperforms ResNet50 model, obtaining 84% accuracy.","Nunavath, Vimala, Danilin, Oddvar",,,Deep Learning Based Multi-Class Classification of Invasive Plant Species,,,10.1109/ICAIT61638.2024.10690602 , ,,"Efficient and proper identification of invasive plants is crucial for environmental conservation and ecosystem manage- ment. Timely recognition of these invaders is essential for proac- tive prevention measures, especially considering the potential risks they pose to human health and safety. For example, certain species may produce allergic pollen, toxic compounds or thorns that can cause skin irritation or injury to humans and animals. However, current methods rely on manual identification, which is labor-intensive and prone to misidentification due to the diversity and morphological similarities of these plants. Therefore, in this study, we investigate the efficacy of two deep learning algorithms, ResNet50 and EfficientNetB0, for multi-class classification of invasive plants. Utilizing data sourced from Kaggle and images scrapped from Google, our combined dataset encompasses images of five distinct invasive plant species. Through our experiments, we found that the EfficientNetB0 model outperforms ResNet50 model, obtaining 84% accuracy.",,,,, ,  2024 Second International Conference on Advances in Information Technology (ICAIT),Deep learning;Prevention and mitigation;Manuals;Skin;Internet;Health and safety;Information technology;Invasive plants;Deep learning;CNNs;ResNet50;EfficientNetB0;Multi-class classification;Image classification,out_of_scope,
3104,"**Title**GalaxyGPT: A Hybrid Framework for Large Language Model Safety

**Abstract**The challenge of balancing safety and utility in Large Language Models (LLMs) requires novel solutions that go beyond conventional methods of pre- and post-processing, red-teaming, and feedback fine-tuning. In response to this, we introduce GalaxyGPT, a framework that synergizes safety moderation services of Internet vendors with LLMs to enhance safety performance. This necessity arises from the growing complexity of online interactions and the imperative to ensure that LLMs operate within safe and ethical boundaries without compromising their utility. GalaxyGPT leverages advanced algorithms and a comprehensive dataset to significantly improve safety measures, achieving notable accuracy (95.8%) and F1-score (94.5%) through evaluations of our custom dataset comprising 500 single-round safety tests, 100 multi-round dialogue tests, and 200 open-source tests. These results starkly outperform the safety metrics of APIs from six vendors (average 40.5% accuracy) and LLMs without GalaxyGPT integration (73% accuracy). Additionally, we contribute to the community by releasing an open-source test set of 600 entries and a compact classification model for security tasks, specifically designed to challenge and enhance the robustness of APIs, thereby facilitating the efficient deployment and application of GalaxyGPT in diverse environments.","Zhou, Hange, Zheng, Jiabin, Zhang, Longtu",,,GalaxyGPT: A Hybrid Framework for Large Language Model Safety,,,10.1109/ACCESS.2024.3425662 , ,,"The challenge of balancing safety and utility in Large Language Models (LLMs) requires novel solutions that go beyond conventional methods of pre- and post-processing, red-teaming, and feedback fine-tuning. In response to this, we introduce GalaxyGPT, a framework that synergizes safety moderation services of Internet vendors with LLMs to enhance safety performance. This necessity arises from the growing complexity of online interactions and the imperative to ensure that LLMs operate within safe and ethical boundaries without compromising their utility. GalaxyGPT leverages advanced algorithms and a comprehensive dataset to significantly improve safety measures, achieving notable accuracy (95.8%) and F1-score (94.5%) through evaluations of our custom dataset comprising 500 single-round safety tests, 100 multi-round dialogue tests, and 200 open-source tests. These results starkly outperform the safety metrics of APIs from six vendors (average 40.5% accuracy) and LLMs without GalaxyGPT integration (73% accuracy). Additionally, we contribute to the community by releasing an open-source test set of 600 entries and a compact classification model for security tasks, specifically designed to challenge and enhance the robustness of APIs, thereby facilitating the efficient deployment and application of GalaxyGPT in diverse environments.",,,,, ,  ,Safety;Security;Accuracy;Reviews;Large language models;Task analysis;Social networking (online);Artificial intelligence;Content management;Artificial intelligence;content moderation;ChatGPT;large language model;model safety;prompt engineering;supervised fine-tuning,out_of_scope,
3105,"**Title**Bayesian Classifiers for Chemical Toxicity Prediction

**Abstract**A major concern across the globe is the growing number of new chemicals that are brought to use on a regular basis without having any knowledge about their toxic behavior. The challenge here is that the growth in the number of chemicals is fast, and the traditional standards for toxicity testing involve a slow and expensive process of in vivo animal testing. Hence, a number of attempts are being made to find alternate methods of toxicity testing. In this paper we explore Bayesian classifiers and show that if we approximate posterior in the Bayesian classifier with specially crafted basis functions, we can improve upon the performance. We have tested our methods using data sets from the Environmental Protection Agency (EPA). Our experimental study demonstrated the utility of the advanced Bayesian classification approach.","Mishra, Meenakshi, Potetz, Brian, Huan, Jun",,,Bayesian Classifiers for Chemical Toxicity Prediction,,,10.1109/BIBM.2011.109 , ,,"A major concern across the globe is the growing number of new chemicals that are brought to use on a regular basis without having any knowledge about their toxic behavior. The challenge here is that the growth in the number of chemicals is fast, and the traditional standards for toxicity testing involve a slow and expensive process of in vivo animal testing. Hence, a number of attempts are being made to find alternate methods of toxicity testing. In this paper we explore Bayesian classifiers and show that if we approximate posterior in the Bayesian classifier with specially crafted basis functions, we can improve upon the performance. We have tested our methods using data sets from the Environmental Protection Agency (EPA). Our experimental study demonstrated the utility of the advanced Bayesian classification approach.",,,,, ,  2011 IEEE International Conference on Bioinformatics and Biomedicine,Chemicals;Bayesian methods;Support vector machines;Classification algorithms;Accuracy;Belief propagation;Testing;computational prediction of toxicity;bayes point;expectation propagation;belief propagation,out_of_scope,
3106,"**Title**Applying Case Based Based Reasoning to Sensor Fusion

**Abstract**One of the possible causes for global warming is the human intervention in the environment. The increasing amount of industrial and residential contaminants in lakes and rivers is seriously harming the quality of the water resources. In many countries, most of the sewage is directly sent to rivers or lakes, without any treatment. The impact on the environment of toxic waste, from a wide variety of manufacturing processes, is well known. More recently, however, it has become clear that the more subtle effects of nutrient level and chemical balance changes arising from farming land run-off and sewage water treatment also have a serious, but indirect, effect on the states of rivers, lakes and even the sea. This paper investigates the use of a hybrid Case Based Reasoning system for monitoring water quality based on chemical and physical parameters and algae population.","Policastro, Claudio A., Carvalho, Andre C.P.L.F.",,,Applying Case Based Based Reasoning to Sensor Fusion,,,10.1109/ISSNIP.2007.4496880 , ,,"One of the possible causes for global warming is the human intervention in the environment. The increasing amount of industrial and residential contaminants in lakes and rivers is seriously harming the quality of the water resources. In many countries, most of the sewage is directly sent to rivers or lakes, without any treatment. The impact on the environment of toxic waste, from a wide variety of manufacturing processes, is well known. More recently, however, it has become clear that the more subtle effects of nutrient level and chemical balance changes arising from farming land run-off and sewage water treatment also have a serious, but indirect, effect on the states of rivers, lakes and even the sea. This paper investigates the use of a hybrid Case Based Reasoning system for monitoring water quality based on chemical and physical parameters and algae population.",,,,, ,"  2007 3rd International Conference on Intelligent Sensors, Sensor Networks and Information",Sensor fusion;Lakes;Rivers;Sludge treatment;Wastewater treatment;Chemicals;Global warming;Humans;Manufacturing industries;Water resources,out_of_scope,
3107,"**Title**Leveraging BERT-GRU Model for Drugs Interaction Relationship Extraction

**Abstract**In the medical field, drugs are often used in combination to improve their efficacy, but it is also common for drug interactions to produce adverse reactions that can put a patient’s health at risk and even cause serious side effects or toxic reactions. In order to minimise the risk of adverse reactions from drug interactions, doctors need to understand the properties of each drug and provide appropriate dosing instructions based on the patient’s individual circumstances. In order to allow physicians to quickly extract drug-drug relationships, drug-drug interaction relationship extraction techniques need to be studied and analysed to establish a medical drug information base to assist physicians in accessing important information about drug-drug relationships and avoiding adverse drug interactions. This paper proposes a new algorithm for drug interaction relationship extraction, with two main studies covering the following aspects: (1) To address the problems of multiple meanings of words in relationship extraction, high computational complexity, low training efficiency and low generalization ability, this paper proposes a new model BERT-GRU based on recurrent neural network and BERT. in order to eliminate the influence of Chinese word separation ambiguity on entity relationship classification, the BERT is introduced as an embedding layer to better obtain the contextual information of Chinese characters; then The long-distance dependencies of entities in the sentences are captured by gated loop units and output to the Sigmoid layer for classification, so as to obtain better entity relationship classification results. (2) By comparing and analysing the experimental results of the BERT-GRU model with other models, the BERT-GRU model showed better performance on the drug-interaction relationship extraction task, especially achieving higher F1 values for relationships of advice, mechanism and int types. The BERT-GRU model performed even better compared to several other common models. This suggests that the combination of BERT and GRU is very effective in the drug interaction relationship extraction task. In summary, through a series of experimental comparisons, the BERT-GRU model proposes in this paper can effectively solve the problems of inability to distinguish between polysemous words and low training efficiency, and provides a more effective method for drug interaction relationship extraction.","Shen, Hang, Zhu, Xun, Deng, Hongtao",,,Leveraging BERT-GRU Model for Drugs Interaction Relationship Extraction,,,10.1109/ISCSIC60498.2023.00081 , ,,"In the medical field, drugs are often used in combination to improve their efficacy, but it is also common for drug interactions to produce adverse reactions that can put a patient’s health at risk and even cause serious side effects or toxic reactions. In order to minimise the risk of adverse reactions from drug interactions, doctors need to understand the properties of each drug and provide appropriate dosing instructions based on the patient’s individual circumstances. In order to allow physicians to quickly extract drug-drug relationships, drug-drug interaction relationship extraction techniques need to be studied and analysed to establish a medical drug information base to assist physicians in accessing important information about drug-drug relationships and avoiding adverse drug interactions. This paper proposes a new algorithm for drug interaction relationship extraction, with two main studies covering the following aspects: (1) To address the problems of multiple meanings of words in relationship extraction, high computational complexity, low training efficiency and low generalization ability, this paper proposes a new model BERT-GRU based on recurrent neural network and BERT. in order to eliminate the influence of Chinese word separation ambiguity on entity relationship classification, the BERT is introduced as an embedding layer to better obtain the contextual information of Chinese characters; then The long-distance dependencies of entities in the sentences are captured by gated loop units and output to the Sigmoid layer for classification, so as to obtain better entity relationship classification results. (2) By comparing and analysing the experimental results of the BERT-GRU model with other models, the BERT-GRU model showed better performance on the drug-interaction relationship extraction task, especially achieving higher F1 values for relationships of advice, mechanism and int types. The BERT-GRU model performed even better compared to several other common models. This suggests that the combination of BERT and GRU is very effective in the drug interaction relationship extraction task. In summary, through a series of experimental comparisons, the BERT-GRU model proposes in this paper can effectively solve the problems of inability to distinguish between polysemous words and low training efficiency, and provides a more effective method for drug interaction relationship extraction.",,,,, ,  2023 7th International Symposium on Computer Science and Intelligent Control (ISCSIC),Drugs;Deep learning;Analytical models;Feature extraction;Data mining;Task analysis;Context modeling;relational extraction;BERT;GRU,out_of_scope,
3108,"**Title**Drug Toxicity Classification Based on ReliefF and K-means Algorithm

**Abstract**Mongolian medicine Garidi-5 is a well-known regional compound formulation used for drying and treating the disease of yellow water. It contains the toxic herb Cao Wu and has been in use till date. Biochemical indicators in mice are important for studying drug toxicity. In this study, 32 SD rats were divided into four groups and given a daily oral dose of Garidi-5 at 0 g/kg, 0.3429 g/kg, 0.0857 g/kg, and 0.0214 $g$/k$g$, respectively, for 28 consecutive days. A feature selection algorithm based on the ReliefF algorithm was used to identify Garidi-5 poisoning in rats using organ indicators and blood biochemical indicators. In terms of feature selection, the most important relevant indicators were CKMB, ALP, HWR, CREP, CK, UREA, ALT, and L2WR. The K-means algorithm was used to perform cluster analysis on the rats' data indicators, and the results showed that after using the ReliefF algorithm for feature selection, the predicted accuracy and silhouette coefficient increased by 21.43% and 0.0779, respectively, when the feature weight threshold was set to 0.035. Empirical analysis showed that the ReliefF feature selection algorithm can improve the accuracy of toxicity prediction.","Wang, Luyao, Bai, Meirong, Zhao, Hongkai, Qiu, Sen, Wang, Zhelong, Zhao, Hongyu",,,Drug Toxicity Classification Based on ReliefF and K-means Algorithm,,,10.1109/ICICIP60808.2024.10477820 , ,,"Mongolian medicine Garidi-5 is a well-known regional compound formulation used for drying and treating the disease of yellow water. It contains the toxic herb Cao Wu and has been in use till date. Biochemical indicators in mice are important for studying drug toxicity. In this study, 32 SD rats were divided into four groups and given a daily oral dose of Garidi-5 at 0 g/kg, 0.3429 g/kg, 0.0857 g/kg, and 0.0214 $g$/k$g$, respectively, for 28 consecutive days. A feature selection algorithm based on the ReliefF algorithm was used to identify Garidi-5 poisoning in rats using organ indicators and blood biochemical indicators. In terms of feature selection, the most important relevant indicators were CKMB, ALP, HWR, CREP, CK, UREA, ALT, and L2WR. The K-means algorithm was used to perform cluster analysis on the rats' data indicators, and the results showed that after using the ReliefF algorithm for feature selection, the predicted accuracy and silhouette coefficient increased by 21.43% and 0.0779, respectively, when the feature weight threshold was set to 0.035. Empirical analysis showed that the ReliefF feature selection algorithm can improve the accuracy of toxicity prediction.",,,,, ,  2024 12th International Conference on Intelligent Control and Information Processing (ICICIP),Drugs;Toxicology;Liver;Clustering algorithms;Rats;Myocardium;Prediction algorithms;Feature selection;Garidi-5;ReliefF algorithm;K-means algorithm;Computational toxicology,out_of_scope,
3109,"**Title**Analysis and Detection of Skin Disorders using Artificial Intelligence-based learning

**Abstract**Skin conditions present considerable health challenges globally, as their covert susceptibility to infections not only induces physical afflictions but also precipitates episodes of depression. Regular and adequate skin examinations are a big step towards the early detection of any damaging or precancerous skin changes that could lead to skin disease. It is necessary to first distinguish between skin and non-skin in order to detect skin ailments. In this paper five different algorithms of artificial intelligence have been selected and used to skin disease dataset. Techniques based on machine learning can help advance frameworks that are capable of classifying different types of skin diseases. We have worked with naive bayes, CNN, Random Forest, logistic regression, kernel SVM, and a few more machine learning techniques. Using graphs, a comparable analysis that was dependent on training accuracy and confusion matrix parameters was carried out. It is found that, out of all the available candidates, CNN provides the best training precision for correctly predicting skin disorders.","Pattnayak, Parthasarathi, Patnaik, Sanghamitra, Gourisaria, Mahendra Kumar, Singh, Satyendr, Barik, Lalbihari, Patra, Sudhansu Shekhar",,,Analysis and Detection of Skin Disorders using Artificial Intelligence-based learning,,,10.1109/NMITCON62075.2024.10699007 , ,,"Skin conditions present considerable health challenges globally, as their covert susceptibility to infections not only induces physical afflictions but also precipitates episodes of depression. Regular and adequate skin examinations are a big step towards the early detection of any damaging or precancerous skin changes that could lead to skin disease. It is necessary to first distinguish between skin and non-skin in order to detect skin ailments. In this paper five different algorithms of artificial intelligence have been selected and used to skin disease dataset. Techniques based on machine learning can help advance frameworks that are capable of classifying different types of skin diseases. We have worked with naive bayes, CNN, Random Forest, logistic regression, kernel SVM, and a few more machine learning techniques. Using graphs, a comparable analysis that was dependent on training accuracy and confusion matrix parameters was carried out. It is found that, out of all the available candidates, CNN provides the best training precision for correctly predicting skin disorders.",,,,, ,"  2024 Second International Conference on Networks, Multimedia and Information Technology (NMITCON)",Training;Support vector machines;Machine learning algorithms;Medical services;Skin;Real-time systems;Bayes methods;Medical diagnostic imaging;Random forests;Diseases;Machine learning;kernel SVM;CNN;Random forest;naive Bayes;logistic regression,out_of_scope,
3110,"**Title**LASSI: An LLM-Based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes

**Abstract**This paper addresses the problem of providing a novel approach to sourcing significant training data for LLMs focused on science and engineering. In particular, a crucial challenge is sourcing parallel scientific codes in the ranges of millions to billions of codes. To tackle this problem, we propose an automated pipeline framework called LASSI, designed to translate between parallel programming languages by bootstrapping existing closed- or open-source LLMs. LASSI incorporates autonomous enhancement through self-correcting loops where errors encountered during the compilation and execution of generated code are fed back to the LLM through guided prompting for debugging and refactoring. We highlight the bidirectional translation of existing GPU benchmarks between OpenMP target offload and CUDA to validate LASSI. The results of evaluating LASSI with different application codes across four LLMs demonstrate the effectiveness of LASSI for generating executable parallel codes, with 80% of OpenMP to CUDA translations and 85% of CUDA to OpenMP translations producing the expected output. We also observe approximately 78% of OpenMP to CUDA translations and 62% of CUDA to OpenMP translations execute within 10% of or at a faster runtime than the original benchmark code in the same language.","Dearing, Matthew T., Tao, Yiheng, Wu, Xingfu, Lan, Zhiling, Taylor, Valerie",,,LASSI: An LLM-Based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes,,,10.1109/CLUSTERWorkshops61563.2024.00029 , ,,"This paper addresses the problem of providing a novel approach to sourcing significant training data for LLMs focused on science and engineering. In particular, a crucial challenge is sourcing parallel scientific codes in the ranges of millions to billions of codes. To tackle this problem, we propose an automated pipeline framework called LASSI, designed to translate between parallel programming languages by bootstrapping existing closed- or open-source LLMs. LASSI incorporates autonomous enhancement through self-correcting loops where errors encountered during the compilation and execution of generated code are fed back to the LLM through guided prompting for debugging and refactoring. We highlight the bidirectional translation of existing GPU benchmarks between OpenMP target offload and CUDA to validate LASSI. The results of evaluating LASSI with different application codes across four LLMs demonstrate the effectiveness of LASSI for generating executable parallel codes, with 80% of OpenMP to CUDA translations and 85% of CUDA to OpenMP translations producing the expected output. We also observe approximately 78% of OpenMP to CUDA translations and 62% of CUDA to OpenMP translations execute within 10% of or at a faster runtime than the original benchmark code in the same language.",,,,, ,  2024 IEEE International Conference on Cluster Computing Workshops (CLUSTER Workshops),Codes;Runtime;Parallel programming;Conferences;Large language models;Pipelines;Graphics processing units;Training data;Debugging;Benchmark testing;Large Language Models (LLMs);Code Generation;Code Translation;Parallel Scientific Codes;Self-Correcting,out_of_scope,
3111,"**Title**Advancements in Natural Language Understanding and Applications: A Study on ChatGPT with Novel Approaches to Fairness and Accuracy in Education

**Abstract**Natural Language Processing (NLP) has evolved significantly since the 1950s, with early research focusing on tasks like machine translation, information retrieval, and text summarization. Initially, most NLP research emphasized syntactic analysis, but the challenge of understanding and processing unstructured text remained. Recent advancements in large-scale language models (LLMs), such as ChatGPT, have revolutionized the field by enabling zero-shot execution of various NLP tasks without task-specific training. ChatGPT, based on the Transformer architecture, represents a major breakthrough in NLP, generating high-quality natural language responses and self-correcting based on dialogue context. This paper investigates the applications of ChatGPT in educational tasks, focusing on enhancing the fairness and accuracy of its responses. Fairness refers to ensuring that users receive consistent and unbiased answers to the same queries, while accuracy involves improving the precision of ChatGPT's outputs, particularly in complex educational tasks such as scientific literature review and content comprehension. We propose novel solutions, including dynamic model weighting for fairness and integrating external knowledge bases to boost accuracy. Experiments conducted on educational tasks demonstrate significant improvements in both fairness and accuracy, showing that the proposed methods enable ChatGPT to provide more reliable and consistent educational support. Our findings suggest that, with these innovations, ChatGPT can play a pivotal role in improving educational outcomes by offering fair access to quality learning content while addressing accuracy challenges. Future work will explore expanding this approach to other fields where NLP plays a crucial role.","Guo, Siyuan",,,Advancements in Natural Language Understanding and Applications: A Study on ChatGPT with Novel Approaches to Fairness and Accuracy in Education,,,10.1109/ISPCEM64498.2024.00088 , ,,"Natural Language Processing (NLP) has evolved significantly since the 1950s, with early research focusing on tasks like machine translation, information retrieval, and text summarization. Initially, most NLP research emphasized syntactic analysis, but the challenge of understanding and processing unstructured text remained. Recent advancements in large-scale language models (LLMs), such as ChatGPT, have revolutionized the field by enabling zero-shot execution of various NLP tasks without task-specific training. ChatGPT, based on the Transformer architecture, represents a major breakthrough in NLP, generating high-quality natural language responses and self-correcting based on dialogue context. This paper investigates the applications of ChatGPT in educational tasks, focusing on enhancing the fairness and accuracy of its responses. Fairness refers to ensuring that users receive consistent and unbiased answers to the same queries, while accuracy involves improving the precision of ChatGPT's outputs, particularly in complex educational tasks such as scientific literature review and content comprehension. We propose novel solutions, including dynamic model weighting for fairness and integrating external knowledge bases to boost accuracy. Experiments conducted on educational tasks demonstrate significant improvements in both fairness and accuracy, showing that the proposed methods enable ChatGPT to provide more reliable and consistent educational support. Our findings suggest that, with these innovations, ChatGPT can play a pivotal role in improving educational outcomes by offering fair access to quality learning content while addressing accuracy challenges. Future work will explore expanding this approach to other fields where NLP plays a crucial role.",,,,, ,"  2024 4th International Signal Processing, Communications and Engineering Management Conference (ISPCEM)",Training;Technological innovation;Accuracy;Computational modeling;Knowledge based systems;Focusing;Text summarization;Chatbots;Transformers;Natural language processing;ChatGPT;Natural Language Processing;Deep Learning;Fairness in AI;Accuracy Enhancement,out_of_scope,
3112,"**Title**Student-AI Question Cocreation for Enhancing Reading Comprehension

**Abstract**Student question generation (SQG) is an effective strategy for improving reading comprehension. It helps students improve their understanding of reading materials, metacognitively monitor their comprehension, and self-correct comprehension gaps. Internet technologies have been used to facilitate SQG process through intensive peer support. However, the availability, level of task commitment, and capabilities of student peers have emerged as significant concerns, particularly in light of the global pandemic and the subsequent postpandemic era. Thus, this article presents a student–artificial intelligence (AI) cocreation tool called CoAsker for supporting question generation. Following recent human-computer interaction (HCI) research in human-AI collaborative writing, CoAsker first allows students to provide question clues and answers and then uses a state-of-the-art pretrained language model, T5-PEGASUS, to generate questions. Finally, the student can use this AI question directly or perform reflection by comparing his or her questions with the AI question. An empirical study was conducted to examine the quality of AI questions and the effect of this tool on student engagement and reading comprehension. The results of the study show that students using this tool (treatment) were more engaged in generating low-level cognitive questions and performed better in acquiring knowledge than those using a traditional online question generation tool (control). These results indicate that student-AI question cocreation is beneficial to SQG training and educational assessment for reading comprehension, such as repeated practices.","Liu, Ming, Zhang, Jingxu, Nyagoga, Lucy Michael, Liu, Li",,,Student-AI Question Cocreation for Enhancing Reading Comprehension,,,10.1109/TLT.2023.3333439 , ,,"Student question generation (SQG) is an effective strategy for improving reading comprehension. It helps students improve their understanding of reading materials, metacognitively monitor their comprehension, and self-correct comprehension gaps. Internet technologies have been used to facilitate SQG process through intensive peer support. However, the availability, level of task commitment, and capabilities of student peers have emerged as significant concerns, particularly in light of the global pandemic and the subsequent postpandemic era. Thus, this article presents a student–artificial intelligence (AI) cocreation tool called CoAsker for supporting question generation. Following recent human-computer interaction (HCI) research in human-AI collaborative writing, CoAsker first allows students to provide question clues and answers and then uses a state-of-the-art pretrained language model, T5-PEGASUS, to generate questions. Finally, the student can use this AI question directly or perform reflection by comparing his or her questions with the AI question. An empirical study was conducted to examine the quality of AI questions and the effect of this tool on student engagement and reading comprehension. The results of the study show that students using this tool (treatment) were more engaged in generating low-level cognitive questions and performed better in acquiring knowledge than those using a traditional online question generation tool (control). These results indicate that student-AI question cocreation is beneficial to SQG training and educational assessment for reading comprehension, such as repeated practices.",,,,, ,  ,Writing;Artificial intelligence;Computational modeling;Task analysis;Internet;Human computer interaction;Federated learning;Authoring systems;educational technology;natural language processing,out_of_scope,
3113,"**Title**HiCRISP: An LLM-Based Hierarchical Closed-Loop Robotic Intelligent Self-Correction Planner

**Abstract**The integration of Large Language Models (LLMs) into robotics has revolutionized human-robot interactions and autonomous task planning. However, these systems are often unable to self-correct during the task execution, which hinders their adaptability in dynamic real-world environments. To address this issue, we present an LLM-based Hierarchical Closed-loop Robotic Intelligent Self-correction Planner (Hi-CRISP), an innovative framework that enables robots to correct errors within individual steps during the task execution. HiCRISP actively monitors and adapts the task execution process, addressing both high-level planning and low-level action errors. Extensive benchmark experiments, encompassing virtual and real-world scenarios, showcase HiCRISP's exceptional performance, positioning it as a promising solution for robotic task planning with LLMs.","Ming, Chenlin, Lin, Jiacheng, Fong, Pangkit, Wang, Han, Duan, Xiaoming, He, Jianping",,,HiCRISP: An LLM-Based Hierarchical Closed-Loop Robotic Intelligent Self-Correction Planner,,,10.1109/CAC63892.2024.10865457 , ,,"The integration of Large Language Models (LLMs) into robotics has revolutionized human-robot interactions and autonomous task planning. However, these systems are often unable to self-correct during the task execution, which hinders their adaptability in dynamic real-world environments. To address this issue, we present an LLM-based Hierarchical Closed-loop Robotic Intelligent Self-correction Planner (Hi-CRISP), an innovative framework that enables robots to correct errors within individual steps during the task execution. HiCRISP actively monitors and adapts the task execution process, addressing both high-level planning and low-level action errors. Extensive benchmark experiments, encompassing virtual and real-world scenarios, showcase HiCRISP's exceptional performance, positioning it as a promising solution for robotic task planning with LLMs.",,,,, ,  2024 China Automation Congress (CAC),Automation;Large language models;Human-robot interaction;Benchmark testing;Planning;Robots;Monitoring,out_of_scope,
3114,"**Title**Design of English Speaking Training System Based on Human-Computer Interaction

**Abstract**How to solve the lack of realtime feedback in oral training has always been a difficult problem. Human-computer interaction is very effective in providing flexibility, personalized support and realtime feedback to the system. This paper uses advanced voice input and recognition technology to accurately transcribe the learner's spoken expression, and then uses voice output and synthesis technology to communicate the voice feedback generated by the system to the learner, and finally realizes the realtime feedback and evaluation function, and gives accurate assessments and suggestions by analyzing the learner's spoken expression. After systematic testing, the pronunciation accuracy rate of students using the human-computer interaction system is 0.3-0.5. The personalized learning support and realtime feedback functions of the system help learners self-correct and improve their oral skills.","Ghoji, Patime, Abduwali, Aysigul, Husiyin, Maysigul",,,Design of English Speaking Training System Based on Human-Computer Interaction,,,10.1109/CSAT61646.2023.00071 , ,,"How to solve the lack of realtime feedback in oral training has always been a difficult problem. Human-computer interaction is very effective in providing flexibility, personalized support and realtime feedback to the system. This paper uses advanced voice input and recognition technology to accurately transcribe the learner's spoken expression, and then uses voice output and synthesis technology to communicate the voice feedback generated by the system to the learner, and finally realizes the realtime feedback and evaluation function, and gives accurate assessments and suggestions by analyzing the learner's spoken expression. After systematic testing, the pronunciation accuracy rate of students using the human-computer interaction system is 0.3-0.5. The personalized learning support and realtime feedback functions of the system help learners self-correct and improve their oral skills.",,,,, ,  2023 International Conference on Computer Science and Automation Technology (CSAT),Training;Human computer interaction;Computer science;Systematics;Computational modeling;Speech recognition;Speech enhancement;English Speaking Training System;Human-Computer Interaction;Hidden Markov Model;Pronunciation Assessment Weights,out_of_scope,
3115,"**Title**VulnGPT: Enhancing Source Code Vulnerability Detection Using AutoGPT and Adaptive Supervision Strategies

**Abstract**In this paper, we present a novel approach to vulnerability detection in source code using a collaborative setup built on top of AutoGPT, with a controller and an evaluator AI working together. The controller oversees the evaluation process and adds a layer of self-critique to the GPT- 4 model, while the evaluator AI conducts the security assessment. By following a step-by-step interaction process, the controller prompts the evaluator AI to verify identified vulnerabilities, enabling the AI to self-correct and improve its accuracy. We discuss the results of our approach, which demonstrates the potential for effective vulnerability detection and highlights areas for improvement. Our research aims to advance the development of AI-driven security evaluation techniques to enhance the overall quality of vulnerability detection, which can be used in various areas such as IoT.","Eberhardt, Gergely, Milánkovich, Ákos",,,VulnGPT: Enhancing Source Code Vulnerability Detection Using AutoGPT and Adaptive Supervision Strategies,,,10.1109/DCOSS-IoT61029.2024.00072 , ,,"In this paper, we present a novel approach to vulnerability detection in source code using a collaborative setup built on top of AutoGPT, with a controller and an evaluator AI working together. The controller oversees the evaluation process and adds a layer of self-critique to the GPT- 4 model, while the evaluator AI conducts the security assessment. By following a step-by-step interaction process, the controller prompts the evaluator AI to verify identified vulnerabilities, enabling the AI to self-correct and improve its accuracy. We discuss the results of our approach, which demonstrates the potential for effective vulnerability detection and highlights areas for improvement. Our research aims to advance the development of AI-driven security evaluation techniques to enhance the overall quality of vulnerability detection, which can be used in various areas such as IoT.",,,,, ,  2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT),Adaptive systems;Accuracy;Source coding;Process control;Collaboration;Security;Internet of Things;vulnerability detection;source code;automation;GPT,out_of_scope,
3116,"**Title**A hybrid approach for simultaneous obstacle avoidance and stabilization of dynamic bipedal walking using the aldebaran nao robot

**Abstract**In this paper, we propose a monocular vision system for autonomous obstacle avoidance and simultaneous stabilization of dynamic bipedal walking using the Aldebaran Nao robot. In particular, we address the case where erroneous bipedal locomotion causes the robot to drift away from a planned trajectory over time. To eliminate drifting, we use hybrid control patterns. This results in an efficient, self-correcting system that does not require to alter the robot's world representation. We confirm the efficiency and accuracy of the proposed system in a set of experiments.","Ullrich, Christian, Dotenco, Sergiu, Gallwitz, Florian",,,A hybrid approach for simultaneous obstacle avoidance and stabilization of dynamic bipedal walking using the aldebaran nao robot,,,10.1109/I4CS.2015.7294493 , ,,"In this paper, we propose a monocular vision system for autonomous obstacle avoidance and simultaneous stabilization of dynamic bipedal walking using the Aldebaran Nao robot. In particular, we address the case where erroneous bipedal locomotion causes the robot to drift away from a planned trajectory over time. To eliminate drifting, we use hybrid control patterns. This results in an efficient, self-correcting system that does not require to alter the robot's world representation. We confirm the efficiency and accuracy of the proposed system in a set of experiments.",,,,, ,  2015 15th International Conference on Innovations for Community Services (I4CS),Visualization;Computer architecture;Legged locomotion;Navigation;Collision avoidance;Cameras;Humanoid robots;robot control;computer vision,out_of_scope,
3117,"**Title**Automated Functionality and Security Evaluation of Large Language Models

**Abstract**Natural language processing (NLP) is rapidly developing. A series of Large Language Models (LLMs) have emerged, represented by ChatGPT, which have made significant breakthroughs in natural language understanding and generation, enabling fluent dialogue with humans, understanding human intentions, and completing complex tasks. However, in addition to the fairness and toxicity of traditional language models, some new problems, including hallucination, have also emerged in LLMs, making them hard to use. Evaluating LLMs manually is challenging due to subjectivity and inefficiency. In this paper, we focused on the fuzzy matching, toxicity detection, and hallucination detection in the evaluation of LLMs automatically, and fine-tune the Mixtral-8x7B Model, which can be deployed in private cloud environment, and prove the effectiveness of our method through experiments.","Ding, Minjie, Shen, Ying, Chen, Mingang",,,Automated Functionality and Security Evaluation of Large Language Models,,,10.1109/SmartCloud62736.2024.00014 , ,,"Natural language processing (NLP) is rapidly developing. A series of Large Language Models (LLMs) have emerged, represented by ChatGPT, which have made significant breakthroughs in natural language understanding and generation, enabling fluent dialogue with humans, understanding human intentions, and completing complex tasks. However, in addition to the fairness and toxicity of traditional language models, some new problems, including hallucination, have also emerged in LLMs, making them hard to use. Evaluating LLMs manually is challenging due to subjectivity and inefficiency. In this paper, we focused on the fuzzy matching, toxicity detection, and hallucination detection in the evaluation of LLMs automatically, and fine-tune the Mixtral-8x7B Model, which can be deployed in private cloud environment, and prove the effectiveness of our method through experiments.",,,,, ,  2024 9th IEEE International Conference on Smart Cloud (SmartCloud),Cloud computing;Toxicology;Accuracy;Graphics processing units;Chatbots;Security;Task analysis;LLM;evaluation;fuzzy matching;toxicity;hallucination,detection#evaluation,
3118,"**Title**Monitoring the Environmental Impact of TiO$_{\bf 2}$ Nanoparticles Using a Plant-Based Sensor Network

**Abstract**The increased manufacturing of nanoparticles for use in cosmetics, foods, and clothing necessitates the need for an effective system to monitor and evaluate the potential environmental impact of these nanoparticles. The goal of this research was to develop a plant-based sensor network for characterizing, monitoring, and understanding the environmental impact of TiO2 nanoparticles. The network consisted of potted Arabidopsis thaliana with a surrounding water supply, which was monitored by cameras attached to a laptop computer running a machine learning algorithm. Using the proposed plant sensor network, we were able to examine the toxicity of TiO2 nanoparticles in two systems: algae and terrestrial plants. Increased terrestrial plant growth was observed upon introduction of the nanoparticles, whereas algal growth decreased significantly. The proposed system can be further automated for high-throughput screening of nanoparticle toxicity in the environment at multiple trophic levels. The proposed plant-based sensor network could be used for more accurate characterization of the environmental impact of nanomaterials.","Lenaghan, Scott C., Li, Yuanyuan, Zhang, Hao, Burris, Jason N., Stewart, C. Neal, Parker, Lynne E., Zhang, Mingjun",,,Monitoring the Environmental Impact of TiO$_{\bf 2}$ Nanoparticles Using a Plant-Based Sensor Network,,,10.1109/TNANO.2013.2242089 , ,,"The increased manufacturing of nanoparticles for use in cosmetics, foods, and clothing necessitates the need for an effective system to monitor and evaluate the potential environmental impact of these nanoparticles. The goal of this research was to develop a plant-based sensor network for characterizing, monitoring, and understanding the environmental impact of TiO2 nanoparticles. The network consisted of potted Arabidopsis thaliana with a surrounding water supply, which was monitored by cameras attached to a laptop computer running a machine learning algorithm. Using the proposed plant sensor network, we were able to examine the toxicity of TiO2 nanoparticles in two systems: algae and terrestrial plants. Increased terrestrial plant growth was observed upon introduction of the nanoparticles, whereas algal growth decreased significantly. The proposed system can be further automated for high-throughput screening of nanoparticle toxicity in the environment at multiple trophic levels. The proposed plant-based sensor network could be used for more accurate characterization of the environmental impact of nanomaterials.",,,,, ,  ,Nanoparticles;Biosensors;Algae;Monitoring;Biomedical monitoring;Cameras;Subspace constraints;Biosystems;environmental monitoring;nanobioscience;nanobiotechnology,out_of_scope,
3119,"**Title**Encouraging Emotion Regulation in Social Media Conversations through Self-Reflection

**Abstract**Digital Emotion Regulation (DER) is the practice of employing digital technologies, such as smartphones, to influence one's emotional state. However, online rage, hate speech, or toxicity that stem from ineffective Emotional Regulation (ER) often harms online well-being. Earlier research has focused on identifying ER with multi-modal sensors and studying daily DER practices, but the contextual dynamics of DER remain unexplored. This work provides an intervention for supporting DER in online conversations. It introduces a graph-based framework to identify the need for ER in these conversations. Additionally, it informs users of their emotional influence on a conversation, prompting self-reflection. Through interaction design, this work introduces a technique to de-anonymize online users, encouraging accountability and responsible online behaviour to maintain digital well-being. We collected 2.5K tweets from major news outlets and Australian state Premiers over a year, analysing emotions at individual and group levels in Twitter conversations. Compared to Google's Perspective API, our framework reduced toxicity by 10% on test data, surpassing Google's API by 3%.","Verma, Akriti, Islam, Shama, Moghaddam, Valeh, Anwar, Adnan",,,Encouraging Emotion Regulation in Social Media Conversations through Self-Reflection,,,10.1109/IEEECONF58110.2023.10520471 , ,,"Digital Emotion Regulation (DER) is the practice of employing digital technologies, such as smartphones, to influence one's emotional state. However, online rage, hate speech, or toxicity that stem from ineffective Emotional Regulation (ER) often harms online well-being. Earlier research has focused on identifying ER with multi-modal sensors and studying daily DER practices, but the contextual dynamics of DER remain unexplored. This work provides an intervention for supporting DER in online conversations. It introduces a graph-based framework to identify the need for ER in these conversations. Additionally, it informs users of their emotional influence on a conversation, prompting self-reflection. Through interaction design, this work introduces a technique to de-anonymize online users, encouraging accountability and responsible online behaviour to maintain digital well-being. We collected 2.5K tweets from major news outlets and Australian state Premiers over a year, analysing emotions at individual and group levels in Twitter conversations. Compared to Google's Perspective API, our framework reduced toxicity by 10% on test data, surpassing Google's API by 3%.",,,,, ,  2023 IEEE Engineering Informatics,Emotion recognition;Toxicology;Social networking (online);Multimodal sensors;Hate speech;Oral communication;Regulation;Digital Emotion Regulation (DER);Human Computer Interaction (HCI);Affective Computing;Emotions in Social Media,detection,
3120,"**Title**A High-Sensitivity Potentiometric Mercuric Ion Sensor Based on m-Toluidine Films

**Abstract**A sensor of $m$ -toluidine polymer film coated platinum electrode was fabricated by the electropolymerization using cyclic voltammetry technique for the detection of mercury ions (Hg2+) in aqueous solution. This paper was carried out using the simple potentiometric method and confirmed by a cyclic voltammetry technique. The effects of the polymer film thickness and pH of Hg2+ solutions on the response of the sensor were studied. Moreover, the stability, sensitivity, and selectivity of the $m$ -toluidine sensor were investigated. The optimum thickness of the polymer film was obtained after ten cyclic voltammetric runs. This film has a Nernstian response slope of 29.19 mV/decade with a detection limit of $3.54\times 10^{\mathrm {\mathbf {-5}}}$ M at 293 K by the simple potentiometric method. In addition, it has a sensitivity of $4\times 10^{\mathrm {\mathbf {-7}}}$ AM $^{\mathrm {\mathbf {-1}}}$ with a detection limit of $1.33\times 10^{\mathrm {\mathbf {-7}}}$ M by the cyclic voltammetry method. Moreover, the sensor is specific to Hg2+ ions in the presence of other ions, such as Na+, K+, Mg2+, Ca2+, Co2+, Ni2+, Zn2+, and Pb2+. Furthermore, the most stable response of the sensor to Hg2+ ions in the solution of pH ranged from 4 to 6.4 for a lifetime of about eleven weeks. Moreover, the sensor was applied for detection of four natural samples: 1) tap water; 2) underground water; 3) first distillate water; and 4) another sample wasted with Hg2+ ions.","Sayyah, Said M., Shaban, Mohamed, Rabia, Mohamed",,,A High-Sensitivity Potentiometric Mercuric Ion Sensor Based on m-Toluidine Films,,,10.1109/JSEN.2015.2505313 , ,,"A sensor of $m$ -toluidine polymer film coated platinum electrode was fabricated by the electropolymerization using cyclic voltammetry technique for the detection of mercury ions (Hg2+) in aqueous solution. This paper was carried out using the simple potentiometric method and confirmed by a cyclic voltammetry technique. The effects of the polymer film thickness and pH of Hg2+ solutions on the response of the sensor were studied. Moreover, the stability, sensitivity, and selectivity of the $m$ -toluidine sensor were investigated. The optimum thickness of the polymer film was obtained after ten cyclic voltammetric runs. This film has a Nernstian response slope of 29.19 mV/decade with a detection limit of $3.54\times 10^{\mathrm {\mathbf {-5}}}$ M at 293 K by the simple potentiometric method. In addition, it has a sensitivity of $4\times 10^{\mathrm {\mathbf {-7}}}$ AM $^{\mathrm {\mathbf {-1}}}$ with a detection limit of $1.33\times 10^{\mathrm {\mathbf {-7}}}$ M by the cyclic voltammetry method. Moreover, the sensor is specific to Hg2+ ions in the presence of other ions, such as Na+, K+, Mg2+, Ca2+, Co2+, Ni2+, Zn2+, and Pb2+. Furthermore, the most stable response of the sensor to Hg2+ ions in the solution of pH ranged from 4 to 6.4 for a lifetime of about eleven weeks. Moreover, the sensor was applied for detection of four natural samples: 1) tap water; 2) underground water; 3) first distillate water; and 4) another sample wasted with Hg2+ ions.",,,,, ,  ,Sensors;Electrodes;Ions;Chemical sensors;Biomembranes;Metals;Polymers;Cyclic voltammetry;m-toluidin;Mercuric ions;Potentiometric method;Sensor;cyclic voltammetry;m-toluidin;mercuric ions;potentiometric method;sensor,out_of_scope,
3121,"**Title**Poisonous Mushroom Detection Using Graph Neural Networks

**Abstract**This study delves into the use of Graph Neural Networks (GNNs) for the classification of poisonous and edible mushrooms based on image data, aiming to address the limitations of manual identification methods. Three GNN architectures, Graph Convolutional Network (GCN), GraphSAGE, and Graph Isomorphism Network (GIN), are examined, with a comparison of the Adam and Stochastic Gradient Descent (SGD) optimizers within each. The results underscore GNNs' effectiveness in discerning toxic mushrooms by capturing nuanced pixel relationships, offering a valuable contribution to the fields of biology and toxicology, with practical implications for mushroom toxicity prevention.","Pathirana, D.P.C.H, Rajapaksha, R.M.T.U., Rathnayake, H.M. Samadhi Chathuranga, Sirisena, Kosala, Samarathunga, Udara",,,Poisonous Mushroom Detection Using Graph Neural Networks,,,10.1109/ICAC60630.2023.10417353 , ,,"This study delves into the use of Graph Neural Networks (GNNs) for the classification of poisonous and edible mushrooms based on image data, aiming to address the limitations of manual identification methods. Three GNN architectures, Graph Convolutional Network (GCN), GraphSAGE, and Graph Isomorphism Network (GIN), are examined, with a comparison of the Adam and Stochastic Gradient Descent (SGD) optimizers within each. The results underscore GNNs' effectiveness in discerning toxic mushrooms by capturing nuanced pixel relationships, offering a valuable contribution to the fields of biology and toxicology, with practical implications for mushroom toxicity prevention.",,,,, ,  2023 5th International Conference on Advancements in Computing (ICAC),Toxicology;Computer architecture;Graph neural networks;Biology;Convolutional neural networks;Mushroom classification;Graph Neural Networks;Deep Learning;Poisonous Mushroom Detection;Image Processing,out_of_scope,
3122,"**Title**Revealing Online Threats Through Leveraging RNN Models for Advanced Cyberbullying Detection

**Abstract**Researchers are increasingly focused on the challenge of cyberbullying detection, driven by its growing presence on social media platforms—a realm where individuals share thoughts, opinions, and aspects of their lives. Unfortunately, these platforms often become arenas for toxicity, with cyberbullying manifesting through posts that are offensive, violent, or intimidating. This phenomenon, transcending national boundaries, inflicts harm on victims, affecting all facets of their lives. In our study, we introduce a method for identifying hate speech utilizing Recurrent Neural Network (RNN) models, specifically applied to a dataset in the Darija dialect. We assessed the model's effectiveness using metrics such as accuracy, precision, recall, and F1-score, and employed confusion matrices and ROC-AUC curves for visual evaluation.","Rachidi, Rabia, Errami, Mouaad, Ouassil, Mohamed Amine, Jebbari, Mohammed, Cherradi, Bouchaib, Silkan, Hassan",,,Revealing Online Threats Through Leveraging RNN Models for Advanced Cyberbullying Detection,,,10.1109/IRASET60544.2024.10548957 , ,,"Researchers are increasingly focused on the challenge of cyberbullying detection, driven by its growing presence on social media platforms—a realm where individuals share thoughts, opinions, and aspects of their lives. Unfortunately, these platforms often become arenas for toxicity, with cyberbullying manifesting through posts that are offensive, violent, or intimidating. This phenomenon, transcending national boundaries, inflicts harm on victims, affecting all facets of their lives. In our study, we introduce a method for identifying hate speech utilizing Recurrent Neural Network (RNN) models, specifically applied to a dataset in the Darija dialect. We assessed the model's effectiveness using metrics such as accuracy, precision, recall, and F1-score, and employed confusion matrices and ROC-AUC curves for visual evaluation.",,,,, ,"  2024 4th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)","Measurement;Visualization;Recurrent neural networks;Toxicology;Refining;Hate speech;Cyberbullying;Cyberbullying; social network, neural networks, bidirectional gated recurrent unit;Long-Short-term-Memory;RNN",out_but_toxicity,
3123,"**Title**Bioluminescent Sensors for Onsite Non-specific Screening of Toxic Agents in Food and Water

**Abstract**This paper presents a non-specific detection system for quickly screening toxic and harmful contaminants in food products by utilizing the properties of naturally occurring bioluminescence in selected living bacteria. The goal of the project was to evaluate the effectiveness of using luminescent bacteria as ""canaries"" for rapid non-specific detection of toxic contaminants for homeland food protection and defense. Vibro fischeri was used as the specific biological sensor in this study. The bacteria was grown in marine broth and maintained between 22 and 25degC for optimal growth. Cultures were used to determine the presence of a surrogate toxicant, in this case, sodium hypochlorite (bleach) in various concentrations. Initial results show that 10% bleach quenches light emission immediately upon contact with the bacteria contained in 3 food matrices, namely: skim milk, 2% milk, and drinking water. This naturally occurring biological sensor would be useful in providing an inexpensive, highly renewable early warning system of a potentially catastrophic event. A successful system would enhance early surveillance against any intentional attack on the US food supply, including drinking water. Even in the absence of a bioterrorism event, the biological sensor would still be useful in control measures against naturally occurring or sanitation-constrained toxic substances.","Alocilja, Evangelyn C., McLean, Trevor",,,Bioluminescent Sensors for Onsite Non-specific Screening of Toxic Agents in Food and Water,,,10.1109/THS.2007.370046 , ,,"This paper presents a non-specific detection system for quickly screening toxic and harmful contaminants in food products by utilizing the properties of naturally occurring bioluminescence in selected living bacteria. The goal of the project was to evaluate the effectiveness of using luminescent bacteria as ""canaries"" for rapid non-specific detection of toxic contaminants for homeland food protection and defense. Vibro fischeri was used as the specific biological sensor in this study. The bacteria was grown in marine broth and maintained between 22 and 25degC for optimal growth. Cultures were used to determine the presence of a surrogate toxicant, in this case, sodium hypochlorite (bleach) in various concentrations. Initial results show that 10% bleach quenches light emission immediately upon contact with the bacteria contained in 3 food matrices, namely: skim milk, 2% milk, and drinking water. This naturally occurring biological sensor would be useful in providing an inexpensive, highly renewable early warning system of a potentially catastrophic event. A successful system would enhance early surveillance against any intentional attack on the US food supply, including drinking water. Even in the absence of a bioterrorism event, the biological sensor would still be useful in control measures against naturally occurring or sanitation-constrained toxic substances.",,,,, ,  2007 IEEE Conference on Technologies for Homeland Security,Bioluminescence;Biosensors;Microorganisms;Bleaching;Dairy products;Food products;Protection;Alarm systems;Surveillance;Bioterrorism,out_of_scope,
3124,"**Title**Heart rate variability and baroreceptor reflex sensitivity in doxorubicin-induced cardiomyopathy

**Abstract**The clinical use of doxorubicin, an effective chemotherapeutic is hampered by the development of irreversible cardiotoxicity. Here we test comprehensive analysis of heart rate (HR) variability (HRV) for early detection of doxorubicin-induced cardiotoxicity. Experiments were conducted in adult male Wistar rats treated for 15 days with saline (CONT) or doxorubicin (DOXO, total dose 15 mg/kg, i.p.). DOXO rats exhibited cardiotoxicity and increased mortality. Thirty five days post treatment, HR variability and baro-receptor reflex sensitivity of DOXO rats were increased in respect to CONT rats, while HR entropy was reduced. The results recommend comprehensive analysis of HRV for early detection of doxorubicin-induced cardiomyopathy.","Loncar-Turukalo, Tatjana, Vasic, Marko, Mijatovic, Gorana, Japundzic-Zigon, Nina, Bajic, Dragana",,,Heart rate variability and baroreceptor reflex sensitivity in doxorubicin-induced cardiomyopathy,,,10.1109/ESGCO.2014.6847548 , ,,"The clinical use of doxorubicin, an effective chemotherapeutic is hampered by the development of irreversible cardiotoxicity. Here we test comprehensive analysis of heart rate (HR) variability (HRV) for early detection of doxorubicin-induced cardiotoxicity. Experiments were conducted in adult male Wistar rats treated for 15 days with saline (CONT) or doxorubicin (DOXO, total dose 15 mg/kg, i.p.). DOXO rats exhibited cardiotoxicity and increased mortality. Thirty five days post treatment, HR variability and baro-receptor reflex sensitivity of DOXO rats were increased in respect to CONT rats, while HR entropy was reduced. The results recommend comprehensive analysis of HRV for early detection of doxorubicin-induced cardiomyopathy.",,,,, ,  2014 8th Conference of the European Study Group on Cardiovascular Oscillations (ESGCO),Rats;Heart rate variability;Entropy;Educational institutions;Europe,out_of_scope,
3125,"**Title**BRCycle-GAN: A Near-Infrared Fluorescence Image Processing Network Based on a Small Training Set

**Abstract**As a noninvasive, nonradiative and high-speed imaging modality, fluorescence imaging in the second near-infrared window (NIR-II, 1,000-1,700 nm) has demonstrated great potential for biomedical research and clinical study. The NIR-II window can be further divided into two spectral regions: NIR-IIa (1,000-1,300 nm) and NIR-IIb (1,500-1,700 nm). Compared to NIR-IIa, imaging in NIR-IIb region affords high-resolution imaging at subcentimeter tissue depths due to suppressed photon scattering and diminished tissue autofluorescence at long wavelengths, but relies on probes with high toxicity. To address the problem, researchers employ deep learning networks to attain NIR-IIb images from NIR-IIa images. However, current methods require numerous paired or unpaired images (more than 2800 images) as training sets, which can hardly acquire. In this work, an innovative convolutional neural network (BRCycle-GAN) is trained based on a small training set (merely 63 images) to transform NIR-IIa images into images with NIR-IIb imaging qualities. The NIR-IIb images generated by BRCycle-GAN outperform previous network models in terms of peak signal-to-noise ratio, cosine similarity and other image evaluation indices.","Wang, Yuran, Wang, Lugui, Tian, Ye",,,BRCycle-GAN: A Near-Infrared Fluorescence Image Processing Network Based on a Small Training Set,,,10.1109/ACCESS.2024.3421525 , ,,"As a noninvasive, nonradiative and high-speed imaging modality, fluorescence imaging in the second near-infrared window (NIR-II, 1,000-1,700 nm) has demonstrated great potential for biomedical research and clinical study. The NIR-II window can be further divided into two spectral regions: NIR-IIa (1,000-1,300 nm) and NIR-IIb (1,500-1,700 nm). Compared to NIR-IIa, imaging in NIR-IIb region affords high-resolution imaging at subcentimeter tissue depths due to suppressed photon scattering and diminished tissue autofluorescence at long wavelengths, but relies on probes with high toxicity. To address the problem, researchers employ deep learning networks to attain NIR-IIb images from NIR-IIa images. However, current methods require numerous paired or unpaired images (more than 2800 images) as training sets, which can hardly acquire. In this work, an innovative convolutional neural network (BRCycle-GAN) is trained based on a small training set (merely 63 images) to transform NIR-IIa images into images with NIR-IIb imaging qualities. The NIR-IIb images generated by BRCycle-GAN outperform previous network models in terms of peak signal-to-noise ratio, cosine similarity and other image evaluation indices.",,,,, ,  ,Generators;Imaging;Training;Fluorescence;Probes;Convolution;Biomedical imaging;Deep learning;Optical imaging;Deep learning;biomedical image processing;optical imaging,out_of_scope,
3126,"**Title**Analysis of Classification Algorithms for Oil Spill Recognition Using SAR Data

**Abstract**The research work examination extends the application of Synthetic aperture radar (SAR) data for recognition of oil let outs. The focus of this examination is on classing approaches for oil let outs detection using SAR imagery. Image processing techniques are used to derive feature vectors for ocean patch. The out-turn of the image processing is a fixed-length column vector for each dubious region used to classify whether the region contain an oil spill or not. The two classes of the data are oil spill and non-spill. The data of this study consists of standard imbalanced machine learning dataset. 937 cases with 48 derived attributes, a patch number, and a class description which has 896 cases as non-oil let out designate with class description 0 and oil spill with 41 cases is indicated by a class description. Basic EDA and data pre-processing are done before model building. Best classifier models are used for prediction of the data. The gradient boosting classifier providing the highest accuracy score of 98% and is selected as the best classifier for the oil prediction.","K, Trishika, A, Rakshitha, Kodipalli, Ashwini, Rao, Trupthi, V, Pushpalatha, B R, Rohini",,,Analysis of Classification Algorithms for Oil Spill Recognition Using SAR Data,,,10.1109/CIISCA59740.2023.00054 , ,,"The research work examination extends the application of Synthetic aperture radar (SAR) data for recognition of oil let outs. The focus of this examination is on classing approaches for oil let outs detection using SAR imagery. Image processing techniques are used to derive feature vectors for ocean patch. The out-turn of the image processing is a fixed-length column vector for each dubious region used to classify whether the region contain an oil spill or not. The two classes of the data are oil spill and non-spill. The data of this study consists of standard imbalanced machine learning dataset. 937 cases with 48 derived attributes, a patch number, and a class description which has 896 cases as non-oil let out designate with class description 0 and oil spill with 41 cases is indicated by a class description. Basic EDA and data pre-processing are done before model building. Best classifier models are used for prediction of the data. The gradient boosting classifier providing the highest accuracy score of 98% and is selected as the best classifier for the oil prediction.",,,,, ,"  2023 International Conference on Computational Intelligence for Information, Security and Communication Applications (CIISCA)",Oils;Image processing;Support vector machine classification;Boosting;Data models;Synthetic aperture radar;Regression tree analysis;Synthetic Aperture Radar (SAR);Oil spill classification;Machine learning;Classifiers;Gradient boosting classifier;Support Vector Machine;K-Fold;Logistic regression;Decision tree classifier;Bagging;Boosting;KNN;Naïve Bayes,out_of_scope,
3127,"**Title**Machine Learning Assisted Sanitizer Quality Identification Using Permittivity Measurement

**Abstract**Sanitizers play a crucial role in hygiene and the prevention of infectious diseases by reducing harmful microorganisms on surfaces. This paper focuses on alcohol-based sanitizers, specifically those containing ethanol and isopropyl alcohol, known for their rapid action and broad spectrum efficacy. The effectiveness of these sanitizers depends on the alcohol content, with water enhancing their performance. Traditional quality detection methods are accurate but time-consuming. This work proposes a support vector machine based classification model combined with a complex permittivity measurement system to assess sanitizer quality. The model achieves 97.2% accuracy for a frequency range of 0.2–20 GHz at 25°C, with improved accuracy of 99% in the 2–5 GHz range, identifying this as the optimal frequency range for sanitizer classification. This method is compatible with any permittivity measurement system with measurement error ±15%. Significant time savings in quality assessment is also achieved.","H.P, Thushara, S, Mridula, K, Neema",,,Machine Learning Assisted Sanitizer Quality Identification Using Permittivity Measurement,,,10.1109/ICACC63692.2024.10845335 , ,,"Sanitizers play a crucial role in hygiene and the prevention of infectious diseases by reducing harmful microorganisms on surfaces. This paper focuses on alcohol-based sanitizers, specifically those containing ethanol and isopropyl alcohol, known for their rapid action and broad spectrum efficacy. The effectiveness of these sanitizers depends on the alcohol content, with water enhancing their performance. Traditional quality detection methods are accurate but time-consuming. This work proposes a support vector machine based classification model combined with a complex permittivity measurement system to assess sanitizer quality. The model achieves 97.2% accuracy for a frequency range of 0.2–20 GHz at 25°C, with improved accuracy of 99% in the 2–5 GHz range, identifying this as the optimal frequency range for sanitizer classification. This method is compatible with any permittivity measurement system with measurement error ±15%. Significant time savings in quality assessment is also achieved.",,,,, ,  2024 11th International Conference on Advances in Computing and Communications (ICACC),Support vector machines;Measurement errors;Accuracy;Permittivity measurement;Prevention and mitigation;Quality control;Vectors;Quality assessment;Safety;Public healthcare;Complex permittivity;alcohol based sanitizers;machine learning;support vector machine;identification;classification,out_of_scope,
3128,"**Title**Chlorophyll change and spectral response of maize seedling under iron stress

**Abstract**Iron stress could pose a great threat to plant physiological processes and food security. Hyperspectral remote sensing is an important technology for stress monitoring of crop because of its rapid, nondestructive and macro-scale detection ability. In this study, maize seeding was taken as an example to study its chlorophyll change and spectral response under different iron concentration. The result showed that (1) with the increase of concentration of iron stress, chlorophyll content increased at first and then decreased and the maximum value appeared at 500mg/kg, and (2) selected spectral indices are positively correlative with chlorophyll content. Among the indices, RVI is the best index to evaluate chlorophyll content and then it is the right index to detect the iron stress of maize seedlings.","Ma, Baodong, Xu, Ao, Zhang, Xuanxuan, Wu, Lixin",,,Chlorophyll change and spectral response of maize seedling under iron stress,,,10.1109/IGARSS.2016.7730672 , ,,"Iron stress could pose a great threat to plant physiological processes and food security. Hyperspectral remote sensing is an important technology for stress monitoring of crop because of its rapid, nondestructive and macro-scale detection ability. In this study, maize seeding was taken as an example to study its chlorophyll change and spectral response under different iron concentration. The result showed that (1) with the increase of concentration of iron stress, chlorophyll content increased at first and then decreased and the maximum value appeared at 500mg/kg, and (2) selected spectral indices are positively correlative with chlorophyll content. Among the indices, RVI is the best index to evaluate chlorophyll content and then it is the right index to detect the iron stress of maize seedlings.",,,,, ,  2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS),Iron;Stress;Soil;Indexes;Remote sensing;Pollution measurement;Soil measurements;maize seedling;iron stress;chlorophyll;spectral indices,out_of_scope,
3129,"**Title**Rapid Assessment of Adverse Drug Reactions by Statistical Solution of Gene Association Network

**Abstract**Adverse drug reaction (ADR) is a common clinical problem, sometimes accompanying with high risk of mortality and morbidity. It is also one of the major factors that lead to failure in new drug development. Unfortunately, most of current experimental and computational methods are unable to evaluate clinical safety of drug candidates in early drug discovery stage due to the very limited knowledge of molecular mechanisms underlying ADRs. Therefore, in this study, we proposed a novel naïve Bayesian model for rapid assessment of clinical ADRs with frequency estimation. This model was constructed on a gene-ADR association network, which covered 611 US FDA approved drugs, 14,251 genes, and 1,254 distinct ADR terms. An average detection rate of 99.86 and 99.73 percent were achieved eventually in identification of known ADRs in internal test data set and external case analyses respectively. Moreover, a comparative analysis between the estimated frequencies of ADRs and their observed frequencies was undertaken. It is observed that these two frequencies have the similar distribution trend. These results suggest that the naïve Bayesian model based on gene-ADR association network can serve as an efficient and economic tool in rapid ADRs assessment.","Xiang, Yan-Ping, Liu, Ke, Cheng, Xian-Ying, Cheng, Cheng, Gong, Fang, Pan, Jian-Bo, Ji, Zhi-Liang",,,Rapid Assessment of Adverse Drug Reactions by Statistical Solution of Gene Association Network,,,10.1109/TCBB.2014.2338292 , ,,"Adverse drug reaction (ADR) is a common clinical problem, sometimes accompanying with high risk of mortality and morbidity. It is also one of the major factors that lead to failure in new drug development. Unfortunately, most of current experimental and computational methods are unable to evaluate clinical safety of drug candidates in early drug discovery stage due to the very limited knowledge of molecular mechanisms underlying ADRs. Therefore, in this study, we proposed a novel naïve Bayesian model for rapid assessment of clinical ADRs with frequency estimation. This model was constructed on a gene-ADR association network, which covered 611 US FDA approved drugs, 14,251 genes, and 1,254 distinct ADR terms. An average detection rate of 99.86 and 99.73 percent were achieved eventually in identification of known ADRs in internal test data set and external case analyses respectively. Moreover, a comparative analysis between the estimated frequencies of ADRs and their observed frequencies was undertaken. It is observed that these two frequencies have the similar distribution trend. These results suggest that the naïve Bayesian model based on gene-ADR association network can serve as an efficient and economic tool in rapid ADRs assessment.",,,,, ,  ,Drugs;Frequency estimation;Computational modeling;Predictive models;Bayes methods;Chemicals;Databases;Adverse drug reactions;gene-ADR association network;naïve Bayesian model,out_of_scope,
3130,"**Title**A Comparative Review: Research in Safety and Sustainability of Carbon Nanomaterials Without and With Machine Learning Assistance

**Abstract**In recent years, the rapid development of nanomaterials and nanoproducts has led to their widespread application in energy, aerospace, agriculture, industry, and biomedicine. However, carbon nanomaterials (CNMs) have been shown to possess toxic properties that negatively impact both the environment and human health. Then, toxicological risk assessment of CNMs are necessary to identify their potential adverse effects. This review examines the safety and sustainability of fullerenes, graphene, and carbon nanotubes in critical areas. First, the toxicity of CNMs in medicine, environmental engineering, energy, food, cosmetic and agriculture sectors using traditional detection methods is summarized. Then, the application of machine learning techniques for assessing the toxicity of these types of CNMs is reviewed. Finally, a comparative analysis of traditional and machine learning methods for detecting carbon nanomaterial toxicity is presented, highlighting key issues that need to be addressed in future research.","Wang, Liqing, Wang, Hongyan, Bai, Mingyu, Wu, Yin, Guo, Tongshu, Cai, Dirui, Sun, Peiyan, Xiao, Na, Li, Ansheng, Ming, Wuyi",,,A Comparative Review: Research in Safety and Sustainability of Carbon Nanomaterials Without and With Machine Learning Assistance,,,10.1109/ACCESS.2024.3494549 , ,,"In recent years, the rapid development of nanomaterials and nanoproducts has led to their widespread application in energy, aerospace, agriculture, industry, and biomedicine. However, carbon nanomaterials (CNMs) have been shown to possess toxic properties that negatively impact both the environment and human health. Then, toxicological risk assessment of CNMs are necessary to identify their potential adverse effects. This review examines the safety and sustainability of fullerenes, graphene, and carbon nanotubes in critical areas. First, the toxicity of CNMs in medicine, environmental engineering, energy, food, cosmetic and agriculture sectors using traditional detection methods is summarized. Then, the application of machine learning techniques for assessing the toxicity of these types of CNMs is reviewed. Finally, a comparative analysis of traditional and machine learning methods for detecting carbon nanomaterial toxicity is presented, highlighting key issues that need to be addressed in future research.",,,,, ,  ,Nanomaterials;Toxicology;Safety;Biomedical imaging;Sustainable development;Nanotechnology;Nanoparticles;Carbon;Proteins;Nanobioscience;Machine learning;Environmental factors;Agriculture;Carbon nanomaterials;safety;sustainability;toxicity;machine learning;medical;environmental engineering;energy;food;cosmetic;agriculture,out_of_scope,
3131,"**Title**Artificial Intelligence in MOBA Games: A Multivocal Literature Mapping

**Abstract**Esports—games played competitively—comprise a major sector of the global games industry. Esports have been used as a testbed for game artificial intelligence (AI) and game analytics for two decades. This article presents a multivocal literature mapping of available research that focuses strictly on the use of artificial intelligence approaches in multiplayer online battle arena (MOBA) games, one of the most popular esports genres and the one most widely used for game AI and game analytics research. A mapping is performed on relevant publications published between 2011 and 2022 and systematically examines them to extract similarities, gaps, and main findings. We analyzed 124 publications to identify the most studied topics, the most commonly used techniques, and the most commonly applied evaluation methods. The results show that League of Legends and Defense of the Ancients are the most studied games, with outcome prediction being the most popular research topic. Finally, we provide an analysis of the potential future flagship areas for research in the domain, considering the gaps found in the white and grey literature.","Costa, Lincoln Magalhães, Drachen, Anders, Souza, Francisco Carlos Monteiro, Xexéo, Geraldo",,,Artificial Intelligence in MOBA Games: A Multivocal Literature Mapping,,,10.1109/TG.2023.3282157 , ,,"Esports—games played competitively—comprise a major sector of the global games industry. Esports have been used as a testbed for game artificial intelligence (AI) and game analytics for two decades. This article presents a multivocal literature mapping of available research that focuses strictly on the use of artificial intelligence approaches in multiplayer online battle arena (MOBA) games, one of the most popular esports genres and the one most widely used for game AI and game analytics research. A mapping is performed on relevant publications published between 2011 and 2022 and systematically examines them to extract similarities, gaps, and main findings. We analyzed 124 publications to identify the most studied topics, the most commonly used techniques, and the most commonly applied evaluation methods. The results show that League of Legends and Defense of the Ancients are the most studied games, with outcome prediction being the most popular research topic. Finally, we provide an analysis of the potential future flagship areas for research in the domain, considering the gaps found in the white and grey literature.",,,,, ,  ,Games;Industries;Measurement;Machine learning;Databases;Systematics;Bibliographies;Artificial intelligence;literature mapping;machine learning;multiplayer online battle arena (MOBA),out_of_scope,
3132,"**Title**Nano-Theranostics With Plasmonic Nanobubbles

**Abstract**The multifunctionality of uniting diagnosis and treatment in one cell level theranostic procedure is the major promise and challenge of nanoparticle medicine. The efficacy, functionality, safety and precision of a nanoparticle medicine may be radically increased by replacing materials with preset stationary properties by non-stationary on-demand nanoevents with dynamically tunable diagnostic and therapeutic functions. This review describes such events, plasmonic nanobubbles, which are vapor nanobubbles threshold-activated around metal nanoparticles by a short laser pulse. Their transient nature delivers unprecedented multi-functionality and unites the diagnosis and therapy at cell level. Plasmonic nanobubble theranostics presents an entirely new platform for future medicine that brings established diagnostics and therapeutics to cell level.","Lukianova-Hleb, Ekaterina Y., Lapotko, Dmitri O.",,,Nano-Theranostics With Plasmonic Nanobubbles,,,10.1109/JSTQE.2013.2284431 , ,,"The multifunctionality of uniting diagnosis and treatment in one cell level theranostic procedure is the major promise and challenge of nanoparticle medicine. The efficacy, functionality, safety and precision of a nanoparticle medicine may be radically increased by replacing materials with preset stationary properties by non-stationary on-demand nanoevents with dynamically tunable diagnostic and therapeutic functions. This review describes such events, plasmonic nanobubbles, which are vapor nanobubbles threshold-activated around metal nanoparticles by a short laser pulse. Their transient nature delivers unprecedented multi-functionality and unites the diagnosis and therapy at cell level. Plasmonic nanobubble theranostics presents an entirely new platform for future medicine that brings established diagnostics and therapeutics to cell level.",,,,, ,  ,Gold;Nanoparticles;Optical scattering;Lasers;Nanobioscience;Optical pulses;Plasmons;Gold nanoparticle;laser;nanomedicine;theranostics;plasmonic nanobubble,out_of_scope,
3133,"**Title**Potential neuroprotective effect of commercial Bacopa monniera extract

**Abstract**Bacopa monniera, also referred as Brahmi is being widely used for enhancement of cognitive effect and memory development for centuries. To analyse the neuroprotective effect of commercial Bacopa monniera extract (BmE) on human neuroblastoma cell-line SH-SY5Y was treated with the free radical generate by hydrogen peroxide (H2O2). The concentration of H2O2 that caused 50% neuronal death (IC50) was determined. Therefore, cells were treated with different concentrations of BmE for 2 h before incubation with H2O2 for 24 h. In this study, neurotoxicity effect of BmE also being assessed formerly. MTS (3-(4,5-dimethylthiazol-2-yl)-5-(3-carboxymethoxyphenyl) 2-(4-sulfophenyl)-2H-tetrazolium) assay was employe d to analyse the cell viability. Results revealed that BmE was not harmful within the tested concentration range (100 ng/ml to 10 mg/ml). The finding also showed that BmE could protect neuron cells against toxicity induced by H2O2. These results suggests that BmE possesses potent neuroprotective activity and may be a potential neurodegenerative disease drug that is worthy of further study.","Zandar, Nor-Aainaa Md, Zain, Mazatulikhma Mat",,,Potential neuroprotective effect of commercial Bacopa monniera extract,,,10.1109/CSPA.2010.5545256 , ,,"Bacopa monniera, also referred as Brahmi is being widely used for enhancement of cognitive effect and memory development for centuries. To analyse the neuroprotective effect of commercial Bacopa monniera extract (BmE) on human neuroblastoma cell-line SH-SY5Y was treated with the free radical generate by hydrogen peroxide (H2O2). The concentration of H2O2 that caused 50% neuronal death (IC50) was determined. Therefore, cells were treated with different concentrations of BmE for 2 h before incubation with H2O2 for 24 h. In this study, neurotoxicity effect of BmE also being assessed formerly. MTS (3-(4,5-dimethylthiazol-2-yl)-5-(3-carboxymethoxyphenyl) 2-(4-sulfophenyl)-2H-tetrazolium) assay was employe d to analyse the cell viability. Results revealed that BmE was not harmful within the tested concentration range (100 ng/ml to 10 mg/ml). The finding also showed that BmE could protect neuron cells against toxicity induced by H2O2. These results suggests that BmE possesses potent neuroprotective activity and may be a potential neurodegenerative disease drug that is worthy of further study.",,,,, ,  2010 6th International Colloquium on Signal Processing & its Applications,Alzheimer's disease;Neurons;Parkinson's disease;Hydrogen;Drugs;Protection;Pathogens;Stress;Signal processing;Humans;Bacopa monniera extract (BmE);Neuroprotective effect;Hydroge peroxide;SH-SY5Y,out_of_scope,
3134,"**Title**Glyphosate Detection Through Piezoelectric and Fiber Optic Sensors Based on Molecular Imprinted Polymers

**Abstract**Glyphosate (N-(phosphonomethyl)glycine) is a popular broad-spectrum systemic herbicide commonly used to kill weeds and grasses that compete with crops. It is one of the most used herbicides worldwide that has been already detected in soils and groundwater. Its toxicity and persistence to humans and environment have been pointed out in literature. The detection and quantification of glyphosate or its degradation product (aminomethyl)phosphonic acid (AMPA) are thus an urgent need. In this article, we use molecularly imprinted polymers (MIPs) integrated with different sensing platforms for glyphosate detection. The platforms are based on a piezoelectric quartz crystal and on fiber optics. The assembled piezoelectric quartz crystal system allowed to rapidly characterize MIP binding to glyphosate, with sensitivity of 0.769 and 0.496 Hz/(mg/L) and good selectivity to several tested interferents (selectivity coefficients lower than 0.04 for AMPA and inorganic salts). Optical fiber systems, namely an optical fiber tip and a dip probe fiber bundle, were further developed and combined with a fluorescent MIP selective layer, allowing a proof of concept toward an in situ operational system for glyphosate detection. Fiber tip sensor displayed higher sensitivity to glyphosate compared to dip probe, 0.19 and 0.048 (mg/L) $^{-{1}}$ , respectively, but with linear behavior in different concentration ranges, up to 1 mg/L and between 2 and 7 mg/L, respectively. The developed sensing platforms allowed fast measurements directly in the solution, making them promising probes for practical deployment for environmental monitoring.","Sequeira, Filipa, Reis, Sílvia, Oliveira, Ricardo, Veríssimo, Marta I.S., Gomes, Maria Teresa S. R., Rudnitskaya, Alisa, Bilro, Lúcia",,,Glyphosate Detection Through Piezoelectric and Fiber Optic Sensors Based on Molecular Imprinted Polymers,,,10.1109/JSEN.2024.3395892 , ,,"Glyphosate (N-(phosphonomethyl)glycine) is a popular broad-spectrum systemic herbicide commonly used to kill weeds and grasses that compete with crops. It is one of the most used herbicides worldwide that has been already detected in soils and groundwater. Its toxicity and persistence to humans and environment have been pointed out in literature. The detection and quantification of glyphosate or its degradation product (aminomethyl)phosphonic acid (AMPA) are thus an urgent need. In this article, we use molecularly imprinted polymers (MIPs) integrated with different sensing platforms for glyphosate detection. The platforms are based on a piezoelectric quartz crystal and on fiber optics. The assembled piezoelectric quartz crystal system allowed to rapidly characterize MIP binding to glyphosate, with sensitivity of 0.769 and 0.496 Hz/(mg/L) and good selectivity to several tested interferents (selectivity coefficients lower than 0.04 for AMPA and inorganic salts). Optical fiber systems, namely an optical fiber tip and a dip probe fiber bundle, were further developed and combined with a fluorescent MIP selective layer, allowing a proof of concept toward an in situ operational system for glyphosate detection. Fiber tip sensor displayed higher sensitivity to glyphosate compared to dip probe, 0.19 and 0.048 (mg/L) $^{-{1}}$ , respectively, but with linear behavior in different concentration ranges, up to 1 mg/L and between 2 and 7 mg/L, respectively. The developed sensing platforms allowed fast measurements directly in the solution, making them promising probes for practical deployment for environmental monitoring.",,,,, ,  ,Sensors;Optical fibers;Optical fiber sensors;Sensitivity;Probes;Fluorescence;Piezoelectric devices;Fluorescence;glyphosate;molecularly imprinted polymer (MIP);optical fiber probe;optical fiber sensor;piezoelectric sensor,out_of_scope,
3135,"**Title**A Functional Programmable Polypeptide Nanofibers-Modified Optical Fiber SPR Biosensor for Specific Detection of Rabbit IgG

**Abstract**A polypeptide nanofibers (PNs)-modified optical fiber surface plasmon resonance (SPR) biosensor for specific detecting of rabbit IgG was proposed in this article. Based on the optical properties, biochemical properties, and programmable characteristics of PNs, the proposed SPR biosensor has the advantages of ease preparation, low toxicity, a large surface area, and high bio-sensitivity. In this study, the SPR biosensor was specifically developed to detect rabbit IgG. The bio-sensitivity of 1.36 nm/( $\mu \text{g}$ /mL) and limit of detection (LOD) $0.015 ~\mu \text{g}$ /mL are achieved experimentally. Compared with other single nanomaterial modified SPR biosensors, the developed biosensor has the higher bio-sensitivity and lower LOD. These findings indicate a significant improvement in the performance of PNs-modified biosensors. Furthermore, based on the programmable characteristics, the proposed sensor can be applied in various biosensing environments (such as nucleic acid, biological small molecules, glucose, etc.), providing customized solutions for diverse sensing needs. This significantly expands the potential applications of PNs-modified optical fiber SPR biosensors.","Cao, Guangxiao, Chang, Pengxiang, Zhang, Ailing, Liu, Fei, Pan, Honggang, Wang, Junfeng, Lin, Sihang, Yang, Tengfei, Zhang, Yongning",,,A Functional Programmable Polypeptide Nanofibers-Modified Optical Fiber SPR Biosensor for Specific Detection of Rabbit IgG,,,10.1109/JSEN.2024.3372427 , ,,"A polypeptide nanofibers (PNs)-modified optical fiber surface plasmon resonance (SPR) biosensor for specific detecting of rabbit IgG was proposed in this article. Based on the optical properties, biochemical properties, and programmable characteristics of PNs, the proposed SPR biosensor has the advantages of ease preparation, low toxicity, a large surface area, and high bio-sensitivity. In this study, the SPR biosensor was specifically developed to detect rabbit IgG. The bio-sensitivity of 1.36 nm/( $\mu \text{g}$ /mL) and limit of detection (LOD) $0.015 ~\mu \text{g}$ /mL are achieved experimentally. Compared with other single nanomaterial modified SPR biosensors, the developed biosensor has the higher bio-sensitivity and lower LOD. These findings indicate a significant improvement in the performance of PNs-modified biosensors. Furthermore, based on the programmable characteristics, the proposed sensor can be applied in various biosensing environments (such as nucleic acid, biological small molecules, glucose, etc.), providing customized solutions for diverse sensing needs. This significantly expands the potential applications of PNs-modified optical fiber SPR biosensors.",,,,, ,  ,Biosensors;Sensors;Optical fiber sensors;Nanobioscience;Optical fibers;Biomedical optical imaging;Optical device fabrication;Biosensor;immune reaction;optical fiber;polypeptide nanofibers (PNs);self-assembly;surface plasmon resonance (SPR),out_of_scope,
3136,"**Title**Borewell Accident Prevention System

**Abstract**The Internet Of Things has entered into the everyday functioning of countless number of industries. The applications include but are not limited to smart cities, smart grids, smart homes, physical security, e-health, asset management and logistics. In this paper, we have focused on implementing IOT in the prevention methodology of keeping people from becoming victims of falling in empty borewells, which might cause fatal injuries and subsequent death. The dawning of burgeoning industrial demand for the earth's natural resources like water, petrol, diesel and compressed natural which are available deep inside the earth's crust, require the earth's surface to be mechanically broken up and thrust into. This generates the need to delve into the earth's crust to produce deep underground hollows which can be referred to as borewells. After the exploitation of the earth's natural resources from under the ground, these borewells are often laid bare and exposed from the surface of the earth primarily due to negligence of the manufacturing industry authorities and the local government corporation maintenance services. The exposed holes on the earth's surface make people susceptible to falling into the deep wells which might cause fatal injuries or their eventual death. Even exposure to the toxicity of the earth's internal environment may cause unforeseen internal health damage. The prevention methodology provides a fully automated system that raises an alert in case of the proximity of any person with the borewell opening. We have discussed two prevention methods, one using an ultrasonic distance sensor and the other using a passive infrared sensor. The ultrasonic distance sensor uses the principle of echo with ultrasonic sound waves while the passive infrared sensor uses the change in intensity of infrared waves to determine the distance between the person and the borewell and thereby raise an alert.","Chowdhury, Shriya, Bhattacharjee, Sanjana, Gopisetti, Dolphy, Priya, Khushi",,,Borewell Accident Prevention System,,,10.1109/NEleX59773.2023.10420968 , ,,"The Internet Of Things has entered into the everyday functioning of countless number of industries. The applications include but are not limited to smart cities, smart grids, smart homes, physical security, e-health, asset management and logistics. In this paper, we have focused on implementing IOT in the prevention methodology of keeping people from becoming victims of falling in empty borewells, which might cause fatal injuries and subsequent death. The dawning of burgeoning industrial demand for the earth's natural resources like water, petrol, diesel and compressed natural which are available deep inside the earth's crust, require the earth's surface to be mechanically broken up and thrust into. This generates the need to delve into the earth's crust to produce deep underground hollows which can be referred to as borewells. After the exploitation of the earth's natural resources from under the ground, these borewells are often laid bare and exposed from the surface of the earth primarily due to negligence of the manufacturing industry authorities and the local government corporation maintenance services. The exposed holes on the earth's surface make people susceptible to falling into the deep wells which might cause fatal injuries or their eventual death. Even exposure to the toxicity of the earth's internal environment may cause unforeseen internal health damage. The prevention methodology provides a fully automated system that raises an alert in case of the proximity of any person with the borewell opening. We have discussed two prevention methods, one using an ultrasonic distance sensor and the other using a passive infrared sensor. The ultrasonic distance sensor uses the principle of echo with ultrasonic sound waves while the passive infrared sensor uses the change in intensity of infrared waves to determine the distance between the person and the borewell and thereby raise an alert.",,,,, ,  2023 International Conference on Next Generation Electronics (NEleX),Earth;Natural resources;Law enforcement;Infrared sensors;Acoustics;Injuries;Water resources;borewell;prevention;proximity;sensor;alert,out_of_scope,
3137,"**Title**On mission Twitter Profiles: A Study of Selective Toxic Behavior

**Abstract**The argument for persistent social media influence campaigns, often funded by malicious entities, is gaining traction. These entities utilize instrumented profiles to disseminate divisive content and disinformation, shaping public perception. Despite ample evidence of these instrumented profiles, few identification methods exist to locate them in the wild. To evade detection and appear genuine, small clusters of instrumented profiles engage in unrelated discussions, diverting attention from their true goals [34]. This strategic thematic diversity conceals their selective polarity towards certain topics and fosters public trust [49]. This study aims to characterize profiles potentially used for influence operations, termed “on-mission profiles,” relying solely on thematic content diversity within unlabeled data. Distinguishing this work is its focus on content volume and toxicity towards specific themes. Longitudinal data from 138K Twitter (rebranded as X) profiles and 293M tweets enables profiling based on theme diversity. High thematic diversity groups predominantly produce toxic content concerning specific themes, like politics, health, and news—classifying them as “on-mission” profiles. Using the identified on-mission” profiles, we design a classifier for unseen, unlabeled data. Employing a linear SVM model, we train and test it on an 80/20% split of the most diverse profiles. The classifier achieves a flawless 100% accuracy, facilitating the discovery of previously unknown “on-mission” profiles in the wild.","Qayyum, Hina, Ikram, Muhammad, Zhao, Benjamin Zi Hao, Wood, Ian D., Kourtellis, Nicolas, Kaafar, Mohamed Ali",,,On mission Twitter Profiles: A Study of Selective Toxic Behavior,,,10.1109/BigData59044.2023.10386248 , ,,"The argument for persistent social media influence campaigns, often funded by malicious entities, is gaining traction. These entities utilize instrumented profiles to disseminate divisive content and disinformation, shaping public perception. Despite ample evidence of these instrumented profiles, few identification methods exist to locate them in the wild. To evade detection and appear genuine, small clusters of instrumented profiles engage in unrelated discussions, diverting attention from their true goals [34]. This strategic thematic diversity conceals their selective polarity towards certain topics and fosters public trust [49]. This study aims to characterize profiles potentially used for influence operations, termed “on-mission profiles,” relying solely on thematic content diversity within unlabeled data. Distinguishing this work is its focus on content volume and toxicity towards specific themes. Longitudinal data from 138K Twitter (rebranded as X) profiles and 293M tweets enables profiling based on theme diversity. High thematic diversity groups predominantly produce toxic content concerning specific themes, like politics, health, and news—classifying them as “on-mission” profiles. Using the identified on-mission” profiles, we design a classifier for unseen, unlabeled data. Employing a linear SVM model, we train and test it on an 80/20% split of the most diverse profiles. The classifier achieves a flawless 100% accuracy, facilitating the discovery of previously unknown “on-mission” profiles in the wild.",,,,, ,  2023 IEEE International Conference on Big Data (BigData),Support vector machines;Toxicology;Social networking (online);Instruments;Blogs;Media;Real-time systems;On-mission profile on Twitter(X);Toxicity;misbehavior;thematic diversity in online content,detection,
3138,"**Title**Human like biosensor disease simulator, disease analyzer and drug delivery system

**Abstract**In a society, public health plays an important role in human life. There is no human being who is ideally healthy. Every family will have some ill health, sickness and a need exists for medication. In a locality a hospital is an essential establishment for the caretaking of the health of the people around. Every human being may have certain level of toxicity causing disturbance in normal function. The hospital must have a well drawn out procedure for maintenance of equipments serving as a reference for doctors, clinical laboratories and nurses with expertise and appropriate diagnosis and treatment procedures. There could be varieties of diseases in so many inpatients and outpatients that need attention. For any patient depending upon the disease by virtue of the symptoms, clinical test reports and history of the patient, a doctor with his knowledge base is to make a decision and prepare a diagnosis. Based on the diagnosis the treatment procedures are implemented by the nurses. This process is a much generalized methodology for any location wherever treatment is necessary for the patients. It is also observed that there is always a shortage of medical practitioners and expertise required for many diseases. Drug dosing is a technique that is done to cure the diseases through proper prescription and control of drugs that have been identified to the corresponding disease based on diagnosis. Drug dosing is a very critical and challenging step that needs to be correctly monitored and prescribed by the doctor. Drug dosing in human beings also depends upon size, area, weight and volume of the recipient. There are various ways of drug dosing, targeted therapies are the current state of the art and are probably the best predictor in terms of perceiving the dosing. Nanobio systems are used for targeted therapies. Food and Drug Administration (FDA) has recommended the use of nanobio systems for targeted therapy and drug dosing but they do not have many models. In reality very few exist. With limitations in availability of common platforms for development and validation of automated systems there is a need for a new methodology or integration of multiple platforms to integrate biosensors, expert system and drug diffusion unit. The Automatic drug delivery system is based on bio sensors which functions like a human. However the bio sensors are not under the purview of this project. To create a real time model, the sensors were simulated. Employing Servo motors connected to a voltage divider network simulated sensors. Eight voltage dividers were employed wherein, in each of the dividers; a fixed resistor & a potentiometer were used. The servo motor moves the wiper of pot and thus varies the voltage output on the ADC channel.","Eswaran, Ushaa, Eswaran, Vivek, Sudharshan, V. B.",,,"Human like biosensor disease simulator, disease analyzer and drug delivery system",,,10.1109/CICT.2013.6558250 , ,,"In a society, public health plays an important role in human life. There is no human being who is ideally healthy. Every family will have some ill health, sickness and a need exists for medication. In a locality a hospital is an essential establishment for the caretaking of the health of the people around. Every human being may have certain level of toxicity causing disturbance in normal function. The hospital must have a well drawn out procedure for maintenance of equipments serving as a reference for doctors, clinical laboratories and nurses with expertise and appropriate diagnosis and treatment procedures. There could be varieties of diseases in so many inpatients and outpatients that need attention. For any patient depending upon the disease by virtue of the symptoms, clinical test reports and history of the patient, a doctor with his knowledge base is to make a decision and prepare a diagnosis. Based on the diagnosis the treatment procedures are implemented by the nurses. This process is a much generalized methodology for any location wherever treatment is necessary for the patients. It is also observed that there is always a shortage of medical practitioners and expertise required for many diseases. Drug dosing is a technique that is done to cure the diseases through proper prescription and control of drugs that have been identified to the corresponding disease based on diagnosis. Drug dosing is a very critical and challenging step that needs to be correctly monitored and prescribed by the doctor. Drug dosing in human beings also depends upon size, area, weight and volume of the recipient. There are various ways of drug dosing, targeted therapies are the current state of the art and are probably the best predictor in terms of perceiving the dosing. Nanobio systems are used for targeted therapies. Food and Drug Administration (FDA) has recommended the use of nanobio systems for targeted therapy and drug dosing but they do not have many models. In reality very few exist. With limitations in availability of common platforms for development and validation of automated systems there is a need for a new methodology or integration of multiple platforms to integrate biosensors, expert system and drug diffusion unit. The Automatic drug delivery system is based on bio sensors which functions like a human. However the bio sensors are not under the purview of this project. To create a real time model, the sensors were simulated. Employing Servo motors connected to a voltage divider network simulated sensors. Eight voltage dividers were employed wherein, in each of the dividers; a fixed resistor & a potentiometer were used. The servo motor moves the wiper of pot and thus varies the voltage output on the ADC channel.",,,,, ,  2013 IEEE Conference on Information & Communication Technologies,Diseases;Drugs;Nanowires;Biosensors;Drug delivery;Servomotors;Nano wires;PSA;Biosensor;Biomarker;Antibodies,out_of_scope,
3139,"**Title**Federated Learning Support for Cybersecurity: Fundamentals, Applications, and Opportunities

**Abstract**The term “Federated Learning” (FL) refers to a modern and advanced intelligence system that uses data storage that is not centralised. Most industrialists are hesitant to use the Internet of Everything (IoT) technology since cyberattacks are common and occur in numerous real-time applications around the globe. To deal with this problem, FL can be used to prevent such cyberattacks by offering better cybersecurity. This research intends to fill in some of the gaps between where federated AI is now and where it can be widely used by doing a thorough investigation of FL’s security and privacy features. We provide an informative description of techniques and different implementation styles, while also examining the current difficulties in FL, and we establish a complete evaluation of security and privacy problems that must be taken into account. Our research shows that the privacy risks connected with FL are lower than the security risks. While inference-based attacks pose the greatest risk to FL’s privacy, transmission difficulties, toxicity, and backdoor breaches pose the greatest risk to security. In the final section of the paper, we outline key areas for future study that will help FL adapt to real-world settings.","Mohawesh, Rami, Maqsood, Sumbal, Jararweh, Yaser, Salameh, Haythem Bany",,,"Federated Learning Support for Cybersecurity: Fundamentals, Applications, and Opportunities",,,10.1109/ICCNS58795.2023.10193279 , ,,"The term “Federated Learning” (FL) refers to a modern and advanced intelligence system that uses data storage that is not centralised. Most industrialists are hesitant to use the Internet of Everything (IoT) technology since cyberattacks are common and occur in numerous real-time applications around the globe. To deal with this problem, FL can be used to prevent such cyberattacks by offering better cybersecurity. This research intends to fill in some of the gaps between where federated AI is now and where it can be widely used by doing a thorough investigation of FL’s security and privacy features. We provide an informative description of techniques and different implementation styles, while also examining the current difficulties in FL, and we establish a complete evaluation of security and privacy problems that must be taken into account. Our research shows that the privacy risks connected with FL are lower than the security risks. While inference-based attacks pose the greatest risk to FL’s privacy, transmission difficulties, toxicity, and backdoor breaches pose the greatest risk to security. In the final section of the paper, we outline key areas for future study that will help FL adapt to real-world settings.",,,,, ,"  2023 International Conference on Intelligent Computing, Communication, Networking and Services (ICCNS)",Privacy;Toxicology;Federated learning;Memory;Real-time systems;Internet of Things;Computer crime;cybersecurity;machine learning;federated learning,detection,
3140,"**Title**Exploring Traditional Chinese Medicine in Treating Gouty Arthritis: A Study of Drug Combination Patterns

**Abstract**Traditional Chinese Medicine (TCM) has been proved to have advantages on low-toxicity and can benefit decreasing uric acid for the treatment of gouty arthritis disease. However, there is a challenge to discover effective drug combinations from large amount drug usage due to complex drug variations in TCM prescriptions. To that end, this paper proposes a new weighted Apriori algorithm for association rule mining to discover drug combination patterns more accurately compared with conventional Apriori algorithm. In addition, this paper applies a Fast-Newman algorithm to explore and validate the usage patterns of TCM for the treatment of gouty arthritis through comparing a list of complex network algorithms. Experiment data is 315 actual outpatient medical records from the Guangdong Provincial Traditional Chinese Medicine Hospital, which is a top-ranked TCM hospital in China. According to the result by the weighted Apriori algorithm, the Chinese medicine Zexie and Tufuling are the most frequently used drug combination for the treatment of the disease. In the statistics of drug category, the medicinal properties are mainly cold, while the medicinal flavors are mainly bitter and sweet. According to the result by the Fast-Newman algorithm, four core communities of drug usage are identified, one of them suggesting that it is necessary to focus on the adverse emotions and sleep quality in the treatment of the disease. The experiment results provide therapeutic reference for clinical practice of TCM drug usage for the treatment of gouty arthritis disease.","Qiu, Weihan, Chen, Tao, Chen, Zifeng, Zhu, Fangjie, Chen, Wenying, Chen, Xiumin, Ou, Aihua, Wang, Maojie, Huang, Runyue",,,Exploring Traditional Chinese Medicine in Treating Gouty Arthritis: A Study of Drug Combination Patterns,,,10.1109/BESC64747.2024.10780665 , ,,"Traditional Chinese Medicine (TCM) has been proved to have advantages on low-toxicity and can benefit decreasing uric acid for the treatment of gouty arthritis disease. However, there is a challenge to discover effective drug combinations from large amount drug usage due to complex drug variations in TCM prescriptions. To that end, this paper proposes a new weighted Apriori algorithm for association rule mining to discover drug combination patterns more accurately compared with conventional Apriori algorithm. In addition, this paper applies a Fast-Newman algorithm to explore and validate the usage patterns of TCM for the treatment of gouty arthritis through comparing a list of complex network algorithms. Experiment data is 315 actual outpatient medical records from the Guangdong Provincial Traditional Chinese Medicine Hospital, which is a top-ranked TCM hospital in China. According to the result by the weighted Apriori algorithm, the Chinese medicine Zexie and Tufuling are the most frequently used drug combination for the treatment of the disease. In the statistics of drug category, the medicinal properties are mainly cold, while the medicinal flavors are mainly bitter and sweet. According to the result by the Fast-Newman algorithm, four core communities of drug usage are identified, one of them suggesting that it is necessary to focus on the adverse emotions and sleep quality in the treatment of the disease. The experiment results provide therapeutic reference for clinical practice of TCM drug usage for the treatment of gouty arthritis disease.",,,,, ,  2024 11th International Conference on Behavioural and Social Computing (BESC),Drugs;Social computing;Hospitals;Complex networks;Arthritis;Association rule learning;Gouty arthritis;Traditional Chinese Medicine;Weighted Apriori algorithm;Fast-Newman algorithm;Drug,out_of_scope,
3141,"**Title**Leveraging Deep Learning for Detecting Toxicity in Online Comments

**Abstract**Toxic comments are pervasive on online platforms, which makes it difficult to maintain positive dialogue and create a secure online space. People’s emotions and overall state of mental health start to seriously decline as a result of those toxic remarks. In this study, we examine how optimizers affect the training of three well-known RNN architectures for the toxic comment categorization task: LSTM, Bi-LSTM, and GRU. According to our research, the model’s performance is greatly influenced by the optimizer used; the Bi-LSTM model, which was trained using the ADAM optimizer, showed the greatest test accuracy of $\mathbf{9 5. 3 3 \%}$. Our results highlight the crucial role optimization techniques play in improving moderation systems’ effectiveness and advancing the creation of more potent mitigation strategies for online toxicity.","Rayani, Reddy Kowshik, Tekula, Samhitha, Vattigunta, Subhash Kovid, Kovi, Naveen Kumar, Namitha, Kalakunnath",,,Leveraging Deep Learning for Detecting Toxicity in Online Comments,,,10.1109/ICCCNT61001.2024.10726256 , ,,"Toxic comments are pervasive on online platforms, which makes it difficult to maintain positive dialogue and create a secure online space. People’s emotions and overall state of mental health start to seriously decline as a result of those toxic remarks. In this study, we examine how optimizers affect the training of three well-known RNN architectures for the toxic comment categorization task: LSTM, Bi-LSTM, and GRU. According to our research, the model’s performance is greatly influenced by the optimizer used; the Bi-LSTM model, which was trained using the ADAM optimizer, showed the greatest test accuracy of $\mathbf{9 5. 3 3 \%}$. Our results highlight the crucial role optimization techniques play in improving moderation systems’ effectiveness and advancing the creation of more potent mitigation strategies for online toxicity.",,,,, ,  2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),Training;Deep learning;Toxicology;Accuracy;Prevention and mitigation;Mental health;Computer architecture;Optimization;Long short term memory;Toxicity detection;LSTM;GRU;Filtration,detection,
3142,"**Title**Ultrasound median nerve localization by classification based on despeckle filtering and feature selection

**Abstract**Ultrasound-guided regional anaesthesia (UGRA) is growing rapidly in the medical field, and becomes a standard procedure in many worldwide hospitals. UGRA can specifically benefit from image processing and machine learning techniques. Very few studies have been developed for that purpose. This paper focuses on automatic localization of nerve in ultrasound images, in order to assist anaesthetists during UGRA procedure. Due to the complex structure of nerve and poor quality of ultrasound images, the automatic detection of nerve region is a challenging problem. To handle such issue, several processing phases are required. For that purpose, we propose a new method, based on despeckling, feature ranking and majority vote classification, for a robust and accurate median nerve localization. The proposed method is applied on a real dataset obtained from eight patients. The obtained results showed high performance for median nerve detection achieving accuracy of 89% of the f-score measure.","Hadjerci, Oussama, Hafiane, Adel, Conte, Donatello, Makris, Pascal, Vieyres, Pierre, Delbos, Alain",,,Ultrasound median nerve localization by classification based on despeckle filtering and feature selection,,,10.1109/ICIP.2015.7351588 , ,,"Ultrasound-guided regional anaesthesia (UGRA) is growing rapidly in the medical field, and becomes a standard procedure in many worldwide hospitals. UGRA can specifically benefit from image processing and machine learning techniques. Very few studies have been developed for that purpose. This paper focuses on automatic localization of nerve in ultrasound images, in order to assist anaesthetists during UGRA procedure. Due to the complex structure of nerve and poor quality of ultrasound images, the automatic detection of nerve region is a challenging problem. To handle such issue, several processing phases are required. For that purpose, we propose a new method, based on despeckling, feature ranking and majority vote classification, for a robust and accurate median nerve localization. The proposed method is applied on a real dataset obtained from eight patients. The obtained results showed high performance for median nerve detection achieving accuracy of 89% of the f-score measure.",,,,, ,  2015 IEEE International Conference on Image Processing (ICIP),Feature extraction;Ultrasonic imaging;Visualization;Support vector machines;Anesthesia;Image reconstruction;Epidermis;Despeckling filter;feature extraction;feature selection;supervised learning;nerve detection;regional anesthesia,out_of_scope,
3143,"**Title**A framework for detecting arsenic disease

**Abstract**Humans are exposed to arsenic (As) primarily from air, food and water. Anyone can develop arsenic toxicity as a result of arsenic exposure. Most of the reports of chronic as well as toxicity in human focus attention on skin manifestations because of its diagnostic specificity. A dermal manifestation such as hyperpigmentation is diagnostic of chronic arsenicosis. This paper focuses on designing and modelling a system that will collate Pigmented Skin Lesion (PSL), their analysis, corresponding observations and conclusions by medical experts using prototyping methodology. The system uses computational intelligence technique to analyse, process, and classify the image library data based on texture and morphological features of the images. A user in a remote location can use mobile data acquisition devices (such as smartphone) to generate images of PSL, supply such images as input to the proposed system, which in turns should intelligently be able to specify the arsenic poisoned hyperpigmentation status of the imaged PSL. The system has been evaluated with a set of images and found that the system can almost accurately detect arsenic.","Islam, Md. Ariful, Arefin, Mohammad Shamsul",,,A framework for detecting arsenic disease,,,10.1109/CEEICT.2016.7873149 , ,,"Humans are exposed to arsenic (As) primarily from air, food and water. Anyone can develop arsenic toxicity as a result of arsenic exposure. Most of the reports of chronic as well as toxicity in human focus attention on skin manifestations because of its diagnostic specificity. A dermal manifestation such as hyperpigmentation is diagnostic of chronic arsenicosis. This paper focuses on designing and modelling a system that will collate Pigmented Skin Lesion (PSL), their analysis, corresponding observations and conclusions by medical experts using prototyping methodology. The system uses computational intelligence technique to analyse, process, and classify the image library data based on texture and morphological features of the images. A user in a remote location can use mobile data acquisition devices (such as smartphone) to generate images of PSL, supply such images as input to the proposed system, which in turns should intelligently be able to specify the arsenic poisoned hyperpigmentation status of the imaged PSL. The system has been evaluated with a set of images and found that the system can almost accurately detect arsenic.",,,,, ,  2016 3rd International Conference on Electrical Engineering and Information Communication Technology (ICEEICT),Arsenic;Image color analysis;Lesions;Diseases;Skin;Image segmentation;Feature extraction;Arsenic disease;medical imaging;automated diagnosis;skin disease,out_of_scope,
3144,"**Title**Enhancing Inclusive Online Conversations with Multimodal AI for Contextual Toxicity Analysis, Automated Rephrasing, and Bias Detection

**Abstract**Online communities and discussion platforms provide a suitable stage to share ideas, opinions and thoughts. But they have also created space to increase negativity by posting toxic and nuance contents and comments, leading to division, chaos and fights. These contents are sometimes targeted on a certain group of people based on gender, caste, religion and countries, paving ways to the disrupting of world peace. Some of these contents are targeted against an individual and are threatening and harsh, which can be coined as cyber bullying. The proposed system is aimed to provide a multi-featured solution that encompasses real time data moderation with the help of ensemble of embedder modules like GloVe, Emo2Vec and BERT to produce both semantic and contextual embeddings accompanied by BERT encoder and classifier, rephrasing module to provide inclusive paraphrases for the toxic inputs while preserving the information and a reinforcement module for the system to increase its adaptivity. This novel combination of modules overcomes the limitations of existing system by increasing the usability, robustness and real time processing.","Ananthajothi, K, Meenakshi, R, Monica, S",,,"Enhancing Inclusive Online Conversations with Multimodal AI for Contextual Toxicity Analysis, Automated Rephrasing, and Bias Detection",,,10.1109/ICSES60034.2023.10465509 , ,,"Online communities and discussion platforms provide a suitable stage to share ideas, opinions and thoughts. But they have also created space to increase negativity by posting toxic and nuance contents and comments, leading to division, chaos and fights. These contents are sometimes targeted on a certain group of people based on gender, caste, religion and countries, paving ways to the disrupting of world peace. Some of these contents are targeted against an individual and are threatening and harsh, which can be coined as cyber bullying. The proposed system is aimed to provide a multi-featured solution that encompasses real time data moderation with the help of ensemble of embedder modules like GloVe, Emo2Vec and BERT to produce both semantic and contextual embeddings accompanied by BERT encoder and classifier, rephrasing module to provide inclusive paraphrases for the toxic inputs while preserving the information and a reinforcement module for the system to increase its adaptivity. This novel combination of modules overcomes the limitations of existing system by increasing the usability, robustness and real time processing.",,,,, ,"  2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)",Deep learning;Ethics;Toxicology;Semantics;Cyberbullying;Oral communication;Real-time systems;Cyber Bullying;Multi-Feature Solution;GloVe;Emo2Vec;BERT;rephrasing and reinforcement module,detection,
3145,"**Title**Evaluation of E-nose technology for detection of the causative bacteria in different culture media on diabetic foot infection

**Abstract**The three different culture media namely blood agar, Mueller Hinton and MacConkey were used in this study to identify and classify the causative bacteria on diabetic foot infection using electronic nose (E-nose). All the samples were taken from the clinical specimens using standard swabbing technique. E-nose consisting an array of 32 conducting polymer sensors was used to detect volatile organic compounds (VOCs) released by the bacteria in the infected areas. The VOC profiles of three bacterial groups from three genera namely Escherichia coli (ECOLI), Staphylococcus aureus (SAU) and Pseudomonas aeruginosa (PAE) were characterized using statistical classification technique called Linear Discriminant Analysis (LDA) to differentiate between different agars used with individual bacteria species which accounted for all the data. Although these methods are still fundamental, there is an increasing shift toward molecular diagnostics of bacteria. This investigation showed that the E-nose was able to correctly classify different bacterial species in all three culture media with up to 90% accuracy.","Yusuf, N., Omar, M. I., Zakaria, A., Jeffree, A. I., Thriumani, R., Abdullah, A. A., Shakaff, A. Y. M., Masnan, M. J., Yeap, E. J., Othman, A., Yasin, M. S.",,,Evaluation of E-nose technology for detection of the causative bacteria in different culture media on diabetic foot infection,,,10.1109/IECBES.2014.7047589 , ,,"The three different culture media namely blood agar, Mueller Hinton and MacConkey were used in this study to identify and classify the causative bacteria on diabetic foot infection using electronic nose (E-nose). All the samples were taken from the clinical specimens using standard swabbing technique. E-nose consisting an array of 32 conducting polymer sensors was used to detect volatile organic compounds (VOCs) released by the bacteria in the infected areas. The VOC profiles of three bacterial groups from three genera namely Escherichia coli (ECOLI), Staphylococcus aureus (SAU) and Pseudomonas aeruginosa (PAE) were characterized using statistical classification technique called Linear Discriminant Analysis (LDA) to differentiate between different agars used with individual bacteria species which accounted for all the data. Although these methods are still fundamental, there is an increasing shift toward molecular diagnostics of bacteria. This investigation showed that the E-nose was able to correctly classify different bacterial species in all three culture media with up to 90% accuracy.",,,,, ,  2014 IEEE Conference on Biomedical Engineering and Sciences (IECBES),Microorganisms;Diabetes;Media;Foot;Blood;Sensors;Electronic noses,out_of_scope,
3146,"**Title**An emergency monitoring about sudden water pollution accident in drinking water sources

**Abstract**This paper discusses some possible roles for emergency pollution accident in drinking water sources. Different procedures have been developed to measure the pollutants content of drinking water both in normal and in emergency situations, such as those arising from accidental and terrorist events. The authors analyze the primary factor of emergency pollution incident in drinking water sources and give general principles of emergency monitoring about emergency pollution incident. And according to different stage the paper gives a sequence about preferential control pollution; the test items were presented the choice to start the first level and second-level monitoring. The paper describes the procedures of emergency monitoring; these provide the rapid and full technical support to water security monitoring and offers reference for the corresponding reference monitor department.","Zhu, Yi-Chun, Tang, Min-Kang, Du, Mao-an",,,An emergency monitoring about sudden water pollution accident in drinking water sources,,,10.1109/ICEMMS.2010.5563493 , ,,"This paper discusses some possible roles for emergency pollution accident in drinking water sources. Different procedures have been developed to measure the pollutants content of drinking water both in normal and in emergency situations, such as those arising from accidental and terrorist events. The authors analyze the primary factor of emergency pollution incident in drinking water sources and give general principles of emergency monitoring about emergency pollution incident. And according to different stage the paper gives a sequence about preferential control pollution; the test items were presented the choice to start the first level and second-level monitoring. The paper describes the procedures of emergency monitoring; these provide the rapid and full technical support to water security monitoring and offers reference for the corresponding reference monitor department.",,,,, ,  2010 IEEE International Conference on Emergency Management and Management Sciences,Monitoring;Pollution measurement;Surface contamination;Water pollution;Gallium nitride;Nitrogen;drinking water sources;sudden pollution accident;emergency monitoring;emergency procedures,out_of_scope,
3147,"**Title**Simultaneous determination of N-acetylcysteine and acetaminophen by voltammetric method using N-(3,4-dihydroxyphenethyl)-3, 5 dinitrobenzamide modified multiwall carbon nanotube paste electrode nanostructured materials in advanced membrane technology for separation processes

**Abstract**Summary form only given. N-acetylcysteine (NAC) commonly known as acetylcysteine, is a pharmaceutical drug and nutritional supplement with numerous uses. Its primary use is as a mucolytic agent. The drug rapidly metabolizes to intracellular glutathione which acts as a powerful antioxidant in the body. Finally, it has been claimed to have a protective effect against cancer for its action as an antioxidant and a glutathione precursor. Acetaminaphen (AC) is widely used as an analgesic anti-pyretic drug with similar effects as aspirin. It is regarded as a suitable replacement for aspirin in patients sensitive to aspirin or those with asthma. Intravenous acetylcysteine is typically administered for the treatment of paracetamol (acetaminophen) overdose. Large quantities of paracetamol causes a minor metabolite called N-acetyl-p-benzoquinone imine (NAPQI) that accumulates in the body and is normally conjugated by glutathione. When taken in excess, the body's limited glutathione reserves fail to inactivate the toxic NAPQI. The metabolite thus produced is then free to react with key hepatic enzymes, damaging hepatocytes. This may lead to severe liver damage and even to death by fulminant liver failure. Due to this fatal effect, simultaneous determination of these compounds (NAC & AC) is very important. However, a major problem is that at bare electrodes, the anodic peak potentials for NAC and AC are almost the same, which results in their overlapped current responses and makes their discrimination very difficult. In this project, a new dopamine-derivative, i.e. N-(3,4-dihydroxyphenethyl)-3,5dinitrobenzamide (N-DHPB), was synthesized and its application was investigated for the simultaneous determination of NAC and acetaminophen (AC) using modified multiwall carbon nanotubes paste electrode. This modified electrode exhibited a potent and persistent electron mediating behavior followed by well separated oxidation peaks of NAC and AC. Differential pulse voltammetry (DPV) peak currents of NAC and AC increased linearly with their concentration in the ranges of 0.5-200 μmol L-1 and 15.0-270 μmol L-1 respectively. The detection limits for NAC and AC were 0.2 μmol L-1 and 10.0 μmol L-1 respectively. The relative standard deviation for seven successive assays of 1.0 and 30.0 μmol L-1 NAC and AC were 1.7% and 2.2%, respectively. The proposed sensor was successfully applied for the determination of NAC in human urine, tablet, and serum samples.","Ensafi, Ali A.",,,"Simultaneous determination of N-acetylcysteine and acetaminophen by voltammetric method using N-(3,4-dihydroxyphenethyl)-3, 5 dinitrobenzamide modified multiwall carbon nanotube paste electrode nanostructured materials in advanced membrane technology for separation processes",,,10.1109/ESCINANO.2010.5701083 , ,,"Summary form only given. N-acetylcysteine (NAC) commonly known as acetylcysteine, is a pharmaceutical drug and nutritional supplement with numerous uses. Its primary use is as a mucolytic agent. The drug rapidly metabolizes to intracellular glutathione which acts as a powerful antioxidant in the body. Finally, it has been claimed to have a protective effect against cancer for its action as an antioxidant and a glutathione precursor. Acetaminaphen (AC) is widely used as an analgesic anti-pyretic drug with similar effects as aspirin. It is regarded as a suitable replacement for aspirin in patients sensitive to aspirin or those with asthma. Intravenous acetylcysteine is typically administered for the treatment of paracetamol (acetaminophen) overdose. Large quantities of paracetamol causes a minor metabolite called N-acetyl-p-benzoquinone imine (NAPQI) that accumulates in the body and is normally conjugated by glutathione. When taken in excess, the body's limited glutathione reserves fail to inactivate the toxic NAPQI. The metabolite thus produced is then free to react with key hepatic enzymes, damaging hepatocytes. This may lead to severe liver damage and even to death by fulminant liver failure. Due to this fatal effect, simultaneous determination of these compounds (NAC & AC) is very important. However, a major problem is that at bare electrodes, the anodic peak potentials for NAC and AC are almost the same, which results in their overlapped current responses and makes their discrimination very difficult. In this project, a new dopamine-derivative, i.e. N-(3,4-dihydroxyphenethyl)-3,5dinitrobenzamide (N-DHPB), was synthesized and its application was investigated for the simultaneous determination of NAC and acetaminophen (AC) using modified multiwall carbon nanotubes paste electrode. This modified electrode exhibited a potent and persistent electron mediating behavior followed by well separated oxidation peaks of NAC and AC. Differential pulse voltammetry (DPV) peak currents of NAC and AC increased linearly with their concentration in the ranges of 0.5-200 μmol L-1 and 15.0-270 μmol L-1 respectively. The detection limits for NAC and AC were 0.2 μmol L-1 and 10.0 μmol L-1 respectively. The relative standard deviation for seven successive assays of 1.0 and 30.0 μmol L-1 NAC and AC were 1.7% and 2.2%, respectively. The proposed sensor was successfully applied for the determination of NAC in human urine, tablet, and serum samples.",,,,, ,  2010 International Conference on Enabling Science and Nanotechnology (ESciNano),Carbon nanotubes,out_of_scope,
3148,"**Title**High Detectivity and Stability Self-Powered UV Photodetector Based on the GaN/CsAg₂I₃ Microbelt Heterojunction

**Abstract**In recent years, the exceptional properties of lead halide perovskites have garnered significant attention in the field of optoelectronic devices. However, the instability and toxicity of lead severely hinder their prospective commercial development. Consequently, lead-free halide perovskites and their analogues are attracting increased attention. In this work, perovskite-like CsAg2I3 microbelts were prepared in situ on the GaN substrate via a space-confined method. Furthermore, a heterojunction of CsAg2I3/GaN was fabricated and employed in the self-powered ultraviolet (UV) photodetectors (PDs) by capitalizing on its excellent band matching and wide bandgap. The presence of a built-in electric field in the heterojunction significantly suppresses the dark current, which results in a remarkably high photo-to-dark current ratio (PDCR) of approximately 3700. The low dark current additionally contributes to the reduction of shot noise, thereby enabling the detectivity of the device to reach $10^{{12}}$ Jones. Moreover, the device possesses decent stability to UV light. These results indicate the potential application of this PD in the field of stability detection for weak UV light.","Wang, Xin, Gui, Pengbin, Wei, Xinjian, Wang, Zhouying, Hu, Tianye, Yang, Liangpan, Wang, Siliang, Huang, Zhixiang",,,High Detectivity and Stability Self-Powered UV Photodetector Based on the GaN/CsAg₂I₃ Microbelt Heterojunction,,,10.1109/LED.2024.3411067 , ,,"In recent years, the exceptional properties of lead halide perovskites have garnered significant attention in the field of optoelectronic devices. However, the instability and toxicity of lead severely hinder their prospective commercial development. Consequently, lead-free halide perovskites and their analogues are attracting increased attention. In this work, perovskite-like CsAg2I3 microbelts were prepared in situ on the GaN substrate via a space-confined method. Furthermore, a heterojunction of CsAg2I3/GaN was fabricated and employed in the self-powered ultraviolet (UV) photodetectors (PDs) by capitalizing on its excellent band matching and wide bandgap. The presence of a built-in electric field in the heterojunction significantly suppresses the dark current, which results in a remarkably high photo-to-dark current ratio (PDCR) of approximately 3700. The low dark current additionally contributes to the reduction of shot noise, thereby enabling the detectivity of the device to reach $10^{{12}}$ Jones. Moreover, the device possesses decent stability to UV light. These results indicate the potential application of this PD in the field of stability detection for weak UV light.",,,,, ,  ,Dark current;Heterojunctions;Substrates;Silicon;Photonic band gap;Photodetectors;Cesium;Gallium nitride;CsAg₂I₃ microbelt;ultraviolet photodetector;heterojunction;self-powered;high photo-to-dark current ratio,out_of_scope,
3149,"**Title**Application of Mixture Designs for Detection and Characterization of Multi-Drug Synergism

**Abstract**Detection and characterization of synergism are critical focus in multi-drug interplay. To assess combined drug action, the classical methods such as isobologram and interaction index are still simple and sometimes unable to describe complex drug interaction adequately. Statistical-model based methods are found more flexible and informative in detecting and characterizing complex drug interactions, which require well- designed experiments. In this study, a kind of experimental designs, called mixture designs, is proposed for the detection and characterization of multi-drug synergism and optimization. Compared with other statistical-model based methods, mixture designs are demonstrated to be more useful when the total dose of the drugs under investigation is to be controlled in a moderate level. A case study of inhibition effect of three bioactive chemical compounds identified from an anti-angiogenesis traditional Chinese medicine on human umbilical vein endothelial cells is shown as an illustration to demonstrate the application of mixture designs in multi-drug combination discovery.","Lu, Xuan, Huang, Yanfang, Zhang, Bo, Li, Shao",,,Application of Mixture Designs for Detection and Characterization of Multi-Drug Synergism,,,10.1109/ICBBE.2007.108 , ,,"Detection and characterization of synergism are critical focus in multi-drug interplay. To assess combined drug action, the classical methods such as isobologram and interaction index are still simple and sometimes unable to describe complex drug interaction adequately. Statistical-model based methods are found more flexible and informative in detecting and characterizing complex drug interactions, which require well- designed experiments. In this study, a kind of experimental designs, called mixture designs, is proposed for the detection and characterization of multi-drug synergism and optimization. Compared with other statistical-model based methods, mixture designs are demonstrated to be more useful when the total dose of the drugs under investigation is to be controlled in a moderate level. A case study of inhibition effect of three bioactive chemical compounds identified from an anti-angiogenesis traditional Chinese medicine on human umbilical vein endothelial cells is shown as an illustration to demonstrate the application of mixture designs in multi-drug combination discovery.",,,,, ,  2007 1st International Conference on Bioinformatics and Biomedical Engineering,Drugs;Design for experiments;Design optimization;Design methodology;Chemical compounds;Humans;Veins;Bioinformatics;Design automation;Statistical analysis,out_of_scope,
3150,"**Title**Radiomics-Based Reliable Predictions of Side Effects After Radiotherapy for Prostate Cancer

**Abstract**This work offers insight into the effectiveness of probabilistic models, specifically those based on ensemble approximations, in predicting adverse side effects following radiotherapy for prostate cancer. We trained a random forest model on radiomic features from 134 T2-weighted Magnetic Resonance (MRI) images of the prostate gland to identify patients experiencing acute or chronic rectal and urinary toxicity (AU-ROC ranging from 61.4% for endorectal coil acquisitions to 70.8% for the full dataset). We evaluated the reliability of the predictions using an ensemble approximation of simplified random forests obtained by an adaptive procedure of random subsampling of the training data. We used this reliability score to define a not-confident class and then recompute performance metrics more in accordance with a probabilistic approach. The outcomes we obtained (up to 7.9% increase in accuracy) indicate the approximated probabilistic models pledge more reliable predictions, thus being suitable for further investigation.","Del Corso, Giulio, Pachetti, Eva, Buongiorno, Rossana, Rodrigues, Ana Carolina, Germanese, Danila, Pascali, M. Antonietta, Almeida, José, Rodrigues, Nuno, Tsiknakis, Manolis, Papanikolaou, Nickolas, Regge, Daniele, Marias, Kostas, Consortium, ProCAncer-I, Colantonio, Sara",,,Radiomics-Based Reliable Predictions of Side Effects After Radiotherapy for Prostate Cancer,,,10.1109/ISBI56570.2024.10635233 , ,,"This work offers insight into the effectiveness of probabilistic models, specifically those based on ensemble approximations, in predicting adverse side effects following radiotherapy for prostate cancer. We trained a random forest model on radiomic features from 134 T2-weighted Magnetic Resonance (MRI) images of the prostate gland to identify patients experiencing acute or chronic rectal and urinary toxicity (AU-ROC ranging from 61.4% for endorectal coil acquisitions to 70.8% for the full dataset). We evaluated the reliability of the predictions using an ensemble approximation of simplified random forests obtained by an adaptive procedure of random subsampling of the training data. We used this reliability score to define a not-confident class and then recompute performance metrics more in accordance with a probabilistic approach. The outcomes we obtained (up to 7.9% increase in accuracy) indicate the approximated probabilistic models pledge more reliable predictions, thus being suitable for further investigation.",,,,, ,  2024 IEEE International Symposium on Biomedical Imaging (ISBI),Toxicology;Magnetic resonance imaging;Training data;Predictive models;Probabilistic logic;Radiation therapy;Reliability;Machine Learning for Image Analysis;Radiomics;Prostate Cancer;Trustworthiness;Reliability,out_of_scope,
3151,"**Title**Utilization of Chitosan-Based Sensor Thin Films for the Detection of Lead Ion by Surface Plasmon Resonance Optical Sensor

**Abstract**Chitosan-based sensor thin films were fabricated to detect trace amounts of lead ion using surface plasmon resonance (SPR) optical sensor. The gold surface used for SPR measure- ments was modified with chitosan and chitosan-tert-butylcalix[4]arene-tetrakis(N,N-dimethylthioacetamide) (chitosan-BCAT). Both chitosan and chitosan-BCAT layers were deposited on the gold surface by spin coating technique. The experiment has been carried out to monitor the SPR signals for lead ion with sensitive enhancement by chitosan and chitosan-BCAT layers. For both layers, the change in resonance angle (Δθ) is directly proportional to the concentration of lead ion solution. The higher amounts of Δθ were obtained for chitosan-BCAT film due to a specific binding of BCAT with lead ion. The chitosan-BCAT film enhanced the sensitivity of detection down to 0.03 ppm. Data analysis also has been done by Matlab software using Fresnel formula for multilayer system.","Fen, Yap Wing, Yunus, W. Mahmood Mat",,,Utilization of Chitosan-Based Sensor Thin Films for the Detection of Lead Ion by Surface Plasmon Resonance Optical Sensor,,,10.1109/JSEN.2012.2235311 , ,,"Chitosan-based sensor thin films were fabricated to detect trace amounts of lead ion using surface plasmon resonance (SPR) optical sensor. The gold surface used for SPR measure- ments was modified with chitosan and chitosan-tert-butylcalix[4]arene-tetrakis(N,N-dimethylthioacetamide) (chitosan-BCAT). Both chitosan and chitosan-BCAT layers were deposited on the gold surface by spin coating technique. The experiment has been carried out to monitor the SPR signals for lead ion with sensitive enhancement by chitosan and chitosan-BCAT layers. For both layers, the change in resonance angle (Δθ) is directly proportional to the concentration of lead ion solution. The higher amounts of Δθ were obtained for chitosan-BCAT film due to a specific binding of BCAT with lead ion. The chitosan-BCAT film enhanced the sensitivity of detection down to 0.03 ppm. Data analysis also has been done by Matlab software using Fresnel formula for multilayer system.",,,,, ,  ,"Films;Gold;Sensitivity;Plasmons;Ions;Optical sensors;Chitosan;lead ion;surface plasmon resonance;tert-butylcalix[4]arene-tetrakis(N, n-dimethylthio- acetamide) (BCAT)",out_of_scope,
3152,"**Title**Bengali Cyberbullying Text Detection: A Comprehensive Study

**Abstract**Cyberbullying is a serious online problem that involves harassment and harm via digital communication systems. It can have serious effects on people’s mental health and well-being. This research aims to address cyberbullying in Bengali, a low-resource language that has gotten little attention. Previous machine learning approaches for Bengali cyberbullying detection relied on feature extraction techniques that failed to accurately capture word meanings. To address this restriction, this study suggests using word embedding, which portrays words as multidimensional vectors that capture their semantic interactions. The research will compare several machine learning algorithms and feature extraction techniques in order to give a thorough analysis of their accuracy and performance measures. This study intends to contribute to the development of a sophisticated cyberbullying detection model for Bengali. The results demonstrate that one of the ensemble-based models outperforms individual models, achieving a higher accuracy of 0.796, recall of 0.796, and precision of 0.804. The findings of this study promise to make a substantial contribution against cyberbullying in Bengali. This study aims to establish the framework for future breakthroughs in the field of linguistic cybersecurity through its insightful results and methodological approach.","Hamza, Golam Ibna, Muthaki, Tahsina, Masuk, Safwan Ibne, Mushfiqur Rahman, Mohammad, Saha Joy, Sajib Kumar, Muhammad Shah, Faisal",,,Bengali Cyberbullying Text Detection: A Comprehensive Study,,,10.1109/ICCIT60459.2023.10441141 , ,,"Cyberbullying is a serious online problem that involves harassment and harm via digital communication systems. It can have serious effects on people’s mental health and well-being. This research aims to address cyberbullying in Bengali, a low-resource language that has gotten little attention. Previous machine learning approaches for Bengali cyberbullying detection relied on feature extraction techniques that failed to accurately capture word meanings. To address this restriction, this study suggests using word embedding, which portrays words as multidimensional vectors that capture their semantic interactions. The research will compare several machine learning algorithms and feature extraction techniques in order to give a thorough analysis of their accuracy and performance measures. This study intends to contribute to the development of a sophisticated cyberbullying detection model for Bengali. The results demonstrate that one of the ensemble-based models outperforms individual models, achieving a higher accuracy of 0.796, recall of 0.796, and precision of 0.804. The findings of this study promise to make a substantial contribution against cyberbullying in Bengali. This study aims to establish the framework for future breakthroughs in the field of linguistic cybersecurity through its insightful results and methodological approach.",,,,, ,  2023 26th International Conference on Computer and Information Technology (ICCIT),Deep learning;Analytical models;Computational modeling;Cyberbullying;Transformers;Feature extraction;Vectors;cyberbullying;toxicity;Bengali,out_but_toxicity,
3153,"**Title**Detect the Unseen: An Expandable Detection Model for Stem Cell Images

**Abstract**Stem cell culture in vitro is essential for research in cell biology, drug toxicity and translational studies. In recent years, there has been a surge in the development of deep learning-based object detection algorithms tailored for image analysis of stem cell culture. However, many of these algorithms fall short in terms of performance and interpretability. To address these challenges, we present StemCellDet, an innovative multimodal-based method for stem cell detection. By harnessing the power of the pretrained CLIP model, StemCellDet uniquely encodes descriptions of stem cell categories into text embeddings, which are then synchronized with image embeddings. This synchronization enhances the model’s ability to identify critical features for accurate stem cell model categorization. Furthermore, by integrating knowledge distillation and introducing our proposed Semantic Fusion Module (SFM), StemCellDet can adeptly identify stem cell culture categories that were not present during its training phase using only their textual descriptions. Our experiments highlight StemCellDet’s robust detection capabilities and its advantages in terms of accuracy and generalizability.","Li, Hao, Lin, Yating, Chen, Ying, Lin, Sijie, Huang, Zhibin, Yang, Wenxian, Li, Wei, Yu, Rongshan",,,Detect the Unseen: An Expandable Detection Model for Stem Cell Images,,,10.1109/BIBM58861.2023.10385979 , ,,"Stem cell culture in vitro is essential for research in cell biology, drug toxicity and translational studies. In recent years, there has been a surge in the development of deep learning-based object detection algorithms tailored for image analysis of stem cell culture. However, many of these algorithms fall short in terms of performance and interpretability. To address these challenges, we present StemCellDet, an innovative multimodal-based method for stem cell detection. By harnessing the power of the pretrained CLIP model, StemCellDet uniquely encodes descriptions of stem cell categories into text embeddings, which are then synchronized with image embeddings. This synchronization enhances the model’s ability to identify critical features for accurate stem cell model categorization. Furthermore, by integrating knowledge distillation and introducing our proposed Semantic Fusion Module (SFM), StemCellDet can adeptly identify stem cell culture categories that were not present during its training phase using only their textual descriptions. Our experiments highlight StemCellDet’s robust detection capabilities and its advantages in terms of accuracy and generalizability.",,,,, ,  2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Training;Deep learning;Vocabulary;Toxicology;Stem cells;Data models;Synchronization;Stem Cell Image;Object Detection;Multimodal;CLIP;Generalization,out_of_scope,
3154,"**Title**Gold nanoparticle decorated AAO filter membrane for SERS sensing of urine acetaminophen

**Abstract**Acetaminophen overdose is linked to more emergency room visits than any other drug. Current standard procedure to detect overdoses rely on serum immunoassays, which provides sensitive detection, but are labor-and time-intensive. We present a surface-enhanced Raman scattering filter sensor for label-free detection of acetaminophen concentrations down to 10 μM in 5 mL urine within 5 minutes. The sensor was created by forming gold nanoparticles on an anodic aluminum oxide filter. The sensor was demonstrated to be reusable after simple cleaning procedures, and provides a potential application for point-of-care diagnosis with Raman detection.","Sung, Yu-Lung, Zhao, Fusheng, Li, Jingting, Shih, Wei-Chuan",,,Gold nanoparticle decorated AAO filter membrane for SERS sensing of urine acetaminophen,,,10.1109/ICSENS.2016.7808622 , ,,"Acetaminophen overdose is linked to more emergency room visits than any other drug. Current standard procedure to detect overdoses rely on serum immunoassays, which provides sensitive detection, but are labor-and time-intensive. We present a surface-enhanced Raman scattering filter sensor for label-free detection of acetaminophen concentrations down to 10 μM in 5 mL urine within 5 minutes. The sensor was created by forming gold nanoparticles on an anodic aluminum oxide filter. The sensor was demonstrated to be reusable after simple cleaning procedures, and provides a potential application for point-of-care diagnosis with Raman detection.",,,,, ,  2016 IEEE SENSORS,Raman scattering;Gold;Cleaning;Sensitivity;Surface treatment;Surface morphology;Drugs;acetaminophen;APAP;anodized aluminum oxide;filter;Raman spectroscopy;Surface-enhanced Raman scattering,out_of_scope,
3155,"**Title**DNA/AuNP-graphene back-gated field effect transistor as a biosensor for lead (II) ion detection

**Abstract**Lead is a very toxic substance that causes metabolic disruption by mimicking the chemical profile of other important ions in the human body. The current technique of determining the presence of lead in drinkable water are simply too expensive to be implemented for large-scale real time monitoring. As an alternative, a sensor based on graphene field effect transistor is developed. The graphene layer itself is decorated with gold nanoparticle (AuNP) and it acts as a sensing medium while guanine-rich deoxyribonucleic acid (DNA) that is attached to the AuNP acts as a chemical probe. The guanine-rich DNA forms G-quadruplex when exposed to lead ions and thus changes the overall charge on the surface of the graphene. The changes can be observed via I-V measurement of the sensor. The fabricated sensors are capable of detecting lead ions even at 20 nM concentration. Such a sensor is scalable and can offer a cheap and effective option for monitoring the quality of water in real-time.","Chee, Ling Hoe, Kumar, Pradeep, Kang, Chun Hong, Burhanudin, Zainal A.",,,DNA/AuNP-graphene back-gated field effect transistor as a biosensor for lead (II) ion detection,,,10.1109/RSM.2017.8069165 , ,,"Lead is a very toxic substance that causes metabolic disruption by mimicking the chemical profile of other important ions in the human body. The current technique of determining the presence of lead in drinkable water are simply too expensive to be implemented for large-scale real time monitoring. As an alternative, a sensor based on graphene field effect transistor is developed. The graphene layer itself is decorated with gold nanoparticle (AuNP) and it acts as a sensing medium while guanine-rich deoxyribonucleic acid (DNA) that is attached to the AuNP acts as a chemical probe. The guanine-rich DNA forms G-quadruplex when exposed to lead ions and thus changes the overall charge on the surface of the graphene. The changes can be observed via I-V measurement of the sensor. The fabricated sensors are capable of detecting lead ions even at 20 nM concentration. Such a sensor is scalable and can offer a cheap and effective option for monitoring the quality of water in real-time.",,,,, ,  2017 IEEE Regional Symposium on Micro and Nanoelectronics (RSM),DNA;Graphene;Lead;Ions;Field effect transistors;Chemicals;lead;DNA;AuNP;Graphene FET;G-quadruplex,out_of_scope,
3156,"**Title**A love wave biosensor with a phononic wave guiding layer for VEGF detection in selective platelet activation

**Abstract**A Love wave sensor with a phononic parylene-C wave guiding layer is proposed to detect the VEGF secreted during the selective platelet activation process, where arrays of a different material (filling material) are fabricated in the parylene-C films. The effects of the structural design parameters (period width and period number) on the electric response of sensors are investigated. As the period width is increasing, the resonance frequencies are shifted, and the insertion losses are changed accordingly; however, along with the period number varies, there is no obvious change in the sensor response. The numerical results from finite element method (FEM) illustrate that with specific period width the acoustic waves at the vicinity of resonance frequency could be enhanced through the phononic sensing area of Love wave sensor, when signals of other frequencies are attenuated. The results indicate a potential Love wave sensor with high sensitivity and reliability in the cell biology applications.","Wu, Huiyan, Zu, Hongfei, Wang, Qing-Ming, Wang, James H.C.",,,A love wave biosensor with a phononic wave guiding layer for VEGF detection in selective platelet activation,,,10.1109/ULTSYM.2017.8092842 , ,,"A Love wave sensor with a phononic parylene-C wave guiding layer is proposed to detect the VEGF secreted during the selective platelet activation process, where arrays of a different material (filling material) are fabricated in the parylene-C films. The effects of the structural design parameters (period width and period number) on the electric response of sensors are investigated. As the period width is increasing, the resonance frequencies are shifted, and the insertion losses are changed accordingly; however, along with the period number varies, there is no obvious change in the sensor response. The numerical results from finite element method (FEM) illustrate that with specific period width the acoustic waves at the vicinity of resonance frequency could be enhanced through the phononic sensing area of Love wave sensor, when signals of other frequencies are attenuated. The results indicate a potential Love wave sensor with high sensitivity and reliability in the cell biology applications.",,,,, ,  2017 IEEE International Ultrasonics Symposium (IUS),Resonant frequency;Insertion loss;Finite element analysis;Biosensors;Sensitivity;Surface acoustic waves;Love Wave;Phononic Wave Guiding Layer,out_of_scope,
3157,"**Title**Manganese-enhanced MRI detected the gray matter lesions in the late phase of mild hypoxic-ischemic injury in neonatal rat

**Abstract**This study aims to use manganese-enhanced MRI (MEMRI) to investigate the progression and permanence of the gray matter injuries in a neonatal rat model by mild hypoxic-ischemia (H-I) insult. Histological analyses were performed using staining for Mn superoxide dismutase (Mn-SOD) and glutamine synthetase (GS), which are Mn-binding enzymes against oxidative stress and glutamate excitotoxicity in neurodegeneration, and the standard hematoxylin and eosin (H&E). The transient changes associated with gray matter injuries in T2-weighted image (T2WI) and diffusion weighted image (DWI) in acute phase were shown to be detectable using MEMRI in late phase by systemic Mn2+ administration, correlating with the local cell death, GS and Mn-SOD increase. Therefore, MEMRI may be a potentially useful diagnostic paradigm for detecting the gray matter injuries that are otherwise undetectable using the current MRI techniques in late phase of mild H-I injury.","Yang, Jian, Wu, Ed X.",,,Manganese-enhanced MRI detected the gray matter lesions in the late phase of mild hypoxic-ischemic injury in neonatal rat,,,10.1109/IEMBS.2007.4352220 , ,,"This study aims to use manganese-enhanced MRI (MEMRI) to investigate the progression and permanence of the gray matter injuries in a neonatal rat model by mild hypoxic-ischemia (H-I) insult. Histological analyses were performed using staining for Mn superoxide dismutase (Mn-SOD) and glutamine synthetase (GS), which are Mn-binding enzymes against oxidative stress and glutamate excitotoxicity in neurodegeneration, and the standard hematoxylin and eosin (H&E). The transient changes associated with gray matter injuries in T2-weighted image (T2WI) and diffusion weighted image (DWI) in acute phase were shown to be detectable using MEMRI in late phase by systemic Mn2+ administration, correlating with the local cell death, GS and Mn-SOD increase. Therefore, MEMRI may be a potentially useful diagnostic paradigm for detecting the gray matter injuries that are otherwise undetectable using the current MRI techniques in late phase of mild H-I injury.",,,,, ,  2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,Magnetic resonance imaging;Phase detection;Lesions;Injuries;Pediatrics;Manganese;Stress;Biochemistry;Amino acids;Frequency,out_of_scope,
3158,"**Title**Electrochemical detection of arsenic via a microfluidic sensor and mobile interface towards affordable, rapid, and point-of-use water monitoring

**Abstract**Arsenic contamination of groundwater presents a major obstacle to the development of water infrastructure in developing countries, with severe long-term health consequences. Current solutions for arsenic testing range from simple colorimetric assays to sophisticated laboratory tests. Colorimetric kits are simple and low-cost, yet these types of tests generally suffer from a lack of precision and use toxic chemicals as test reagents while laboratory-based techniques, such as mass spectrometry, are accurate but considerably more expensive, requiring off-site analysis of samples. Electrochemical detection in a microfluidic platform offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. Toward a solution to water quality interventions, we have demonstrated an electrochemical sensor combined with mobile interface that detects arsenic suitable for rapid, affordable, and point-of-care water monitoring. Using this platform, we successfully demonstrate the detection of arsenic and the automatic interpretation and mapping of the detection results via a mobile application. We expect such a platform for diagnostics via mobile phone with automated test interpretation and mapping to provide an indispensable tool, especially in rural areas where the needs are the greatest, but the lack of laboratory facilities and trained personnel is a real obstacle.","Kim, Unyoung, Demaree, Benjamin, VanderGiessen, Jessica, Reynolds, Mary, Perricone, Kyle, Seubert, John, Elahi, Zuhayr, Gandhi, Sonny, Krishnan, Shoba, Figueira, Silvia",,,"Electrochemical detection of arsenic via a microfluidic sensor and mobile interface towards affordable, rapid, and point-of-use water monitoring",,,10.1109/HealthCom.2013.6720742 , ,,"Arsenic contamination of groundwater presents a major obstacle to the development of water infrastructure in developing countries, with severe long-term health consequences. Current solutions for arsenic testing range from simple colorimetric assays to sophisticated laboratory tests. Colorimetric kits are simple and low-cost, yet these types of tests generally suffer from a lack of precision and use toxic chemicals as test reagents while laboratory-based techniques, such as mass spectrometry, are accurate but considerably more expensive, requiring off-site analysis of samples. Electrochemical detection in a microfluidic platform offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. Toward a solution to water quality interventions, we have demonstrated an electrochemical sensor combined with mobile interface that detects arsenic suitable for rapid, affordable, and point-of-care water monitoring. Using this platform, we successfully demonstrate the detection of arsenic and the automatic interpretation and mapping of the detection results via a mobile application. We expect such a platform for diagnostics via mobile phone with automated test interpretation and mapping to provide an indispensable tool, especially in rural areas where the needs are the greatest, but the lack of laboratory facilities and trained personnel is a real obstacle.",,,,, ,"  2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)",Electrodes;Water pollution;Mobile communication;Water resources;Ink;Silver;Pollution measurement;biosensors;electrochemical devices;biomedical telemetry;mobile computing;cellular phones,out_of_scope,
3159,"**Title**Confronting Hate Speech in SMART Environments: An Approach that Uses Ensemble Learning and LSTM

**Abstract**In the current digital age of the Internet and online virtualization, it has established different kinds of online media, such as social media: two important and most pervasive ways of communicating. However, it becomes a little hard for them to deal with the responsibility, i.e., to regulate and filter the toxic or harmful content across the platform, specifically in filtering out the offensive comments posted by the users. In this work, we are particularly interested in the main mission of hate comment detection. Our major objective is to flag those comments which are offensive, harmful, and abusive in an online conversation. This paper proposes an original ensembling based learning scheme, taking the power of LSTM neural networks, to solve this crucial problem. LSTMs, specially designed types of RNNs, have shown to be effective in sequence modeling and also demonstrated some promising results in problems related to sequences. Our methodology is based on the existence of certain LSTM models of small size, which are trained on an independent fraction of all completed and pre-processed data. This approach allows the ensemble to capture the diversity in patterns; hence, it contributes to the large robustness of hate comment detection. In an ever-globalized and digitized world, the advent of dependable methodologies for hate comment detection becomes cardinal in acquiring safe and inclusive online environments. Our research is a promising step towards reducing online toxicity in order to have healthier and more constructive digital conversations.","Kaushik, Priyanka, Rohilla, Rohit, Walia, Pravansh, Shankar, Saksham, Kaushik, Manas M., Gupta, Tarushi Sandeep",,,Confronting Hate Speech in SMART Environments: An Approach that Uses Ensemble Learning and LSTM,,,10.1109/ICSD60021.2024.10751441 , ,,"In the current digital age of the Internet and online virtualization, it has established different kinds of online media, such as social media: two important and most pervasive ways of communicating. However, it becomes a little hard for them to deal with the responsibility, i.e., to regulate and filter the toxic or harmful content across the platform, specifically in filtering out the offensive comments posted by the users. In this work, we are particularly interested in the main mission of hate comment detection. Our major objective is to flag those comments which are offensive, harmful, and abusive in an online conversation. This paper proposes an original ensembling based learning scheme, taking the power of LSTM neural networks, to solve this crucial problem. LSTMs, specially designed types of RNNs, have shown to be effective in sequence modeling and also demonstrated some promising results in problems related to sequences. Our methodology is based on the existence of certain LSTM models of small size, which are trained on an independent fraction of all completed and pre-processed data. This approach allows the ensemble to capture the diversity in patterns; hence, it contributes to the large robustness of hate comment detection. In an ever-globalized and digitized world, the advent of dependable methodologies for hate comment detection becomes cardinal in acquiring safe and inclusive online environments. Our research is a promising step towards reducing online toxicity in order to have healthier and more constructive digital conversations.",,,,, ,  2023 International Conference on Smart Devices (ICSD),Voice activity detection;Toxicology;Social networking (online);Hate speech;Oral communication;Speech recognition;Robustness;Ensemble learning;Virtualization;Long short term memory;Hate comment detection;LSTM;LSTM and RNN;Ensemble Learning;Hate speech detection,detection,
3160,"**Title**Lab-on-a-chip sensor for assessment of manganese exposure

**Abstract**In this paper, we describe development of a point-of-care sensor for rapid electrochemical measurement of biological exposure to manganese (Mn). The sensor was fabricated using bismuth as working electrode and Ag/AgCl as integrated reference. Electrochemical performance of the lab-on-a-chip sensor was characterized by measuring oxidation reduction potential (ORP) of reference solutions and square wave stripping voltammetry (SWSV) of Mn standard solutions. The envisioned sensor will permit workers quickly and safely monitor their biological dose of Mn on the jobsite, minimizing exposure and ensuring worker safety.","Jothimuthu, Preetha, Haynes, Erin, Papautsky, Ian",,,Lab-on-a-chip sensor for assessment of manganese exposure,,,10.1109/ICSENS.2008.4716420 , ,,"In this paper, we describe development of a point-of-care sensor for rapid electrochemical measurement of biological exposure to manganese (Mn). The sensor was fabricated using bismuth as working electrode and Ag/AgCl as integrated reference. Electrochemical performance of the lab-on-a-chip sensor was characterized by measuring oxidation reduction potential (ORP) of reference solutions and square wave stripping voltammetry (SWSV) of Mn standard solutions. The envisioned sensor will permit workers quickly and safely monitor their biological dose of Mn on the jobsite, minimizing exposure and ensuring worker safety.",,,,, ,"  SENSORS, 2008 IEEE",Lab-on-a-chip;Manganese;Biosensors;Sensor phenomena and characterization;Bismuth;Electrodes;Oxidation;Measurement standards;Monitoring;Occupational safety,out_of_scope,
3161,"**Title**Health risk assessment of mercury exposure for the sensitive populations living along the Di'Er Songhua River region

**Abstract**The Di'er Songhua River is an important tributary of the Songhua River, which originates from Tianchi Lake in the Changbai Mountains and flows through central Jilin Province in northeast China. In the early sixties of last century, this river became one of the typical water bodies with mercury polluted river, due to its discharge of wastewater containing mercury. In order to investigate whether there were still human health risk from mercury exposure for the sensitive subpopulations living in the Di'er Songhua River region, a number of 155 hair samples were collected from the children aged of 0 to 15 and the women of childbearing age aged from 16 to 45, and the hair total mercury concentrations were detected by the methods of CVAAS. The average hair total mercury concentrations of child was 0.99 mg/kg with the range of 0.16–14.97 mg/kg. The mean hair mercury value of the women of childbearing age was 2.43 mg/kg with the range of 0.07–92.13 mg/kg. There were 7.69% of women of childbearing age with their high hair mercury concentrations exceeded 2.8 mg/kg, whose frequency of paraesthesia was 50%. There were 7.69% of women of childbearing age with their high hair mercury concentrations exceeded 3.8 mg/kg, whose frequency of comprehensive nervous system influence was 5%. There were 1.91% of children with their high hair mercury concentrations exceeded 2.8 mg/kg, whose frequency of paraesthesia was 50%. There were 0.02% of children with their high hair mercury concentrations exceeded 3.8 mg/kg, whose frequency of comprehensive nervous system influence was 5%.","Lei, Zhang",,,Health risk assessment of mercury exposure for the sensitive populations living along the Di'Er Songhua River region,,,10.1109/ICMT.2011.6002811 , ,,"The Di'er Songhua River is an important tributary of the Songhua River, which originates from Tianchi Lake in the Changbai Mountains and flows through central Jilin Province in northeast China. In the early sixties of last century, this river became one of the typical water bodies with mercury polluted river, due to its discharge of wastewater containing mercury. In order to investigate whether there were still human health risk from mercury exposure for the sensitive subpopulations living in the Di'er Songhua River region, a number of 155 hair samples were collected from the children aged of 0 to 15 and the women of childbearing age aged from 16 to 45, and the hair total mercury concentrations were detected by the methods of CVAAS. The average hair total mercury concentrations of child was 0.99 mg/kg with the range of 0.16–14.97 mg/kg. The mean hair mercury value of the women of childbearing age was 2.43 mg/kg with the range of 0.07–92.13 mg/kg. There were 7.69% of women of childbearing age with their high hair mercury concentrations exceeded 2.8 mg/kg, whose frequency of paraesthesia was 50%. There were 7.69% of women of childbearing age with their high hair mercury concentrations exceeded 3.8 mg/kg, whose frequency of comprehensive nervous system influence was 5%. There were 1.91% of children with their high hair mercury concentrations exceeded 2.8 mg/kg, whose frequency of paraesthesia was 50%. There were 0.02% of children with their high hair mercury concentrations exceeded 3.8 mg/kg, whose frequency of comprehensive nervous system influence was 5%.",,,,, ,  2011 International Conference on Multimedia Technology,Hair;Pediatrics;Nervous system;Rivers;Mercury (metals);Risk management;Aging;mercury;hair;sensitive populations;health risk assessment;the Di'er Songhua River,out_of_scope,
3162,"**Title**Effect of apoptosis and DNA damage on rat vascular endothelial cells induced by fluoride and arsenite

**Abstract**In order to observe the effect of fluoride and arsenite on vascular endothelial cells and to explore their alone or associated mechanism on the blood circulatory system. Rat aorta endothelial cells was cultured in Vitro and was contaminated with NaF at 0μmol / L, 600μmol / L and 900μmol / L and NaAsO2 0μmol / L, 0.1μmol / L, 1.0μmol / L compatibility for 48h. Cell morphology was observed with light microscopy, cell activity was detected by MTT, apoptosis was by flow cytometry, DNA damage in endothelial cells was analyzed through single cell gel electrophoresis. The cells of non-exposed control group and the low concentration of fluoride and arsenite group grew well and showed pebble-shaped spindle-shaped, but they appeared poor growth state, some were round with necrosis in alone or associated with high concentrations groups. The cell activity and DNA damage in fluoride and arsenite alone or associated with high concentrations groups was lower and more seriously than in non-exposed control group and low concentration group (P<;0.05), and the cells apoptosis was the opposite result. Fluoride and arsenite alone or in combination can reduce the activity of vascular endothelial cells, induced apoptosis, induce DNA damage, and there was a dose - response relationship.","Shuguang, Jin, Jinghong, Yu, Huan, Li, Hongyan, Wang",,,Effect of apoptosis and DNA damage on rat vascular endothelial cells induced by fluoride and arsenite,,,10.1109/HHBE.2011.6028376 , ,,"In order to observe the effect of fluoride and arsenite on vascular endothelial cells and to explore their alone or associated mechanism on the blood circulatory system. Rat aorta endothelial cells was cultured in Vitro and was contaminated with NaF at 0μmol / L, 600μmol / L and 900μmol / L and NaAsO2 0μmol / L, 0.1μmol / L, 1.0μmol / L compatibility for 48h. Cell morphology was observed with light microscopy, cell activity was detected by MTT, apoptosis was by flow cytometry, DNA damage in endothelial cells was analyzed through single cell gel electrophoresis. The cells of non-exposed control group and the low concentration of fluoride and arsenite group grew well and showed pebble-shaped spindle-shaped, but they appeared poor growth state, some were round with necrosis in alone or associated with high concentrations groups. The cell activity and DNA damage in fluoride and arsenite alone or associated with high concentrations groups was lower and more seriously than in non-exposed control group and low concentration group (P<;0.05), and the cells apoptosis was the opposite result. Fluoride and arsenite alone or in combination can reduce the activity of vascular endothelial cells, induced apoptosis, induce DNA damage, and there was a dose - response relationship.",,,,, ,  Proceedings 2011 International Conference on Human Health and Biomedical Engineering,Cells (biology);DNA;Educational institutions;Atherosclerosis;Joints;Injuries;Public healthcare;Sodium fluoride;Sodium arsenite;Endothelial cells;Apoptosis;DNA damage,out_of_scope,
3163,"**Title**Detection and quantification of arsenic in water using electronic tongue

**Abstract**Present manuscript reports the detection and quantification of Arsenic (As) in water to 5 ppb level using simple electronic tongue instrumentation. Anodic stripping voltammetry is used to detect arsenic. An arsenic quantifier is designed using multivariate data processing of the accumulated experimental data pool. Subsequently, a low cost and indigenous possible arsenic meter scheme suitable for bulk monitoring of Arsenic is proposed.","Agir, Sujeevan Kumar, Kundu, Madhusree",,,Detection and quantification of arsenic in water using electronic tongue,,,10.1109/CMI.2016.7413783 , ,,"Present manuscript reports the detection and quantification of Arsenic (As) in water to 5 ppb level using simple electronic tongue instrumentation. Anodic stripping voltammetry is used to detect arsenic. An arsenic quantifier is designed using multivariate data processing of the accumulated experimental data pool. Subsequently, a low cost and indigenous possible arsenic meter scheme suitable for bulk monitoring of Arsenic is proposed.",,,,, ,"  2016 IEEE First International Conference on Control, Measurement and Instrumentation (CMI)",Arsenic;Electrodes;Sensor arrays;Gold;Instruments;Copper;Arsenic;e-tongue;ASV;PCA;electrode,out_of_scope,
3164,"**Title**Ensemble Learning in the Recognition of Various Types of the Online Toxicity

**Abstract**This article offers approaches to classifying online toxicity using a set of methods learning. It focuses on detecting toxic posts mainly on fake news and offensive posts. The article also provides definitions of basic terms, problems associated with recognizing toxic posts, places on the web where they occur, as well as specific steps that can be taken to protect users from them. Based on the analysis of the current state and the latest knowledge, various methods of ensemble machine learning are proposed, which have been used for training, testing and evaluation on different groups of toxic posts. The article also contains detailed test results.","Machová, Kristína, Mach, Marián, Balara, Viliam, Husnaj, Patrik",,,Ensemble Learning in the Recognition of Various Types of the Online Toxicity,,,10.1109/ICETA63795.2024.10850784 , ,,"This article offers approaches to classifying online toxicity using a set of methods learning. It focuses on detecting toxic posts mainly on fake news and offensive posts. The article also provides definitions of basic terms, problems associated with recognizing toxic posts, places on the web where they occur, as well as specific steps that can be taken to protect users from them. Based on the analysis of the current state and the latest knowledge, various methods of ensemble machine learning are proposed, which have been used for training, testing and evaluation on different groups of toxic posts. The article also contains detailed test results.",,,,, ,  2024 International Conference on Emerging eLearning Technologies and Applications (ICETA),Training;Measurement;Toxicology;Social networking (online);Ensemble learning;Fake news;Bagging;Random forests;Long short term memory;Testing;ensemble machine learning;toxic posts detection;random forests;bagging;boosting,detection,
3165,"**Title**Detection of Artificially Created Faces with Convolutional Networks

**Abstract**The automatic detection of artificially generated content presents one of the most current topics in the field of artificial intelligence. It may help disguise deceitful users, spread misinformation or help in the dissemination of false accusations and therefore it is may prove vital in terms of teaching and improving the information literacy at schools,public institutions or general public. The automatic recognition of various forms of toxicity and artificially created faces in online space can help teachers to teach an information literacy and a critical thinking.This paper focuses on the detection of artificially generated faces depicted on still images with the utilization various types of convolutional neural networks.The paper presents an experiment aimed at multitude of methods which share the same convolutional basis. The focus is the creation of a efficient tool for image classification, which for our purposes was conducted with the use of ResNet, DenseNet and VGG architectures.","Balara, V., Machová, K.",,,Detection of Artificially Created Faces with Convolutional Networks,,,10.1109/ICETA63795.2024.10850853 , ,,"The automatic detection of artificially generated content presents one of the most current topics in the field of artificial intelligence. It may help disguise deceitful users, spread misinformation or help in the dissemination of false accusations and therefore it is may prove vital in terms of teaching and improving the information literacy at schools,public institutions or general public. The automatic recognition of various forms of toxicity and artificially created faces in online space can help teachers to teach an information literacy and a critical thinking.This paper focuses on the detection of artificially generated faces depicted on still images with the utilization various types of convolutional neural networks.The paper presents an experiment aimed at multitude of methods which share the same convolutional basis. The focus is the creation of a efficient tool for image classification, which for our purposes was conducted with the use of ResNet, DenseNet and VGG architectures.",,,,, ,  2024 International Conference on Emerging eLearning Technologies and Applications (ICETA),Image recognition;Toxicology;Social networking (online);Computational modeling;Large language models;Computer architecture;Convolutional neural networks;Security;Faces;Image classification;convolutional neural networks;deepfake detection;deep learning,out_of_scope,
3166,"**Title**A Model Interpretability-Based Defense Against Clean-Label Backdoor Attacks

**Abstract**The widespread application of deep learning in autonomous driving and intelligent transportation has brought attention to the security of traffic sign recognition systems. Clean-label backdoor attacks present a significant threat to model robustness. This paper proposes a defense method that integrates model interpretability techniques, combining gradient-based and perturbation-based approaches. The method generates image heat maps and filters perturbed images to construct an effective data cleaning framework for identifying and removing backdoor triggers. Experiments on the Traffic Sign Recognition Dataset show that this integrated approach maintains high detection accuracy across various attack modes, achieving a Matthews correlation coefficient of 0.975 under random triggers. The method also demonstrates strong adaptability to different attack patterns. This research enhances the security of deep learning models in safety-critical applications and has broad implications for future work in securing AI systems.","Shuhan, Zhang, Wenbo, Jiang, Yuxin, Lu, Hongwei, Li",,,A Model Interpretability-Based Defense Against Clean-Label Backdoor Attacks,,,10.1109/ICCWAMTIP64812.2024.10873733 , ,,"The widespread application of deep learning in autonomous driving and intelligent transportation has brought attention to the security of traffic sign recognition systems. Clean-label backdoor attacks present a significant threat to model robustness. This paper proposes a defense method that integrates model interpretability techniques, combining gradient-based and perturbation-based approaches. The method generates image heat maps and filters perturbed images to construct an effective data cleaning framework for identifying and removing backdoor triggers. Experiments on the Traffic Sign Recognition Dataset show that this integrated approach maintains high detection accuracy across various attack modes, achieving a Matthews correlation coefficient of 0.975 under random triggers. The method also demonstrates strong adaptability to different attack patterns. This research enhances the security of deep learning models in safety-critical applications and has broad implications for future work in securing AI systems.",,,,, ,  2024 21st International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP),Deep learning;Correlation coefficient;Adaptation models;Filters;Computational modeling;Transportation;Information processing;Media;Robustness;Heat maps;Backdoor attacks;Backdoor defenses;Model interpretability,out_of_scope,
3167,"**Title**PEFL: Privacy-Preserved and Efficient Federated Learning With Blockchain

**Abstract**With the rise of federated learning (FL) in the realm of machine learning for data privacy protection, its unique distributed data processing characteristics have garnered widespread attention. However, the implementation of FL faces many challenges, as achieving a balance between data privacy, model security, and system efficiency is difficult, often requiring the sacrifice of efficiency for privacy and security. Moreover, this process typically assumes the existence of a trusted server for coordination. Addressing these challenges, this article proposes a privacy-preserved and efficient FL framework with blockchain (PEFL). PEFL utilizes blockchain and differential privacy techniques to coordinate privacy protection among clients, and filters out anomalous model parameters through an aggregation-side detection algorithm to resist poisoning attacks. Under the assumption of an untrusted server, we design the model-validated fault-tolerant federation (MFF) consensus mechanism based on a committee, balancing efficiency expectations to regulate the server and ensure the reliability of the training process. Through experiments on the MNIST and CIFAR10 datasets, and comparison with typical FL schemes, PEFL demonstrates better defense against various attack models. Besides, it achieves higher training efficiency while ensuring privacy security.","Tian, Lei, Lin, Feilong, Gan, Jiahao, Jia, Riheng, Zheng, Zhonglong, Li, Minglu",,,PEFL: Privacy-Preserved and Efficient Federated Learning With Blockchain,,,10.1109/JIOT.2024.3479328 , ,,"With the rise of federated learning (FL) in the realm of machine learning for data privacy protection, its unique distributed data processing characteristics have garnered widespread attention. However, the implementation of FL faces many challenges, as achieving a balance between data privacy, model security, and system efficiency is difficult, often requiring the sacrifice of efficiency for privacy and security. Moreover, this process typically assumes the existence of a trusted server for coordination. Addressing these challenges, this article proposes a privacy-preserved and efficient FL framework with blockchain (PEFL). PEFL utilizes blockchain and differential privacy techniques to coordinate privacy protection among clients, and filters out anomalous model parameters through an aggregation-side detection algorithm to resist poisoning attacks. Under the assumption of an untrusted server, we design the model-validated fault-tolerant federation (MFF) consensus mechanism based on a committee, balancing efficiency expectations to regulate the server and ensure the reliability of the training process. Through experiments on the MNIST and CIFAR10 datasets, and comparison with typical FL schemes, PEFL demonstrates better defense against various attack models. Besides, it achieves higher training efficiency while ensuring privacy security.",,,,, ,  ,Computational modeling;Blockchains;Training;Servers;Data models;Security;Privacy;Protection;Federated learning;Internet of Things;Blockchain;consensus mechanism;differential privacy (DP);federated learning (FL);privacy security,out_of_scope,
3168,"**Title**DriftGLY: A Low-Cost IoT-Based Ecosystem for Monitoring Agrochemical Spray Drifts

**Abstract**Agrochemicals are to be blamed for the poisoning of millions of human beings worldwide, with acute and chronic exposure to such substances causing thousands of deaths. The presence of agrochemicals in the air is caused by drift—a phenomenon that originates from ground and aerial spraying applied in lands used for agribusiness. Drift refers to the spread and wind-driven transport of agrochemicals that have been volatilized during spraying, and which can easily reach towns and cities. Actively monitoring agrochemical drift is essential to protect the health of citizens and the environment. Many of the systems used for monitoring agrochemicals are currently analog, while those with some degree of digitalization are expensive, complex, and not easily scalable. Therefore, new cost-effective, stand-alone, reliable, easy-to-implement, and citizen-oriented technological tools need to be designed and developed. This article introduces “DriftGLY,” an innovative, low-cost Internet of Things (IoT) early warning system that utilizes a digital traffic light to continuously and automatically monitor the presence of agrochemicals in the air, both individually and in cocktail form. The key innovation of DriftGLY lies in the close relationship between the configuration of its digital traffic light and the precise calculation of the quantity of agrochemicals deposited in spray tanks. This configuration is specifically based on the parameter of the dose rate expressed in liters per hectare of these contaminants. DriftGLY incorporates an original collection system that allows for the indirect detection of agrochemicals in their particulate, gaseous, and, unlike traditional systems, liquid forms. In this manner, DriftGLY displays pollution risk levels through its digital traffic light, transmitting them to an IoT platform via various connectivity options, such as WiFi, LoRaWAN, and GSM/GPRS, and posts them on the social network X (formerly known as Twitter). The aim of this action is to democratize information and promote the necessary changes for citizens to enjoy a healthy and balanced environment.","Aira, Javier, Olivares, Teresa, Delicado, Francisco M.",,,DriftGLY: A Low-Cost IoT-Based Ecosystem for Monitoring Agrochemical Spray Drifts,,,10.1109/TIM.2024.3350146 , ,,"Agrochemicals are to be blamed for the poisoning of millions of human beings worldwide, with acute and chronic exposure to such substances causing thousands of deaths. The presence of agrochemicals in the air is caused by drift—a phenomenon that originates from ground and aerial spraying applied in lands used for agribusiness. Drift refers to the spread and wind-driven transport of agrochemicals that have been volatilized during spraying, and which can easily reach towns and cities. Actively monitoring agrochemical drift is essential to protect the health of citizens and the environment. Many of the systems used for monitoring agrochemicals are currently analog, while those with some degree of digitalization are expensive, complex, and not easily scalable. Therefore, new cost-effective, stand-alone, reliable, easy-to-implement, and citizen-oriented technological tools need to be designed and developed. This article introduces “DriftGLY,” an innovative, low-cost Internet of Things (IoT) early warning system that utilizes a digital traffic light to continuously and automatically monitor the presence of agrochemicals in the air, both individually and in cocktail form. The key innovation of DriftGLY lies in the close relationship between the configuration of its digital traffic light and the precise calculation of the quantity of agrochemicals deposited in spray tanks. This configuration is specifically based on the parameter of the dose rate expressed in liters per hectare of these contaminants. DriftGLY incorporates an original collection system that allows for the indirect detection of agrochemicals in their particulate, gaseous, and, unlike traditional systems, liquid forms. In this manner, DriftGLY displays pollution risk levels through its digital traffic light, transmitting them to an IoT platform via various connectivity options, such as WiFi, LoRaWAN, and GSM/GPRS, and posts them on the social network X (formerly known as Twitter). The aim of this action is to democratize information and promote the necessary changes for citizens to enjoy a healthy and balanced environment.",,,,, ,  ,Agrochemicals;Monitoring;Pollution measurement;Internet of Things;Contamination;Wireless fidelity;Technological innovation;Agriculture;agrochemicals;air pollution;environmental monitoring;Internet of Things (IoT);low-power wide-area network (LPWAN);persistent organic pollutants (POPs);smart cities,,
3169,"**Title**Monitoring and preventive measures about heavy metal pollution

**Abstract**Taking overmuch in toxic heavy metal elements will lead to reduce of personal immunity or become permanently disabled, even death. In local region, the soils and water bodies which persons rely for existence had been contaminated, which the toxic heavy metal elements had been accumulated over a long period of time because it is difficult to degradation by microorganism, and even a local “time bomb” of geochemical field will may be formed. In certain period it will suddenly appear so that to form extensive epidemics. They can be transformed between heavy metal pollutions in soils and water and air, in which the soils pollution is most serious in consequence and is difficult to restore. When the heavy metal pollutions of soils very serious, it can be led to food chain poisoning, reduction of the body diathesis of local population and addition of children with disease, and that offend of the heavy metal elements in local grain crops and vegetables and affect edible. In the course of industrialized society of our country, therefore, it is a very important work that strengthen the prevent measure of the extent of the heavy metal pollutions in soils and water and air, which it is an important guarantee of the ensure sustainable society development. Regional geochemistry is the foundation work of the effective monitoring in detection of soils and water bodies (including groundwater) so that a system of the prevent measure can be established as soon early as possible.","Li, Wenyuan",,,Monitoring and preventive measures about heavy metal pollution,,,10.1109/ISWREP.2011.5893684 , ,,"Taking overmuch in toxic heavy metal elements will lead to reduce of personal immunity or become permanently disabled, even death. In local region, the soils and water bodies which persons rely for existence had been contaminated, which the toxic heavy metal elements had been accumulated over a long period of time because it is difficult to degradation by microorganism, and even a local “time bomb” of geochemical field will may be formed. In certain period it will suddenly appear so that to form extensive epidemics. They can be transformed between heavy metal pollutions in soils and water and air, in which the soils pollution is most serious in consequence and is difficult to restore. When the heavy metal pollutions of soils very serious, it can be led to food chain poisoning, reduction of the body diathesis of local population and addition of children with disease, and that offend of the heavy metal elements in local grain crops and vegetables and affect edible. In the course of industrialized society of our country, therefore, it is a very important work that strengthen the prevent measure of the extent of the heavy metal pollutions in soils and water and air, which it is an important guarantee of the ensure sustainable society development. Regional geochemistry is the foundation work of the effective monitoring in detection of soils and water bodies (including groundwater) so that a system of the prevent measure can be established as soon early as possible.",,,,, ,  2011 International Symposium on Water Resource and Environmental Protection,Geology;Fetus;Pollution;Monitoring;heavy metal pollution;“time bomb” of geochemical field;regional geochemistry;prevent measure,out_of_scope,
3170,"**Title**Two-Level Fuzzy Based Fire Prediction Scheme Using Wireless Sensor Network

**Abstract**Recent research works focus on monitoring temperature and relative humidity to detect fire accidents in firework industries. Many of the fire accidents reported are due to the friction of the chemicals during heavy wind flow. This confirms that air flow and toxicity of the gases are to be monitored in addition to temperature and relative humidity. Nevertheless, the existing works lack monitoring of air flow and toxicity. Hence, a Wireless Sensor Network that monitors all the essential parameters is deployed using IRIS motes. Further, the severity of the risk is evaluated through a proposed novel two-level fuzzy based fire prediction scheme implemented in MATLAB. An alarm is raised as a warning signal for labours and people close to the environment during high risk. Thus fire accidents at firework industries can be predicted and damage be avoided. The fuzzy is validated through simulation. Through motes the parameters are observed at different times and their corresponding risk probability is evaluated. The results confirm the supremacy of the proposal.","Nagpal, Shobhit Kumar, Sudha, S.",,,Two-Level Fuzzy Based Fire Prediction Scheme Using Wireless Sensor Network,,,10.1109/ICACCE.2015.105 , ,,"Recent research works focus on monitoring temperature and relative humidity to detect fire accidents in firework industries. Many of the fire accidents reported are due to the friction of the chemicals during heavy wind flow. This confirms that air flow and toxicity of the gases are to be monitored in addition to temperature and relative humidity. Nevertheless, the existing works lack monitoring of air flow and toxicity. Hence, a Wireless Sensor Network that monitors all the essential parameters is deployed using IRIS motes. Further, the severity of the risk is evaluated through a proposed novel two-level fuzzy based fire prediction scheme implemented in MATLAB. An alarm is raised as a warning signal for labours and people close to the environment during high risk. Thus fire accidents at firework industries can be predicted and damage be avoided. The fuzzy is validated through simulation. Through motes the parameters are observed at different times and their corresponding risk probability is evaluated. The results confirm the supremacy of the proposal.",,,,, ,  2015 Second International Conference on Advances in Computing and Communication Engineering,Temperature sensors;Humidity;Fires;Monitoring;Temperature measurement;Wireless sensor networks;Temperature distribution;wireless sensor network;fuzzy logic controller;fire prediction;firework industry;risk probability;monitoring system,out_of_scope,
3171,"**Title**Ag-Loaded WS2-Based Pb2+ Ion Detection in Water

**Abstract**The prompt detection of aqueous pollutants, with both high speed and precision, holds great significance due to the substantial threats they impose on human well-being and the environment. Lead and its derivatives exhibit a high level of toxicity, capable of inducing various ailments. Nevertheless, existing lead detection systems are suffered from several drawbacks, including sluggish response times, elevated cost, and a lack of mobility. Here, a sensor for highly sensitive, selective, and rapid detection of the trace amount of toxic lead (Pb $^{{2}+}{)}$ ions was successfully developed using tungsten disulfide (WS $_{{2}}{)}$ functionalized interdigitated electrodes (IDEs). Pristine and silver (Ag)-loaded WS2 were synthesized via the facile hydrothermal method. A series of characterizations are performed to investigate the crystal structure, surface morphology, and elemental composition of the synthesized materials. When exposed to 10 parts per billion (ppb) of Pb $^{{2}+}$ ion solution, pristine WS2 nanorods exhibited a 1.31-mA change in current, while at the loading of 1% and 2% Ag, further enhancements in Pb $^{{2}+}$ ion sensitivity were observed. However, further increasing the Ag (4 wt%) loading on WS2 nanorods reduced the sensing response. The developed sensor was characterized by an excellent sensitivity of $819 \mu \text{A}$ /ppb and an impressive detection limit of 75 ppt. Additionally, the sensor showed a rapid response time of less than 5 s, rendering its suitability for real-time heavy metal ion detection applications. The outstanding performance of WS2-based sensors makes them a compelling choice for practical application in monitoring environmental quality and detecting toxic metals.","Chaudhary, Sumit, Patel, Chandrabhan, Mahapatra, Brahamadutta, Kumar, Pawan, Dubey, Mayank, Sriram, Sharath, Mukherjee, Shaibal",,,Ag-Loaded WS2-Based Pb2+ Ion Detection in Water,,,10.1109/JSEN.2023.3341066 , ,,"The prompt detection of aqueous pollutants, with both high speed and precision, holds great significance due to the substantial threats they impose on human well-being and the environment. Lead and its derivatives exhibit a high level of toxicity, capable of inducing various ailments. Nevertheless, existing lead detection systems are suffered from several drawbacks, including sluggish response times, elevated cost, and a lack of mobility. Here, a sensor for highly sensitive, selective, and rapid detection of the trace amount of toxic lead (Pb $^{{2}+}{)}$ ions was successfully developed using tungsten disulfide (WS $_{{2}}{)}$ functionalized interdigitated electrodes (IDEs). Pristine and silver (Ag)-loaded WS2 were synthesized via the facile hydrothermal method. A series of characterizations are performed to investigate the crystal structure, surface morphology, and elemental composition of the synthesized materials. When exposed to 10 parts per billion (ppb) of Pb $^{{2}+}$ ion solution, pristine WS2 nanorods exhibited a 1.31-mA change in current, while at the loading of 1% and 2% Ag, further enhancements in Pb $^{{2}+}$ ion sensitivity were observed. However, further increasing the Ag (4 wt%) loading on WS2 nanorods reduced the sensing response. The developed sensor was characterized by an excellent sensitivity of $819 \mu \text{A}$ /ppb and an impressive detection limit of 75 ppt. Additionally, the sensor showed a rapid response time of less than 5 s, rendering its suitability for real-time heavy metal ion detection applications. The outstanding performance of WS2-based sensors makes them a compelling choice for practical application in monitoring environmental quality and detecting toxic metals.",,,,, ,  ,Ions;Nanorods;Water pollution;Metals;Sensor phenomena and characterization;Thermal engineering;Sensitivity analysis;Tungsten;Hydrothermal;lead (Pb2+);selectivity;sensitivity;silver (Ag) loading;tungsten disulfide (WS2),out_of_scope,
3172,"**Title**Characterization of gold and silver nanoparticles using it's color image segmentation and feature extraction using fuzzy C-means clustering and generalized shape theory

**Abstract**We present a systematic study of the effect of size and shape on the spectral response of individual silver and gold nanoparticles. When developing nanoparticles as catalysts, their shape is very important. For a certain volume of material, nanoparticles make the best catalysts when they have a large surface area. It is a challenge to find the shape that has the largest surface area for its volume. The main focus of this paper is the interesting change in properties of the materials due to increase surface area to volume ratio. This type of characterization helps the researchers in size-based spectral tuning, biological labeling, and toxicity studies and suggest general protocols to address these problems.","Dutta Majumder, D., Karan, Sankar, Goswami, A.",,,Characterization of gold and silver nanoparticles using it's color image segmentation and feature extraction using fuzzy C-means clustering and generalized shape theory,,,10.1109/ICCSP.2011.5739402 , ,,"We present a systematic study of the effect of size and shape on the spectral response of individual silver and gold nanoparticles. When developing nanoparticles as catalysts, their shape is very important. For a certain volume of material, nanoparticles make the best catalysts when they have a large surface area. It is a challenge to find the shape that has the largest surface area for its volume. The main focus of this paper is the interesting change in properties of the materials due to increase surface area to volume ratio. This type of characterization helps the researchers in size-based spectral tuning, biological labeling, and toxicity studies and suggest general protocols to address these problems.",,,,, ,  2011 International Conference on Communications and Signal Processing,Nanobioscience;Biomedical measurements;Microscopy;Optical imaging;Biomedical optical imaging;Artificial neural networks;Fuzzy C-Means Clustering;Generalized Shape Theory & Metric;Nanomaterial;Nanoimaging,out_of_scope,
3173,"**Title**Pattern recognition using finite-iteration cellular systems

**Abstract**Cellular systems are defined by cells that have an internal state and local interactions between cells that govern the dynamics of the system. We propose to use a special kind of cellular neural networks (CNNs) which operates in finite iteration discrete-time mode and mimics the processing of visual perception in biological systems for digit recognition. We propose also a solution to another type of pattern recognition problem using a non-standard cellular neural networks called molecular graph networks (MGNs) which offer direct mapping from compound to property of interest such as physico-chemical, toxicity, logP, inhibitory activity MGNs translate molecular topology to network topology. We show how to design/train by backpropagation CNNs and MGNs in their discrete-time and finite-iteration versions to perform classification on real-world data sets.","Ogorzatek, M., Merkwirth, C., Wichard, J.",,,Pattern recognition using finite-iteration cellular systems,,,10.1109/CNNA.2005.1543160 , ,,"Cellular systems are defined by cells that have an internal state and local interactions between cells that govern the dynamics of the system. We propose to use a special kind of cellular neural networks (CNNs) which operates in finite iteration discrete-time mode and mimics the processing of visual perception in biological systems for digit recognition. We propose also a solution to another type of pattern recognition problem using a non-standard cellular neural networks called molecular graph networks (MGNs) which offer direct mapping from compound to property of interest such as physico-chemical, toxicity, logP, inhibitory activity MGNs translate molecular topology to network topology. We show how to design/train by backpropagation CNNs and MGNs in their discrete-time and finite-iteration versions to perform classification on real-world data sets.",,,,, ,  2005 9th International Workshop on Cellular Neural Networks and Their Applications,Pattern recognition;Cellular neural networks;Bonding;Computer networks;Network topology;Engines;Paper technology;Information technology;Visual perception;Biological systems,out_of_scope,
3174,"**Title**Autonomous operating process for zebrafish embryo injection

**Abstract**Embryo injection is a significant technique in molecule biology and drug discovery for zebrafish, one of the most popular model organisms. Traditional zebrafish embyo injection is manually conducted under microscope, requiring challenging coordination of hand, eye and foot and their respective precise control as well as ceaseless labour. An autonomous operating process for zebrafish embryo injection is proposed in this paper. Based on a micromanipulation robot system, the operating process integrates computer vision and micromanipulation robot control to realize batch embryo injection automatically. Successful rate of 93% and survival ratio of 89.5% at operating speed of 6-7 embryos are obtained, verifying the feasibility and effectiveness of the process. Finally, the process is applied to investigate the toxicity of a dye and receives success.","Yiliao, Wang, Mingzhu, Sun, Xin, Zhao, Baoquan, Zhao",,,Autonomous operating process for zebrafish embryo injection,,,10.1109/3M-NANO.2012.6472927 , ,,"Embryo injection is a significant technique in molecule biology and drug discovery for zebrafish, one of the most popular model organisms. Traditional zebrafish embyo injection is manually conducted under microscope, requiring challenging coordination of hand, eye and foot and their respective precise control as well as ceaseless labour. An autonomous operating process for zebrafish embryo injection is proposed in this paper. Based on a micromanipulation robot system, the operating process integrates computer vision and micromanipulation robot control to realize batch embryo injection automatically. Successful rate of 93% and survival ratio of 89.5% at operating speed of 6-7 embryos are obtained, verifying the feasibility and effectiveness of the process. Finally, the process is applied to investigate the toxicity of a dye and receives success.",,,,, ,"  2012 International Conference on Manipulation, Manufacturing and Measurement on the Nanoscale (3M-NANO)",Embryo;Fluids;Microscopy;Microinjection;Robot kinematics;Autonomous Operating Process;Zebrafish Embryo Injection;Visual feedback,out_of_scope,
3175,"**Title**Silk cocoon and rubber based gas sensors

**Abstract**Biological materials are going to be important in the realm of sensor research. The natural membranous materials e.g. garlic peel, onion peel, natural rubber surface, inner surface layer of cocoon etc. are very much sensitive towards different weather parameters, different environment threatening gases e.g. ammonia, sulphur dioxide etc. Exploiting this sensitivity such materials can be best used as sensors with their qualities like eco friendliness, no toxicity etc. In this present paper gas sensing characteristics of cocoon membrane as well as natural rubber surface had been investigated exploring their surface conductivity.","Ghosh, P. K., Sarkar, A.",,,Silk cocoon and rubber based gas sensors,,,10.1109/ICSensT.2012.6461653 , ,,"Biological materials are going to be important in the realm of sensor research. The natural membranous materials e.g. garlic peel, onion peel, natural rubber surface, inner surface layer of cocoon etc. are very much sensitive towards different weather parameters, different environment threatening gases e.g. ammonia, sulphur dioxide etc. Exploiting this sensitivity such materials can be best used as sensors with their qualities like eco friendliness, no toxicity etc. In this present paper gas sensing characteristics of cocoon membrane as well as natural rubber surface had been investigated exploring their surface conductivity.",,,,, ,  2012 Sixth International Conference on Sensing Technology (ICST),Rubber;Biomembranes;Time factors;Gases;Adsorption;Sensors;gas sensing;response time;recovery time;surface conductance;dispersion force;physisorption,out_of_scope,
3176,"**Title**Evanescent field absorption spectroscopy of trace gases using functionalized microring Resonators

**Abstract**We detect trace gases at ppb levels using evanescent-field absorption spectroscopy in microring resonators coated with sorbent polymers. The overtone spectra derive from mid-infrared resonances that provide a signature of analyte toxicity.","Stievater, T. H., Pruessner, M. W., Park, D., Rabinovich, W. S., McGill, R. A., Holmstrom, S. A., Khurgin, J. B.",,,Evanescent field absorption spectroscopy of trace gases using functionalized microring Resonators,,,10.1364/CLEO_SI.2013.CM4O.4 , ,,We detect trace gases at ppb levels using evanescent-field absorption spectroscopy in microring resonators coated with sorbent polymers. The overtone spectra derive from mid-infrared resonances that provide a signature of analyte toxicity.,,,,, ,  CLEO: 2013,Absorption;Optical waveguides;Optical resonators;Gases;Optical sensors;Optical surface waves;Plastics,out_of_scope,
3177,"**Title**3D Trajectory Planning Based on FEM with Application of Brachytherapy

**Abstract**Brachytherapy is a validate treatment for certain stage,prostate cancer.Large deformation characteristic of soft tissue and force loaded on the tip of insertion needle will cause some unexpectable results, such as imprecise implant of radioactive seeds and extra injury to other tissues. Apparently, improved implant accuracy can not only improve the local control but also reduce global toxicity. As a part of on going efforts to develop robot assisted brachytherapy, the current investigation focuses on dynamic trajectory planning of the brachytherapy needle. Toward that goal, a 3D planning algorithm based on artificial potential field, non-linear material model and dynamic finite element method is proposed. The whole insertion process has been discretized into several time steps. Using compartment trajectory planning in each time step constantly, the dynamic trajectory planning can be conducted smoothly. A numerical simulation has been done to prove the algorithm validity. The result shows that the needle can reach the target without touching the obstacle.","Jiang, Shan, Liu, Xiaoyan, Song, Yongchun",,,3D Trajectory Planning Based on FEM with Application of Brachytherapy,,,10.1109/BMEI.2009.5305180 , ,,"Brachytherapy is a validate treatment for certain stage,prostate cancer.Large deformation characteristic of soft tissue and force loaded on the tip of insertion needle will cause some unexpectable results, such as imprecise implant of radioactive seeds and extra injury to other tissues. Apparently, improved implant accuracy can not only improve the local control but also reduce global toxicity. As a part of on going efforts to develop robot assisted brachytherapy, the current investigation focuses on dynamic trajectory planning of the brachytherapy needle. Toward that goal, a 3D planning algorithm based on artificial potential field, non-linear material model and dynamic finite element method is proposed. The whole insertion process has been discretized into several time steps. Using compartment trajectory planning in each time step constantly, the dynamic trajectory planning can be conducted smoothly. A numerical simulation has been done to prove the algorithm validity. The result shows that the needle can reach the target without touching the obstacle.",,,,, ,  2009 2nd International Conference on Biomedical Engineering and Informatics,Trajectory;Brachytherapy;Needles;Implants;Biological tissues;Injuries;Robots;Conducting materials;Finite element methods;Numerical simulation,out_of_scope,
3178,"**Title**Assessment of Copper Effects on a Diatom Species Through Multi-Scale Fractal Fourier Ptychographic Microscopy

**Abstract**Microalgae are actually considered as sentinel species to detect heavy metal (HM)- driven environmental pollution, since they usually show a dose-dependent response to these persistent pollutants. However, conventional techniques to determine signs of stress (such as evaluation of growth rates, visualization with electron microscopes, enzymatic assays to determine microalgal antioxidant response and molecular analyses aimed at evaluating the overespression of genes involved in HM stress) are time-consuming and do not provide in real time information regarding eventual phenomena of aquatic pollution. To overcome this problem, we settled a novel method: a multi-scale microscopy analysis based on Fourier Ptychographic Microscopy (FPM), choosing copper (Cu) as tested-contaminant for its high toxicity and a diatom species isolated from a seawater environment facing the Sarno River mouth. We combined FPM with a new multi-scale analysis method based on fractal geometry and were able to analyse the detrimental effects of Cu on Skeletonema pseudocostatum with this innovative approach.","Sardo, Angela, Bianco, Vittorio, Miccio, Lisa, Pirone, Daniele, Behal, Jaromir, Memmolo, Pasquale, Cavalletti, Elena, Ferraro, Pietro",,,Assessment of Copper Effects on a Diatom Species Through Multi-Scale Fractal Fourier Ptychographic Microscopy,,,10.1109/MetroSea62823.2024.10765781 , ,,"Microalgae are actually considered as sentinel species to detect heavy metal (HM)- driven environmental pollution, since they usually show a dose-dependent response to these persistent pollutants. However, conventional techniques to determine signs of stress (such as evaluation of growth rates, visualization with electron microscopes, enzymatic assays to determine microalgal antioxidant response and molecular analyses aimed at evaluating the overespression of genes involved in HM stress) are time-consuming and do not provide in real time information regarding eventual phenomena of aquatic pollution. To overcome this problem, we settled a novel method: a multi-scale microscopy analysis based on Fourier Ptychographic Microscopy (FPM), choosing copper (Cu) as tested-contaminant for its high toxicity and a diatom species isolated from a seawater environment facing the Sarno River mouth. We combined FPM with a new multi-scale analysis method based on fractal geometry and were able to analyse the detrimental effects of Cu on Skeletonema pseudocostatum with this innovative approach.",,,,, ,  2024 IEEE International Workshop on Metrology for the Sea; Learning to Measure Sea Health Parameters (MetroSea),Visualization;Pollution;Toxicology;Sea measurements;Fractals;Real-time systems;Rivers;Electron microscopy;Copper;Stress;diatoms;heavy metal pollution;copper;Fourier Ptychographic Microscopy (FPM);fractal analysis,out_of_scope,
3179,"**Title**Effects of spin coating speed on nanostructured Titanium Dioxide thin films properties

**Abstract**Development of Titanium Dioxide (TiO2) as a useful semiconductor material has sparked interest among researchers to study this unique compound. Among the advantages of TiO2 includes wide energy band gap (3.2 eV), chemical inertness, non toxicity, high photocatalytic property and its' abundance in nature. These properties have open ways for the usage of this material in electronic devices application such as Dye Sensitized Solar Cell (DSSC), photocatalytic purifier, and gas sensors.","Zahidi, Musa Mohamed, Malek, Mohd Firdaus, Mamat, Mohamad Hafiz, Rashied, Norulhuda Abd, Noor, Uzer Mohd, Mahmood, Mohamad Rusop Bin",,,Effects of spin coating speed on nanostructured Titanium Dioxide thin films properties,,,10.1109/ESCINANO.2010.5701016 , ,,"Development of Titanium Dioxide (TiO2) as a useful semiconductor material has sparked interest among researchers to study this unique compound. Among the advantages of TiO2 includes wide energy band gap (3.2 eV), chemical inertness, non toxicity, high photocatalytic property and its' abundance in nature. These properties have open ways for the usage of this material in electronic devices application such as Dye Sensitized Solar Cell (DSSC), photocatalytic purifier, and gas sensors.",,,,, ,  2010 International Conference on Enabling Science and Nanotechnology (ESciNano),,out_of_scope,
3180,"**Title**Breakthrough Volumes of Perfluorocarboxylates in Using WAX Cartridges for Analysis of Sewage

**Abstract**Perfluorocarboxylates (PFCAs) are the subject of increasingly intense environmental research due to their persistence, bioaccumulation, toxicity, and global distribution. In order to determine wide chain length PFCAs simultaneously, weak anion exchange (WAX) cartridges have recently been used for solid phase extraction (SPE) in analysis of these chemicals in environmental water samples. However, given the conflicts between the limited ion-exchange capacity of WAX cartridges and the relatively large enrichment coefficient required for analysis of these low pollution level chemicals, it is crucial to select appropriate water sample volumes for specific WAX cartridges in order to ensure the recoveries for all analytes. The objective of this study is to determine the breakthrough volumes of short- and long-chain PFCAs in analysis of sewage using specific WAX cartridges (60 mg, 3 cc) for SPE. The results indicate that the occurrence of breakthrough is dependent on not only the sample volume but also the perfluorocarbon chain length of analytes. The breakthrough volumes for short-chain PFCAs (<C5) range from 200 to 300 mL, while breakthrough does not happen on the medial- (C5-C10) and long-chain ones (>C10) in present study. The relatively low recoveries of long- chain PFCAs (>C10) are mainly due to matrix effects rather than breakthrough because internal standard is not suitable for these chemical. Finally, the volume selected for loading on WAX cartridges (60 mg, 3 cc) in analysis of sewage is 200 mL in order to avoid breakthrough for short-chain PFCAs (<C5) and reduce matrix effect as far as possible for long-chain ones (>C10). Meanwhile, this volume also ensures the quantitation of these chemicals presented in sewage samples because enrichment coefficients are large enough.","Li, Fei, Zhang, Chaojie, Qu, Yan, Chen, Jing, Zhou, Qi",,,Breakthrough Volumes of Perfluorocarboxylates in Using WAX Cartridges for Analysis of Sewage,,,10.1109/ICBBE.2009.5162464 , ,,"Perfluorocarboxylates (PFCAs) are the subject of increasingly intense environmental research due to their persistence, bioaccumulation, toxicity, and global distribution. In order to determine wide chain length PFCAs simultaneously, weak anion exchange (WAX) cartridges have recently been used for solid phase extraction (SPE) in analysis of these chemicals in environmental water samples. However, given the conflicts between the limited ion-exchange capacity of WAX cartridges and the relatively large enrichment coefficient required for analysis of these low pollution level chemicals, it is crucial to select appropriate water sample volumes for specific WAX cartridges in order to ensure the recoveries for all analytes. The objective of this study is to determine the breakthrough volumes of short- and long-chain PFCAs in analysis of sewage using specific WAX cartridges (60 mg, 3 cc) for SPE. The results indicate that the occurrence of breakthrough is dependent on not only the sample volume but also the perfluorocarbon chain length of analytes. The breakthrough volumes for short-chain PFCAs (<C5) range from 200 to 300 mL, while breakthrough does not happen on the medial- (C5-C10) and long-chain ones (>C10) in present study. The relatively low recoveries of long- chain PFCAs (>C10) are mainly due to matrix effects rather than breakthrough because internal standard is not suitable for these chemical. Finally, the volume selected for loading on WAX cartridges (60 mg, 3 cc) in analysis of sewage is 200 mL in order to avoid breakthrough for short-chain PFCAs (<C5) and reduce matrix effect as far as possible for long-chain ones (>C10). Meanwhile, this volume also ensures the quantitation of these chemicals presented in sewage samples because enrichment coefficients are large enough.",,,,, ,  2009 3rd International Conference on Bioinformatics and Biomedical Engineering,Chemical analysis;Solids;Water pollution;Chemical industry;Toxicology;Chaos;Pollution control;Educational institutions;Pollution measurement;Interference,out_of_scope,
3181,"**Title**Troll and Abuser Identification in Social Media for Code-Mixed English, Bangla, and Banglish Text Analysis Using LLMs

**Abstract**Social networking platforms have become our center for daily communication. These networks removed all the barriers that used to exist by providing open platform for sharing thoughts, keeping in touch with friends, and even voicing for what we believe in. Unfortunately, this has also opened the door for trolls and online bullies to run rampant. Along with democratizing communication, these platforms have created a distinctive vocabulary, such as the widespread usage of emojis, which are particularly well-liked by younger audiences. “Banglish” a hybrid language that combines Bengali and English is widely used by Bengalis around the world. It creates serious difficulties for traditional content filtering systems. This study examines how to identify trolls and abusive content in Banglish text using sophisticated large language models (LLMs), such as OpenAI GPT-4, Google Gemini, and Meta LLaMA. Our goal is to use these models to improve the security and reduce the toxicity of social media environments, ensuring a more secure online experience for all users.","Nezami, Mohammad Arif, Huda, Mohammad Nurul",,,"Troll and Abuser Identification in Social Media for Code-Mixed English, Bangla, and Banglish Text Analysis Using LLMs",,,10.1109/ICNGN63705.2024.10871363 , ,,"Social networking platforms have become our center for daily communication. These networks removed all the barriers that used to exist by providing open platform for sharing thoughts, keeping in touch with friends, and even voicing for what we believe in. Unfortunately, this has also opened the door for trolls and online bullies to run rampant. Along with democratizing communication, these platforms have created a distinctive vocabulary, such as the widespread usage of emojis, which are particularly well-liked by younger audiences. “Banglish” a hybrid language that combines Bengali and English is widely used by Bengalis around the world. It creates serious difficulties for traditional content filtering systems. This study examines how to identify trolls and abusive content in Banglish text using sophisticated large language models (LLMs), such as OpenAI GPT-4, Google Gemini, and Meta LLaMA. Our goal is to use these models to improve the security and reduce the toxicity of social media environments, ensuring a more secure online experience for all users.",,,,, ,  2024 International Conference on Intelligent Computing and Next Generation Networks (ICNGN),Vocabulary;Toxicology;Text analysis;Filtering;Large language models;Cyberbullying;Internet;Security;Next generation networking;Emojis;AI;LLMs;Machine learning;Sentiment Analysis;Troll detection;Social media;Code-mixed language;Banglish;Bangla,out_but_toxicity,
3182,"**Title**A Multi-Target Tracking Method for Phytoplankton Based on Adaptive Buffer Intersection-Over-Union

**Abstract**In this study, we propose a novel multi-target tracking method based on Adaptive Buffer Intersection over Union (A-BIOU), aiming to effectively track phytoplankton, especially those targets with irregular motions and indistinguishable appearance. To address the challenge of tracking irregular moving targets, we first extend the space for detection and trajectory matching by adding buffers to compensate for the bias of Kalman filtering in motion estimation. However, improperly setting the buffer size may lead to the problem of misassociation of different targets. To cope with this problem, we propose a new association strategy. Specifically, we classify trajectories into high-density region trajectories and low-density region trajectories by Gaussian density estimation and perform the association in two steps. In the first step of association, we match the high-density region trajectories with the detection using a smaller buffer Intersection over Union that is adaptively adjusted; while in the second step of association, we match the remaining trajectories with the detection using a larger buffer Intersection over Union that is adaptively adjusted. Although, our method is relatively simple, it works well in the multi-target tracking task of phytoplankton. We validated this paper's method using Peridinium umbonatum var. inaequale as an experimental subject, and the experimental results show that the evaluation metrics of IDF1, IDSW, HOTA, and MOTA of multi-target tracking reach 83.91, 317, 76.93, and 92.87, respectively, with an accuracy that is significantly better than that of existing multi-target tracking methods. This provides an effective means for accurately obtaining phytoplankton community movement parameters and developing comprehensive toxicity analysis techniques based on phytoplankton movement and behavior characteristics.","Wang, Tao, Yin, Gaofang, Zhao, Nanjing",,,A Multi-Target Tracking Method for Phytoplankton Based on Adaptive Buffer Intersection-Over-Union,,,10.1109/AINIT61980.2024.10581537 , ,,"In this study, we propose a novel multi-target tracking method based on Adaptive Buffer Intersection over Union (A-BIOU), aiming to effectively track phytoplankton, especially those targets with irregular motions and indistinguishable appearance. To address the challenge of tracking irregular moving targets, we first extend the space for detection and trajectory matching by adding buffers to compensate for the bias of Kalman filtering in motion estimation. However, improperly setting the buffer size may lead to the problem of misassociation of different targets. To cope with this problem, we propose a new association strategy. Specifically, we classify trajectories into high-density region trajectories and low-density region trajectories by Gaussian density estimation and perform the association in two steps. In the first step of association, we match the high-density region trajectories with the detection using a smaller buffer Intersection over Union that is adaptively adjusted; while in the second step of association, we match the remaining trajectories with the detection using a larger buffer Intersection over Union that is adaptively adjusted. Although, our method is relatively simple, it works well in the multi-target tracking task of phytoplankton. We validated this paper's method using Peridinium umbonatum var. inaequale as an experimental subject, and the experimental results show that the evaluation metrics of IDF1, IDSW, HOTA, and MOTA of multi-target tracking reach 83.91, 317, 76.93, and 92.87, respectively, with an accuracy that is significantly better than that of existing multi-target tracking methods. This provides an effective means for accurately obtaining phytoplankton community movement parameters and developing comprehensive toxicity analysis techniques based on phytoplankton movement and behavior characteristics.",,,,, ,"  2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)",Measurement;Seminars;Reactive power;Target tracking;Toxicology;Motion segmentation;Switches;phytoplankton;multi-target tracking;adaptive buffer intersection over union;data association,out_of_scope,
3183,"**Title**Oxidative Stress and Growth Behavior Responses of Marine Diatoms Phaeodactylum Tricornutum and Skeletonema Costatum to Three Typical Persistent Organic Pollutants

**Abstract**To study the oxidative stress responses and growth behavior of marine diatom to persistent organic pollutants (POPs), Phaeodactylum tricornutum and Skeletonema costatum, two species of algae which are potentially harmful to marine environment as red tide algae, were chosen as test diatoms against three common kinds of POPs in the ocean: Aroclor 1254, benzo[a]pyrene (BaP), and dichlorodiphenyltrichloroethane (DDT). The two algae were cultivated in three concentrations of 50, 100 and 500 μg L-1 for 72 h; and the temporal production of malondialdehyde (MDA) and the activities of superoxide dismutase (SOD) and peroxidase (POD) were determined. Results showed that MDA responded quicker than SOD in P. tricornutum and S. costatum, a peak of MDA was detected after 2 h of exposure, while the activity of SOD peaked after 12 h of exposure. For studying the growth behavior of diatoms in the bi-algal culture to POPs, two species in different initial cell densities were investigated in 28-day exposure to the three POPs in concentrations of 15 and 50 μg L-1. The growth of P. tricornutum increased significantly only in the medium enriched with 50 μg L-1 DDT (ratiomax = 148%). On contrast, the cell density of S. costatum increased during the most time of exposure regardless of initial cell density. The results demonstrate that POPs toxicity could cause oxidative stress even cell damage in both P. tricornutum and S. costatum, but algal growth was promoted by the POPs in the mixed culture, which indicated that the presence of pollutants in the sea was an important inducement of the species groups change. The results of this study may provide valuable help for detailed studies of oxidative stress and growth behavior responses of marine diatom to POPs.","Qu, Ying, Zhou, Hai-long, Su, Wen, Wu, Hui-feng, Xue, Qin-zhao",,,Oxidative Stress and Growth Behavior Responses of Marine Diatoms Phaeodactylum Tricornutum and Skeletonema Costatum to Three Typical Persistent Organic Pollutants,,,10.1109/ICMULT.2010.5631158 , ,,"To study the oxidative stress responses and growth behavior of marine diatom to persistent organic pollutants (POPs), Phaeodactylum tricornutum and Skeletonema costatum, two species of algae which are potentially harmful to marine environment as red tide algae, were chosen as test diatoms against three common kinds of POPs in the ocean: Aroclor 1254, benzo[a]pyrene (BaP), and dichlorodiphenyltrichloroethane (DDT). The two algae were cultivated in three concentrations of 50, 100 and 500 μg L-1 for 72 h; and the temporal production of malondialdehyde (MDA) and the activities of superoxide dismutase (SOD) and peroxidase (POD) were determined. Results showed that MDA responded quicker than SOD in P. tricornutum and S. costatum, a peak of MDA was detected after 2 h of exposure, while the activity of SOD peaked after 12 h of exposure. For studying the growth behavior of diatoms in the bi-algal culture to POPs, two species in different initial cell densities were investigated in 28-day exposure to the three POPs in concentrations of 15 and 50 μg L-1. The growth of P. tricornutum increased significantly only in the medium enriched with 50 μg L-1 DDT (ratiomax = 148%). On contrast, the cell density of S. costatum increased during the most time of exposure regardless of initial cell density. The results demonstrate that POPs toxicity could cause oxidative stress even cell damage in both P. tricornutum and S. costatum, but algal growth was promoted by the POPs in the mixed culture, which indicated that the presence of pollutants in the sea was an important inducement of the species groups change. The results of this study may provide valuable help for detailed studies of oxidative stress and growth behavior responses of marine diatom to POPs.",,,,, ,  2010 International Conference on Multimedia Technology,Algae;Stress;Proteins;Communities;Tides;Compounds,out_of_scope,
3184,"**Title**AI in Healthcare – Precision Medicine and Diagnosis

**Abstract**By knowing the early risk factors prediction of disease through precision medicine has enhanced medical care surpassed the conventional symptom-driven treatment approach. To choose the best course for precision medicine, it is requisite to carefully consider both broad and overall patient data, the required posology data of patient; in case to understand the patient history to differentiate between sick and reasonably healthy individuals. This will enhance our comprehension of the molecular markers that can signify alterations in health. Artificial intelligence, precision, and genetic medicine leads to the better patient care. Genomic medicine technologies are being used by patients who have distinct healthcare needs or less typical therapeutic responses. Through sophisticated computing and inference, artificial intelligence (AI) offers insights that improve medical decision-making by allowing the system to think and learn. This in-depth study examines the relationship between artificial intelligence (AI) and healthcare, with a particular emphasis on the revolutionary potential of AI-driven personalized treatment regimens in the field of precision medicine. The essay emphasizes its significant influence on healthcare across multiple sectors and places a focus on responsible growth for the common good. In order to ensure a full investigation of the topic, the research method entails a detailed examination of AI in healthcare through indexed databases. The story explores how AI is transforming treatment planning, diagnosis, and patient care, especially in fields like radiation. When treating patients with metastatic cutaneous melanoma, standard medical imaging methods including CT, MRI, and PET are essential. Through the improvement of customized image-guided precision medicine strategies, advances in artificial intelligence (AI) techniques like radiomics, machine learning, and deep learning have the potential to completely transform the use of medical imaging. In this article, we will analyze how AI/radiomics might be used to mine data from medical pictures, including tumor volume, heterogeneity, and shape, to give doctors insights into cancer biology and enhance patient care in the clinic and during clinical trials. Artificial intelligence (AI) holds promise for improving many aspects of treating metastatic cutaneous melanoma, such as diagnosis, planning, delivery, response assessment, toxicity assessment, and patient monitoring.","Patel, Suvarna U, Jirvankar, Pranita",,,AI in Healthcare – Precision Medicine and Diagnosis,,,10.1109/IDICAIEI61867.2024.10842772 , ,,"By knowing the early risk factors prediction of disease through precision medicine has enhanced medical care surpassed the conventional symptom-driven treatment approach. To choose the best course for precision medicine, it is requisite to carefully consider both broad and overall patient data, the required posology data of patient; in case to understand the patient history to differentiate between sick and reasonably healthy individuals. This will enhance our comprehension of the molecular markers that can signify alterations in health. Artificial intelligence, precision, and genetic medicine leads to the better patient care. Genomic medicine technologies are being used by patients who have distinct healthcare needs or less typical therapeutic responses. Through sophisticated computing and inference, artificial intelligence (AI) offers insights that improve medical decision-making by allowing the system to think and learn. This in-depth study examines the relationship between artificial intelligence (AI) and healthcare, with a particular emphasis on the revolutionary potential of AI-driven personalized treatment regimens in the field of precision medicine. The essay emphasizes its significant influence on healthcare across multiple sectors and places a focus on responsible growth for the common good. In order to ensure a full investigation of the topic, the research method entails a detailed examination of AI in healthcare through indexed databases. The story explores how AI is transforming treatment planning, diagnosis, and patient care, especially in fields like radiation. When treating patients with metastatic cutaneous melanoma, standard medical imaging methods including CT, MRI, and PET are essential. Through the improvement of customized image-guided precision medicine strategies, advances in artificial intelligence (AI) techniques like radiomics, machine learning, and deep learning have the potential to completely transform the use of medical imaging. In this article, we will analyze how AI/radiomics might be used to mine data from medical pictures, including tumor volume, heterogeneity, and shape, to give doctors insights into cancer biology and enhance patient care in the clinic and during clinical trials. Artificial intelligence (AI) holds promise for improving many aspects of treating metastatic cutaneous melanoma, such as diagnosis, planning, delivery, response assessment, toxicity assessment, and patient monitoring.",,,,, ,"  2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)",Precision medicine;Genomics;Medical services;Melanoma;Planning;Artificial intelligence;Bioinformatics;Medical diagnostic imaging;Cancer;Tumors;Machine Learning;Precision Medicine;Genomic Medicine;Therapeutic;Artificial Intelligence,out_of_scope,
3185,"**Title**Integration AI Techniques in Low-Resource Language: The Case of Kazakh Language

**Abstract**Sentiment analysis is an extensively explored domain within natural language processing (NLP); nevertheless, a significant emphasis has been placed on languages possessing ample resources, such as English. This paper delves into the transformative capabilities of Optical Character Recognition (OCR), Natural Language Processing (NLP), and Speech Recognition, emphasizing their potential impact on low-resource languages, particularly focusing on Kazakh. OCR, a pivotal AI technique, extracts characters from images, revolutionizing the digitization of business records and streamlining mundane tasks. NLP, another powerful AI tool, analyzes and generates human-like text, while Speech Recognition converts spoken words into text. According to findings the OCR model demonstrated effectiveness, achieving an accuracy rate of 85% with losses ranging from 1.5 to 2, while TTS (text-to-speech) method mean opinion score (MOS) results with 95% confidence intervals. In addition, AI Meta research center assessed over 40,000 diverse translations, including Kazakh language directions using the human-translated benchmark, they integrated human evaluation with a unique toxicity benchmark across all 200 languages to ensure translation safety. Achieving a substantial 44% improvement over the prior state-of-the-art, the model by Meta AI establishes a crucial foundation for realizing a universal translation system. However, there remains ample room for exploration and refinement in the integration of these AI technologies, particularly in expanding the scope of evaluation metrics and addressing potential challenges in low-resource language settings.","Kamshat, Asmaganbetova, Auyeskhan, Ulanbek, Zarina, Nurzhanova, Alen, Serikbayev, Yeskazina, Malika",,,Integration AI Techniques in Low-Resource Language: The Case of Kazakh Language,,,10.1109/IEEECONF61558.2024.10585350 , ,,"Sentiment analysis is an extensively explored domain within natural language processing (NLP); nevertheless, a significant emphasis has been placed on languages possessing ample resources, such as English. This paper delves into the transformative capabilities of Optical Character Recognition (OCR), Natural Language Processing (NLP), and Speech Recognition, emphasizing their potential impact on low-resource languages, particularly focusing on Kazakh. OCR, a pivotal AI technique, extracts characters from images, revolutionizing the digitization of business records and streamlining mundane tasks. NLP, another powerful AI tool, analyzes and generates human-like text, while Speech Recognition converts spoken words into text. According to findings the OCR model demonstrated effectiveness, achieving an accuracy rate of 85% with losses ranging from 1.5 to 2, while TTS (text-to-speech) method mean opinion score (MOS) results with 95% confidence intervals. In addition, AI Meta research center assessed over 40,000 diverse translations, including Kazakh language directions using the human-translated benchmark, they integrated human evaluation with a unique toxicity benchmark across all 200 languages to ensure translation safety. Achieving a substantial 44% improvement over the prior state-of-the-art, the model by Meta AI establishes a crucial foundation for realizing a universal translation system. However, there remains ample room for exploration and refinement in the integration of these AI technologies, particularly in expanding the scope of evaluation metrics and addressing potential challenges in low-resource language settings.",,,,, ,  2024 IEEE AITU: Digital Generation,Sentiment analysis;Toxicology;Optical character recognition;Speech recognition;Benchmark testing;Streaming media;Text to speech;Optical Character Recognition;Kazakh language;Low-Resource Languages;Artificial Intelligent;Text-to-Speech;Neural machine translation;Text to language,out_but_toxicity,
3186,"**Title**Multi-class Investigation of Acute Lymphoblastic Leukemia using Optimized Deep Convolutional Neural Network on Blood Smear Images

**Abstract**Cancer of the bone marrow, often known as Acute Lymphoblastic Leukemia (ALL), is characterized by the unchecked growth of lymphoid progenitor cells. It affects both children and adults and is the most prevalent form of childhood cancer. There have been considerable advances in the diagnosis and treatment of acute lymphoblastic leukemia in recent years. The ability to accurately assess risk and develop an appropriate treatment strategy relies on a diagnosis that takes into account all relevant clinical, morphological, cytogenetic, and molecular aspects. However, in order to enhance survival and quality of life for those afflicted by this aggressive hematological malignancy, more research and clinical trials are required to address the issues associated with resistance, relapse, and long-term toxicity. Therefore, in this research a deep optimized convolutional neural network is proposed for the early detection and diagnosis of ALL. The deep optimized CNN model architecture comprises of five convolutional blocks with 13 conv layers, 5 max pool layers. The proposed deep optimized CNN model is tuned using the hyperparameters such as epochs, batch size and optimizers namely Adam and Adamax. Out of the two optimizers, the proposed deep optimized CNN model has outperformed using Adam optimizer with the points of accuracy and precision as 0.96 and 0.95 respectively.","Dangore, Monika, R, Ashwini S, Ghanashyam Chendke, Aishwarya, Shirbhate, Radha, Mali, Yogesh Kisan, Kisan Borate, Vishal",,,Multi-class Investigation of Acute Lymphoblastic Leukemia using Optimized Deep Convolutional Neural Network on Blood Smear Images,,,10.1109/MITADTSoCiCon60330.2024.10575245 , ,,"Cancer of the bone marrow, often known as Acute Lymphoblastic Leukemia (ALL), is characterized by the unchecked growth of lymphoid progenitor cells. It affects both children and adults and is the most prevalent form of childhood cancer. There have been considerable advances in the diagnosis and treatment of acute lymphoblastic leukemia in recent years. The ability to accurately assess risk and develop an appropriate treatment strategy relies on a diagnosis that takes into account all relevant clinical, morphological, cytogenetic, and molecular aspects. However, in order to enhance survival and quality of life for those afflicted by this aggressive hematological malignancy, more research and clinical trials are required to address the issues associated with resistance, relapse, and long-term toxicity. Therefore, in this research a deep optimized convolutional neural network is proposed for the early detection and diagnosis of ALL. The deep optimized CNN model architecture comprises of five convolutional blocks with 13 conv layers, 5 max pool layers. The proposed deep optimized CNN model is tuned using the hyperparameters such as epochs, batch size and optimizers namely Adam and Adamax. Out of the two optimizers, the proposed deep optimized CNN model has outperformed using Adam optimizer with the points of accuracy and precision as 0.96 and 0.95 respectively.",,,,, ,"  2024 MIT Art, Design and Technology School of Computing International Conference (MITADTSoCiCon)",Accuracy;Toxicology;Biological system modeling;Bones;Convolutional neural networks;Progenitor cells;Blood;Acute Lymphoblastic;Leukemia (ALL);Disease;Haematological;CNN,out_of_scope,
3187,"**Title**Structural and biocompatibility challenges for 3D printed microfluidic devices for IVF

**Abstract**In Vitro Fertilization (IVF) is a widely used treatment for infertility, but success rates for UK women under 35 stand at approximately 32%. Culture conditions significantly affect in-vitro embryo development and treatment efficacy. Over 40 years, IVF procedures evolved, with microfluidic platforms emerging to enhance culture conditions. These platforms, designed to mimic a natural environment, show promise without negatively affecting development rates. However, potential impacts on embryo characteristics require further evaluation. The study introduces a microfluidic concept compatible with time-lapse microscopy. Two prototyping methods are compared, being soft lithography in PDMS and 3D printing in HTL resin. Results indicate successful prototype detection and loading efficiency, with the soft lithographic method showing a lower assembly yield. 3D printing facilitates rapid design, in particular for high aspect ratio microfluidic devices. However, viability assessments suggest additional steps are required to exclude material embryo toxicity of the resin.","Mancinelli, Elena, Miranda, Andreia Santos, Picton, Helen M., Pensabene, Virginia",,,Structural and biocompatibility challenges for 3D printed microfluidic devices for IVF,,,10.1109/EMBC53108.2024.10782247 , ,,"In Vitro Fertilization (IVF) is a widely used treatment for infertility, but success rates for UK women under 35 stand at approximately 32%. Culture conditions significantly affect in-vitro embryo development and treatment efficacy. Over 40 years, IVF procedures evolved, with microfluidic platforms emerging to enhance culture conditions. These platforms, designed to mimic a natural environment, show promise without negatively affecting development rates. However, potential impacts on embryo characteristics require further evaluation. The study introduces a microfluidic concept compatible with time-lapse microscopy. Two prototyping methods are compared, being soft lithography in PDMS and 3D printing in HTL resin. Results indicate successful prototype detection and loading efficiency, with the soft lithographic method showing a lower assembly yield. 3D printing facilitates rapid design, in particular for high aspect ratio microfluidic devices. However, viability assessments suggest additional steps are required to exclude material embryo toxicity of the resin.",,,,, ,  2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),Soft lithography;Embryo;Image resolution;Microscopy;Toxic chemicals;Three-dimensional printing;Resins;Microfluidics;Assembly;Testing;microfluidic;embryo culture;IVF;rapid prototyping,out_of_scope,
3188,"**Title**Electrochemical Fingerprinting for Discrimination of $\mathrm{A}\beta_{3-16}, \mathrm{A}\beta_{11-16}$ and their Pyroglutamate Counterparts, Related to Alzheimer's Disease

**Abstract**The $\beta$-amyloid $(\mathrm{A}\beta)$ peptides are believed to be crucial for Alzheimer's disease (AD) by forming toxic oligomers in the brain, which cause neuronal death. Consequently, these peptides serve as biomarkers of AD. Various forms of AP have been identified so far, and their levels vary between healthy and afflicted individuals. Moreover, forms naturally modified through pyroglutamylation at the amino terminus are characterized by higher toxicity and resistance to proteolytic degradation. The current methods focus exclusively on the determination of the $\mathrm{A}\beta_{1-42}/\mathrm{A}\beta_{1-40}$ ratio, losing information on the broad spectrum of other forms, which could be at least as important as the routinely determined AP peptides. In this work, we proposed a novel detection strategy of short analogs of AP peptides: $\mathrm{A}\beta_{3-16}$, APll-16, and their pyroglutamate counterparts related to Alzheimer's disease. The proposed approach is based on the chemometric analysis of voltammetric signals recorded in solutions of Cu(II)-A $\beta$ complexes for generating and extracting characteristic fingerprints of the different $\mathrm{A}\beta$ analogs for their further discrimination.","Tobolska, Aleksandra, Biernat, Katarzyna, Wezynfeld, Nina E., Wróblewski, Wojciech, Ciosek-Skibińska, Patrycja",,,"Electrochemical Fingerprinting for Discrimination of $\mathrm{A}\beta_{3-16}, \mathrm{A}\beta_{11-16}$ and their Pyroglutamate Counterparts, Related to Alzheimer's Disease",,,10.1109/SENSORS60989.2024.10784537 , ,,"The $\beta$-amyloid $(\mathrm{A}\beta)$ peptides are believed to be crucial for Alzheimer's disease (AD) by forming toxic oligomers in the brain, which cause neuronal death. Consequently, these peptides serve as biomarkers of AD. Various forms of AP have been identified so far, and their levels vary between healthy and afflicted individuals. Moreover, forms naturally modified through pyroglutamylation at the amino terminus are characterized by higher toxicity and resistance to proteolytic degradation. The current methods focus exclusively on the determination of the $\mathrm{A}\beta_{1-42}/\mathrm{A}\beta_{1-40}$ ratio, losing information on the broad spectrum of other forms, which could be at least as important as the routinely determined AP peptides. In this work, we proposed a novel detection strategy of short analogs of AP peptides: $\mathrm{A}\beta_{3-16}$, APll-16, and their pyroglutamate counterparts related to Alzheimer's disease. The proposed approach is based on the chemometric analysis of voltammetric signals recorded in solutions of Cu(II)-A $\beta$ complexes for generating and extracting characteristic fingerprints of the different $\mathrm{A}\beta$ analogs for their further discrimination.",,,,, ,  2024 IEEE SENSORS,Toxicology;Peptides;Fingerprint recognition;Biomarkers;Redox;Nanomaterials;Mass spectroscopy;Sensors;Alzheimer's disease;Principal component analysis;$\beta$-amyloid;Alzheimer's disease;voltammetry;machine learning,out_of_scope,
3189,"**Title**Ultrasound-assisted targeted delivery of drug-loaded nanoparticles for retinoblastoma treatment

**Abstract**Retinoblastoma, the most common eye cancer in children, requires early detection and effective treatment to improve survival rates and preserve vision. Current therapies involving Melphalan can cause toxicity with frequent use, highlighting the need for innovative, minimally invasive approaches. In this study, we developed Melphalan-loaded poly(lactic-co-glycolic) acid (PLGA) nanoparticles and evaluated their potential for ultrasound-assisted controlled drug release. We confirmed successful drug encapsulation, with nanoparticles showing efficient drug loading (95.14%) and uniform size distribution. Cumulative drug release experiments demonstrated sustained release, with 77.25% of the drug released over 120 hours. Confocal microscopy revealed enhanced cellular uptake of the model drug under ultrasound stimulation, showing a 1.58-fold increase compared to non-ultrasound conditions. Cell viability tests indicated significant antitumor effects at higher drug concentrations. These findings suggest that PLGA nanoparticles offer a promising platform for the stable incorporation and controlled release of hydrophilic antitumor drugs like Melphalan, particularly when used in conjunction with ultrasound.","Park, Jun Hon, Mehta, Sourabh Madhav, Paulmurugan, Ramasamy, Dahl, Jeremy J.",,,Ultrasound-assisted targeted delivery of drug-loaded nanoparticles for retinoblastoma treatment,,,10.1109/UFFC-JS60046.2024.10793607 , ,,"Retinoblastoma, the most common eye cancer in children, requires early detection and effective treatment to improve survival rates and preserve vision. Current therapies involving Melphalan can cause toxicity with frequent use, highlighting the need for innovative, minimally invasive approaches. In this study, we developed Melphalan-loaded poly(lactic-co-glycolic) acid (PLGA) nanoparticles and evaluated their potential for ultrasound-assisted controlled drug release. We confirmed successful drug encapsulation, with nanoparticles showing efficient drug loading (95.14%) and uniform size distribution. Cumulative drug release experiments demonstrated sustained release, with 77.25% of the drug released over 120 hours. Confocal microscopy revealed enhanced cellular uptake of the model drug under ultrasound stimulation, showing a 1.58-fold increase compared to non-ultrasound conditions. Cell viability tests indicated significant antitumor effects at higher drug concentrations. These findings suggest that PLGA nanoparticles offer a promising platform for the stable incorporation and controlled release of hydrophilic antitumor drugs like Melphalan, particularly when used in conjunction with ultrasound.",,,,, ,"  2024 IEEE Ultrasonics, Ferroelectrics, and Frequency Control Joint Symposium (UFFC-JS)",Drugs;Nanoparticles;Ultrasonic imaging;Toxicology;Minimally invasive surgery;Microscopy;Loading;Medical treatment;Acoustics;Load modeling;ultrasound;drug delivery;drug carrier;tumor therapy;retinoblastoma,out_of_scope,
3190,"**Title**Electrochemical Quantification of Erythrosine Using Poly-L-Glutamic Acid Decorated Pencil Graphite Electrode

**Abstract**The widespread utilization of food colorants, coupled with their potential toxicity, has increased substantial health concerns in the contemporary world. In response to this issue, we have developed an effective and easy method for quantifying erythrosine by utilizing voltammetric analysis and modifying the surface of the pencil graphite electrode (PGE) with a biopolymer of L-glutamic acid (GA). This sensor is a selective and sensitive analysis of the food additive, erythrosine, by employing an inexpensive electroanalytical technique. We successfully developed a PGE modified with L-GA as the sensing material for the determination of erythrosine by utilizing the differential pulse voltammetric method. The simplicity of the electrode with a high sensitivity of 12.36 $\mu $ A/ $\mu $ M/cm2 and a linear range of 0.5–6 and 10–60 $\mu $ M for erythrosine detection results in a lower detection value of 0.003 $\mu $ M and limit of quantification value as 0.01 $\mu $ M.","Devu, C., Dhiya, P., Agraja, P. S., Rejithamol, R.",,,Electrochemical Quantification of Erythrosine Using Poly-L-Glutamic Acid Decorated Pencil Graphite Electrode,,,10.1109/JSEN.2024.3521419 , ,,"The widespread utilization of food colorants, coupled with their potential toxicity, has increased substantial health concerns in the contemporary world. In response to this issue, we have developed an effective and easy method for quantifying erythrosine by utilizing voltammetric analysis and modifying the surface of the pencil graphite electrode (PGE) with a biopolymer of L-glutamic acid (GA). This sensor is a selective and sensitive analysis of the food additive, erythrosine, by employing an inexpensive electroanalytical technique. We successfully developed a PGE modified with L-GA as the sensing material for the determination of erythrosine by utilizing the differential pulse voltammetric method. The simplicity of the electrode with a high sensitivity of 12.36 $\mu $ A/ $\mu $ M/cm2 and a linear range of 0.5–6 and 10–60 $\mu $ M for erythrosine detection results in a lower detection value of 0.003 $\mu $ M and limit of quantification value as 0.01 $\mu $ M.",,,,, ,  ,Electrodes;Sensors;Graphite;Surface topography;Additives;Surface impedance;X-ray scattering;Surface morphology;Polymers;Films;Erythrosine B;L-glutamic acid (GA);pencil graphite electrode (PGE),out_of_scope,
3191,"**Title**Multi-Network Based Approach for Drug Repurposing

**Abstract**Drug discovery is a long and expensive process. Unfortunately, the pharmaceutical industry is currently facing a significant challenge of high attrition rates during drug development because most candidate molecules fail to pass toxicity studies, leading to limited availability of drugs in the market. The method of drug repurposing can be employed to address this issue, which recognizes new applications of existing drugs outside of their original intended purpose. This paper utilizes a novel complex multi-layered network (MLN) approach for aggregating drug networks of varying information into a single unified network. Under the hypothesis that drugs that are closely related will appear as neighboring nodes, using a community detection approach allows novel discovery of new applications of old and existing drugs. This paper describes a method to aggregate MLNs. Drug data is collated from DrugBank and PubChem; an adjacency matrix is created, from which the Normalized Graph Laplacian (NGL) is generated. Prior to network aggregation, eigenvectors, and Uniform Manifold Approximation and Projection (UMAP) methods were utilized to reduce the network dimension. Additionally, a nonparametric inference was implemented to test for complete spatial randomness (CSR) to check for node scattering. This novel method showed some interesting insights into old and existing drugs with respect to their neighboring drugs by revealing potential repurposing opportunities based on their proximity within the network, suggesting that closely grouped drugs may share therapeutic effects, or other properties.","Reponte, Ronan Jasper G., Rodriguez, Joshua C., Ompad, Gerard D., Ceniza-Canillo, Angie M.",,,Multi-Network Based Approach for Drug Repurposing,,,10.1109/COMNETSAT63286.2024.10862464 , ,,"Drug discovery is a long and expensive process. Unfortunately, the pharmaceutical industry is currently facing a significant challenge of high attrition rates during drug development because most candidate molecules fail to pass toxicity studies, leading to limited availability of drugs in the market. The method of drug repurposing can be employed to address this issue, which recognizes new applications of existing drugs outside of their original intended purpose. This paper utilizes a novel complex multi-layered network (MLN) approach for aggregating drug networks of varying information into a single unified network. Under the hypothesis that drugs that are closely related will appear as neighboring nodes, using a community detection approach allows novel discovery of new applications of old and existing drugs. This paper describes a method to aggregate MLNs. Drug data is collated from DrugBank and PubChem; an adjacency matrix is created, from which the Normalized Graph Laplacian (NGL) is generated. Prior to network aggregation, eigenvectors, and Uniform Manifold Approximation and Projection (UMAP) methods were utilized to reduce the network dimension. Additionally, a nonparametric inference was implemented to test for complete spatial randomness (CSR) to check for node scattering. This novel method showed some interesting insights into old and existing drugs with respect to their neighboring drugs by revealing potential repurposing opportunities based on their proximity within the network, suggesting that closely grouped drugs may share therapeutic effects, or other properties.",,,,, ,"  2024 IEEE International Conference on Communication, Networks and Satellite (COMNETSAT)",Drugs;Manifolds;Toxicology;Satellites;Laplace equations;Scattering;Complex networks;Transforms;Drug discovery;Pharmaceutical industry;drug repurposing;multi-layered networks;Neglected Tropical Diseases (NTD);Uniform Manifold Approximation and Projection (UMAP),out_of_scope,
3192,"**Title**Synthesis of Nanop Article From Coal: A Review

**Abstract**Carbon nanomaterials have sparked considerable interest due to their exceptional properties and diverse applications. Carbon dots (CDs) have surfaced as a unique class of zero-dimensional carbon nanomaterials, alongside Carbon Quantum Dots (CQDs), Graphene Quantum Dots (GQDs), and Carbonized Polymer Dots (CPDs). CDs generated from coal, like as coke, coal pitch, and coal tar, have recently grown in prominence because of their abundance, low cost, and ease of synthesis employing green and efficient technologies such H202 chemical oxidation. This review digs into the most recent breakthroughs in coal-based CD production and uses, with a particular emphasis on their potential for energy, environmental protection, biomedicine, and polymer composites. Coal-based CDs provide several advantages, including minimal toxicity, excellent biocompatibility, high chemical stability, and outstanding photophysical characteristics. As a result, they have been extensively explored in biological imaging, ion detection, photocatalysis, and optoelectronic devices. Researchers were able to precisely control the optical properties of CDs by regulating band gaps and introducing heteroatom (N, P, S, and B) doping, taking advantage of the quantum confinement effect and edge effect. Furthermore, the scalability of coal-based CDs holds the promise of widespread applications and the commercialization of environmentally friendly and cost-effective nanomaterials, which will benefit a variety of fields and improve people's quality of life. Despite significant progress, several knowledge gaps remain, demanding further research. These include understanding the structure-property relationship, developing eco-friendly synthetic approaches with improved yield and quantum yield, and exploring the potential of coal-based CDs in diverse application domains. As the research on CDs continues to gain momentum, these nanomaterials are undoubtedly becoming the focal point of scientific endeavors, driving innovations, and addressing contemporary challenges across multiple disciplines","Danmallam, Ummulkhairi Nasiru, Gimba, Abdullahi SB, Adeleke, Adekunle Akanni, Nzerem, Petrus, Salihu, Ayuba, Okafor, Ikechukwu",,,Synthesis of Nanop Article From Coal: A Review,,,10.1109/ICMEAS58693.2023.10429859 , ,,"Carbon nanomaterials have sparked considerable interest due to their exceptional properties and diverse applications. Carbon dots (CDs) have surfaced as a unique class of zero-dimensional carbon nanomaterials, alongside Carbon Quantum Dots (CQDs), Graphene Quantum Dots (GQDs), and Carbonized Polymer Dots (CPDs). CDs generated from coal, like as coke, coal pitch, and coal tar, have recently grown in prominence because of their abundance, low cost, and ease of synthesis employing green and efficient technologies such H202 chemical oxidation. This review digs into the most recent breakthroughs in coal-based CD production and uses, with a particular emphasis on their potential for energy, environmental protection, biomedicine, and polymer composites. Coal-based CDs provide several advantages, including minimal toxicity, excellent biocompatibility, high chemical stability, and outstanding photophysical characteristics. As a result, they have been extensively explored in biological imaging, ion detection, photocatalysis, and optoelectronic devices. Researchers were able to precisely control the optical properties of CDs by regulating band gaps and introducing heteroatom (N, P, S, and B) doping, taking advantage of the quantum confinement effect and edge effect. Furthermore, the scalability of coal-based CDs holds the promise of widespread applications and the commercialization of environmentally friendly and cost-effective nanomaterials, which will benefit a variety of fields and improve people's quality of life. Despite significant progress, several knowledge gaps remain, demanding further research. These include understanding the structure-property relationship, developing eco-friendly synthetic approaches with improved yield and quantum yield, and exploring the potential of coal-based CDs in diverse application domains. As the research on CDs continues to gain momentum, these nanomaterials are undoubtedly becoming the focal point of scientific endeavors, driving innovations, and addressing contemporary challenges across multiple disciplines",,,,, ,  2023 2nd International Conference on Multidisciplinary Engineering and Applied Science (ICMEAS),Photonic band gap;Quantum dots;Potential well;Coal;Production;Nanomaterials;Chemicals;Nanotechnology;Carbon nanoparticle;coal,out_of_scope,
3193,"**Title**Toxicity Detection in Soap using Deep Learning

**Abstract**One of the most generic skincare products used by the majority of the masses is soap, which is availablein a variety of colors, shapes and fragrances. People generally tend to purchase soaps based on appearances and brand but unfortunately are unaware of the harmful chemical substances which are used in the process of manufacturing which deteriorates the skin causing long term damages. Furthermore, the popular brands in the market are endorsing soaps that predominantly contain carcinogens and the consumers are not aware of the health-hazards. Deep learning principles included in the suggested technique can be utilized to forecast soap’s toxicity based on the presence of dangerous ingredients. A deep learning model is created using the previous dataset which is the most essential part of deep learning. Machine learning is used to create a categorization model once the data has been displayed to aid in characteristic analysis. The precision, recall, and F1 score performance indicators are used to assess some algorithms.","K, Ananthajothi, Prathima, Sola. Yuva, Ps, Subhiksha, V, Varshini, M, Tharun",,,Toxicity Detection in Soap using Deep Learning,,,10.1109/ICSES60034.2023.10465402 , ,,"One of the most generic skincare products used by the majority of the masses is soap, which is availablein a variety of colors, shapes and fragrances. People generally tend to purchase soaps based on appearances and brand but unfortunately are unaware of the harmful chemical substances which are used in the process of manufacturing which deteriorates the skin causing long term damages. Furthermore, the popular brands in the market are endorsing soaps that predominantly contain carcinogens and the consumers are not aware of the health-hazards. Deep learning principles included in the suggested technique can be utilized to forecast soap’s toxicity based on the presence of dangerous ingredients. A deep learning model is created using the previous dataset which is the most essential part of deep learning. Machine learning is used to create a categorization model once the data has been displayed to aid in characteristic analysis. The precision, recall, and F1 score performance indicators are used to assess some algorithms.",,,,, ,"  2023 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)",Deep learning;Toxicology;Machine learning algorithms;Shape;Image color analysis;Optical character recognition;Predictive models;pH;Deep learning;Precision;Recall;F1 score;toxicity,out_of_scope,
3194,"**Title**Bacterial Biosensor Supported in Nanoclays Intercalated With Ionic Liquids for General Toxicity Assessment

**Abstract**One of the main problems in the design of a biosensor is the composition of the biorecognition membranes since traditional synthetic polymers rely on poorly biocompatible polymerization processes, and natural biomaterials present low stability. In this work, the immobilization of bacteria in conducting materials, such as smectite-type clays modified with organic compounds, was evaluated for the development of a microbial biosensor applied to general toxicity assessment. Specifically, the montmorillonite clay-based ionic liquids were selected and designed for the development of a low-cost amperometric microbial biosensors for the rapid detection of chemical pollutants, here demonstrated by the pesticide 3.5-diclorophenol (DCP). In the biosensor, Escherichia coli (E. coli) are immobilized in the clay matrix doped with ionic liquids as sensing element and optimized to guarantee maximal bacterial retention and metabolic activity. The metabolic activity is determined using ferricyanide, which reduced by bacteria into ferrocyanide, thus producing an electrochemically quantifiable signal. Results showed the inhibitory effect of the DCP pesticide on the bacterial growth at concentrations of 8.25 ppm and then finding a maximum mean effective concentration (CE50) of 8.0 ppm, which are values lower than those currently reported in the literature.","Ospina-Rodríguez, Sergio A., Prieto-Castañeda, Natalia, Vigués, Nuria, Muñoz–Berbel, Xavier",,,Bacterial Biosensor Supported in Nanoclays Intercalated With Ionic Liquids for General Toxicity Assessment,,,10.1109/LSENS.2024.3413082 , ,,"One of the main problems in the design of a biosensor is the composition of the biorecognition membranes since traditional synthetic polymers rely on poorly biocompatible polymerization processes, and natural biomaterials present low stability. In this work, the immobilization of bacteria in conducting materials, such as smectite-type clays modified with organic compounds, was evaluated for the development of a microbial biosensor applied to general toxicity assessment. Specifically, the montmorillonite clay-based ionic liquids were selected and designed for the development of a low-cost amperometric microbial biosensors for the rapid detection of chemical pollutants, here demonstrated by the pesticide 3.5-diclorophenol (DCP). In the biosensor, Escherichia coli (E. coli) are immobilized in the clay matrix doped with ionic liquids as sensing element and optimized to guarantee maximal bacterial retention and metabolic activity. The metabolic activity is determined using ferricyanide, which reduced by bacteria into ferrocyanide, thus producing an electrochemically quantifiable signal. Results showed the inhibitory effect of the DCP pesticide on the bacterial growth at concentrations of 8.25 ppm and then finding a maximum mean effective concentration (CE50) of 8.0 ppm, which are values lower than those currently reported in the literature.",,,,, ,  ,Biosensors;Surface treatment;Liquids;Adsorption;Electrodes;Sensors;Scanning electron microscopy;Chemical and biological sensors;bacterial biosensors;dichlorophenol (DCP);Escherichia coli (E. coli);ferricyanide;general toxicity;ionic liquids;montmorillonite,out_of_scope,
3195,"**Title**Toxicity Unveiled: Understanding Online Conversations

**Abstract**Internet forums enable people to express their opinions and participate in discussions on a range of subjects in the current digital era. But sometimes, this right to free speech can lead to the dissemination of harmful remarks like hate speech, harassment, and other types of damaging material. Ensuring a secure and courteous online space requires identifying and eliminating remarks that are harmful. This research article investigates many approaches to detecting poisonous comments, including classic machine learning techniques like BOW and TF-IDF, and deep learning methods like LSTM. In addition, we explore the performance of stochastic gradient descent (SGD) regressor and decision tree models in categorizing harmful remarks using these variables. Through rigorous research and review, we show that these approaches are effective at recognizing hazardous remarks. Our findings help to build strong models for automated toxic comment detection, promoting healthier online discourse.","Patil, Ratna, Kulkarni, Swapneel, Ingole, Prajwal, Kumar, Pratiyush, Pawar, Sandesh, Rawandale, Shiltalkumar",,,Toxicity Unveiled: Understanding Online Conversations,,,10.1109/ICEECT61758.2024.10738878 , ,,"Internet forums enable people to express their opinions and participate in discussions on a range of subjects in the current digital era. But sometimes, this right to free speech can lead to the dissemination of harmful remarks like hate speech, harassment, and other types of damaging material. Ensuring a secure and courteous online space requires identifying and eliminating remarks that are harmful. This research article investigates many approaches to detecting poisonous comments, including classic machine learning techniques like BOW and TF-IDF, and deep learning methods like LSTM. In addition, we explore the performance of stochastic gradient descent (SGD) regressor and decision tree models in categorizing harmful remarks using these variables. Through rigorous research and review, we show that these approaches are effective at recognizing hazardous remarks. Our findings help to build strong models for automated toxic comment detection, promoting healthier online discourse.",,,,, ,  2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT),Deep learning;Toxicology;Accuracy;Reviews;Stochastic processes;Predictive models;Data models;Speech processing;Long short term memory;Regression tree analysis;toxic comment detection;hate speech detection;online moderation;ml;dl;bow;tf-idf;lstm;text classification;natural language processing,detection,
3196,"**Title**A Comparison of Word Embeddings for Comment Toxicity Detection: Detection Power of Computer

**Abstract**The rapid expansion of online communities and social media platforms, the issue of toxic comments has become increasingly prevalent. Toxic comments not only contribute to a negative user experience but also have the potential to propagate hate speech, harassment, and cyberbullies. Therefore, there is a pressing need for robust and efficient comment toxicity detection systems that can automatically identify and flag toxic comments. The proposed methodology involves preprocessing the data-set by removing punctuation, applying stemming and lemmatization techniques to standardize the text. The data is then transformed into a matrix representation using tokenization, padding, and word embedding techniques. In the word embedding phase, three popular algorithms, namely Word2Vec, GloVe, and FastText, are compared to determine the most suitable approach for capturing the semantic meaning of words. The architectural design comprises several layers, encompassing an embedding layer, bidirectional LSTM layer, dropout layers, and dense layers. The bidirectional LSTM layer plays a crucial role in assimilating contextual information from both preceding and subsequent words within the comment. Training involves utilizing the training set, followed by evaluation. This project addresses the crucial need for comment toxicity detection and provides an effective methodology for identifying toxic comments in online platforms. By automatically detecting and flagging toxic comments, this system can contribute to fostering a healthier and more respectful online environment. Index Terms—comment toxicity detection, social media plat-forms, toxic comments, hate speech, harassment, cyberbullies, stemming, lemmatization, word embedding, Word2Vec, GloVe, FastText, bidirectional LSTM.","R, Prasanna Kumar, G, Bharathi Mohan, R, Elakkiya, P, Varsha",,,A Comparison of Word Embeddings for Comment Toxicity Detection: Detection Power of Computer,,,10.1109/ICCSAI59793.2023.10421356 , ,,"The rapid expansion of online communities and social media platforms, the issue of toxic comments has become increasingly prevalent. Toxic comments not only contribute to a negative user experience but also have the potential to propagate hate speech, harassment, and cyberbullies. Therefore, there is a pressing need for robust and efficient comment toxicity detection systems that can automatically identify and flag toxic comments. The proposed methodology involves preprocessing the data-set by removing punctuation, applying stemming and lemmatization techniques to standardize the text. The data is then transformed into a matrix representation using tokenization, padding, and word embedding techniques. In the word embedding phase, three popular algorithms, namely Word2Vec, GloVe, and FastText, are compared to determine the most suitable approach for capturing the semantic meaning of words. The architectural design comprises several layers, encompassing an embedding layer, bidirectional LSTM layer, dropout layers, and dense layers. The bidirectional LSTM layer plays a crucial role in assimilating contextual information from both preceding and subsequent words within the comment. Training involves utilizing the training set, followed by evaluation. This project addresses the crucial need for comment toxicity detection and provides an effective methodology for identifying toxic comments in online platforms. By automatically detecting and flagging toxic comments, this system can contribute to fostering a healthier and more respectful online environment. Index Terms—comment toxicity detection, social media plat-forms, toxic comments, hate speech, harassment, cyberbullies, stemming, lemmatization, word embedding, Word2Vec, GloVe, FastText, bidirectional LSTM.",,,,, ,"  2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI)",Training;Toxicology;Semantics;Hate speech;Cyberbullying;Computer architecture;User interfaces;comment toxicity detection;social media platforms;toxic comments;hate speech;harassment;cyberbullies;stemming;lemmatization;word embedding;Word2Vec;GloVe;FastText;bidirectional LSTM,detection,
3197,"**Title**Unmasking Toxicity: A Comprehensive Analysis of Hate Speech Detection in Banglish

**Abstract**As the digital landscape expands, the rise of online hate speech presents a pressing challenge, necessitating sophis-ticated tools for effective detection and mitigation. This project focuses on the intricate linguistic landscape of Banglish a hybrid language amalgamating Bengali and English striving to develop robust models tailored to its unique characteristics. The dataset, comprising 5000 Banglish comments categorized into various hate speech types, serves as the foundation for model exploration. Our approach spans a wide variety of models, including traditional machine learning (SVM, Logistic Regression,random forest), advanced deep learning architectures and innovative hybrid models (CNN+BiLSTM). Approaches for feature extraction such word embedding, TF-IDF, and Bag-of-Words and sentiment analysis scores are adapted to the nuances of Banglish. Ethical considerations guide our development, addressing algorithmic bias and user rights. The experimental results provide a nuanced understanding of model performance, in- cluding accuracy (90%), precision, recall, and F1 score. Insights derived from these analyses contribute to the ongoing refinement of hate speech detection methodologies, advancing the field of computational linguistics and ethical artificial intelligence.","Islam, Md. Hasibul, Farzana, Kaniz, Khalil, Ibrahim, Ara, Shaneen, Shazid, Md.Ruhul Amin, Kabir Mehedi, Md Humaion",,,Unmasking Toxicity: A Comprehensive Analysis of Hate Speech Detection in Banglish,,,10.1109/ICEEICT62016.2024.10534362 , ,,"As the digital landscape expands, the rise of online hate speech presents a pressing challenge, necessitating sophis-ticated tools for effective detection and mitigation. This project focuses on the intricate linguistic landscape of Banglish a hybrid language amalgamating Bengali and English striving to develop robust models tailored to its unique characteristics. The dataset, comprising 5000 Banglish comments categorized into various hate speech types, serves as the foundation for model exploration. Our approach spans a wide variety of models, including traditional machine learning (SVM, Logistic Regression,random forest), advanced deep learning architectures and innovative hybrid models (CNN+BiLSTM). Approaches for feature extraction such word embedding, TF-IDF, and Bag-of-Words and sentiment analysis scores are adapted to the nuances of Banglish. Ethical considerations guide our development, addressing algorithmic bias and user rights. The experimental results provide a nuanced understanding of model performance, in- cluding accuracy (90%), precision, recall, and F1 score. Insights derived from these analyses contribute to the ongoing refinement of hate speech detection methodologies, advancing the field of computational linguistics and ethical artificial intelligence.",,,,, ,  2024 6th International Conference on Electrical Engineering and Information & Communication Technology (ICEEICT),Support vector machines;Adaptation models;Ethics;Sentiment analysis;Toxicology;Machine learning algorithms;Hate speech;Banglish;hate speech detection;multilingualism;deep learning;computational linguistics;ethical AI;content moderation,out_but_toxicity,
3198,"**Title**Multimodal Fusion for Abusive Speech Detection Using Liquid Neural Networks and Convolution Neural Network

**Abstract**The recent surge in the use of social media has created vast spaces for viral content that attracts attention of large crowds. This has paved the way to the misuse of these platforms making them breading grounds for toxicity and harassment. Hence there is a need for effective abuse detection methods. In our research, we leverage the ADIMA dataset to investigate abuse detection methodologies, aiming to enhance the effectiveness of existing systems. We propose a multimodal, multilingual abuse detection system that includes three main aspects: the utilization of multimodal fusion techniques for abuse detection, the application of Liquid Neural Networks (LNN) in identifying abusive text content, the use of Convolutional Neural Networks (CNN) in identifying abusive audio utterances and the extension of multimodal fusion abuse detection to cross-lingual settings. This enabled our system to detect abuses in 10 Indian languages. Our approach takes the existing works a step further as it is able to accommodate multiple modalities and multiple languages. We use Convolutional Neural Networks to analyze sound patterns from melspectrograms and Liquid Neural Networks to process text information. To consolidate the strengths of both the representation, late fusion is applied to combine the results, resulting in an ensemble model which achieves an accuracy of 77.47%, and an AUC of 77.89% on the multilingual test set.","Paval, Ks, Radhakrishnan, Vishnu, Krishnan, Km, Lal, G Jyothish, Premjith, B",,,Multimodal Fusion for Abusive Speech Detection Using Liquid Neural Networks and Convolution Neural Network,,,10.1109/ICCCNT61001.2024.10724438 , ,,"The recent surge in the use of social media has created vast spaces for viral content that attracts attention of large crowds. This has paved the way to the misuse of these platforms making them breading grounds for toxicity and harassment. Hence there is a need for effective abuse detection methods. In our research, we leverage the ADIMA dataset to investigate abuse detection methodologies, aiming to enhance the effectiveness of existing systems. We propose a multimodal, multilingual abuse detection system that includes three main aspects: the utilization of multimodal fusion techniques for abuse detection, the application of Liquid Neural Networks (LNN) in identifying abusive text content, the use of Convolutional Neural Networks (CNN) in identifying abusive audio utterances and the extension of multimodal fusion abuse detection to cross-lingual settings. This enabled our system to detect abuses in 10 Indian languages. Our approach takes the existing works a step further as it is able to accommodate multiple modalities and multiple languages. We use Convolutional Neural Networks to analyze sound patterns from melspectrograms and Liquid Neural Networks to process text information. To consolidate the strengths of both the representation, late fusion is applied to combine the results, resulting in an ensemble model which achieves an accuracy of 77.47%, and an AUC of 77.89% on the multilingual test set.",,,,, ,  2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),Voice activity detection;Liquids;Accuracy;Toxicology;Social networking (online);Convolution;Image processing;Neural networks;Convolutional neural networks;Surges;Abuse-Detection;Late Fusion;Liquid Neural Networks;Abusive Speech;Convolutional Neural Networks,out_but_toxicity,
3199,"**Title**On-line learning dynamic models for nerve detection in ultrasound videos

**Abstract**The leading advantage of Ultrasound-Guided Regional Anesthesia (UGRA) is the ability to visualize the anatomical structure of interest. The nerve detection should translate into greater efficacy, by ensuring accurate deposition and spread of local anesthetic around the target nerve. The identification of nerve is among the most difficult tasks that anesthetists can encounter in the UGRA procedure. It is important to develop an automatic nerve detection algorithm to assist the UGRA practitioners. However, robust and automated nerve detection is challenging due to inherent noise and artifacts in ultrasound images and to the variability of the nerve structure. In order to deal with such a problem we propose a new method based on learning and estimating a dynamic on-line model of nerve position consistency and confidence measure by using generalized Gaussian distribution assumption. Based on that, Naive Bayesian measure is used to indicate whether a detected nerve region is reliable or not. Experiments were conducted on 7000 ultrasound images from 10 patients achieving an average f-score of 83%.","Hadjerci, Oussama, Hafiane, Adel, Vieyres, Pierre, Conte, Donatello, Makris, Pascal, Delbos, Alain",,,On-line learning dynamic models for nerve detection in ultrasound videos,,,10.1109/ICIP.2016.7532333 , ,,"The leading advantage of Ultrasound-Guided Regional Anesthesia (UGRA) is the ability to visualize the anatomical structure of interest. The nerve detection should translate into greater efficacy, by ensuring accurate deposition and spread of local anesthetic around the target nerve. The identification of nerve is among the most difficult tasks that anesthetists can encounter in the UGRA procedure. It is important to develop an automatic nerve detection algorithm to assist the UGRA practitioners. However, robust and automated nerve detection is challenging due to inherent noise and artifacts in ultrasound images and to the variability of the nerve structure. In order to deal with such a problem we propose a new method based on learning and estimating a dynamic on-line model of nerve position consistency and confidence measure by using generalized Gaussian distribution assumption. Based on that, Naive Bayesian measure is used to indicate whether a detected nerve region is reliable or not. Experiments were conducted on 7000 ultrasound images from 10 patients achieving an average f-score of 83%.",,,,, ,  2016 IEEE International Conference on Image Processing (ICIP),Videos;Computational modeling;Ultrasonic imaging;Position measurement;Context;Gaussian distribution;Visualization;Dynamic model;feature extraction and selection;supervised learning;nerve detection;regional anesthesia,out_of_scope,
3200,"**Title**Poisoning Detection in Federated Learning System: An Adaptive Approach

**Abstract**There are two key challenges in artificial intelligence electronic medical diagnosis systems: data silos and privacy security. More and more electronic medical systems are choosing federated learning frameworks in the modeling process. However, malicious third parties join the federated learning process as data holders and launch poisoning attacks on the global model, which brings new security challenges to electronic medical systems based on federated learning. Most of the current anti-poisoning methods rely on estimating the number of poisoned nodes, but methods that do not estimate the number of poisoned nodes lack stability. This paper studies existing defense methods and designs a new algorithm for poisoning detection of computing node parameters based on weight distribution that does not rely on prior knowledge of poisoned nodes. On this basis, an adaptive optimizer is designed to solve the stability problem of poisoning detection. The experiment was tested on a sleep posture recognition dataset. Our method can still maintain good stability under attacks with infection rates as high as 50%, and can achieve over 94% accuracy under poisoning attacks.","Cheng, Anze, Qi, Lin, Lv, Liangyu, Gao, Siyuan, Li, Zhaoming",,,Poisoning Detection in Federated Learning System: An Adaptive Approach,,,10.1109/ICN60549.2023.10426100 , ,,"There are two key challenges in artificial intelligence electronic medical diagnosis systems: data silos and privacy security. More and more electronic medical systems are choosing federated learning frameworks in the modeling process. However, malicious third parties join the federated learning process as data holders and launch poisoning attacks on the global model, which brings new security challenges to electronic medical systems based on federated learning. Most of the current anti-poisoning methods rely on estimating the number of poisoned nodes, but methods that do not estimate the number of poisoned nodes lack stability. This paper studies existing defense methods and designs a new algorithm for poisoning detection of computing node parameters based on weight distribution that does not rely on prior knowledge of poisoned nodes. On this basis, an adaptive optimizer is designed to solve the stability problem of poisoning detection. The experiment was tested on a sleep posture recognition dataset. Our method can still maintain good stability under attacks with infection rates as high as 50%, and can achieve over 94% accuracy under poisoning attacks.",,,,, ,  2023 International Conference on Intelligent Communication and Networking (ICN),Adaptive systems;Toxicology;Federated learning;Stability analysis;Security;Usability;Medical diagnostic imaging;federal learning;adversarial federal learning;poisoning attack;gesture recognition;artificial intelligence security,out_of_scope,
3201,"**Title**Ammonia Detection Scheme in Breeding Pond

**Abstract**This paper uses test strips to detect the ammonia values in ponds, and a digital camera to capture the strip image color after strip been soaked in cultivation water. Once the strip color is obtained, then it is compared with the standard database to obtain the ammonia values. Finally, it will check the ammonia value is over threshold value. If exceeding the threshold, the system will alarm and automatically release the medicine into the pool to resolve the crisis of fish from death.","Chen, Wen Yuan, Sun, Rong Hung, Chen, Yuan Shan",,,Ammonia Detection Scheme in Breeding Pond,,,10.1109/IS3C.2014.46 , ,,"This paper uses test strips to detect the ammonia values in ponds, and a digital camera to capture the strip image color after strip been soaked in cultivation water. Once the strip color is obtained, then it is compared with the standard database to obtain the ammonia values. Finally, it will check the ammonia value is over threshold value. If exceeding the threshold, the system will alarm and automatically release the medicine into the pool to resolve the crisis of fish from death.",,,,, ,"  2014 International Symposium on Computer, Consumer and Control",Strips;Image color analysis;Marine animals;Standards;Databases;Water resources;Hardware;Ammonia;Breeding pond;Color detection,out_of_scope,
3202,"**Title**Accounting for Cancer Patients with Severe Outcomes: An Anomaly Detection Perspective

**Abstract**Health outcomes and radiation-induced toxicities for cancer patients undergoing radiation therapy are influenced by several factors, including the disease process, treatment plan, and various symptoms produced by both the disease and treatment. Accurate prediction and assessment of a patient’s health status are pivotal for precision and personalized healthcare, especially for patients suffering severe outcomes such as pain, depression, and sleep disorders. Motivated by the issue of extreme class imbalance, this study investigates a set of unsupervised anomaly detection approaches to classify patients with mild/intermediate and severe outcomes using patient-reported outcomes (PROs) datasets. We found that the HBOS method demonstrated superior performance for the minority class, representing cancer patients with severe health statuses. Moreover, IForest and KNN showcased good potential by effectively considering both majority and minority patients. This study may provide insightful guidelines for clinical practice.","Yan, Yang, Lominska, Christopher, Gan, Gregory N, Gao, Hao, Chen, Zhong",,,Accounting for Cancer Patients with Severe Outcomes: An Anomaly Detection Perspective,,,10.1109/BigData62323.2024.10825503 , ,,"Health outcomes and radiation-induced toxicities for cancer patients undergoing radiation therapy are influenced by several factors, including the disease process, treatment plan, and various symptoms produced by both the disease and treatment. Accurate prediction and assessment of a patient’s health status are pivotal for precision and personalized healthcare, especially for patients suffering severe outcomes such as pain, depression, and sleep disorders. Motivated by the issue of extreme class imbalance, this study investigates a set of unsupervised anomaly detection approaches to classify patients with mild/intermediate and severe outcomes using patient-reported outcomes (PROs) datasets. We found that the HBOS method demonstrated superior performance for the minority class, representing cancer patients with severe health statuses. Moreover, IForest and KNN showcased good potential by effectively considering both majority and minority patients. This study may provide insightful guidelines for clinical practice.",,,,, ,  2024 IEEE International Conference on Big Data (BigData),Toxicology;Pain;Medical treatment;Nearest neighbor methods;Depression;Radiation therapy;Anomaly detection;Cancer;Principal component analysis;Guidelines;Unsupervised classification;imbalance distribution;anomaly detection;patient-reported outcomes;severe health status;radiation therapy,out_of_scope,
3203,"**Title**An Enhanced Multimodal Negative Feedback Detection Framework with Target Retrieval in Thai Spoken Audio

**Abstract**This research addresses the challenge of effectively identifying negative feedback in spoken audio within the context of voluminous and complex user-generated content. The study introduces an integrated audio analytics framework de-signed to enhance processing speed and accuracy. The frame-work combines Query-by-Example Spoken Term Detection (QbE-STD), Speaker Diarization (SD), and Automatic Speech Recognition (ASR) with text-based feedback (sentiment, toxicity and sarcasm detection). By employing QbE-STD, the system facilitates targeted retrieval of specific terms, thus optimizing processing duration. Additionally, the application of transfer learning techniques to under-resourced languages, such as Thai, demonstrates significant improvements in the accuracy of both ASR and text-based feedback analysis. This research paves the way for future studies in large-scale analysis of audio-based negative feedback. It also highlights the potential for deploying efficient audio analytics in various fields, including content moderation and decision support systems.","Chantangphol, Pantid, Singkul, Sattaya, Lodkaew, Thanawat, Maharattanamalai, Nattasit, Petchsod, Atthakorn, Sakdejayont, Theerat, Chalothorn, Tawunrat",,,An Enhanced Multimodal Negative Feedback Detection Framework with Target Retrieval in Thai Spoken Audio,,,10.1109/ICMEW63481.2024.10645364 , ,,"This research addresses the challenge of effectively identifying negative feedback in spoken audio within the context of voluminous and complex user-generated content. The study introduces an integrated audio analytics framework de-signed to enhance processing speed and accuracy. The frame-work combines Query-by-Example Spoken Term Detection (QbE-STD), Speaker Diarization (SD), and Automatic Speech Recognition (ASR) with text-based feedback (sentiment, toxicity and sarcasm detection). By employing QbE-STD, the system facilitates targeted retrieval of specific terms, thus optimizing processing duration. Additionally, the application of transfer learning techniques to under-resourced languages, such as Thai, demonstrates significant improvements in the accuracy of both ASR and text-based feedback analysis. This research paves the way for future studies in large-scale analysis of audio-based negative feedback. It also highlights the potential for deploying efficient audio analytics in various fields, including content moderation and decision support systems.",,,,, ,  2024 IEEE International Conference on Multimedia and Expo Workshops (ICMEW),Decision support systems;Sentiment analysis;Negative feedback;Accuracy;Toxicology;Conferences;Transfer learning;Multimodal Negative Feedback Detection;Target retrieval;Transfer learning;Audio analysis;Thai,out_of_scope,
3204,"**Title**Implementation of electrochemical sensors in arsenic-contaminated areas of West Bengal in India toward rapid and point-of-use detection of arsenic in drinking water

**Abstract**The difficulty of detecting small quantities of arsenic in water currently threatens the health of millions of people worldwide, as long-term exposure to arsenic has been associated with both cancerous and noncancerous health risks. Existing technologies make it possible to very accurately quantify arsenic levels in water; however the expense, extensive training, and off-site analysis required by these methods impede wide scale-use. Electrochemical detection offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. Toward a solution to water quality interventions, we have demonstrated an affordable and point-of-use platform capable of detecting trace amounts of arsenic in groundwater samples. Our electrochemical sensor utilizes a three-electrode system with carbon, silver, and silver/silver electrodes integrated with a handheld electrochemical analyzer. We employed our sensor to investigate arsenic concentration in drinking water on-site in the arsenic affected areas of the North 24 Parganas district in West Bengal, India. 38 samples were collected from shallow, midrange, and deep wells. A small water sample from each well was applied to the electrodes and the current response was quickly captured, returning quantitative results to the user, which alleviates the lag times and imprecise colorimetric assays that encumber current arsenic detection systems.","Kim, Unyoung, VanderGiessen, Jessica, Savarimuthu, Xavier",,,Implementation of electrochemical sensors in arsenic-contaminated areas of West Bengal in India toward rapid and point-of-use detection of arsenic in drinking water,,,10.1109/GHTC.2014.6970325 , ,,"The difficulty of detecting small quantities of arsenic in water currently threatens the health of millions of people worldwide, as long-term exposure to arsenic has been associated with both cancerous and noncancerous health risks. Existing technologies make it possible to very accurately quantify arsenic levels in water; however the expense, extensive training, and off-site analysis required by these methods impede wide scale-use. Electrochemical detection offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. Toward a solution to water quality interventions, we have demonstrated an affordable and point-of-use platform capable of detecting trace amounts of arsenic in groundwater samples. Our electrochemical sensor utilizes a three-electrode system with carbon, silver, and silver/silver electrodes integrated with a handheld electrochemical analyzer. We employed our sensor to investigate arsenic concentration in drinking water on-site in the arsenic affected areas of the North 24 Parganas district in West Bengal, India. 38 samples were collected from shallow, midrange, and deep wells. A small water sample from each well was applied to the electrodes and the current response was quickly captured, returning quantitative results to the user, which alleviates the lag times and imprecise colorimetric assays that encumber current arsenic detection systems.",,,,, ,  IEEE Global Humanitarian Technology Conference (GHTC 2014),Water pollution;Electrodes;Sensors;Silver;Water resources;Pollution measurement;Electric potential;biosensors;electrochemical devices;arsenic;water contamination,out_of_scope,
3205,"**Title**Visual detection of mercury vapor using plasmonic nanoparticle array

**Abstract**The fast and sensitive detections of chemicals adsorption onto solid substrates are of importance to many fields. Ordered arrays of gold nanoparticles with strong surface plasmon resonances allow directly visualized detection of molecular scale adsorptions of mercury vapor on solid substrates. The adsorbed species change local dielectric constants surrounding plasmonic nanoparticles, leading to shifts of plasmon resonance peaks into short wavelength direction because of interactions of chemicals with nanoparticles. The magnitude of peak shifts is proportional to the amount of adsorbed chemicals in certain range, and is sufficiently large so that color changes can be seen directly by naked eyes. The ordered nanoparticles can be made over a large area at high yield, allowing a quantitative, passive, and sensitive detection of molecular species.","Wang, Chaoming, Ma, Zeyu, Hossain, Mainul, Su, Ming",,,Visual detection of mercury vapor using plasmonic nanoparticle array,,,10.1109/ICSENS.2010.5690261 , ,,"The fast and sensitive detections of chemicals adsorption onto solid substrates are of importance to many fields. Ordered arrays of gold nanoparticles with strong surface plasmon resonances allow directly visualized detection of molecular scale adsorptions of mercury vapor on solid substrates. The adsorbed species change local dielectric constants surrounding plasmonic nanoparticles, leading to shifts of plasmon resonance peaks into short wavelength direction because of interactions of chemicals with nanoparticles. The magnitude of peak shifts is proportional to the amount of adsorbed chemicals in certain range, and is sufficiently large so that color changes can be seen directly by naked eyes. The ordered nanoparticles can be made over a large area at high yield, allowing a quantitative, passive, and sensitive detection of molecular species.",,,,, ,"  SENSORS, 2010 IEEE",Nanoparticles;Gold;Glass;Plasmons;Arrays;Substrates;Optical sensors,out_of_scope,
3206,"**Title**Development of low-cost plastic microfluidic sensors toward rapid and point-of-use detection of arsenic in drinking water for global health

**Abstract**The difficulty of detecting small quantities of arsenic in water currently threatens the health of millions of people worldwide, as long-term exposure to arsenic has been associated with both cancerous and noncancerous health risks. Existing technologies make it possible to very accurately quantify arsenic levels in water; however the expense, extensive training, and off-site analysis required by these methods impede wide scale-use. Electrochemical detection in a microfluidic platform offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. Toward a solution to water quality interventions, we have demonstrated an affordable and point-of-use microfluidic platform capable of detecting trace amounts of arsenic in groundwater samples. Our electrochemical sensor utilizes a three-electrode system with carbon, silver, and silver/silver chloride ink electrodes printed onto a disposable plastic substrate. A small water sample is applied to the electrodes and the current response is quickly captured, returning quantitative information to the user, which alleviates the lag times and imprecise colorimetric assays that encumber current arsenic detection systems.","Kim, Unyoung, VanderGiessen, Jessica, Demaree, Benjamin, Reynolds, Mary, Perricone, Kyle",,,Development of low-cost plastic microfluidic sensors toward rapid and point-of-use detection of arsenic in drinking water for global health,,,10.1109/BioCAS.2013.6679652 , ,,"The difficulty of detecting small quantities of arsenic in water currently threatens the health of millions of people worldwide, as long-term exposure to arsenic has been associated with both cancerous and noncancerous health risks. Existing technologies make it possible to very accurately quantify arsenic levels in water; however the expense, extensive training, and off-site analysis required by these methods impede wide scale-use. Electrochemical detection in a microfluidic platform offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. Toward a solution to water quality interventions, we have demonstrated an affordable and point-of-use microfluidic platform capable of detecting trace amounts of arsenic in groundwater samples. Our electrochemical sensor utilizes a three-electrode system with carbon, silver, and silver/silver chloride ink electrodes printed onto a disposable plastic substrate. A small water sample is applied to the electrodes and the current response is quickly captured, returning quantitative information to the user, which alleviates the lag times and imprecise colorimetric assays that encumber current arsenic detection systems.",,,,, ,  2013 IEEE Biomedical Circuits and Systems Conference (BioCAS),Electrodes;Sensors;Silver;Ink;Water pollution;Microfluidics;Water resources;biosensors;electrochemical devices;microfluidics;lab-on-a-chip,out_of_scope,
3207,"**Title**Onboard Near-Real-Time Detection of Harmful Algal Blooms Using a Convolutional Neural Network and Multispectral Imagery from a Satellite in Low Earth Orbit

**Abstract**Freshwater harmful algal blooms (HABs) pose significant ecological and public health risks worldwide. Detecting HABs soon after they form is critical to managing the damage they cause. While in-situ measurements are more accurate at detecting and measuring their toxicity levels, satellite imagery is more adept at capturing the spatial and temporal dynamics of these blooms over large geographic regions. Satellites can also more persistently monitor for HABs. In the past, empirical methods and machine learning methods have used multispectral satellite imagery to estimate HAB biomass. To build upon the current body of research, this paper investigates an approach to expedite HAB detection by utilizing a convolutional neural network (CNN) deployed onboard a CubeSat in low Earth orbit to detect HABs in near-real-time. The CNN is trained with multispectral imagery from the Sentinel-2 satellite constellation aggregated with in-situ cyanobacteria cell counts from the Seabass CAML dataset. The results successfully demonstrated the capability of a CNN to detect cyanobacterial blooms using multispectral imagery. After classifying HAB predictions into 5 severity classes, the best performing model achieved a RMSE of 1.33 between HAB severity levels. Training the CNN on 30m GSD imagery with RGB and red edge (B05) bands achieved a RMSE of 1.83 between HAB severity levels, which was inadequate for detecting HABs in small inland water bodies. Improved performance was observed with 10m ground sample distance (GSD) band combinations. The best performing networks utilized all of Sentinel-2's 10m and 20m spectral bands.","Parsons, Jonathan D., Seto, Mae L.",,,Onboard Near-Real-Time Detection of Harmful Algal Blooms Using a Convolutional Neural Network and Multispectral Imagery from a Satellite in Low Earth Orbit,,,10.1109/OCEANS55160.2024.10754588 , ,,"Freshwater harmful algal blooms (HABs) pose significant ecological and public health risks worldwide. Detecting HABs soon after they form is critical to managing the damage they cause. While in-situ measurements are more accurate at detecting and measuring their toxicity levels, satellite imagery is more adept at capturing the spatial and temporal dynamics of these blooms over large geographic regions. Satellites can also more persistently monitor for HABs. In the past, empirical methods and machine learning methods have used multispectral satellite imagery to estimate HAB biomass. To build upon the current body of research, this paper investigates an approach to expedite HAB detection by utilizing a convolutional neural network (CNN) deployed onboard a CubeSat in low Earth orbit to detect HABs in near-real-time. The CNN is trained with multispectral imagery from the Sentinel-2 satellite constellation aggregated with in-situ cyanobacteria cell counts from the Seabass CAML dataset. The results successfully demonstrated the capability of a CNN to detect cyanobacterial blooms using multispectral imagery. After classifying HAB predictions into 5 severity classes, the best performing model achieved a RMSE of 1.33 between HAB severity levels. Training the CNN on 30m GSD imagery with RGB and red edge (B05) bands achieved a RMSE of 1.83 between HAB severity levels, which was inadequate for detecting HABs in small inland water bodies. Improved performance was observed with 10m ground sample distance (GSD) band combinations. The best performing networks utilized all of Sentinel-2's 10m and 20m spectral bands.",,,,, ,  OCEANS 2024 - Halifax,Satellites;Image edge detection;Low earth orbit satellites;Cyanobacteria;Predictive models;Extraterrestrial measurements;Data models;Satellite images;Convolutional neural networks;Spatial resolution;Convolutional Neural Network (CNN);Earth Observation;Harmful Algal Blooms (HABs);Machine Learning;Sentinel-2,out_of_scope,
3208,"**Title**Eliminating Toxicity in Text: An NLP Framework for Clean Content Extraction

**Abstract**This research study proposes a machine learning-based application called ToxiGuard, which is designed to ascertain the toxic language in text. The proposed technique employs the use of the Natural Language Processing (NLP) mechanism and a Naive Bayes based classifier to detect and categorize unhealthy or toxic comments. First the given text data is preprocessed by dividing or tokenizing the sentences into different words, once tokens are formed it will be passed as an argument into the proposed method which removes all the words which are unhealthy based on the trained model. Model takes the decision based on the patterns correlated with toxic or unhealthy language. The proposed mechanism is represented in the form of a graphical user interface (GUI) built with Tkinter. GUI being designed enables user to upload a text file which contains serious of text or sentences analysis is being done and visual representation of the outcome is plotted with help of a bar chart of the maximum frequency of each toxic words. In addition to analysis report outcome of the analysis can be exported for further review process. ToxiGuard focus to help or classify online content by providing effective and user-friendly application in-order to detect harmful or unhealthy language.","Kumar, Sharath, Dmello, Daxia Vlora, Janani, Devi, K D, Avani, P, Kirthana Kamath",,,Eliminating Toxicity in Text: An NLP Framework for Clean Content Extraction,,,10.1109/ICICNIS64247.2024.10823171 , ,,"This research study proposes a machine learning-based application called ToxiGuard, which is designed to ascertain the toxic language in text. The proposed technique employs the use of the Natural Language Processing (NLP) mechanism and a Naive Bayes based classifier to detect and categorize unhealthy or toxic comments. First the given text data is preprocessed by dividing or tokenizing the sentences into different words, once tokens are formed it will be passed as an argument into the proposed method which removes all the words which are unhealthy based on the trained model. Model takes the decision based on the patterns correlated with toxic or unhealthy language. The proposed mechanism is represented in the form of a graphical user interface (GUI) built with Tkinter. GUI being designed enables user to upload a text file which contains serious of text or sentences analysis is being done and visual representation of the outcome is plotted with help of a bar chart of the maximum frequency of each toxic words. In addition to analysis report outcome of the analysis can be exported for further review process. ToxiGuard focus to help or classify online content by providing effective and user-friendly application in-order to detect harmful or unhealthy language.",,,,, ,  2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS),Visualization;Toxicology;Sensitivity;Scalability;Feature extraction;Natural language processing;Safety;Security;Standards;Graphical user interfaces;ToxiGuard;NLP;Toxic;Unhealthy;Tkinter;Naïve based classifier,detection,
3209,"**Title**Aquasift: A low-cost, hand-held potentiostat for point-of-use electrochemical detection of contaminants in drinking water

**Abstract**The difficulty of detecting small quantities of contaminants in water supplies currently threatens the health of millions of people worldwide, as consumption of contaminated water has been associated with both cancerous and noncancerous health risks. Existing technologies make it possible to very accurately quantify contaminant levels in water; however the expense, extensive training, and off-site analysis required by these methods prevent wide scale use. Electrochemical detection offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. With a goal of water quality interventions, we have presented an affordable and point-of-use platform capable of detecting small amounts of arsenic in water samples. Our electrochemical system utilizes a three-electrode sensor integrated with a handheld, self-designed potentiostat called Aquasift. Aquasift's hardware is simplified as much as possible to maintain affordability and relies on firmware complexity to provide functionality comparable to more expensive bench top potentiostats. Several optional on-board digital filters are available for signal conditioning. The Aquasift can sample at a rate up to 1KSPS and the output data rate is adjustable from 1KSPS down to 1 sample per second. The board uses 12-bit data converters to provide a voltage resolution of 806 micro volts. The Aquasift is powered directly from the USB port and requires no additional power source. We compare the results obtained from the Aquasift of arsenic testing to those obtained from a commercially available bench top potentiostat. The results show Aquasift's comparable accuracy to the commercial analyzer, and demonstrate that our proposed system is a more affordable, portable alternative to laboratory testing.","Wu, Philip, Vazquez, Gabriela, Mikstas, Nicholas, Krishnan, Shoba, Kim, Unyoung",,,"Aquasift: A low-cost, hand-held potentiostat for point-of-use electrochemical detection of contaminants in drinking water",,,10.1109/GHTC.2017.8239306 , ,,"The difficulty of detecting small quantities of contaminants in water supplies currently threatens the health of millions of people worldwide, as consumption of contaminated water has been associated with both cancerous and noncancerous health risks. Existing technologies make it possible to very accurately quantify contaminant levels in water; however the expense, extensive training, and off-site analysis required by these methods prevent wide scale use. Electrochemical detection offers many advantages, such as portability, minimal use of instrumentation, and ready integration with electronics. With a goal of water quality interventions, we have presented an affordable and point-of-use platform capable of detecting small amounts of arsenic in water samples. Our electrochemical system utilizes a three-electrode sensor integrated with a handheld, self-designed potentiostat called Aquasift. Aquasift's hardware is simplified as much as possible to maintain affordability and relies on firmware complexity to provide functionality comparable to more expensive bench top potentiostats. Several optional on-board digital filters are available for signal conditioning. The Aquasift can sample at a rate up to 1KSPS and the output data rate is adjustable from 1KSPS down to 1 sample per second. The board uses 12-bit data converters to provide a voltage resolution of 806 micro volts. The Aquasift is powered directly from the USB port and requires no additional power source. We compare the results obtained from the Aquasift of arsenic testing to those obtained from a commercially available bench top potentiostat. The results show Aquasift's comparable accuracy to the commercial analyzer, and demonstrate that our proposed system is a more affordable, portable alternative to laboratory testing.",,,,, ,  2017 IEEE Global Humanitarian Technology Conference (GHTC),Arsenic;Water pollution;Electrodes;Connectors;Testing;Water resources;Pollution measurement;Aquasift;biosensors;potentiostats;electrochemical devices;arsenic;water contamination,out_of_scope,
3210,"**Title**Early detection of neurodegeneration in brain ischemia by manganese-enhanced MRI

**Abstract**This study aims to employ in vivo manganese-enhanced MRI (MEMRI) to detect neurodegenerative changes in two models of brain ischemia, photothrombotic cortical injury (PCI) and transient middle cerebral artery occlusion (MCAO) in rodents. After systemic Mn2+ injection to both ischemic models, a close pattern of T1-weighted hyperintensity was observed throughout different brain regions in comparison to the distribution of GFAP, MnSOD and GS immunoreactivities, whereby conventional MRI could hardly detect such. In addition, the infarct volumes in the posterior parts of the brain had significantly reduced after Mn2+ injection to the MCAO model. It is suggested that exogenous Mn2+ injection may provide enhanced MEMRI detection of oxidative stress and gliosis early after brain ischemia. Manganese may also mediate infarctions at remote brain regions in transient focal cerebral ischemia before delayed secondary damage takes place.","Chan, Kevin C., Cai, Ke-xia, Su, Huan-xing, Hung, Victor K., Cheung, Matthew M., Chiu, Chi-tat, Guo, Hua, Jian, Yang, Chung, Sookja K., Wu, Wu-tian, Wu, Ed X.",,,Early detection of neurodegeneration in brain ischemia by manganese-enhanced MRI,,,10.1109/IEMBS.2008.4650058 , ,,"This study aims to employ in vivo manganese-enhanced MRI (MEMRI) to detect neurodegenerative changes in two models of brain ischemia, photothrombotic cortical injury (PCI) and transient middle cerebral artery occlusion (MCAO) in rodents. After systemic Mn2+ injection to both ischemic models, a close pattern of T1-weighted hyperintensity was observed throughout different brain regions in comparison to the distribution of GFAP, MnSOD and GS immunoreactivities, whereby conventional MRI could hardly detect such. In addition, the infarct volumes in the posterior parts of the brain had significantly reduced after Mn2+ injection to the MCAO model. It is suggested that exogenous Mn2+ injection may provide enhanced MEMRI detection of oxidative stress and gliosis early after brain ischemia. Manganese may also mediate infarctions at remote brain regions in transient focal cerebral ischemia before delayed secondary damage takes place.",,,,, ,  2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,Brain modeling;Mice;Manganese;Magnetic resonance imaging;Rats;Transient analysis,out_of_scope,
3211,"**Title**A Sensitive Lead-Free Perovskite Photodetector for Self-Powered Blue Light Hazard Detection Application

**Abstract**The detection of blue light hazard for artificial illuminants has become a challenging issue. In this work, a self-powered narrowband photodetector based on lead-free perovskite Cs2AgBiBr6 for low-toxicity blue light hazard detection has been reported. Under zero bias, the responsivity and specific detectivity at response peak of 450 nm can reach 0.327 A/W and ${2}.{8}\times {10} ^{{10}}$ Jones, respectively. In visible light, the photodetector is only sensitive to blue light with a rejection ratio (450/510 nm) of 28.4, effectively suppressing the influence of other visible light without filters. Then an error factor is introduced to establish a relationship between the blue light weighted radiance and photocurrent. By integrating with the back-end circuit, a portable detection system is demonstrated, which can smartly evaluate the blue light hazard level of artificial illuminants. We believe that such highly sensitive and lead-free features render it a promising candidate for human eyes protection in the field of green healthcare.","An, Xiang, Zhu, Zhi-Guo, Liu, Zheng, Zhang, Xiang, Wang, Jiang, Li, Zong-Yang, Wang, Li, Wu, Chun-Yan, Liang, Feng-Xia, Song, Ping-An, Luo, Lin-Bao",,,A Sensitive Lead-Free Perovskite Photodetector for Self-Powered Blue Light Hazard Detection Application,,,10.1109/LED.2024.3394442 , ,,"The detection of blue light hazard for artificial illuminants has become a challenging issue. In this work, a self-powered narrowband photodetector based on lead-free perovskite Cs2AgBiBr6 for low-toxicity blue light hazard detection has been reported. Under zero bias, the responsivity and specific detectivity at response peak of 450 nm can reach 0.327 A/W and ${2}.{8}\times {10} ^{{10}}$ Jones, respectively. In visible light, the photodetector is only sensitive to blue light with a rejection ratio (450/510 nm) of 28.4, effectively suppressing the influence of other visible light without filters. Then an error factor is introduced to establish a relationship between the blue light weighted radiance and photocurrent. By integrating with the back-end circuit, a portable detection system is demonstrated, which can smartly evaluate the blue light hazard level of artificial illuminants. We believe that such highly sensitive and lead-free features render it a promising candidate for human eyes protection in the field of green healthcare.",,,,, ,  ,Photodetectors;Perovskites;Hazards;Photoconductivity;Lighting;Absorption;Narrowband;Lead-free perovskite;narrowband;self-powered photodetector;blue light hazard detection,out_of_scope,
3212,"**Title**In Silico-Based Toxicity Predicition Using Camel Algorithm-Support Vector Machine: Case Study NR-AhR Toxicity Type

**Abstract**Toxicity assessment is a crucial aspect of drug development, evaluating the harm a compound may inflict on an organism, notably within organ systems like the liver. This study employs the Camel Algorithm for feature selection and the Support Vector Machine (SVM) method, specifically targeting NR-AhR toxicity. Utilizing the Tox21 Data Challenge dataset, a comprehensive exploration of three SVM kernel functions-Linear, Radial Basis Function (RBF), and Polynomial-is conducted, accompanied by thorough hyperparameter tuning. The results showcase improvements across all kernels, with the RBF kernel emerging as the most effective. The optimized model, integrating the Camel Algorithm and the RBF kernel in SVM, surpasses alternative approaches, demonstrating exceptional predictive capabilities. Upon evaluation with test data, this refined model achieves an impressive accuracy of 0.921 and an Fl-Score of 0.612. In summary, this research not only contributes to the ongoing enhancement of methodologies for toxicity prediction but also presents a robust approach within the NR-AhR dataset context. The findings underscore the significance of the Camel Algorithm and SVM in advancing safer and more effective pharmaceutical development, marking a significant stride in the field.","Bamba, Renaldi Mahardika Putra, Kurniawan, Isman, Astuti, Widi",,,In Silico-Based Toxicity Predicition Using Camel Algorithm-Support Vector Machine: Case Study NR-AhR Toxicity Type,,,10.1109/ICoDSA62899.2024.10652195 , ,,"Toxicity assessment is a crucial aspect of drug development, evaluating the harm a compound may inflict on an organism, notably within organ systems like the liver. This study employs the Camel Algorithm for feature selection and the Support Vector Machine (SVM) method, specifically targeting NR-AhR toxicity. Utilizing the Tox21 Data Challenge dataset, a comprehensive exploration of three SVM kernel functions-Linear, Radial Basis Function (RBF), and Polynomial-is conducted, accompanied by thorough hyperparameter tuning. The results showcase improvements across all kernels, with the RBF kernel emerging as the most effective. The optimized model, integrating the Camel Algorithm and the RBF kernel in SVM, surpasses alternative approaches, demonstrating exceptional predictive capabilities. Upon evaluation with test data, this refined model achieves an impressive accuracy of 0.921 and an Fl-Score of 0.612. In summary, this research not only contributes to the ongoing enhancement of methodologies for toxicity prediction but also presents a robust approach within the NR-AhR dataset context. The findings underscore the significance of the Camel Algorithm and SVM in advancing safer and more effective pharmaceutical development, marking a significant stride in the field.",,,,, ,  2024 International Conference on Data Science and Its Applications (ICoDSA),Support vector machines;Toxicology;Accuracy;Predictive models;Prediction algorithms;Vectors;Data models;Camel Algorithm;Support Vector Machine;Toxicity Prediction;NR-AHR;Linear;Radial Basis Function;Polyno-mial,out_of_scope,
3213,"**Title**Cuckoo Search-Driven Optimization of Artificial Neural Networks for Accurate Fingerprint-Based Toxicity Prediction

**Abstract**Human exposure to a wide range of chemical compounds, some of which pose significant health risks, underscores the critical need to assess chemical toxicity comprehensively. Accurate toxicity assessment is pivotal for minimizing exposure to hazardous substances commonly found in everyday products. High-Throughput Screening (HTS) has traditionally been the go-to method for evaluating toxicity in large-scale chemical assessments. However, HTS has drawbacks, including time-intensive procedures and substantial research costs. Recognizing the limitations of HTS, this study explores alternative approaches to toxicity prediction. Specifically, we investigate the implementation of machine learning techniques to address the shortcomings of HTS. Our research focuses on predicting toxicity utilizing fingerprint datasets and harnessing the power of Artificial Neural Networks (ANNs), which are optimized through the innovative Cuckoo Search Algorithm (CSA). In our study, we identified optimal model configurations, highlighting the effectiveness of ANNs trained with three hidden layers and specific hidden node configurations [61, 69, 105]. Additionally, we employed the Rectified Linear Unit (ReLU) activation function. Our findings demonstrate promising performance, with an F1-Score of 0.6153 and an accuracy of 0.9652, showcasing the potential of this approach in toxicity prediction. This research opens the door to more efficient and cost-effective methods for evaluating chemical toxicity, offering a valuable alternative to conventional HTS techniques.","Rizwandy, Ryan Rizky, Aditsania, Annisa, Kurniawan, Isman",,,Cuckoo Search-Driven Optimization of Artificial Neural Networks for Accurate Fingerprint-Based Toxicity Prediction,,,10.1109/ICoABCD59879.2023.10390946 , ,,"Human exposure to a wide range of chemical compounds, some of which pose significant health risks, underscores the critical need to assess chemical toxicity comprehensively. Accurate toxicity assessment is pivotal for minimizing exposure to hazardous substances commonly found in everyday products. High-Throughput Screening (HTS) has traditionally been the go-to method for evaluating toxicity in large-scale chemical assessments. However, HTS has drawbacks, including time-intensive procedures and substantial research costs. Recognizing the limitations of HTS, this study explores alternative approaches to toxicity prediction. Specifically, we investigate the implementation of machine learning techniques to address the shortcomings of HTS. Our research focuses on predicting toxicity utilizing fingerprint datasets and harnessing the power of Artificial Neural Networks (ANNs), which are optimized through the innovative Cuckoo Search Algorithm (CSA). In our study, we identified optimal model configurations, highlighting the effectiveness of ANNs trained with three hidden layers and specific hidden node configurations [61, 69, 105]. Additionally, we employed the Rectified Linear Unit (ReLU) activation function. Our findings demonstrate promising performance, with an F1-Score of 0.6153 and an accuracy of 0.9652, showcasing the potential of this approach in toxicity prediction. This research opens the door to more efficient and cost-effective methods for evaluating chemical toxicity, offering a valuable alternative to conventional HTS techniques.",,,,, ,"  2023 International Conference on Artificial Intelligence, Blockchain, Cloud Computing, and Data Analytics (ICoABCD)",High-temperature superconductors;Toxicology;Machine learning algorithms;Artificial neural networks;Computer architecture;Fingerprint recognition;Predictive models;Toxicity;Fingerprint;Prediction;Artificial Neural Network;Cuckoo Search Algorithm,out_of_scope,
3214,"**Title**Toxicity Prediction Study of Small Molecules Based on Graph Attention Networks

**Abstract**Small molecule toxicity prediction has a very important value in many fields such as drug design and chemical biology, the establishment of small molecule toxicity prediction model can help researchers focus on the research focus, improve the efficiency of research and development, in the future will certainly be widely used for people's scientific research and production and life convenience. However, traditional machine learning methods cannot directly use molecules as inputs, and how to accurately extract molecular features is also a difficult thing. To solve the problems above, this study proposes a model based on a graph attention network, by introducing the attention mechanism also mines the connection relationship between atoms and atoms, and aggregates the feature information of other nodes weighted by the attention coefficient. The algorithm is validated on the publicly available dataset Tox21 with AUC values of 0.958, 0.829, and 0.823 on the training, validation, and test sets. Compared with the traditional convolutional neural network-based model, the AUC value is improved by 0.5% on average, which better predicts molecular toxicity.","Tong, Yaxin, Guo, Qiwei, Cui, Jianye, Peng, Xin",,,Toxicity Prediction Study of Small Molecules Based on Graph Attention Networks,,,10.1109/AIHCIR61661.2023.00107 , ,,"Small molecule toxicity prediction has a very important value in many fields such as drug design and chemical biology, the establishment of small molecule toxicity prediction model can help researchers focus on the research focus, improve the efficiency of research and development, in the future will certainly be widely used for people's scientific research and production and life convenience. However, traditional machine learning methods cannot directly use molecules as inputs, and how to accurately extract molecular features is also a difficult thing. To solve the problems above, this study proposes a model based on a graph attention network, by introducing the attention mechanism also mines the connection relationship between atoms and atoms, and aggregates the feature information of other nodes weighted by the attention coefficient. The algorithm is validated on the publicly available dataset Tox21 with AUC values of 0.958, 0.829, and 0.823 on the training, validation, and test sets. Compared with the traditional convolutional neural network-based model, the AUC value is improved by 0.5% on average, which better predicts molecular toxicity.",,,,, ,"  2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR)",Training;Toxicology;Production;Predictive models;Atoms;Feature extraction;Convolutional neural networks;Toxicity prediction;Machine Learning;Attention Mechanism;GAT,out_of_scope,
3215,"**Title**Toxicity Predicition of 3D-Domain Swapped Predicted Proteins using Machine Learning Approach

**Abstract**In this study efforts are put to createimplimention of development of a structure activity relationship (SAR) based model, that is used to anticipate toxicities and save time, testing on animals, money, chemicals at the time of protein-ligand interaction for drug development. Machine learning models are implemented on seven 3D-domain swapped proteins. In first level classification model were implemented and in second level regression model were implemented. Training dataset includes swapped proteins structure with their Pharmocological activities and contain about 501 features. Because of the extreme imbalance and abundance of characteristics in our dataset, we first carried out feature selection.then the data-preprocessing. We also implemented the K-folds cross validation for the same and the simulation results were obtained.","Pandey, A., Upadhyay, A.K.",,,Toxicity Predicition of 3D-Domain Swapped Predicted Proteins using Machine Learning Approach,,,10.1109/IC2E362166.2024.10827572 , ,,"In this study efforts are put to createimplimention of development of a structure activity relationship (SAR) based model, that is used to anticipate toxicities and save time, testing on animals, money, chemicals at the time of protein-ligand interaction for drug development. Machine learning models are implemented on seven 3D-domain swapped proteins. In first level classification model were implemented and in second level regression model were implemented. Training dataset includes swapped proteins structure with their Pharmocological activities and contain about 501 features. Because of the extreme imbalance and abundance of characteristics in our dataset, we first carried out feature selection.then the data-preprocessing. We also implemented the K-folds cross validation for the same and the simulation results were obtained.",,,,, ,"  2024 International Conference on Computer, Electronics, Electrical Engineering & their Applications (IC2E3)",Proteins;Drugs;Toxicology;Animals;Biological system modeling;Computational modeling;Machine learning;Predictive models;Safety;Chemicals;Machine learning model;feature;3D-domain swapping;proteins;accuracy,out_of_scope,
3216,"**Title**Support Vector Machine Based on Universal Kernel Function and Its Application in Quantitative Structure - Toxicity Relationship Model

**Abstract**Comparing with traditional statistical modeling methods, support vector machine (SVM) has much advantage for solving regression and classification problems. For nonlinear regression, the kernel function of SVM transforms the nonlinear input space into a high dimensional feature space in which the solution of the problem can be represented as being a linear regression problem. Therefore, in all probability the performance of SVM models is decided by the kernel function, and choosing a proper kernel function is very important. Whereas the nature of the data is usually unknown, it is very difficult to make, on beforehand, a proper choice out of the possible kernel functions. For this reason, during the model building process, usually more than one kernel is applied to select the one which gives the best prediction performance. Unfortunately, this will lead to a very time-consuming optimization procedure. To circumvent this disadvantage, a novel universal kernel function based on the Pearson VII function (PUKF) is introduced in this paper. PUKF can replace the common kernel functions, and simplifies the training process of SVM nonlinear regression. SVM based on PUKF was applied to model the Quantitative Structure-Toxicity Relationship (QSTR) to investigate its potential in nonlinear regression. As a case, the QSTR of the toxicity of a heterogeneous set of compounds to Vibrio fischeri was researched, the results showed the excellent generalization performance and robustness of the SVM based on PUKF.","Qifu, Zheng, Haifeng, Huang, Youzheng, Zhang, Guodong, Su",,,Support Vector Machine Based on Universal Kernel Function and Its Application in Quantitative Structure - Toxicity Relationship Model,,,10.1109/IFITA.2009.256 , ,,"Comparing with traditional statistical modeling methods, support vector machine (SVM) has much advantage for solving regression and classification problems. For nonlinear regression, the kernel function of SVM transforms the nonlinear input space into a high dimensional feature space in which the solution of the problem can be represented as being a linear regression problem. Therefore, in all probability the performance of SVM models is decided by the kernel function, and choosing a proper kernel function is very important. Whereas the nature of the data is usually unknown, it is very difficult to make, on beforehand, a proper choice out of the possible kernel functions. For this reason, during the model building process, usually more than one kernel is applied to select the one which gives the best prediction performance. Unfortunately, this will lead to a very time-consuming optimization procedure. To circumvent this disadvantage, a novel universal kernel function based on the Pearson VII function (PUKF) is introduced in this paper. PUKF can replace the common kernel functions, and simplifies the training process of SVM nonlinear regression. SVM based on PUKF was applied to model the Quantitative Structure-Toxicity Relationship (QSTR) to investigate its potential in nonlinear regression. As a case, the QSTR of the toxicity of a heterogeneous set of compounds to Vibrio fischeri was researched, the results showed the excellent generalization performance and robustness of the SVM based on PUKF.",,,,, ,  2009 International Forum on Information Technology and Applications,Support vector machines;Kernel;Support vector machine classification;Information technology;Predictive models;Linear regression;Biological system modeling;Educational institutions;Shape;Chemicals;support vector machine;Person VII function;quantitative structure-toxicity relationship;universal kernel function;nonlinear modeling,out_of_scope,
3217,"**Title**What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners’ Perspective

**Abstract**Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.CCS CONCEPTS• Software and its engineering → Software implementation planning.","Yu, Xiao, Zhang, Zexian, Niu, Feifei, Hu, Xing, Xia, Xin, Grundy, John",,,What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners’ Perspective,,, , ,,"Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.CCS CONCEPTS• Software and its engineering → Software implementation planning.",,,,, ,  2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE),Training;Surveys;Data integrity;Large language models;Documentation;Software;Planning;Continents;Interviews;Software engineering;Large Language Models;High-Quality Data;Practitioners’ Perspective;Empirical Study,out_of_scope,
3218,"**Title**Toxicity and Sentiment Analysis About Digital Bounty on Social Media

**Abstract**The presence of social media has a positive impact but social media is also a means for negative things to happen, such as cyberbullying, data theft, and sexual crimes. Digital bounty or competition to find perpetrators digitally is one of the activities of cyberbullying and digital vigilantism (doxing). Digital bounties have negative impacts such as psychological and socio-economic impacts on perpetrators (bounty targets) and encourage reduced public trust in applicable legal institutions. The number of opinions on social media requires sentiment classification and toxicity measurements. To get the best results, a classification method is searched for the appropriate dataset by comparison, using k-fold validation (KNN, NBC, SVM, DT), in the classification process using the selected method. Give positive opinion results, (supporting digital bounty posts of 1540 and negative of 439, and in toxicity, analysis using Communalytic, most comments in the dataset scored 0 – 0.4.","Aji, Fazjar Sekti, Iriani, Ade, Hendry",,,Toxicity and Sentiment Analysis About Digital Bounty on Social Media,,,10.1109/iCAST57874.2023.10359318 , ,,"The presence of social media has a positive impact but social media is also a means for negative things to happen, such as cyberbullying, data theft, and sexual crimes. Digital bounty or competition to find perpetrators digitally is one of the activities of cyberbullying and digital vigilantism (doxing). Digital bounties have negative impacts such as psychological and socio-economic impacts on perpetrators (bounty targets) and encourage reduced public trust in applicable legal institutions. The number of opinions on social media requires sentiment classification and toxicity measurements. To get the best results, a classification method is searched for the appropriate dataset by comparison, using k-fold validation (KNN, NBC, SVM, DT), in the classification process using the selected method. Give positive opinion results, (supporting digital bounty posts of 1540 and negative of 439, and in toxicity, analysis using Communalytic, most comments in the dataset scored 0 – 0.4.",,,,, ,  2023 12th International Conference on Awareness Science and Technology (iCAST),Support vector machines;Sentiment analysis;Toxicology;Law;Cyberbullying;Psychology;Tag clouds;sentiment analysis;toxicity analysis;doxing,out_but_toxicity,
3219,"**Title**Text Mining Domestic Extremism Topics on Multiple Social Media Platforms

**Abstract**The U.S. Capitol riot increased scholarly interest in the relationship between online platforms and domestic extremism. This study utilized text mining methods such as LDA topic modeling and toxicity analysis to assess the prominent narratives disseminated by influential far-right accounts on three social media platforms around the riot timeframe. We utilized a novel categorization system to classify topic streams into narrative frames. Parler posts contained the greatest conspiratorial content and cross-platform content sharing. Twitter was found to have a small number of far-right accounts that actively disseminate extremist views. YouTube far-right influencers produced the highest number of videos related to racial topics. Parler posts demonstrated a strong association between toxicity measures and current trending topics. A few mentions of far-right accounts within the top 20 topic streams, reveal that extreme racial and nationalist ideologies are active on the Twitter platform, even though overall toxicity was low. Our YouTube data was seeded by far-right accounts, and therefore, not surprisingly, the content was revealed to contain a high degree of racially-charged discourse. Our analysis revealed, however, that the YouTube data was also characterized by a high level of toxicity coming from both creators and commenters. Both Parler and YouTube demonstrated that some far-right content creators were able to drive up the toxicity of the discourse. These results attest to the impact social media influencers have on online discourse. Interestingly, however, the toxicity scores for related YouTube videos remained low, suggesting that the video-promotion algorithm does not necessarily increase exposure to radical content.","Mead, Esther L., McNerney, Hillary W., Agarwal, Nitin",,,Text Mining Domestic Extremism Topics on Multiple Social Media Platforms,,,10.1109/CLNLP64123.2024.00028 , ,,"The U.S. Capitol riot increased scholarly interest in the relationship between online platforms and domestic extremism. This study utilized text mining methods such as LDA topic modeling and toxicity analysis to assess the prominent narratives disseminated by influential far-right accounts on three social media platforms around the riot timeframe. We utilized a novel categorization system to classify topic streams into narrative frames. Parler posts contained the greatest conspiratorial content and cross-platform content sharing. Twitter was found to have a small number of far-right accounts that actively disseminate extremist views. YouTube far-right influencers produced the highest number of videos related to racial topics. Parler posts demonstrated a strong association between toxicity measures and current trending topics. A few mentions of far-right accounts within the top 20 topic streams, reveal that extreme racial and nationalist ideologies are active on the Twitter platform, even though overall toxicity was low. Our YouTube data was seeded by far-right accounts, and therefore, not surprisingly, the content was revealed to contain a high degree of racially-charged discourse. Our analysis revealed, however, that the YouTube data was also characterized by a high level of toxicity coming from both creators and commenters. Both Parler and YouTube demonstrated that some far-right content creators were able to drive up the toxicity of the discourse. These results attest to the impact social media influencers have on online discourse. Interestingly, however, the toxicity scores for related YouTube videos remained low, suggesting that the video-promotion algorithm does not necessarily increase exposure to radical content.",,,,, ,  2024 International Conference on Computational Linguistics and Natural Language Processing (CLNLP),Text mining;Toxicology;Video on demand;Social networking (online);Blogs;Drives;Natural language processing;Web sites;Streams;Videos;text mining;social media;domestic extremism,detection,
3220,"**Title**Transformer-Based Automated Segmentation of the Median Nerve in Ultrasound Videos of Wrist-to-Elbow Region

**Abstract**Segmenting the median nerve is essential for identifying nerve entrapment syndromes, guiding surgical planning and interventions, and furthering understanding of nerve anatomy. This study aims to develop an automated tool that can assist clinicians in localizing and segmenting the median nerve from the wrist, mid-forearm, and elbow in ultrasound videos. This is the first fully automated single deep learning model for accurate segmentation of the median nerve from the wrist to the elbow in ultrasound videos, along with the computation of the cross-sectional area (CSA) of the nerve. The visual transformer architecture, which was originally proposed to detect and classify 41 classes in YouTube videos, was modified to predict the median nerve in every frame of ultrasound videos. This is achieved by modifying the bounding box sequence matching block of the visual transformer. The median nerve segmentation is a binary class prediction, and the entire bipartite matching sequence is eliminated, enabling a direct comparison of the prediction with expert annotation in a frame-by-frame fashion. Model training, validation, and testing were performed on a dataset comprising ultrasound videos collected from 100 subjects, which were partitioned into 80, ten, and ten subjects, respectively. The proposed model was compared with U-Net, U-Net++, Siam U-Net, Attention U-Net, LSTM U-Net, and Trans U-Net. The proposed transformer-based model effectively leveraged the temporal and spatial information present in ultrasound video frames and efficiently segmented the median nerve with an average dice similarity coefficient (DSC) of approximately 94% at the wrist and 84% in the entire forearm region.","Gujarati, Karan R., Bathala, Lokesh, Venkatesh, Vaddadi, Mathew, Raji Susan, Yalavarthy, Phaneendra K.",,,Transformer-Based Automated Segmentation of the Median Nerve in Ultrasound Videos of Wrist-to-Elbow Region,,,10.1109/TUFFC.2023.3330539 , ,,"Segmenting the median nerve is essential for identifying nerve entrapment syndromes, guiding surgical planning and interventions, and furthering understanding of nerve anatomy. This study aims to develop an automated tool that can assist clinicians in localizing and segmenting the median nerve from the wrist, mid-forearm, and elbow in ultrasound videos. This is the first fully automated single deep learning model for accurate segmentation of the median nerve from the wrist to the elbow in ultrasound videos, along with the computation of the cross-sectional area (CSA) of the nerve. The visual transformer architecture, which was originally proposed to detect and classify 41 classes in YouTube videos, was modified to predict the median nerve in every frame of ultrasound videos. This is achieved by modifying the bounding box sequence matching block of the visual transformer. The median nerve segmentation is a binary class prediction, and the entire bipartite matching sequence is eliminated, enabling a direct comparison of the prediction with expert annotation in a frame-by-frame fashion. Model training, validation, and testing were performed on a dataset comprising ultrasound videos collected from 100 subjects, which were partitioned into 80, ten, and ten subjects, respectively. The proposed model was compared with U-Net, U-Net++, Siam U-Net, Attention U-Net, LSTM U-Net, and Trans U-Net. The proposed transformer-based model effectively leveraged the temporal and spatial information present in ultrasound video frames and efficiently segmented the median nerve with an average dice similarity coefficient (DSC) of approximately 94% at the wrist and 84% in the entire forearm region.",,,,, ,  ,Transformers;Videos;Ultrasonic imaging;Image segmentation;Wrist;Task analysis;Visualization;Cross-sectional area (CSA);median nerve segmentation;ultrasound video;vision transformer (ViT),out_of_scope,
3221,"**Title**Model Poisoning Attack Against Neural Network Interpreters in IoT Devices

**Abstract**Neural network models have become integral to Internet of Things (IoT) systems, with applications spanning from industrial automation to critical infrastructure management. Despite their prevalence, the deployment of these models within IoT systems introduces distinctive security vulnerabilities. In particular, adversaries may execute model poisoning attacks, which aim to alter the decision-making processes of embedded models, leading to erroneous outcomes. Existing model poisoning attacks necessitate access to extensive auxiliary datasets, such as the training dataset itself or one with same distribution. These requirements often render such attacks impractical in IoT contexts, given the constrained storage and computational resources of IoT devices. This paper proposes the first model poisoning attack against interpreters without auxiliary datasets to manipulate the model’s behavior. We evaluate the attack on three real-world datasets, and results indicate that this attack can successfully coerce the targeted interpreters to produce outcomes aligned with an adversary’s intentions, while maintaining nearly indistinguishable performance from the original model, thereby ensuring its stealthiness. Furthermore, beyond directly affected interpreters, our experiments reveal that four additional interpreters coupled to the poisoned model are indirectly influenced, underscoring the attack’s transferability.","Zhang, Xianglong, Li, Feng, Zhang, Huanle, Zhang, Haoxin, Huang, Zhijian, Fan, Lisheng, Cheng, Xiuzhen, Hu, Pengfei",,,Model Poisoning Attack Against Neural Network Interpreters in IoT Devices,,,10.1109/TMC.2024.3486218 , ,,"Neural network models have become integral to Internet of Things (IoT) systems, with applications spanning from industrial automation to critical infrastructure management. Despite their prevalence, the deployment of these models within IoT systems introduces distinctive security vulnerabilities. In particular, adversaries may execute model poisoning attacks, which aim to alter the decision-making processes of embedded models, leading to erroneous outcomes. Existing model poisoning attacks necessitate access to extensive auxiliary datasets, such as the training dataset itself or one with same distribution. These requirements often render such attacks impractical in IoT contexts, given the constrained storage and computational resources of IoT devices. This paper proposes the first model poisoning attack against interpreters without auxiliary datasets to manipulate the model’s behavior. We evaluate the attack on three real-world datasets, and results indicate that this attack can successfully coerce the targeted interpreters to produce outcomes aligned with an adversary’s intentions, while maintaining nearly indistinguishable performance from the original model, thereby ensuring its stealthiness. Furthermore, beyond directly affected interpreters, our experiments reveal that four additional interpreters coupled to the poisoned model are indirectly influenced, underscoring the attack’s transferability.",,,,, ,  ,Computational modeling;Data models;Internet of Things;Training;Predictive models;Neural networks;Monitoring;Mobile computing;Dogs;Biomedical monitoring;Interpreter;IoT devices;model poisoning attack;neural networks,out_of_scope,
3222,"**Title**Development of a radiobiological evaluation tool to assess the expected clinical impacts of contouring accuracy between manual and semi-automated segmentation algorithms

**Abstract**RADEval is a tool developed to assess the expected clinical impact of contouring accuracy when comparing manual contouring and semi-automated segmentation. The RADEval tool, designed to process large scale datasets, imported a total of 2,760 segmentation datasets, along with a Simultaneous Truth and Performance Level Estimation (STAPLE) to act as ground truth tumor segmentations. Virtual dose-maps were created within RADEval and two different tumor control probability (TCP) values using a Logistic and a Poisson TCP models were calculated in RADEval using each STAPLE and each dose-map. RADEval also virtually generated a ring of normal tissue. To evaluate clinical impact, two different uncomplicated TCP (UTCP) values were calculated in RADEval by using two TCP-NTCP correlation parameters (δ = 0 and 1). NTCP values showed that semi-automatic segmentation resulted in lower NTCP with an average 1.5 - 1.6 % regardless of STAPLE design. This was true even though each normal tissue was created from each STAPLE (p <; 0.00001). TCP and UTCP presented no statistically significant differences (p ≥ 0.1884). The intra-operator standard deviations (SDs) for TCP, NTCP and UTCP were significantly lower for the semi-automatic segmentation method regardless of STAPLE design (p <; 0.0331). Both intra-and inter-operator SDs of TCP, NTCP and UTCP were significantly lower for semi-automatic segmentation for the STAPLE 1 design (p <;0.0331). RADEval was able to efficiently process 4,920 datasets of two STAPLE designs and successfully assess the expected clinical impact of contouring accuracy.","Kim, Yusung, Patwardhan, Kaustubh Anil, Beichel, Reinhard R, Smith, Brian J., Mart, Christopher, Plichta, Kristin A., Chang, Tangel, Sonka, Milan, Graham, Michael M., Magnotta, Vince, Casavant, Thomas, Xia, Junyi, Buatti, John M.",,,Development of a radiobiological evaluation tool to assess the expected clinical impacts of contouring accuracy between manual and semi-automated segmentation algorithms,,,10.1109/EMBC.2017.8037588 , ,,"RADEval is a tool developed to assess the expected clinical impact of contouring accuracy when comparing manual contouring and semi-automated segmentation. The RADEval tool, designed to process large scale datasets, imported a total of 2,760 segmentation datasets, along with a Simultaneous Truth and Performance Level Estimation (STAPLE) to act as ground truth tumor segmentations. Virtual dose-maps were created within RADEval and two different tumor control probability (TCP) values using a Logistic and a Poisson TCP models were calculated in RADEval using each STAPLE and each dose-map. RADEval also virtually generated a ring of normal tissue. To evaluate clinical impact, two different uncomplicated TCP (UTCP) values were calculated in RADEval by using two TCP-NTCP correlation parameters (δ = 0 and 1). NTCP values showed that semi-automatic segmentation resulted in lower NTCP with an average 1.5 - 1.6 % regardless of STAPLE design. This was true even though each normal tissue was created from each STAPLE (p <; 0.00001). TCP and UTCP presented no statistically significant differences (p ≥ 0.1884). The intra-operator standard deviations (SDs) for TCP, NTCP and UTCP were significantly lower for the semi-automatic segmentation method regardless of STAPLE design (p <; 0.0331). Both intra-and inter-operator SDs of TCP, NTCP and UTCP were significantly lower for semi-automatic segmentation for the STAPLE 1 design (p <;0.0331). RADEval was able to efficiently process 4,920 datasets of two STAPLE designs and successfully assess the expected clinical impact of contouring accuracy.",,,,, ,  2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),,out_of_scope,
3223,"**Title**A software pipeline for multiple microarray data analysis

**Abstract**Microarray platforms such as Gene expression, oligonucleotide (GeneChip), and cDNA (complementary DNA) can play a critical role in the understanding of genome sequencing, by providing information for hundreds or thousands genes in a single assay, information not available by using other methodologies of investigation. Microarray experiments aim to survey patterns of gene expression by assaying the expression levels of thousands of genes in parallel in a single assay. Thus, microarray are known as high-throughput technologies, allowing the investigation of genetic variations underlying the inter-individual variability in drug pharmacokinetics/pharmacodynamics, providing a complete understanding of gene function, regulation, and interactions. Thus, to exploit all the power of this massive amount of data in the short possible time (before that data becomes obsolete), the necessity to develop databases and software tools for efficient data collection and analysis arises. The establishing of efficient and scalable software tools avoids that researcher will be overwhelming from this ever-growing flow of data. At this reason, a preliminary design of a platform named microPipe, for the multiple analysis of microarray data sets is proposed. Specifically, the paper outlines the main issues and challenges relative to the design of such a platform.","Agapito, Giuseppe, Cannataro, Mario",,,A software pipeline for multiple microarray data analysis,,,10.1109/BIBM.2017.8217956 , ,,"Microarray platforms such as Gene expression, oligonucleotide (GeneChip), and cDNA (complementary DNA) can play a critical role in the understanding of genome sequencing, by providing information for hundreds or thousands genes in a single assay, information not available by using other methodologies of investigation. Microarray experiments aim to survey patterns of gene expression by assaying the expression levels of thousands of genes in parallel in a single assay. Thus, microarray are known as high-throughput technologies, allowing the investigation of genetic variations underlying the inter-individual variability in drug pharmacokinetics/pharmacodynamics, providing a complete understanding of gene function, regulation, and interactions. Thus, to exploit all the power of this massive amount of data in the short possible time (before that data becomes obsolete), the necessity to develop databases and software tools for efficient data collection and analysis arises. The establishing of efficient and scalable software tools avoids that researcher will be overwhelming from this ever-growing flow of data. At this reason, a preliminary design of a platform named microPipe, for the multiple analysis of microarray data sets is proposed. Specifically, the paper outlines the main issues and challenges relative to the design of such a platform.",,,,, ,  2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Tools;Data analysis;Drugs;Software tools;Data mining;Bioinformatics;Genomics,out_of_scope,
3224,"**Title**Data Processing Techniques for Modern Multimodal Models

**Abstract**Data processing plays an significant role in current multimodal model training. In this paper. we provide an comprehensive review of common data processing techniques used in modern multimodal model training with a focus on diffusion models and multimodal large language models (MLLMs). We summarized all techniques into four categories: data quality, data quantity, data distribution and data safety. We further present our findings in the choice of data process methods in different type of models. This study aims to provide guidance to multimodal models developers with effective data processing techniques.","Li, Yinheng, Ding, Han, Chen, Hang",,,Data Processing Techniques for Modern Multimodal Models,,,10.1109/IPTA62886.2024.10755555 , ,,"Data processing plays an significant role in current multimodal model training. In this paper. we provide an comprehensive review of common data processing techniques used in modern multimodal model training with a focus on diffusion models and multimodal large language models (MLLMs). We summarized all techniques into four categories: data quality, data quantity, data distribution and data safety. We further present our findings in the choice of data process methods in different type of models. This study aims to provide guidance to multimodal models developers with effective data processing techniques.",,,,, ,"  2024 IEEE Thirteenth International Conference on Image Processing Theory, Tools and Applications (IPTA)",Training;Surveys;Reviews;Large language models;Training data;Data processing;Data models;Safety;Iterative methods;Standards;Data Processing;Data Augmentation;Stable Diffusion;Multimodal Large Language Model;Bias and Fairness,out_of_scope,
3225,"**Title**Nanotoxicity modeling in multidimentional cube

**Abstract**Nanotoxicity modeling can reveal the relationship between nanomaterial properties and unintended adverse effects. Traditional modeling usually builds a prediction model on the whole dataset. It does not examine the subsets of the data and their quality for model building. In this paper, we introduce a prediction cube approach to nanotoxicity modeling. Prediction cube is a new type of data cube for data exploration and predictive analytics. It can help researchers slice/dice a large amount of nanotoxicity data and measure the quality of different subsets for building prediction models. We constructed a prediction cube using a sample nanotoxicity data on zebrafish. The results show that the prediction cube can help identify useful subsets for building high quality prediction models. And the cube interface facilitates the exploration of data subsets and associated models.","Liu, Xiong, Tang, Kaizhi, Xiao, Lemin, Song, Mitchell, Xu, Roger",,,Nanotoxicity modeling in multidimentional cube,,,10.1109/BIBM.2014.6999370 , ,,"Nanotoxicity modeling can reveal the relationship between nanomaterial properties and unintended adverse effects. Traditional modeling usually builds a prediction model on the whole dataset. It does not examine the subsets of the data and their quality for model building. In this paper, we introduce a prediction cube approach to nanotoxicity modeling. Prediction cube is a new type of data cube for data exploration and predictive analytics. It can help researchers slice/dice a large amount of nanotoxicity data and measure the quality of different subsets for building prediction models. We constructed a prediction cube using a sample nanotoxicity data on zebrafish. The results show that the prediction cube can help identify useful subsets for building high quality prediction models. And the cube interface facilitates the exploration of data subsets and associated models.",,,,, ,  2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Predictive models;Data models;Nanobioscience;Materials;Data mining;Accuracy;Machine learning algorithms;Nanotoxicity;modeling;data mining;data cube;prediction cube,out_of_scope,
3226,"**Title**Exploring Machine Learning Applications and Future Prospects in Drug Discovery

**Abstract**This study aims to provide a wide-ranging investigation of the ML-based drug discovery approach by discussing ML methods, results, and outcomes at the drug development process. The methodology covers the steps of data acquisition and preprocessing, feature engineering and selection, model selection and optimization, virtual screening of drugs, prediction of response to drugs, toxicity prediction, integration of multi-omics data, and validation and deployment of an ML model. The study shows superiority of ML-driven methods in terms of speeding up the candidate selection process, prediction of drug target relationships, toxicity prognosis, and integration of multiple molecular datasets for the discovery of new therapeutic targets and biomarkers. While the models might perform seriously in metrics and such, without the model interpretability, generalization, and ethics, there comes necessity to research more and to work together with various experts. A talk is given where a clear link between accurate delivering results, ethical management and regulations as well as a fully transparent reporting as can be done is given for responsible and fair ML technology development in drug discovery is made. If we cast our eye on the future, constant improvements and capital increases in ML based methods are set to achieve a fundamental breakthrough in drug development and individualized medicine and thus ultimately turn patients lives upside down for the better also global scale.","Prabhu, M. Ramkumar, Nancy, P., Rosaline, R.Anto Arockia, Pandian, A. Pasumpon, Devipriya, A., Arunagiri, Bhuvaneswari",,,Exploring Machine Learning Applications and Future Prospects in Drug Discovery,,,10.1109/ICCSP60870.2024.10543411 , ,,"This study aims to provide a wide-ranging investigation of the ML-based drug discovery approach by discussing ML methods, results, and outcomes at the drug development process. The methodology covers the steps of data acquisition and preprocessing, feature engineering and selection, model selection and optimization, virtual screening of drugs, prediction of response to drugs, toxicity prediction, integration of multi-omics data, and validation and deployment of an ML model. The study shows superiority of ML-driven methods in terms of speeding up the candidate selection process, prediction of drug target relationships, toxicity prognosis, and integration of multiple molecular datasets for the discovery of new therapeutic targets and biomarkers. While the models might perform seriously in metrics and such, without the model interpretability, generalization, and ethics, there comes necessity to research more and to work together with various experts. A talk is given where a clear link between accurate delivering results, ethical management and regulations as well as a fully transparent reporting as can be done is given for responsible and fair ML technology development in drug discovery is made. If we cast our eye on the future, constant improvements and capital increases in ML based methods are set to achieve a fundamental breakthrough in drug development and individualized medicine and thus ultimately turn patients lives upside down for the better also global scale.",,,,, ,  2024 10th International Conference on Communication and Signal Processing (ICCSP),Drugs;Ethics;Technological innovation;Toxicology;Biological system modeling;Collaboration;Machine learning;Machine Learning;Drug Discovery;Virtual Screening;Molecular Docking;Predictive Modeling,out_of_scope,
3227,"**Title**CARDIOCARE platform: A beyond the state of the art approach for the management of elderly multimorbid patients with breast cancer therapy induced cardiac toxicity*

**Abstract**Breast cancer (BC) is the most common cancer in women in Europe and worldwide, with a high prevalence in middle-aged and older women. The last years, the evolution in the existing treatment approaches have contributed to improved clinical outcomes and survival rates. Nevertheless, BC therapy-related cardiotoxicity, poses a severe impact in the short- and long-term Quality of Life (QoL) and associated survival of the BC patients. This study demonstrates how the CARDIOCARE platform and the developed risk stratification models provides healthcare professionals with a valuable tool for effectively managing BC patients, preventing treatment induced cardiotoxicity and improving their QoL. This is accomplished through the integration of multi-source patient-specific data from patient-oriented mobile applications and wearable sensors, and by the employment of beyond the state-of-the-art data mining and machine learning approaches.","Tsiouris, Kostas M., Karanasiou, Georgia, Sfakianakis, Stelios, Manikis, George, Kalliatakis, Grigoris, Antoniades, Athos, Lakkas, Lampros, Mauri, Davide, Mazzocco, Ketti, Papakonstantinou, Andri, Filippatos, Gerasimos, Constantinidou, Anastasia, Šeruga, Bostjan, Conti, Constanza, Bucur, Anca, Pacella, Elsa, Marias, Kostas, Tsiknakis, Manolis, Fotiadis, Dimitrios I.",,,CARDIOCARE platform: A beyond the state of the art approach for the management of elderly multimorbid patients with breast cancer therapy induced cardiac toxicity*,,,10.1109/BIBM58861.2023.10385541 , ,,"Breast cancer (BC) is the most common cancer in women in Europe and worldwide, with a high prevalence in middle-aged and older women. The last years, the evolution in the existing treatment approaches have contributed to improved clinical outcomes and survival rates. Nevertheless, BC therapy-related cardiotoxicity, poses a severe impact in the short- and long-term Quality of Life (QoL) and associated survival of the BC patients. This study demonstrates how the CARDIOCARE platform and the developed risk stratification models provides healthcare professionals with a valuable tool for effectively managing BC patients, preventing treatment induced cardiotoxicity and improving their QoL. This is accomplished through the integration of multi-source patient-specific data from patient-oriented mobile applications and wearable sensors, and by the employment of beyond the state-of-the-art data mining and machine learning approaches.",,,,, ,  2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Technological innovation;Toxicology;Wearable computers;Medical treatment;Machine learning;Breast cancer;Mobile applications;Breast cancer;cardiotoxicity;risk stratification models;machine learning;mobile application,out_of_scope,
3228,"**Title**Clustering of chemical data sets for drug discovery

**Abstract**Chemoinformatics clustering algorithms are important issues for drug discovery process. So, there are many clustering algorithms that are available for analyzing large chemical data sets of medium and high dimensionality. The quality of these algorithms depends on the nature of data sets and the accuracy needed by the application. The applications of clustering algorithms in the drug discovery process are compound selection, virtual library generation, High-Throughput Screening (HTS), Quantitative Structure-Activity Relationship (QSAR) analysis and Absorption, Distribution, Metabolism, Elimination and Toxicity (ADMET) prediction. Based on Structure-Activity Relationship (SAR) model, compounds with similar structure have similar biological activities. So, clustering algorithms must group more similar compounds in one cluster. K-Means, bisecting K-Means and Ward clustering algorithms are the most popular clustering algorithms that have a wide range of applications in chemoinformatics. In this paper, a comparative study between these algorithms is presented. These algorithms are applied over homogeneous and heterogeneous chemical data sets. The results are compared to determine which algorithms are more suitable depending on the nature of data sets, computation time and accuracy of produced clusters. Accuracy is evaluated using standard deviation metric. Experimental results show that K-Means algorithm is preferable for small number of clusters for homogeneous and heterogeneous data sets in terms of time and standard deviation. Bisecting K-Means and Ward algorithms are preferable for large number of clusters for homogeneous and heterogeneous data sets in term of standard deviation, but bisecting K-Means algorithm is preferable in term of time.","Malhat, Mohamed G., Mousa, Hamdy M., El-Sisi, Ashraf B.",,,Clustering of chemical data sets for drug discovery,,,10.1109/INFOS.2014.7036702 , ,,"Chemoinformatics clustering algorithms are important issues for drug discovery process. So, there are many clustering algorithms that are available for analyzing large chemical data sets of medium and high dimensionality. The quality of these algorithms depends on the nature of data sets and the accuracy needed by the application. The applications of clustering algorithms in the drug discovery process are compound selection, virtual library generation, High-Throughput Screening (HTS), Quantitative Structure-Activity Relationship (QSAR) analysis and Absorption, Distribution, Metabolism, Elimination and Toxicity (ADMET) prediction. Based on Structure-Activity Relationship (SAR) model, compounds with similar structure have similar biological activities. So, clustering algorithms must group more similar compounds in one cluster. K-Means, bisecting K-Means and Ward clustering algorithms are the most popular clustering algorithms that have a wide range of applications in chemoinformatics. In this paper, a comparative study between these algorithms is presented. These algorithms are applied over homogeneous and heterogeneous chemical data sets. The results are compared to determine which algorithms are more suitable depending on the nature of data sets, computation time and accuracy of produced clusters. Accuracy is evaluated using standard deviation metric. Experimental results show that K-Means algorithm is preferable for small number of clusters for homogeneous and heterogeneous data sets in terms of time and standard deviation. Bisecting K-Means and Ward algorithms are preferable for large number of clusters for homogeneous and heterogeneous data sets in term of standard deviation, but bisecting K-Means algorithm is preferable in term of time.",,,,, ,  2014 9th International Conference on Informatics and Systems,Drug Discovery;Chemoinformatics;Clustering;K-Means;Bisecting K-Means;Ward,out_of_scope,
3229,"**Title**Multitask Learning with Feature Selection for Groups of Related Tasks

**Abstract**Multitask learning has been thoroughly proven to improve the generalization performance given a set of related tasks. Most multitask learning algorithm assume that all tasks are related. However, if all the tasks are not related, negative transfer of information occurs amongst the tasks, and the performance of traditional multitask learning algorithm worsens. Thus, we design an algorithm that simultaneously groups the related tasks and trains only the related task together. There are different approaches to train the related tasks in multi-task learning based on which information is shared across the tasks. These approaches either assume that the parameters of each of the tasks are situated close together, or assume that there is a common underlying latent space in the features of the tasks that is related. Most multi-task learning algorithm use either regularization method or matrix-variate priors. In our algorithm, the related tasks are tied together by a set of common features selected by each tasks. Thus, to train the related tasks together, we use spike and slab prior to select a common set of features for the related tasks, and a mixture of gaussians prior to select the set of related tasks. For validation, the developed algorithm is tested on toxicity prediction and hand written digit recognition data sets. The results show a significant improvement over multitask learning with feature selection for larger number of tasks. Further, the developed algorithm is also compared against another state of the art algorithm that similarly groups the related tasks together and proven to be better and more accurate.","Mishra, Meenakshi, Huan, Jun",,,Multitask Learning with Feature Selection for Groups of Related Tasks,,,10.1109/ICDM.2013.151 , ,,"Multitask learning has been thoroughly proven to improve the generalization performance given a set of related tasks. Most multitask learning algorithm assume that all tasks are related. However, if all the tasks are not related, negative transfer of information occurs amongst the tasks, and the performance of traditional multitask learning algorithm worsens. Thus, we design an algorithm that simultaneously groups the related tasks and trains only the related task together. There are different approaches to train the related tasks in multi-task learning based on which information is shared across the tasks. These approaches either assume that the parameters of each of the tasks are situated close together, or assume that there is a common underlying latent space in the features of the tasks that is related. Most multi-task learning algorithm use either regularization method or matrix-variate priors. In our algorithm, the related tasks are tied together by a set of common features selected by each tasks. Thus, to train the related tasks together, we use spike and slab prior to select a common set of features for the related tasks, and a mixture of gaussians prior to select the set of related tasks. For validation, the developed algorithm is tested on toxicity prediction and hand written digit recognition data sets. The results show a significant improvement over multitask learning with feature selection for larger number of tasks. Further, the developed algorithm is also compared against another state of the art algorithm that similarly groups the related tasks together and proven to be better and more accurate.",,,,, ,  2013 IEEE 13th International Conference on Data Mining,Chemicals;Slabs;Training;Vectors;Bayes methods;Equations;Mathematical model;Multi-task Learning;Expectation Propagation;Groups of Tasks;Spike and Slab Prior;Mixture of Gaussian Prior,detection,
3230,"**Title**Locking the SUMO Switch: Inhibiting Rhes and mHTT Interactions Using De Novo Design To Prevent The Spread of Huntington’s Disease

**Abstract**Huntington’s disease (HD) is a deadly neurodegener-ative disorder, claiming the lives of 2.27 million people annually. It is essential to create therapies and drugs that target the cause of the disease. HD is caused by an increase in the soluble and mutant forms of the huntingtin protein (mHTT). SUMOylation of mHTT by Rhes (ras homolog enriched in striatum) through the E3 ligase domain triggers the solubility of mHTT. The SUMOylation of mHTT by Rhes is essential for its toxicity. The spread of mHTT through the brain is facilitated by its toxicity and tunneling nanotubes (TNTs). Inhibition of the cysteine 263 residue on Rhes prevents the formation of TNTs and the spread of mHTT. A model of Rhes and mHTT was constructed using constrained docking. Anchor residues in the protein complex were identified using the web server PocketQuery, which was used to construct small-molecule inhibitors using the web server LEA3D. Eight inhibitors were found through PocketQuery and LEA3D, and an inhibitor for cysteine 263 was created. In order to predict the activity of the inhibitors, a QSAR model was constructed using open-access data on E3 ligase inhibitors. Calculations for the pKd and Gibbs free energy yielded a two-tailed P value of 0.0408 for ${p K d}$ and 0.0409 for Gibbs free energy, indicating that the Rhes- mHTT inhibitors are more efficient than the controls. Blood brain barrier permeability was tested, and five out of the nine inhibitors were predicted as blood brain barrier permeable. Molecular dynamics simulations indicated that the best SUMO E3 ligase inhibitor (ARG260) and the cysteine 263 inhibitor were stable as they had an RMSD of under $2 \mathrm{~A}^{\circ}$. Retrosynthetic pathways for the inhibitors were also calculated to facilitate wet-lab synthesis using IBM RXN, which indicated high confidence, showing non- difficult synthesis. The inhibitors had low toxicity, with an Acute Oral Toxicity Class of 4 for both inhibitors. The created drugs can also be used as a prophylactic therapy to prevent symptom onset. HD is terrible, claiming millions of lives and tearing apart families. In addition, key interacting residues of the Rhes-mHTT complex were discovered to guide further drug discovery. It is essential to create new therapies to target the SUMOylation and spread of mHTT, such as small-molecule therapies, which this research aims to address.","Krishnan, Bhavyahshree Navaneetha",,,Locking the SUMO Switch: Inhibiting Rhes and mHTT Interactions Using De Novo Design To Prevent The Spread of Huntington’s Disease,,,10.1109/NAP62956.2024.10739680 , ,,"Huntington’s disease (HD) is a deadly neurodegener-ative disorder, claiming the lives of 2.27 million people annually. It is essential to create therapies and drugs that target the cause of the disease. HD is caused by an increase in the soluble and mutant forms of the huntingtin protein (mHTT). SUMOylation of mHTT by Rhes (ras homolog enriched in striatum) through the E3 ligase domain triggers the solubility of mHTT. The SUMOylation of mHTT by Rhes is essential for its toxicity. The spread of mHTT through the brain is facilitated by its toxicity and tunneling nanotubes (TNTs). Inhibition of the cysteine 263 residue on Rhes prevents the formation of TNTs and the spread of mHTT. A model of Rhes and mHTT was constructed using constrained docking. Anchor residues in the protein complex were identified using the web server PocketQuery, which was used to construct small-molecule inhibitors using the web server LEA3D. Eight inhibitors were found through PocketQuery and LEA3D, and an inhibitor for cysteine 263 was created. In order to predict the activity of the inhibitors, a QSAR model was constructed using open-access data on E3 ligase inhibitors. Calculations for the pKd and Gibbs free energy yielded a two-tailed P value of 0.0408 for ${p K d}$ and 0.0409 for Gibbs free energy, indicating that the Rhes- mHTT inhibitors are more efficient than the controls. Blood brain barrier permeability was tested, and five out of the nine inhibitors were predicted as blood brain barrier permeable. Molecular dynamics simulations indicated that the best SUMO E3 ligase inhibitor (ARG260) and the cysteine 263 inhibitor were stable as they had an RMSD of under $2 \mathrm{~A}^{\circ}$. Retrosynthetic pathways for the inhibitors were also calculated to facilitate wet-lab synthesis using IBM RXN, which indicated high confidence, showing non- difficult synthesis. The inhibitors had low toxicity, with an Acute Oral Toxicity Class of 4 for both inhibitors. The created drugs can also be used as a prophylactic therapy to prevent symptom onset. HD is terrible, claiming millions of lives and tearing apart families. In addition, key interacting residues of the Rhes-mHTT complex were discovered to guide further drug discovery. It is essential to create new therapies to target the SUMOylation and spread of mHTT, such as small-molecule therapies, which this research aims to address.",,,,, ,  2024 IEEE 14th International Conference Nanomaterials: Applications & Properties (NAP),Proteins;Toxicology;Inhibitors;Medical treatment;Brain modeling;Web servers;Stability analysis;Blood;Diseases;Testing;Rhes;mutant huntingtin;de novo design;Huntington’s Disease,out_of_scope,
3231,"**Title**A Federated Learning Aggregation that Integrates Clustering and Momentum Correction Based on Historical High-Quality Gradients

**Abstract**Nowadays, federated learning emerges as a new technique to preserve data privacy in distributed machine learning by limiting local data to the client and only aggregating model parameters from multiple parties on the server side. However, it also faces consequent threats from malicious clients, and some methods have been proposed without sufficient defense capability and efficient aggregation. To address these problems, we propose a novel aggregation algorithm, which incorporates PCA operation and clustering to select the excellent client in each round; and brings in a momentum-accelerated historical quality gradient-based approach to increase the weight when the performances of the global model are consistently degraded, which can achieve faster convergence on the basis of ensuring that the update direction of the global model is not manipulated by malicious nodes. Experimental results on the MNIST datasets show that our algorithm is only 0.93% lower than FedAvg under a no-attack scenario, and exhibits faster convergence compared to Krum, Multi-Krum, and Trimmed Mean Aggregation, and the accuracy improves 10.68%,35.83%,19.65% under Black-Box Edge Attack, Sign Flipping Attack, and Same Value Attack.","Xu, Jian, Guo, Bing, Chen, Fei, Shen, Yan, Dai, Shengxin, Dai, Cheng",,,A Federated Learning Aggregation that Integrates Clustering and Momentum Correction Based on Historical High-Quality Gradients,,,10.1109/ISPA-BDCloud-SocialCom-SustainCom59178.2023.00110 , ,,"Nowadays, federated learning emerges as a new technique to preserve data privacy in distributed machine learning by limiting local data to the client and only aggregating model parameters from multiple parties on the server side. However, it also faces consequent threats from malicious clients, and some methods have been proposed without sufficient defense capability and efficient aggregation. To address these problems, we propose a novel aggregation algorithm, which incorporates PCA operation and clustering to select the excellent client in each round; and brings in a momentum-accelerated historical quality gradient-based approach to increase the weight when the performances of the global model are consistently degraded, which can achieve faster convergence on the basis of ensuring that the update direction of the global model is not manipulated by malicious nodes. Experimental results on the MNIST datasets show that our algorithm is only 0.93% lower than FedAvg under a no-attack scenario, and exhibits faster convergence compared to Krum, Multi-Krum, and Trimmed Mean Aggregation, and the accuracy improves 10.68%,35.83%,19.65% under Black-Box Edge Attack, Sign Flipping Attack, and Same Value Attack.",,,,, ,"  2023 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)",Limiting;Federated learning;Clustering algorithms;Distributed databases;Robustness;Security;Servers;Federated learning;Secure aggregation;Momentum correction;Clustering,out_of_scope,
3232,"**Title**Optimisation of Classifier Ensemble for Predictive Toxicology Applications

**Abstract**Ensembles of classifiers proved potential in getting higher accuracy compared to a single classifier. High diversity in an ensemble may improve the performance results significantly. We propose an ensemble approach which has diversity calculated using disagreement measure of classification output. A CRS (Classifier Ranking System) is introduced for the selection of relevant classifiers. We also propose the Optimisation of Classifiers Ensemble Method (OCEM) technique which applies to the ensemble selection. In this paper, we focus on classification models for predictive toxicology applications, for which computational models are required to replace in vivo experiments. The results show that our method performs well in selecting the relevant ensemble model to improve the prediction from a collection of classifiers.","Makhtar, Mokhairi, Yang, Longzhi, Neagu, Daniel, Ridley, Mick",,,Optimisation of Classifier Ensemble for Predictive Toxicology Applications,,,10.1109/UKSim.2012.41 , ,,"Ensembles of classifiers proved potential in getting higher accuracy compared to a single classifier. High diversity in an ensemble may improve the performance results significantly. We propose an ensemble approach which has diversity calculated using disagreement measure of classification output. A CRS (Classifier Ranking System) is introduced for the selection of relevant classifiers. We also propose the Optimisation of Classifiers Ensemble Method (OCEM) technique which applies to the ensemble selection. In this paper, we focus on classification models for predictive toxicology applications, for which computational models are required to replace in vivo experiments. The results show that our method performs well in selecting the relevant ensemble model to improve the prediction from a collection of classifiers.",,,,, ,  2012 UKSim 14th International Conference on Computer Modelling and Simulation,Predictive models;Accuracy;Toxicology;Data models;Diversity reception;Computational modeling;Classification algorithms;Classifier Ensemble;Decision Fusion Strategy;Classifiers Ranking Value,out_of_scope,
3233,"**Title**Data-based modeling and prediction of cytotoxicity on microelectronic sensors

**Abstract**This paper is concerned with dynamic modeling, prediction and analysis of cell cytotoxicity. A real-time cell electronic sensing (RT-CES) system has been used for continuously monitoring dynamic cytotoxicity responses of living cells. Cells are grown onto the surfaces of the microelectronic sensors. Changes in cell number expressed as cell index (CI) have been recorded on-line as time series. The CI data are used to develop dynamic prediction models for cell cytotoxicity process. We consider Support Vector Regression (SVR) algorithm to implement data-based system identification. Through several validation studies, multi-step-ahead predictions are calculated and compared with the actual CI. It is shown that SVR-based dynamic modeling has great potential in predicting the cytotoxicity response of the cells in the presence of toxicant.","Khatibisepehr, Shima, Ibrahim, Fadi, Xing, James Z., Roa, Wilson, Huang, Biao",,,Data-based modeling and prediction of cytotoxicity on microelectronic sensors,,, , ,,"This paper is concerned with dynamic modeling, prediction and analysis of cell cytotoxicity. A real-time cell electronic sensing (RT-CES) system has been used for continuously monitoring dynamic cytotoxicity responses of living cells. Cells are grown onto the surfaces of the microelectronic sensors. Changes in cell number expressed as cell index (CI) have been recorded on-line as time series. The CI data are used to develop dynamic prediction models for cell cytotoxicity process. We consider Support Vector Regression (SVR) algorithm to implement data-based system identification. Through several validation studies, multi-step-ahead predictions are calculated and compared with the actual CI. It is shown that SVR-based dynamic modeling has great potential in predicting the cytotoxicity response of the cells in the presence of toxicant.",,,,, ,  2011 International Symposium on Advanced Control of Industrial Processes (ADCONIP),Indexes;Predictive models;Training;Mathematical model;Computer architecture;Mercury (metals);Microprocessors,out_of_scope,
3234,"**Title**MP-MIENN: predicting multifunctional peptides by neural network with multiangle initialization embedding

**Abstract**Functional peptide has been utilized widely in the treatment of disease due to its high absorption rate, low toxicity, and biological activity, making it a possible substitute for traditional antibiotic medications in the biomedical field. A number of machine learning methods have been developed recently for the prediction of functional peptides. However, few studies take into account multifunctional peptide identification, and the majority mainly depends on statistical features. Therefore, in the imbalanced multi-label functional peptide datasets, we propose a novel predictor, MP-MIENN. Firstly, we use physicochemical and evolutionary information to describe the peptide sequence's initiation features from different perspectives. Secondly, to extract more discriminative features of peptide sequences of varying lengths, the features are combined and then fed into a deep neural network. Ultimately, a novel loss function is developed to substitute for the traditional cross entropy loss function in order to handle the class imbalance issues. The results demonstrate that our approach improves accuracy over existing approaches by 3.89% on publicly available peptide datasets, while significantly improving the model's efficacious capacity to capture sequence information.","Xu, Jing, Ruan, Xiaoli, Yang, Jing, Xia, Sina, Li, Shaobo",,,MP-MIENN: predicting multifunctional peptides by neural network with multiangle initialization embedding,,,10.1109/ICCC59590.2023.10507686 , ,,"Functional peptide has been utilized widely in the treatment of disease due to its high absorption rate, low toxicity, and biological activity, making it a possible substitute for traditional antibiotic medications in the biomedical field. A number of machine learning methods have been developed recently for the prediction of functional peptides. However, few studies take into account multifunctional peptide identification, and the majority mainly depends on statistical features. Therefore, in the imbalanced multi-label functional peptide datasets, we propose a novel predictor, MP-MIENN. Firstly, we use physicochemical and evolutionary information to describe the peptide sequence's initiation features from different perspectives. Secondly, to extract more discriminative features of peptide sequences of varying lengths, the features are combined and then fed into a deep neural network. Ultimately, a novel loss function is developed to substitute for the traditional cross entropy loss function in order to handle the class imbalance issues. The results demonstrate that our approach improves accuracy over existing approaches by 3.89% on publicly available peptide datasets, while significantly improving the model's efficacious capacity to capture sequence information.",,,,, ,  2023 9th International Conference on Computer and Communications (ICCC),Representation learning;Toxicology;Peptides;Computational modeling;Artificial neural networks;Predictive models;Feature extraction;functional peptide;multilabel classification;deep neural networks;class imbalance,out_of_scope,
3235,"**Title**SafeCultural: A Dataset for Evaluating Safety and Cultural Sensitivity in Large Language Models

**Abstract**The increasing use of Large Language Models (LLMs) in daily life raises important questions about ensuring their trustworthiness. While existing datasets are widely used to evaluate issues like safety and hallucinations, they often overlook important factors like social norms and cultural sensitivity. This paper introduces a dataset that incorporates regional cultural aspects, allowing LLMs to be more adaptable across diverse contexts. This dataset covers aspects of both safety and cultural sensitivity. The safety component includes seven dimensions: Unlawful Conduct, Toxicity, Violence, Privacy Violations, Harms to Minors, Adult Content, and Mental Health Issues. Cultural sensitivity is divided into three categories: Beliefs, Behaviors, and Safety. We tested across seven LLMs, the dataset aims to help models overcome cultural barriers, fostering user-friendly and culturally aware development. Furthermore, we provide guidelines for creating and evaluating culturally sensitive prompts to ensure they meet safety and cultural standards. The finding of this paper may help the development of more adaptable, culturally aware, and trustworthy LLMs for daily use.","Vongpradit, Pawat, Imsombut, Aurawan, Kongyoung, Sarawoot, Damrongrat, Chaianun, Phaholphinyo, Sitthaa, Tanawong, Tanik",,,SafeCultural: A Dataset for Evaluating Safety and Cultural Sensitivity in Large Language Models,,,10.1109/InCIT63192.2024.10810548 , ,,"The increasing use of Large Language Models (LLMs) in daily life raises important questions about ensuring their trustworthiness. While existing datasets are widely used to evaluate issues like safety and hallucinations, they often overlook important factors like social norms and cultural sensitivity. This paper introduces a dataset that incorporates regional cultural aspects, allowing LLMs to be more adaptable across diverse contexts. This dataset covers aspects of both safety and cultural sensitivity. The safety component includes seven dimensions: Unlawful Conduct, Toxicity, Violence, Privacy Violations, Harms to Minors, Adult Content, and Mental Health Issues. Cultural sensitivity is divided into three categories: Beliefs, Behaviors, and Safety. We tested across seven LLMs, the dataset aims to help models overcome cultural barriers, fostering user-friendly and culturally aware development. Furthermore, we provide guidelines for creating and evaluating culturally sensitive prompts to ensure they meet safety and cultural standards. The finding of this paper may help the development of more adaptable, culturally aware, and trustworthy LLMs for daily use.",,,,, ,  2024 8th International Conference on Information Technology (InCIT),Training;Adaptation models;Privacy;Sensitivity;Toxicology;Large language models;Safety;Cultural differences;Standards;Guidelines;Trustworthiness;Safety;Cultural;LLMS,Gen_dataset,
3236,"**Title**Generative Adversarial Network-Based Augmentation With Noval 2-Step Authentication for Anti-Coronavirus Peptide Prediction

**Abstract**The virus poses a longstanding and enduring danger to various forms of life. Despite the ongoing endeavors to combat viral diseases, there exists a necessity to explore and develop novel therapeutic options. Antiviral peptides are bioactive molecules with a favorable toxicity profile, making them promising alternatives for viral infection treatment. Therefore, this article employed a generative adversarial network for antiviral peptide augmentation and a novel two-step authentication process for augmented synthetic peptides to enhance antiviral activity prediction. Additionally, five widely utilized deep learning models were employed for classification purposes. Initially, a GAN was used to augment the antiviral peptide. In a two-step authentication process, the NCBI-BLAST was utilized to identify the antiviral activity resemblance between the synthetic and real peptide. Subsequently, the hydrophobicity, hydrophilicity, hydroxylic nature, positive charge, and negative charge of synthetic and authentic antiviral peptides were compared before their utilization. Later, to examine the impact of authenticated peptide augmentation in the prediction of antiviral peptides, a comparison is conducted with the outcomes of non-peptide augmented prediction. The study demonstrates that the 1-D convolution neural network with augmented peptide exhibits superior performance compared to other employed classifiers and state-of-the-art models. The network attains a mean classification accuracy of 95.41%, an AUC value of 0.95, and an MCC value of 0.90 on the benchmark antiviral and anti-corona peptides dataset. Thus, the performance of the proposed model indicates its efficacy in predicting the antiviral activity of peptides.","Kumar, Aditya, Singh, Deepak",,,Generative Adversarial Network-Based Augmentation With Noval 2-Step Authentication for Anti-Coronavirus Peptide Prediction,,,10.1109/TCBB.2024.3431688 , ,,"The virus poses a longstanding and enduring danger to various forms of life. Despite the ongoing endeavors to combat viral diseases, there exists a necessity to explore and develop novel therapeutic options. Antiviral peptides are bioactive molecules with a favorable toxicity profile, making them promising alternatives for viral infection treatment. Therefore, this article employed a generative adversarial network for antiviral peptide augmentation and a novel two-step authentication process for augmented synthetic peptides to enhance antiviral activity prediction. Additionally, five widely utilized deep learning models were employed for classification purposes. Initially, a GAN was used to augment the antiviral peptide. In a two-step authentication process, the NCBI-BLAST was utilized to identify the antiviral activity resemblance between the synthetic and real peptide. Subsequently, the hydrophobicity, hydrophilicity, hydroxylic nature, positive charge, and negative charge of synthetic and authentic antiviral peptides were compared before their utilization. Later, to examine the impact of authenticated peptide augmentation in the prediction of antiviral peptides, a comparison is conducted with the outcomes of non-peptide augmented prediction. The study demonstrates that the 1-D convolution neural network with augmented peptide exhibits superior performance compared to other employed classifiers and state-of-the-art models. The network attains a mean classification accuracy of 95.41%, an AUC value of 0.95, and an MCC value of 0.90 on the benchmark antiviral and anti-corona peptides dataset. Thus, the performance of the proposed model indicates its efficacy in predicting the antiviral activity of peptides.",,,,, ,  ,Peptides;Predictive models;Generative adversarial networks;Accuracy;Authentication;Task analysis;COVID-19;2-step authentication;anti-corona peptides identification;antiviral peptides identification;deep learning model;generative adversarial network(GAN);peptide augmentation,out_of_scope,
3237,"**Title**Machine Learning-Guided Production of a Self-Nanoemulsifying System for Delivery of Anacardic Acid

**Abstract**Bioactive molecules from plants remain an important source of drug candidates. However, these have poor in vivo performance due to low water solubility leading to inadequate distribution, which can be counteracted by oil-in-water nanoemulsion drug delivery systems. A limitation preventing the widespread adoption of nanoemulsions is the expensive, time-consuming iterative development process. In this study, we developed a nanoemulsion design by machine learning (ML). We retrieved average particle size and polydispersity index (PDI) data associated to nanoemulsion composition to construct a dataset from literature. A predictive ML model was used to identify improved self-nanoemulsifying systems including olive oil as base and combinations of Tween 20, Tween 80, glycerol, and soy lecithin. The predictive power of the model was determined by Dynamic Light Scattering. The nanoemulsions were loaded with pure anacardic acid. Encapsulation efficiency (EE%) was measured by HPLC, and the cytotoxic activity was evaluated on HEPG2, a human hepatic cancer cell line, and HEK-293, a normal-like human embryonic kidney cell line. The model’s accuracy was 83%. The best-performing formulation was 10% olive oil, 60% Tween 20, and 30% glycerol, exhibiting average particle size of $162.8 \pm 26 \mathrm{~nm}$, a PDI of $0.234 \pm 0.03$, and full EE%. The naked nanoemulsion presented no toxicity in HEK-293 but exerted an inhibitory effect on HEPG2. Moreover, loading the solution into the nanoemulsion increased the cytotoxic effect on HEPG2 in comparison to the naked nanoemulsion, and free anacardic acid, yielding an IC50 value of $12.4 \pm 0.3 \mu \mathrm{M}$. These results suggest that the formulation identified by the model was a successful carrier of the compound. This study presents a proof of concept on how ML can reduce the development pipeline of nanoemulsified drug delivery systems.","Prieto-Medrano, Cassandra, Garcia-Varela, Rebeca, Sánchez-Ante, Gildardo, Zavala-Martinez, Araceli, Sánchez-López, Angélica, Cavazos-Garduño, Adriana, Perfecto-Avalos, Yocanxóchitl",,,Machine Learning-Guided Production of a Self-Nanoemulsifying System for Delivery of Anacardic Acid,,,10.1109/NAP62956.2024.10739709 , ,,"Bioactive molecules from plants remain an important source of drug candidates. However, these have poor in vivo performance due to low water solubility leading to inadequate distribution, which can be counteracted by oil-in-water nanoemulsion drug delivery systems. A limitation preventing the widespread adoption of nanoemulsions is the expensive, time-consuming iterative development process. In this study, we developed a nanoemulsion design by machine learning (ML). We retrieved average particle size and polydispersity index (PDI) data associated to nanoemulsion composition to construct a dataset from literature. A predictive ML model was used to identify improved self-nanoemulsifying systems including olive oil as base and combinations of Tween 20, Tween 80, glycerol, and soy lecithin. The predictive power of the model was determined by Dynamic Light Scattering. The nanoemulsions were loaded with pure anacardic acid. Encapsulation efficiency (EE%) was measured by HPLC, and the cytotoxic activity was evaluated on HEPG2, a human hepatic cancer cell line, and HEK-293, a normal-like human embryonic kidney cell line. The model’s accuracy was 83%. The best-performing formulation was 10% olive oil, 60% Tween 20, and 30% glycerol, exhibiting average particle size of $162.8 \pm 26 \mathrm{~nm}$, a PDI of $0.234 \pm 0.03$, and full EE%. The naked nanoemulsion presented no toxicity in HEK-293 but exerted an inhibitory effect on HEPG2. Moreover, loading the solution into the nanoemulsion increased the cytotoxic effect on HEPG2 in comparison to the naked nanoemulsion, and free anacardic acid, yielding an IC50 value of $12.4 \pm 0.3 \mu \mathrm{M}$. These results suggest that the formulation identified by the model was a successful carrier of the compound. This study presents a proof of concept on how ML can reduce the development pipeline of nanoemulsified drug delivery systems.",,,,, ,  2024 IEEE 14th International Conference Nanomaterials: Applications & Properties (NAP),Encapsulation;Oils;Loading;Machine learning;Predictive models;Particle measurements;Drug delivery;Biological cells;Load modeling;Cancer;nanobiomedicine;phytoextracts;selfnanoemulsification;machine learning,out_of_scope,
3238,"**Title**LEMTL: Enhancing the pharmacokinetic predictions of multitask learning with existing pharmacokinetics

**Abstract**Evaluation of pharmacokinetic properties such as absorption, distribution, metabolism, excretion, and toxicity is essential but costly and time-consuming in the research and development of new drug candidates. This challenge has driven many researchers to use multitask learning for in silico predictions. Given extra information such as SMILES (simplified molecular input line entry system) as input data, existing multitask learning methods can usually have a good performance in predicting pharmacokinetics, which are served as labels/tasks. However, most of these methods are based solely on additional information, overlooking potentially available pharmacokinetics, which can be utilized to further enhance the prediction of unavailable ones. To address this limitation, we propose Label Enhanced MultiTask Learning (LEMTL), a framework to improve the prediction accuracy of unknown pharmacokinetics of existing multitask learning methods by aggregating shared feature representations learned from additional information and from known pharmacokinetics. Experiments on synthetic and real datasets demonstrate significant improvements over the associated multitask learning approaches when incorporated within the LEMTL framework.","Li, Ying, Deng, Xiao, Lv, Jingsong, Chen, Hongyang, Yang, Yao",,,LEMTL: Enhancing the pharmacokinetic predictions of multitask learning with existing pharmacokinetics,,,10.1109/BIBM62325.2024.10822596 , ,,"Evaluation of pharmacokinetic properties such as absorption, distribution, metabolism, excretion, and toxicity is essential but costly and time-consuming in the research and development of new drug candidates. This challenge has driven many researchers to use multitask learning for in silico predictions. Given extra information such as SMILES (simplified molecular input line entry system) as input data, existing multitask learning methods can usually have a good performance in predicting pharmacokinetics, which are served as labels/tasks. However, most of these methods are based solely on additional information, overlooking potentially available pharmacokinetics, which can be utilized to further enhance the prediction of unavailable ones. To address this limitation, we propose Label Enhanced MultiTask Learning (LEMTL), a framework to improve the prediction accuracy of unknown pharmacokinetics of existing multitask learning methods by aggregating shared feature representations learned from additional information and from known pharmacokinetics. Experiments on synthetic and real datasets demonstrate significant improvements over the associated multitask learning approaches when incorporated within the LEMTL framework.",,,,, ,  2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Learning systems;Drugs;Toxicology;Accuracy;Absorption;Feature extraction;Pharmacokinetics;Metabolism;Bioinformatics;Research and development;pharmacokinetics;ADMET;multitask learning;label enhanced,out_of_scope,
3239,"**Title**Optimized Quantification of Multiple Drug Concentrations by WeightedMSE With Machine Learning on Electrochemical Sensor

**Abstract**Quantification of multiple drugs is of great importance and urgently needed in therapeutic drug monitoring (TDM) and personalized therapy. Especially, based on cyclic voltammograms (CVs) obtained by electrochemical sensors, the use of artificial neural networks (ANNs) has been widely attempted in the accurate quantification of drug concentrations, enabling the development of point-of-care and potentially system-level wearable devices. However, most of the work only considers the accuracy of how the predicted value is close to the actual value, which does not consider whether the predicted drug concentration is underestimated. In practical drug quantification, potential toxicity due to overexposure with underestimated quantification can lead to endangering the patient's body. Therefore, avoiding underestimating the concentration of drugs based on existing quantification models is required and necessary to optimize the conventional loss function at the output stage of ANN. In this letter, a novel loss function based on mean squared error (MSE), WeightedMSE, is proposed for avoiding underestimated quantification. It can be changed flexibly by adjusting parameters in order to adapt the acceptable overestimation range corresponding to the different types of drugs. A simulated dataset and a real dataset of etoposide and methotrexate are used as drug models, demonstrating that the proposed method can avoid underestimation in predicted values by over 98% in quantifying the concentration of multiple drugs and showing significant effectiveness for the development of point-of-care and wearable monitoring systems.","Matsumoto, Tatsunori, Du, Lin, Rodino, Francesca, Thoma, Yann, Premachandra, Chinthaka, Carrara, Sandro",,,Optimized Quantification of Multiple Drug Concentrations by WeightedMSE With Machine Learning on Electrochemical Sensor,,,10.1109/LSENS.2024.3452009 , ,,"Quantification of multiple drugs is of great importance and urgently needed in therapeutic drug monitoring (TDM) and personalized therapy. Especially, based on cyclic voltammograms (CVs) obtained by electrochemical sensors, the use of artificial neural networks (ANNs) has been widely attempted in the accurate quantification of drug concentrations, enabling the development of point-of-care and potentially system-level wearable devices. However, most of the work only considers the accuracy of how the predicted value is close to the actual value, which does not consider whether the predicted drug concentration is underestimated. In practical drug quantification, potential toxicity due to overexposure with underestimated quantification can lead to endangering the patient's body. Therefore, avoiding underestimating the concentration of drugs based on existing quantification models is required and necessary to optimize the conventional loss function at the output stage of ANN. In this letter, a novel loss function based on mean squared error (MSE), WeightedMSE, is proposed for avoiding underestimated quantification. It can be changed flexibly by adjusting parameters in order to adapt the acceptable overestimation range corresponding to the different types of drugs. A simulated dataset and a real dataset of etoposide and methotrexate are used as drug models, demonstrating that the proposed method can avoid underestimation in predicted values by over 98% in quantifying the concentration of multiple drugs and showing significant effectiveness for the development of point-of-care and wearable monitoring systems.",,,,, ,  ,Drugs;Feature extraction;Sensors;Vectors;Monitoring;Time division multiplexing;Sensor phenomena and characterization;Sensor applications;artificial neural network (ANN);cyclic voltammogram (CV);drug quantification;loss function;personalized therapy;therapeutic drug monitoring (TDM),out_of_scope,
3240,"**Title**Overall Survival Analyzer: A software tool to analyze genotyping and clinical data enriched with temporal events

**Abstract**The estimation of survival distributions of patients is an important current problem in clinical oncology. The current trend is to integrate molecular data (such as genomic data) with clinical data (e.g. cancer type, stage of the disease, etc) and then to link survival distributions to molecular profile of patients. Recently, the Affymetrix DMET (Drug Metabolizing Enzymes and Transporters) microarray technology has enabled the possibility to determine the allelic variants of a patient and to relate them to phenotype (e.g. drug toxicity). Therefore, the analysis of survival distribution of patients starting from their profile obtained using DMET data may reveal important knowledge to clinicians. In order to provide support to this analysis we propose Overall Survival Analyzer (OS-Analyzer), a software tool able to compute the Overall Survival and Progression-Free Survival (PFS). The tool is able to perform an automatic analysis of data avoiding wasting time on the manual analysis. OS-Analyzer is available to download at the follows web address: https://sites.google.com/site/overallsurvivalanalyzer/.","Agapito, G., Guzzi, P.H., Botta, C., Arbitrio, M., Tassone, P., Tagliaferri, P., Cannataro, M.",,,Overall Survival Analyzer: A software tool to analyze genotyping and clinical data enriched with temporal events,,,10.1109/BIBM.2015.7359886 , ,,"The estimation of survival distributions of patients is an important current problem in clinical oncology. The current trend is to integrate molecular data (such as genomic data) with clinical data (e.g. cancer type, stage of the disease, etc) and then to link survival distributions to molecular profile of patients. Recently, the Affymetrix DMET (Drug Metabolizing Enzymes and Transporters) microarray technology has enabled the possibility to determine the allelic variants of a patient and to relate them to phenotype (e.g. drug toxicity). Therefore, the analysis of survival distribution of patients starting from their profile obtained using DMET data may reveal important knowledge to clinicians. In order to provide support to this analysis we propose Overall Survival Analyzer (OS-Analyzer), a software tool able to compute the Overall Survival and Progression-Free Survival (PFS). The tool is able to perform an automatic analysis of data avoiding wasting time on the manual analysis. OS-Analyzer is available to download at the follows web address: https://sites.google.com/site/overallsurvivalanalyzer/.",,,,, ,  2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Genomics;Bioinformatics;Probes;Navigation;Parallel computing;Statistical software;Bioinformatics,out_of_scope,
3241,"**Title**Retracted: An IoT Based Smart Healthcare Medical System using Deep Learning Algorithm

**Abstract**The Internet of Things (IoT) has developed over the past ten years, integrating technological advances like machine learning, deep learning, distribution networks of the supply chain, edge computing, cybersecurity, and datasets. This evolution has expanded industrial acceptance, primarily with in healthcare sector. Incorporating machine learning approach, the IoT assists in providing analysis among real-time data and historical data. In this work, a deep-learning-based method is used to design and develop an IoT-based noninvasive automated patient distress monitoring and surveillance mechanism. The system relies on an IP video camera to track the participant’s strength and mobility without the need for any smart wearables. The retrieval of various important locations on the body of the patient is done using the Mask-RCNN approach. Deploying these rules of association from data mining, these six primary body parts are then created from the important aspects that were discovered. Additionally, data about the identified crucial point dimensions is collected to analyses the patient’s pain. The spatial and temporal thresholds are then used to categorize gestures as being related to comfortable or uncomfortable situations. These crucial details are also utilized to ascertain how the patient is positioned while resting on the mattress. Continuous monitoring of the person’s postural and bodily position allows for the differentiation of comfort from discomfort. Separate video clips spanning the beds of 2 patients are taken for exploratory examination.","Gehlot, Aashat, Misra, Neeti",,,Retracted: An IoT Based Smart Healthcare Medical System using Deep Learning Algorithm,,,10.1109/MysuruCon55714.2022.9972370 , ,,"The Internet of Things (IoT) has developed over the past ten years, integrating technological advances like machine learning, deep learning, distribution networks of the supply chain, edge computing, cybersecurity, and datasets. This evolution has expanded industrial acceptance, primarily with in healthcare sector. Incorporating machine learning approach, the IoT assists in providing analysis among real-time data and historical data. In this work, a deep-learning-based method is used to design and develop an IoT-based noninvasive automated patient distress monitoring and surveillance mechanism. The system relies on an IP video camera to track the participant’s strength and mobility without the need for any smart wearables. The retrieval of various important locations on the body of the patient is done using the Mask-RCNN approach. Deploying these rules of association from data mining, these six primary body parts are then created from the important aspects that were discovered. Additionally, data about the identified crucial point dimensions is collected to analyses the patient’s pain. The spatial and temporal thresholds are then used to categorize gestures as being related to comfortable or uncomfortable situations. These crucial details are also utilized to ascertain how the patient is positioned while resting on the mattress. Continuous monitoring of the person’s postural and bodily position allows for the differentiation of comfort from discomfort. Separate video clips spanning the beds of 2 patients are taken for exploratory examination.",,,,, ,  2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon),,out_of_scope,
3242,"**Title**Optimal Transport Based Graph Kernels for Drug Property Prediction

**Abstract**Objective: The development of pharmaceutical agents relies heavily on optimizing their pharmacodynamics, pharmacokinetics, and toxicological properties, collectively known as ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity). Accurate assessment of these properties during the early stages of drug development is challenging due to resource-intensive experimental evaluation and limited comprehensive data availability. To overcome these obstacles, there has been a growing reliance on computational and predictive tools, leveraging recent advancements in machine learning and graph-based methodologies. This study presents an innovative approach that harnesses the power of optimal transport (OT) theory to construct three graph kernels for predicting drug ADMET properties. This approach involves the use of graph matching to create a similarity matrix, which is subsequently integrated into a predictive model. Results: Through extensive evaluations on 19 distinct ADMET datasets, the potential of this methodology becomes evident. The OT-based graph kernels exhibits exceptional performance, outperforming state-of-the-art graph deep learning models in 9 out of 19 datasets, even surpassing the most impactful Graph Neural Network (GNN) that excels in 4 datasets. Furthermore, they are very competitive in 2 additional datasets. Conclusion: Our proposed novel class of OT-based graph kernels not only demonstrates a high degree of effectiveness and competitiveness but also, in contrast to graph neural networks, offers interpretability, adaptability and generalizability across multiple datasets.","Aburidi, Mohammed, Marcia, Roummel",,,Optimal Transport Based Graph Kernels for Drug Property Prediction,,,10.1109/OJEMB.2024.3480708 , ,,"Objective: The development of pharmaceutical agents relies heavily on optimizing their pharmacodynamics, pharmacokinetics, and toxicological properties, collectively known as ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity). Accurate assessment of these properties during the early stages of drug development is challenging due to resource-intensive experimental evaluation and limited comprehensive data availability. To overcome these obstacles, there has been a growing reliance on computational and predictive tools, leveraging recent advancements in machine learning and graph-based methodologies. This study presents an innovative approach that harnesses the power of optimal transport (OT) theory to construct three graph kernels for predicting drug ADMET properties. This approach involves the use of graph matching to create a similarity matrix, which is subsequently integrated into a predictive model. Results: Through extensive evaluations on 19 distinct ADMET datasets, the potential of this methodology becomes evident. The OT-based graph kernels exhibits exceptional performance, outperforming state-of-the-art graph deep learning models in 9 out of 19 datasets, even surpassing the most impactful Graph Neural Network (GNN) that excels in 4 datasets. Furthermore, they are very competitive in 2 additional datasets. Conclusion: Our proposed novel class of OT-based graph kernels not only demonstrates a high degree of effectiveness and competitiveness but also, in contrast to graph neural networks, offers interpretability, adaptability and generalizability across multiple datasets.",,,,, ,  ,Kernel;Drugs;Predictive models;Graph neural networks;Biological system modeling;Accuracy;Metabolism;Training;Toxicology;Support vector machines;Optimal tranpsort;ADMET properties;wasserstein distance;graph matching;graph kernels,out_of_scope,
3243,"**Title**Recovery of Metabolomic Spectral Sources using Non-negative Matrix Factorization

**Abstract**1H magnetic resonance spectra (MRS) of biofluids contain rich biochemical information about the metabolic status of an organism. Through the application of pattern recognition and classification algorithms, such data have been shown to provide information for disease diagnosis as well as the effects of potential therapeutics. In this paper we describe a novel approach, using non-negative matrix factorization (NMF), for rapidly identifying metabolically meaningful spectral patterns in1H MRS. We show that the intensities of these identified spectral patterns can be related to the onset of, and recovery from, toxicity in both a time-related and dose-related fashion. These patterns can be seen as a new type of biomarker for the biological effect under study. We demonstrate, using k-means clustering, that the recovered patterns can be used to characterize the metabolic status of the animal during the experiment.","Du, Shuyan, Sajda, P., Stoyanova, R., Brown, T.R.",,,Recovery of Metabolomic Spectral Sources using Non-negative Matrix Factorization,,,10.1109/IEMBS.2005.1615528 , ,,"1H magnetic resonance spectra (MRS) of biofluids contain rich biochemical information about the metabolic status of an organism. Through the application of pattern recognition and classification algorithms, such data have been shown to provide information for disease diagnosis as well as the effects of potential therapeutics. In this paper we describe a novel approach, using non-negative matrix factorization (NMF), for rapidly identifying metabolically meaningful spectral patterns in1H MRS. We show that the intensities of these identified spectral patterns can be related to the onset of, and recovery from, toxicity in both a time-related and dose-related fashion. These patterns can be seen as a new type of biomarker for the biological effect under study. We demonstrate, using k-means clustering, that the recovered patterns can be used to characterize the metabolic status of the animal during the experiment.",,,,, ,  2005 IEEE Engineering in Medicine and Biology 27th Annual Conference,Metabolomics;Animals;Clustering algorithms;Biomedical engineering;Cancer;Magnetic resonance;Organisms;Pattern recognition;Classification algorithms;Diseases,out_of_scope,
3244,"**Title**Combination of Chemometric Methods Based on Data Mining for Studying the Speciation of Metal-Ligand Systems

**Abstract**The methods based on data mining in chemometrics are promising techniques to study the speciation of metals. The speciation of metals in natural water is important in studies of the toxicity of metals for aquatic organisms. Since the data obtained are in great amount and of multivariate nature, many of the variables studied are correlated. Data mining of these data requires the combination of several multivariate data analysis methods. In this case, principal component analysis (PCA), evolving factor analysis (EFA) and SIMPLE-to-use Interactive Self-modeling Mixture Analysis (SIMPLISMA) were applied to the study of the speciation of Zn(II)-4-(2-pyridylazo) resorcinol (PAR) system. Three programs named SPGRAFA, SPGREFA and SPGRSIMP having both the function of picture interpretation and calculations were designed, based on mathematical algorithms. Error functions were calculated for evaluating the number of species. Submatrix analysis plots were constructed to estimate the species present in the system. SIMPLISMA, which is based on a pure variable approach, can be used for feature extraction in mixture analysis. These methods have been proven to be useful in studies concerning the speciation of complex systems in environmental samples.","Ren, Shouxin, Gao, Ling",,,Combination of Chemometric Methods Based on Data Mining for Studying the Speciation of Metal-Ligand Systems,,,10.1109/ITCS.2009.32 , ,,"The methods based on data mining in chemometrics are promising techniques to study the speciation of metals. The speciation of metals in natural water is important in studies of the toxicity of metals for aquatic organisms. Since the data obtained are in great amount and of multivariate nature, many of the variables studied are correlated. Data mining of these data requires the combination of several multivariate data analysis methods. In this case, principal component analysis (PCA), evolving factor analysis (EFA) and SIMPLE-to-use Interactive Self-modeling Mixture Analysis (SIMPLISMA) were applied to the study of the speciation of Zn(II)-4-(2-pyridylazo) resorcinol (PAR) system. Three programs named SPGRAFA, SPGREFA and SPGRSIMP having both the function of picture interpretation and calculations were designed, based on mathematical algorithms. Error functions were calculated for evaluating the number of species. Submatrix analysis plots were constructed to estimate the species present in the system. SIMPLISMA, which is based on a pure variable approach, can be used for feature extraction in mixture analysis. These methods have been proven to be useful in studies concerning the speciation of complex systems in environmental samples.",,,,, ,  2009 International Conference on Information Technology and Computer Science,Data mining;Matrix decomposition;Chemistry;Data analysis;Principal component analysis;Feature extraction;Eigenvalues and eigenfunctions;Information technology;Computer science;Organisms;speciation;metal-ligand systems;data mining;chemometrics,out_of_scope,
3245,"**Title**Sexism Discovery using CNN, Word Embeddings, NLP and Data Augmentation

**Abstract**The pervasive issue of online sexism continues to pose significant challenges, fostering environments characterized by toxicity and perpetuating harmful societal norms. In response, this paper presents an approach for the discovery of sexist statements employing convolutional neural networks (CNNs), Word Embeddings, and data augmentation techniques. Through the fusion of CNNs’ capacity for hierarchical feature extraction with the semantic representations afforded by Word Embeddings, our method achieves exemplary discrimination performance. Additionally, the incorporation of data augmentation enriches the training dataset, thereby augmenting model generalization and resilience. Empirical evaluation on a larger dataset of statements demonstrates the efficacy of our approach, surpassing many baseline approaches in terms of discovery accuracy, precision, recall and F1-score.","Fattahi, Jaouhar, Sghaier, Feriel, Mejri, Mohamed, Ghayoula, Ridha, Bahroun, Sahbi, Ziadia, Marwa",,,"Sexism Discovery using CNN, Word Embeddings, NLP and Data Augmentation",,,10.1109/CoDIT62066.2024.10708284 , ,,"The pervasive issue of online sexism continues to pose significant challenges, fostering environments characterized by toxicity and perpetuating harmful societal norms. In response, this paper presents an approach for the discovery of sexist statements employing convolutional neural networks (CNNs), Word Embeddings, and data augmentation techniques. Through the fusion of CNNs’ capacity for hierarchical feature extraction with the semantic representations afforded by Word Embeddings, our method achieves exemplary discrimination performance. Additionally, the incorporation of data augmentation enriches the training dataset, thereby augmenting model generalization and resilience. Empirical evaluation on a larger dataset of statements demonstrates the efficacy of our approach, surpassing many baseline approaches in terms of discovery accuracy, precision, recall and F1-score.",,,,, ,"  2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)",Training;Adaptation models;Toxicology;Semantics;Training data;Data augmentation;Natural language processing;Data models;Convolutional neural networks;Resilience,detection,
3246,"**Title**Continuous Prompt for Chemical Language Model Aided Anticancer Synergistic Drug Combination Prediction

**Abstract**Identifying synergistic drug combinations is paramount significance in addressing complex diseases while reducing the risks of toxicities and other adverse effects. Although a plethora of computational methods have been proposed in this domain, most of them are underpinned only by physicochemical or biological features. Recently, Chemical Language Models (CLMs) are shown to be capable of learning better representations that hold utility across diverse tasks, from molecular property prediction, de novo drug design, drug-target interaction, and more. In this study, we proposed CLMSyn, a continuous prompt for CLM aided synergistic drug combinations prediction. Unlike existing works employ CLMs for downstream tasks, we adopt the prompt learning to fine-tune CLM, that is, only train small-scale prompt while keeping CLM fixed. Furthermore, we harness the the multi-head attention mechanism to fuse the learned vector from the CLM, chemical descriptors and gene expression of cell line. A comprehensive array of experiments conducted on a benchmark dataset, encompassing four distinct synergy types, substantiates the superior performance of CLMSyn when contrasted against existing state-of-the-art methods. These empirical findings provide compelling evidence attesting to the efficacy of CLMSyn as a potent instrumentality in expediting the identification of pioneering combination therapies.","Geng, Guannan, Zhao, Lingling, Wang, Chunyu, Liu, Xiaoyan, Wang, Junjie",,,Continuous Prompt for Chemical Language Model Aided Anticancer Synergistic Drug Combination Prediction,,,10.1109/BigData59044.2023.10386652 , ,,"Identifying synergistic drug combinations is paramount significance in addressing complex diseases while reducing the risks of toxicities and other adverse effects. Although a plethora of computational methods have been proposed in this domain, most of them are underpinned only by physicochemical or biological features. Recently, Chemical Language Models (CLMs) are shown to be capable of learning better representations that hold utility across diverse tasks, from molecular property prediction, de novo drug design, drug-target interaction, and more. In this study, we proposed CLMSyn, a continuous prompt for CLM aided synergistic drug combinations prediction. Unlike existing works employ CLMs for downstream tasks, we adopt the prompt learning to fine-tune CLM, that is, only train small-scale prompt while keeping CLM fixed. Furthermore, we harness the the multi-head attention mechanism to fuse the learned vector from the CLM, chemical descriptors and gene expression of cell line. A comprehensive array of experiments conducted on a benchmark dataset, encompassing four distinct synergy types, substantiates the superior performance of CLMSyn when contrasted against existing state-of-the-art methods. These empirical findings provide compelling evidence attesting to the efficacy of CLMSyn as a potent instrumentality in expediting the identification of pioneering combination therapies.",,,,, ,  2023 IEEE International Conference on Big Data (BigData),Drugs;Toxicology;Instruments;Medical treatment;Predictive models;Benchmark testing;Feature extraction;Drug Combination;Chemical Language Model;Prompt Learning;Multi-head Attention,out_of_scope,
3247,"**Title**B3P3-v: Detecting Blood-Brain Barrier Penetrating Peptides from Sequences with Nu-SVC

**Abstract**Effectively transporting therapeutic compounds to the brain poses a considerable obstacle in developing drugs for treating diseases associated with the central nervous system. This challenge mainly arises from the blood-brain barrier (BBB), a natural defense mechanism that limits the access of biotherapeutics to their intended locations within the central nervous system. This barrier obstructs effective treatments for numerous neurological disorders. Peptide therapeutics have emerged as a promising avenue in this field, owing to advancements in peptide chemistry. Compared to small molecules, peptides offer advantages such as high potency, selectivity, low toxicity, and reduced risk of drug interactions. However, the discovery and synthesis of Blood-Brain Barrier Penetrating Peptides (BBBPPs) through experimental methods can be time-consuming and expensive. In this study, we propose a BBBPPs prediction model utilizing the Nu-Support Vector Classifier (with an accuracy of 0.84, an AUCROC of 0.91, and an F1-score of 0.84). The model employs a straightforward physio-chemical feature set derived from the composition, transitions, and distribution of amino acids. The B3P3-v is available at https://github.com/Bhadra-labIB3P3-v","N, Sathiyajith J, C, Gopi Mohan, Siu, Shirley W.I., Bhadra, Pratiti",,,B3P3-v: Detecting Blood-Brain Barrier Penetrating Peptides from Sequences with Nu-SVC,,,10.1109/INCET61516.2024.10593074 , ,,"Effectively transporting therapeutic compounds to the brain poses a considerable obstacle in developing drugs for treating diseases associated with the central nervous system. This challenge mainly arises from the blood-brain barrier (BBB), a natural defense mechanism that limits the access of biotherapeutics to their intended locations within the central nervous system. This barrier obstructs effective treatments for numerous neurological disorders. Peptide therapeutics have emerged as a promising avenue in this field, owing to advancements in peptide chemistry. Compared to small molecules, peptides offer advantages such as high potency, selectivity, low toxicity, and reduced risk of drug interactions. However, the discovery and synthesis of Blood-Brain Barrier Penetrating Peptides (BBBPPs) through experimental methods can be time-consuming and expensive. In this study, we propose a BBBPPs prediction model utilizing the Nu-Support Vector Classifier (with an accuracy of 0.84, an AUCROC of 0.91, and an F1-score of 0.84). The model employs a straightforward physio-chemical feature set derived from the composition, transitions, and distribution of amino acids. The B3P3-v is available at https://github.com/Bhadra-labIB3P3-v",,,,, ,  2024 5th International Conference for Emerging Technology (INCET),Drugs;Accuracy;Toxicology;Peptides;Stacking;Central nervous system;Predictive models;blood-brain barrier;peptide design;prediction;nu-support vector classifier;machine learning;classification,out_of_scope,
3248,"**Title**KUChemBio: A repository of computational chemical biology data sets

**Abstract**Data set curation in cheminformatics is largely ignored, and many publications do not provide the specific chemical structures used in their experiments. Access to chemical structures is vital for experiment reproducibility and comparison of competing methods. To address this limitation, the KU Chemical Biology Database (KUChemBio) has established a collection of 69 data sets for computational chemical biology experiments. Data sets fall into several categories including ADME, toxicity, binding affinity, solubility, melting points, and others. Chemical structures in SDF or Smiles format are provided along with binary or real valued activity labels. Data sets have been consolidated from other online repositories and content from recent publications has been added as well. KUChemBio is located at http://bcf.ku.edu/kuchembio.","Hall, Aaron Smalter, Huan, Jun",,,KUChemBio: A repository of computational chemical biology data sets,,,10.1109/BigData.2013.6691756 , ,,"Data set curation in cheminformatics is largely ignored, and many publications do not provide the specific chemical structures used in their experiments. Access to chemical structures is vital for experiment reproducibility and comparison of competing methods. To address this limitation, the KU Chemical Biology Database (KUChemBio) has established a collection of 69 data sets for computational chemical biology experiments. Data sets fall into several categories including ADME, toxicity, binding affinity, solubility, melting points, and others. Chemical structures in SDF or Smiles format are provided along with binary or real valued activity labels. Data sets have been consolidated from other online repositories and content from recent publications has been added as well. KUChemBio is located at http://bcf.ku.edu/kuchembio.",,,,, ,  2013 IEEE International Conference on Big Data,Chemicals;Compounds;Absorption;Drugs;Biology;Inhibitors;Computational modeling,out_of_scope,
3249,"**Title**Prediction of DILI in Humans: Investigating Opportunities in DILIst Data, Chemical Features, Machine Learning and Rule-Based Methods

**Abstract**Despite recent scientific developments, combating Drug Induced Liver Injury (DILI) associated risks is still a major challenge and there is an urgent need for breakthroughs in the assessment of DILI. To address this, we have built and evaluated several Machine Learning (ML) and rule-based models. Our approach is focused on three aspects: i) selection of three new high-quality datasets, DILI-876, DILI-955, and DILI-1148 from DILIst (DILI severity and toxicity) dataset, by applying several scientific criteria. The datasets DILI-876, DILI-955, and DILI-1148 contain drugs that fall within three chemical spaces, namely, drugs with molecular weights of ⩽500, ⩽ 750, and ""no molecular weight bias"" respectively. ii) Evaluation of the influence of three types of data division methods and chemical features on model performance. iii) Evaluation of four ML and one rule-based method for developing reliable DILI models. These efforts resulted in high-performing DILI models that are superior to reported ML models, based on AUC, F1, specificity, and most significantly, with superior performance in the case of DILI positive and negative drugs. The test set characteristics of the best ANN DILI model developed using DILI-876 are AUC-0.908, accuracy-0.804, sensitivity-0.804, specificity-0.815, balanced accuracy-0.809, MCC-0.594, precision-0.821, and F1-0.807. The best SVM DILI models showed similar performance characteristics. The order of predictive performance of the ML models derived from the three datasets is DILI-876>DILI-955>DILI-1148, and the order of performance of the ML methods is ANN~SVM>LR>RF. The order of performance of the models built using the three chemical features is fingerprints>descriptors>fragments. From the performance analysis of our models for individual chemical and DILI classes, we infer that our models performed equally well for DILI negative drugs e.g., the success level of prediction is 81.355% for ""vNo"" drugs, as reflected by the excellent specificity of the models for the imbalanced DILI data. Similarly, they performed equally well in the case of DILI positives, as reflected by the excellent sensitivity of our models. It is evident from the success level of prediction of ""vMost"" (81.818%), ""vLess"" (90.163%), and ""others"" (73.333%), DILI concerns, that our models are excellent candidates for easy adoption in real-world applications.","Narayanan, Advaith Nila, Das, Shyam Sundar, Mirnalinee, T. T.",,,"Prediction of DILI in Humans: Investigating Opportunities in DILIst Data, Chemical Features, Machine Learning and Rule-Based Methods",,,10.1109/BIBM58861.2023.10385311 , ,,"Despite recent scientific developments, combating Drug Induced Liver Injury (DILI) associated risks is still a major challenge and there is an urgent need for breakthroughs in the assessment of DILI. To address this, we have built and evaluated several Machine Learning (ML) and rule-based models. Our approach is focused on three aspects: i) selection of three new high-quality datasets, DILI-876, DILI-955, and DILI-1148 from DILIst (DILI severity and toxicity) dataset, by applying several scientific criteria. The datasets DILI-876, DILI-955, and DILI-1148 contain drugs that fall within three chemical spaces, namely, drugs with molecular weights of ⩽500, ⩽ 750, and ""no molecular weight bias"" respectively. ii) Evaluation of the influence of three types of data division methods and chemical features on model performance. iii) Evaluation of four ML and one rule-based method for developing reliable DILI models. These efforts resulted in high-performing DILI models that are superior to reported ML models, based on AUC, F1, specificity, and most significantly, with superior performance in the case of DILI positive and negative drugs. The test set characteristics of the best ANN DILI model developed using DILI-876 are AUC-0.908, accuracy-0.804, sensitivity-0.804, specificity-0.815, balanced accuracy-0.809, MCC-0.594, precision-0.821, and F1-0.807. The best SVM DILI models showed similar performance characteristics. The order of predictive performance of the ML models derived from the three datasets is DILI-876>DILI-955>DILI-1148, and the order of performance of the ML methods is ANN~SVM>LR>RF. The order of performance of the models built using the three chemical features is fingerprints>descriptors>fragments. From the performance analysis of our models for individual chemical and DILI classes, we infer that our models performed equally well for DILI negative drugs e.g., the success level of prediction is 81.355% for ""vNo"" drugs, as reflected by the excellent specificity of the models for the imbalanced DILI data. Similarly, they performed equally well in the case of DILI positives, as reflected by the excellent sensitivity of our models. It is evident from the success level of prediction of ""vMost"" (81.818%), ""vLess"" (90.163%), and ""others"" (73.333%), DILI concerns, that our models are excellent candidates for easy adoption in real-world applications.",,,,, ,  2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),Drugs;Training;Radio frequency;Analytical models;Machine learning;Predictive models;Fingerprint recognition;Drug Discovery & Development;drug safety;Drug Induced Liver Injury;Cheminformatics;Machine Learning;Rule-based method;Chemical features;Fingerprints;Descriptors;Fragments,out_of_scope,
3250,"**Title**Wasserstein Distance-Based Graph Kernel for Enhancing Drug Safety and Efficacy Prediction *

**Abstract**Drug development relies heavily on the optimization of therapeutic agents concerning their pharmacodynamics, pharmacokinetics, and toxicological properties. These properties, collectively known as ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity), play a pivotal role in determining a drug's efficacy and safety. However, assessing these properties during the early stages of drug development poses substantial challenges, driven by the resource-intensive nature of experimental evaluation and the scarcity of comprehensive data. To address these hurdles, computational and predictive tools have gained prominence, capitalizing on recent advances in machine learning and graph-based methodologies. This study introduces an innovative approach that leverages optimal transport (OT) to construct a graph kernel for predicting drug ADMET properties. The approach involves graph matching to create a similarity matrix, which is subsequently employed in a predictive model. Extensive evaluations on 19 ADMET datasets demonstrate the promise of this methodology. Our OT-based graph kernel out-performs state-of-the-art graph deep learning models in 8 out of 19 datasets, outperforming the most impactful GNN (which outperforms on 4 datasets) and competes effectively in 3 others, showcasing its adaptability and generalization capabilities and potential to enhance pharmaceuticals.","Aburidi, Mohammed, Marcia, Roummel",,,Wasserstein Distance-Based Graph Kernel for Enhancing Drug Safety and Efficacy Prediction *,,,10.1109/AIMHC59811.2024.00029 , ,,"Drug development relies heavily on the optimization of therapeutic agents concerning their pharmacodynamics, pharmacokinetics, and toxicological properties. These properties, collectively known as ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity), play a pivotal role in determining a drug's efficacy and safety. However, assessing these properties during the early stages of drug development poses substantial challenges, driven by the resource-intensive nature of experimental evaluation and the scarcity of comprehensive data. To address these hurdles, computational and predictive tools have gained prominence, capitalizing on recent advances in machine learning and graph-based methodologies. This study introduces an innovative approach that leverages optimal transport (OT) to construct a graph kernel for predicting drug ADMET properties. The approach involves graph matching to create a similarity matrix, which is subsequently employed in a predictive model. Extensive evaluations on 19 ADMET datasets demonstrate the promise of this methodology. Our OT-based graph kernel out-performs state-of-the-art graph deep learning models in 8 out of 19 datasets, outperforming the most impactful GNN (which outperforms on 4 datasets) and competes effectively in 3 others, showcasing its adaptability and generalization capabilities and potential to enhance pharmaceuticals.",,,,, ,"  2024 IEEE First International Conference on Artificial Intelligence for Medicine, Health and Care (AIMHC)",Drugs;Proteins;Adaptation models;Toxicology;Pharmacodynamics;Predictive models;Safety;Optimal Transport;Wasserstein Distance;Graph Matching;Drug Discovery;ADMET Properties,out_of_scope,
3251,"**Title**Optimizing Modified Barium Swallow Exam Workflow: Automating Pre-Analysis Video Sorting in Swallowing Function Assessment

**Abstract**Modified Barium Swallow (MBS) exams, performed using video-fluoroscopy, an X-ray imaging technique, are essential for assessing swallowing function. They visualize the barium bolus (contrast agent) during the swallowing process in the head and neck area, thereby providing crucial insights into the dynamics of swallowing. Typically, these exams include both diagnostic anteroposterior (AP) and lateral planes, in addition to non-diagnostic ""scout"" films. This study introduces a deep learning solution aimed at streamlining the pre-analysis process of MBS exams by automating the identification of video orientations and scout video clips. Our methods are trained and tested on a comprehensive dataset comprising 2,315 video clips from 172 MBS exams and 106 patients. To distinguish AP videos from lateral views, our model achieved more than 99% accuracy at the frame level and 100% at the video level. In differentiating scout from bolus swallowing tasks, the model attained a maximum accuracy of 86% at the video level. We further merged these two tasks into a multi-task learning approach further enhanced the accuracy to 91% for scout/bolus differentiation. These advancements allow clinicians to allocate more efforts to focus primarily on lateral view videos for clinically relevant measurements such as the Penetration-Aspiration Scale (PAS) and Dynamic Imaging Grade of Swallowing Toxicity (DIGEST). This image sorting is also a pre-requisite step necessary to apply deep learning solutions to full image analysis.","Mao, Shitong, Naser, Mohamed A., Buoy, Sheila Nida, Brock, Kristy K., Hutcheson, Katherine A.",,,Optimizing Modified Barium Swallow Exam Workflow: Automating Pre-Analysis Video Sorting in Swallowing Function Assessment,,,10.1109/EMBC53108.2024.10782457 , ,,"Modified Barium Swallow (MBS) exams, performed using video-fluoroscopy, an X-ray imaging technique, are essential for assessing swallowing function. They visualize the barium bolus (contrast agent) during the swallowing process in the head and neck area, thereby providing crucial insights into the dynamics of swallowing. Typically, these exams include both diagnostic anteroposterior (AP) and lateral planes, in addition to non-diagnostic ""scout"" films. This study introduces a deep learning solution aimed at streamlining the pre-analysis process of MBS exams by automating the identification of video orientations and scout video clips. Our methods are trained and tested on a comprehensive dataset comprising 2,315 video clips from 172 MBS exams and 106 patients. To distinguish AP videos from lateral views, our model achieved more than 99% accuracy at the frame level and 100% at the video level. In differentiating scout from bolus swallowing tasks, the model attained a maximum accuracy of 86% at the video level. We further merged these two tasks into a multi-task learning approach further enhanced the accuracy to 91% for scout/bolus differentiation. These advancements allow clinicians to allocate more efforts to focus primarily on lateral view videos for clinically relevant measurements such as the Penetration-Aspiration Scale (PAS) and Dynamic Imaging Grade of Swallowing Toxicity (DIGEST). This image sorting is also a pre-requisite step necessary to apply deep learning solutions to full image analysis.",,,,, ,  2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),Deep learning;Visualization;Barium;Accuracy;Toxicology;Streaming media;Multitasking;Aerodynamics;X-ray imaging;Sorting;Modified Barium Swallow (MBS);Deep Learning;Video-fluoroscopy;Swallowing Function Assessment,out_of_scope,
3252,"**Title**Life-Cycle Assessment of Renewable-based Hydrogen Production via PEM Electrolyzer in Indonesia

**Abstract**By 2030, Indonesia intends to reduce greenhouse gases by 29%. With growing concerns about climate change and the need to decarbonize the industrial, and energy systems, the Indonesian government has been motivated to consider clean hydrogen from renewable resources as a sustainable fuel for major industrial sector, such as in the manufacture of aluminum, iron, and steel. Among all hydrogen production methods, Proton Exchange Membrane (PEM) is the best option when high-purity hydrogen is required. This paper seeks to perform a life cycle assessment (LCA) on renewable-based hydrogen production via the PEM electrolyzer. The proposed case study contains the wind power, PEM electrolyzer, H2 compression, and desalination unit to prepare the water for the electrolysis process. The 1 kg H2 generation is considered as a function unit for calculating all LCA’s indicators. The system boundary is divided into four subsystems, and all inputs-output processes, energy flows, emissions to air, and water, etc. are included. The CML-IA approach is used for the characterization and normalization of 8 midpoint environment impacts using the World 2001 dataset. The proposed LCA on the H2 production is carried out in OpenLCA 2.1 software. The results reveal that electricity generation and H2 compression are the most considerable subsystems. Between of all indicators, human toxicity, acidification, and photochemical ozone creation impacts have the most significant role, respectively. It should be noted that the sensitivity analysis for ±20% deviation on the results approves the main achievements of this study.","Hemmati, Mohammad, Bayati, Navid, Ebel, Thomas",,,Life-Cycle Assessment of Renewable-based Hydrogen Production via PEM Electrolyzer in Indonesia,,,10.1109/icSmartGrid61824.2024.10578087 , ,,"By 2030, Indonesia intends to reduce greenhouse gases by 29%. With growing concerns about climate change and the need to decarbonize the industrial, and energy systems, the Indonesian government has been motivated to consider clean hydrogen from renewable resources as a sustainable fuel for major industrial sector, such as in the manufacture of aluminum, iron, and steel. Among all hydrogen production methods, Proton Exchange Membrane (PEM) is the best option when high-purity hydrogen is required. This paper seeks to perform a life cycle assessment (LCA) on renewable-based hydrogen production via the PEM electrolyzer. The proposed case study contains the wind power, PEM electrolyzer, H2 compression, and desalination unit to prepare the water for the electrolysis process. The 1 kg H2 generation is considered as a function unit for calculating all LCA’s indicators. The system boundary is divided into four subsystems, and all inputs-output processes, energy flows, emissions to air, and water, etc. are included. The CML-IA approach is used for the characterization and normalization of 8 midpoint environment impacts using the World 2001 dataset. The proposed LCA on the H2 production is carried out in OpenLCA 2.1 software. The results reveal that electricity generation and H2 compression are the most considerable subsystems. Between of all indicators, human toxicity, acidification, and photochemical ozone creation impacts have the most significant role, respectively. It should be noted that the sensitivity analysis for ±20% deviation on the results approves the main achievements of this study.",,,,, ,  2024 12th International Conference on Smart Grid (icSmartGrid),Life cycle assessment;Toxicology;Sensitivity analysis;Electricity;Hydrogen;Production;Wind power generation;Hydrogen production;renewable energy;life cycle assessment;impact assessment;electrolyzer,out_of_scope,
3253,"**Title**Machine Learning based Modeling of Drugs using Virtual Screening and in Silico Approach

**Abstract**The process and implementation of drug development is a complex structure which is a time-consuming process with higher accuracy. A transformative approach to optimize drug discovery is achieved through the integration of drug discovery with a virtual screening process. This is implemented through the in silico machine learning process. The traditional methods involve extracting and testing numerous chemical compounds in vitro and in vivo in the identification of potential drug contenders. These methods lead to various drawbacks that include higher costs with timelines. To overcome the drawbacks of the existing system, the integration of paradigm modeling is initiated. The behavior of molecules with biological targets is determined through In-silico machine learning algorithms. The effective analysis of millions of chemical compounds is done using a virtual screening process through computational simulations and desired pharmacological effects. The machine learning algorithms help in the extraction of intricate patterns from the molecular dataset. Certain properties such as molecule binding affinity, bioavailability, and toxicity are predicted using these algorithms. They help to optimize the molecular structure in silico to improve the interaction with the target proteins. The reliability is achieved through the quality of the training data with the robustness of the algorithm. They help to generalize newer chemical combinations that provide the solution for various diseases with personalized recommendations through the aid of artificial intelligence.","Balamurugan, K S, Appathurai, K, Sathish Kumar, P J, Kumutha, D, Surendran, R",,,Machine Learning based Modeling of Drugs using Virtual Screening and in Silico Approach,,,10.1109/ICOSEC61587.2024.10722732 , ,,"The process and implementation of drug development is a complex structure which is a time-consuming process with higher accuracy. A transformative approach to optimize drug discovery is achieved through the integration of drug discovery with a virtual screening process. This is implemented through the in silico machine learning process. The traditional methods involve extracting and testing numerous chemical compounds in vitro and in vivo in the identification of potential drug contenders. These methods lead to various drawbacks that include higher costs with timelines. To overcome the drawbacks of the existing system, the integration of paradigm modeling is initiated. The behavior of molecules with biological targets is determined through In-silico machine learning algorithms. The effective analysis of millions of chemical compounds is done using a virtual screening process through computational simulations and desired pharmacological effects. The machine learning algorithms help in the extraction of intricate patterns from the molecular dataset. Certain properties such as molecule binding affinity, bioavailability, and toxicity are predicted using these algorithms. They help to optimize the molecular structure in silico to improve the interaction with the target proteins. The reliability is achieved through the quality of the training data with the robustness of the algorithm. They help to generalize newer chemical combinations that provide the solution for various diseases with personalized recommendations through the aid of artificial intelligence.",,,,, ,  2024 5th International Conference on Smart Electronics and Communication (ICOSEC),Drugs;Analytical models;Machine learning algorithms;Toxicology;Biological system modeling;Computational modeling;Machine learning;Prediction algorithms;Drug discovery;Chemical compounds;Drug development;Complex structure;Virtual screening process;Machine learning process;Computational simulations;Pharmacological effects,out_of_scope,
3254,"**Title**AI-Based Virtual Screening for Identifying Novel Drug Candidates

**Abstract**VR screening uses computers to find large databases of chemical compounds and predict their potential as medications based on factors such as binding affinity, pharmacokinetics, and toxicity. This accelerates the process of discovering novel medications by concentrating on compounds with a higher likelihood of efficacy. This results in decreased expenses and increased effectiveness over an extended period. The study demonstrates the utilization of many artificial intelligence techniques in virtual screening, including deep learning networks, machine learning models, and other sophisticated computer technologies. The analysis examines the training of AI models on diverse datasets, incorporating data from existing databases, research publications, and experimental studies. This demonstrates the potential of AI in discovering novel chemicals for the treatment of cancer, infectious diseases, neurological disorders, and uncommon ailments. There are limitations associated with utilizing Molecular structure-based CADD methods. This research reviews current tools, applications, and methods for medication production speed and cost reduction. Structure-Based Virtual Screening (SBVS) is essential to medication development, according to research.","RadhaMahendran, S., Vishal Deshmukh, Sheetal, Thiyagasundaram, T., Sivakumar, K., Tilak Babu, S. B G, Pratap Singh, Surya",,,AI-Based Virtual Screening for Identifying Novel Drug Candidates,,,10.1109/ICRTCST61793.2024.10578375 , ,,"VR screening uses computers to find large databases of chemical compounds and predict their potential as medications based on factors such as binding affinity, pharmacokinetics, and toxicity. This accelerates the process of discovering novel medications by concentrating on compounds with a higher likelihood of efficacy. This results in decreased expenses and increased effectiveness over an extended period. The study demonstrates the utilization of many artificial intelligence techniques in virtual screening, including deep learning networks, machine learning models, and other sophisticated computer technologies. The analysis examines the training of AI models on diverse datasets, incorporating data from existing databases, research publications, and experimental studies. This demonstrates the potential of AI in discovering novel chemicals for the treatment of cancer, infectious diseases, neurological disorders, and uncommon ailments. There are limitations associated with utilizing Molecular structure-based CADD methods. This research reviews current tools, applications, and methods for medication production speed and cost reduction. Structure-Based Virtual Screening (SBVS) is essential to medication development, according to research.",,,,, ,  2024 5th International Conference on Recent Trends in Computer Science and Technology (ICRTCST),Computers;Training;Neurological diseases;Toxicology;Databases;Reviews;Computational modeling;Drug discovery uses virtual screening;AI;and ML Techniques;Bioinformatics and Computational Biology;Chemoinformatics;Target Identification and Validation;Drug candidate identification,out_of_scope,
3255,"**Title**Advancing the Boundary of Pre-Trained Models for Drug Discovery: Interpretable Fine-Tuning Empowered by Molecular Physicochemical Properties

**Abstract**In the field of drug discovery, a proliferation of pre-trained models has surfaced, exhibiting exceptional performance across a variety of tasks. However, the extensive size of these models, coupled with the limited interpretative capabilities of current fine-tuning methods, impedes the integration of pre-trained models into the drug discovery process. This paper pushes the boundaries of pre-trained models in drug discovery by designing a novel fine-tuning paradigm known as the Head Feature Parallel Adapter (HFPA), which is highly interpretable, high-performing, and has fewer parameters than other widely used methods. Specifically, this approach enables the model to consider diverse information across representation subspaces concurrently by strategically using Adapters, which can operate directly within the model's feature space. Our tactic freezes the backbone model and forces various small-size Adapters' corresponding subspaces to focus on exploring different atomic and chemical bond knowledge, thus maintaining a small number of trainable parameters and enhancing the interpretability of the model. Moreover, we furnish a comprehensive interpretability analysis, imparting valuable insights into the chemical area. HFPA outperforms over seven physiology and toxicity tasks and achieves state-of-the-art results in three physical chemistry tasks. We also test ten additional molecular datasets, demonstrating the robustness and broad applicability of HFPA.","Lian, Xiaoqing, Zhu, Jie, Lv, Tianxu, Hong, Xiaoyan, Ding, Longzhen, Chu, Wei, Ni, Jianming, Pan, Xiang",,,Advancing the Boundary of Pre-Trained Models for Drug Discovery: Interpretable Fine-Tuning Empowered by Molecular Physicochemical Properties,,,10.1109/JBHI.2024.3416348 , ,,"In the field of drug discovery, a proliferation of pre-trained models has surfaced, exhibiting exceptional performance across a variety of tasks. However, the extensive size of these models, coupled with the limited interpretative capabilities of current fine-tuning methods, impedes the integration of pre-trained models into the drug discovery process. This paper pushes the boundaries of pre-trained models in drug discovery by designing a novel fine-tuning paradigm known as the Head Feature Parallel Adapter (HFPA), which is highly interpretable, high-performing, and has fewer parameters than other widely used methods. Specifically, this approach enables the model to consider diverse information across representation subspaces concurrently by strategically using Adapters, which can operate directly within the model's feature space. Our tactic freezes the backbone model and forces various small-size Adapters' corresponding subspaces to focus on exploring different atomic and chemical bond knowledge, thus maintaining a small number of trainable parameters and enhancing the interpretability of the model. Moreover, we furnish a comprehensive interpretability analysis, imparting valuable insights into the chemical area. HFPA outperforms over seven physiology and toxicity tasks and achieves state-of-the-art results in three physical chemistry tasks. We also test ten additional molecular datasets, demonstrating the robustness and broad applicability of HFPA.",,,,, ,  ,Adaptation models;Task analysis;Head;Biological system modeling;Bioinformatics;Predictive models;Benchmark testing;Fine-tuning;drug discovery;interpretability,out_of_scope,
3256,"**Title**Prediction of NPK Fertilizer in Chili Plants Using SARIMA Model

**Abstract**Agriculture is one of the key sectors in the Indonesian economy, contributing approximately 14% to the national Gross Domestic Product. Chili plants are one of the main agricultural commodities in the country. Fertilization is crucial in chili plant cultivation to enhance yield and production quality. While proper fertilization can increase plant growth and productivity, excessive doses can lead to plant toxicity. Therefore, an accurate prediction model is needed to estimate the nutritional requirements of chili plants. This study aims to develop a prediction model for the nutritional needs of chili plants using a machine learning approach. The data used come from the Nutrient and Water Supply Monitoring System for chili plant growth and yield based on 10 T. The dataset includes chili plants treated with various doses of Nitrogen $(N)$, Phosphorus $(P)$, and Potassium $(K)$ fertilizers monitored by NPK sensors. The machine learning method applied is the Seasonal Autoregressive Integrated Moving Average (SARIMA), which can predict time series data. The model was evaluated using the metrics mean absolute error (MAE), root mean square error (RMSE), and mean absolute percentage error (MAPE). The SARIMA model (1,1,1)(1,1,0)[12J showed the best evaluation results, with an average MAE of 0.783, RMSE of 6.377, and MAPE of 0. 005. The SARIMA model can help farmers optimize NPK fertilizer practices to increase productivity and efficiency in the cultivation of chili plants.","Pratama, Rian Putra, Fakhurroja, Hanif, Bangkit, Harry, Pramesti, Dita",,,Prediction of NPK Fertilizer in Chili Plants Using SARIMA Model,,,10.1109/ICISS62896.2024.10751445 , ,,"Agriculture is one of the key sectors in the Indonesian economy, contributing approximately 14% to the national Gross Domestic Product. Chili plants are one of the main agricultural commodities in the country. Fertilization is crucial in chili plant cultivation to enhance yield and production quality. While proper fertilization can increase plant growth and productivity, excessive doses can lead to plant toxicity. Therefore, an accurate prediction model is needed to estimate the nutritional requirements of chili plants. This study aims to develop a prediction model for the nutritional needs of chili plants using a machine learning approach. The data used come from the Nutrient and Water Supply Monitoring System for chili plant growth and yield based on 10 T. The dataset includes chili plants treated with various doses of Nitrogen $(N)$, Phosphorus $(P)$, and Potassium $(K)$ fertilizers monitored by NPK sensors. The machine learning method applied is the Seasonal Autoregressive Integrated Moving Average (SARIMA), which can predict time series data. The model was evaluated using the metrics mean absolute error (MAE), root mean square error (RMSE), and mean absolute percentage error (MAPE). The SARIMA model (1,1,1)(1,1,0)[12J showed the best evaluation results, with an average MAE of 0.783, RMSE of 6.377, and MAPE of 0. 005. The SARIMA model can help farmers optimize NPK fertilizer practices to increase productivity and efficiency in the cultivation of chili plants.",,,,, ,  2024 International Conference on ICT for Smart Society (ICISS),Productivity;Accuracy;Toxicology;Plants (biology);Machine learning;Predictive models;Nutrients;Monitoring;Fertilizers;Farming;Chili Plants;NPK Fertilization;Prediction Model;SARIMA;Machine learning,out_of_scope,
3257,"**Title**Prediction of Metal Oxide Nanoparticles for Anticancer Drug Delivery Using Machine Learning

**Abstract**This work uses machine learning to predict how well metal oxide nanoparticles (MONPs) will deliver anticancer medications in a novel attempt to transform nanomedicine. In order to determine the ideal metal oxide nanoparticles (MONPs) for efficient anticancer drug delivery, this project explores a variety of machine learning techniques. Using an extensive dataset that includes toxicity profiles, drug transport efficiency assessments, and MONP physicochemical properties, the research examines the predictive power of many machine learning techniques. By means of rigorous validation procedures and careful experimentation, the research aims to identify the most effective models for precisely forecasting the optimal MONPs for anticancer medication delivery. Through comparative evaluations of several algorithms, the study seeks to offer important insights into the best methods for this crucial application. The results of this study have the potential to significantly advance the area of nanomedicine by enabling the logical design and selection of MONPs for enhanced anticancer drug delivery, thereby contributing to the ongoing efforts in combating cancer with precision and efficacy.","A, Michel Ashick, P, Eben Sophia, S, Stewart Kirubakaran, D, Narmadha",,,Prediction of Metal Oxide Nanoparticles for Anticancer Drug Delivery Using Machine Learning,,,10.1109/ICAIT61638.2024.10690572 , ,,"This work uses machine learning to predict how well metal oxide nanoparticles (MONPs) will deliver anticancer medications in a novel attempt to transform nanomedicine. In order to determine the ideal metal oxide nanoparticles (MONPs) for efficient anticancer drug delivery, this project explores a variety of machine learning techniques. Using an extensive dataset that includes toxicity profiles, drug transport efficiency assessments, and MONP physicochemical properties, the research examines the predictive power of many machine learning techniques. By means of rigorous validation procedures and careful experimentation, the research aims to identify the most effective models for precisely forecasting the optimal MONPs for anticancer medication delivery. Through comparative evaluations of several algorithms, the study seeks to offer important insights into the best methods for this crucial application. The results of this study have the potential to significantly advance the area of nanomedicine by enabling the logical design and selection of MONPs for enhanced anticancer drug delivery, thereby contributing to the ongoing efforts in combating cancer with precision and efficacy.",,,,, ,  2024 Second International Conference on Advances in Information Technology (ICAIT),Nanoparticles;Accuracy;Precision medicine;Metals;Machine learning;Predictive models;Prediction algorithms;Drug delivery;Nanomedicine;Cancer;metal oxide;nanoparticles;anticancer drug;machine learning,out_of_scope,
3258,"**Title**Positive Sample Augmentation with Graph Mixup for DDI Prediction

**Abstract**Unexpected drug-drug interactions (DDIs) may occur when drugs are taken at the same time. Harmful DDIs can reduce drug efficacy and even increase unintended toxicity, putting patients treated with different drugs at risk. Previous works on DDI prediction mainly rely on hand-engineered domain knowledge, which is laborious to obtain and cannot handle the problem of sparse positive samples in DDI prediction. Even though some works attempt to handle data sparsity from the perspective of data distribution to improve the generalization ability of the model, they are limited to negative samples distribution. To address these limitations, we propose a novel method, Graph Mixup for Positive Sample Augmentation (GMPSA), to effectively combine positive drug molecule graphs and extend the training distribution to alleviate the problem of sparse positive samples. To model the graph signals and graph structures jointly, we map source graphs to the fused gromov-wasserstein metric space, then minimizes the weighted sum of transportation distances between the distributions of the source graphs and the objective graph in this metric space. By doing so, interpolated positive samples improve the the generalization error of the model. Experiments results on a real-word dataset show that our method effectively improve the perfomermance in DDI prediction on a state-of-the-art architecture. Further studies also verify the robustness and generalizability of GMPSA under different GNN backbones and parameter settings.","Yu, Hailong, Ma, Xinyu, Chu, Xu, Wang, Yasha, Wu, Rengyu, Zhou, Qiang",,,Positive Sample Augmentation with Graph Mixup for DDI Prediction,,,10.1109/MedAI59581.2023.00034 , ,,"Unexpected drug-drug interactions (DDIs) may occur when drugs are taken at the same time. Harmful DDIs can reduce drug efficacy and even increase unintended toxicity, putting patients treated with different drugs at risk. Previous works on DDI prediction mainly rely on hand-engineered domain knowledge, which is laborious to obtain and cannot handle the problem of sparse positive samples in DDI prediction. Even though some works attempt to handle data sparsity from the perspective of data distribution to improve the generalization ability of the model, they are limited to negative samples distribution. To address these limitations, we propose a novel method, Graph Mixup for Positive Sample Augmentation (GMPSA), to effectively combine positive drug molecule graphs and extend the training distribution to alleviate the problem of sparse positive samples. To model the graph signals and graph structures jointly, we map source graphs to the fused gromov-wasserstein metric space, then minimizes the weighted sum of transportation distances between the distributions of the source graphs and the objective graph in this metric space. By doing so, interpolated positive samples improve the the generalization error of the model. Experiments results on a real-word dataset show that our method effectively improve the perfomermance in DDI prediction on a state-of-the-art architecture. Further studies also verify the robustness and generalizability of GMPSA under different GNN backbones and parameter settings.",,,,, ,  2023 IEEE International Conference on Medical Artificial Intelligence (MedAI),Drugs;Training;Toxicology;Transportation;Transforms;Robustness;Task analysis;drug-drug interaction prediction;data augmentation;imbalance problem;graph neural networks,out_of_scope,
3259,"**Title**A Hybrid Deep Learning Techniques Using BERT and CNN for Toxic Comments Classification

**Abstract**Cyberbullying is a pervasive issue across all forms of media, affecting various demographics and platforms indiscriminately. From social media networks to online forums and comment sections on news sites, the harmful behavior of cyberbullying manifests in many forms, including harassment, threats, and demeaning comments. This ubiquity underscores the need for effective detection mechanisms. This paper explores the identification of toxic traits in online comments using advanced hybrid models, specifically BERT-CNN and BERT-LSTM. The research methodology involved constructing and configuring multiple layers within these models to optimize their ability to detect harmful content. For the BERT-CNN model, BERT's powerful language understanding capabilities are combined with CNN's strength in feature extraction through convolutional layers, capturing spatial hierarchies of features. In the BERT-LSTM model, BERT is integrated with LSTM layers to leverage their ability to learn long-term dependencies and sequential patterns in text. Various configurations of these models were tested, including adj ustments in the batch sizes and the length of the word tokens, to enhance performance in identifying toxic language. The best model which is BERT-CNN using the configuration 256 as the unit and 32 as the batch size achieved 94.48% accuracy in detecting toxic comments. The result from the model indicates that by harnessing BERT's contextual embeddings and the respective benefits of CNN's and LSTM's processing capabilities, it is possible to significantly reduce the frequency of cyberbullying through effective detection, ultimately fostering safer online environments across different media platforms.","Jessica, Adelia, Sugiarto, Migel Sastrawan, Jerry, Achmad, Said, Sutoyo, Rhio",,,A Hybrid Deep Learning Techniques Using BERT and CNN for Toxic Comments Classification,,,10.1109/ICIMTech63123.2024.10780934 , ,,"Cyberbullying is a pervasive issue across all forms of media, affecting various demographics and platforms indiscriminately. From social media networks to online forums and comment sections on news sites, the harmful behavior of cyberbullying manifests in many forms, including harassment, threats, and demeaning comments. This ubiquity underscores the need for effective detection mechanisms. This paper explores the identification of toxic traits in online comments using advanced hybrid models, specifically BERT-CNN and BERT-LSTM. The research methodology involved constructing and configuring multiple layers within these models to optimize their ability to detect harmful content. For the BERT-CNN model, BERT's powerful language understanding capabilities are combined with CNN's strength in feature extraction through convolutional layers, capturing spatial hierarchies of features. In the BERT-LSTM model, BERT is integrated with LSTM layers to leverage their ability to learn long-term dependencies and sequential patterns in text. Various configurations of these models were tested, including adj ustments in the batch sizes and the length of the word tokens, to enhance performance in identifying toxic language. The best model which is BERT-CNN using the configuration 256 as the unit and 32 as the batch size achieved 94.48% accuracy in detecting toxic comments. The result from the model indicates that by harnessing BERT's contextual embeddings and the respective benefits of CNN's and LSTM's processing capabilities, it is possible to significantly reduce the frequency of cyberbullying through effective detection, ultimately fostering safer online environments across different media platforms.",,,,, ,  2024 International Conference on Information Management and Technology (ICIMTech),Adaptation models;Visualization;Accuracy;Transfer learning;Cyberbullying;Media;Feature extraction;Information management;Convolutional neural networks;Long short term memory;toxic comment detection;BERT;LSTM;CNN;cyberbullying,detection,
3260,"**Title**The Automatic Detection of Abusive Language in Dota 2 Chat Messages

**Abstract**This study addresses the pervasive issue of abusive language in online video game communication channels, focusing on Dota 2 chat messages. The aim was to employ diverse traditional machine learning algorithms and advanced deep learning architectures to identify and classify toxic and abusive language effectively. Leveraging TF-IDF, GloVe word embeddings, and self-trained embeddings, the research compared various classical machine learning models such as Naïve Bayes, Logistic Regression, and Support Vector Machine with convolutional and recurrent neural network models. The results revealed a consistent trend where deep learning models, particularly those employing GRUs and LSTMs, outperformed classical machine learning models. Experiments also demonstrated that self-trained embeddings generally outperformed GloVe embeddings in the domain of online video game chat messages.","Du Toit, Johannes Louis, Kotzé, Eduan",,,The Automatic Detection of Abusive Language in Dota 2 Chat Messages,,,10.1109/ACDSA59508.2024.10467500 , ,,"This study addresses the pervasive issue of abusive language in online video game communication channels, focusing on Dota 2 chat messages. The aim was to employ diverse traditional machine learning algorithms and advanced deep learning architectures to identify and classify toxic and abusive language effectively. Leveraging TF-IDF, GloVe word embeddings, and self-trained embeddings, the research compared various classical machine learning models such as Naïve Bayes, Logistic Regression, and Support Vector Machine with convolutional and recurrent neural network models. The results revealed a consistent trend where deep learning models, particularly those employing GRUs and LSTMs, outperformed classical machine learning models. Experiments also demonstrated that self-trained embeddings generally outperformed GloVe embeddings in the domain of online video game chat messages.",,,,, ,"  2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)",Deep learning;Support vector machines;Video games;Analytical models;Logistic regression;Recurrent neural networks;Machine learning algorithms;abusive language classification;embeddings;GloVe;neural networks;machine learning;deep learning,detection,
3261,"**Title**Measuring and Mitigating Stereotype Bias in Language Models: An Overview of Debiasing Techniques

**Abstract**This paper provides an overview of methods for measuring the stereotype bias of pre-trained language models. It explains the term ‘stereotype bias’ and its measurement. A comprehensive review of language model debiasing techniques, including Dropout, Counterfactual Data Augmentation, Iterative Nullspace Projection, Sent-Debias, Self-Debias, Context-Debias, FairFil, and Auto-Debias, is provided. Subsequently, these techniques are compared, and their advantages and disadvantages are highlighted. In addition, there is an explanation of how these techniques work simply. In the future, debiasing techniques will be tested on pre-trained models for the Slovak language, focusing on the task of toxic language detection.","Sokolová, Zuzana, Harahus, Maroš, Staš, Ján, Kupcová, Eva, Sokol, Miroslav, Koctúrová, Marianna, Juhár, Jozef",,,Measuring and Mitigating Stereotype Bias in Language Models: An Overview of Debiasing Techniques,,,10.1109/ELMAR62909.2024.10694175 , ,,"This paper provides an overview of methods for measuring the stereotype bias of pre-trained language models. It explains the term ‘stereotype bias’ and its measurement. A comprehensive review of language model debiasing techniques, including Dropout, Counterfactual Data Augmentation, Iterative Nullspace Projection, Sent-Debias, Self-Debias, Context-Debias, FairFil, and Auto-Debias, is provided. Subsequently, these techniques are compared, and their advantages and disadvantages are highlighted. In addition, there is an explanation of how these techniques work simply. In the future, debiasing techniques will be tested on pre-trained models for the Slovak language, focusing on the task of toxic language detection.",,,,, ,  2024 International Symposium ELMAR,Measurement;Ethics;Reviews;Scalability;Focusing;Data augmentation;Robustness;Data models;Iterative methods;Testing;Debiasing technique;Language model;Measuring;Mitigating;Stereotype bias,detection,
3262,"**Title**AdversaFlow: Visual Red Teaming for Large Language Models with Multi-Level Adversarial Flow

**Abstract**Large Language Models (LLMs) are powerful but also raise significant security concerns, particularly regarding the harm they can cause, such as generating fake news that manipulates public opinion on social media and providing responses to unethical activities. Traditional red teaming approaches for identifying AI vulnerabilities rely on manual prompt construction and expertise. This paper introduces AdversaFlow, a novel visual analytics system designed to enhance LLM security against adversarial attacks through human-AI collaboration. AdversaFlow involves adversarial training between a target model and a red model, featuring unique multi-level adversarial flow and fluctuation path visualizations. These features provide insights into adversarial dynamics and LLM robustness, enabling experts to identify and mitigate vulnerabilities effectively. We present quantitative evaluations and case studies validating our system's utility and offering insights for future AI security solutions. Our method can enhance LLM security, supporting downstream scenarios like social media regulation by enabling more effective detection, monitoring, and mitigation of harmful content and behaviors.","Deng, Dazhen, Zhang, Chuhan, Zheng, Huawei, Pu, Yuwen, Ji, Shouling, Wu, Yingcai",,,AdversaFlow: Visual Red Teaming for Large Language Models with Multi-Level Adversarial Flow,,,10.1109/TVCG.2024.3456150 , ,,"Large Language Models (LLMs) are powerful but also raise significant security concerns, particularly regarding the harm they can cause, such as generating fake news that manipulates public opinion on social media and providing responses to unethical activities. Traditional red teaming approaches for identifying AI vulnerabilities rely on manual prompt construction and expertise. This paper introduces AdversaFlow, a novel visual analytics system designed to enhance LLM security against adversarial attacks through human-AI collaboration. AdversaFlow involves adversarial training between a target model and a red model, featuring unique multi-level adversarial flow and fluctuation path visualizations. These features provide insights into adversarial dynamics and LLM robustness, enabling experts to identify and mitigate vulnerabilities effectively. We present quantitative evaluations and case studies validating our system's utility and offering insights for future AI security solutions. Our method can enhance LLM security, supporting downstream scenarios like social media regulation by enabling more effective detection, monitoring, and mitigation of harmful content and behaviors.",,,,, ,  ,Security;Analytical models;Training;Visual analytics;Artificial intelligence;Toxicology;Safety;Visual Analytics for Machine Learning;Artificial Intelligence Security;Large Language Models;Text Visualization,out_of_scope,
3263,"**Title**Smart Helmet for Coal Mine Workers

**Abstract**A more conventional version of the smart helmet has been developed to help miners while working in the mining sector. The mining industry frequently has dangerous occurrences, many of which end in fatalities or seriously injured parties. Using different sensors, the smart helmet able to recognize catastrophic situations such as presence of harmful gases like Carbon-Monoxide (CO), Methane (CH4), Ammonia (NH3) as well as temperature and humidity within the mine areas. Also the pulse of the coal miner monitored continuously so that it can be detected whether the miner is facing some difficulty or if any accident has occurred in the mine. Helmet wear by miner or not wear, is detected by an infrared sensor, hence negligence of the miner for not wearing the safety helmet can be avoided. Each sensor used has a threshold value that, if that value is exceeded, it causes the buzzer to activate, signaling the miners and supervisors. Wi-Fi and ThingSpeak is used for the remote transmission of information from coal mine to a central location. This technology may improve the safety and scale back accidents within the coal mines.","Patil, Punam J, Bhole, Manisha, Pawar, Dilip N., Nadgaundi, Swati, Pawar, Reshma, Mhatre, Atharva",,,Smart Helmet for Coal Mine Workers,,,10.1109/ICICIS56802.2023.10430243 , ,,"A more conventional version of the smart helmet has been developed to help miners while working in the mining sector. The mining industry frequently has dangerous occurrences, many of which end in fatalities or seriously injured parties. Using different sensors, the smart helmet able to recognize catastrophic situations such as presence of harmful gases like Carbon-Monoxide (CO), Methane (CH4), Ammonia (NH3) as well as temperature and humidity within the mine areas. Also the pulse of the coal miner monitored continuously so that it can be detected whether the miner is facing some difficulty or if any accident has occurred in the mine. Helmet wear by miner or not wear, is detected by an infrared sensor, hence negligence of the miner for not wearing the safety helmet can be avoided. Each sensor used has a threshold value that, if that value is exceeded, it causes the buzzer to activate, signaling the miners and supervisors. Wi-Fi and ThingSpeak is used for the remote transmission of information from coal mine to a central location. This technology may improve the safety and scale back accidents within the coal mines.",,,,, ,  2023 International Conference on Integration of Computational Intelligent System (ICICIS),Temperature sensors;Temperature measurement;Head;Safety;Coal mining;Fuel processing industries;Monitoring;Smart Helmet;Coal Mine Safety;Hazard Detection;Remote Monitoring,out_of_scope,
3264,"**Title**RP Conversion and Air Quality Evaluation

**Abstract**One of the most important issues is indoor air quality in our environment-related. Formaldehyde, ammonia and other toxic substances in interior decoration materials and new furniture is known as a major source of indoor air pollution, indoor air gas into its volatile state. However, it is still using the current measurement tools to accurately estimate a challenge overall air quality. Therefore, the conversion from a region to a point (RP) is developed to evaluate the air quality in this article. Conversion from one area is defined as the first point value. It is the difference between the center and the belief that the threshold interval. In the RP conversion confident interval of the two sensors basic probability function is calculated based on the measurement value sensor of formaldehyde and ammonia sensor. Then, the interval is converted to a particular belief values. After the collision the extent and computing portfolio, the degree of contamination by the maximum probability and belief interval was chosen to represent the results of the integration decision. Compared with the Dempster-Shafer evidential reasoning conversion and weighted fusion method, the experiment proved that the conversion can improve the RP interval faith belief functions separability. In addition, the degree of conflict of evidence greatly reduced, so that the evidential reasoning to proceed.","Wang, Mei, Wang, Liang, Xu, Ningbo, Fu, Zhouxing",,,RP Conversion and Air Quality Evaluation,,,10.1109/IS3C.2014.70 , ,,"One of the most important issues is indoor air quality in our environment-related. Formaldehyde, ammonia and other toxic substances in interior decoration materials and new furniture is known as a major source of indoor air pollution, indoor air gas into its volatile state. However, it is still using the current measurement tools to accurately estimate a challenge overall air quality. Therefore, the conversion from a region to a point (RP) is developed to evaluate the air quality in this article. Conversion from one area is defined as the first point value. It is the difference between the center and the belief that the threshold interval. In the RP conversion confident interval of the two sensors basic probability function is calculated based on the measurement value sensor of formaldehyde and ammonia sensor. Then, the interval is converted to a particular belief values. After the collision the extent and computing portfolio, the degree of contamination by the maximum probability and belief interval was chosen to represent the results of the integration decision. Compared with the Dempster-Shafer evidential reasoning conversion and weighted fusion method, the experiment proved that the conversion can improve the RP interval faith belief functions separability. In addition, the degree of conflict of evidence greatly reduced, so that the evidential reasoning to proceed.",,,,, ,"  2014 International Symposium on Computer, Consumer and Control",Sensors;Estimation;Cognition;Air pollution;Atmospheric measurements;Pollution measurement;air quality evaluation;RP conversion;AWF Fusion,out_of_scope,
3265,"**Title**Cultural Insights in Souls-Like Games: Analyzing Player Behaviors, Perspectives, and Emotions Across a Multicultural Context

**Abstract**Souls-like games are one of the most popular and emerging genres in the contemporary gaming world. This study compared the behavioral characteristics, perspectives, and emotional expressions of players in Souls-like games from different cultural backgrounds, specifically examining the distinctions and commonalities among them. Natural language processing techniques were employed to analyze English, Chinese, and Russian reviews of 17 Souls-like games to investigate players' gaming experiences, including gameplay behaviors, game evaluations, and emotional experiences. The findings revealed significant disparities among players from different cultures in all three aspects of their engagement with Souls-like games. Specifically, these players exhibited significant culture-related variations in their behavioral characteristics toward Souls-like games. In terms of perspectives, English-speaking players tended to focus more on game optimization, whereas Chinese and Russian players paid greater attention to game combat design. Regarding emotional expressions, Chinese players were more prone to exhibit emotions of anger and disgust, while English and Russian players displayed a more neutral emotional stance. These cultural insights provide valuable information for game developers to better meet the needs and expectations of players from different cultural backgrounds. This study not only broadens our understanding of player behaviors and cultural influences but also lends robust support to cross-cultural gaming research.","Pan, Sicheng, Xu, Gary J. W., Guo, Kun, Park, Seop Hyeong, Ding, Hongliang",,,"Cultural Insights in Souls-Like Games: Analyzing Player Behaviors, Perspectives, and Emotions Across a Multicultural Context",,,10.1109/TG.2024.3366239 , ,,"Souls-like games are one of the most popular and emerging genres in the contemporary gaming world. This study compared the behavioral characteristics, perspectives, and emotional expressions of players in Souls-like games from different cultural backgrounds, specifically examining the distinctions and commonalities among them. Natural language processing techniques were employed to analyze English, Chinese, and Russian reviews of 17 Souls-like games to investigate players' gaming experiences, including gameplay behaviors, game evaluations, and emotional experiences. The findings revealed significant disparities among players from different cultures in all three aspects of their engagement with Souls-like games. Specifically, these players exhibited significant culture-related variations in their behavioral characteristics toward Souls-like games. In terms of perspectives, English-speaking players tended to focus more on game optimization, whereas Chinese and Russian players paid greater attention to game combat design. Regarding emotional expressions, Chinese players were more prone to exhibit emotions of anger and disgust, while English and Russian players displayed a more neutral emotional stance. These cultural insights provide valuable information for game developers to better meet the needs and expectations of players from different cultural backgrounds. This study not only broadens our understanding of player behaviors and cultural influences but also lends robust support to cross-cultural gaming research.",,,,, ,  ,Games;Cultural differences;Behavioral sciences;Social networking (online);Video games;History;Emotion recognition;Cultural difference;emotion detection;game reviews;human factors in games;Souls-like games;topic modeling,out_of_scope,
3266,"**Title**GPRS Based System for Atmospheric Pollution Monitoring and Warning

**Abstract**This paper presents the synthesis of a SCADA (supervisory control and data acquisition) system, named Pollution Guard, designed to collect and process atmospheric pollution data measured in several strategic points of a region. Pollution Guard makes use of the GPRS (general packet radio service) data communication infrastructure from a mobile communication provider that covers a very large area, practically the air pollution data being collected from every place in the country. In comparison to other similar systems, the new functionalities provided by Pollution Guard are the SMS (short messaging system) and e-mail alerts generated when the level of toxic substances exceeds some given values, chosen with regard to respiratory illness","Constantin, Suciu, Moldoveanu, Florin, Campeanu, Radu, Baciu, Ioana, Grigorescu, Sorin Mihai, Carstea, Bogdan, Voinea, Vlad",,,GPRS Based System for Atmospheric Pollution Monitoring and Warning,,,10.1109/AQTR.2006.254630 , ,,"This paper presents the synthesis of a SCADA (supervisory control and data acquisition) system, named Pollution Guard, designed to collect and process atmospheric pollution data measured in several strategic points of a region. Pollution Guard makes use of the GPRS (general packet radio service) data communication infrastructure from a mobile communication provider that covers a very large area, practically the air pollution data being collected from every place in the country. In comparison to other similar systems, the new functionalities provided by Pollution Guard are the SMS (short messaging system) and e-mail alerts generated when the level of toxic substances exceeds some given values, chosen with regard to respiratory illness",,,,, ,"  2006 IEEE International Conference on Automation, Quality and Testing, Robotics",Ground penetrating radar;Monitoring;Air pollution;Control system synthesis;SCADA systems;Atmospheric measurements;Pollution measurement;Packet radio networks;Data communication;Mobile communication;Data acquisition;analog-to-digital conversion;microcontroller;wireless;GPRS;SMS;Java,out_of_scope,
3267,"**Title**Visions of Violence : Threatful Communication in Incel Communities

**Abstract**The incel subculture has gained increasing attention due to its toxic nature and its association with real-world violence. This paper investigates the prevalence and characteristics of violent threatful communication within incel forums, focusing on a platform known as Blackpill. We have trained a machine learning model to detect violent threatful language and analyzed the posts. The analysis concentrated on three key aspects: the identity of perpetrators (categorized into first-person, third-person, or generalized), the targets (individuals, groups, or general targets), and the types of violence described (general violence, sexual violence, self-harm, and military violence). The analysis showed that the most common type violent threatful communication involved generalized perpetrators targeting groups. Additionally, 13.5% of the violent threatful communication contained coded language, including references to video games to obscure violent intentions. A smaller proportion of the posts (4.1%) glorified past mass shooters and violent criminals.This research highlights the complexities of identifying violent rhetoric in online forums and the use of coded language to evade detection, emphasizing the need for refined models in threat detection.","Lundmark, Lukas, Kaati, Lisa, Shrestha, Amendra",,,Visions of Violence : Threatful Communication in Incel Communities,,,10.1109/BigData62323.2024.10825043 , ,,"The incel subculture has gained increasing attention due to its toxic nature and its association with real-world violence. This paper investigates the prevalence and characteristics of violent threatful communication within incel forums, focusing on a platform known as Blackpill. We have trained a machine learning model to detect violent threatful language and analyzed the posts. The analysis concentrated on three key aspects: the identity of perpetrators (categorized into first-person, third-person, or generalized), the targets (individuals, groups, or general targets), and the types of violence described (general violence, sexual violence, self-harm, and military violence). The analysis showed that the most common type violent threatful communication involved generalized perpetrators targeting groups. Additionally, 13.5% of the violent threatful communication contained coded language, including references to video games to obscure violent intentions. A smaller proportion of the posts (4.1%) glorified past mass shooters and violent criminals.This research highlights the complexities of identifying violent rhetoric in online forums and the use of coded language to evade detection, emphasizing the need for refined models in threat detection.",,,,, ,  2024 IEEE International Conference on Big Data (BigData),Video games;Analytical models;Focusing;Machine learning;Big Data;Threat assessment;Rhetoric;Complexity theory,detection,
3268,"**Title**Enhancing Toxic Comment Classification: A Deep Learning Approach with Pre-trained Language Models

**Abstract**Because of online communication, e-commerce, and digital devices, text data—especially short text—permeates every aspect of our life in the digital age. However, this transformation has also unveiled a darker side - the prevalence of harmful, offensive, and toxic comments, including hate speech and harassment. The integrity of online groups, social harmony, and individual safety are all gravely threatened by this toxin. In this work, we examine the effectiveness of two recurrent neural network (RNN) architectures, namely Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM), for the classification of damaging comments. These models are evaluated using key metrics such as F1-score, recall, accuracy, and precision. Important measures, including accuracy, precision, recall, and F1-score, are used to assess these models. According to our findings, the GRU achieves higher precision and overall accuracy, while the LSTM performs well in recall, spotting harmful comments at the expense of pinpoint accuracy. Model selection should align with specific project goals and trade-offs between precision and recall.","Tejwani, Khushi, Naik, Ved, Lari, Aanya, Jhaveri, Dhruvin",,,Enhancing Toxic Comment Classification: A Deep Learning Approach with Pre-trained Language Models,,,10.1109/ICISAA62385.2024.10829297 , ,,"Because of online communication, e-commerce, and digital devices, text data—especially short text—permeates every aspect of our life in the digital age. However, this transformation has also unveiled a darker side - the prevalence of harmful, offensive, and toxic comments, including hate speech and harassment. The integrity of online groups, social harmony, and individual safety are all gravely threatened by this toxin. In this work, we examine the effectiveness of two recurrent neural network (RNN) architectures, namely Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM), for the classification of damaging comments. These models are evaluated using key metrics such as F1-score, recall, accuracy, and precision. Important measures, including accuracy, precision, recall, and F1-score, are used to assess these models. According to our findings, the GRU achieves higher precision and overall accuracy, while the LSTM performs well in recall, spotting harmful comments at the expense of pinpoint accuracy. Model selection should align with specific project goals and trade-offs between precision and recall.",,,,, ,  2024 International Conference on Intelligent Systems and Advanced Applications (ICISAA),Measurement;Accuracy;Toxicology;Recurrent neural networks;Personal digital devices;Logic gates;Information age;Safety;Intelligent systems;Long short term memory;Enhancing Toxic Comment Classification;GRU;LSTM;Toxicity;Comment;Function;Deep Learning;RNN,detection,
3269,"**Title**Toxic language based echo chambers on the Incels.net community: A network analysis approach

**Abstract**This study examines interaction patterns on the web forum Incels.net through Social Network Analysis, focusing on the formation of echo chambers characterized by toxic language. We explore several hypotheses: (H2) users tend to engage in animated one-to-one interactions by quoting each other; (H4) frequent posters are less likely to be quoted by less active users, indicating a lack of clear leadership; and (H5) users sharing the same sentiment are more likely to participate in large discussions (echo chambers) but do not engage in one-to-one conversations. Our findings enhance the understanding of behaviors that may contribute to radicalization within fringe online communities and offer insights for future research into similar extreme hate forums.","Janssen, Mathieu, Zucca, Claudia, Cascavilla, Giuseppe, Cuzzocrea, Alfredo",,,Toxic language based echo chambers on the Incels.net community: A network analysis approach,,,10.1109/BigData62323.2024.10825922 , ,,"This study examines interaction patterns on the web forum Incels.net through Social Network Analysis, focusing on the formation of echo chambers characterized by toxic language. We explore several hypotheses: (H2) users tend to engage in animated one-to-one interactions by quoting each other; (H4) frequent posters are less likely to be quoted by less active users, indicating a lack of clear leadership; and (H5) users sharing the same sentiment are more likely to participate in large discussions (echo chambers) but do not engage in one-to-one conversations. Our findings enhance the understanding of behaviors that may contribute to radicalization within fringe online communities and offer insights for future research into similar extreme hate forums.",,,,, ,  2024 IEEE International Conference on Big Data (BigData),Leadership;Social networking (online);Focusing;Oral communication;Network analyzers;Inceldom;Sentiment Analysis;TERGMs;Social Networks;language-based echo chambers,detection,
3270,"**Title**On Large Language Models’ Resilience to Coercive Interrogation

**Abstract**Large Language Models (LLMs) are increasingly employed in numerous applications. It is hence important to ensure that their ethical standard aligns with humans’. However, existing jail-breaking efforts show that such alignment could be compromised by well-crafted prompts. In this paper, we disclose a new threat to LLMs alignment when a malicious actor has access to the top-k token predictions at each output position of the model, such as in all open-source LLMs and many commercial LLMs that provide the needed APIs (e.g., some GPT versions). It does not require crafting any prompt. Instead, it leverages the observation that even when an LLM declines a toxic query, the harmful response is concealed deep within the output logits. We can coerce the model to disclose it by forcefully using low-ranked output tokens during auto-regressive output generation, and such forcing is only needed in a very small number of selected output positions. We call it model interrogation. Since our method operates differently from jail-breaking, it has better effectiveness than state-of-the- art jail-breaking techniques (92% versus 62%) and is 10 to 20 times faster. The toxic content elicited by our method is also of better quality. More importantly, it is complementary to jail-breaking, and a synergetic integration of the two exhibits superior performance over individual methods. We also find that with interrogation, harmful content can even be extracted from models customized for coding tasks.","Zhang, Zhuo, Shen, Guangyu, Tao, Guanhong, Cheng, Siyuan, Zhang, Xiangyu",,,On Large Language Models’ Resilience to Coercive Interrogation,,,10.1109/SP54263.2024.00208 , ,,"Large Language Models (LLMs) are increasingly employed in numerous applications. It is hence important to ensure that their ethical standard aligns with humans’. However, existing jail-breaking efforts show that such alignment could be compromised by well-crafted prompts. In this paper, we disclose a new threat to LLMs alignment when a malicious actor has access to the top-k token predictions at each output position of the model, such as in all open-source LLMs and many commercial LLMs that provide the needed APIs (e.g., some GPT versions). It does not require crafting any prompt. Instead, it leverages the observation that even when an LLM declines a toxic query, the harmful response is concealed deep within the output logits. We can coerce the model to disclose it by forcefully using low-ranked output tokens during auto-regressive output generation, and such forcing is only needed in a very small number of selected output positions. We call it model interrogation. Since our method operates differently from jail-breaking, it has better effectiveness than state-of-the- art jail-breaking techniques (92% versus 62%) and is 10 to 20 times faster. The toxic content elicited by our method is also of better quality. More importantly, it is complementary to jail-breaking, and a synergetic integration of the two exhibits superior performance over individual methods. We also find that with interrogation, harmful content can even be extracted from models customized for coding tasks.",,,,, ,  2024 IEEE Symposium on Security and Privacy (SP),Privacy;Ethics;Art;Large language models;Predictive models;Encoding;Security,detection,
3271,"**Title**CRDA: Content Risk Drift Assessment of Large Language Models through Adversarial Multi-Agent Interaction

**Abstract**As Large Language Models (LLMs) continue to enhance their capabilities in multi-agent collaborative applications, the unpredictability of the generative content risks has intensified. Particularly in ongoing interaction scenarios with users, it remains unclear whether there is generative content risk drift over time. In this context, ""drift risk"" refers to the trend of progressively intensified content risk that emerges during sustained adversarial interactions among LLM agents. Additionally, the high cost associated with constructing complex adversarial environments for agents impedes the transferability of current assessment methods for LLMs to multi-agent adversarial scenarios. In this paper, we introduce a low-cost and lightweight framework for assessing content risk drift of LLMs, named CRDA. This framework, bypassing the need for constructing complex adversarial environments, offers a method that integrates roles and responses memory to guide automatically multi-round adversarial interactions among LLM agents, that is, multiple agents as avatars of a single LLM. In this approach, LLM agents enable the analysis of content risk drift of this LLM. Moreover, we explore the impact of restricted roles and the unsafe content with negative viewpoints in responses memory on the content risk drift of LLMs. Considering the rapid advancement of Chinese LLM capabilities, this study selects real adversarial topics in Chinese and assesses content risk drift of five representative Chinese LLMs. The research finds that these LLMs exhibit significant content risk drift even after a certain safety alignment, showing an initial increase followed by a gradual decrease. As the adversarial process progresses, under restricted roles, agents more effectively breach the model's safety alignment, leading to content risk drift of the LLM. The content drift risk assessment can be quantified specifically by measuring the deterioration rate at which LLM agents deteriorate from positive to negative and analyzing the underlying trends during the automatically multi-round adversarial interactions. In restricted and general roles adversarial interactions, all agents of five Chinese LLMs exhibit an overall average increase of 31.5% and 16.38% in the cumulative deterioration rate respectively by the 10th round, compared to the baseline no-roles adversarial interactions. Finally, we hope that the framework and findings presented in this paper will offer valuable insights for research on safety alignment in LLM agents during adversarial processes.","Liu, Zongzhen, Li, Guoyi, Shi, Bingkang, Zhang, Xiaodan, Ge, Jingguo, Wu, Yulei, Lyu, Honglei",,,CRDA: Content Risk Drift Assessment of Large Language Models through Adversarial Multi-Agent Interaction,,,10.1109/IJCNN60899.2024.10650172 , ,,"As Large Language Models (LLMs) continue to enhance their capabilities in multi-agent collaborative applications, the unpredictability of the generative content risks has intensified. Particularly in ongoing interaction scenarios with users, it remains unclear whether there is generative content risk drift over time. In this context, ""drift risk"" refers to the trend of progressively intensified content risk that emerges during sustained adversarial interactions among LLM agents. Additionally, the high cost associated with constructing complex adversarial environments for agents impedes the transferability of current assessment methods for LLMs to multi-agent adversarial scenarios. In this paper, we introduce a low-cost and lightweight framework for assessing content risk drift of LLMs, named CRDA. This framework, bypassing the need for constructing complex adversarial environments, offers a method that integrates roles and responses memory to guide automatically multi-round adversarial interactions among LLM agents, that is, multiple agents as avatars of a single LLM. In this approach, LLM agents enable the analysis of content risk drift of this LLM. Moreover, we explore the impact of restricted roles and the unsafe content with negative viewpoints in responses memory on the content risk drift of LLMs. Considering the rapid advancement of Chinese LLM capabilities, this study selects real adversarial topics in Chinese and assesses content risk drift of five representative Chinese LLMs. The research finds that these LLMs exhibit significant content risk drift even after a certain safety alignment, showing an initial increase followed by a gradual decrease. As the adversarial process progresses, under restricted roles, agents more effectively breach the model's safety alignment, leading to content risk drift of the LLM. The content drift risk assessment can be quantified specifically by measuring the deterioration rate at which LLM agents deteriorate from positive to negative and analyzing the underlying trends during the automatically multi-round adversarial interactions. In restricted and general roles adversarial interactions, all agents of five Chinese LLMs exhibit an overall average increase of 31.5% and 16.38% in the cumulative deterioration rate respectively by the 10th round, compared to the baseline no-roles adversarial interactions. Finally, we hope that the framework and findings presented in this paper will offer valuable insights for research on safety alignment in LLM agents during adversarial processes.",,,,, ,  2024 International Joint Conference on Neural Networks (IJCNN),Costs;Large language models;Avatars;Neural networks;Collaboration;Market research;Safety,out_of_scope,
3272,"**Title**The development of Taiwan's Toxic Potential Indicator (TPI)

**Abstract**This paper presents a study of evaluating environmental impacts in Taiwan's electronics product manufacturing. The focus of impact evaluation is on the toxic potential of electronics product. The computational structure of Toxic Potential Indicator (TPI) developed by Fraunhofer Institute for Reliability and Microintegration (IZM) was used to evaluate the toxic potential of electronics product in Taiwan. The difficulties and problems in implementing the computing TPI value in Taiwan was identified and discussed. Some adjusting approach is proposed in this paper to overcome it. The proposed procedures and evaluated results can be used as the basis for environmentally conscious electronics product design in Taiwan.","Yen, Sheng-Bou, Chen, Jahau Lewis",,,The development of Taiwan's Toxic Potential Indicator (TPI),,,10.1109/ECODIM.2003.1322746 , ,,This paper presents a study of evaluating environmental impacts in Taiwan's electronics product manufacturing. The focus of impact evaluation is on the toxic potential of electronics product. The computational structure of Toxic Potential Indicator (TPI) developed by Fraunhofer Institute for Reliability and Microintegration (IZM) was used to evaluate the toxic potential of electronics product in Taiwan. The difficulties and problems in implementing the computing TPI value in Taiwan was identified and discussed. Some adjusting approach is proposed in this paper to overcome it. The proposed procedures and evaluated results can be used as the basis for environmentally conscious electronics product design in Taiwan.,,,,, ,  2003 EcoDesign 3rd International Symposium on Environmentally Conscious Design and Inverse Manufacturing,Electronics industry,out_of_scope,
3273,"**Title**Garbage collector-A Web Based System

**Abstract**Smart cities are implementing web-based systems to improve the living conditions of their inhabitants. One such solution is the implementation of an efficient and eco-friendly garbage management system. Currently, garbage collection involves regular garbage trucks that pick-up garbage once a week in every zone of the city, which is a highly inefficient use of government resources. In this work, a web-based system is proposed to manage the large amount of garbage collected daily while also providing a better solution. The system involves users renting dumpsters to collect waste generated in their respective areas, which will then be decomposed at designated dumping yards. This approach aims to reduce emissions of toxic chemicals that pollute the environment.","Gupta, Piyush, Khan, Fardeen, Dixit, Varun, Chaudhary, Laxmi",,,Garbage collector-A Web Based System,,,10.1109/ICI60088.2023.10421653 , ,,"Smart cities are implementing web-based systems to improve the living conditions of their inhabitants. One such solution is the implementation of an efficient and eco-friendly garbage management system. Currently, garbage collection involves regular garbage trucks that pick-up garbage once a week in every zone of the city, which is a highly inefficient use of government resources. In this work, a web-based system is proposed to manage the large amount of garbage collected daily while also providing a better solution. The system involves users renting dumpsters to collect waste generated in their respective areas, which will then be decomposed at designated dumping yards. This approach aims to reduce emissions of toxic chemicals that pollute the environment.",,,,, ,  2023 Second International Conference on Informatics (ICI),Humanities;Smart cities;Toxic chemicals;Government;Real-time systems;Informatics;Standards;Garbage management;Web based system;Garbage Collection;Services,out_of_scope,
3274,"**Title**Constructing Toxic Potential Indicator (TPI) for mixture material

**Abstract**When the designer applies TPI methodology into mixture material to estimate the environmental impact, the designer will often face an obstacle that the unit of mixtures' MAK is ppm, and the molecular weight of mixtures can't be obtained. Therefore, the designer can't transform the unit of mixtures' MAK from ppm into mg/m3. This study proposes three feasible methods to evaluate the TPI value of mixture products. After comparing the advantages and defects of these three feasible methods, this study proposes a best method to construct the TPI value of mixture material. Constructing the products' TPI with mixtures not only can evaluate the environmental impact, but also can help the designer developing sustainable products.","Chen, Jahau Lewis, Ju, Jian-Hung, Yen, Sheng-Bou",,,Constructing Toxic Potential Indicator (TPI) for mixture material,,, , ,,"When the designer applies TPI methodology into mixture material to estimate the environmental impact, the designer will often face an obstacle that the unit of mixtures' MAK is ppm, and the molecular weight of mixtures can't be obtained. Therefore, the designer can't transform the unit of mixtures' MAK from ppm into mg/m3. This study proposes three feasible methods to evaluate the TPI value of mixture products. After comparing the advantages and defects of these three feasible methods, this study proposes a best method to construct the TPI value of mixture material. Constructing the products' TPI with mixtures not only can evaluate the environmental impact, but also can help the designer developing sustainable products.",,,,, ,  2012 Electronics Goes Green 2012+,Water pollution;Employment;Materials;Abstracts,out_of_scope,
3275,"**Title**Conversation Sentiment Analysis in League of Legends Game Community

**Abstract**Gaming communities are groups of people from different nations, religions, genders, and ages who come to play games and have discussions about the games. However, some gaming communities are plagued by toxic behavior of people in communities, which negatively affects to other players. A Conversation Sentiment Analysis in the League of Legends Game Community is about analyzing the toxicity of the League of Legends game community by using the Sentiment Analysis methods which have Bag-of-Words and Weight Score method, and then comparing it with three machine learning techniques: Logistic Regression, Support Vector Machine (SVM), and CatBoost, and showing how members in this community have interacted with other members in the community by using the Conversation Mapping Interactive method.","Pongkhan, Thutchaphong, Khoosirirat, Phutanate, Songmuang, Pokpong, Kongkachandra, Rachada",,,Conversation Sentiment Analysis in League of Legends Game Community,,,10.1109/ICCI60780.2024.10532675 , ,,"Gaming communities are groups of people from different nations, religions, genders, and ages who come to play games and have discussions about the games. However, some gaming communities are plagued by toxic behavior of people in communities, which negatively affects to other players. A Conversation Sentiment Analysis in the League of Legends Game Community is about analyzing the toxicity of the League of Legends game community by using the Sentiment Analysis methods which have Bag-of-Words and Weight Score method, and then comparing it with three machine learning techniques: Logistic Regression, Support Vector Machine (SVM), and CatBoost, and showing how members in this community have interacted with other members in the community by using the Conversation Mapping Interactive method.",,,,, ,  2024 IEEE International Conference on Cybernetics and Innovations (ICCI),Support vector machines;Sentiment analysis;Humanities;Technological innovation;Logistic regression;Toxicology;Social networking (online);Toxic behavior;Sentiment Analysis;Machine Learning;Conversation Mapping;Sentiment Classification;Text Mining;NLP;Game Community;Network Graph,detection,
3276,"**Title**How to improve control system performance using FF function blocks

**Abstract**An important process control trend is the implementation of digital communication with field control devices. Traditional distributed control systems are being augmented with smart field instruments. Foundation Fieldbus is a digital control network that interlinks such ""smart"" field instruments like sensors and actuators in a process control environment. In the Foundation Fieldbus all the control algorithms and data acquisition are executed by structures called function blocks. This paper attempts to improve the performance based on these function blocks. First, an introduction to the function blocks of Foundation Fieldbus and their structure and execution process are presented. Then, an example of a fermentation process is described. The structure of the control system and the implementation of distributed control based on function blocks are discussed. Finally, the problems related to system safety with function blocks and their programming language are dealt with.","Chen, Jiming, Wang, Zhi, Sun, YouXian",,,How to improve control system performance using FF function blocks,,,10.1109/CCA.2002.1038744 , ,,"An important process control trend is the implementation of digital communication with field control devices. Traditional distributed control systems are being augmented with smart field instruments. Foundation Fieldbus is a digital control network that interlinks such ""smart"" field instruments like sensors and actuators in a process control environment. In the Foundation Fieldbus all the control algorithms and data acquisition are executed by structures called function blocks. This paper attempts to improve the performance based on these function blocks. First, an introduction to the function blocks of Foundation Fieldbus and their structure and execution process are presented. Then, an example of a fermentation process is described. The structure of the control system and the implementation of distributed control based on function blocks are discussed. Finally, the problems related to system safety with function blocks and their programming language are dealt with.",,,,, ,  Proceedings of the International Conference on Control Applications,Control systems;System performance;Communication system control;Field buses;Process control;Distributed control;Instruments;Digital communication;Digital control;Intelligent sensors,out_of_scope,
3277,"**Title**Construction of Emergency Decision System Based on GIS

**Abstract**In order to achieve quick response and scientific decision-making, it is necessary to build a distributed emergency decision-making system. In this paper, the system uses a frame structure with combination of B/S and C/S technologies, and bases on WebGIS and other technologies, which provide a technology platform for the System. This system has the ability to report the disaster situation to the command center, simultaneously, it also fast implements auxiliary decision. This article focuses on the design thoughts, key technologies, and applications, and finally an example is given for analysis and simulation to explore the system specific application in an emergency.","Zhu, Lingyun, Song, Wenhua, Li, Qinggong",,,Construction of Emergency Decision System Based on GIS,,,10.1109/KESE.2009.52 , ,,"In order to achieve quick response and scientific decision-making, it is necessary to build a distributed emergency decision-making system. In this paper, the system uses a frame structure with combination of B/S and C/S technologies, and bases on WebGIS and other technologies, which provide a technology platform for the System. This system has the ability to report the disaster situation to the command center, simultaneously, it also fast implements auxiliary decision. This article focuses on the design thoughts, key technologies, and applications, and finally an example is given for analysis and simulation to explore the system specific application in an emergency.",,,,, ,  2009 Pacific-Asia Conference on Knowledge Engineering and Software Engineering,Geographic Information Systems;Decision making;Information analysis;Decision support systems;Disaster management;Analytical models;Accidents;Knowledge engineering;Fires;Computer network management;WebGIS;emergency;decision support model;construction,out_of_scope,
3278,"**Title**TCM-KDIF: An Information Interaction Framework Driven by Knowledge–Data and Its Clinical Application in Traditional Chinese Medicine

**Abstract**The effectiveness of traditional Chinese medicine (TCM) has been proved by various researches in decades, especially in the COVID-19 pandemic. Numerous TCM-AI interdisciplinary researches have been proposed for trying to modeling its mechanism and knowledge, assisting efficient decision making of human doctors. Currently, most of the works are focus on supervised learning paradigm. Such methodology leads to the fact that models fail in scenario of rare disease (few samples are available). In this work, we focus on the knowledge–data-oriented mechanism and design a framework enables the model ability to interact the information between knowledge and samples, called TCM-KDIF. We build a TCM knowledge graph (KG) with the TCM concepts (macroscopic) and molecular biology (microcosmic). Based on it, models can interact the information of training samples with external KG by TCM-KDIF. The proposed framework extracts the features of training samples and its related knowledge subgraph first. Then, these two types of information communicate in both directions between samples and knowledge subgraph iteratively. The TCM-KDIF is evaluated on the TCM prescription generation task. The experimental results demonstrate that the TCM-KDIF outperforms all comparison baselines, reduces model’s dependency on training samples, and reveal the possible interact mechanisms between medicine and symptoms.","Liu, Zhi, Yang, Jiaxi, Chen, Kui, Yang, Tao, Li, Xiaochen, Lu, Bingjie, Fu, Dianzheng, Zheng, Zeyu, Luo, Changyong",,,TCM-KDIF: An Information Interaction Framework Driven by Knowledge–Data and Its Clinical Application in Traditional Chinese Medicine,,,10.1109/JIOT.2024.3368029 , ,,"The effectiveness of traditional Chinese medicine (TCM) has been proved by various researches in decades, especially in the COVID-19 pandemic. Numerous TCM-AI interdisciplinary researches have been proposed for trying to modeling its mechanism and knowledge, assisting efficient decision making of human doctors. Currently, most of the works are focus on supervised learning paradigm. Such methodology leads to the fact that models fail in scenario of rare disease (few samples are available). In this work, we focus on the knowledge–data-oriented mechanism and design a framework enables the model ability to interact the information between knowledge and samples, called TCM-KDIF. We build a TCM knowledge graph (KG) with the TCM concepts (macroscopic) and molecular biology (microcosmic). Based on it, models can interact the information of training samples with external KG by TCM-KDIF. The proposed framework extracts the features of training samples and its related knowledge subgraph first. Then, these two types of information communicate in both directions between samples and knowledge subgraph iteratively. The TCM-KDIF is evaluated on the TCM prescription generation task. The experimental results demonstrate that the TCM-KDIF outperforms all comparison baselines, reduces model’s dependency on training samples, and reveal the possible interact mechanisms between medicine and symptoms.",,,,, ,  ,Diseases;Knowledge graphs;Pathology;Supervised learning;Microscopy;Few shot learning;Drugs;Medical services;Natural language processing;Clinical diagnosis;Few-shot learning;intelligent medicine;knowledge graph (KG);natural language processing;rare disease;traditional Chinese medicine (TCM) clinical records;TCM,out_of_scope,
3279,"**Title**Monitoring The Evolution Of Antisemitic Hate Speech On Extremist Social Media

**Abstract**Racism and intolerance on social media contribute to a toxic online environment which may spill offline to foster hatred, and eventually lead to physical violence. That is the case with online antisemitism, the specific category of hatred considered in this study. Tracking antisemitic themes and their associated terminology over time in online discussions could help monitor the sentiments of their participants and their evolution, and possibly offer avenues for intervention that may prevent the escalation of hatred. Due to the large volume and constant evolution of online traffic, monitoring conversations manually is impractical. Instead, we propose an automated method that extracts antisemitic themes and terminology from extremist social media over time and captures their evolution. Since supervised learning would be too limited for such a task, we created an unsupervised online machine learning approach that uses large language models to assess the contextual similarity of posts. The method clusters similar posts together, dividing, and creating additional clusters over time when subthemes emerge from existing ones or new themes appear. The antisemitic terminology used within each theme is extracted from the posts in each cluster. Our experiments show that our methodology outperforms existing baselines and demonstrates the kind of themes and sub-themes it discovers within antisemitic discourse along with their associated terminology. We believe that our approach will be useful for monitoring the evolution of all kinds of hatred beyond antisemitism on social platforms.","Ul Mustafa, Raza, Japkowicz, Nathalie",,,Monitoring The Evolution Of Antisemitic Hate Speech On Extremist Social Media,,,10.1109/DPSH60098.2024.10774848 , ,,"Racism and intolerance on social media contribute to a toxic online environment which may spill offline to foster hatred, and eventually lead to physical violence. That is the case with online antisemitism, the specific category of hatred considered in this study. Tracking antisemitic themes and their associated terminology over time in online discussions could help monitor the sentiments of their participants and their evolution, and possibly offer avenues for intervention that may prevent the escalation of hatred. Due to the large volume and constant evolution of online traffic, monitoring conversations manually is impractical. Instead, we propose an automated method that extracts antisemitic themes and terminology from extremist social media over time and captures their evolution. Since supervised learning would be too limited for such a task, we created an unsupervised online machine learning approach that uses large language models to assess the contextual similarity of posts. The method clusters similar posts together, dividing, and creating additional clusters over time when subthemes emerge from existing ones or new themes appear. The antisemitic terminology used within each theme is extracted from the posts in each cluster. Our experiments show that our methodology outperforms existing baselines and demonstrates the kind of themes and sub-themes it discovers within antisemitic discourse along with their associated terminology. We believe that our approach will be useful for monitoring the evolution of all kinds of hatred beyond antisemitism on social platforms.",,,,, ,  2024 IEEE Digital Platforms and Societal Harms (DPSH),Visualization;Social networking (online);Terminology;Large language models;Supervised learning;Knowledge based systems;Hate speech;Machine learning;Oral communication;Monitoring;hate speech;concept formation;monitoring;antisemitic speech,detection,
3280,"**Title**Uninstall, Noob! Views on Rampant Toxicity in Online Gaming

**Abstract**Video games have become a big part of the digital world, evolving from mere sources of entertainment to entire career paths. Combined with improved device accessibility and implemented network-based features, gamers all around the world can play together any time they want. While the increased social aspects of video games mean that players can make new friends wherever they are in the world, some gamers take advantage of anonymity to harass others for various reasons. As the number of gamers grows over the years, so does the number of toxic behaviors found in online video games. In this research, a survey is conducted on the United Arab Emirates University (UAEU) community to collect their experiences with toxicity and harassment in online video games, as well as player reporting systems. The results show that racism, sexism, and extreme slurs are encountered the most and that current reporting systems are ineffective in the battle to curb toxicity.","Saleous, Heba, Gergely, Marton",,,"Uninstall, Noob! Views on Rampant Toxicity in Online Gaming",,,10.1109/DASC/PiCom/CBDCom/Cy59711.2023.10361444 , ,,"Video games have become a big part of the digital world, evolving from mere sources of entertainment to entire career paths. Combined with improved device accessibility and implemented network-based features, gamers all around the world can play together any time they want. While the increased social aspects of video games mean that players can make new friends wherever they are in the world, some gamers take advantage of anonymity to harass others for various reasons. As the number of gamers grows over the years, so does the number of toxic behaviors found in online video games. In this research, a survey is conducted on the United Arab Emirates University (UAEU) community to collect their experiences with toxicity and harassment in online video games, as well as player reporting systems. The results show that racism, sexism, and extreme slurs are encountered the most and that current reporting systems are ineffective in the battle to curb toxicity.",,,,, ,"  2023 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)",Surveys;Video games;Toxicology;Engineering profession;Databases;Hate speech;Entertainment industry;Video games;cyberbullying;harassment;survey;negativity,out_but_toxicity,
3281,"**Title**KoMIS: An Ontology-Based Knowledge Management System for Industrial Safety

**Abstract**This paper presents an ontology-based knowledge management system for indexing and retrieving information about a domain-specific corpus of resources in an industrial enterprise. From our ongoing project KoMIS (knowledge management for industrial safety), we introduce in this paper our approach to index the internal resources of an enterprise using two ontologies; a domain ontology that describes the terms of the studied domain (the industrial safety domain), and an application ontology that describes the various types of indexed resources. In our indexing approach, the resulting index is an RDF file that can be interrogated using one of the RDF query languages. An ontology-based information retrieval system is built as a Web application to help and guide users in their research for resources. Thanks to our indexing and retrieval model, the returned Web page of results is built dynamically so that each potential modification of the application ontology will be taken into account without affecting the internal structure of the information retrieval system.","Assali, Amjad Abou, Lenne, Dominique, Debray, Bruno",,,KoMIS: An Ontology-Based Knowledge Management System for Industrial Safety,,,10.1109/DEXA.2007.34 , ,,"This paper presents an ontology-based knowledge management system for indexing and retrieving information about a domain-specific corpus of resources in an industrial enterprise. From our ongoing project KoMIS (knowledge management for industrial safety), we introduce in this paper our approach to index the internal resources of an enterprise using two ontologies; a domain ontology that describes the terms of the studied domain (the industrial safety domain), and an application ontology that describes the various types of indexed resources. In our indexing approach, the resulting index is an RDF file that can be interrogated using one of the RDF query languages. An ontology-based information retrieval system is built as a Web application to help and guide users in their research for resources. Thanks to our indexing and retrieval model, the returned Web page of results is built dynamically so that each potential modification of the application ontology will be taken into account without affecting the internal structure of the information retrieval system.",,,,, ,  18th International Workshop on Database and Expert Systems Applications (DEXA 2007),Ontologies;Knowledge management;Safety;Indexing;Information retrieval;Content management;Environmental management;Resource management;Resource description framework;Web pages,out_of_scope,
3282,"**Title**SMAH: a new software package for evaluating major accident hazard

**Abstract**The mathematical models are very useful tools to predict the impacts of chemical process accidents. However, application of the models requires people competent in mathematic and computer programming. This paper presents a developed tool called 'Simulation of Major Accident Hazards' (SMAH). It is a software package which would be more users friendly and effective for evaluating the consequences of major accidents. It was developed using visual basic language (VB) whose its state of art consists of a graphic user interface (GUI) as front end and mathematical models as a back end (source code). Furthermore, results of calculations using the codes can be presented in tabulated and graphical forms, can be saved and transferred (exported) to the GIS software for risk presentation. This paper aims to present the framework of the simulator.","Mustapha, S., El-Harbawi, M.",,,SMAH: a new software package for evaluating major accident hazard,,,10.1109/ICSMC.2005.1571485 , ,,"The mathematical models are very useful tools to predict the impacts of chemical process accidents. However, application of the models requires people competent in mathematic and computer programming. This paper presents a developed tool called 'Simulation of Major Accident Hazards' (SMAH). It is a software package which would be more users friendly and effective for evaluating the consequences of major accidents. It was developed using visual basic language (VB) whose its state of art consists of a graphic user interface (GUI) as front end and mathematical models as a back end (source code). Furthermore, results of calculations using the codes can be presented in tabulated and graphical forms, can be saved and transferred (exported) to the GIS software for risk presentation. This paper aims to present the framework of the simulator.",,,,, ,"  2005 IEEE International Conference on Systems, Man and Cybernetics",Software packages;Accidents;Hazards;Mathematical model;Chemical processes;Application software;Mathematics;Programming;Computational modeling;Visual BASIC;major accident hazard;mathematical models;Visual Basic,out_of_scope,
3283,"**Title**Analysis of Different Adversarial Attacks on Various NLP SoTA Models

**Abstract**The core technology driving several applications, including as question answering, machine translation, and text categorization, is known as “Deep Learning-based Text Understanding” (DLTU). Given an input x and any goal classification y, it is feasible to create a new input x’ that is identical to x but classed as y. However, neural networks are susceptible to adversarial instances. Given its growing use in security-sensitive applications like sentiment analysis and toxic content monitoring, it is quite troubling that the security flaws of DLTU remain widely hidden despite its enormous popularity. Here, we demonstrate how various SoTA NLP models are intrinsically susceptible to different types of adversarial text attacks, in which specially crafted texts are used to cause misbehavior in the target DLTU systems and services. By exposing the maliciously created adversarial cases, it is possible to assess or possibly enhance the robustness of these models. Here the various NLP SoTA models are TextAttack, a Python-based framework is used for analyzing different adversarial attacks on various NLP So-TA models.","Maheshwari, Varsha, Dutta, Kamlesh, Kushwaha, Aanchal",,,Analysis of Different Adversarial Attacks on Various NLP SoTA Models,,,10.1109/CIISCA59740.2023.00049 , ,,"The core technology driving several applications, including as question answering, machine translation, and text categorization, is known as “Deep Learning-based Text Understanding” (DLTU). Given an input x and any goal classification y, it is feasible to create a new input x’ that is identical to x but classed as y. However, neural networks are susceptible to adversarial instances. Given its growing use in security-sensitive applications like sentiment analysis and toxic content monitoring, it is quite troubling that the security flaws of DLTU remain widely hidden despite its enormous popularity. Here, we demonstrate how various SoTA NLP models are intrinsically susceptible to different types of adversarial text attacks, in which specially crafted texts are used to cause misbehavior in the target DLTU systems and services. By exposing the maliciously created adversarial cases, it is possible to assess or possibly enhance the robustness of these models. Here the various NLP SoTA models are TextAttack, a Python-based framework is used for analyzing different adversarial attacks on various NLP So-TA models.",,,,, ,"  2023 International Conference on Computational Intelligence for Information, Security and Communication Applications (CIISCA)",Analytical models;Sentiment analysis;Computational modeling;Perturbation methods;Text categorization;Robustness;Question answering (information retrieval);BERT Model;Adversarial Attacks;RoBERTa Model;ALBERT Model;XLNet Model;DistilBERT Model,detection,
3284,"**Title**An integrated architecture, methods and some tools for creating more sustainable and greener enterprises

**Abstract**Sustainable green engineering design and manufacturing are changing every aspect of our life. This is because the climate is changing and customers are demanding sustainable green products and processes. Since many methods, designs and systems have to be changed, this is a complex field of integrated science and engineering, and we are only at the beginning. Sustainable green engineering has already attracted a wide area of research topics, including all aspects of energy management in every process step throughout the system's lifecycle, renewable energy creation and storage, all sorts of waste reduction methods, new approaches to risk analysis and customer requirements analysis, new biodegradable materials, sustainable non-toxic manufacturing processes and machinery, new levels of optimization in control systems, advanced digital design/manufacturing system simulation methods, sustainability statistics, human and machine error prevention, reuse, recycling, and others. In this paper we offer an overview, as well as some methodology and concrete results.","Ranky, Paul G.",,,"An integrated architecture, methods and some tools for creating more sustainable and greener enterprises",,,10.1109/ISSST.2010.5507696 , ,,"Sustainable green engineering design and manufacturing are changing every aspect of our life. This is because the climate is changing and customers are demanding sustainable green products and processes. Since many methods, designs and systems have to be changed, this is a complex field of integrated science and engineering, and we are only at the beginning. Sustainable green engineering has already attracted a wide area of research topics, including all aspects of energy management in every process step throughout the system's lifecycle, renewable energy creation and storage, all sorts of waste reduction methods, new approaches to risk analysis and customer requirements analysis, new biodegradable materials, sustainable non-toxic manufacturing processes and machinery, new levels of optimization in control systems, advanced digital design/manufacturing system simulation methods, sustainability statistics, human and machine error prevention, reuse, recycling, and others. In this paper we offer an overview, as well as some methodology and concrete results.",,,,, ,  Proceedings of the 2010 IEEE International Symposium on Sustainable Systems and Technology,Design engineering;Power engineering and energy;Material storage;Risk analysis;Manufacturing;Green products;Design methodology;Energy management;Renewable energy resources;Energy storage;A1 is the loss of defective under (y0−Δ1);A2 is the loss of defective upper (y0+Δ2);σ22 is the average square deviation from y0 of values under y0;σ22 is the average square deviation from y0 of values upper y0;Loss function: L(y) =kσ2;intelligent Sustainable Enterprise Engineering (iSEE:Green),out_of_scope,
3285,"**Title**GitRev: An LLM-Based Gamification Framework for Modern Code Review Activities

**Abstract**Modern code review (MCR) is recognized as an effective software quality assurance practice that is broadly adopted by open-source and commercial software projects. MCR is most effective when developers follow best practices, as it improves code quality, enhances knowledge transfer, increases team awareness and shares code ownership. However, prior work highlights that poor code review practices are common and often manifest in the form of low review participation and engagement, shallow review, and toxic communications. To address these issues, we introduce GitRev, a novel approach that applies gamification mechanisms to boost developer motivation and engagement. GitRev is built on top of a Large Language Model (LLM), used as a points-based reward system that leverages the code change context, and code review activities. We implement GitRev as a GitHub app with a web browser extension that consists of a client-side web browser extension that gamifies the GitHub user interface, and a server-side composed of a Node.js server for authentication and data management. To evaluate GitRev, we conduct a controlled experiment with 86 graduate and undergraduate students. Results indicate the promising potential of our approach for improving the code review process and developers' engagement. GitRev is publicly available at https://anonymous.40pen.science/r/GitRev-OB74","Khelifi, Jasem, Chouchen, Moataz, Ouni, Ali, Wang, Dong, Kula, Raula Gaikovina, Hamza, Salma, Mkaouer, Mohamed Wiem",,,GitRev: An LLM-Based Gamification Framework for Modern Code Review Activities,,,10.1109/SCAM63643.2024.00031 , ,,"Modern code review (MCR) is recognized as an effective software quality assurance practice that is broadly adopted by open-source and commercial software projects. MCR is most effective when developers follow best practices, as it improves code quality, enhances knowledge transfer, increases team awareness and shares code ownership. However, prior work highlights that poor code review practices are common and often manifest in the form of low review participation and engagement, shallow review, and toxic communications. To address these issues, we introduce GitRev, a novel approach that applies gamification mechanisms to boost developer motivation and engagement. GitRev is built on top of a Large Language Model (LLM), used as a points-based reward system that leverages the code change context, and code review activities. We implement GitRev as a GitHub app with a web browser extension that consists of a client-side web browser extension that gamifies the GitHub user interface, and a server-side composed of a Node.js server for authentication and data management. To evaluate GitRev, we conduct a controlled experiment with 86 graduate and undergraduate students. Results indicate the promising potential of our approach for improving the code review process and developers' engagement. GitRev is publicly available at https://anonymous.40pen.science/r/GitRev-OB74",,,,, ,  2024 IEEE International Conference on Source Code Analysis and Manipulation (SCAM),Codes;Reviews;Source coding;Large language models;Software quality;User interfaces;Browsers;Servers;Knowledge transfer;Software development management;Modern Code Review;GitHub;Gamification,out_of_scope,
3286,"**Title**On the Adversarial Robustness of Multi-Modal Foundation Models

**Abstract**Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images $\left({{\varepsilon _\infty } = 1/255}\right)$ in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model. Note: This paper contains fake information to illustrate the outcome of our attacks. It does not reflect the opinion of the authors.","Schlarmann, Christian, Hein, Matthias",,,On the Adversarial Robustness of Multi-Modal Foundation Models,,,10.1109/ICCVW60793.2023.00395 , ,,"Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images $\left({{\varepsilon _\infty } = 1/255}\right)$ in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model. Note: This paper contains fake information to illustrate the outcome of our attacks. It does not reflect the opinion of the authors.",,,,, ,  2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW),Visualization;Computer vision;Perturbation methods;Computational modeling;Conferences;Robustness;Behavioral sciences;adversarial robustness;multi modal models;security;foundation models,out_of_scope,
3287,"**Title**An Extensive Examination of Toxicity, Polarisation, and Biasing in Political Conversations on Social Media

**Abstract**Recent developments in social media uses and its availability on ubiquitous devices makes it a perfect platform to express our views. However, many groups, organizations and people try to influence the users by posting biased contents. Some of them try to polarize the opinion of users. Many of them use toxic language to target some users. The activities such as biasing, polarization and use of toxic language make the users feel uncomfortable in using social media. Our research paper highlights key characteristics, uncovers patterns, and offers solutions to lessen the detrimental impacts of polarization, bias, and toxicity.","Garg, Navin, Singh, Ashwini Kumar, Manchanda, Mahesh",,,"An Extensive Examination of Toxicity, Polarisation, and Biasing in Political Conversations on Social Media",,,10.1109/IC2PCT60090.2024.10486236 , ,,"Recent developments in social media uses and its availability on ubiquitous devices makes it a perfect platform to express our views. However, many groups, organizations and people try to influence the users by posting biased contents. Some of them try to polarize the opinion of users. Many of them use toxic language to target some users. The activities such as biasing, polarization and use of toxic language make the users feel uncomfortable in using social media. Our research paper highlights key characteristics, uncovers patterns, and offers solutions to lessen the detrimental impacts of polarization, bias, and toxicity.",,,,, ,"  2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT)",Toxicology;Social networking (online);Reviews;Organizations;Oral communication;Minimization;Communications technology;Toxicity;Biasing;Polarization;Echo Chambers;Social fragmentation;Narrative manipulation,detection,
3288,"**Title**Research on intelligent control technology of chicken house environment in large-scale chicken farms

**Abstract**In order to solve the problem of the influence of dust particles and toxic gases on the growth of chickens in chicken houses faced by large-scale chicken farms, this study aims to develop an intelligent control system for chicken house environment in chicken farms, and to explore the solution of intelligent control of chicken house environment by utilizing the Internet, the Internet of Things (IoT), and high-voltage electrostatic and plasma technologies.This study uses a function-driven development approach, using basic hardware such as sensor fusion hardware, communication equipment, high-voltage electrostatic precipitator, and plasma discharge device, and completes the system function development using the ROS (Robot Operating System) embedded development platform and the Java language to determine the usability and reliability of the system by running tests in chicken farms.The core functions of the system include environmental de-dusting and purification by adjusting the strong discharge field, and deodorization and disinfection purification by the plasma reactor. The high-voltage electrostatic discharge technology designed in this study can realize the automatic adjustment function, and the discharge docking area and discharge gap can be changed by rotating the button, so as to change the discharge field strength and achieve different purification design requirements. The plasma reactor adopts a honeycomb structure, the blocking medium is enameled, in order to ensure uniform discharge, the conductive layer is plated onto the enamel plate, the other side of the electrode is made of planed 316 stainless steel plate, the high-speed phase-locked loop MM74HC4046 is used to lock the operating frequency, and the power is automatically adjusted using the PFM method, and the resonant capacitor adopts the new type of capacitor that has a large capacity and a small ESR of the equivalent series resistance. Through the actual operation test in the chicken farm, users are satisfied with the usability, ease of use and reliability of the system and equipment.In this study, an intelligent control system for chicken house environment was designed to create a comfortable and good developmental environment for chickens, to effectively improve the level of intelligent farming, and to provide sufficient experimental basis and theoretical support for the environmental management and optimization of chicken houses.","Quan, Qingle, Palaoag, Thelma D., Sun, Hanqing",,,Research on intelligent control technology of chicken house environment in large-scale chicken farms,,,10.1109/ICCET62255.2024.00007 , ,,"In order to solve the problem of the influence of dust particles and toxic gases on the growth of chickens in chicken houses faced by large-scale chicken farms, this study aims to develop an intelligent control system for chicken house environment in chicken farms, and to explore the solution of intelligent control of chicken house environment by utilizing the Internet, the Internet of Things (IoT), and high-voltage electrostatic and plasma technologies.This study uses a function-driven development approach, using basic hardware such as sensor fusion hardware, communication equipment, high-voltage electrostatic precipitator, and plasma discharge device, and completes the system function development using the ROS (Robot Operating System) embedded development platform and the Java language to determine the usability and reliability of the system by running tests in chicken farms.The core functions of the system include environmental de-dusting and purification by adjusting the strong discharge field, and deodorization and disinfection purification by the plasma reactor. The high-voltage electrostatic discharge technology designed in this study can realize the automatic adjustment function, and the discharge docking area and discharge gap can be changed by rotating the button, so as to change the discharge field strength and achieve different purification design requirements. The plasma reactor adopts a honeycomb structure, the blocking medium is enameled, in order to ensure uniform discharge, the conductive layer is plated onto the enamel plate, the other side of the electrode is made of planed 316 stainless steel plate, the high-speed phase-locked loop MM74HC4046 is used to lock the operating frequency, and the power is automatically adjusted using the PFM method, and the resonant capacitor adopts the new type of capacitor that has a large capacity and a small ESR of the equivalent series resistance. Through the actual operation test in the chicken farm, users are satisfied with the usability, ease of use and reliability of the system and equipment.In this study, an intelligent control system for chicken house environment was designed to create a comfortable and good developmental environment for chickens, to effectively improve the level of intelligent farming, and to provide sufficient experimental basis and theoretical support for the environmental management and optimization of chicken houses.",,,,, ,  2024 7th International Conference on Communication Engineering and Technology (ICCET),Purification;High-voltage techniques;Discharges (electric);Hardware;Plasmas;Internet of Things;Usability;chicken coop environment;intelligent control;high voltage electrostatic;plasma,out_of_scope,
3289,"**Title**Controllable Text Generation Based on Enhanced Non-Residual Attention

**Abstract**The typical construction method of prompts in CLM results in the combination of prompt text information and input text information being too long, and designing a prompt is challenging. Fixed template combinations can impact the grammatical structure, complicate the understanding of the prompt model, and influence the control effect of the generative model. By enhancing Non-Residual Attention, the prompt model processes prompt information to generate improved prompts. This enables the generative model to access comprehensive enhanced prompt information and input text information at any time step. At the same time, a copying mechanism is incorporated into the generative model to tackle the consistency issue of contextual text and enhance the controllability of the generative model. This enables the model output to encompass input text information or prompt text information, thereby reflecting contextual consistency and improving output control. Based on the ROCStory dataset with labeled characters, emotions, and actions, the results indicate that the enhanced Non-Residual Attention model has better control and generation effects compared to the original method.","Hu, Huiting, Wang, Xing, Zhu, Guohua",,,Controllable Text Generation Based on Enhanced Non-Residual Attention,,,10.1109/ICETCI61221.2024.10594398 , ,,"The typical construction method of prompts in CLM results in the combination of prompt text information and input text information being too long, and designing a prompt is challenging. Fixed template combinations can impact the grammatical structure, complicate the understanding of the prompt model, and influence the control effect of the generative model. By enhancing Non-Residual Attention, the prompt model processes prompt information to generate improved prompts. This enables the generative model to access comprehensive enhanced prompt information and input text information at any time step. At the same time, a copying mechanism is incorporated into the generative model to tackle the consistency issue of contextual text and enhance the controllability of the generative model. This enables the model output to encompass input text information or prompt text information, thereby reflecting contextual consistency and improving output control. Based on the ROCStory dataset with labeled characters, emotions, and actions, the results indicate that the enhanced Non-Residual Attention model has better control and generation effects compared to the original method.",,,,, ,"  2024 IEEE 4th International Conference on Electronic Technology, Communication and Information (ICETCI)",Coherence;Syntactics;Controllability;Logic;Context modeling;CLM;the Non-Residual Attention;copying mechanism,out_of_scope,
3290,"**Title**Maths: Multimodal Transformer-Based Human-Readable Solver

**Abstract**Multimodal mathematical reasoning has gained increasing attention in recent times. However, previous effective methods have not tried to reason in the form of natural language. In this paper, we introduce a model named MATHS (MultimodAl Transformer-based Human-readable Solver) for visual arithmetic and geometry problems in multimodal mathematical reasoning tasks. Drawing inspiration from Multimodal Large Language Models (MLLMs), our approach involves generating problem-solving processes expressed in natural language, in order to leverage the inherent reasoning capabilities embedded within language models. To address the challenge of precise calculations for language models, our work proposes a Math-Constrained Generation (MCG) method to impose hard constraints on generated outputs. Extensive experiments demonstrate our model excels in visual arithmetic task, and achieves results that are either better or comparable to existing methods in geometry problems. Code is available at https://github.com/ycpNotFound/MATHS.","Pan, Yicheng, Zhang, Zhenrong, Ma, Jiefeng, Hu, Pengfei, Du, Jun, Wang, Qing, Zhang, Jianshu, Liu, Dan, Wei, Si",,,Maths: Multimodal Transformer-Based Human-Readable Solver,,,10.1109/ICME57554.2024.10687434 , ,,"Multimodal mathematical reasoning has gained increasing attention in recent times. However, previous effective methods have not tried to reason in the form of natural language. In this paper, we introduce a model named MATHS (MultimodAl Transformer-based Human-readable Solver) for visual arithmetic and geometry problems in multimodal mathematical reasoning tasks. Drawing inspiration from Multimodal Large Language Models (MLLMs), our approach involves generating problem-solving processes expressed in natural language, in order to leverage the inherent reasoning capabilities embedded within language models. To address the challenge of precise calculations for language models, our work proposes a Math-Constrained Generation (MCG) method to impose hard constraints on generated outputs. Extensive experiments demonstrate our model excels in visual arithmetic task, and achieves results that are either better or comparable to existing methods in geometry problems. Code is available at https://github.com/ycpNotFound/MATHS.",,,,, ,  2024 IEEE International Conference on Multimedia and Expo (ICME),Geometry;Visualization;Large language models;Natural languages;Production;Transformers;Cognition;Mathematical models;Problem-solving;Arithmetic;Multimodal;Mathematics Reasoning;Controllable Text Generation,out_of_scope,
3291,"**Title**Tailored Definitions With Easy Reach: Complexity-Controllable Definition Generation

**Abstract**The task of complexity-controllable definition generation refers to providing definitions with different readability for words in specific contexts. This task can be utilized to help language learners eliminate reading barriers and facilitate language acquisition. However, the available training data for this task remains scarce due to the difficulty of obtaining reliable definition data and the high cost of data standardization. To tackle those challenges, we introduce a general solution from both the data-driven and method-driven perspectives. We construct a large-scale standard Chinese dataset, COMPILING, which contains both difficult and simple definitions and can serve as a benchmark for future research. Besides, we propose a multitasking framework SimpDefiner for unsupervised controllable definition generation. By designing a parameter-sharing scheme between two decoders, the framework can extract the complexity information from the non-parallel corpus. Moreover, we propose the SimpDefiner guided prompting (SGP) method, where simple definitions generated by SimpDefiner are utilized to construct prompts for GPT-4, hence obtaining more realistic and contextually appropriate definitions. The results demonstrate SimpDefiner's outstanding ability to achieve controllable generation and better results could be achieved when GPT-4 is incorporated.","Yang, Liner, Yuan, Jiaxin, Kong, Cunliang, Yu, Jingsi, Chong, Ruining, Liu, Zhenghao, Yang, Erhong",,,Tailored Definitions With Easy Reach: Complexity-Controllable Definition Generation,,,10.1109/TBDATA.2024.3522805 , ,,"The task of complexity-controllable definition generation refers to providing definitions with different readability for words in specific contexts. This task can be utilized to help language learners eliminate reading barriers and facilitate language acquisition. However, the available training data for this task remains scarce due to the difficulty of obtaining reliable definition data and the high cost of data standardization. To tackle those challenges, we introduce a general solution from both the data-driven and method-driven perspectives. We construct a large-scale standard Chinese dataset, COMPILING, which contains both difficult and simple definitions and can serve as a benchmark for future research. Besides, we propose a multitasking framework SimpDefiner for unsupervised controllable definition generation. By designing a parameter-sharing scheme between two decoders, the framework can extract the complexity information from the non-parallel corpus. Moreover, we propose the SimpDefiner guided prompting (SGP) method, where simple definitions generated by SimpDefiner are utilized to construct prompts for GPT-4, hence obtaining more realistic and contextually appropriate definitions. The results demonstrate SimpDefiner's outstanding ability to achieve controllable generation and better results could be achieved when GPT-4 is incorporated.",,,,, ,  ,Dictionaries;Complexity theory;Annotations;Chatbots;Big Data;Training data;Decoding;Costs;Standards;Semantics;Controllable text generation;definition generation;unsupervised style transfer,out_of_scope,
3292,"**Title**AI - Assisted Text Composition for Automated Content Authoring Using Transformer-Based Language Models

**Abstract**In this paper, we introduce a hybrid method that combines the use of Controllable Text Generation (CTG) approach via Large Language Models (LLMs), fine-tuned language models and sentence transformers in a single framework to generate real-author styled articles in Turkish language. As such, we seek to exemplify hybrid solutions that produce real-human styled high-quality contents, given limited resources and relatively short text prompts as inputs. To achieve this, we introduce a novel method to assemble an author-specific article in different coherence and fluency levels, based on phrasal control of the CTG process. Control phrases are automatically assembled based on a semantic correlation measure calculated using sentence embed dings corresponding to author articles, that are obtained from pre-trained sentence transformers.","Alpdemir, Yusuf, Alpdemir, Mahmut Nedim",,,AI - Assisted Text Composition for Automated Content Authoring Using Transformer-Based Language Models,,,10.1109/IC_ASET61847.2024.10596255 , ,,"In this paper, we introduce a hybrid method that combines the use of Controllable Text Generation (CTG) approach via Large Language Models (LLMs), fine-tuned language models and sentence transformers in a single framework to generate real-author styled articles in Turkish language. As such, we seek to exemplify hybrid solutions that produce real-human styled high-quality contents, given limited resources and relatively short text prompts as inputs. To achieve this, we introduce a novel method to assemble an author-specific article in different coherence and fluency levels, based on phrasal control of the CTG process. Control phrases are automatically assembled based on a semantic correlation measure calculated using sentence embed dings corresponding to author articles, that are obtained from pre-trained sentence transformers.",,,,, ,  2024 IEEE International Conference on Advanced Systems and Emergent Technologies (IC_ASET),Training;Large language models;Semantics;Process control;Transformers;Robustness;Hybrid power systems;Machine Learning;Language Models;Text Generation;Text Classification;Customized Content Generation;Transformer Architectures,out_of_scope,
3293,"**Title**A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models

**Abstract**Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they rely on superficial reference comparisons instead of incorporating key aspects of counter narrative quality as evaluation criteria. To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs. We found that LLM evaluators achieve strong alignment to human-annotated scores and feedback and outperform alternative metrics, indicating their potential as multi-aspect, reference-free and interpretable evaluators for counter narrative evaluation.","Jones, Jaylen, Mo, Lingbo, Fosler-Lussier, Eric, Sun, Huan",,,A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models,,,10.18653/v1/2024.naacl-short.14 , ,,"Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they rely on superficial reference comparisons instead of incorporating key aspects of counter narrative quality as evaluation criteria. To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs. We found that LLM evaluators achieve strong alignment to human-annotated scores and feedback and outperform alternative metrics, indicating their potential as multi-aspect, reference-free and interpretable evaluators for counter narrative evaluation.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers),,detox,
3294,"**Title**{B}asque and {S}panish Counter Narrative Generation: Data Creation and Evaluation

**Abstract**Counter Narratives (CNs) are non-negative textual responses to Hate Speech (HS) aiming at defusing online hatred and mitigating its spreading across media. Despite the recent increase in HS content posted online, research on automatic CN generation has been relatively scarce and predominantly focused on English. In this paper, we present CONAN-EUS, a new Basque and Spanish dataset for CN generation developed by means of Machine Translation (MT) and professional post-edition. Being a parallel corpus, also with respect to the original English CONAN, it allows to perform novel research on multilingual and crosslingual automatic generation of CNs. Our experiments on CN generation with mT5, a multilingual encoder-decoder model, shows that generation greatly benefits from training on post-edited data, as opposed to relying on silver MT data only. These results are confirmed by their correlation with a qualitative manual evaluation, demonstrating that manually revised training data remains crucial for the quality of the generated CNs. Furthermore, multilingual data augmentation improves results over monolingual settings for structurally similar languages such as English and Spanish, while being detrimental for Basque, a language isolate. Similar findings occur in zero-shot crosslingual evaluations, where model transfer (fine-tuning in English and generating in a different target language) outperforms fine-tuning mT5 on machine translated data for Spanish but not for Basque. This provides an interesting insight into the asymmetry in the multilinguality of generative models, a challenging topic which is still open to research. Data and code will be made publicly available upon publication.","Bengoetxea, Jaione, Chung, Yi-Ling, Guerini, Marco, Agerri, Rodrigo",,,{B}asque and {S}panish Counter Narrative Generation: Data Creation and Evaluation,,, , ,,"Counter Narratives (CNs) are non-negative textual responses to Hate Speech (HS) aiming at defusing online hatred and mitigating its spreading across media. Despite the recent increase in HS content posted online, research on automatic CN generation has been relatively scarce and predominantly focused on English. In this paper, we present CONAN-EUS, a new Basque and Spanish dataset for CN generation developed by means of Machine Translation (MT) and professional post-edition. Being a parallel corpus, also with respect to the original English CONAN, it allows to perform novel research on multilingual and crosslingual automatic generation of CNs. Our experiments on CN generation with mT5, a multilingual encoder-decoder model, shows that generation greatly benefits from training on post-edited data, as opposed to relying on silver MT data only. These results are confirmed by their correlation with a qualitative manual evaluation, demonstrating that manually revised training data remains crucial for the quality of the generated CNs. Furthermore, multilingual data augmentation improves results over monolingual settings for structurally similar languages such as English and Spanish, while being detrimental for Basque, a language isolate. Similar findings occur in zero-shot crosslingual evaluations, where model transfer (fine-tuning in English and generating in a different target language) outperforms fine-tuning mT5 on machine translated data for Spanish but not for Basque. This provides an interesting insight into the asymmetry in the multilinguality of generative models, a challenging topic which is still open to research. Data and code will be made publicly available upon publication.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,out_but_toxicity,
3295,"**Title**A Semi-Supervised Approach to Detect Toxic Comments

**Abstract**Toxic comments contain forms of non-acceptable language targeted towards groups or individuals. These types of comments become a serious concern for government organizations, online communities, and social media platforms. Although there are some approaches to handle non-acceptable language, most of them focus on supervised learning and the English language. In this paper, we deal with toxic comment detection as a semi-supervised strategy over a heterogeneous graph. We evaluate the approach on a toxic dataset of the Portuguese language, outperforming several graph-based methods and achieving competitive results compared to transformer architectures.","Saraiva, Ghivvago Damas, Anchi{\^e}ta, Rafael, Neto, Francisco Assis Ricarte, Moura, Raimundo",,,A Semi-Supervised Approach to Detect Toxic Comments,,, , ,,"Toxic comments contain forms of non-acceptable language targeted towards groups or individuals. These types of comments become a serious concern for government organizations, online communities, and social media platforms. Although there are some approaches to handle non-acceptable language, most of them focus on supervised learning and the English language. In this paper, we deal with toxic comment detection as a semi-supervised strategy over a heterogeneous graph. We evaluate the approach on a toxic dataset of the Portuguese language, outperforming several graph-based methods and achieving competitive results compared to transformer architectures.",,,,, ,  Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021),,detection,
3296,"**Title**Unlearning Bias in Language Models by Partitioning Gradients

**Abstract**Recent research has shown that large-scale pretrained language models, specifically transformers, tend to exhibit issues relating to racism, sexism, religion bias, and toxicity in general. Unfortunately, these pretrained language models are used almost universally in downstream tasks, and natural language processing is often applied to make real-world predictions. Thus, debiasing these language models as early in development as possible is increasingly crucial for preventing unintentional harms caused by natural language systems. To this end, we propose a new technique called partitioned contrastive gradient unlearning (PCGU), a gray-box method for debiasing pretrained masked language models. PCGU aims to optimize only the weights that contribute most to a specific domain of bias, doing so by computing a first-order approximation based on the gradients of contrastive sentence pairs. Our experiments show that PCGU is both low-cost and seems particularly effective at pinpointing the sources of implicit social bias in large pretrained transformers. Although we train using PCGU in the gender-profession domain only, we find that doing so can also partially mitigate bias across other domains. All code for our implementation and experiments can be found at \url{https://github.com/CharlesYu2000/PCGU-UnlearningBias}.","Yu, Charles, Jeoung, Sullam, Kasi, Anish, Yu, Pengfei, Ji, Heng",,,Unlearning Bias in Language Models by Partitioning Gradients,,,10.18653/v1/2023.findings-acl.375 , ,,"Recent research has shown that large-scale pretrained language models, specifically transformers, tend to exhibit issues relating to racism, sexism, religion bias, and toxicity in general. Unfortunately, these pretrained language models are used almost universally in downstream tasks, and natural language processing is often applied to make real-world predictions. Thus, debiasing these language models as early in development as possible is increasingly crucial for preventing unintentional harms caused by natural language systems. To this end, we propose a new technique called partitioned contrastive gradient unlearning (PCGU), a gray-box method for debiasing pretrained masked language models. PCGU aims to optimize only the weights that contribute most to a specific domain of bias, doing so by computing a first-order approximation based on the gradients of contrastive sentence pairs. Our experiments show that PCGU is both low-cost and seems particularly effective at pinpointing the sources of implicit social bias in large pretrained transformers. Although we train using PCGU in the gender-profession domain only, we find that doing so can also partially mitigate bias across other domains. All code for our implementation and experiments can be found at \url{https://github.com/CharlesYu2000/PCGU-UnlearningBias}.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3297,"**Title**Which One Is More Toxic? Findings from Jigsaw Rate Severity of Toxic Comments

**Abstract**The proliferation of online hate speech has necessitated the creation of algorithms which can detect toxicity. Most of the past research focuses on this detection as a classification task, but assigning an absolute toxicity label is often tricky. Hence, few of the past works transform the same task into a regression. This paper shows the comparative evaluation of different transformers and traditional machine learning models on a recently released toxicity severity measurement dataset by Jigsaw. We further demonstrate the issues with the model predictions using explainability analysis.","Das, Millon, Saha, Punyajoy, Das, Mithun",,,Which One Is More Toxic? Findings from Jigsaw Rate Severity of Toxic Comments,,, , ,,"The proliferation of online hate speech has necessitated the creation of algorithms which can detect toxicity. Most of the past research focuses on this detection as a classification task, but assigning an absolute toxicity label is often tricky. Hence, few of the past works transform the same task into a regression. This paper shows the comparative evaluation of different transformers and traditional machine learning models on a recently released toxicity severity measurement dataset by Jigsaw. We further demonstrate the issues with the model predictions using explainability analysis.",,,,, ,"  Proceedings of the Third Workshop on Threat, Aggression and Cyberbullying (TRAC 2022)",,detection,
3298,"**Title**{PPL-MCTS}: {C}onstrained Textual Generation Through Discriminator-Guided {MCTS} Decoding

**Abstract**Large language models (LM) based on Transformers allow to generate plausible long texts. In this paper, we explore how this generation can be further controlled at decoding time to satisfy certain constraints (e.g. being non-toxic, conveying certain emotions, using a specific writing style, etc.) without fine-tuning the LM.Precisely, we formalize constrained generation as a tree exploration process guided by a discriminator that indicates how well the associated sequence respects the constraint. This approach, in addition to being easier and cheaper to train than fine-tuning the LM, allows to apply the constraint more finely and dynamically. We propose several original methods to search this generation tree, notably the Monte Carlo Tree Search (MCTS) which provides theoretical guarantees on the search efficiency, but also simpler methods based on re-ranking a pool of diverse sequences using the discriminator scores. These methods are evaluated, with automatic and human-based metrics, on two types of constraints and languages: review polarity and emotion control in French and English. We show that discriminator-guided MCTS decoding achieves state-of-the-art results without having to tune the language model, in both tasks and languages. We also demonstrate that other proposed decoding methods based on re-ranking can be really effective when diversity among the generated propositions is encouraged.","Chaffin, Antoine, Claveau, Vincent, Kijak, Ewa",,,{PPL-MCTS}: {C}onstrained Textual Generation Through Discriminator-Guided {MCTS} Decoding,,,10.18653/v1/2022.naacl-main.215 , ,,"Large language models (LM) based on Transformers allow to generate plausible long texts. In this paper, we explore how this generation can be further controlled at decoding time to satisfy certain constraints (e.g. being non-toxic, conveying certain emotions, using a specific writing style, etc.) without fine-tuning the LM.Precisely, we formalize constrained generation as a tree exploration process guided by a discriminator that indicates how well the associated sequence respects the constraint. This approach, in addition to being easier and cheaper to train than fine-tuning the LM, allows to apply the constraint more finely and dynamically. We propose several original methods to search this generation tree, notably the Monte Carlo Tree Search (MCTS) which provides theoretical guarantees on the search efficiency, but also simpler methods based on re-ranking a pool of diverse sequences using the discriminator scores. These methods are evaluated, with automatic and human-based metrics, on two types of constraints and languages: review polarity and emotion control in French and English. We show that discriminator-guided MCTS decoding achieves state-of-the-art results without having to tune the language model, in both tasks and languages. We also demonstrate that other proposed decoding methods based on re-ranking can be really effective when diversity among the generated propositions is encouraged.",,,,, ,  Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,detox,
3299,"**Title**{SSNCSE}{\_}{NLP}@{LT}-{EDI}-{ACL}2022: Homophobia/Transphobia Detection in Multiple Languages using {SVM} Classifiers and {BERT}-based Transformers

**Abstract**Over the years, there has been a slow but steady change in the attitude of society towards different kinds of sexuality. However, on social media platforms, where people have the license to be anonymous, toxic comments targeted at homosexuals, transgenders and the LGBTQ+ community are not uncommon. Detection of homophobic comments on social media can be useful in making the internet a safer place for everyone. For this task, we used a combination of word embeddings and SVM Classifiers as well as some BERT-based transformers. We achieved a weighted F1-score of 0.93 on the English dataset, 0.75 on the Tamil dataset and 0.87 on the Tamil-English Code-Mixed dataset.","Swaminathan, Krithika, B, Bharathi, G L, Gayathri, Sampath, Hrishik",,,{SSNCSE}{\_}{NLP}@{LT}-{EDI}-{ACL}2022: Homophobia/Transphobia Detection in Multiple Languages using {SVM} Classifiers and {BERT}-based Transformers,,,10.18653/v1/2022.ltedi-1.34 , ,,"Over the years, there has been a slow but steady change in the attitude of society towards different kinds of sexuality. However, on social media platforms, where people have the license to be anonymous, toxic comments targeted at homosexuals, transgenders and the LGBTQ+ community are not uncommon. Detection of homophobic comments on social media can be useful in making the internet a safer place for everyone. For this task, we used a combination of word embeddings and SVM Classifiers as well as some BERT-based transformers. We achieved a weighted F1-score of 0.93 on the English dataset, 0.75 on the Tamil dataset and 0.87 on the Tamil-English Code-Mixed dataset.",,,,, ,"  Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",,detection,
3300,"**Title**Cisco at {S}em{E}val-2021 Task 5: What`s Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments

**Abstract**Social network platforms are generally used to share positive, constructive, and insightful content. However, in recent times, people often get exposed to objectionable content like threat, identity attacks, hate speech, insults, obscene texts, offensive remarks or bullying. Existing work on toxic speech detection focuses on binary classification or on differentiating toxic speech among a small set of categories. This paper describes the system proposed by team Cisco for SemEval-2021 Task 5: Toxic Spans Detection, the first shared task focusing on detecting the spans in the text that attribute to its toxicity, in English language. We approach this problem primarily in two ways: a sequence tagging approach and a dependency parsing approach. In our sequence tagging approach we tag each token in a sentence under a particular tagging scheme. Our best performing architecture in this approach also proved to be our best performing architecture overall with an F1 score of 0.6922, thereby placing us 7th on the final evaluation phase leaderboard. We also explore a dependency parsing approach where we extract spans from the input sentence under the supervision of target span boundaries and rank our spans using a biaffine model. Finally, we also provide a detailed analysis of our results and model performance in our paper.","Ghosh, Sreyan, Kumar, Sonal",,,Cisco at {S}em{E}val-2021 Task 5: What`s Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments,,,10.18653/v1/2021.semeval-1.29 , ,,"Social network platforms are generally used to share positive, constructive, and insightful content. However, in recent times, people often get exposed to objectionable content like threat, identity attacks, hate speech, insults, obscene texts, offensive remarks or bullying. Existing work on toxic speech detection focuses on binary classification or on differentiating toxic speech among a small set of categories. This paper describes the system proposed by team Cisco for SemEval-2021 Task 5: Toxic Spans Detection, the first shared task focusing on detecting the spans in the text that attribute to its toxicity, in English language. We approach this problem primarily in two ways: a sequence tagging approach and a dependency parsing approach. In our sequence tagging approach we tag each token in a sentence under a particular tagging scheme. Our best performing architecture in this approach also proved to be our best performing architecture overall with an F1 score of 0.6922, thereby placing us 7th on the final evaluation phase leaderboard. We also explore a dependency parsing approach where we extract spans from the input sentence under the supervision of target span boundaries and rank our spans using a biaffine model. Finally, we also provide a detailed analysis of our results and model performance in our paper.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3301,"**Title**{WLV}-{RIT} at {S}em{E}val-2021 Task 5: A Neural Transformer Framework for Detecting Toxic Spans

**Abstract**In recent years, the widespread use of social media has led to an increase in the generation of toxic and offensive content on online platforms. In response, social media platforms have worked on developing automatic detection methods and employing human moderators to cope with this deluge of offensive content. While various state-of-the-art statistical models have been applied to detect toxic posts, there are only a few studies that focus on detecting the words or expressions that make a post offensive. This motivates the organization of the SemEval-2021 Task 5: Toxic Spans Detection competition, which has provided participants with a dataset containing toxic spans annotation in English posts. In this paper, we present the WLV-RIT entry for the SemEval-2021 Task 5. Our best performing neural transformer model achieves an 0.68 F1-Score. Furthermore, we develop an open-source framework for multilingual detection of offensive spans, i.e., MUDES, based on neural transformers that detect toxic spans in texts.","Ranasinghe, Tharindu, Sarkar, Diptanu, Zampieri, Marcos, Ororbia, Alexander",,,{WLV}-{RIT} at {S}em{E}val-2021 Task 5: A Neural Transformer Framework for Detecting Toxic Spans,,,10.18653/v1/2021.semeval-1.111 , ,,"In recent years, the widespread use of social media has led to an increase in the generation of toxic and offensive content on online platforms. In response, social media platforms have worked on developing automatic detection methods and employing human moderators to cope with this deluge of offensive content. While various state-of-the-art statistical models have been applied to detect toxic posts, there are only a few studies that focus on detecting the words or expressions that make a post offensive. This motivates the organization of the SemEval-2021 Task 5: Toxic Spans Detection competition, which has provided participants with a dataset containing toxic spans annotation in English posts. In this paper, we present the WLV-RIT entry for the SemEval-2021 Task 5. Our best performing neural transformer model achieves an 0.68 F1-Score. Furthermore, we develop an open-source framework for multilingual detection of offensive spans, i.e., MUDES, based on neural transformers that detect toxic spans in texts.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3302,"**Title**Sefamerve {ARGE} at {S}em{E}val-2021 Task 5: Toxic Spans Detection Using Segmentation Based 1-{D} Convolutional Neural Network Model

**Abstract**This paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our approach considers toxic spans detection as a segmentation problem. The system, Waw-unet, consists of a 1-D convolutional neural network adopted from U-Net architecture commonly applied for semantic segmentation. We customize existing architecture by adding a special network block considering for text segmentation, as an essential component of the model. We compared the model with two transformers-based systems RoBERTa and XLM-RoBERTa to see its performance against pre-trained language models. We obtained 0.6251 f1 score with Waw-unet while 0.6390 and 0.6601 with the compared models respectively.","Delil, Selman, Kuyumcu, Birol, Aksakall{\i}, C{\""u}neyt",,,Sefamerve {ARGE} at {S}em{E}val-2021 Task 5: Toxic Spans Detection Using Segmentation Based 1-{D} Convolutional Neural Network Model,,,10.18653/v1/2021.semeval-1.123 , ,,"This paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our approach considers toxic spans detection as a segmentation problem. The system, Waw-unet, consists of a 1-D convolutional neural network adopted from U-Net architecture commonly applied for semantic segmentation. We customize existing architecture by adding a special network block considering for text segmentation, as an essential component of the model. We compared the model with two transformers-based systems RoBERTa and XLM-RoBERTa to see its performance against pre-trained language models. We obtained 0.6251 f1 score with Waw-unet while 0.6390 and 0.6601 with the compared models respectively.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3303,"**Title**{UTNLP} at {S}em{E}val-2021 Task 5: A Comparative Analysis of Toxic Span Detection using Attention-based, Named Entity Recognition, and Ensemble Models

**Abstract**Detecting which parts of a sentence contribute to that sentence`s toxicity{---}rather than providing a sentence-level verdict of hatefulness{---} would increase the interpretability of models and allow human moderators to better understand the outputs of the system. This paper presents our team`s, UTNLP, methodology and results in the SemEval-2021 shared task 5 on toxic spans detection. We test multiple models and contextual embeddings and report the best setting out of all. The experiments start with keyword-based models and are followed by attention-based, named entity- based, transformers-based, and ensemble models. Our best approach, an ensemble model, achieves an F1 of 0.684 in the competition`s evaluation phase.","Salemi, Alireza, Sabri, Nazanin, Kebriaei, Emad, Bahrak, Behnam, Shakery, Azadeh",,,"{UTNLP} at {S}em{E}val-2021 Task 5: A Comparative Analysis of Toxic Span Detection using Attention-based, Named Entity Recognition, and Ensemble Models",,,10.18653/v1/2021.semeval-1.136 , ,,"Detecting which parts of a sentence contribute to that sentence`s toxicity{---}rather than providing a sentence-level verdict of hatefulness{---} would increase the interpretability of models and allow human moderators to better understand the outputs of the system. This paper presents our team`s, UTNLP, methodology and results in the SemEval-2021 shared task 5 on toxic spans detection. We test multiple models and contextual embeddings and report the best setting out of all. The experiments start with keyword-based models and are followed by attention-based, named entity- based, transformers-based, and ensemble models. Our best approach, an ensemble model, achieves an F1 of 0.684 in the competition`s evaluation phase.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3304,"**Title**{DFKI} {SLT} at {G}erm{E}val 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments

**Abstract**We present our submission to the first subtask of GermEval 2021 (classification of German Facebook comments as toxic or not). Binary sequence classification is a standard NLP task with known state-of-the-art methods. Therefore, we focus on data preparation by using two different techniques: task-specific pre-training and data augmentation. First, we pre-train multilingual transformers (XLM-RoBERTa and MT5) on 12 hatespeech detection datasets in nine different languages. In terms of F1, we notice an improvement of 10{\%} on average, using task-specific pre-training. Second, we perform data augmentation by labelling unlabelled comments, taken from Facebook, to increase the size of the training dataset by 79{\%}. Models trained on the augmented training dataset obtain on average +0.0282 (+5{\%}) F1 score compared to models trained on the original training dataset. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5. The code of the project is available at: \url{https://github.com/airKlizz/germeval2021toxic}.","Calizzano, Remi, Ostendorff, Malte, Rehm, Georg",,,{DFKI} {SLT} at {G}erm{E}val 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments,,, , ,,"We present our submission to the first subtask of GermEval 2021 (classification of German Facebook comments as toxic or not). Binary sequence classification is a standard NLP task with known state-of-the-art methods. Therefore, we focus on data preparation by using two different techniques: task-specific pre-training and data augmentation. First, we pre-train multilingual transformers (XLM-RoBERTa and MT5) on 12 hatespeech detection datasets in nine different languages. In terms of F1, we notice an improvement of 10{\%} on average, using task-specific pre-training. Second, we perform data augmentation by labelling unlabelled comments, taken from Facebook, to increase the size of the training dataset by 79{\%}. Models trained on the augmented training dataset obtain on average +0.0282 (+5{\%}) F1 score compared to models trained on the original training dataset. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5. The code of the project is available at: \url{https://github.com/airKlizz/germeval2021toxic}.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3305,"**Title**{WLV}-{RIT} at {G}erm{E}val 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments

**Abstract**This paper addresses the identification of toxic, engaging, and fact-claiming comments on social media. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in German. Considering the relatedness of the three tasks, we approached the problem using large pre-trained transformer models and multitask learning. Our results indicate that multitask learning achieves performance superior to the more common single task learning approach in all three tasks. We submit our best systems to GermEval-2021 under the team name WLV-RIT.","Morgan, Skye, Ranasinghe, Tharindu, Zampieri, Marcos",,,"{WLV}-{RIT} at {G}erm{E}val 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments",,, , ,,"This paper addresses the identification of toxic, engaging, and fact-claiming comments on social media. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in German. Considering the relatedness of the three tasks, we approached the problem using large pre-trained transformer models and multitask learning. Our results indicate that multitask learning achieves performance superior to the more common single task learning approach in all three tasks. We submit our best systems to GermEval-2021 under the team name WLV-RIT.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3306,"**Title**{UCTG}: A Unified Controllable Text Generation Framework for Query Auto-Completion

**Abstract**In the field of natural language generation (NLG), controlling text generation (CTG) is critical, particularly in query auto-completion (QAC) where the need for personalization and diversity is paramount. However, it is essentially challenging to adapt to various control objectives and constraints, which results in existing CTG approaches meeting with mixed success. This paper presents UCTG, a unified controllable text generation framework, which introduces a novel prompt learning method for CTG. Specifically, this framework seamlessly integrates a control module, a prompt module, and a generation module. The control module leverages a fine-tuned model to distill user preference features and behavioral patterns from historical data, incorporating human feedback into the model`s loss functions. These features are then transformed by the prompt module into vectors that guide the generation module. As such, the text generation can be flexibly controlled without modifying the task settings. By employing this unified approach, UCTG significantly improves query accuracy and coherence in tasks with different objectives and constraints, which is validated by extensive experiments on the Meituan and AOL real-world datasets. UCTG not only improves text generation control in QAC but also sets a new framework for flexible NLG applications.","Li, Zhipeng, Zheng, Shuang, Xiao, Jiaping, Li, Xianneng, Wang, Lei",,,{UCTG}: A Unified Controllable Text Generation Framework for Query Auto-Completion,,, , ,,"In the field of natural language generation (NLG), controlling text generation (CTG) is critical, particularly in query auto-completion (QAC) where the need for personalization and diversity is paramount. However, it is essentially challenging to adapt to various control objectives and constraints, which results in existing CTG approaches meeting with mixed success. This paper presents UCTG, a unified controllable text generation framework, which introduces a novel prompt learning method for CTG. Specifically, this framework seamlessly integrates a control module, a prompt module, and a generation module. The control module leverages a fine-tuned model to distill user preference features and behavioral patterns from historical data, incorporating human feedback into the model`s loss functions. These features are then transformed by the prompt module into vectors that guide the generation module. As such, the text generation can be flexibly controlled without modifying the task settings. By employing this unified approach, UCTG significantly improves query accuracy and coherence in tasks with different objectives and constraints, which is validated by extensive experiments on the Meituan and AOL real-world datasets. UCTG not only improves text generation control in QAC but also sets a new framework for flexible NLG applications.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics: Industry Track,,out_of_scope,
3307,"**Title**Sentiment- and Keyword-Controllable Text Generation in {G}erman with Pre-trained Language Models

**Abstract**Controllable Text Generation (CTG) aims to en-
    hance the controllability of language models by
    providing the user with mechanisms to control
     attributes such as sentiment, topic, and style in
    the generated text. Despite the progress in En-
    glish text generation, the potential challenges
    of CTG in other languages such as German re-
    main largely underexplored. This study investi-
    gates CTG with Pre-trained Language Models
    (PLMs), i.e. GPT-2 in German, to achieve both
    sentiment and keyword control. To this end,
    Supervised Fine-Tuning (SFT) and Reinforce-
   ment Learning (RL) were first used for senti-
   ment control and then the Logit Modification
   Mechanism for keyword forcing. Our initial
    study has shown that the combination of these
    techniques is promising for CTG in German.
   More specifically, text generation works well
    with respect to the given sentiment, while im-
    provements are still needed to ensure coherence
    and fluency in the generated text with specific
    keywords. Compared to forcing nouns, forcing
    sentiment-based keywords degrades the quality
    of the texts. This means that sentiment and key-
   word control need to be combined in a single
    training process to achieve better concurrent
     control. The code is publicly available to repro-
    duce the results1.

1  Introduction

The rise of Pre-trained Language Models (PLMs)
has revolutionized text generation, making a sub-
stantial advancement in fields like e-commerce and
marketing.  These models, trained on extensive
text corpora, are capable of generating new con-
tent with a deep understanding of language (Zhang
et al., 2022). Despite their remarkable abilities, the
probabilistic nature of these models means the gen-
erated texts may not always align perfectly with
the intents of users.

  1https://github.com/polie94/
SwissText2024  In response to this challenge, various meth-
ods for Controllable Text Generation (CTG) have
emerged, including but not limited to fine-tuning,
retraining, and post-processing (Zhang et al., 2022).
These strategies, while effective to some extent, of-
ten fall short of granting users full control over
the sentiment or topic attributes of the generated
text. In contrast, the “plug-and-play” approach de-
scribed by Zhu et al. (2022) offers a more interac-
tive approach by incorporating external inputs such
as keywords or topic labels to intuitively control the
generated text. This approach not only enhances
control over the final output but also streamlines
text creation, enhancing efficiency and aligning
language models with human preferences.
  Recent CTG research has mainly concentrated
on English, leaving a gap to other languages, like
German. German CTG presents unique challenges
due to its complex grammar and compound words,
raising questions about how existing techniques
generalize to German and the interplay between
sentiment and keyword control.
  To address these challenges, this study focuses
on adapting the German GPT-2 model (Minixhofer
et al., 2022) for “plug-and-play” manner. Given a
sentiment token, a set of keywords and a prompt,
we expect the model to complete the given prompt
with respect to the specified sentiment and utilizing
the given keywords. Our approach involves devel-
oping a sentiment classifier, conducting Supervised
Fine-Tuning (SFT), and utilizing Reinforcement
Learning (RL) for further refinement. Additionally,
we adapted a Logit Modification Mechanism from
Pascual et al. (2020) to incorporate specified key-
words into the generated content. The contributions
of this work are twofold:
    • We evaluate the synergy between the fine-
     tuning and post-processing in CTG, showing
      their mutual influence on the generated text.
    • We identify the gap in a performance evalua-
     tion when combining the sentiment and key-","{\.Z}al, Paulina Aleksandra, Lu, Guang, Gu, Nianlong",,,Sentiment- and Keyword-Controllable Text Generation in {G}erman with Pre-trained Language Models,,, , ,,"Controllable Text Generation (CTG) aims to en-
    hance the controllability of language models by
    providing the user with mechanisms to control
     attributes such as sentiment, topic, and style in
    the generated text. Despite the progress in En-
    glish text generation, the potential challenges
    of CTG in other languages such as German re-
    main largely underexplored. This study investi-
    gates CTG with Pre-trained Language Models
    (PLMs), i.e. GPT-2 in German, to achieve both
    sentiment and keyword control. To this end,
    Supervised Fine-Tuning (SFT) and Reinforce-
   ment Learning (RL) were first used for senti-
   ment control and then the Logit Modification
   Mechanism for keyword forcing. Our initial
    study has shown that the combination of these
    techniques is promising for CTG in German.
   More specifically, text generation works well
    with respect to the given sentiment, while im-
    provements are still needed to ensure coherence
    and fluency in the generated text with specific
    keywords. Compared to forcing nouns, forcing
    sentiment-based keywords degrades the quality
    of the texts. This means that sentiment and key-
   word control need to be combined in a single
    training process to achieve better concurrent
     control. The code is publicly available to repro-
    duce the results1.

1  Introduction

The rise of Pre-trained Language Models (PLMs)
has revolutionized text generation, making a sub-
stantial advancement in fields like e-commerce and
marketing.  These models, trained on extensive
text corpora, are capable of generating new con-
tent with a deep understanding of language (Zhang
et al., 2022). Despite their remarkable abilities, the
probabilistic nature of these models means the gen-
erated texts may not always align perfectly with
the intents of users.

  1https://github.com/polie94/
SwissText2024  In response to this challenge, various meth-
ods for Controllable Text Generation (CTG) have
emerged, including but not limited to fine-tuning,
retraining, and post-processing (Zhang et al., 2022).
These strategies, while effective to some extent, of-
ten fall short of granting users full control over
the sentiment or topic attributes of the generated
text. In contrast, the “plug-and-play” approach de-
scribed by Zhu et al. (2022) offers a more interac-
tive approach by incorporating external inputs such
as keywords or topic labels to intuitively control the
generated text. This approach not only enhances
control over the final output but also streamlines
text creation, enhancing efficiency and aligning
language models with human preferences.
  Recent CTG research has mainly concentrated
on English, leaving a gap to other languages, like
German. German CTG presents unique challenges
due to its complex grammar and compound words,
raising questions about how existing techniques
generalize to German and the interplay between
sentiment and keyword control.
  To address these challenges, this study focuses
on adapting the German GPT-2 model (Minixhofer
et al., 2022) for “plug-and-play” manner. Given a
sentiment token, a set of keywords and a prompt,
we expect the model to complete the given prompt
with respect to the specified sentiment and utilizing
the given keywords. Our approach involves devel-
oping a sentiment classifier, conducting Supervised
Fine-Tuning (SFT), and utilizing Reinforcement
Learning (RL) for further refinement. Additionally,
we adapted a Logit Modification Mechanism from
Pascual et al. (2020) to incorporate specified key-
words into the generated content. The contributions
of this work are twofold:
    • We evaluate the synergy between the fine-
     tuning and post-processing in CTG, showing
      their mutual influence on the generated text.
    • We identify the gap in a performance evalua-
     tion when combining the sentiment and key-",,,,, ,  Proceedings of the 9th edition of the Swiss Text Analytics Conference,,out_but_toxicity,
3308,"**Title**Personalized Text Generation with Fine-Grained Linguistic Control

**Abstract**As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized. However, most research on controllable text generation focuses on controlling the content or modeling specific high-level/coarse-grained attributes that reflect authors' writing styles, such as formality, domain, or sentiment. In this paper, we focus on controlling fine-grained attributes spanning multiple linguistic dimensions, such as lexical and syntactic attributes. We introduce a novel benchmark to train generative models and evaluate their ability to generate personalized text based on multiple fine-grained linguistic attributes. We systematically investigate the performance of various large language models on our benchmark and draw insights from the factors that impact their performance. We make our code, data, models, and benchmarks publicly available.","Alhafni, Bashar, Kulkarni, Vivek, Kumar, Dhruv, Raheja, Vipul",,,Personalized Text Generation with Fine-Grained Linguistic Control,,, , ,,"As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized. However, most research on controllable text generation focuses on controlling the content or modeling specific high-level/coarse-grained attributes that reflect authors' writing styles, such as formality, domain, or sentiment. In this paper, we focus on controlling fine-grained attributes spanning multiple linguistic dimensions, such as lexical and syntactic attributes. We introduce a novel benchmark to train generative models and evaluate their ability to generate personalized text based on multiple fine-grained linguistic attributes. We systematically investigate the performance of various large language models on our benchmark and draw insights from the factors that impact their performance. We make our code, data, models, and benchmarks publicly available.",,,,, ,  Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024),,detox,
3309,"**Title**{PG}-Story: Taxonomy, Dataset, and Evaluation for Ensuring Child-Safe Content for Story Generation

**Abstract**Creating children`s stories through text generation is a creative task that requires stories to be both entertaining and suitable for young audiences. However, since current story generation systems often rely on pre-trained language models fine-tuned with limited story data, they may not always prioritize child-friendliness. This can lead to the unintended generation of stories containing problematic elements such as violence, profanity, and biases. Regrettably, despite the significance of these concerns, there is a lack of clear guidelines and benchmark datasets for ensuring content safety for children. In this paper, we introduce a taxonomy specifically tailored to assess content safety in text, with a strong emphasis on children`s well-being. We present PG-Story, a dataset that includes detailed annotations for both sentence-level and discourse-level safety. We demonstrate the potential of identifying unsafe content through self-diagnosis and employing controllable generation techniques during the decoding phase to minimize unsafe elements in generated stories.","Tsai, Alicia Y., Oraby, Shereen, Narayan-Chen, Anjali, Cervone, Alessandra, Gella, Spandana, Verma, Apurv, Chung, Tagyoung, Huang, Jing, Peng, Nanyun",,,"{PG}-Story: Taxonomy, Dataset, and Evaluation for Ensuring Child-Safe Content for Story Generation",,,10.18653/v1/2024.nlp4pi-1.7 , ,,"Creating children`s stories through text generation is a creative task that requires stories to be both entertaining and suitable for young audiences. However, since current story generation systems often rely on pre-trained language models fine-tuned with limited story data, they may not always prioritize child-friendliness. This can lead to the unintended generation of stories containing problematic elements such as violence, profanity, and biases. Regrettably, despite the significance of these concerns, there is a lack of clear guidelines and benchmark datasets for ensuring content safety for children. In this paper, we introduce a taxonomy specifically tailored to assess content safety in text, with a strong emphasis on children`s well-being. We present PG-Story, a dataset that includes detailed annotations for both sentence-level and discourse-level safety. We demonstrate the potential of identifying unsafe content through self-diagnosis and employing controllable generation techniques during the decoding phase to minimize unsafe elements in generated stories.",,,,, ,  Proceedings of the Third Workshop on NLP for Positive Impact,,out_of_scope,
3310,"**Title**Formal Semantic Controls over Language Models

**Abstract**Text embeddings provide a concise representation of the semantics of sentences and larger spans of text, rather than individual words, capturing a wide range of linguistic features. They have found increasing application to a variety of NLP tasks, including machine translation and natural language inference. While most recent breakthroughs in task performance are being achieved by large scale distributional models, there is a growing disconnection between their knowledge representation and traditional semantics, which hinders efforts to capture such knowledge in human interpretable form or explain model inference behaviour. In this tutorial, we examine from basics to the cutting edge research on the analysis and control of text representations, aiming to shorten the gap between deep latent semantics and formal symbolics. This includes the considerations on knowledge formalisation, the linguistic information that can be extracted and measured from distributional models, and intervention techniques that enable explainable reasoning and controllable text generation, covering methods from pooling to LLM-based.","Silva de Carvalho, Danilo, Zhang, Yingji, Freitas, Andr{\'e}",,,Formal Semantic Controls over Language Models,,, , ,,"Text embeddings provide a concise representation of the semantics of sentences and larger spans of text, rather than individual words, capturing a wide range of linguistic features. They have found increasing application to a variety of NLP tasks, including machine translation and natural language inference. While most recent breakthroughs in task performance are being achieved by large scale distributional models, there is a growing disconnection between their knowledge representation and traditional semantics, which hinders efforts to capture such knowledge in human interpretable form or explain model inference behaviour. In this tutorial, we examine from basics to the cutting edge research on the analysis and control of text representations, aiming to shorten the gap between deep latent semantics and formal symbolics. This includes the considerations on knowledge formalisation, the linguistic information that can be extracted and measured from distributional models, and intervention techniques that enable explainable reasoning and controllable text generation, covering methods from pooling to LLM-based.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024): Tutorial Summaries",,out_of_scope,
3311,"**Title**{CAMERA}{\textthreesuperior}: An Evaluation Dataset for Controllable Ad Text Generation in {J}apanese

**Abstract**Ad text generation is the task of creating compelling text from an advertising asset that describes products or services, such as a landing page. In advertising, diversity plays an important role in enhancing the effectiveness of an ad text, mitigating a phenomenon called {\textquotedblleft}ad fatigue,{\textquotedblright} where users become disengaged due to repetitive exposure to the same advertisement. Despite numerous efforts in ad text generation, the aspect of diversifying ad texts has received limited attention, particularly in non-English languages like Japanese. To address this, we present CAMERA{\textthreesuperior}, an evaluation dataset for controllable text generation in the advertising domain in Japanese. Our dataset includes 3,980 ad texts written by expert annotators, taking into account various aspects of ad appeals. We make CAMERA{\textthreesuperior} publicly available, allowing researchers to examine the capabilities of recent NLG models in controllable text generation in a real-world scenario.","Inoue, Go, Kato, Akihiko, Mita, Masato, Honda, Ukyo, Zhang, Peinan",,,{CAMERA}{\textthreesuperior}: An Evaluation Dataset for Controllable Ad Text Generation in {J}apanese,,, , ,,"Ad text generation is the task of creating compelling text from an advertising asset that describes products or services, such as a landing page. In advertising, diversity plays an important role in enhancing the effectiveness of an ad text, mitigating a phenomenon called {\textquotedblleft}ad fatigue,{\textquotedblright} where users become disengaged due to repetitive exposure to the same advertisement. Despite numerous efforts in ad text generation, the aspect of diversifying ad texts has received limited attention, particularly in non-English languages like Japanese. To address this, we present CAMERA{\textthreesuperior}, an evaluation dataset for controllable text generation in the advertising domain in Japanese. Our dataset includes 3,980 ad texts written by expert annotators, taking into account various aspects of ad appeals. We make CAMERA{\textthreesuperior} publicly available, allowing researchers to examine the capabilities of recent NLG models in controllable text generation in a real-world scenario.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,out_of_scope,
3312,"**Title**Effective Integration of Text Diffusion and Pre-Trained Language Models with Linguistic Easy-First Schedule

**Abstract**Diffusion models have become a powerful generative modeling paradigm, achieving great success in continuous data patterns. However, the discrete nature of text data results in compatibility issues between continuous diffusion models (CDMs) and pre-trained language models (PLMs). That is, the performance of diffusion models even degrades when combined with PLMs. To alleviate this issue, we propose to utilize a pre-trained decoder to convert the denoised embedding vectors into natural language instead of using the widely used rounding operation. In this way, CDMs can be more effectively combined with PLMs. Additionally, considering that existing noise schedules in text diffusion models do not take into account the linguistic differences among tokens, which violates the easy-first policy for text generation, we propose a linguistic easy-first schedule that incorporates the measure of word importance, conforming to easy-first-generation linguistic features and bringing about improved generation quality. Experiment results on the E2E dataset and five controllable tasks show that our approach can combine the merits of CDMs and PLMs, significantly outperforming other diffusion-based models.","Ou, Yimin, Jian, Ping",,,Effective Integration of Text Diffusion and Pre-Trained Language Models with Linguistic Easy-First Schedule,,, , ,,"Diffusion models have become a powerful generative modeling paradigm, achieving great success in continuous data patterns. However, the discrete nature of text data results in compatibility issues between continuous diffusion models (CDMs) and pre-trained language models (PLMs). That is, the performance of diffusion models even degrades when combined with PLMs. To alleviate this issue, we propose to utilize a pre-trained decoder to convert the denoised embedding vectors into natural language instead of using the widely used rounding operation. In this way, CDMs can be more effectively combined with PLMs. Additionally, considering that existing noise schedules in text diffusion models do not take into account the linguistic differences among tokens, which violates the easy-first policy for text generation, we propose a linguistic easy-first schedule that incorporates the measure of word importance, conforming to easy-first-generation linguistic features and bringing about improved generation quality. Experiment results on the E2E dataset and five controllable tasks show that our approach can combine the merits of CDMs and PLMs, significantly outperforming other diffusion-based models.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,out_of_scope,
3313,"**Title**Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques

**Abstract**Rerunning a metric-based evaluation should be more straightforward and results should be closer than in a human-based evaluation, especially where code and model checkpoints are made available by the original authors. As this brief report of our efforts to rerun a metric-based evaluation of a set of multi-aspect controllable text generation (CTG) techniques shows however, such reruns of evaluations do not always produce results that are the same as the original results, and can reveal errors in the orginal work.","Lorandi, Michela, Belz, Anya",,,Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques,,, , ,,"Rerunning a metric-based evaluation should be more straightforward and results should be closer than in a human-based evaluation, especially where code and model checkpoints are made available by the original authors. As this brief report of our efforts to rerun a metric-based evaluation of a set of multi-aspect controllable text generation (CTG) techniques shows however, such reruns of evaluations do not always produce results that are the same as the original results, and can reveal errors in the orginal work.",,,,, ,  Proceedings of the Fourth Workshop on Human Evaluation of NLP Systems (HumEval) @ LREC-COLING 2024,,out_of_scope,
3314,"**Title**Analysis of Material Facts on Financial Assets: A Generative {AI} Approach

**Abstract**Material facts (MF) are crucial and obligatory disclosures that can significantly influence asset values. Following their release, financial analysts embark on the meticulous and highly specialized task of crafting analyses to shed light on their impact on company assets, a challenge elevated by the daily amount of MFs released. Generative AI, with its demonstrated power of crafting coherent text, emerges as a promising solution to this task. However, while these analyses must incorporate the MF, they must also transcend it, enhancing it with vital background information, valuable and grounded recommendations, prospects, potential risks, and their underlying reasoning. In this paper, we approach this task as an instance of controllable text generation, aiming to ensure adherence to the MF and other pivotal attributes as control elements. We first explore language models' capacity to manage this task by embedding those elements into prompts and engaging popular chatbots. A bilingual proof of concept underscores both the potential and the challenges of applying generative AI techniques to this task.","Assis, Gabriel, Vianna, Daniela, Pappa, Gisele L., Plastino, Alexandre, Meira Jr, Wagner, da Silva, Altigran Soares, Paes, Aline",,,Analysis of Material Facts on Financial Assets: A Generative {AI} Approach,,, , ,,"Material facts (MF) are crucial and obligatory disclosures that can significantly influence asset values. Following their release, financial analysts embark on the meticulous and highly specialized task of crafting analyses to shed light on their impact on company assets, a challenge elevated by the daily amount of MFs released. Generative AI, with its demonstrated power of crafting coherent text, emerges as a promising solution to this task. However, while these analyses must incorporate the MF, they must also transcend it, enhancing it with vital background information, valuable and grounded recommendations, prospects, potential risks, and their underlying reasoning. In this paper, we approach this task as an instance of controllable text generation, aiming to ensure adherence to the MF and other pivotal attributes as control elements. We first explore language models' capacity to manage this task by embedding those elements into prompts and engaging popular chatbots. A bilingual proof of concept underscores both the potential and the challenges of applying generative AI techniques to this task.",,,,, ,"  Proceedings of the Joint Workshop of the 7th Financial Technology and Natural Language Processing, the 5th Knowledge Discovery from Unstructured Data in Financial Services, and the 4th Workshop on Economics and Natural Language Processing",,out_of_scope,
3315,"**Title**{G}aussian Process Optimization for Adaptable Multi-Objective Text Generation using Linearly-Weighted Language Models

**Abstract**In multi-objective text generation, we aim to optimize over multiple weighted aspects (e.g., toxicity, semantic preservation, fluency) of the generated text. However, multi-objective weighting schemes may change dynamically in practice according to deployment requirements, evolving business needs, personalization requirements on edge devices, or the availability of new language models and/or objective requirements. Ideally, we need an efficient method to adapt to the dynamic requirements of the overall objective. To address these requirements, we propose a linear combination of objective-specific language models to \textbf{efficiently} adapt the decoding process and optimize for the desired objective \textbf{without} the significant computational overhead of retraining one or more language models. We show empirically that we can leverage Gaussian Process black box optimization to adapt the language model decoder weights to outperform other fixed weighting schemes and standard baselines of the task in only a few iterations of decoding. Overall this approach enables highly efficient adaptation of controllable language models via multi-objective weighting schemes that may evolve dynamically in practical deployment situations.","Abdollah Pour, Mohammad Mahdi, Pesaranghader, Ali, Cohen, Eldan, Sanner, Scott",,,{G}aussian Process Optimization for Adaptable Multi-Objective Text Generation using Linearly-Weighted Language Models,,,10.18653/v1/2024.findings-naacl.99 , ,,"In multi-objective text generation, we aim to optimize over multiple weighted aspects (e.g., toxicity, semantic preservation, fluency) of the generated text. However, multi-objective weighting schemes may change dynamically in practice according to deployment requirements, evolving business needs, personalization requirements on edge devices, or the availability of new language models and/or objective requirements. Ideally, we need an efficient method to adapt to the dynamic requirements of the overall objective. To address these requirements, we propose a linear combination of objective-specific language models to \textbf{efficiently} adapt the decoding process and optimize for the desired objective \textbf{without} the significant computational overhead of retraining one or more language models. We show empirically that we can leverage Gaussian Process black box optimization to adapt the language model decoder weights to outperform other fixed weighting schemes and standard baselines of the task in only a few iterations of decoding. Overall this approach enables highly efficient adaptation of controllable language models via multi-objective weighting schemes that may evolve dynamically in practical deployment situations.",,,,, ,  Findings of the Association for Computational Linguistics: NAACL 2024,,detox,
3316,"**Title**Reinforcement Learning with Token-level Feedback for Controllable Text Generation

**Abstract**To meet the requirements of real-world applications, it is essential to control generations of large language models (LLMs). Prior research has tried to introduce reinforcement learning (RL) into controllable text generation while most existing methods suffer from overfitting issues (finetuning-based methods) or semantic collapse (post-processing methods). However, current RL methods are generally guided by coarse-grained (sentence/paragraph-level) feedback, which may lead to suboptimal performance owing to semantic twists or progressions within sentences. To tackle that, we propose a novel reinforcement learning algorithm named TOLE which formulates TOken-LEvel rewards for controllable text generation, and employs a {\textquotedblleft}first-quantize-then-noise{\textquotedblright} paradigm to enhance the robustness of the RL algorithm. Furthermore, TOLE can be flexibly extended to multiple constraints with little computational expense. Experimental results show that our algorithm can achieve superior performance on both single-attribute and multi-attribute control tasks. We have released our codes at https://github.com/WindyLee0822/CTG.","Li, Wendi, Wei, Wei, Xu, Kaihe, Xie, Wenfeng, Chen, Dangyang, Cheng, Yu",,,Reinforcement Learning with Token-level Feedback for Controllable Text Generation,,,10.18653/v1/2024.findings-naacl.111 , ,,"To meet the requirements of real-world applications, it is essential to control generations of large language models (LLMs). Prior research has tried to introduce reinforcement learning (RL) into controllable text generation while most existing methods suffer from overfitting issues (finetuning-based methods) or semantic collapse (post-processing methods). However, current RL methods are generally guided by coarse-grained (sentence/paragraph-level) feedback, which may lead to suboptimal performance owing to semantic twists or progressions within sentences. To tackle that, we propose a novel reinforcement learning algorithm named TOLE which formulates TOken-LEvel rewards for controllable text generation, and employs a {\textquotedblleft}first-quantize-then-noise{\textquotedblright} paradigm to enhance the robustness of the RL algorithm. Furthermore, TOLE can be flexibly extended to multiple constraints with little computational expense. Experimental results show that our algorithm can achieve superior performance on both single-attribute and multi-attribute control tasks. We have released our codes at https://github.com/WindyLee0822/CTG.",,,,, ,  Findings of the Association for Computational Linguistics: NAACL 2024,,out_of_scope,
3317,"**Title**{TARA}: Token-level Attribute Relation Adaptation for Multi-Attribute Controllable Text Generation

**Abstract**Multi-attribute controllable  text generation
   (CTG) aims to generate fluent text satisfying
    multiple attributes, which is an important and
    challenging task. The majority of previous re-
    search on multi-attribute CTG has ignored the
    interrelations of attributes that affect the per-
    formance of text generation. Recently, several
   work considers the attribute relations by explic-
     itly defining them as inhibtory. We argue that
    for multi-attribute CTG, the attribute relations
    are not fixed, which can be not only inhibtory
    but promotive as well. In this paper, we tackle
    the multi-attribute CTG problem by explicitly
    identifying the above attribute relations for the
     first time and propose TARA, which employs
    token-level attribute relation adaptation and rep-
    resentation to generate text with the balanced
     multi-attribute control. Experimental results on
    the benchmark dataset demonstrate the effec-
    tiveness of our proposed method.

1  Introduction

Multi-attribute controllable text generation (CTG)
aims to generate fluent text satisfying multiple at-
tributes.  The majority of previous research on
multi-attribute CTG mainly employs parameter-
efficient fine-tuning (Keskar et al., 2019; Zhang
et al., 2020) and inference-time methods (Dathathri
et al., 2020; Krause et al., 2021) to tackle the prob-
lem. However, most of them has ignored the inter-
relations of attributes, which is a fundamental issue
in multi-attribute CTG.
  Recent work (Qian et al., 2022; Ding et al., 2023)
take the attribute relations into consider and uti-
lizes prefix tuning or VAE to train a multi-attribute
model. Several work (Gu et al., 2022; Huang et al.,
2023) further defines multi-attribute relation as in-
hibtory. For instance, Dist. Lens (Gu et al., 2022)
identify that mutual interference of controllers
causes attribute control degeneration and searches

   *Corresponding authorFigure 1: Token-level multi-attribute promotive and
inhibitory relations. Here MSG is the abbreviation of
Monosodium Glutamate.

for intersections in the attribute space. Prompt-
Gating (Huang et al., 2023) use trainable gates to
normalize the interference among attributes.
   In practical situations, the attribute relations are
not fixed, nor are they only manifested as ""in-
hibitory"". Take the examples in Figure 1. There
are multiple attributes including sentiment (with
""positive"" and ""negative"" attribute values) and topic
(with ""Mexican"", ""American"" and ""Asian"" attribute
values) in a typical restaurant domain. Fries demon-
strates the promotive relation between positive and
American, and the inhibitory relation between neg-
ative and American. This indicates that a more
fine-grained definition and exploitation of attribute
relations is needed for multi-attribute CTG.
   In this paper, we tackle the multi-attribute CTG
with Token-level Attribute Relation Adaptation
and representation, and propose TARA, which uses
a dynamic text generation strategy. In summary,
our contributions are as follows:

    • We firstly identify both promotive and in-
     hibitory  attribute  relations,  and  develop
     a token-level  attribute relation adaptation
    method for multi-attribute CTG.

    • The proposed attribute-adaptive prefix tuning
     adjusts attribute’s expression with token-level
      attribute representation, and the dynamic text
     generation strategy we design balances multi-
      attribute control with promotive and inhibitory
      attribute relations.12570Attribute 1:  SentimentPositive                 Negativepromotive   Fries        inhibitory   MSG  promotiveFries   inhibitory   MSG
inhibitoryAttribute 2:   TopicMexican        American            Asian","Cao, Yilin, Zhao, Jiahao, Zhang, Ruike, Zou, Hanyi, Mao, Wenji",,,{TARA}: Token-level Attribute Relation Adaptation for Multi-Attribute Controllable Text Generation,,,10.18653/v1/2024.findings-emnlp.734 , ,,"Multi-attribute controllable  text generation
   (CTG) aims to generate fluent text satisfying
    multiple attributes, which is an important and
    challenging task. The majority of previous re-
    search on multi-attribute CTG has ignored the
    interrelations of attributes that affect the per-
    formance of text generation. Recently, several
   work considers the attribute relations by explic-
     itly defining them as inhibtory. We argue that
    for multi-attribute CTG, the attribute relations
    are not fixed, which can be not only inhibtory
    but promotive as well. In this paper, we tackle
    the multi-attribute CTG problem by explicitly
    identifying the above attribute relations for the
     first time and propose TARA, which employs
    token-level attribute relation adaptation and rep-
    resentation to generate text with the balanced
     multi-attribute control. Experimental results on
    the benchmark dataset demonstrate the effec-
    tiveness of our proposed method.

1  Introduction

Multi-attribute controllable text generation (CTG)
aims to generate fluent text satisfying multiple at-
tributes.  The majority of previous research on
multi-attribute CTG mainly employs parameter-
efficient fine-tuning (Keskar et al., 2019; Zhang
et al., 2020) and inference-time methods (Dathathri
et al., 2020; Krause et al., 2021) to tackle the prob-
lem. However, most of them has ignored the inter-
relations of attributes, which is a fundamental issue
in multi-attribute CTG.
  Recent work (Qian et al., 2022; Ding et al., 2023)
take the attribute relations into consider and uti-
lizes prefix tuning or VAE to train a multi-attribute
model. Several work (Gu et al., 2022; Huang et al.,
2023) further defines multi-attribute relation as in-
hibtory. For instance, Dist. Lens (Gu et al., 2022)
identify that mutual interference of controllers
causes attribute control degeneration and searches

   *Corresponding authorFigure 1: Token-level multi-attribute promotive and
inhibitory relations. Here MSG is the abbreviation of
Monosodium Glutamate.

for intersections in the attribute space. Prompt-
Gating (Huang et al., 2023) use trainable gates to
normalize the interference among attributes.
   In practical situations, the attribute relations are
not fixed, nor are they only manifested as ""in-
hibitory"". Take the examples in Figure 1. There
are multiple attributes including sentiment (with
""positive"" and ""negative"" attribute values) and topic
(with ""Mexican"", ""American"" and ""Asian"" attribute
values) in a typical restaurant domain. Fries demon-
strates the promotive relation between positive and
American, and the inhibitory relation between neg-
ative and American. This indicates that a more
fine-grained definition and exploitation of attribute
relations is needed for multi-attribute CTG.
   In this paper, we tackle the multi-attribute CTG
with Token-level Attribute Relation Adaptation
and representation, and propose TARA, which uses
a dynamic text generation strategy. In summary,
our contributions are as follows:

    • We firstly identify both promotive and in-
     hibitory  attribute  relations,  and  develop
     a token-level  attribute relation adaptation
    method for multi-attribute CTG.

    • The proposed attribute-adaptive prefix tuning
     adjusts attribute’s expression with token-level
      attribute representation, and the dynamic text
     generation strategy we design balances multi-
      attribute control with promotive and inhibitory
      attribute relations.12570Attribute 1:  SentimentPositive                 Negativepromotive   Fries        inhibitory   MSG  promotiveFries   inhibitory   MSG
inhibitoryAttribute 2:   TopicMexican        American            Asian",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,out_of_scope,
3318,"**Title**{T}iny{S}tyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings

**Abstract**The goal of text style transfer is to transform the style of texts while preserving their original meaning, often with only a few examples of the target style. Existing style transfer methods generally rely on the few-shot capabilities of large language models or on complex controllable text generation approaches that are inefficient and underperform on fluency metrics. We introduce TinyStyler, a lightweight but effective approach, which leverages a small language model (800M params) and pre-trained authorship embeddings to perform efficient, few-shot text style transfer. We evaluate on the challenging task of authorship style transfer and find TinyStyler outperforms strong approaches such as GPT-4. We also evaluate TinyStyler`s ability to perform text attribute style transfer (formal $\leftrightarrow$ informal) with automatic and human evaluations and find that the approach outperforms recent controllable text generation methods.","Horvitz, Zachary, Patel, Ajay, Singh, Kanishk, Callison-Burch, Chris, McKeown, Kathleen, Yu, Zhou",,,{T}iny{S}tyler: Efficient Few-Shot Text Style Transfer with Authorship Embeddings,,,10.18653/v1/2024.findings-emnlp.781 , ,,"The goal of text style transfer is to transform the style of texts while preserving their original meaning, often with only a few examples of the target style. Existing style transfer methods generally rely on the few-shot capabilities of large language models or on complex controllable text generation approaches that are inefficient and underperform on fluency metrics. We introduce TinyStyler, a lightweight but effective approach, which leverages a small language model (800M params) and pre-trained authorship embeddings to perform efficient, few-shot text style transfer. We evaluate on the challenging task of authorship style transfer and find TinyStyler outperforms strong approaches such as GPT-4. We also evaluate TinyStyler`s ability to perform text attribute style transfer (formal $\leftrightarrow$ informal) with automatic and human evaluations and find that the approach outperforms recent controllable text generation methods.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,out_of_scope,
3319,"**Title**{U}ni{F}ashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation

**Abstract**The fashion domain encompasses a variety of real-world multimodal tasks, including multimodal retrieval and multimodal generation. The rapid advancements in artificial intelligence generated content, particularly in technologies like large language models for text generation and diffusion models for visual generation, have sparked widespread research interest in applying these multimodal models in the fashion domain. However, tasks that use embeddings, such as image-to-text or text-to-image retrieval, have been largely ignored from this perspective due to the diverse nature of the multimodal fashion domain. And current research on multi-task single models lack focus on image generation. In this work, we present UniFashion, a unified framework that simultaneously tackles the challenges of multimodal generation and retrieval tasks within the fashion domain, integrating image generation with retrieval tasks and text generation tasks. UniFashion unifies embedding and generative tasks by integrating a diffusion model and LLM, enabling controllable and high-fidelity generation. Our model significantly outperforms previous single-task state-of-the-art models across diverse fashion tasks, and can be readily adapted to manage complex vision-language tasks. This work demonstrates the potential learning synergy between multimodal generation and retrieval, offering a promising direction for future research in the fashion domain.","Zhao, Xiangyu, Zhang, Yuehan, Zhang, Wenlong, Wu, Xiao-Ming",,,{U}ni{F}ashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation,,,10.18653/v1/2024.emnlp-main.89 , ,,"The fashion domain encompasses a variety of real-world multimodal tasks, including multimodal retrieval and multimodal generation. The rapid advancements in artificial intelligence generated content, particularly in technologies like large language models for text generation and diffusion models for visual generation, have sparked widespread research interest in applying these multimodal models in the fashion domain. However, tasks that use embeddings, such as image-to-text or text-to-image retrieval, have been largely ignored from this perspective due to the diverse nature of the multimodal fashion domain. And current research on multi-task single models lack focus on image generation. In this work, we present UniFashion, a unified framework that simultaneously tackles the challenges of multimodal generation and retrieval tasks within the fashion domain, integrating image generation with retrieval tasks and text generation tasks. UniFashion unifies embedding and generative tasks by integrating a diffusion model and LLM, enabling controllable and high-fidelity generation. Our model significantly outperforms previous single-task state-of-the-art models across diverse fashion tasks, and can be readily adapted to manage complex vision-language tasks. This work demonstrates the potential learning synergy between multimodal generation and retrieval, offering a promising direction for future research in the fashion domain.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3320,"**Title**Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation

**Abstract**Domain experts across engineering, healthcare, and education follow strict standards for producing quality content such as technical manuals, medication instructions, and children`s reading materials. However, current works in controllable text generation have yet to explore using these standards as references for control. Towards this end, we introduce Standardize, a retrieval-style in-context learning-based framework to guide large language models to align with expert-defined standards. Focusing on English language standards in the education domain as a use case, we consider the Common European Framework of Reference for Languages (CEFR) and Common Core Standards (CCS) for the task of open-ended content generation. Our findings show that models can gain 45{\%} to 100{\%} increase in precise accuracy across open and commercial LLMs evaluated, demonstrating that the use of knowledge artifacts extracted from standards and integrating them in the generation process can effectively guide models to produce better standard-aligned content.","Imperial, Joseph Marvin, Forey, Gail, Tayyar Madabushi, Harish",,,Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation,,,10.18653/v1/2024.emnlp-main.94 , ,,"Domain experts across engineering, healthcare, and education follow strict standards for producing quality content such as technical manuals, medication instructions, and children`s reading materials. However, current works in controllable text generation have yet to explore using these standards as references for control. Towards this end, we introduce Standardize, a retrieval-style in-context learning-based framework to guide large language models to align with expert-defined standards. Focusing on English language standards in the education domain as a use case, we consider the Common European Framework of Reference for Languages (CEFR) and Common Core Standards (CCS) for the task of open-ended content generation. Our findings show that models can gain 45{\%} to 100{\%} increase in precise accuracy across open and commercial LLMs evaluated, demonstrating that the use of knowledge artifacts extracted from standards and integrating them in the generation process can effectively guide models to produce better standard-aligned content.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3321,"**Title**{RSA}-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework

**Abstract**Despite significant advancements in natural language generation, controlling language models to produce texts with desired attributes remains a formidable challenge. In this work, we introduce RSA-Control, a training-free controllable text generation framework grounded in pragmatics. RSA-Control directs the generation process by recursively reasoning between imaginary speakers and listeners, enhancing the likelihood that target attributes are correctly interpreted by listeners amidst distractors. Additionally, we introduce a self-adjustable rationality parameter, which allows for automatic adjustment of control strength based on context. Our experiments, conducted with two task types and two types of language models, demonstrate that RSA-Control achieves strong attribute control while maintaining language fluency and content consistency. Our code is available at https://github.com/Ewanwong/RSA-Control.","Wang, Yifan, Demberg, Vera",,,{RSA}-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework,,,10.18653/v1/2024.emnlp-main.318 , ,,"Despite significant advancements in natural language generation, controlling language models to produce texts with desired attributes remains a formidable challenge. In this work, we introduce RSA-Control, a training-free controllable text generation framework grounded in pragmatics. RSA-Control directs the generation process by recursively reasoning between imaginary speakers and listeners, enhancing the likelihood that target attributes are correctly interpreted by listeners amidst distractors. Additionally, we introduce a self-adjustable rationality parameter, which allows for automatic adjustment of control strength based on context. Our experiments, conducted with two task types and two types of language models, demonstrate that RSA-Control achieves strong attribute control while maintaining language fluency and content consistency. Our code is available at https://github.com/Ewanwong/RSA-Control.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3322,"**Title**On the In-context Generation of Language Models

**Abstract**Large language models (LLMs) are found to have the ability of in-context generation (ICG): when they are fed with an in-context prompt concatenating a few somehow similar examples, they can implicitly recognize the pattern of them and then complete the prompt in the same pattern. ICG is curious, since language models are usually not explicitly trained in the same way as the in-context prompt, and the distribution of examples in the prompt differs from that of sequences in the pretrained corpora. This paper provides a systematic study of the ICG ability of language models, covering discussions about its source and influential factors, in the view of both theory and empirical experiments. Concretely, we first propose a plausible latent variable model to model the distribution of the pretrained corpora, and then formalize ICG as a problem of next topic prediction. With this framework, we can prove that the repetition nature of a few topics ensures the ICG ability on them theoretically. Then, we use this controllable pretrained distribution to generate several medium-scale synthetic datasets (token scale: 2.1B-3.9B) and experiment with different settings of Transformer architectures (parameter scale: 4M-234M). Our experimental results further offer insights into how the data and model architectures influence ICG.","Jiang, Zhongtao, Zhang, Yuanzhe, Luo, Kun, Yuan, Xiaowei, Zhao, Jun, Liu, Kang",,,On the In-context Generation of Language Models,,,10.18653/v1/2024.emnlp-main.568 , ,,"Large language models (LLMs) are found to have the ability of in-context generation (ICG): when they are fed with an in-context prompt concatenating a few somehow similar examples, they can implicitly recognize the pattern of them and then complete the prompt in the same pattern. ICG is curious, since language models are usually not explicitly trained in the same way as the in-context prompt, and the distribution of examples in the prompt differs from that of sequences in the pretrained corpora. This paper provides a systematic study of the ICG ability of language models, covering discussions about its source and influential factors, in the view of both theory and empirical experiments. Concretely, we first propose a plausible latent variable model to model the distribution of the pretrained corpora, and then formalize ICG as a problem of next topic prediction. With this framework, we can prove that the repetition nature of a few topics ensures the ICG ability on them theoretically. Then, we use this controllable pretrained distribution to generate several medium-scale synthetic datasets (token scale: 2.1B-3.9B) and experiment with different settings of Transformer architectures (parameter scale: 4M-234M). Our experimental results further offer insights into how the data and model architectures influence ICG.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3323,"**Title**Control Large Language Models via Divide and Conquer

**Abstract**This paper investigates the capability of LLMs on controllable generation with prompt-based controlling, focusing on Lexically Constrained Generation (LCG). We systematically evaluate the performance of LLMs on satisfying lexical constraints with prompt-based controlling, as well as their efficacy in downstream applications. We identified three key reasons that highlight the limitations of LLMs in LCG, including (1) position bias, where LLMs tend to satisfy constraints that appear in specific positions within the input; (2) low responsiveness to control decoding parameters, which minimally impact the performance of LLMs; and (3) struggle with handling the inherent complexity of certain constraints (e.g. compound word). We conclude that black-box LLMs face significant challenges in consistently satisfying lexical constraints with prompt-based controlling. To address this bottleneck, we introduce the Divide and Conquer Generation strategy, effective for both white-box and black-box LLMs, to enhance LLMs performance in LCG tasks, which demonstrates over 90{\%} improvement on success rate in the most challenging LCG task. Our analysis aims to provide valuable insights into the performance of LLMs in LCG with prompt-based controlling, and our proposed strategy offers a pathway to more sophisticated and customized text generation applications.","Li, Bingxuan, Wang, Yiwei, Meng, Tao, Chang, Kai-Wei, Peng, Nanyun",,,Control Large Language Models via Divide and Conquer,,,10.18653/v1/2024.emnlp-main.850 , ,,"This paper investigates the capability of LLMs on controllable generation with prompt-based controlling, focusing on Lexically Constrained Generation (LCG). We systematically evaluate the performance of LLMs on satisfying lexical constraints with prompt-based controlling, as well as their efficacy in downstream applications. We identified three key reasons that highlight the limitations of LLMs in LCG, including (1) position bias, where LLMs tend to satisfy constraints that appear in specific positions within the input; (2) low responsiveness to control decoding parameters, which minimally impact the performance of LLMs; and (3) struggle with handling the inherent complexity of certain constraints (e.g. compound word). We conclude that black-box LLMs face significant challenges in consistently satisfying lexical constraints with prompt-based controlling. To address this bottleneck, we introduce the Divide and Conquer Generation strategy, effective for both white-box and black-box LLMs, to enhance LLMs performance in LCG tasks, which demonstrates over 90{\%} improvement on success rate in the most challenging LCG task. Our analysis aims to provide valuable insights into the performance of LLMs in LCG with prompt-based controlling, and our proposed strategy offers a pathway to more sophisticated and customized text generation applications.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3324,"**Title**{E}dit{E}val: An Instruction-Based Benchmark for Text Improvements

**Abstract**Evaluation of text generation to date has primarily focused on content created sequentially, rather than improvements on a piece of text. Writing, however, is naturally an iterative and incremental process that requires expertise in different modular skills such as fixing outdated information or making the writing style more consistent. Even so, comprehensive evaluation of a model`s capacity to perform these skills and the ability to edit remains sparse. This work introduces EditEval: An instruction-based, benchmark and evaluation suite that leverages high-quality existing and new datasets in English for the automatic evaluation of editing capabilities, such as making text more cohesive and paraphrasing. We evaluate several pre-trained models, which shows that InstructGPT and PEER on average perform the best, but that most baselines fall below the supervised state-of-the-art, particularly when neutralizing and updating information. Our analysis also shows that commonly used metrics for editing tasks do not always correlate well, and that prompts leading to the strongest performance do not necessarily elicit strong performance across different models. Through the release of this benchmark (code and data available at https://github.com/facebookresearch/EditEval) and a publicly available leaderboard challenge, we hope to unlock future work on developing models more capable of controllable and iterative editing.","Dwivedi-Yu, Jane, Schick, Timo, Jiang, Zhengbao, Lomeli, Maria, Lewis, Patrick, Izacard, Gautier, Grave, Edouard, Riedel, Sebastian, Petroni, Fabio",,,{E}dit{E}val: An Instruction-Based Benchmark for Text Improvements,,,10.18653/v1/2024.conll-1.7 , ,,"Evaluation of text generation to date has primarily focused on content created sequentially, rather than improvements on a piece of text. Writing, however, is naturally an iterative and incremental process that requires expertise in different modular skills such as fixing outdated information or making the writing style more consistent. Even so, comprehensive evaluation of a model`s capacity to perform these skills and the ability to edit remains sparse. This work introduces EditEval: An instruction-based, benchmark and evaluation suite that leverages high-quality existing and new datasets in English for the automatic evaluation of editing capabilities, such as making text more cohesive and paraphrasing. We evaluate several pre-trained models, which shows that InstructGPT and PEER on average perform the best, but that most baselines fall below the supervised state-of-the-art, particularly when neutralizing and updating information. Our analysis also shows that commonly used metrics for editing tasks do not always correlate well, and that prompts leading to the strongest performance do not necessarily elicit strong performance across different models. Through the release of this benchmark (code and data available at https://github.com/facebookresearch/EditEval) and a publicly available leaderboard challenge, we hope to unlock future work on developing models more capable of controllable and iterative editing.",,,,, ,  Proceedings of the 28th Conference on Computational Natural Language Learning,,out_of_scope,
3325,"**Title**Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation

**Abstract**Compositional generalization, representing the model`s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking. We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of MCTG approaches. We observe that existing MCTG works generally confront a noticeable performance drop in compositional testing. To mitigate this issue, we introduce Meta-MCTG, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase. We demonstrate the effectiveness of Meta-MCTG through achieving obvious improvement (by at most 3.64{\%}) for compositional testing performance in 94.4{\%}.","Zhong, Tianqi, Li, Zhaoyi, Wang, Quan, Song, Linqi, Wei, Ying, Lian, Defu, Mao, Zhendong",,,Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation,,,10.18653/v1/2024.acl-long.351 , ,,"Compositional generalization, representing the model`s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking. We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of MCTG approaches. We observe that existing MCTG works generally confront a noticeable performance drop in compositional testing. To mitigate this issue, we introduce Meta-MCTG, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase. We demonstrate the effectiveness of Meta-MCTG through achieving obvious improvement (by at most 3.64{\%}) for compositional testing performance in 94.4{\%}.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3326,"**Title**{F}ree{C}trl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation

**Abstract**Controllable text generation (CTG) seeks to craft texts adhering to specific attributes, traditionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. These approaches, while effective, demand extensive computational and data resources. In contrast, some proposed learning-free alternatives circumvent learning but often yield inferior results, exemplifying the fundamental machine learning trade-off between computational expense and model efficacy. To overcome these limitations, we propose FreeCtrl, a learning-free approach that dynamically adjusts the weights of selected feedforward neural network (FFN) vectors to steer the outputs of large language models (LLMs). FreeCtrl hinges on the principle that the weights of different FFN vectors influence the likelihood of different tokens appearing in the output. By identifying and adaptively adjusting the weights of attribute-related FFN vectors, FreeCtrl can control the output likelihood of attribute keywords in the generated content. Extensive experiments on single- and multi-attribute control reveal that the learning-free FreeCtrl outperforms other learning-free and learning-based methods, successfully resolving the dilemma between learning costs and model performance.","Feng, Zijian, Zhou, Hanzhang, Mao, Kezhi, Zhu, Zixiao",,,{F}ree{C}trl: Constructing Control Centers with Feedforward Layers for Learning-Free Controllable Text Generation,,,10.18653/v1/2024.acl-long.412 , ,,"Controllable text generation (CTG) seeks to craft texts adhering to specific attributes, traditionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. These approaches, while effective, demand extensive computational and data resources. In contrast, some proposed learning-free alternatives circumvent learning but often yield inferior results, exemplifying the fundamental machine learning trade-off between computational expense and model efficacy. To overcome these limitations, we propose FreeCtrl, a learning-free approach that dynamically adjusts the weights of selected feedforward neural network (FFN) vectors to steer the outputs of large language models (LLMs). FreeCtrl hinges on the principle that the weights of different FFN vectors influence the likelihood of different tokens appearing in the output. By identifying and adaptively adjusting the weights of attribute-related FFN vectors, FreeCtrl can control the output likelihood of attribute keywords in the generated content. Extensive experiments on single- and multi-attribute control reveal that the learning-free FreeCtrl outperforms other learning-free and learning-based methods, successfully resolving the dilemma between learning costs and model performance.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3327,"**Title**Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation

**Abstract**Multi-aspect controllable text generation aims to control the generated texts in attributes from multiple aspects (e.g., {\textquotedblleft}positive{\textquotedblright} from sentiment and {\textquotedblleft}sport{\textquotedblright} from topic). Existing works neglect attribute correlations formed by the intertwining of different attributes. Particularly, the stereotype formed by imbalanced attribute correlations significantly affects multi-aspect control. In this paper, we propose MAGIC, a new multi-aspect controllable text generation method with disentangled counterfactual augmentation. We alleviate the issue of imbalanced attribute correlations during training using counterfactual feature vectors in the attribute latent space by disentanglement. During inference, we enhance attribute correlations by target-guided counterfactual augmentation to further improve multi-aspect control. Experiments show that MAGIC outperforms state-of-the-art baselines in both imbalanced and balanced attribute correlation scenarios.","Liu, Yi, Liu, Xiangyu, Zhu, Xiangrong, Hu, Wei",,,Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation,,,10.18653/v1/2024.acl-long.500 , ,,"Multi-aspect controllable text generation aims to control the generated texts in attributes from multiple aspects (e.g., {\textquotedblleft}positive{\textquotedblright} from sentiment and {\textquotedblleft}sport{\textquotedblright} from topic). Existing works neglect attribute correlations formed by the intertwining of different attributes. Particularly, the stereotype formed by imbalanced attribute correlations significantly affects multi-aspect control. In this paper, we propose MAGIC, a new multi-aspect controllable text generation method with disentangled counterfactual augmentation. We alleviate the issue of imbalanced attribute correlations during training using counterfactual feature vectors in the attribute latent space by disentanglement. During inference, we enhance attribute correlations by target-guided counterfactual augmentation to further improve multi-aspect control. Experiments show that MAGIC outperforms state-of-the-art baselines in both imbalanced and balanced attribute correlation scenarios.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detox,
3328,"**Title**How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques

**Abstract**Recent advances in the development of large Pretrained Language Models, such as GPT, BERT and Bloom, have achieved remarkable performance on a wide range of different NLP tasks. However, when used for text generation tasks, these models still have limitations when it comes to controlling the content and style of the generated text, often producing content that is incorrect, irrelevant, or inappropriate in the context of a given task. In this survey paper, we explore methods for controllable text generation with a focus on sentiment control. We systematically collect papers from the ACL Anthology, create a categorisation scheme based on different control techniques and controlled attributes, and use the scheme to categorise and compare methods. The result is a detailed and comprehensive overview of state-of-the-art techniques for sentiment-controlled text generation categorised on the basis of how the control is implemented and what attributes are controlled and providing a clear idea of their relative strengths and weaknesses.","Lorandi, Michela, Belz, Anya",,,How to Control Sentiment in Text Generation: A Survey of the State-of-the-Art in Sentiment-Control Techniques,,,10.18653/v1/2023.wassa-1.30 , ,,"Recent advances in the development of large Pretrained Language Models, such as GPT, BERT and Bloom, have achieved remarkable performance on a wide range of different NLP tasks. However, when used for text generation tasks, these models still have limitations when it comes to controlling the content and style of the generated text, often producing content that is incorrect, irrelevant, or inappropriate in the context of a given task. In this survey paper, we explore methods for controllable text generation with a focus on sentiment control. We systematically collect papers from the ACL Anthology, create a categorisation scheme based on different control techniques and controlled attributes, and use the scheme to categorise and compare methods. The result is a detailed and comprehensive overview of state-of-the-art techniques for sentiment-controlled text generation categorised on the basis of how the control is implemented and what attributes are controlled and providing a clear idea of their relative strengths and weaknesses.",,,,, ,"  Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",,detox,
3329,"**Title**Extract, Select and Rewrite: A Modular Sentence Summarization Method

**Abstract**A modular approach has the advantage of being compositional and controllable, comparing to most end-to-end models. In this paper we propose Extract-Select-Rewrite (ESR), a three-phase abstractive sentence summarization method. We decompose summarization into three stages: (i) knowledge extraction, where we extract relation triples from the text using off-the-shelf tools; (ii) content selection, where a subset of triples are selected; and (iii) rewriting, where the selected triple are realized into natural language. Our results demonstrates that ESR is competitive with the best end-to-end models while being more faithful. {\%}than these baseline models. Being modular, ESR`s modules can be trained on separate data which is beneficial in low-resource settings and enhancing the style controllability on text generation.","Guan, Shuo, Padmakumar, Vishakh",,,"Extract, Select and Rewrite: A Modular Sentence Summarization Method",,,10.18653/v1/2023.newsum-1.4 , ,,"A modular approach has the advantage of being compositional and controllable, comparing to most end-to-end models. In this paper we propose Extract-Select-Rewrite (ESR), a three-phase abstractive sentence summarization method. We decompose summarization into three stages: (i) knowledge extraction, where we extract relation triples from the text using off-the-shelf tools; (ii) content selection, where a subset of triples are selected; and (iii) rewriting, where the selected triple are realized into natural language. Our results demonstrates that ESR is competitive with the best end-to-end models while being more faithful. {\%}than these baseline models. Being modular, ESR`s modules can be trained on separate data which is beneficial in low-resource settings and enhancing the style controllability on text generation.",,,,, ,  Proceedings of the 4th New Frontiers in Summarization Workshop,,out_of_scope,
3330,"**Title**Towards an Efficient Approach for Controllable Text Generation

**Abstract**Since the emergence of Transformers ar-
    chitecture, the Natural Language Genera-
    tion (NLG) field has advanced at break-
   neck  speed.    Large  language models
   (LLMs) have achieved remarkable results
    in the field of generative artificial intelli-
   gence (AI). Nevertheless, they also present
   some problems worth analysing: not only
    are they computationally non-viable  to
   academia, but they also have other issues,
   such us not generating text in a fully con-
    trollable way or the phenomenon known as
    hallucination. Because of this, the purpose
    of this paper is to outline and set the ideas
    for a new PhD thesis research. This PhD
    thesis will aim at advancing the state of
    the art by discovering new cost-effective,
    efficient and high-performing approaches
    to controlled text generation that could
   perform well in the different NLG tasks.
    Therefore, the main objective of this PhD
    thesis is to design a novel and efficient
    task-agnostic architecture that could obtain
    equivalent performance of LLMs, while
    generating text in a controllable way and
    including external commonsense knowl-
    edge.

1  Introduction

Natural  language  generation  (NLG)  field  is
the sub-field within natural language processing
(NLP) area that generates natural language to meet
a communicative goal (Reiter and Dale, 1997).

© 2023 The authors. This article is licensed under a Creative
Commons 4.0 licence, no derivative works, attribution, CC-
BY-ND. Traditionally, there was a more classical and global
 vision about the NLG architecture that implied
 to divide generation in three stages:  (1) macro-
 planning, (2) micro-planning and (3) surface re-
 alisation (Reiter and Dale, 1997).  Later, neural
 networks caused a new trend in NLG, involving
 what we know nowadays as generative artificial in-
 telligente (AI). Generative AI is a trend that en-
 compasses systems that are constructed applying
 machine learning algorithms (Sun et al., 2022).
 Whitin this trend, Transformers (Vaswani et al.,
 2017) have revolutionised the NLG field owing to
 the concept of attention. Several proposals based
 on Transformers have been made, being Large
 Language Models (LLMs) the ones which better
 performance have achieved in tasks such as text
 summarisation or machine-translation, among oth-
 ers (Wolf et al., 2020). Despite this, these mod-
 els present some issues worth commenting on. On
 the one hand, bests LLMs, such as GPT4 (esti-
 mated to have 1 trillion of parameters) (OpenAI,
 2023) or LLaMa (65 billions of parameters) (Tou-
 vron et al., 2023) have a huge amount of parame-
 ters in their neural networks, which is only avail-
 able to big companies, such as Google, due to the
 economic and temporary expense of training that
 models. On the other hand, these models do not
 generate text in a fully controlled way, leading to
 problems, such as hallucination or the lack of com-
 monsense, among others. In fact, hallucination oc-
 curs even in the most superior LLMs such as GPT4
 (Zhao et al., 2023). Figure 1 shows an example of
 hallucination in ChatGPT.
   Because of this, the purpose of this paper is to
 set up the ideas for a new PhD thesis in which
 we will study and present a novel architecture that

 1Tested in May, 2023

26","Mart{\'i}nez-Murillo, Iv{\'a}n, Moreda, Paloma, Lloret, Elena",,,Towards an Efficient Approach for Controllable Text Generation,,, , ,,"Since the emergence of Transformers ar-
    chitecture, the Natural Language Genera-
    tion (NLG) field has advanced at break-
   neck  speed.    Large  language models
   (LLMs) have achieved remarkable results
    in the field of generative artificial intelli-
   gence (AI). Nevertheless, they also present
   some problems worth analysing: not only
    are they computationally non-viable  to
   academia, but they also have other issues,
   such us not generating text in a fully con-
    trollable way or the phenomenon known as
    hallucination. Because of this, the purpose
    of this paper is to outline and set the ideas
    for a new PhD thesis research. This PhD
    thesis will aim at advancing the state of
    the art by discovering new cost-effective,
    efficient and high-performing approaches
    to controlled text generation that could
   perform well in the different NLG tasks.
    Therefore, the main objective of this PhD
    thesis is to design a novel and efficient
    task-agnostic architecture that could obtain
    equivalent performance of LLMs, while
    generating text in a controllable way and
    including external commonsense knowl-
    edge.

1  Introduction

Natural  language  generation  (NLG)  field  is
the sub-field within natural language processing
(NLP) area that generates natural language to meet
a communicative goal (Reiter and Dale, 1997).

© 2023 The authors. This article is licensed under a Creative
Commons 4.0 licence, no derivative works, attribution, CC-
BY-ND. Traditionally, there was a more classical and global
 vision about the NLG architecture that implied
 to divide generation in three stages:  (1) macro-
 planning, (2) micro-planning and (3) surface re-
 alisation (Reiter and Dale, 1997).  Later, neural
 networks caused a new trend in NLG, involving
 what we know nowadays as generative artificial in-
 telligente (AI). Generative AI is a trend that en-
 compasses systems that are constructed applying
 machine learning algorithms (Sun et al., 2022).
 Whitin this trend, Transformers (Vaswani et al.,
 2017) have revolutionised the NLG field owing to
 the concept of attention. Several proposals based
 on Transformers have been made, being Large
 Language Models (LLMs) the ones which better
 performance have achieved in tasks such as text
 summarisation or machine-translation, among oth-
 ers (Wolf et al., 2020). Despite this, these mod-
 els present some issues worth commenting on. On
 the one hand, bests LLMs, such as GPT4 (esti-
 mated to have 1 trillion of parameters) (OpenAI,
 2023) or LLaMa (65 billions of parameters) (Tou-
 vron et al., 2023) have a huge amount of parame-
 ters in their neural networks, which is only avail-
 able to big companies, such as Google, due to the
 economic and temporary expense of training that
 models. On the other hand, these models do not
 generate text in a fully controlled way, leading to
 problems, such as hallucination or the lack of com-
 monsense, among others. In fact, hallucination oc-
 curs even in the most superior LLMs such as GPT4
 (Zhao et al., 2023). Figure 1 shows an example of
 hallucination in ChatGPT.
   Because of this, the purpose of this paper is to
 set up the ideas for a new PhD thesis in which
 we will study and present a novel architecture that

 1Tested in May, 2023

26",,,,, ,"  Proceedings of the 1st International Workshop on Multilingual, Multimodal and Multitask Language Generation",,out_of_scope,
3331,"**Title**Generating Faithful Text From a Knowledge Graph with Noisy Reference Text

**Abstract**Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model`s ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model`s performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.","Hashem, Tahsina, Wang, Weiqing, Wijaya, Derry Tanti, Ali, Mohammed Eunus, Li, Yuan-Fang",,,Generating Faithful Text From a Knowledge Graph with Noisy Reference Text,,,10.18653/v1/2023.inlg-main.8 , ,,"Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model`s ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model`s performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.",,,,, ,  Proceedings of the 16th International Natural Language Generation Conference,,out_of_scope,
3332,"**Title**Validating Predictive Models Of Evaluative Language For Controllable {D}ata2{T}ext Generation

**Abstract**In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings. In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader`s expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.","Langner, Maurice, Klabunde, Ralf",,,Validating Predictive Models Of Evaluative Language For Controllable {D}ata2{T}ext Generation,,,10.18653/v1/2023.inlg-main.22 , ,,"In data2text generation, tabular data is transformed into a text that expresses information from that source domain. While some text types, such as instructions, demand objective and neutral language without any expressive and evaluative content, many other text types are expected to provide expressions for these kinds of subjective meanings. In controllable, pipelined neural NLG separate learning models, notably regression models, can be used to predict whether some feature deviates sufficiently strongly from an expected value, so that evaluative language would be appropriate for verbalizing this finding. In this paper, we present an empirical study on the comprehension of evaluative adverbs and adjectival modifiers in car reviews, a text type that is characterized by a mixture of factual information with evaluations expressing positive or negative surprise. We show to what extend regression-based decision boundaries for producing evaluative content in controllable data2text NLG match the reader`s expectations that are raised by those evaluative markers. Finally we show that regression values in combination with standard deviation of the technical input data constitute reasonable Boolean thresholds for both positive and negative surprise, which provide the basis for the development of more complex models that also include the scalar base of adverbs and modifiers.",,,,, ,  Proceedings of the 16th International Natural Language Generation Conference,,out_of_scope,
3333,"**Title**Harnessing the Plug-and-Play Controller by Prompting

**Abstract**Controllable text generation is a growing field within natural language generation (NLG) that focuses on producing text that meets specific constraints in real-world applications. Previous approaches, such as plug-and-play controllers (PPCs), aimed to steer the properties of generated text in a flexible manner. However, these methods often compromised the integrity of the language model`s decoding process, resulting in less smooth text generation.Alternatively, other techniques utilized multiple attribute prompts to align the generated text with desired attributes, but this approach required prompt design for each attribute and was dependent on the size of the language model. This paper introduces a novel method for flexible attribute control in text generation using pre-trained language models (PLMs). The proposed approach aims to enhance the fluency of generated text by guiding the generation process with PPCs. The key idea is to dynamically adjust the distribution of generated text by modifying prompts, effectively constraining the output space of the language model and influencing the desired attribute. To enable smooth cooperation between the PLM and the PPC, our work innovativel proposes a new model fine-tuning method: Reinforcement Learning with Dynamic Adjust Feedback (RLDAF).This fine-tuning process adapts a small subset of the language model`s parameters based on the generating actions taken during the PPC control process. The resulting harmonious collaboration between the PLM and PPC leads to improved smoothness in text generation during inference. Extensive experiments were conducted on the SST2 dataset, and the proposed method outperformed previous approaches in various evaluation metrics, including text fluency and attribute consistency.","Wang, Hao, Sha, Lei",,,Harnessing the Plug-and-Play Controller by Prompting,,, , ,,"Controllable text generation is a growing field within natural language generation (NLG) that focuses on producing text that meets specific constraints in real-world applications. Previous approaches, such as plug-and-play controllers (PPCs), aimed to steer the properties of generated text in a flexible manner. However, these methods often compromised the integrity of the language model`s decoding process, resulting in less smooth text generation.Alternatively, other techniques utilized multiple attribute prompts to align the generated text with desired attributes, but this approach required prompt design for each attribute and was dependent on the size of the language model. This paper introduces a novel method for flexible attribute control in text generation using pre-trained language models (PLMs). The proposed approach aims to enhance the fluency of generated text by guiding the generation process with PPCs. The key idea is to dynamically adjust the distribution of generated text by modifying prompts, effectively constraining the output space of the language model and influencing the desired attribute. To enable smooth cooperation between the PLM and the PPC, our work innovativel proposes a new model fine-tuning method: Reinforcement Learning with Dynamic Adjust Feedback (RLDAF).This fine-tuning process adapts a small subset of the language model`s parameters based on the generating actions taken during the PPC control process. The resulting harmonious collaboration between the PLM and PPC leads to improved smoothness in text generation during inference. Extensive experiments were conducted on the SST2 dataset, and the proposed method outperformed previous approaches in various evaluation metrics, including text fluency and attribute consistency.",,,,, ,"  Proceedings of the Third Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",,detox,
3334,"**Title**{M}ac{L}a{S}a: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space

**Abstract**Multi-aspect controllable text generation aims to generate fluent sentences that possess multiple desired attributes simultaneously. Traditional methods either require expensive iteration / searching within the discrete text space during the decoding stage, or train separate controllers for each aspect, resulting in a degradation of text quality due to the discrepancy between different aspects. To address these limitations, we introduce a novel approach for $\textbf{M}$ulti-$\textbf{a}$spect $\textbf{c}$ontrol, namely MacLaSa, that estimates compact $\textbf{La}$tent space for multiple aspects, and performs efficient $\textbf{Sa}$mpling with a fast sampler. To eliminate the domain discrepancies between different aspects, we first utilize a variational autoencoder (VAE) network to map text sequences from various data sources into close latent representations. The estimated latent space enables the formulation of joint energy-based models and the plugging in of arbitrary attribute discriminators to achieve multi-aspect control. Afterwards, we draw latent samples with a fast sampler based on ordinary differential equations and feed sampled examples to the VAE decoder to produce target text sequences. Experimental results demonstrate that MacLaSa outperforms strong baselines on both attribute relevance and textual quality while maintaining a high inference speed.","Ding, Hanxing, Pang, Liang, Wei, Zihao, Shen, Huawei, Cheng, Xueqi, Chua, Tat-Seng",,,{M}ac{L}a{S}a: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space,,,10.18653/v1/2023.findings-emnlp.292 , ,,"Multi-aspect controllable text generation aims to generate fluent sentences that possess multiple desired attributes simultaneously. Traditional methods either require expensive iteration / searching within the discrete text space during the decoding stage, or train separate controllers for each aspect, resulting in a degradation of text quality due to the discrepancy between different aspects. To address these limitations, we introduce a novel approach for $\textbf{M}$ulti-$\textbf{a}$spect $\textbf{c}$ontrol, namely MacLaSa, that estimates compact $\textbf{La}$tent space for multiple aspects, and performs efficient $\textbf{Sa}$mpling with a fast sampler. To eliminate the domain discrepancies between different aspects, we first utilize a variational autoencoder (VAE) network to map text sequences from various data sources into close latent representations. The estimated latent space enables the formulation of joint energy-based models and the plugging in of arbitrary attribute discriminators to achieve multi-aspect control. Afterwards, we draw latent samples with a fast sampler based on ordinary differential equations and feed sampled examples to the VAE decoder to produce target text sequences. Experimental results demonstrate that MacLaSa outperforms strong baselines on both attribute relevance and textual quality while maintaining a high inference speed.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,out_of_scope,
3335,"**Title**Uniform Complexity for Text Generation

**Abstract**Large language models (LLMs) have shown promising results in a wide array of generative NLP tasks, such as summarization and machine translation. In the context of narrative generation, however, existing models still do not capture factors that contribute to producing consistent text. For instance, it is logical that a piece of text or a story should be uniformly readable throughout and that this form of complexity should be controllable. As such, if the complexity of an input text prompt is rated first-grade reading level in the Flesch Reading Ease test, then the generated text continuing the plot should also be within this range of complexity. With this in mind, we introduce Uniform Complexity for Text Generation (UCTG), a new benchmark test which raises the challenge of making generative models observe uniform linguistic properties with respect to prompts. We experiment with over 150+ linguistically and cognitively motivated features for evaluating text complexity in humans and generative models. From our results, we find that models such as GPT-2 struggle to preserve the complexity of input prompts used in its generations, even if finetuned with professionally written texts.","Imperial, Joseph Marvin, Madabushi, Harish Tayyar",,,Uniform Complexity for Text Generation,,,10.18653/v1/2023.findings-emnlp.805 , ,,"Large language models (LLMs) have shown promising results in a wide array of generative NLP tasks, such as summarization and machine translation. In the context of narrative generation, however, existing models still do not capture factors that contribute to producing consistent text. For instance, it is logical that a piece of text or a story should be uniformly readable throughout and that this form of complexity should be controllable. As such, if the complexity of an input text prompt is rated first-grade reading level in the Flesch Reading Ease test, then the generated text continuing the plot should also be within this range of complexity. With this in mind, we introduce Uniform Complexity for Text Generation (UCTG), a new benchmark test which raises the challenge of making generative models observe uniform linguistic properties with respect to prompts. We experiment with over 150+ linguistically and cognitively motivated features for evaluating text complexity in humans and generative models. From our results, we find that models such as GPT-2 struggle to preserve the complexity of input prompts used in its generations, even if finetuned with professionally written texts.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,out_of_scope,
3336,"**Title**{GTA}: Gated Toxicity Avoidance for {LM} Performance Preservation

**Abstract**Caution: This paper includes offensive words that could potentially cause unpleasantness. The fast-paced evolution of generative language models such as GPT-4 has demonstrated outstanding results in various NLP generation tasks. However, due to the potential generation of offensive words related to race or gender, various Controllable Text Generation (CTG) methods have been proposed to mitigate the occurrence of harmful words. However, existing CTG methods not only reduce toxicity but also negatively impact several aspects of the language model`s generation performance, including topic consistency, grammar, and perplexity. This paper explores the limitations of previous methods and introduces a novel solution in the form of a simple Gated Toxicity Avoidance (GTA) that can be applied to any CTG method. We also evaluate the effectiveness of the proposed GTA by comparing it with state-of-the-art CTG methods across various datasets. Our findings reveal that gated toxicity avoidance efficiently achieves comparable levels of toxicity reduction to the original CTG methods while preserving the generation performance of the language model.","Kim, Heegyu, Cho, Hyunsouk",,,{GTA}: Gated Toxicity Avoidance for {LM} Performance Preservation,,,10.18653/v1/2023.findings-emnlp.983 , ,,"Caution: This paper includes offensive words that could potentially cause unpleasantness. The fast-paced evolution of generative language models such as GPT-4 has demonstrated outstanding results in various NLP generation tasks. However, due to the potential generation of offensive words related to race or gender, various Controllable Text Generation (CTG) methods have been proposed to mitigate the occurrence of harmful words. However, existing CTG methods not only reduce toxicity but also negatively impact several aspects of the language model`s generation performance, including topic consistency, grammar, and perplexity. This paper explores the limitations of previous methods and introduces a novel solution in the form of a simple Gated Toxicity Avoidance (GTA) that can be applied to any CTG method. We also evaluate the effectiveness of the proposed GTA by comparing it with state-of-the-art CTG methods across various datasets. Our findings reveal that gated toxicity avoidance efficiently achieves comparable levels of toxicity reduction to the original CTG methods while preserving the generation performance of the language model.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detox,
3337,"**Title**{GRACE}: Gradient-guided Controllable Retrieval for Augmenting Attribute-based Text Generation

**Abstract**Attribute-based generation methods are of growing significance in controlling the generation of large pre-trained language models (PLMs). Existing studies control the generation by (1) finetuning the model with attributes or (2) guiding the inference processing toward control signals while freezing the PLM. However, finetuning approaches infuse domain bias into generation, making it hard to generate out-of-domain texts. Besides, many methods guide the inference in its word-by-word generation, pushing the word probability to the target attributes, resulting in less fluent sentences. We argue that distilling controlling information from natural texts can produce fluent sentences while maintaining high controllability. In this paper, we propose \textbf{GRA}dient-guided \textbf{C}ontrollable r\textbf{E}trieval (GRACE), a retrieval-augmented generation framework to facilitate the generation of fluent sentences with high attribute relevance. GRACE memorizes the semantic and attribute information from unlabeled corpora and applies a controllable retrieval to obtain desired information. For the generation, we design techniques to eliminate the domain bias from the retrieval results and integrate it into the generation model. Additionally, we propose a gradient-guided generation scheme that iteratively steers generation toward higher attribute relevance. Experimental results and quantities of examples verify the effectiveness of our method.","Wen, Zhihua, Tian, Zhiliang, Huang, Zhen, Yang, Yuxin, Jian, Zexin, Wang, Changjian, Li, Dongsheng",,,{GRACE}: Gradient-guided Controllable Retrieval for Augmenting Attribute-based Text Generation,,,10.18653/v1/2023.findings-acl.530 , ,,"Attribute-based generation methods are of growing significance in controlling the generation of large pre-trained language models (PLMs). Existing studies control the generation by (1) finetuning the model with attributes or (2) guiding the inference processing toward control signals while freezing the PLM. However, finetuning approaches infuse domain bias into generation, making it hard to generate out-of-domain texts. Besides, many methods guide the inference in its word-by-word generation, pushing the word probability to the target attributes, resulting in less fluent sentences. We argue that distilling controlling information from natural texts can produce fluent sentences while maintaining high controllability. In this paper, we propose \textbf{GRA}dient-guided \textbf{C}ontrollable r\textbf{E}trieval (GRACE), a retrieval-augmented generation framework to facilitate the generation of fluent sentences with high attribute relevance. GRACE memorizes the semantic and attribute information from unlabeled corpora and applies a controllable retrieval to obtain desired information. For the generation, we design techniques to eliminate the domain bias from the retrieval results and integrate it into the generation model. Additionally, we propose a gradient-guided generation scheme that iteratively steers generation toward higher attribute relevance. Experimental results and quantities of examples verify the effectiveness of our method.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3338,"**Title**Generating Summaries with Controllable Readability Levels

**Abstract**Readability refers to how easily a reader can understand a written text. Several factors affect the readability level, such as the complexity of the text, its subject matter, and the reader`s background knowledge. Generating summaries based on different readability levels is critical for enabling knowledge consumption by diverse audiences. However, current text generation approaches lack refined control, resulting in texts that are not customized to readers' proficiency levels. In this work, we bridge this gap and study techniques to generate summaries at specified readability levels. Unlike previous methods that focus on a specific readability level (e.g., lay summarization), we generate summaries with fine-grained control over their readability. We develop three text generation techniques for controlling readability: (1) instruction-based readability control, (2) reinforcement learning to minimize the gap between requested and observed readability and (3) a decoding approach that uses lookahead to estimate the readability of upcoming decoding steps. We show that our generation methods significantly improve readability control on news summarization (CNN/DM dataset), as measured by various readability metrics and human judgement, establishing strong baselines for controllable readability in summarization.","Ribeiro, Leonardo F. R., Bansal, Mohit, Dreyer, Markus",,,Generating Summaries with Controllable Readability Levels,,,10.18653/v1/2023.emnlp-main.714 , ,,"Readability refers to how easily a reader can understand a written text. Several factors affect the readability level, such as the complexity of the text, its subject matter, and the reader`s background knowledge. Generating summaries based on different readability levels is critical for enabling knowledge consumption by diverse audiences. However, current text generation approaches lack refined control, resulting in texts that are not customized to readers' proficiency levels. In this work, we bridge this gap and study techniques to generate summaries at specified readability levels. Unlike previous methods that focus on a specific readability level (e.g., lay summarization), we generate summaries with fine-grained control over their readability. We develop three text generation techniques for controlling readability: (1) instruction-based readability control, (2) reinforcement learning to minimize the gap between requested and observed readability and (3) a decoding approach that uses lookahead to estimate the readability of upcoming decoding steps. We show that our generation methods significantly improve readability control on news summarization (CNN/DM dataset), as measured by various readability metrics and human judgement, establishing strong baselines for controllable readability in summarization.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3339,"**Title**{D}u{NST}: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation

**Abstract**Self-training (ST) has prospered again in language understanding by augmenting the fine-tuning of big pre-trained models when labeled data is insufficient. However, it remains challenging to incorporate ST into attribute-controllable language generation. Augmented only by self-generated pseudo text, generation models \textit{over-exploit} the previously learned text space and \textit{fail to explore} a larger one, suffering from a restricted generalization boundary and limited controllability. In this work, we propose DuNST, a novel ST framework to tackle these problems. DuNST jointly models text generation and classification as a dual process and further perturbs and escapes from the collapsed space by adding two kinds of flexible noise. In this way, our model could construct and utilize both pseudo text generated from given labels and pseudo labels predicted from available unlabeled text, which are gradually refined during the ST phase. We theoretically demonstrate that DuNST can be regarded as enhancing the exploration of the potentially larger real text space while maintaining exploitation, guaranteeing improved performance. Experiments on three controllable generation tasks show that DuNST significantly boosts control accuracy with comparable generation fluency and diversity against several strong baselines.","Feng, Yuxi, Yi, Xiaoyuan, Wang, Xiting, Lakshmanan, V.S., Laks, Xie, Xing",,,{D}u{NST}: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation,,,10.18653/v1/2023.acl-long.488 , ,,"Self-training (ST) has prospered again in language understanding by augmenting the fine-tuning of big pre-trained models when labeled data is insufficient. However, it remains challenging to incorporate ST into attribute-controllable language generation. Augmented only by self-generated pseudo text, generation models \textit{over-exploit} the previously learned text space and \textit{fail to explore} a larger one, suffering from a restricted generalization boundary and limited controllability. In this work, we propose DuNST, a novel ST framework to tackle these problems. DuNST jointly models text generation and classification as a dual process and further perturbs and escapes from the collapsed space by adding two kinds of flexible noise. In this way, our model could construct and utilize both pseudo text generated from given labels and pseudo labels predicted from available unlabeled text, which are gradually refined during the ST phase. We theoretically demonstrate that DuNST can be regarded as enhancing the exploration of the potentially larger real text space while maintaining exploitation, guaranteeing improved performance. Experiments on three controllable generation tasks show that DuNST significantly boosts control accuracy with comparable generation fluency and diversity against several strong baselines.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detox,
3340,"**Title**{NEUROSTRUCTURAL} {DECODING}: Neural Text Generation with Structural Constraints

**Abstract**Text generation often involves producing coherent and grammatically correct texts that also satisfy a given set of semantic constraints. While most approaches for conditional text generation have primarily focused on lexical constraints, they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints. We address this gap by introducing NeuroStructural Decoding, a new decoding algorithm that incorporates syntactic constraints to further improve the quality of the generated text. We build NeuroStructural Decoding on the NeuroLogic Decoding (Lu etal. 2021) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints. Our algorithm is powerful and scalable. It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object)during decoding by parsing the partial generations at each step. To this end, we adapt a dependency parser to generate parses for incomplete sentences. Our approach is evaluated on three different language generation tasks, and the results show improved performance in both lexical and syntactic metrics compared to previous methods. The results suggest this is a promising solution for integrating fine-grained controllable generation into the conventional beam search decoding.","Bastan, Mohaddeseh, Surdeanu, Mihai, Balasubramanian, Niranjan",,,{NEUROSTRUCTURAL} {DECODING}: Neural Text Generation with Structural Constraints,,,10.18653/v1/2023.acl-long.528 , ,,"Text generation often involves producing coherent and grammatically correct texts that also satisfy a given set of semantic constraints. While most approaches for conditional text generation have primarily focused on lexical constraints, they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints. We address this gap by introducing NeuroStructural Decoding, a new decoding algorithm that incorporates syntactic constraints to further improve the quality of the generated text. We build NeuroStructural Decoding on the NeuroLogic Decoding (Lu etal. 2021) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints. Our algorithm is powerful and scalable. It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object)during decoding by parsing the partial generations at each step. To this end, we adapt a dependency parser to generate parses for incomplete sentences. Our approach is evaluated on three different language generation tasks, and the results show improved performance in both lexical and syntactic metrics compared to previous methods. The results suggest this is a promising solution for integrating fine-grained controllable generation into the conventional beam search decoding.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3341,"**Title**An Investigation into the Effect of Control Tokens on Text Simplification

**Abstract**Recent work on text simplification has focused on the use of control tokens to further the state of the art. However, it is not easy to further improve without an in-depth comprehension of the mechanisms underlying control tokens. One unexplored factor is the tokenisation strategy, which we also explore. In this paper, we (1) reimplemented ACCESS, (2) explored the effects of varying control tokens, (3) tested the influences of different tokenisation strategies, and (4) demonstrated how separate control tokens affect performance. We show variations of performance in the four control tokens separately. We also uncover how the design of control tokens could influence the performance and propose some suggestions for designing control tokens, which also reaches into other controllable text generation tasks.","Li, Zihao, Shardlow, Matthew, Hassan, Saeed",,,An Investigation into the Effect of Control Tokens on Text Simplification,,,10.18653/v1/2022.tsar-1.14 , ,,"Recent work on text simplification has focused on the use of control tokens to further the state of the art. However, it is not easy to further improve without an in-depth comprehension of the mechanisms underlying control tokens. One unexplored factor is the tokenisation strategy, which we also explore. In this paper, we (1) reimplemented ACCESS, (2) explored the effects of varying control tokens, (3) tested the influences of different tokenisation strategies, and (4) demonstrated how separate control tokens affect performance. We show variations of performance in the four control tokens separately. We also uncover how the design of control tokens could influence the performance and propose some suggestions for designing control tokens, which also reaches into other controllable text generation tasks.",,,,, ,"  Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022)",,out_of_scope,
3342,"**Title**Graph-based Keyword Planning for Legal Clause Generation from Topics

**Abstract**Generating domain-specific content such as legal clauses based on minimal user-provided information can be of significant benefit in automating legal contract generation. In this paper, we propose a controllable graph-based mechanism that can generate legal clauses using only the topic or type of the legal clauses. Our pipeline consists of two stages involving a graph-based planner followed by a clause generator. The planner outlines the content of a legal clause as a sequence of keywords in the order of generic to more specific clause information based on the input topic using a controllable graph-based mechanism. The generation stage takes in a given plan and generates a clause. The pipeline consists of a graph-based planner followed by text generation. We illustrate the effectiveness of our proposed two-stage approach on a broad set of clause topics in contracts.","Joshi, Sagar, Balaji, Sumanth, Garimella, Aparna, Varma, Vasudeva",,,Graph-based Keyword Planning for Legal Clause Generation from Topics,,,10.18653/v1/2022.nllp-1.26 , ,,"Generating domain-specific content such as legal clauses based on minimal user-provided information can be of significant benefit in automating legal contract generation. In this paper, we propose a controllable graph-based mechanism that can generate legal clauses using only the topic or type of the legal clauses. Our pipeline consists of two stages involving a graph-based planner followed by a clause generator. The planner outlines the content of a legal clause as a sequence of keywords in the order of generic to more specific clause information based on the input topic using a controllable graph-based mechanism. The generation stage takes in a given plan and generates a clause. The pipeline consists of a graph-based planner followed by text generation. We illustrate the effectiveness of our proposed two-stage approach on a broad set of clause topics in contracts.",,,,, ,  Proceedings of the Natural Legal Language Processing Workshop 2022,,out_of_scope,
3343,"**Title**{N}euro{L}ogic A*esque Decoding: Constrained Text Generation with Lookahead Heuristics

**Abstract**The dominant paradigm for neural text generation is left-to-right decoding from autoregressive language models. Constrained or controllable generation under complex lexical constraints, however, requires foresight to plan ahead feasible future paths. Drawing inspiration from the $A^*$ search algorithm, we propose NeuroLogic A*esque, a decoding algorithm that incorporates heuristic estimates of future cost. We develop lookahead heuristics that are efficient for large-scale language models, making our method a drop-in replacement for common techniques such as beam search and top-$k$ sampling. To enable constrained generation, we build on NeuroLogic decoding (Lu et al., 2021), combining its flexibility in incorporating logical constraints with A*esque estimates of future constraint satisfaction. Our approach outperforms competitive baselines on five generation tasks, and achieves new state-of-the-art performance on table-to-text generation, constrained machine translation, and keyword-constrained generation. The improvements are particularly notable on tasks that require complex constraint satisfaction or in few-shot or zero-shot settings. NeuroLogic A*esque illustrates the power of decoding for improving and enabling new capabilities of large-scale language models.","Lu, Ximing, Welleck, Sean, West, Peter, Jiang, Liwei, Kasai, Jungo, Khashabi, Daniel, Le Bras, Ronan, Qin, Lianhui, Yu, Youngjae, Zellers, Rowan, Smith, Noah A., Choi, Yejin",,,{N}euro{L}ogic A*esque Decoding: Constrained Text Generation with Lookahead Heuristics,,,10.18653/v1/2022.naacl-main.57 , ,,"The dominant paradigm for neural text generation is left-to-right decoding from autoregressive language models. Constrained or controllable generation under complex lexical constraints, however, requires foresight to plan ahead feasible future paths. Drawing inspiration from the $A^*$ search algorithm, we propose NeuroLogic A*esque, a decoding algorithm that incorporates heuristic estimates of future cost. We develop lookahead heuristics that are efficient for large-scale language models, making our method a drop-in replacement for common techniques such as beam search and top-$k$ sampling. To enable constrained generation, we build on NeuroLogic decoding (Lu et al., 2021), combining its flexibility in incorporating logical constraints with A*esque estimates of future constraint satisfaction. Our approach outperforms competitive baselines on five generation tasks, and achieves new state-of-the-art performance on table-to-text generation, constrained machine translation, and keyword-constrained generation. The improvements are particularly notable on tasks that require complex constraint satisfaction or in few-shot or zero-shot settings. NeuroLogic A*esque illustrates the power of decoding for improving and enabling new capabilities of large-scale language models.",,,,, ,  Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,out_of_scope,
3344,"**Title**Falsesum: Generating Document-level {NLI} Examples for Recognizing Factual Inconsistency in Summarization

**Abstract**Neural abstractive summarization models are prone to generate summaries that are factually inconsistent with their source documents. Previous work has introduced the task of recognizing such factual inconsistency as a downstream application of natural language inference (NLI). However, state-of-the-art NLI models perform poorly in this context due to their inability to generalize to the target task. In this work, we show that NLI models can be effective for this task when the training data is augmented with high-quality task-oriented examples. We introduce Falsesum, a data generation pipeline leveraging a controllable text generation model to perturb human-annotated summaries, introducing varying types of factual inconsistencies. Unlike previously introduced document-level NLI datasets, our generated dataset contains examples that are diverse and inconsistent yet plausible. We show that models trained on a Falsesum-augmented NLI dataset improve the state-of-the-art performance across four benchmarks for detecting factual inconsistency in summarization.","Utama, Prasetya, Bambrick, Joshua, Moosavi, Nafise, Gurevych, Iryna",,,Falsesum: Generating Document-level {NLI} Examples for Recognizing Factual Inconsistency in Summarization,,,10.18653/v1/2022.naacl-main.199 , ,,"Neural abstractive summarization models are prone to generate summaries that are factually inconsistent with their source documents. Previous work has introduced the task of recognizing such factual inconsistency as a downstream application of natural language inference (NLI). However, state-of-the-art NLI models perform poorly in this context due to their inability to generalize to the target task. In this work, we show that NLI models can be effective for this task when the training data is augmented with high-quality task-oriented examples. We introduce Falsesum, a data generation pipeline leveraging a controllable text generation model to perturb human-annotated summaries, introducing varying types of factual inconsistencies. Unlike previously introduced document-level NLI datasets, our generated dataset contains examples that are diverse and inconsistent yet plausible. We show that models trained on a Falsesum-augmented NLI dataset improve the state-of-the-art performance across four benchmarks for detecting factual inconsistency in summarization.",,,,, ,  Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,out_of_scope,
3345,"**Title**Controllable Text Generation for All Ages: Evaluating a Plug-and-Play Approach to Age-Adapted Dialogue

**Abstract**To be trusted and perceived as natural and coherent, conversational systems must adapt to the language of their users. While personalized dialogue is a promising direction, controlling generation for fine-grained language features remains a challenge in this approach. A recent line of research showed the effectiveness of leveraging pre-trained language models toward adapting to a text`s topic or sentiment. In this study, we build on these approaches and focus on a higher-level dimension of language variation: speakers' age. We frame the task as a dialogue response generation, and test methods based on bag-of-words (BoW) and neural discriminators (Disc) to condition the output of GPT-2 and DialoGPT without altering the parameters of the language models. We show that Disc models achieve a higher degree of detectable control than BoW models based on automatic evaluation. In contrast, humans can partially detect age differences in BoW but not Disc responses. Since BoW responses are deemed better than Disc ones by humans, simple controllable methods thus appear to be a better tradeoff between adaptation and language quality. Our work confirms the challenges of adapting to higher-level dimensions of language variation. Moreover, it highlights the need to evaluate natural language generation thoroughly.","Jansen, Lennert, Laichter, {\v{S}}t{\v{e}}p{\'a}n Lars, Sinclair, Arabella, van der Goot, Margot, Fernandez, Raquel, Pezzelle, Sandro",,,Controllable Text Generation for All Ages: Evaluating a Plug-and-Play Approach to Age-Adapted Dialogue,,,10.18653/v1/2022.gem-1.14 , ,,"To be trusted and perceived as natural and coherent, conversational systems must adapt to the language of their users. While personalized dialogue is a promising direction, controlling generation for fine-grained language features remains a challenge in this approach. A recent line of research showed the effectiveness of leveraging pre-trained language models toward adapting to a text`s topic or sentiment. In this study, we build on these approaches and focus on a higher-level dimension of language variation: speakers' age. We frame the task as a dialogue response generation, and test methods based on bag-of-words (BoW) and neural discriminators (Disc) to condition the output of GPT-2 and DialoGPT without altering the parameters of the language models. We show that Disc models achieve a higher degree of detectable control than BoW models based on automatic evaluation. In contrast, humans can partially detect age differences in BoW but not Disc responses. Since BoW responses are deemed better than Disc ones by humans, simple controllable methods thus appear to be a better tradeoff between adaptation and language quality. Our work confirms the challenges of adapting to higher-level dimensions of language variation. Moreover, it highlights the need to evaluate natural language generation thoroughly.",,,,, ,"  Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",,out_of_scope,
3346,"**Title**{MR}e{D}: A Meta-Review Dataset for Structure-Controllable Text Generation

**Abstract**When directly using existing text generation datasets for controllable generation, we are facing the problem of not having the domain knowledge and thus the aspects that could be controlled are limited. A typical example is when using CNN/Daily Mail dataset for controllable text summarization, there is no guided information on the emphasis of summary sentences. A more useful text generator should leverage both the input text and the control signal to guide the generation, which can only be built with deep understanding of the domain knowledge. Motivated by this vision, our paper introduces a new text generation dataset, named MReD. Our new dataset consists of 7,089 meta-reviews and all its 45k meta-review sentences are manually annotated with one of the 9 carefully defined categories, including abstract, strength, decision, etc. We present experimental results on start-of-the-art summarization models, and propose methods for structure-controlled generation with both extractive and abstractive models using our annotated data. By exploring various settings and analyzing the model behavior with respect to the control signal, we demonstrate the challenges of our proposed task and the values of our dataset MReD. Meanwhile, MReD also allows us to have a better understanding of the meta-review domain.","Shen, Chenhui, Cheng, Liying, Zhou, Ran, Bing, Lidong, You, Yang, Si, Luo",,,{MR}e{D}: A Meta-Review Dataset for Structure-Controllable Text Generation,,,10.18653/v1/2022.findings-acl.198 , ,,"When directly using existing text generation datasets for controllable generation, we are facing the problem of not having the domain knowledge and thus the aspects that could be controlled are limited. A typical example is when using CNN/Daily Mail dataset for controllable text summarization, there is no guided information on the emphasis of summary sentences. A more useful text generator should leverage both the input text and the control signal to guide the generation, which can only be built with deep understanding of the domain knowledge. Motivated by this vision, our paper introduces a new text generation dataset, named MReD. Our new dataset consists of 7,089 meta-reviews and all its 45k meta-review sentences are manually annotated with one of the 9 carefully defined categories, including abstract, strength, decision, etc. We present experimental results on start-of-the-art summarization models, and propose methods for structure-controlled generation with both extractive and abstractive models using our annotated data. By exploring various settings and analyzing the model behavior with respect to the control signal, we demonstrate the challenges of our proposed task and the values of our dataset MReD. Meanwhile, MReD also allows us to have a better understanding of the meta-review domain.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2022,,out_of_scope,
3347,"**Title**{B}eam{R}: Beam Reweighing with Attribute Discriminators for Controllable Text Generation

**Abstract**Recent advances in natural language processing have led to the availability of large pre-trained language models (LMs), with rich generative capabilities. Although these models are able to produce fluent and coherent text, it remains a challenge to control various attributes of the generation, including sentiment, formality, topic and many others. We propose a Beam Reweighing (BeamR) method, building on top of standard beam search, in order to control different attributes. BeamR combines any generative LM with any attribute discriminator, offering full flexibility of generation style and attribute, while the beam search backbone maintains fluency across different domains. Notably, BeamR allows practitioners to leverage pre-trained models without the need to train generative LMs together with discriminators. We evaluate BeamR in two diverse tasks: sentiment steering, and machine translation formality. Our results show that BeamR performs on par with or better than existing state-of-the-art approaches (including fine-tuned methods), and highlight the flexiblity of BeamR in both causal and seq2seq language modeling tasks.","Landsman, David, Chen, Jerry Zikun, Zaidi, Hussain",,,{B}eam{R}: Beam Reweighing with Attribute Discriminators for Controllable Text Generation,,,10.18653/v1/2022.findings-aacl.40 , ,,"Recent advances in natural language processing have led to the availability of large pre-trained language models (LMs), with rich generative capabilities. Although these models are able to produce fluent and coherent text, it remains a challenge to control various attributes of the generation, including sentiment, formality, topic and many others. We propose a Beam Reweighing (BeamR) method, building on top of standard beam search, in order to control different attributes. BeamR combines any generative LM with any attribute discriminator, offering full flexibility of generation style and attribute, while the beam search backbone maintains fluency across different domains. Notably, BeamR allows practitioners to leverage pre-trained models without the need to train generative LMs together with discriminators. We evaluate BeamR in two diverse tasks: sentiment steering, and machine translation formality. Our results show that BeamR performs on par with or better than existing state-of-the-art approaches (including fine-tuned methods), and highlight the flexiblity of BeamR in both causal and seq2seq language modeling tasks.",,,,, ,  Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022,,detox,
3348,"**Title**{D}is{C}up: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation

**Abstract**Prompt learning with immensely large Casual Language Models (CLMs) has been shown promising for attribute-controllable text generation (CTG). However, vanilla prompt tuning tends to imitate training corpus characteristics beyond the control attributes, resulting in a poor generalization ability. Moreover, it is less able to capture the relationship between different attributes, further limiting the control performance. In this paper, we propose a new CTG approach, namely DisCup, which incorporates the attribute knowledge of discriminator to optimize the control-prompts, steering a frozen CLM to produce attribute-specific texts. Specifically, the frozen CLM model, capable of producing multitudinous texts, is first used to generate the next-token candidates based on the context, so as to ensure the diversity of tokens to be predicted. Then, we leverage an attribute-discriminator to select desired/undesired tokens from those candidates, providing the inter-attribute knowledge. Finally, we bridge the above two traits by an unlikelihood objective for prompt-tuning. Extensive experimental results show that DisCup can achieve a new state-of-the-art control performance while maintaining an efficient and high-quality text generation, only relying on around 10 virtual tokens.","Zhang, Hanqing, Song, Dawei",,,{D}is{C}up: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation,,,10.18653/v1/2022.emnlp-main.223 , ,,"Prompt learning with immensely large Casual Language Models (CLMs) has been shown promising for attribute-controllable text generation (CTG). However, vanilla prompt tuning tends to imitate training corpus characteristics beyond the control attributes, resulting in a poor generalization ability. Moreover, it is less able to capture the relationship between different attributes, further limiting the control performance. In this paper, we propose a new CTG approach, namely DisCup, which incorporates the attribute knowledge of discriminator to optimize the control-prompts, steering a frozen CLM to produce attribute-specific texts. Specifically, the frozen CLM model, capable of producing multitudinous texts, is first used to generate the next-token candidates based on the context, so as to ensure the diversity of tokens to be predicted. Then, we leverage an attribute-discriminator to select desired/undesired tokens from those candidates, providing the inter-attribute knowledge. Finally, we bridge the above two traits by an unlikelihood objective for prompt-tuning. Extensive experimental results show that DisCup can achieve a new state-of-the-art control performance while maintaining an efficient and high-quality text generation, only relying on around 10 virtual tokens.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3349,"**Title**{S}ent{BS}: Sentence-level Beam Search for Controllable Summarization

**Abstract**A wide range of control perspectives have been explored in controllable text generation. Structure-controlled summarization is recently proposed as a useful and interesting research direction. However, current structure-controlling methods have limited effectiveness in enforcing the desired structure. To address this limitation, we propose a sentence-level beam search generation method (SentBS), where evaluation is conducted throughout the generation process to select suitable sentences for subsequent generations. We experiment with different combinations of decoding methods to be used as sub-components by SentBS and evaluate results on the structure-controlled dataset MReD. Experiments show that all explored combinations for SentBS can improve the agreement between the generated text and the desired structure, with the best method significantly reducing the structural discrepancies suffered by the existing model, by approximately 68{\%}.","Shen, Chenhui, Cheng, Liying, Bing, Lidong, You, Yang, Si, Luo",,,{S}ent{BS}: Sentence-level Beam Search for Controllable Summarization,,,10.18653/v1/2022.emnlp-main.699 , ,,"A wide range of control perspectives have been explored in controllable text generation. Structure-controlled summarization is recently proposed as a useful and interesting research direction. However, current structure-controlling methods have limited effectiveness in enforcing the desired structure. To address this limitation, we propose a sentence-level beam search generation method (SentBS), where evaluation is conducted throughout the generation process to select suitable sentences for subsequent generations. We experiment with different combinations of decoding methods to be used as sub-components by SentBS and evaluate results on the structure-controlled dataset MReD. Experiments show that all explored combinations for SentBS can improve the agreement between the generated text and the desired structure, with the best method significantly reducing the structural discrepancies suffered by the existing model, by approximately 68{\%}.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3350,"**Title**{T}ext{B}ox 2.0: A Text Generation Library with Pre-trained Language Models

**Abstract**To facilitate research on text generation, this paper presents a comprehensive and unified library, TextBox 2.0, focusing on the use of pre-trained language models (PLMs). To be comprehensive, our library covers 13 common text generation tasks and their corresponding 83 datasets and further incorporates 45 PLMs covering general, translation, Chinese, dialogue, controllable, distilled, prompting, and lightweight PLMs. We also implement 4 efficient training strategies and provide 4 generation objectives for pre-training new PLMs from scratch. To be unified, we design the interfaces to support the entire research pipeline (from data loading to training and evaluation), ensuring that each step can be fulfilled in a unified way. Despite the rich functionality, it is easy to use our library, either through the friendly Python API or command line. To validate the effectiveness of our library, we conduct extensive experiments and exemplify four types of research scenarios. The project is released at the link: \url{https://github.com/RUCAIBox/TextBox#2.0}.","Tang, Tianyi, Li, Junyi, Chen, Zhipeng, Hu, Yiwen, Yu, Zhuohao, Dai, Wenxun, Zhao, Wayne Xin, Nie, Jian-yun, Wen, Ji-rong",,,{T}ext{B}ox 2.0: A Text Generation Library with Pre-trained Language Models,,,10.18653/v1/2022.emnlp-demos.42 , ,,"To facilitate research on text generation, this paper presents a comprehensive and unified library, TextBox 2.0, focusing on the use of pre-trained language models (PLMs). To be comprehensive, our library covers 13 common text generation tasks and their corresponding 83 datasets and further incorporates 45 PLMs covering general, translation, Chinese, dialogue, controllable, distilled, prompting, and lightweight PLMs. We also implement 4 efficient training strategies and provide 4 generation objectives for pre-training new PLMs from scratch. To be unified, we design the interfaces to support the entire research pipeline (from data loading to training and evaluation), ensuring that each step can be fulfilled in a unified way. Despite the rich functionality, it is easy to use our library, either through the friendly Python API or command line. To validate the effectiveness of our library, we conduct extensive experiments and exemplify four types of research scenarios. The project is released at the link: \url{https://github.com/RUCAIBox/TextBox#2.0}.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,,out_of_scope,
3351,"**Title**{S}tyle{PTB}: A Compositional Benchmark for Fine-grained Controllable Text Style Transfer

**Abstract**Text style transfer aims to controllably generate text with targeted stylistic changes while maintaining core meaning from the source sentence constant. Many of the existing style transfer benchmarks primarily focus on individual high-level semantic changes (e.g. positive to negative), which enable controllability at a high level but do not offer fine-grained control involving sentence structure, emphasis, and content of the sentence. In this paper, we introduce a large-scale benchmark, StylePTB, with (1) paired sentences undergoing 21 fine-grained stylistic changes spanning atomic lexical, syntactic, semantic, and thematic transfers of text, as well as (2) compositions of multiple transfers which allow modeling of fine-grained stylistic changes as building blocks for more complex, high-level transfers. By benchmarking existing methods on StylePTB, we find that they struggle to model fine-grained changes and have an even more difficult time composing multiple styles. As a result, StylePTB brings novel challenges that we hope will encourage future research in controllable text style transfer, compositional models, and learning disentangled representations. Solving these challenges would present important steps towards controllable text generation.","Lyu, Yiwei, Liang, Paul Pu, Pham, Hai, Hovy, Eduard, P{\'o}czos, Barnab{\'a}s, Salakhutdinov, Ruslan, Morency, Louis-Philippe",,,{S}tyle{PTB}: A Compositional Benchmark for Fine-grained Controllable Text Style Transfer,,,10.18653/v1/2021.naacl-main.171 , ,,"Text style transfer aims to controllably generate text with targeted stylistic changes while maintaining core meaning from the source sentence constant. Many of the existing style transfer benchmarks primarily focus on individual high-level semantic changes (e.g. positive to negative), which enable controllability at a high level but do not offer fine-grained control involving sentence structure, emphasis, and content of the sentence. In this paper, we introduce a large-scale benchmark, StylePTB, with (1) paired sentences undergoing 21 fine-grained stylistic changes spanning atomic lexical, syntactic, semantic, and thematic transfers of text, as well as (2) compositions of multiple transfers which allow modeling of fine-grained stylistic changes as building blocks for more complex, high-level transfers. By benchmarking existing methods on StylePTB, we find that they struggle to model fine-grained changes and have an even more difficult time composing multiple styles. As a result, StylePTB brings novel challenges that we hope will encourage future research in controllable text style transfer, compositional models, and learning disentangled representations. Solving these challenges would present important steps towards controllable text generation.",,,,, ,  Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,detox,
3352,"**Title**{N}euro{L}ogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints

**Abstract**Conditional text generation often requires lexical constraints, i.e., which words should or shouldn`t be included in the output text. While the dominant recipe for conditional text generation has been large-scale pretrained language models that are finetuned on the task-specific training data, such models do not learn to follow the underlying constraints reliably, even when supervised with large amounts of task-specific examples. We propose NeuroLogic Decoding, a simple yet effective algorithm that enables neural language models {--} supervised or not {--} to generate fluent text while satisfying complex lexical constraints. Our approach is powerful yet efficient. It handles any set of lexical constraints that is expressible under predicate logic, while its asymptotic runtime is equivalent to conventional beam search. Empirical results on four benchmarks show that NeuroLogic Decoding outperforms previous approaches, including algorithms that handle a subset of our constraints. Moreover, we find that unsupervised models with NeuroLogic Decoding often outperform supervised models with conventional decoding, even when the latter is based on considerably larger networks. Our results suggest the limit of large-scale neural networks for fine-grained controllable generation and the promise of inference-time algorithms.","Lu, Ximing, West, Peter, Zellers, Rowan, Le Bras, Ronan, Bhagavatula, Chandra, Choi, Yejin",,,{N}euro{L}ogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints,,,10.18653/v1/2021.naacl-main.339 , ,,"Conditional text generation often requires lexical constraints, i.e., which words should or shouldn`t be included in the output text. While the dominant recipe for conditional text generation has been large-scale pretrained language models that are finetuned on the task-specific training data, such models do not learn to follow the underlying constraints reliably, even when supervised with large amounts of task-specific examples. We propose NeuroLogic Decoding, a simple yet effective algorithm that enables neural language models {--} supervised or not {--} to generate fluent text while satisfying complex lexical constraints. Our approach is powerful yet efficient. It handles any set of lexical constraints that is expressible under predicate logic, while its asymptotic runtime is equivalent to conventional beam search. Empirical results on four benchmarks show that NeuroLogic Decoding outperforms previous approaches, including algorithms that handle a subset of our constraints. Moreover, we find that unsupervised models with NeuroLogic Decoding often outperform supervised models with conventional decoding, even when the latter is based on considerably larger networks. Our results suggest the limit of large-scale neural networks for fine-grained controllable generation and the promise of inference-time algorithms.",,,,, ,  Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,out_of_scope,
3353,"**Title**{ENTRUST}: Argument Reframing with Language Models and Entailment

**Abstract**Framing involves the positive or negative presentation of an argument or issue depending on the audience and goal of the speaker. Differences in lexical framing, the focus of our work, can have large effects on peoples' opinions and beliefs. To make progress towards reframing arguments for positive effects, we create a dataset and method for this task. We use a lexical resource for {\textquotedblleft}connotations{\textquotedblright} to create a parallel corpus and propose a method for argument reframing that combines controllable text generation (positive connotation) with a post-decoding entailment component (same denotation). Our results show that our method is effective compared to strong baselines along the dimensions of fluency, meaning, and trustworthiness/reduction of fear.","Chakrabarty, Tuhin, Hidey, Christopher, Muresan, Smaranda",,,{ENTRUST}: Argument Reframing with Language Models and Entailment,,,10.18653/v1/2021.naacl-main.394 , ,,"Framing involves the positive or negative presentation of an argument or issue depending on the audience and goal of the speaker. Differences in lexical framing, the focus of our work, can have large effects on peoples' opinions and beliefs. To make progress towards reframing arguments for positive effects, we create a dataset and method for this task. We use a lexical resource for {\textquotedblleft}connotations{\textquotedblright} to create a parallel corpus and propose a method for argument reframing that combines controllable text generation (positive connotation) with a post-decoding entailment component (same denotation). Our results show that our method is effective compared to strong baselines along the dimensions of fluency, meaning, and trustworthiness/reduction of fear.",,,,, ,  Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,out_of_scope,
3354,"**Title**Data-to-text Generation by Splicing Together Nearest Neighbors

**Abstract**We propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from {\textquotedblleft}neighbor{\textquotedblright} source-target pairs. Unlike recent work that conditions on retrieved neighbors but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text, by inserting or replacing them in partially constructed generations. Standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted context-free grammar. We find that policies learned in this way perform on par with strong baselines in terms of automatic and human evaluation, but allow for more interpretable and controllable generation.","Wiseman, Sam, Backurs, Arturs, Stratos, Karl",,,Data-to-text Generation by Splicing Together Nearest Neighbors,,,10.18653/v1/2021.emnlp-main.352 , ,,"We propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from {\textquotedblleft}neighbor{\textquotedblright} source-target pairs. Unlike recent work that conditions on retrieved neighbors but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text, by inserting or replacing them in partially constructed generations. Standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted context-free grammar. We find that policies learned in this way perform on par with strong baselines in terms of automatic and human evaluation, but allow for more interpretable and controllable generation.",,,,, ,  Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3355,"**Title**{DE}xperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts

**Abstract**Despite recent advances in natural language generation, it remains challenging to control attributes of generated text. We propose DExperts: Decoding-time Experts, a decoding-time method for controlled text generation that combines a pretrained language model with {\textquotedblleft}expert{\textquotedblright} LMs and/or {\textquotedblleft}anti-expert{\textquotedblright} LMs in a product of experts. Intuitively, under the ensemble, tokens only get high probability if they are considered likely by the experts, and unlikely by the anti-experts. We apply DExperts to language detoxification and sentiment-controlled generation, where we outperform existing controllable generation methods on both automatic and human evaluations. Moreover, because DExperts operates only on the output of the pretrained LM, it is effective with (anti-)experts of smaller size, including when operating on GPT-3. Our work highlights the promise of tuning small LMs on text with (un)desirable attributes for efficient decoding-time steering.","Liu, Alisa, Sap, Maarten, Lu, Ximing, Swayamdipta, Swabha, Bhagavatula, Chandra, Smith, Noah A., Choi, Yejin",,,{DE}xperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts,,,10.18653/v1/2021.acl-long.522 , ,,"Despite recent advances in natural language generation, it remains challenging to control attributes of generated text. We propose DExperts: Decoding-time Experts, a decoding-time method for controlled text generation that combines a pretrained language model with {\textquotedblleft}expert{\textquotedblright} LMs and/or {\textquotedblleft}anti-expert{\textquotedblright} LMs in a product of experts. Intuitively, under the ensemble, tokens only get high probability if they are considered likely by the experts, and unlikely by the anti-experts. We apply DExperts to language detoxification and sentiment-controlled generation, where we outperform existing controllable generation methods on both automatic and human evaluations. Moreover, because DExperts operates only on the output of the pretrained LM, it is effective with (anti-)experts of smaller size, including when operating on GPT-3. Our work highlights the promise of tuning small LMs on text with (un)desirable attributes for efficient decoding-time steering.",,,,, ,  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,detox,
3356,"**Title**Viable Threat on News Reading: Generating Biased News Using Natural Language Models

**Abstract**Recent advancements in natural language generation has raised serious concerns. High-performance language models are widely used for language generation tasks because they are able to produce fluent and meaningful sentences. These models are already being used to create fake news. They can also be exploited to generate biased news, which can then be used to attack news aggregators to change their reader`s behavior and influence their bias. In this paper, we use a threat model to demonstrate that the publicly available language models can reliably generate biased news content based on an input original news. We also show that a large number of high-quality biased news articles can be generated using controllable text generation. A subjective evaluation with 80 participants demonstrated that the generated biased news is generally fluent, and a bias evaluation with 24 participants demonstrated that the bias (left or right) is usually evident in the generated articles and can be easily identified.","Gupta, Saurabh, Nguyen, Hong Huy, Yamagishi, Junichi, Echizen, Isao",,,Viable Threat on News Reading: Generating Biased News Using Natural Language Models,,,10.18653/v1/2020.nlpcss-1.7 , ,,"Recent advancements in natural language generation has raised serious concerns. High-performance language models are widely used for language generation tasks because they are able to produce fluent and meaningful sentences. These models are already being used to create fake news. They can also be exploited to generate biased news, which can then be used to attack news aggregators to change their reader`s behavior and influence their bias. In this paper, we use a threat model to demonstrate that the publicly available language models can reliably generate biased news content based on an input original news. We also show that a large number of high-quality biased news articles can be generated using controllable text generation. A subjective evaluation with 80 participants demonstrated that the generated biased news is generally fluent, and a bias evaluation with 24 participants demonstrated that the bias (left or right) is usually evident in the generated articles and can be easily identified.",,,,, ,  Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science,,out_of_scope,
3357,"**Title**Controlled Hallucinations: Learning to Generate Faithfully from Noisy Data

**Abstract**Neural text generation (data- or text-to-text) demonstrates remarkable performance when training data is abundant which for many applications is not the case. To collect a large corpus of parallel data, heuristic rules are often used but they inevitably let noise into the data, such as phrases in the output which cannot be explained by the input. Consequently, models pick up on the noise and may hallucinate{--}generate fluent but unsupported text. Our contribution is a simple but powerful technique to treat such hallucinations as a controllable aspect of the generated text, without dismissing any input and without modifying the model architecture. On the WikiBio corpus (Lebret et al., 2016), a particularly noisy dataset, we demonstrate the efficacy of the technique both in an automatic and in a human evaluation.","Filippova, Katja",,,Controlled Hallucinations: Learning to Generate Faithfully from Noisy Data,,,10.18653/v1/2020.findings-emnlp.76 , ,,"Neural text generation (data- or text-to-text) demonstrates remarkable performance when training data is abundant which for many applications is not the case. To collect a large corpus of parallel data, heuristic rules are often used but they inevitably let noise into the data, such as phrases in the output which cannot be explained by the input. Consequently, models pick up on the noise and may hallucinate{--}generate fluent but unsupported text. Our contribution is a simple but powerful technique to treat such hallucinations as a controllable aspect of the generated text, without dismissing any input and without modifying the model architecture. On the WikiBio corpus (Lebret et al., 2016), a particularly noisy dataset, we demonstrate the efficacy of the technique both in an automatic and in a human evaluation.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2020,,out_of_scope,
3358,"**Title**Language Generation via Combinatorial Constraint Satisfaction: A Tree Search Enhanced {M}onte-{C}arlo Approach

**Abstract**Generating natural language under complex constraints is a principled formulation towards controllable text generation. We present a framework to allow specification of combinatorial constraints for sentence generation. We propose TSMC, an efficient method to generate high likelihood sentences with respect to a pre-trained language model while satisfying the constraints. Our approach is highly flexible, requires no task-specific train- ing, and leverages efficient constraint satisfaction solving techniques. To better handle the combinatorial constraints, a tree search algorithm is embedded into the proposal process of the Markov Chain Monte Carlo (MCMC) to explore candidates that satisfy more constraints. Compared to existing MCMC approaches, our sampling approach has a better mixing performance. Experiments show that TSMC achieves consistent and significant improvement on multiple language generation tasks.","Zhang, Maosen, Jiang, Nan, Li, Lei, Xue, Yexiang",,,Language Generation via Combinatorial Constraint Satisfaction: A Tree Search Enhanced {M}onte-{C}arlo Approach,,,10.18653/v1/2020.findings-emnlp.115 , ,,"Generating natural language under complex constraints is a principled formulation towards controllable text generation. We present a framework to allow specification of combinatorial constraints for sentence generation. We propose TSMC, an efficient method to generate high likelihood sentences with respect to a pre-trained language model while satisfying the constraints. Our approach is highly flexible, requires no task-specific train- ing, and leverages efficient constraint satisfaction solving techniques. To better handle the combinatorial constraints, a tree search algorithm is embedded into the proposal process of the Markov Chain Monte Carlo (MCMC) to explore candidates that satisfy more constraints. Compared to existing MCMC approaches, our sampling approach has a better mixing performance. Experiments show that TSMC achieves consistent and significant improvement on multiple language generation tasks.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2020,,out_of_scope,
3359,"**Title**{R}eal{T}oxicity{P}rompts: Evaluating Neural Toxic Degeneration in Language Models

**Abstract**Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning {\textquotedblleft}bad{\textquotedblright} words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.","Gehman, Samuel, Gururangan, Suchin, Sap, Maarten, Choi, Yejin, Smith, Noah A.",,,{R}eal{T}oxicity{P}rompts: Evaluating Neural Toxic Degeneration in Language Models,,,10.18653/v1/2020.findings-emnlp.301 , ,,"Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning {\textquotedblleft}bad{\textquotedblright} words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2020,,Gen_dataset#detection,
3360,"**Title**{MEGATRON}-{CNTRL}: Controllable Story Generation with External Knowledge Using Large-Scale Language Models

**Abstract**Existing pre-trained large language models have shown unparalleled generative capabilities. However, they are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a knowledge retriever, a contextual knowledge ranker, and a conditional text generator. As we do not have access to ground-truth supervision for the knowledge ranker, we make use of weak supervision from sentence embedding. The empirical results show that our model generates more fluent, consistent, and coherent stories with less repetition and higher diversity compared to prior work on the ROC story dataset. We showcase the controllability of our model by replacing the keywords used to generate stories and re-running the generation process. Human evaluation results show that 77.5{\%} of these stories are successfully controlled by the new keywords. Furthermore, by scaling our model from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the quality of generation (from 74.5{\%} to 93.0{\%} for consistency) and controllability (from 77.5{\%} to 91.5{\%}).","Xu, Peng, Patwary, Mostofa, Shoeybi, Mohammad, Puri, Raul, Fung, Pascale, Anandkumar, Anima, Catanzaro, Bryan",,,{MEGATRON}-{CNTRL}: Controllable Story Generation with External Knowledge Using Large-Scale Language Models,,,10.18653/v1/2020.emnlp-main.226 , ,,"Existing pre-trained large language models have shown unparalleled generative capabilities. However, they are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a knowledge retriever, a contextual knowledge ranker, and a conditional text generator. As we do not have access to ground-truth supervision for the knowledge ranker, we make use of weak supervision from sentence embedding. The empirical results show that our model generates more fluent, consistent, and coherent stories with less repetition and higher diversity compared to prior work on the ROC story dataset. We showcase the controllability of our model by replacing the keywords used to generate stories and re-running the generation process. Human evaluation results show that 77.5{\%} of these stories are successfully controlled by the new keywords. Furthermore, by scaling our model from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the quality of generation (from 74.5{\%} to 93.0{\%} for consistency) and controllability (from 77.5{\%} to 91.5{\%}).",,,,, ,  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),,out_of_scope,
3361,"**Title**{CAT}-Gen: Improving Robustness in {NLP} Models via Controlled Adversarial Text Generation

**Abstract**NLP models are shown to suffer from robustness issues, i.e., a model`s prediction can be easily changed under small perturbations to the input. In this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model that, given an input text, generates adversarial texts through controllable attributes that are known to be invariant to task labels. For example, in order to attack a model for sentiment classification over product reviews, we can use the product categories as the controllable attribute which would not change the sentiment of the reviews. Experiments on real-world NLP datasets demonstrate that our method can generate more diverse and fluent adversarial texts, compared to many existing adversarial text generation approaches. We further use our generated adversarial examples to improve models through adversarial training, and we demonstrate that our generated attacks are more robust against model re-training and different model architectures.","Wang, Tianlu, Wang, Xuezhi, Qin, Yao, Packer, Ben, Li, Kang, Chen, Jilin, Beutel, Alex, Chi, Ed",,,{CAT}-Gen: Improving Robustness in {NLP} Models via Controlled Adversarial Text Generation,,,10.18653/v1/2020.emnlp-main.417 , ,,"NLP models are shown to suffer from robustness issues, i.e., a model`s prediction can be easily changed under small perturbations to the input. In this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model that, given an input text, generates adversarial texts through controllable attributes that are known to be invariant to task labels. For example, in order to attack a model for sentiment classification over product reviews, we can use the product categories as the controllable attribute which would not change the sentiment of the reviews. Experiments on real-world NLP datasets demonstrate that our method can generate more diverse and fluent adversarial texts, compared to many existing adversarial text generation approaches. We further use our generated adversarial examples to improve models through adversarial training, and we demonstrate that our generated attacks are more robust against model re-training and different model architectures.",,,,, ,  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),,out_of_scope,
3362,"**Title**What makes a good conversation? How controllable attributes affect human judgments

**Abstract**A good conversation requires balance {--} between simplicity and detail; staying on topic and changing it; asking questions and answering them. Although dialogue agents are commonly evaluated via human judgments of overall quality, the relationship between quality and these individual factors is less well-studied. In this work, we examine two controllable neural text generation methods, conditional training and weighted decoding, in order to control four important attributes for chit-chat dialogue: repetition, specificity, response-relatedness and question-asking. We conduct a large-scale human evaluation to measure the effect of these control parameters on multi-turn interactive conversations on the PersonaChat task. We provide a detailed analysis of their relationship to high-level aspects of conversation, and show that by controlling combinations of these variables our models obtain clear improvements in human quality judgments.","See, Abigail, Roller, Stephen, Kiela, Douwe, Weston, Jason",,,What makes a good conversation? How controllable attributes affect human judgments,,,10.18653/v1/N19-1170 , ,,"A good conversation requires balance {--} between simplicity and detail; staying on topic and changing it; asking questions and answering them. Although dialogue agents are commonly evaluated via human judgments of overall quality, the relationship between quality and these individual factors is less well-studied. In this work, we examine two controllable neural text generation methods, conditional training and weighted decoding, in order to control four important attributes for chit-chat dialogue: repetition, specificity, response-relatedness and question-asking. We conduct a large-scale human evaluation to measure the effect of these control parameters on multi-turn interactive conversations on the PersonaChat task. We provide a detailed analysis of their relationship to high-level aspects of conversation, and show that by controlling combinations of these variables our models obtain clear improvements in human quality judgments.",,,,, ,"  Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",,out_of_scope,
3363,"**Title**Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training

**Abstract**The objective of non-parallel text style transfer, or controllable text generation, is to alter specific attributes (e.g. sentiment, mood, tense, politeness, etc) of a given text while preserving its remaining attributes and content. Generative adversarial network (GAN) is a popular model to ensure the transferred sentences are realistic and have the desired target styles. However, training GAN often suffers from mode collapse problem, which causes that the transferred text is little related to the original text. In this paper, we propose a new GAN model with a word-level conditional architecture and a two-phase training procedure. By using a style-related condition architecture before generating a word, our model is able to maintain style-unrelated words while changing the others. By separating the training procedure into reconstruction and transfer phases, our model is able to learn a proper text generation process, which further improves the content preservation. We test our model on polarity sentiment transfer and multiple-attribute transfer tasks. The empirical results show that our model achieves comparable evaluation scores in both transfer accuracy and fluency but significantly outperforms other state-of-the-art models in content compatibility on three real-world datasets.","Lai, Chih-Te, Hong, Yi-Te, Chen, Hong-You, Lu, Chi-Jen, Lin, Shou-De",,,Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training,,,10.18653/v1/D19-1366 , ,,"The objective of non-parallel text style transfer, or controllable text generation, is to alter specific attributes (e.g. sentiment, mood, tense, politeness, etc) of a given text while preserving its remaining attributes and content. Generative adversarial network (GAN) is a popular model to ensure the transferred sentences are realistic and have the desired target styles. However, training GAN often suffers from mode collapse problem, which causes that the transferred text is little related to the original text. In this paper, we propose a new GAN model with a word-level conditional architecture and a two-phase training procedure. By using a style-related condition architecture before generating a word, our model is able to maintain style-unrelated words while changing the others. By separating the training procedure into reconstruction and transfer phases, our model is able to learn a proper text generation process, which further improves the content preservation. We test our model on polarity sentiment transfer and multiple-attribute transfer tasks. The empirical results show that our model achieves comparable evaluation scores in both transfer accuracy and fluency but significantly outperforms other state-of-the-art models in content compatibility on three real-world datasets.",,,,, ,  Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),,out_of_scope,
3364,"**Title**Learning Neural Templates for Text Generation

**Abstract**While neural, encoder-decoder models have had significant empirical success in text generation, there remain several unaddressed problems with this style of generation. Encoder-decoder models are largely (a) uninterpretable, and (b) difficult to control in terms of their phrasing or content. This work proposes a neural generation system using a hidden semi-markov model (HSMM) decoder, which learns latent, discrete templates jointly with learning to generate. We show that this model learns useful templates, and that these templates make generation both more interpretable and controllable. Furthermore, we show that this approach scales to real data sets and achieves strong performance nearing that of encoder-decoder text generation models.","Wiseman, Sam, Shieber, Stuart, Rush, Alexander",,,Learning Neural Templates for Text Generation,,,10.18653/v1/D18-1356 , ,,"While neural, encoder-decoder models have had significant empirical success in text generation, there remain several unaddressed problems with this style of generation. Encoder-decoder models are largely (a) uninterpretable, and (b) difficult to control in terms of their phrasing or content. This work proposes a neural generation system using a hidden semi-markov model (HSMM) decoder, which learns latent, discrete templates jointly with learning to generate. We show that this model learns useful templates, and that these templates make generation both more interpretable and controllable. Furthermore, we show that this approach scales to real data sets and achieves strong performance nearing that of encoder-decoder text generation models.",,,,, ,  Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3365,"**Title**Controlling Human Perception of Basic User Traits

**Abstract**Much of our online communication is text-mediated and, lately, more common with automated agents. Unlike interacting with humans, these agents currently do not tailor their language to the type of person they are communicating to. In this pilot study, we measure the extent to which human perception of basic user trait information {--} gender and age {--} is controllable through text. Using automatic models of gender and age prediction, we estimate which tweets posted by a user are more likely to mis-characterize his traits. We perform multiple controlled crowdsourcing experiments in which we show that we can reduce the human prediction accuracy of gender to almost random {--} an over 20{\%} drop in accuracy. Our experiments show that it is practically feasible for multiple applications such as text generation, text summarization or machine translation to be tailored to specific traits and perceived as such.","Preo{\c{t}}iuc-Pietro, Daniel, Chandra Guntuku, Sharath, Ungar, Lyle",,,Controlling Human Perception of Basic User Traits,,,10.18653/v1/D17-1248 , ,,"Much of our online communication is text-mediated and, lately, more common with automated agents. Unlike interacting with humans, these agents currently do not tailor their language to the type of person they are communicating to. In this pilot study, we measure the extent to which human perception of basic user trait information {--} gender and age {--} is controllable through text. Using automatic models of gender and age prediction, we estimate which tweets posted by a user are more likely to mis-characterize his traits. We perform multiple controlled crowdsourcing experiments in which we show that we can reduce the human prediction accuracy of gender to almost random {--} an over 20{\%} drop in accuracy. Our experiments show that it is practically feasible for multiple applications such as text generation, text summarization or machine translation to be tailored to specific traits and perceived as such.",,,,, ,  Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3366,"**Title**Innovative Approaches to Enhancing Safety and Ethical {AI} Interactions in Digital Environments

**Abstract**Ensuring safe online environments is a formidable challenge, but nonetheless an important one as people are now chronically online. The increasing online presence of people paired with the prevalence of harmful content such as toxicity, hate speech, misinformation and disinformation across various social media platforms and within different video calls for stronger detection and prevention methods. My research interests primarily lie in applied natural language processing for social good. Previously, I focused on measuring partisan polarization on social media during the COVID-19 pandemic and its societal impacts. Currently, at Ubisoft La Forge, I am dedicated to enhancing player safety within in-game chat systems by developing methods to detect toxicity, evaluating the biases in these detection systems, and assessing the current ecological state of online interactions. Additionally, I am engaged in simulating social media environments using LLMs to ethically test detection methods, evaluate the effectiveness of current mitigation strategies, and potentially introduce new, successful strategies. My suggested topics for discussion: 1. Understanding and mitigating social harms through high fidelity simulated social media environments 2. Enhancing safety in online environments such as within in-game chats (text and speech) 3. Personification of LLM agents 4. Ethically simulating social media sandbox environments at scale with LLM agents 5. Re-balancing the playing field between good and bad actors: Strategies for countering societal-scale manipulation.","Yang, Zachary",,,Innovative Approaches to Enhancing Safety and Ethical {AI} Interactions in Digital Environments,,, , ,,"Ensuring safe online environments is a formidable challenge, but nonetheless an important one as people are now chronically online. The increasing online presence of people paired with the prevalence of harmful content such as toxicity, hate speech, misinformation and disinformation across various social media platforms and within different video calls for stronger detection and prevention methods. My research interests primarily lie in applied natural language processing for social good. Previously, I focused on measuring partisan polarization on social media during the COVID-19 pandemic and its societal impacts. Currently, at Ubisoft La Forge, I am dedicated to enhancing player safety within in-game chat systems by developing methods to detect toxicity, evaluating the biases in these detection systems, and assessing the current ecological state of online interactions. Additionally, I am engaged in simulating social media environments using LLMs to ethically test detection methods, evaluate the effectiveness of current mitigation strategies, and potentially introduce new, successful strategies. My suggested topics for discussion: 1. Understanding and mitigating social harms through high fidelity simulated social media environments 2. Enhancing safety in online environments such as within in-game chats (text and speech) 3. Personification of LLM agents 4. Ethically simulating social media sandbox environments at scale with LLM agents 5. Re-balancing the playing field between good and bad actors: Strategies for countering societal-scale manipulation.",,,,, ,  Proceedings of the 20th Workshop of Young Researchers' Roundtable on Spoken Dialogue Systems,,detection,
3367,"**Title**Automated Adversarial Discovery for Safety Classifiers

**Abstract**Safety classifiers are critical in mitigating toxicity on online forums such as social media and in chatbots. Still, they continue to be vulnerable to emergent, and often innumerable, adversarial attacks.Traditional automated adversarial data generation methods, however, tend to produce attacks that are not diverse, but variations of previously observed harm types.We formalize the task of automated adversarial discovery for safety classifiers - to find new attacks along previously unseen harm dimensions that expose new weaknesses in the classifier.We measure progress on this task along two key axes (1) adversarial success: does the attack fool the classifier? and (2) dimensional diversity: does the attack represent a previously unseen harm type?Our evaluation of existing attack generation methods on the CivilComments toxicity task reveals their limitations: Word perturbation attacks fail to fool classifiers, while prompt-based LLM attacks have more adversarial success, but lack dimensional diversity.Even our best-performing prompt-based method finds new successful attacks on unseen harm dimensions of attacks only 5{\%} of the time.Automatically finding new harmful dimensions of attack is crucial and there is substantial headroom for future research on our new task.","Lal, Yash Kumar, Lahoti, Preethi, Sinha, Aradhana, Qin, Yao, Balashankar, Ananth",,,Automated Adversarial Discovery for Safety Classifiers,,,10.18653/v1/2024.trustnlp-1.2 , ,,"Safety classifiers are critical in mitigating toxicity on online forums such as social media and in chatbots. Still, they continue to be vulnerable to emergent, and often innumerable, adversarial attacks.Traditional automated adversarial data generation methods, however, tend to produce attacks that are not diverse, but variations of previously observed harm types.We formalize the task of automated adversarial discovery for safety classifiers - to find new attacks along previously unseen harm dimensions that expose new weaknesses in the classifier.We measure progress on this task along two key axes (1) adversarial success: does the attack fool the classifier? and (2) dimensional diversity: does the attack represent a previously unseen harm type?Our evaluation of existing attack generation methods on the CivilComments toxicity task reveals their limitations: Word perturbation attacks fail to fool classifiers, while prompt-based LLM attacks have more adversarial success, but lack dimensional diversity.Even our best-performing prompt-based method finds new successful attacks on unseen harm dimensions of attacks only 5{\%} of the time.Automatically finding new harmful dimensions of attack is crucial and there is substantial headroom for future research on our new task.",,,,, ,  Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024),,detection,
3368,"**Title**{F}rench{T}oxicity{P}rompts: a Large Benchmark for Evaluating and Mitigating Toxicity in {F}rench Texts

**Abstract**Large language models (LLMs) are increasingly popular but are also prone to generating bias, toxic or harmful language, which can have detrimental effects on individuals and communities. Although most efforts is put to assess and mitigate toxicity in generated content, it is primarily concentrated on English, while it`s essential to consider other languages as well. For addressing this issue, we create and release FrenchToxicityPrompts, a dataset of 50K naturally occurring French prompts and their continuations, annotated with toxicity scores from a widely used toxicity classifier. We evaluate 14 different models from four prevalent open-sourced families of LLMs against our dataset to assess their potential toxicity across various dimensions. We hope that our contribution will foster future research on toxicity detection and mitigation beyond English.","Brun, Caroline, Nikoulina, Vassilina",,,{F}rench{T}oxicity{P}rompts: a Large Benchmark for Evaluating and Mitigating Toxicity in {F}rench Texts,,, , ,,"Large language models (LLMs) are increasingly popular but are also prone to generating bias, toxic or harmful language, which can have detrimental effects on individuals and communities. Although most efforts is put to assess and mitigate toxicity in generated content, it is primarily concentrated on English, while it`s essential to consider other languages as well. For addressing this issue, we create and release FrenchToxicityPrompts, a dataset of 50K naturally occurring French prompts and their continuations, annotated with toxicity scores from a widely used toxicity classifier. We evaluate 14 different models from four prevalent open-sourced families of LLMs against our dataset to assess their potential toxicity across various dimensions. We hope that our contribution will foster future research on toxicity detection and mitigation beyond English.",,,,, ,"  Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,out_but_toxicity,
3369,"**Title**How Trustworthy are Open-Source {LLM}s? An Assessment under Malicious Demonstrations Shows their Vulnerabilities

**Abstract**The rapid progress in open-source Large Language Models (LLMs) is significantly driving AI development forward. However, there is still a limited understanding of their trustworthiness. Deploying these models at scale without sufficient trustworthiness can pose significant risks, highlighting the need to uncover these issues promptly. In this work, we conduct an adversarial assessment of open-source LLMs on trustworthiness, scrutinizing them across eight different aspects including toxicity, stereotypes, ethics, hallucination, fairness, sycophancy, privacy, and robustness against adversarial demonstrations. We propose advCoU, an extended Chain of Utterances-based (CoU) prompting strategy by incorporating carefully crafted malicious demonstrations for trustworthiness attack. Our extensive experiments encompass recent and representative series of open-source LLMs, including Vicuna, MPT, Falcon, Mistral, and Llama 2. The empirical outcomes underscore the efficacy of our attack strategy across diverse aspects. More interestingly, our result analysis reveals that models with superior performance in general NLP tasks do not always have greater trustworthiness; in fact, larger models can be more vulnerable to attacks. Additionally, models that have undergone instruction tuning, focusing on instruction following, tend to be more susceptible, although fine-tuning LLMs for safety alignment proves effective in mitigating adversarial trustworthiness attacks.","Mo, Lingbo, Wang, Boshi, Chen, Muhao, Sun, Huan",,,How Trustworthy are Open-Source {LLM}s? An Assessment under Malicious Demonstrations Shows their Vulnerabilities,,,10.18653/v1/2024.naacl-long.152 , ,,"The rapid progress in open-source Large Language Models (LLMs) is significantly driving AI development forward. However, there is still a limited understanding of their trustworthiness. Deploying these models at scale without sufficient trustworthiness can pose significant risks, highlighting the need to uncover these issues promptly. In this work, we conduct an adversarial assessment of open-source LLMs on trustworthiness, scrutinizing them across eight different aspects including toxicity, stereotypes, ethics, hallucination, fairness, sycophancy, privacy, and robustness against adversarial demonstrations. We propose advCoU, an extended Chain of Utterances-based (CoU) prompting strategy by incorporating carefully crafted malicious demonstrations for trustworthiness attack. Our extensive experiments encompass recent and representative series of open-source LLMs, including Vicuna, MPT, Falcon, Mistral, and Llama 2. The empirical outcomes underscore the efficacy of our attack strategy across diverse aspects. More interestingly, our result analysis reveals that models with superior performance in general NLP tasks do not always have greater trustworthiness; in fact, larger models can be more vulnerable to attacks. Additionally, models that have undergone instruction tuning, focusing on instruction following, tend to be more susceptible, although fine-tuning LLMs for safety alignment proves effective in mitigating adversarial trustworthiness attacks.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detox,
3370,"**Title**How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models

**Abstract**Given the growing influx of misinformation across news and social media, there is a critical need for systems that can provide effective real-time verification of news claims. Large language or multimodal model based verification has been proposed to scale up online policing mechanisms for mitigating spread of false and harmful content. While these can potentially reduce burden on human fact-checkers, such efforts may be hampered by foundation model training data becoming outdated. In this work, we test the limits of improving foundation model performance without continual updating through an initial study of knowledge transfer using either existing intra- and inter-domain benchmarks or explanations generated from large language models (LLMs).We evaluate on 12 public benchmarks for fact-checking and misinformation detection as well as two other tasks relevant to content moderation - toxicity and stance detection. Our results on two recent multi-modal fact-checking benchmarks, Mocheg and Fakeddit, indicate that knowledge transfer strategies can improve Fakeddit performance over the state-of-the-art by up to 1.7{\%} and Mocheg performance by up to 2.9{\%}. The code, model checkpoints, and dataset are available: https://github.com/given131/ fact-verifier-knowledge-transfer.","Lee, Jaeyoung, Lu, Ximing, Hessel, Jack, Brahman, Faeze, Yu, Youngjae, Bisk, Yonatan, Choi, Yejin, Gabriel, Saadia",,,How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models,,,10.18653/v1/2024.findings-emnlp.764 , ,,"Given the growing influx of misinformation across news and social media, there is a critical need for systems that can provide effective real-time verification of news claims. Large language or multimodal model based verification has been proposed to scale up online policing mechanisms for mitigating spread of false and harmful content. While these can potentially reduce burden on human fact-checkers, such efforts may be hampered by foundation model training data becoming outdated. In this work, we test the limits of improving foundation model performance without continual updating through an initial study of knowledge transfer using either existing intra- and inter-domain benchmarks or explanations generated from large language models (LLMs).We evaluate on 12 public benchmarks for fact-checking and misinformation detection as well as two other tasks relevant to content moderation - toxicity and stance detection. Our results on two recent multi-modal fact-checking benchmarks, Mocheg and Fakeddit, indicate that knowledge transfer strategies can improve Fakeddit performance over the state-of-the-art by up to 1.7{\%} and Mocheg performance by up to 2.9{\%}. The code, model checkpoints, and dataset are available: https://github.com/given131/ fact-verifier-knowledge-transfer.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detection,
3371,"**Title**{XD}etox: Text Detoxification with Token-Level Toxicity Explanations

**Abstract**Methods for mitigating toxic content through masking and infilling often overlook the decision-making process, leading to either insufficient or excessive modifications of toxic tokens. To address this challenge, we propose XDetox, a novel method that integrates token-level toxicity explanations with the masking and infilling detoxification process. We utilized this approach with two strategies to enhance the performance of detoxification. First, identifying toxic tokens to improve the quality of masking. Second, selecting the regenerated sentence by re-ranking the least toxic sentence among candidates. Our experimental results show state-of-the-art performance across four datasets compared to existing detoxification methods. Furthermore, human evaluations indicate that our method outperforms baselines in both fluency and toxicity reduction. These results demonstrate the effectiveness of our method in text detoxification.","Lee, Beomseok, Kim, Hyunwoo, Kim, Keon, Choi, Yong Suk",,,{XD}etox: Text Detoxification with Token-Level Toxicity Explanations,,,10.18653/v1/2024.emnlp-main.848 , ,,"Methods for mitigating toxic content through masking and infilling often overlook the decision-making process, leading to either insufficient or excessive modifications of toxic tokens. To address this challenge, we propose XDetox, a novel method that integrates token-level toxicity explanations with the masking and infilling detoxification process. We utilized this approach with two strategies to enhance the performance of detoxification. First, identifying toxic tokens to improve the quality of masking. Second, selecting the regenerated sentence by re-ranking the least toxic sentence among candidates. Our experimental results show state-of-the-art performance across four datasets compared to existing detoxification methods. Furthermore, human evaluations indicate that our method outperforms baselines in both fluency and toxicity reduction. These results demonstrate the effectiveness of our method in text detoxification.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3372,"**Title**Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding

**Abstract**Large Language Models (LLMs) have demonstrated a powerful ability for text generation. However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired behaviors such as toxicity or hallucinations can manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in mitigating these issues, there is still no guarantee of complete prevention. In this work, we propose formalizing text generation as a future-constrained generation problem to minimize undesirable behaviors and enforce faithfulness to instructions. The estimation of future constraint satisfaction, accomplished using LLMs, guides the text generation process. Our extensive experiments demonstrate the effectiveness of the proposed approach across three distinct text generation tasks: keyword-constrained generation (Lin et al., 2020), toxicity reduction (Gehman et al., 2020), and factual correctness in question-answering (Gao et al., 2023).","Tu, Lifu, Yavuz, Semih, Qu, Jin, Xu, Jiacheng, Meng, Rui, Xiong, Caiming, Zhou, Yingbo",,,Unlocking Anticipatory Text Generation: A Constrained Approach for Large Language Models Decoding,,,10.18653/v1/2024.emnlp-main.870 , ,,"Large Language Models (LLMs) have demonstrated a powerful ability for text generation. However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired behaviors such as toxicity or hallucinations can manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in mitigating these issues, there is still no guarantee of complete prevention. In this work, we propose formalizing text generation as a future-constrained generation problem to minimize undesirable behaviors and enforce faithfulness to instructions. The estimation of future constraint satisfaction, accomplished using LLMs, guides the text generation process. Our extensive experiments demonstrate the effectiveness of the proposed approach across three distinct text generation tasks: keyword-constrained generation (Lin et al., 2020), toxicity reduction (Gehman et al., 2020), and factual correctness in question-answering (Gao et al., 2023).",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3373,"**Title**{M}ental{M}anip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations

**Abstract**Mental manipulation, a significant form of abuse in interpersonal conversations, presents a challenge to identify due to its context-dependent and often subtle nature. The detection of manipulative language is essential for protecting potential victims, yet the field of Natural Language Processing (NLP) currently faces a scarcity of resources and research on this topic. Our study addresses this gap by introducing a new dataset, named $\textsc{MentalManip}$, which consists of 4,000 annotated fictional dialogues. This dataset enables a comprehensive analysis of mental manipulation, pinpointing both the techniques utilized for manipulation and the vulnerabilities targeted in victims. Our research further explores the effectiveness of leading-edge models in recognizing manipulative dialogue and its components through a series of experiments with various configurations. The results demonstrate that these models inadequately identify and categorize manipulative content. Attempts to improve their performance by fine-tuning with existing datasets on mental health and toxicity have not overcome these limitations. We anticipate that $\textsc{MentalManip}$ will stimulate further research, leading to progress in both understanding and mitigating the impact of mental manipulation in conversations.","Wang, Yuxin, Yang, Ivory, Hassanpour, Saeed, Vosoughi, Soroush",,,{M}ental{M}anip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations,,,10.18653/v1/2024.acl-long.206 , ,,"Mental manipulation, a significant form of abuse in interpersonal conversations, presents a challenge to identify due to its context-dependent and often subtle nature. The detection of manipulative language is essential for protecting potential victims, yet the field of Natural Language Processing (NLP) currently faces a scarcity of resources and research on this topic. Our study addresses this gap by introducing a new dataset, named $\textsc{MentalManip}$, which consists of 4,000 annotated fictional dialogues. This dataset enables a comprehensive analysis of mental manipulation, pinpointing both the techniques utilized for manipulation and the vulnerabilities targeted in victims. Our research further explores the effectiveness of leading-edge models in recognizing manipulative dialogue and its components through a series of experiments with various configurations. The results demonstrate that these models inadequately identify and categorize manipulative content. Attempts to improve their performance by fine-tuning with existing datasets on mental health and toxicity have not overcome these limitations. We anticipate that $\textsc{MentalManip}$ will stimulate further research, leading to progress in both understanding and mitigating the impact of mental manipulation in conversations.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3374,"**Title**Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models

**Abstract**Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models. Furthermore, previous approaches have often neglected the crucial factor of language`s evolving nature over time. In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature. We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43{\%} relative latency reduction during inference and being more computationally efficient. By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation. Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild.","Pozzobon, Luiza, Ermis, Beyza, Lewis, Patrick, Hooker, Sara",,,Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models,,,10.18653/v1/2023.findings-emnlp.339 , ,,"Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models. Furthermore, previous approaches have often neglected the crucial factor of language`s evolving nature over time. In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature. We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43{\%} relative latency reduction during inference and being more computationally efficient. By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation. Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detox,
3375,"**Title**{C}on{P}rompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection

**Abstract**Implicit hate speech detection is a challenging task in text classification since no explicit cues (e.g., swear words) exist in the text. While some pre-trained language models have been developed for hate speech detection, they are not specialized in implicit hate speech. Recently, an implicit hate speech dataset with a massive number of samples has been proposed by controlling machine generation. We propose a pre-training approach, ConPrompt, to fully leverage such machine-generated data. Specifically, given a machine-generated statement, we use example statements of its origin prompt as positive samples for contrastive learning. Through pre-training with ConPrompt, we present ToxiGen-ConPrompt, a pre-trained language model for implicit hate speech detection. We conduct extensive experiments on several implicit hate speech datasets and show the superior generalization ability of ToxiGen-ConPrompt compared to other pre-trained models. Additionally, we empirically show that ConPrompt is effective in mitigating identity term bias, demonstrating that it not only makes a model more generalizable but also reduces unintended bias. We analyze the representation quality of ToxiGen-ConPrompt and show its ability to consider target group and toxicity, which are desirable features in terms of implicit hate speeches.","Kim, Youngwook, Park, Shinwoo, Namgoong, Youngsoo, Han, Yo-Sub",,,{C}on{P}rompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection,,,10.18653/v1/2023.findings-emnlp.731 , ,,"Implicit hate speech detection is a challenging task in text classification since no explicit cues (e.g., swear words) exist in the text. While some pre-trained language models have been developed for hate speech detection, they are not specialized in implicit hate speech. Recently, an implicit hate speech dataset with a massive number of samples has been proposed by controlling machine generation. We propose a pre-training approach, ConPrompt, to fully leverage such machine-generated data. Specifically, given a machine-generated statement, we use example statements of its origin prompt as positive samples for contrastive learning. Through pre-training with ConPrompt, we present ToxiGen-ConPrompt, a pre-trained language model for implicit hate speech detection. We conduct extensive experiments on several implicit hate speech datasets and show the superior generalization ability of ToxiGen-ConPrompt compared to other pre-trained models. Additionally, we empirically show that ConPrompt is effective in mitigating identity term bias, demonstrating that it not only makes a model more generalizable but also reduces unintended bias. We analyze the representation quality of ToxiGen-ConPrompt and show its ability to consider target group and toxicity, which are desirable features in terms of implicit hate speeches.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detection,
3376,"**Title**Performance and Risk Trade-offs for Multi-word Text Prediction at Scale

**Abstract**Large Language Models such as GPT-3 are well-suited for text prediction tasks, which can help and delight users during text composition. LLMs are known to generate ethically inappropriate predictions even for seemingly innocuous contexts. Toxicity detection followed by filtering is a common strategy for mitigating the harm from such predictions. However, as we shall argue in this paper, in the context of text prediction, it is not sufficient to detect and filter toxic content. One also needs to ensure factual correctness and group-level fairness of the predictions; failing to do so can make the system ineffective and nonsensical at best, and unfair and detrimental to the users at worst. We discuss the gaps and challenges of toxicity detection approaches - from blocklist-based approaches to sophisticated state-of-the-art neural classifiers - by evaluating them on the text prediction task for English against a manually crafted CheckList of harms targeted at different groups and different levels of severity.","Vashishtha, Aniket, Prasad, S Sai, Bajaj, Payal, Chaudhary, Vishrav, Cook, Kate, Dandapat, Sandipan, Sitaram, Sunayana, Choudhury, Monojit",,,Performance and Risk Trade-offs for Multi-word Text Prediction at Scale,,,10.18653/v1/2023.findings-eacl.167 , ,,"Large Language Models such as GPT-3 are well-suited for text prediction tasks, which can help and delight users during text composition. LLMs are known to generate ethically inappropriate predictions even for seemingly innocuous contexts. Toxicity detection followed by filtering is a common strategy for mitigating the harm from such predictions. However, as we shall argue in this paper, in the context of text prediction, it is not sufficient to detect and filter toxic content. One also needs to ensure factual correctness and group-level fairness of the predictions; failing to do so can make the system ineffective and nonsensical at best, and unfair and detrimental to the users at worst. We discuss the gaps and challenges of toxicity detection approaches - from blocklist-based approaches to sophisticated state-of-the-art neural classifiers - by evaluating them on the text prediction task for English against a manually crafted CheckList of harms targeted at different groups and different levels of severity.",,,,, ,  Findings of the Association for Computational Linguistics: EACL 2023,,detection,
3377,"**Title**Mitigating Societal Harms in Large Language Models

**Abstract**Numerous recent studies have highlighted societal harms that can be caused by language technologies deployed in the wild. While several surveys, tutorials, and workshops have discussed the risks of harms in specific contexts {--} e.g., detecting and mitigating gender bias in NLP models {--} no prior work has developed a unified typology of technical approaches for mitigating harms of language generation models. Our tutorial is based on a survey we recently wrote that proposes such a typology. We will provide an overview of potential social issues in language generation, including toxicity, social biases, misinformation, factual inconsistency, and privacy violations. Our primary focus will be on how to systematically identify risks, and how eliminate them at various stages of model development, from data collection, to model development, to inference/language generation. Through this tutorial, we aim to equip NLP researchers and engineers with a suite of practical tools for mitigating safety risks from pretrained language generation models.","Kumar, Sachin, Balachandran, Vidhisha, Njoo, Lucille, Anastasopoulos, Antonios, Tsvetkov, Yulia",,,Mitigating Societal Harms in Large Language Models,,,10.18653/v1/2023.emnlp-tutorial.5 , ,,"Numerous recent studies have highlighted societal harms that can be caused by language technologies deployed in the wild. While several surveys, tutorials, and workshops have discussed the risks of harms in specific contexts {--} e.g., detecting and mitigating gender bias in NLP models {--} no prior work has developed a unified typology of technical approaches for mitigating harms of language generation models. Our tutorial is based on a survey we recently wrote that proposes such a typology. We will provide an overview of potential social issues in language generation, including toxicity, social biases, misinformation, factual inconsistency, and privacy violations. Our primary focus will be on how to systematically identify risks, and how eliminate them at various stages of model development, from data collection, to model development, to inference/language generation. Through this tutorial, we aim to equip NLP researchers and engineers with a suite of practical tools for mitigating safety risks from pretrained language generation models.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,,detection,
3378,"**Title**Toxicity Classification in {U}krainian

**Abstract**The task of toxicity detection is still a relevant task, especially in the context of safe and fair LMs development. Nevertheless, labeled binary toxicity classification corpora are not available for all languages, which is understandable given the resource-intensive nature of the annotation process. Ukrainian, in particular, is among the languages lacking such resources. To our knowledge, there has been no existing toxicity classification corpus in Ukrainian. In this study, we aim to fill this gap by investigating cross-lingual knowledge transfer techniques and creating labeled corpora by: (i){\textasciitilde}translating from an English corpus, (ii){\textasciitilde}filtering toxic samples using keywords, and (iii){\textasciitilde}annotating with crowdsourcing. We compare LLMs prompting and other cross-lingual transfer approaches with and without fine-tuning offering insights into the most robust and efficient baselines.","Dementieva, Daryna, Khylenko, Valeriia, Babakov, Nikolay, Groh, Georg",,,Toxicity Classification in {U}krainian,,,10.18653/v1/2024.woah-1.19 , ,,"The task of toxicity detection is still a relevant task, especially in the context of safe and fair LMs development. Nevertheless, labeled binary toxicity classification corpora are not available for all languages, which is understandable given the resource-intensive nature of the annotation process. Ukrainian, in particular, is among the languages lacking such resources. To our knowledge, there has been no existing toxicity classification corpus in Ukrainian. In this study, we aim to fill this gap by investigating cross-lingual knowledge transfer techniques and creating labeled corpora by: (i){\textasciitilde}translating from an English corpus, (ii){\textasciitilde}filtering toxic samples using keywords, and (iii){\textasciitilde}annotating with crowdsourcing. We compare LLMs prompting and other cross-lingual transfer approaches with and without fine-tuning offering insights into the most robust and efficient baselines.",,,,, ,  Proceedings of the 8th Workshop on Online Abuse and Harms (WOAH 2024),,out_but_toxicity,
3379,"**Title**Improving Covert Toxicity Detection by Retrieving and Generating References

**Abstract**Models for detecting toxic content play an important role in keeping people safe online. There has been much progress in detecting overt toxicity. Covert toxicity, however, remains a challenge because its detection requires an understanding of implicit meaning and subtle connotations. In this paper, we explore the potential of leveraging references, such as external knowledge and textual interpretations, to enhance the detection of covert toxicity. We run experiments on two covert toxicity datasets with two types of references: 1) information retrieved from a search API, and 2) interpretations generated by large language models. We find that both types of references improve detection, with the latter being more useful than the former. We also find that generating interpretations grounded on properties of covert toxicity, such as humor and irony, lead to the largest improvements","Lee, Dong-Ho, Cho, Hyundong, Jin, Woojeong, Moon, Jihyung, Park, Sungjoon, R{\""o}ttger, Paul, Pujara, Jay, Lee, Roy Ka-wei",,,Improving Covert Toxicity Detection by Retrieving and Generating References,,,10.18653/v1/2024.woah-1.21 , ,,"Models for detecting toxic content play an important role in keeping people safe online. There has been much progress in detecting overt toxicity. Covert toxicity, however, remains a challenge because its detection requires an understanding of implicit meaning and subtle connotations. In this paper, we explore the potential of leveraging references, such as external knowledge and textual interpretations, to enhance the detection of covert toxicity. We run experiments on two covert toxicity datasets with two types of references: 1) information retrieved from a search API, and 2) interpretations generated by large language models. We find that both types of references improve detection, with the latter being more useful than the former. We also find that generating interpretations grounded on properties of covert toxicity, such as humor and irony, lead to the largest improvements",,,,, ,  Proceedings of the 8th Workshop on Online Abuse and Harms (WOAH 2024),,detection,
3380,"**Title**{LLM}-Based Synthetic Datasets: Applications and Limitations in Toxicity Detection

**Abstract**Large Language Model (LLM)-based Synthetic Data is becoming an increasingly important field of research. One of its promising application is in training classifiers to detect online toxicity, which is of increasing concern in today`s digital landscape. In this work, we assess the feasibility of generative models to generate synthetic data for toxic speech detection. Our experiments are conducted on six different toxicity datasets, four of whom are hateful and two are toxic in the broader sense. We then employ a classifier trained on the original data for filtering. To explore the potential of this data, we conduct experiments using combinations of original and synthetic data, synthetic oversampling of the minority class, and a comparison of original vs. synthetic-only training. Results indicate that while our generative models offer benefits in certain scenarios, it does not improve hateful dataset classification. However, it does boost patronizing and condescending language detection. We find that synthetic data generated by LLMs is a promising avenue of research, but further research is needed to improve the quality of the generated data and develop better filtering methods. Code is available on GitHub; the generated dataset will be available on Zenodo in the final submission.","Kruschwitz, Udo, Schmidhuber, Maximilian",,,{LLM}-Based Synthetic Datasets: Applications and Limitations in Toxicity Detection,,, , ,,"Large Language Model (LLM)-based Synthetic Data is becoming an increasingly important field of research. One of its promising application is in training classifiers to detect online toxicity, which is of increasing concern in today`s digital landscape. In this work, we assess the feasibility of generative models to generate synthetic data for toxic speech detection. Our experiments are conducted on six different toxicity datasets, four of whom are hateful and two are toxic in the broader sense. We then employ a classifier trained on the original data for filtering. To explore the potential of this data, we conduct experiments using combinations of original and synthetic data, synthetic oversampling of the minority class, and a comparison of original vs. synthetic-only training. Results indicate that while our generative models offer benefits in certain scenarios, it does not improve hateful dataset classification. However, it does boost patronizing and condescending language detection. We find that synthetic data generated by LLMs is a promising avenue of research, but further research is needed to improve the quality of the generated data and develop better filtering methods. Code is available on GitHub; the generated dataset will be available on Zenodo in the final submission.",,,,, ,"  Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,detection,
3381,"**Title**{MIC}o: Preventative Detoxification of Large Language Models through Inhibition Control

**Abstract**Large Language Models (LLMs) are powerful tools which have been both dominant and commonplace in the field of Artificial Intelligence. Yet, LLMs have a tendency to devolve into toxic degeneration, wherein otherwise safe and unproblematic models begin generating toxic content. For the sake of social responsibility and inspired by the biological mechanisms of inhibition control, we introduce the paradigm of Education for Societal Norms (ESN). By collecting and labeling examples as acceptable and unacceptable (in this case toxic and non-toxic), and including a corresponding acceptable rewrite with every unacceptable example, we introduce a new mechanism for LLM detoxification. We annotate a dataset of 2,850 entries and use it to fine-tune a model, which we call a Model with Inhibition Control (MICo). Evaluating this model on toxicity detection capability, rewrite detoxification, meaning preservation, and overall toxicity reduction, we discover significant improvements over the baseline model. In our experiments we show that overall toxicity of this model is more than 60{\%} reduced, with over 75{\%} reduction in severe toxicity.","Siegelmann, Roy, Mehrabi, Ninareh, Goyal, Palash, Goyal, Prasoon, Bauer, Lisa, Dhamala, Jwala, Galstyan, Aram, Gupta, Rahul, Ghanadan, Reza",,,{MIC}o: Preventative Detoxification of Large Language Models through Inhibition Control,,,10.18653/v1/2024.findings-naacl.110 , ,,"Large Language Models (LLMs) are powerful tools which have been both dominant and commonplace in the field of Artificial Intelligence. Yet, LLMs have a tendency to devolve into toxic degeneration, wherein otherwise safe and unproblematic models begin generating toxic content. For the sake of social responsibility and inspired by the biological mechanisms of inhibition control, we introduce the paradigm of Education for Societal Norms (ESN). By collecting and labeling examples as acceptable and unacceptable (in this case toxic and non-toxic), and including a corresponding acceptable rewrite with every unacceptable example, we introduce a new mechanism for LLM detoxification. We annotate a dataset of 2,850 entries and use it to fine-tune a model, which we call a Model with Inhibition Control (MICo). Evaluating this model on toxicity detection capability, rewrite detoxification, meaning preservation, and overall toxicity reduction, we discover significant improvements over the baseline model. In our experiments we show that overall toxicity of this model is more than 60{\%} reduced, with over 75{\%} reduction in severe toxicity.",,,,, ,  Findings of the Association for Computational Linguistics: NAACL 2024,,detox,
3382,"**Title**Implanting {LLM}`s Knowledge via Reading Comprehension Tree for Toxicity Detection

**Abstract**Toxicity detection plays a crucial role in maintaining the peace of the society. Existing methods can be roughly categorized as small language model (SLM) based and large language model (LLM) based. However, due to the limitation of SLMs on general knowledge and the potential embedded bias in LLMs despite their large amount of knowledge, it is not a good idea to detect toxicity only with either SLM or LLM based method.In this work, we propose to implant LLM`s knowledge into SLM based methods such that we can stick to both types of models' strengths. To this end, we develop a reading comprehension (RC) tree to transfer knowledge between two models. Specifically, we first construct the RC tree, from an extensive to intensive reading perspective, to capture the local and global information in the text. We then model samples encoded by SLM and knowledge extracted from LLM as two distributions using the constructed RT tree. We finally transfer knowledge via optimal transportation between two distributions. Extensive experiments prove the effectiveness of our method on real-world and machine-generated datasets.","Kang, Hankun, Qian, Tieyun",,,Implanting {LLM}`s Knowledge via Reading Comprehension Tree for Toxicity Detection,,,10.18653/v1/2024.findings-acl.56 , ,,"Toxicity detection plays a crucial role in maintaining the peace of the society. Existing methods can be roughly categorized as small language model (SLM) based and large language model (LLM) based. However, due to the limitation of SLMs on general knowledge and the potential embedded bias in LLMs despite their large amount of knowledge, it is not a good idea to detect toxicity only with either SLM or LLM based method.In this work, we propose to implant LLM`s knowledge into SLM based methods such that we can stick to both types of models' strengths. To this end, we develop a reading comprehension (RC) tree to transfer knowledge between two models. Specifically, we first construct the RC tree, from an extensive to intensive reading perspective, to capture the local and global information in the text. We then model samples encoded by SLM and knowledge extracted from LLM as two distributions using the constructed RT tree. We finally transfer knowledge via optimal transportation between two distributions. Extensive experiments prove the effectiveness of our method on real-world and machine-generated datasets.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detection,
3383,"**Title**{M}u{T}ox: Universal {MU}ltilingual Audio-based {TOX}icity Dataset and Zero-shot Detector

**Abstract**Research in toxicity detection in natural language processing for the speech modality (audio-based) is quite limited, particularly for languages other than English. To address these limitations and lay the groundwork for truly multilingual audio-based toxicity detection, we introduce MuTox, the first highly multilingual audio-based dataset with toxicity labels which covers 14 different linguistic families. The dataset comprises 20,000 audio utterances for English and Spanish, and 4,000 for the other 28 languages. To demonstrate the quality of this dataset, we trained the MuTox audio-based toxicity classifier, which enables zero-shot toxicity detection across a wide range of languages. This classifier performs on par with existing text-based trainable classifiers, while expanding the language coverage more than tenfold. When compared to a wordlist-based classifier that covers a similar number of languages, MuTox improves F1-Score by an average of 100{\%}. This significant improvement underscores the potential of MuTox in advancing the field of audio-based toxicity detection.","Costa-juss{\`a}, Marta, Meglioli, Mariano, Andrews, Pierre, Dale, David, Hansanti, Prangthip, Kalbassi, Elahe, Mourachko, Alexandre, Ropers, Christophe, Wood, Carleigh",,,{M}u{T}ox: Universal {MU}ltilingual Audio-based {TOX}icity Dataset and Zero-shot Detector,,,10.18653/v1/2024.findings-acl.340 , ,,"Research in toxicity detection in natural language processing for the speech modality (audio-based) is quite limited, particularly for languages other than English. To address these limitations and lay the groundwork for truly multilingual audio-based toxicity detection, we introduce MuTox, the first highly multilingual audio-based dataset with toxicity labels which covers 14 different linguistic families. The dataset comprises 20,000 audio utterances for English and Spanish, and 4,000 for the other 28 languages. To demonstrate the quality of this dataset, we trained the MuTox audio-based toxicity classifier, which enables zero-shot toxicity detection across a wide range of languages. This classifier performs on par with existing text-based trainable classifiers, while expanding the language coverage more than tenfold. When compared to a wordlist-based classifier that covers a similar number of languages, MuTox improves F1-Score by an average of 100{\%}. This significant improvement underscores the potential of MuTox in advancing the field of audio-based toxicity detection.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,out_but_toxicity,
3384,"**Title**{T}ox{V}id{LM}: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos

**Abstract**In an era of rapidly evolving internet technology, the surge in multimodal content, including videos, has expanded the horizons of online communication. However, the detection of toxic content in this diverse landscape, particularly in low-resource code-mixed languages, remains a critical challenge. While substantial research has addressed toxic content detection in textual data, the realm of video content, especially in non-English languages, has been relatively underexplored. This paper addresses this research gap by introducing a benchmark dataset, the first of its kind, consisting of 931 videos with 4021 code-mixed Hindi-English utterances collected from YouTube. Each utterance within this dataset has been meticulously annotated for toxicity, severity, and sentiment labels. We have developed an advanced Multimodal Multitask framework built for Toxicity detection in Video Content by leveraging Language Models (LMs), crafted for the primary objective along with the additional tasks of conducting sentiment and severity analysis. ToxVidLM incorporates three key modules {--} the Encoder module, Cross-Modal Synchronization module, and Multitask module {--} crafting a generic multimodal LM customized for intricate video classification tasks. Our experiments reveal that incorporating multiple modalities from the videos substantially enhances the performance of toxic content detection by achieving an Accuracy and Weighted F1 score of 94.29{\%} and 94.35{\%}, respectively.","Maity, Krishanu, Poornash, A.S., Saha, Sriparna, Bhattacharyya, Pushpak",,,{T}ox{V}id{LM}: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos,,,10.18653/v1/2024.findings-acl.663 , ,,"In an era of rapidly evolving internet technology, the surge in multimodal content, including videos, has expanded the horizons of online communication. However, the detection of toxic content in this diverse landscape, particularly in low-resource code-mixed languages, remains a critical challenge. While substantial research has addressed toxic content detection in textual data, the realm of video content, especially in non-English languages, has been relatively underexplored. This paper addresses this research gap by introducing a benchmark dataset, the first of its kind, consisting of 931 videos with 4021 code-mixed Hindi-English utterances collected from YouTube. Each utterance within this dataset has been meticulously annotated for toxicity, severity, and sentiment labels. We have developed an advanced Multimodal Multitask framework built for Toxicity detection in Video Content by leveraging Language Models (LMs), crafted for the primary objective along with the additional tasks of conducting sentiment and severity analysis. ToxVidLM incorporates three key modules {--} the Encoder module, Cross-Modal Synchronization module, and Multitask module {--} crafting a generic multimodal LM customized for intricate video classification tasks. Our experiments reveal that incorporating multiple modalities from the videos substantially enhances the performance of toxic content detection by achieving an Accuracy and Weighted F1 score of 94.29{\%} and 94.35{\%}, respectively.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,out_of_scope,
3385,"**Title**{A}ustro{T}ox: A Dataset for Target-Based {A}ustrian {G}erman Offensive Language Detection

**Abstract**Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently, such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian German dialect, comprising 4,562 user comments. In addition to binary offensiveness classification, we identify spans within each comment constituting vulgar language or representing targets of offensive statements. We evaluate fine-tuned Transformer models as well as large language models in a zero- and few-shot fashion. The results indicate that while fine-tuned models excel in detecting linguistic peculiarities such as vulgar dialect, large language models demonstrate superior performance in detecting offensiveness in AustroTox.","Pachinger, Pia, Goldzycher, Janis, Planitzer, Anna, Kusa, Wojciech, Hanbury, Allan, Neidhardt, Julia",,,{A}ustro{T}ox: A Dataset for Target-Based {A}ustrian {G}erman Offensive Language Detection,,,10.18653/v1/2024.findings-acl.713 , ,,"Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently, such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian German dialect, comprising 4,562 user comments. In addition to binary offensiveness classification, we identify spans within each comment constituting vulgar language or representing targets of offensive statements. We evaluate fine-tuned Transformer models as well as large language models in a zero- and few-shot fashion. The results indicate that while fine-tuned models excel in detecting linguistic peculiarities such as vulgar dialect, large language models demonstrate superior performance in detecting offensiveness in AustroTox.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,out_but_toxicity,
3386,"**Title**Toxicity Detection is {NOT} all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method

**Abstract**Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks have truly addressed moderators' needs in accomplishing their work. In this paper, we surface gaps between past research efforts that have aimed to provide automation for aspects of content moderation and the needs of volunteer content moderators, regarding identifying violations of various moderation rules. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines from three exemplar forums. We further put state-of-the-art LLMs to the test, evaluating how well these models perform in flagging violations of platform rules from one particular forum. Finally, we conduct a user survey study with volunteer moderators to gain insight into their perspectives on useful moderation models. Overall, we observe a non trivial gap, as missing developed models and LLMs exhibit moderate to low performance on a significant portion of the rules. Moderators' reports provide guides for future work on developing moderation assistant models.","Cao, Yang Trista, Domingo, Lovely-Frances, Gilbert, Sarah, Mazurek, Michelle L., Shilton, Katie, Daum{\'e} Iii, Hal",,,Toxicity Detection is {NOT} all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators through a User-Centric Method,,,10.18653/v1/2024.emnlp-main.209 , ,,"Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks have truly addressed moderators' needs in accomplishing their work. In this paper, we surface gaps between past research efforts that have aimed to provide automation for aspects of content moderation and the needs of volunteer content moderators, regarding identifying violations of various moderation rules. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines from three exemplar forums. We further put state-of-the-art LLMs to the test, evaluating how well these models perform in flagging violations of platform rules from one particular forum. Finally, we conduct a user survey study with volunteer moderators to gain insight into their perspectives on useful moderation models. Overall, we observe a non trivial gap, as missing developed models and LLMs exhibit moderate to low performance on a significant portion of the rules. Moderators' reports provide guides for future work on developing moderation assistant models.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detection,
3387,"**Title**Can We Statically Locate Knowledge in Large Language Models? Financial Domain and Toxicity Reduction Case Studies

**Abstract**Current large language model (LLM) evaluations rely on benchmarks to assess model capabilities and their encoded knowledge. However, these evaluations cannot reveal where a model encodes its knowledge, and thus little is known about which weights contain specific information. We propose a method to statically (without forward or backward passes) locate topical knowledge in the weight space of an LLM, building on a prior insight that parameters can be decoded into interpretable tokens. If parameters can be mapped into the embedding space, it should be possible to directly search for knowledge via embedding similarity. We study the validity of this assumption across several LLMs for a variety of concepts in the financial domain and a toxicity detection setup. Our analysis yields an improved understanding of the promises and limitations of static knowledge location in real-world scenarios.","Armengol-Estap{\'e}, Jordi, Li, Lingyu, Gehrmann, Sebastian, Gopal, Achintya, Rosenberg, David S, Mann, Gideon S., Dredze, Mark",,,Can We Statically Locate Knowledge in Large Language Models? Financial Domain and Toxicity Reduction Case Studies,,,10.18653/v1/2024.blackboxnlp-1.9 , ,,"Current large language model (LLM) evaluations rely on benchmarks to assess model capabilities and their encoded knowledge. However, these evaluations cannot reveal where a model encodes its knowledge, and thus little is known about which weights contain specific information. We propose a method to statically (without forward or backward passes) locate topical knowledge in the weight space of an LLM, building on a prior insight that parameters can be decoded into interpretable tokens. If parameters can be mapped into the embedding space, it should be possible to directly search for knowledge via embedding similarity. We study the validity of this assumption across several LLMs for a variety of concepts in the financial domain and a toxicity detection setup. Our analysis yields an improved understanding of the promises and limitations of static knowledge location in real-world scenarios.",,,,, ,  Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP,,detox,
3388,"**Title**Automated Ableism: An Exploration of Explicit Disability Biases in Sentiment and Toxicity Analysis Models

**Abstract**We analyze sentiment analysis and toxicity detection models to detect the presence of explicit bias against people with disability (PWD). We employ the bias identification framework of Perturbation Sensitivity Analysis to examine conversations related to PWD on social media platforms, specifically Twitter and Reddit, in order to gain insight into how disability bias is disseminated in real-world social settings. We then create the Bias Identification Test in Sentiment (BITS) corpus to quantify explicit disability bias in any sentiment analysis and toxicity detection models. Our study utilizes BITS to uncover significant biases in four open AIaaS (AI as a Service) sentiment analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API, DistilBERT and two toxicity detection models, namely two versions of Toxic-BERT. Our findings indicate that all of these models exhibit statistically significant explicit bias against PWD.","Narayanan Venkit, Pranav, Srinath, Mukund, Wilson, Shomir",,,Automated Ableism: An Exploration of Explicit Disability Biases in Sentiment and Toxicity Analysis Models,,,10.18653/v1/2023.trustnlp-1.3 , ,,"We analyze sentiment analysis and toxicity detection models to detect the presence of explicit bias against people with disability (PWD). We employ the bias identification framework of Perturbation Sensitivity Analysis to examine conversations related to PWD on social media platforms, specifically Twitter and Reddit, in order to gain insight into how disability bias is disseminated in real-world social settings. We then create the Bias Identification Test in Sentiment (BITS) corpus to quantify explicit disability bias in any sentiment analysis and toxicity detection models. Our study utilizes BITS to uncover significant biases in four open AIaaS (AI as a Service) sentiment analysis tools, namely TextBlob, VADER, Google Cloud Natural Language API, DistilBERT and two toxicity detection models, namely two versions of Toxic-BERT. Our findings indicate that all of these models exhibit statistically significant explicit bias against PWD.",,,,, ,  Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023),,detection#evaluation,
3389,"**Title**Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values

**Abstract**Many NLP classification tasks, such as sexism/racism detection or toxicity detection, are based on human values. Yet, human values can vary under diverse cultural conditions. Therefore, we introduce a framework for value-aligned classification that performs prediction based on explicitly written human values in the command. Along with the task, we propose a practical approach that distills value-aligned knowledge from large-scale language models (LLMs) to construct value-aligned classifiers in two steps. First, we generate value-aligned training data from LLMs by prompt-based few-shot learning. Next, we fine-tune smaller classification models with the generated data for the task. Empirical results show that our VA-Models surpass multiple baselines by at least 15.56{\%} on the F1-score, including few-shot learning with OPT-175B and existing text augmentation methods. We suggest that using classifiers with explicit human value input improves both inclusivity {\&} explainability in AI.","Bang, Yejin, Yu, Tiezheng, Madotto, Andrea, Lin, Zhaojiang, Diab, Mona, Fung, Pascale",,,Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values,,,10.18653/v1/2023.trustnlp-1.27 , ,,"Many NLP classification tasks, such as sexism/racism detection or toxicity detection, are based on human values. Yet, human values can vary under diverse cultural conditions. Therefore, we introduce a framework for value-aligned classification that performs prediction based on explicitly written human values in the command. Along with the task, we propose a practical approach that distills value-aligned knowledge from large-scale language models (LLMs) to construct value-aligned classifiers in two steps. First, we generate value-aligned training data from LLMs by prompt-based few-shot learning. Next, we fine-tune smaller classification models with the generated data for the task. Empirical results show that our VA-Models surpass multiple baselines by at least 15.56{\%} on the F1-score, including few-shot learning with OPT-175B and existing text augmentation methods. We suggest that using classifiers with explicit human value input improves both inclusivity {\&} explainability in AI.",,,,, ,  Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023),,detection,
3390,"**Title**{LEXPLAIN}: Improving Model Explanations via Lexicon Supervision

**Abstract**Model explanations that shed light on the model`s predictions are becoming a desired additional output of NLP models, alongside their predictions. Challenges in creating these explanations include making them trustworthy and faithful to the model`s predictions. In this work, we propose a novel framework for guiding model explanations by supervising them explicitly. To this end, our method, LEXplain, uses task-related lexicons to directly supervise model explanations. This approach consistently improves the model`s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection. Our analyses show that our method also demotes spurious correlations (i.e., with respect to African American English dialect) when performing the task, improving fairness.","Ahia, Orevaoghene, Gonen, Hila, Balachandran, Vidhisha, Tsvetkov, Yulia, Smith, Noah A.",,,{LEXPLAIN}: Improving Model Explanations via Lexicon Supervision,,,10.18653/v1/2023.starsem-1.19 , ,,"Model explanations that shed light on the model`s predictions are becoming a desired additional output of NLP models, alongside their predictions. Challenges in creating these explanations include making them trustworthy and faithful to the model`s predictions. In this work, we propose a novel framework for guiding model explanations by supervising them explicitly. To this end, our method, LEXplain, uses task-related lexicons to directly supervise model explanations. This approach consistently improves the model`s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection. Our analyses show that our method also demotes spurious correlations (i.e., with respect to African American English dialect) when performing the task, improving fairness.",,,,, ,  Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023),,detection,
3391,"**Title**{IREL} at {S}em{E}val-2023 Task 11: User Conditioned Modelling for Toxicity Detection in Subjective Tasks

**Abstract**This paper describes our system used in the SemEval-2023 Task 11 Learning With Disagreements (Le-Wi-Di). This is a subjective task since it deals with detecting hate speech, misogyny and offensive language. Thus, disagreement among annotators is expected. We experiment with different settings like loss functions specific for subjective tasks and include anonymized annotator-specific information to help us understand the level of disagreement. We perform an in-depth analysis of the performance discrepancy of these different modelling choices. Our system achieves a cross-entropy of 0.58, 4.01 and 3.70 on the test sets of HS-Brexit, ArMIS and MD-Agreement, respectively. Our code implementation is publicly available.","Maity, Ankita, Kandru, Pavan, Singh, Bhavyajeet, Aditya Hari, Kancharla, Varma, Vasudeva",,,{IREL} at {S}em{E}val-2023 Task 11: User Conditioned Modelling for Toxicity Detection in Subjective Tasks,,,10.18653/v1/2023.semeval-1.294 , ,,"This paper describes our system used in the SemEval-2023 Task 11 Learning With Disagreements (Le-Wi-Di). This is a subjective task since it deals with detecting hate speech, misogyny and offensive language. Thus, disagreement among annotators is expected. We experiment with different settings like loss functions specific for subjective tasks and include anonymized annotator-specific information to help us understand the level of disagreement. We perform an in-depth analysis of the performance discrepancy of these different modelling choices. Our system achieves a cross-entropy of 0.58, 4.01 and 3.70 on the test sets of HS-Brexit, ArMIS and MD-Agreement, respectively. Our code implementation is publicly available.",,,,, ,  Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023),,detection,
3392,"**Title**Toxicity Detection in {F}innish Using Machine Translation

**Abstract**Due to the popularity of social media platforms and the sheer amount of user-generated content online, the automatic detection of toxic language has become crucial in the creation of a friendly and safe digital space. Previous work has been mostly focusing on English leaving many lower-resource languages behind. In this paper, we present novel resources for toxicity detection in Finnish by introducing two new datasets, a machine translated toxicity dataset for Finnish based on the widely used English Jigsaw dataset and a smaller test set of Suomi24 discussion forum comments originally written in Finnish and manually annotated following the definitions of the labels that were used to annotate the Jigsaw dataset. We show that machine translating the training data to Finnish provides better toxicity detection results than using the original English training data and zero-shot cross-lingual transfer with XLM-R, even with our newly annotated dataset from Suomi24.","Eskelinen, Anni, Silvala, Laura, Ginter, Filip, Pyysalo, Sampo, Laippala, Veronika",,,Toxicity Detection in {F}innish Using Machine Translation,,, , ,,"Due to the popularity of social media platforms and the sheer amount of user-generated content online, the automatic detection of toxic language has become crucial in the creation of a friendly and safe digital space. Previous work has been mostly focusing on English leaving many lower-resource languages behind. In this paper, we present novel resources for toxicity detection in Finnish by introducing two new datasets, a machine translated toxicity dataset for Finnish based on the widely used English Jigsaw dataset and a smaller test set of Suomi24 discussion forum comments originally written in Finnish and manually annotated following the definitions of the labels that were used to annotate the Jigsaw dataset. We show that machine translating the training data to Finnish provides better toxicity detection results than using the original English training data and zero-shot cross-lingual transfer with XLM-R, even with our newly annotated dataset from Suomi24.",,,,, ,  Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa),,out_but_toxicity,
3393,"**Title**No offence, Bert - {I} insult only humans! Multilingual sentence-level attack on toxicity detection networks

**Abstract**We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations.","Berezin, Sergey, Farahbakhsh, Reza, Crespi, Noel",,,"No offence, Bert - {I} insult only humans! Multilingual sentence-level attack on toxicity detection networks",,,10.18653/v1/2023.findings-emnlp.155 , ,,"We introduce a simple yet efficient sentence-level attack on black-box toxicity detector models. By adding several positive words or sentences to the end of a hateful message, we are able to change the prediction of a neural network and pass the toxicity detection system check. This approach is shown to be working on seven languages from three different language families. We also describe the defence mechanism against the aforementioned attack and discuss its limitations.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detection,
3394,"**Title**{T}oxic{C}hat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-{AI} Conversation

**Abstract**Despite remarkable advances that large language models have achieved in chatbots nowadays, maintaining a non-toxic user-AI interactive environment has become increasingly critical nowadays. However, previous efforts in toxicity detection have been mostly based on benchmarks derived from social media contents, leaving the unique challenges inherent to real-world user-AI interactions insufficiently explored. In this work, we introduce ToxicChat, a novel benchmark constructed based on real user queries from an open-source chatbot. This benchmark contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify, revealing a significant domain difference when compared to social media contents. Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat. Our work illuminates the potentially overlooked challenges of toxicity detection in real-world user-AI conversations. In the future, ToxicChat can be a valuable resource to drive further advancements toward building a safe and healthy environment for user-AI interactions.","Lin, Zi, Wang, Zihan, Tong, Yongqi, Wang, Yangkun, Guo, Yuxin, Wang, Yujia, Shang, Jingbo",,,{T}oxic{C}hat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-{AI} Conversation,,,10.18653/v1/2023.findings-emnlp.311 , ,,"Despite remarkable advances that large language models have achieved in chatbots nowadays, maintaining a non-toxic user-AI interactive environment has become increasingly critical nowadays. However, previous efforts in toxicity detection have been mostly based on benchmarks derived from social media contents, leaving the unique challenges inherent to real-world user-AI interactions insufficiently explored. In this work, we introduce ToxicChat, a novel benchmark constructed based on real user queries from an open-source chatbot. This benchmark contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify, revealing a significant domain difference when compared to social media contents. Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat. Our work illuminates the potentially overlooked challenges of toxicity detection in real-world user-AI conversations. In the future, ToxicChat can be a valuable resource to drive further advancements toward building a safe and healthy environment for user-AI interactions.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,Gen_dataset#detection,
3395,"**Title**Towards Detecting Contextual Real-Time Toxicity for In-Game Chat

**Abstract**Real-time toxicity detection in online environments poses a significant challenge, due to the increasing prevalence of social media and gaming platforms. We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata. ToxBuster consistently outperforms conventional toxicity models across popular multiplayer games, including Rainbow Six Siege, For Honor, and DOTA 2. We conduct an ablation study to assess the importance of each model component and explore ToxBuster`s transferability across the datasets. Furthermore, we showcase ToxBuster`s efficacy in post-game moderation, successfully flagging 82.1{\%} of chat-reported players at a precision level of 90.0{\%}. Additionally, we show how an additional 6{\%} of unreported toxic players can be proactively moderated.","Yang, Zachary, Grenon-Godbout, Nicolas, Rabbany, Reihaneh",,,Towards Detecting Contextual Real-Time Toxicity for In-Game Chat,,,10.18653/v1/2023.findings-emnlp.663 , ,,"Real-time toxicity detection in online environments poses a significant challenge, due to the increasing prevalence of social media and gaming platforms. We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata. ToxBuster consistently outperforms conventional toxicity models across popular multiplayer games, including Rainbow Six Siege, For Honor, and DOTA 2. We conduct an ablation study to assess the importance of each model component and explore ToxBuster`s transferability across the datasets. Furthermore, we showcase ToxBuster`s efficacy in post-game moderation, successfully flagging 82.1{\%} of chat-reported players at a precision level of 90.0{\%}. Additionally, we show how an additional 6{\%} of unreported toxic players can be proactively moderated.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detection,
3396,"**Title**Evaluation of {A}frican {A}merican Language Bias in Natural Language Generation

**Abstract**While biases disadvantaging African American Language (AAL) have been uncovered in models for tasks such as speech recognition and toxicity detection, there has been little investigation of these biases for language generation models like ChatGPT. We evaluate how well LLMs understand AAL in comparison to White Mainstream English (WME), the encouraged {\textquotedblleft}standard{\textquotedblright} form of English taught in American classrooms. We measure large language model performance on two tasks: a counterpart generation task, where a model generates AAL given WME and vice versa, and a masked span prediction (MSP) task, where models predict a phrase hidden from their input. Using a novel dataset of AAL texts from a variety of regions and contexts, we present evidence of dialectal bias for six pre-trained LLMs through performance gaps on these tasks.","Deas, Nicholas, Grieser, Jessica, Kleiner, Shana, Patton, Desmond, Turcan, Elsbeth, McKeown, Kathleen",,,Evaluation of {A}frican {A}merican Language Bias in Natural Language Generation,,,10.18653/v1/2023.emnlp-main.421 , ,,"While biases disadvantaging African American Language (AAL) have been uncovered in models for tasks such as speech recognition and toxicity detection, there has been little investigation of these biases for language generation models like ChatGPT. We evaluate how well LLMs understand AAL in comparison to White Mainstream English (WME), the encouraged {\textquotedblleft}standard{\textquotedblright} form of English taught in American classrooms. We measure large language model performance on two tasks: a counterpart generation task, where a model generates AAL given WME and vice versa, and a masked span prediction (MSP) task, where models predict a phrase hidden from their input. Using a novel dataset of AAL texts from a variety of regions and contexts, we present evidence of dialectal bias for six pre-trained LLMs through performance gaps on these tasks.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_but_toxicity,
3397,"**Title**Accounting for Offensive Speech as a Practice of Resistance

**Abstract**Tasks such as toxicity detection, hate speech detection, and online harassment detection have been developed for identifying interactions involving offensive speech. In this work we articulate the need for a relational understanding of offensiveness to help distinguish denotative offensive speech from offensive speech serving as a mechanism through which marginalized communities resist oppressive social norms. Using examples from the queer community, we argue that evaluations of offensive speech must focus on the impacts of language use. We call this the cynic perspective{--} or a characteristic of language with roots in Cynic philosophy that pertains to employing offensive speech as a practice of resistance. We also explore the degree to which NLP systems may encounter limits to modeling relational context.","Diaz, Mark, Amironesei, Razvan, Weidinger, Laura, Gabriel, Iason",,,Accounting for Offensive Speech as a Practice of Resistance,,,10.18653/v1/2022.woah-1.18 , ,,"Tasks such as toxicity detection, hate speech detection, and online harassment detection have been developed for identifying interactions involving offensive speech. In this work we articulate the need for a relational understanding of offensiveness to help distinguish denotative offensive speech from offensive speech serving as a mechanism through which marginalized communities resist oppressive social norms. Using examples from the queer community, we argue that evaluations of offensive speech must focus on the impacts of language use. We call this the cynic perspective{--} or a characteristic of language with roots in Cynic philosophy that pertains to employing offensive speech as a practice of resistance. We also explore the degree to which NLP systems may encounter limits to modeling relational context.",,,,, ,  Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH),,detection,
3398,"**Title**Bias Discovery within Human Raters: A Case Study of the Jigsaw Dataset

**Abstract**Understanding and quantifying the bias introduced by human annotation of data is a crucial problem for trustworthy supervised learning. Recently, a perspectivist trend has emerged in the NLP community, focusing on the inadequacy of previous aggregation schemes, which suppose the existence of single ground truth. This assumption is particularly problematic for sensitive tasks involving subjective human judgments, such as toxicity detection. To address these issues, we propose a preliminary approach for bias discovery within human raters by exploring individual ratings for specific sensitive topics annotated in the texts. Our analysis`s object consists of the Jigsaw dataset, a collection of comments aiming at challenging online toxicity identification.","Marchiori Manerba, Marta, Guidotti, Riccardo, Passaro, Lucia, Ruggieri, Salvatore",,,Bias Discovery within Human Raters: A Case Study of the Jigsaw Dataset,,, , ,,"Understanding and quantifying the bias introduced by human annotation of data is a crucial problem for trustworthy supervised learning. Recently, a perspectivist trend has emerged in the NLP community, focusing on the inadequacy of previous aggregation schemes, which suppose the existence of single ground truth. This assumption is particularly problematic for sensitive tasks involving subjective human judgments, such as toxicity detection. To address these issues, we propose a preliminary approach for bias discovery within human raters by exploring individual ratings for specific sensitive topics annotated in the texts. Our analysis`s object consists of the Jigsaw dataset, a collection of comments aiming at challenging online toxicity identification.",,,,, ,  Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022,,Use_dataset#evaluation,
3399,"**Title**Critical Perspectives: A Benchmark Revealing Pitfalls in {P}erspective{API}

**Abstract**Detecting {\textquotedblleft}toxic{\textquotedblright} language in internet content is a pressing social and technical challenge. In this work, we focus on Perspective API from Jigsaw, a state-of-the-art tool that promises to score the {\textquotedblleft}toxicity{\textquotedblright} of text, with a recent model update that claims impressive results (Lees et al., 2022). We seek to challenge certain normative claims about toxic language by proposing a new benchmark, Selected Adversarial SemanticS, or SASS. We evaluate Perspective on SASS, and compare to low-effort alternatives, like zero-shot and few-shot GPT-3 prompt models, in binary classification settings. We find that Perspective exhibits troubling shortcomings across a number of our toxicity categories. SASS provides a new tool for evaluating performance on previously undetected toxic language that avoids common normative pitfalls. Our work leads us to emphasize the importance of questioning assumptions made by tools already in deployment for toxicity detection in order to anticipate and prevent disparate harms.","Rosenblatt, Lucas, Piedras, Lorena, Wilkins, Julia",,,Critical Perspectives: A Benchmark Revealing Pitfalls in {P}erspective{API},,,10.18653/v1/2022.nlp4pi-1.2 , ,,"Detecting {\textquotedblleft}toxic{\textquotedblright} language in internet content is a pressing social and technical challenge. In this work, we focus on Perspective API from Jigsaw, a state-of-the-art tool that promises to score the {\textquotedblleft}toxicity{\textquotedblright} of text, with a recent model update that claims impressive results (Lees et al., 2022). We seek to challenge certain normative claims about toxic language by proposing a new benchmark, Selected Adversarial SemanticS, or SASS. We evaluate Perspective on SASS, and compare to low-effort alternatives, like zero-shot and few-shot GPT-3 prompt models, in binary classification settings. We find that Perspective exhibits troubling shortcomings across a number of our toxicity categories. SASS provides a new tool for evaluating performance on previously undetected toxic language that avoids common normative pitfalls. Our work leads us to emphasize the importance of questioning assumptions made by tools already in deployment for toxicity detection in order to anticipate and prevent disparate harms.",,,,, ,  Proceedings of the Second Workshop on NLP for Positive Impact (NLP4PI),,detection#evaluation#methodology,
3400,"**Title**What changed? Investigating Debiasing Methods using Causal Mediation Analysis

**Abstract**Previous work has examined how debiasing language models affect downstream tasks, specifically, how debiasing techniques influence task performance and whether debiased models also make impartial predictions in downstream tasks or not. However, what we don`t understand well yet is why debiasing methods have varying impacts on downstream tasks and how debiasing techniques affect internal components of language models, i.e., neurons, layers, and attentions. In this paper, we decompose the internal mechanisms of debiasing language models with respect to gender by applying causal mediation analysis to understand the influence of debiasing methods on toxicity detection as a downstream task. Our findings suggest a need to test the effectiveness of debiasing methods with different bias metrics, and to focus on changes in the behavior of certain components of the models, e.g.,first two layers of language models, and attention heads.","Jeoung, Sullam, Diesner, Jana",,,What changed? Investigating Debiasing Methods using Causal Mediation Analysis,,,10.18653/v1/2022.gebnlp-1.26 , ,,"Previous work has examined how debiasing language models affect downstream tasks, specifically, how debiasing techniques influence task performance and whether debiased models also make impartial predictions in downstream tasks or not. However, what we don`t understand well yet is why debiasing methods have varying impacts on downstream tasks and how debiasing techniques affect internal components of language models, i.e., neurons, layers, and attentions. In this paper, we decompose the internal mechanisms of debiasing language models with respect to gender by applying causal mediation analysis to understand the influence of debiasing methods on toxicity detection as a downstream task. Our findings suggest a need to test the effectiveness of debiasing methods with different bias metrics, and to focus on changes in the behavior of certain components of the models, e.g.,first two layers of language models, and attention heads.",,,,, ,  Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP),,detection,
3401,"**Title**Detecting Cross-Geographic Biases in Toxicity Modeling on Social Media

**Abstract**Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to marginalized groups, potentially furthering disproportionate harms towards them. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations/lexicons available. Consequently, biases concerning non-Western contexts are largely ignored in the literature. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts. We also conduct analysis of a model trained on a dataset with ground truth labels to better understand these biases, and present preliminary mitigation experiments.","Ghosh, Sayan, Baker, Dylan, Jurgens, David, Prabhakaran, Vinodkumar",,,Detecting Cross-Geographic Biases in Toxicity Modeling on Social Media,,,10.18653/v1/2021.wnut-1.35 , ,,"Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to marginalized groups, potentially furthering disproportionate harms towards them. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations/lexicons available. Consequently, biases concerning non-Western contexts are largely ignored in the literature. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts. We also conduct analysis of a model trained on a dataset with ground truth labels to better understand these biases, and present preliminary mitigation experiments.",,,,, ,  Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021),,detection,
3402,"**Title**{T}ox{CCI}n: Toxic Content Classification with Interpretability

**Abstract**Despite the recent successes of transformer-based models in terms of effectiveness on a variety of tasks, their decisions often remain opaque to humans. Explanations are particularly important for tasks like offensive language or toxicity detection on social media because a manual appeal process is often in place to dispute automatically flagged content. In this work, we propose a technique to improve the interpretability of these models, based on a simple and powerful assumption: a post is at least as toxic as its most toxic span. We incorporate this assumption into transformer models by scoring a post based on the maximum toxicity of its spans and augmenting the training process to identify correct spans. We find this approach effective and can produce explanations that exceed the quality of those provided by Logistic Regression analysis (often regarded as a highly-interpretable model), according to a human study.","Xiang, Tong, MacAvaney, Sean, Yang, Eugene, Goharian, Nazli",,,{T}ox{CCI}n: Toxic Content Classification with Interpretability,,, , ,,"Despite the recent successes of transformer-based models in terms of effectiveness on a variety of tasks, their decisions often remain opaque to humans. Explanations are particularly important for tasks like offensive language or toxicity detection on social media because a manual appeal process is often in place to dispute automatically flagged content. In this work, we propose a technique to improve the interpretability of these models, based on a simple and powerful assumption: a post is at least as toxic as its most toxic span. We incorporate this assumption into transformer models by scoring a post based on the maximum toxicity of its spans and augmenting the training process to identify correct spans. We find this approach effective and can produce explanations that exceed the quality of those provided by Logistic Regression analysis (often regarded as a highly-interpretable model), according to a human study.",,,,, ,"  Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,detection,
3403,"**Title**{UPB} at {S}em{E}val-2021 Task 5: Virtual Adversarial Training for Toxic Spans Detection

**Abstract**The real-world impact of polarization and toxicity in the online sphere marked the end of 2020 and the beginning of this year in a negative way. Semeval-2021, Task 5 - Toxic Spans Detection is based on a novel annotation of a subset of the Jigsaw Unintended Bias dataset and is the first language toxicity detection task dedicated to identifying the toxicity-level spans. For this task, participants had to automatically detect character spans in short comments that render the message as toxic. Our model considers applying Virtual Adversarial Training in a semi-supervised setting during the fine-tuning process of several Transformer-based models (i.e., BERT and RoBERTa), in combination with Conditional Random Fields. Our approach leads to performance improvements and more robust models, enabling us to achieve an F1-score of 65.73{\%} in the official submission and an F1-score of 66.13{\%} after further tuning during post-evaluation.","Paraschiv, Andrei, Cercel, Dumitru-Clementin, Dascalu, Mihai",,,{UPB} at {S}em{E}val-2021 Task 5: Virtual Adversarial Training for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.26 , ,,"The real-world impact of polarization and toxicity in the online sphere marked the end of 2020 and the beginning of this year in a negative way. Semeval-2021, Task 5 - Toxic Spans Detection is based on a novel annotation of a subset of the Jigsaw Unintended Bias dataset and is the first language toxicity detection task dedicated to identifying the toxicity-level spans. For this task, participants had to automatically detect character spans in short comments that render the message as toxic. Our model considers applying Virtual Adversarial Training in a semi-supervised setting during the fine-tuning process of several Transformer-based models (i.e., BERT and RoBERTa), in combination with Conditional Random Fields. Our approach leads to performance improvements and more robust models, enabling us to achieve an F1-score of 65.73{\%} in the official submission and an F1-score of 66.13{\%} after further tuning during post-evaluation.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3404,"**Title**{NLRG} at {S}em{E}val-2021 Task 5: Toxic Spans Detection Leveraging {BERT}-based Token Classification and Span Prediction Techniques

**Abstract**Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within English passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models - BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches - Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission - a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions - achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3{\%} on average than those of the shared baseline models - RNNSL and SpaCy NER.","Chhablani, Gunjan, Sharma, Abheesht, Pandey, Harshit, Bhartia, Yash, Suthaharan, Shan",,,{NLRG} at {S}em{E}val-2021 Task 5: Toxic Spans Detection Leveraging {BERT}-based Token Classification and Span Prediction Techniques,,,10.18653/v1/2021.semeval-1.27 , ,,"Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within English passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models - BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches - Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission - a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions - achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3{\%} on average than those of the shared baseline models - RNNSL and SpaCy NER.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3405,"**Title**Can We Improve Model Robustness through Secondary Attribute Counterfactuals?

**Abstract**Developing robust NLP models that perform well on many, even small, slices of data is a significant but important challenge, with implications from fairness to general reliability. To this end, recent research has explored how models rely on spurious correlations, and how counterfactual data augmentation (CDA) can mitigate such issues. In this paper we study how and why modeling counterfactuals over multiple attributes can go significantly further in improving model performance. We propose RDI, a context-aware methodology which takes into account the impact of secondary attributes on the model`s predictions and increases sensitivity for secondary attributes over reweighted counterfactually augmented data. By implementing RDI in the context of toxicity detection, we find that accounting for secondary attributes can significantly improve robustness, with improvements in sliced accuracy on the original dataset up to 7{\%} compared to existing robustness methods. We also demonstrate that RDI generalizes to the coreference resolution task and provide guidelines to extend this to other tasks.","Balashankar, Ananth, Wang, Xuezhi, Packer, Ben, Thain, Nithum, Chi, Ed, Beutel, Alex",,,Can We Improve Model Robustness through Secondary Attribute Counterfactuals?,,,10.18653/v1/2021.emnlp-main.386 , ,,"Developing robust NLP models that perform well on many, even small, slices of data is a significant but important challenge, with implications from fairness to general reliability. To this end, recent research has explored how models rely on spurious correlations, and how counterfactual data augmentation (CDA) can mitigate such issues. In this paper we study how and why modeling counterfactuals over multiple attributes can go significantly further in improving model performance. We propose RDI, a context-aware methodology which takes into account the impact of secondary attributes on the model`s predictions and increases sensitivity for secondary attributes over reweighted counterfactually augmented data. By implementing RDI in the context of toxicity detection, we find that accounting for secondary attributes can significantly improve robustness, with improvements in sliced accuracy on the original dataset up to 7{\%} compared to existing robustness methods. We also demonstrate that RDI generalizes to the coreference resolution task and provide guidelines to extend this to other tasks.",,,,, ,  Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,,detection,
3406,"**Title**A {D}utch Dataset for Cross-lingual Multilabel Toxicity Detection

**Abstract**Multi-label toxicity detection is highly prominent, with many research groups, companies, and individuals engaging with it through shared tasks and dedicated venues. This paper describes a cross-lingual approach to annotating multi-label text classification on a newly developed Dutch language dataset, using a model trained on English data. We present an ensemble model of one Transformer model and an LSTM using Multilingual embeddings. The combination of multilingual embeddings and the Transformer model improves performance in a cross-lingual setting.","Burtenshaw, Ben, Kestemont, Mike",,,A {D}utch Dataset for Cross-lingual Multilabel Toxicity Detection,,, , ,,"Multi-label toxicity detection is highly prominent, with many research groups, companies, and individuals engaging with it through shared tasks and dedicated venues. This paper describes a cross-lingual approach to annotating multi-label text classification on a newly developed Dutch language dataset, using a model trained on English data. We present an ensemble model of one Transformer model and an LSTM using Multilingual embeddings. The combination of multilingual embeddings and the Transformer model improves performance in a cross-lingual setting.",,,,, ,  Proceedings of the 14th Workshop on Building and Using Comparable Corpora (BUCC 2021),,out_but_toxicity,
3407,"**Title**Weight Poisoning Attacks on Pretrained Models

**Abstract**Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct {\textquotedblleft}weight poisoning{\textquotedblright} attacks where pre-trained weights are injected with vulnerabilities that expose {\textquotedblleft}backdoors{\textquotedblright} after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method which we call RIPPLe and an initialization procedure we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks.","Kurita, Keita, Michel, Paul, Neubig, Graham",,,Weight Poisoning Attacks on Pretrained Models,,,10.18653/v1/2020.acl-main.249 , ,,"Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct {\textquotedblleft}weight poisoning{\textquotedblright} attacks where pre-trained weights are injected with vulnerabilities that expose {\textquotedblleft}backdoors{\textquotedblright} after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method which we call RIPPLe and an initialization procedure we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks.",,,,, ,  Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,,detection,
3408,"**Title**{C}onv{AI} at {S}em{E}val-2019 Task 6: Offensive Language Identification and Categorization with Perspective and {BERT}

**Abstract**This paper presents the application of two strong baseline systems for toxicity detection and evaluates their performance in identifying and categorizing offensive language in social media. PERSPECTIVE is an API, that serves multiple machine learning models for the improvement of conversations online, as well as a toxicity detection system, trained on a wide variety of comments from platforms across the Internet. BERT is a recently popular language representation model, fine tuned per task and achieving state of the art performance in multiple NLP tasks. PERSPECTIVE performed better than BERT in detecting toxicity, but BERT was much better in categorizing the offensive type. Both baselines were ranked surprisingly high in the SEMEVAL-2019 OFFENSEVAL competition, PERSPECTIVE in detecting an offensive post (12th) and BERT in categorizing it (11th). The main contribution of this paper is the assessment of two strong baselines for the identification (PERSPECTIVE) and the categorization (BERT) of offensive language with little or no additional training data.","Pavlopoulos, John, Thain, Nithum, Dixon, Lucas, Androutsopoulos, Ion",,,{C}onv{AI} at {S}em{E}val-2019 Task 6: Offensive Language Identification and Categorization with Perspective and {BERT},,,10.18653/v1/S19-2102 , ,,"This paper presents the application of two strong baseline systems for toxicity detection and evaluates their performance in identifying and categorizing offensive language in social media. PERSPECTIVE is an API, that serves multiple machine learning models for the improvement of conversations online, as well as a toxicity detection system, trained on a wide variety of comments from platforms across the Internet. BERT is a recently popular language representation model, fine tuned per task and achieving state of the art performance in multiple NLP tasks. PERSPECTIVE performed better than BERT in detecting toxicity, but BERT was much better in categorizing the offensive type. Both baselines were ranked surprisingly high in the SEMEVAL-2019 OFFENSEVAL competition, PERSPECTIVE in detecting an offensive post (12th) and BERT in categorizing it (11th). The main contribution of this paper is the assessment of two strong baselines for the identification (PERSPECTIVE) and the categorization (BERT) of offensive language with little or no additional training data.",,,,, ,  Proceedings of the 13th International Workshop on Semantic Evaluation,,detection,
3409,"**Title**{M}ulti{P}ara{D}etox: Extending Text Detoxification with Parallel Data to New Languages

**Abstract**Text detoxification is a textual style transfer (TST) task where a text is paraphrased from a toxic surface form, e.g. featuring rude words, to the neutral register. Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic speech combating in social networks (Deng et al., 2023; Mun et al., 2023; Agarwal et al., 2023). All these applications are extremely important to ensure safe communication in modern digital worlds. However, the previous approaches for parallel text detoxification corpora collection{---}ParaDetox (Logacheva et al., 2022) and APPADIA (Atwell et al., 2022){---}were explored only in monolingual setup. In this work, we aim to extend ParaDetox pipeline to multiple languages presenting MultiParaDetox to automate parallel detoxification corpus collection for potentially any language. Then, we experiment with different text detoxification models{---}from unsupervised baselines to LLMs and fine-tuned models on the presented parallel corpora{---}showing the great benefit of parallel corpus presence to obtain state-of-the-art text detoxification models for any language.","Dementieva, Daryna, Babakov, Nikolay, Panchenko, Alexander",,,{M}ulti{P}ara{D}etox: Extending Text Detoxification with Parallel Data to New Languages,,,10.18653/v1/2024.naacl-short.12 , ,,"Text detoxification is a textual style transfer (TST) task where a text is paraphrased from a toxic surface form, e.g. featuring rude words, to the neutral register. Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic speech combating in social networks (Deng et al., 2023; Mun et al., 2023; Agarwal et al., 2023). All these applications are extremely important to ensure safe communication in modern digital worlds. However, the previous approaches for parallel text detoxification corpora collection{---}ParaDetox (Logacheva et al., 2022) and APPADIA (Atwell et al., 2022){---}were explored only in monolingual setup. In this work, we aim to extend ParaDetox pipeline to multiple languages presenting MultiParaDetox to automate parallel detoxification corpus collection for potentially any language. Then, we experiment with different text detoxification models{---}from unsupervised baselines to LLMs and fine-tuned models on the presented parallel corpora{---}showing the great benefit of parallel corpus presence to obtain state-of-the-art text detoxification models for any language.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers),,detox,
3410,"**Title**Are Large Language Models Actually Good at Text Style Transfer?

**Abstract**We analyze the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. Text Style Transfer involves modifying the linguistic style of a text while preserving its core content. We evaluate the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. Our evaluation using automatic metrics, GPT-4 and human evaluations reveals that while some prompted LLMs perform well in English, their performance in on other languages (Hindi, Bengali) remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art. This underscores the necessity of dedicated datasets and specialized models for effective TST.","Mukherjee, Sourabrata, Ojha, Atul Kr., Dusek, Ondrej",,,Are Large Language Models Actually Good at Text Style Transfer?,,, , ,,"We analyze the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. Text Style Transfer involves modifying the linguistic style of a text while preserving its core content. We evaluate the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. Our evaluation using automatic metrics, GPT-4 and human evaluations reveals that while some prompted LLMs perform well in English, their performance in on other languages (Hindi, Bengali) remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art. This underscores the necessity of dedicated datasets and specialized models for effective TST.",,,,, ,  Proceedings of the 17th International Natural Language Generation Conference,,out_but_toxicity,
3411,"**Title**{LLM}s to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification

**Abstract**The lack of high-quality training data remains a significant challenge in NLP. Manual annotation methods, such as crowdsourcing, are costly, require intricate task design skills, and, if used incorrectly, may result in poor data quality. From the other hand, LLMs have demonstrated proficiency in many NLP tasks, including zero-shot and few-shot data annotation. However, they often struggle with text detoxification due to alignment constraints and fail to generate the required detoxified text. This work explores the potential of modern open source LLMs to annotate parallel data for text detoxification. Using the recent technique of activation patching, we generate a pseudo-parallel detoxification dataset based on ParaDetox. The detoxification model trained on our generated data shows comparable performance to the original dataset in automatic detoxification evaluation metrics and superior quality in manual evaluation and side-by-side comparisons.","Moskovskiy, Daniil, Pletenev, Sergey, Panchenko, Alexander",,,{LLM}s to Replace Crowdsourcing For Parallel Data Creation? The Case of Text Detoxification,,,10.18653/v1/2024.findings-emnlp.839 , ,,"The lack of high-quality training data remains a significant challenge in NLP. Manual annotation methods, such as crowdsourcing, are costly, require intricate task design skills, and, if used incorrectly, may result in poor data quality. From the other hand, LLMs have demonstrated proficiency in many NLP tasks, including zero-shot and few-shot data annotation. However, they often struggle with text detoxification due to alignment constraints and fail to generate the required detoxified text. This work explores the potential of modern open source LLMs to annotate parallel data for text detoxification. Using the recent technique of activation patching, we generate a pseudo-parallel detoxification dataset based on ParaDetox. The detoxification model trained on our generated data shows comparable performance to the original dataset in automatic detoxification evaluation metrics and superior quality in manual evaluation and side-by-side comparisons.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detox,
3412,"**Title**{CMD}: a framework for Context-aware Model self-Detoxification

**Abstract**Text detoxification aims to minimize the risk of language models producing toxic content. Existing detoxification methods of directly constraining the model output or further training the model on the non-toxic corpus fail to achieve a decent balance between detoxification effectiveness and generation quality. This issue stems from the neglect of constrain imposed by the context since language models are designed to generate output that closely matches the context while detoxification methods endeavor to ensure the safety of the output even if it semantically deviates from the context. In view of this, we introduce a Context-aware Model self-Detoxification (CMD) framework that pays attention to both the context and the detoxification process, i.e., first detoxifying the context and then making the language model generate along the safe context. Specifically, CMD framework involves two phases: utilizing language models to synthesize data and applying these data for training. We also introduce a toxic contrastive loss that encourages the model generation away from the negative toxic samples. Experiments on various LLMs have verified the effectiveness of our MSD framework, which can yield the best performance compared to baselines.","Tang, Zecheng, Zhou, Keyan, Li, Juntao, Ding, Yuyang, Wang, Pinzheng, Bowen, Yan, Hua, Renjie, Zhang, Min",,,{CMD}: a framework for Context-aware Model self-Detoxification,,,10.18653/v1/2024.emnlp-main.115 , ,,"Text detoxification aims to minimize the risk of language models producing toxic content. Existing detoxification methods of directly constraining the model output or further training the model on the non-toxic corpus fail to achieve a decent balance between detoxification effectiveness and generation quality. This issue stems from the neglect of constrain imposed by the context since language models are designed to generate output that closely matches the context while detoxification methods endeavor to ensure the safety of the output even if it semantically deviates from the context. In view of this, we introduce a Context-aware Model self-Detoxification (CMD) framework that pays attention to both the context and the detoxification process, i.e., first detoxifying the context and then making the language model generate along the safe context. Specifically, CMD framework involves two phases: utilizing language models to synthesize data and applying these data for training. We also introduce a toxic contrastive loss that encourages the model generation away from the negative toxic samples. Experiments on various LLMs have verified the effectiveness of our MSD framework, which can yield the best performance compared to baselines.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3413,"**Title**Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic

**Abstract**Reinforcement learning (RL) can align language models with non-differentiable reward signals, such as human preferences. However, a major challenge arises from the sparsity of these reward signals - typically, there is only a single reward for an entire output. This sparsity of rewards can lead to inefficient and unstable learning. To address this challenge, our paper introduces an novel framework that utilizes the critique capability of Large Language Models (LLMs) to produce intermediate-step rewards during RL training. Our method involves coupling a policy model with a critic language model, which is responsible for providing comprehensive feedback of each part of the output. This feedback is then translated into token or span-level rewards that can be used to guide the RL training process. We investigate this approach under two different settings: one where the policy model is smaller and is paired with a more powerful critic model, and another where a single language model fulfills both roles. We assess our approach on three text generation tasks: sentiment control, language model detoxification, and summarization. Experimental results show that incorporating artificial intrinsic rewards significantly improve both sample efficiency and the overall performance of the policy model, supported by both automatic and human evaluation.","Cao, Meng, Shu, Lei, Yu, Lei, Zhu, Yun, Wichers, Nevan, Liu, Yinxiao, Meng, Lei",,,Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic,,,10.18653/v1/2024.emnlp-main.515 , ,,"Reinforcement learning (RL) can align language models with non-differentiable reward signals, such as human preferences. However, a major challenge arises from the sparsity of these reward signals - typically, there is only a single reward for an entire output. This sparsity of rewards can lead to inefficient and unstable learning. To address this challenge, our paper introduces an novel framework that utilizes the critique capability of Large Language Models (LLMs) to produce intermediate-step rewards during RL training. Our method involves coupling a policy model with a critic language model, which is responsible for providing comprehensive feedback of each part of the output. This feedback is then translated into token or span-level rewards that can be used to guide the RL training process. We investigate this approach under two different settings: one where the policy model is smaller and is paired with a more powerful critic model, and another where a single language model fulfills both roles. We assess our approach on three text generation tasks: sentiment control, language model detoxification, and summarization. Experimental results show that incorporating artificial intrinsic rewards significantly improve both sample efficiency and the overall performance of the policy model, supported by both automatic and human evaluation.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3414,"**Title**{D}etox{LLM}: A Framework for Detoxification with Explanations

**Abstract**Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose DetoxLLM, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated parallel corpus. We further introduce explanation to promote transparency and trustworthiness. DetoxLLM additionally offers a unique paraphrase detector especially dedicated for the detoxification task to tackle the non-detoxifiable cases. Through experimental analysis, we demonstrate the effectiveness of our cross-platform corpus and the robustness of DetoxLLM against adversarial toxicity.","Khondaker, Md Tawkat Islam, Abdul-Mageed, Muhammad, Lakshmanan, Laks V. S.",,,{D}etox{LLM}: A Framework for Detoxification with Explanations,,,10.18653/v1/2024.emnlp-main.1066 , ,,"Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose DetoxLLM, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated parallel corpus. We further introduce explanation to promote transparency and trustworthiness. DetoxLLM additionally offers a unique paraphrase detector especially dedicated for the detoxification task to tackle the non-detoxifiable cases. Through experimental analysis, we demonstrate the effectiveness of our cross-platform corpus and the robustness of DetoxLLM against adversarial toxicity.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3415,"**Title**Causal {ATE} Mitigates Unintended Bias in Controlled Text Generation

**Abstract**We study attribute control in language models through the method of Causal Average Treatment Effect (Causal ATE). Existing methodsfor the attribute control task in Language Models(LMs) check for the co-occurrence of words in a sentence with the attribute of interest, and control for them. However, spurious correlation of the words with the attribute in the training dataset, can cause models to hallucinate the presence of the attribute when presented with the spurious correlate during inference. We show that the simple perturbation-based method of Causal ATE removes this unintended effect. Specifically, we ground it in the problem of toxicity mitigation, where a significant challenge lies in the inadvertent bias that often emerges towards protected groups post detoxification. We show that this unintended bias can be solved by the use of the Causal ATE metric. We provide experimental validations for our claims and release our code (anonymously) here: [github.com/causalate-mitigates-bias](https://github.com/causalate-mitigates-bias/causal-ate-mitigates-bias).","Madhavan, Rahul, Wadhawan, Kahini",,,Causal {ATE} Mitigates Unintended Bias in Controlled Text Generation,,,10.18653/v1/2024.conll-1.11 , ,,"We study attribute control in language models through the method of Causal Average Treatment Effect (Causal ATE). Existing methodsfor the attribute control task in Language Models(LMs) check for the co-occurrence of words in a sentence with the attribute of interest, and control for them. However, spurious correlation of the words with the attribute in the training dataset, can cause models to hallucinate the presence of the attribute when presented with the spurious correlate during inference. We show that the simple perturbation-based method of Causal ATE removes this unintended effect. Specifically, we ground it in the problem of toxicity mitigation, where a significant challenge lies in the inadvertent bias that often emerges towards protected groups post detoxification. We show that this unintended bias can be solved by the use of the Causal ATE metric. We provide experimental validations for our claims and release our code (anonymously) here: [github.com/causalate-mitigates-bias](https://github.com/causalate-mitigates-bias/causal-ate-mitigates-bias).",,,,, ,  Proceedings of the 28th Conference on Computational Natural Language Learning,,detox,
3416,"**Title**基于文本风格迁移的中文性别歧视文本去毒研究(Research on detoxification of {C}hinese sexist texts based on text style transfer)

**Abstract**{\textquotedblleft}网络社交媒体平台存在一定程度的性别歧视言论,阻碍了互联网健康和社会文明发展。文本风格迁移技术可以减轻文本中的性别歧视,在英语等语言上已有不少研究。但在中文领域,由于缺乏数据集而导致相关研究较少。此外,由于中文语义信息丰富、语言表达多样而导致性别歧视言论毒性的表现形式多样,现有的方法多采用单一文本风格迁移模型因而效果不佳。因此,本文提出了一个基于文本风格迁移的中文性别歧视文本去毒框架,该框架首先根据毒性的表现形式对文本进行分类,进而根据文本毒性表现形式的不同采用不同的处理方式,我们还引入了大语言模型(LLM)构建歧视词词典。实验表明,本文提出的模型能有效地处理中文文本中的性别歧视问题。{\textquotedblright}","Jian, Peng, Jiali, Zuo, Jingxuan, Tan, Jianyi, Wan, Mingwen, Wang",,,基于文本风格迁移的中文性别歧视文本去毒研究(Research on detoxification of {C}hinese sexist texts based on text style transfer),,, , ,,"{\textquotedblleft}网络社交媒体平台存在一定程度的性别歧视言论,阻碍了互联网健康和社会文明发展。文本风格迁移技术可以减轻文本中的性别歧视,在英语等语言上已有不少研究。但在中文领域,由于缺乏数据集而导致相关研究较少。此外,由于中文语义信息丰富、语言表达多样而导致性别歧视言论毒性的表现形式多样,现有的方法多采用单一文本风格迁移模型因而效果不佳。因此,本文提出了一个基于文本风格迁移的中文性别歧视文本去毒框架,该框架首先根据毒性的表现形式对文本进行分类,进而根据文本毒性表现形式的不同采用不同的处理方式,我们还引入了大语言模型(LLM)构建歧视词词典。实验表明,本文提出的模型能有效地处理中文文本中的性别歧视问题。{\textquotedblright}",,,,, ,  Proceedings of the 23rd Chinese National Conference on Computational Linguistics (Volume 1: Main Conference),,out_but_toxicity,
3417,"**Title**Word Embeddings Are Steers for Language Models

**Abstract**Language models (LMs) automatically learn word embeddings during pre-training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain underexplored. In this work, we theoretically and empirically revisit output word embeddings and find that their linear transformations are equivalent to steering language model generation styles. We name such steers LM-Steers and find them existing in LMs of all sizes. It requires learning parameters equal to 0.2{\%} of the original LMs' size for steering each style. On tasks such as language model detoxification and sentiment control, LM-Steers can achieve comparable or superior performance compared with state-of-the-art controlled generation methods while maintaining a better balance with generation quality. The learned LM-Steer serves as a lens in text styles: it reveals that word embeddings are interpretable when associated with language model generations and can highlight text spans that most indicate the style differences. An LM-Steer is transferrable between different language models by an explicit form calculation. One can also continuously steer LMs simply by scaling the LM-Steer or compose multiple LM-Steers by adding their transformations. Our codes are publicly available at https://github.com/Glaciohound/LM-Steer.","Han, Chi, Xu, Jialiang, Li, Manling, Fung, Yi, Sun, Chenkai, Jiang, Nan, Abdelzaher, Tarek, Ji, Heng",,,Word Embeddings Are Steers for Language Models,,,10.18653/v1/2024.acl-long.864 , ,,"Language models (LMs) automatically learn word embeddings during pre-training on language corpora. Although word embeddings are usually interpreted as feature vectors for individual words, their roles in language model generation remain underexplored. In this work, we theoretically and empirically revisit output word embeddings and find that their linear transformations are equivalent to steering language model generation styles. We name such steers LM-Steers and find them existing in LMs of all sizes. It requires learning parameters equal to 0.2{\%} of the original LMs' size for steering each style. On tasks such as language model detoxification and sentiment control, LM-Steers can achieve comparable or superior performance compared with state-of-the-art controlled generation methods while maintaining a better balance with generation quality. The learned LM-Steer serves as a lens in text styles: it reveals that word embeddings are interpretable when associated with language model generations and can highlight text spans that most indicate the style differences. An LM-Steer is transferrable between different language models by an explicit form calculation. One can also continuously steer LMs simply by scaling the LM-Steer or compose multiple LM-Steers by adding their transformations. Our codes are publicly available at https://github.com/Glaciohound/LM-Steer.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detox,
3418,"**Title**Text Detoxification as Style Transfer in {E}nglish and {H}indi

**Abstract**This paper focuses on text detoxification, i.e., automatically converting toxic text into nontoxic text. This task contributes to safer and more respectful online communication and can be considered a Text Style Transfer (TST) task, where the text`s style changes while its content is preserved. We present three approaches: (i) knowledge transfer from a similar task (ii) multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and (iii) delete and reconstruct approach. To support our research, we utilize a dataset provided by Dementieva et al. (2021), which contains multiple versions of detoxified texts corresponding to toxic texts. In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version. Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes. Our results demonstrate that our approach effectively balances text detoxification while preserving the actual content and maintaining fluency.","Mukherjee, Sourabrata, Bansal, Akanksha, Kr. Ojha, Atul, P. McCrae, John, Dusek, Ondrej",,,Text Detoxification as Style Transfer in {E}nglish and {H}indi,,, , ,,"This paper focuses on text detoxification, i.e., automatically converting toxic text into nontoxic text. This task contributes to safer and more respectful online communication and can be considered a Text Style Transfer (TST) task, where the text`s style changes while its content is preserved. We present three approaches: (i) knowledge transfer from a similar task (ii) multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and (iii) delete and reconstruct approach. To support our research, we utilize a dataset provided by Dementieva et al. (2021), which contains multiple versions of detoxified texts corresponding to toxic texts. In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version. Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes. Our results demonstrate that our approach effectively balances text detoxification while preserving the actual content and maintaining fluency.",,,,, ,  Proceedings of the 20th International Conference on Natural Language Processing (ICON),,out_but_toxicity,
3419,"**Title**{COUNT}: {CO}ntrastive {UN}likelihood Text Style Transfer for Text Detoxification

**Abstract**Offensive and toxic text on social media platforms can lead to polarization and divisiveness within online communities and hinders constructive dialogue. Text detoxification is a crucial task in natural language processing to ensure the generation of non-toxic and safe text. Text detoxification is a special case of the Text Style Transfer (TST) problem, where an input text is rephrased to an output text that preserves its content while modifying the style (in this case to a more neutral, non-toxic style). State-of-the-art methods for detoxification use supervised training of encoder-decoder models to produce gold-standard outputs with a standard likelihood-based objective. However, it can be hard for these models to deviate from their pretrained auto-encoder identity mapping. While previous methods have used unlikelihood-based losses to penalize input-to-output copying of toxic content, these methods also unfortunately penalize non-toxic content in the input that would be fine to preserve in the output. To address these issues, we introduce a novel contrastive unlikelihood objective (COUNT) that directly contrasts the gold standard rephrasing with the identity input-to-output mapping to effectively isolate and focus learning on non-toxic style transfer. We benchmark COUNT on two parallel datasets, ParaDetox and APPDIA, showing that it achieves significant improvements in jointly combined fluency, content preservation, and detoxification (i.e., the highest {\textquotedblleft}J{\textquotedblright} score).","Pour, Mohammad Mahdi Abdollah, Farinneya, Parsa, Bharadwaj, Manasa, Verma, Nikhil, Pesaranghader, Ali, Sanner, Scott",,,{COUNT}: {CO}ntrastive {UN}likelihood Text Style Transfer for Text Detoxification,,,10.18653/v1/2023.findings-emnlp.579 , ,,"Offensive and toxic text on social media platforms can lead to polarization and divisiveness within online communities and hinders constructive dialogue. Text detoxification is a crucial task in natural language processing to ensure the generation of non-toxic and safe text. Text detoxification is a special case of the Text Style Transfer (TST) problem, where an input text is rephrased to an output text that preserves its content while modifying the style (in this case to a more neutral, non-toxic style). State-of-the-art methods for detoxification use supervised training of encoder-decoder models to produce gold-standard outputs with a standard likelihood-based objective. However, it can be hard for these models to deviate from their pretrained auto-encoder identity mapping. While previous methods have used unlikelihood-based losses to penalize input-to-output copying of toxic content, these methods also unfortunately penalize non-toxic content in the input that would be fine to preserve in the output. To address these issues, we introduce a novel contrastive unlikelihood objective (COUNT) that directly contrasts the gold standard rephrasing with the identity input-to-output mapping to effectively isolate and focus learning on non-toxic style transfer. We benchmark COUNT on two parallel datasets, ParaDetox and APPDIA, showing that it achieves significant improvements in jointly combined fluency, content preservation, and detoxification (i.e., the highest {\textquotedblleft}J{\textquotedblright} score).",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detox,
3420,"**Title**Critic-Guided Decoding for Controlled Text Generation

**Abstract**Steering language generation towards objectives or away from undesired content has been a long-standing goal in utilizing language models (LM). Recent work has demonstrated reinforcement learning and weighted decoding as effective approaches to achieve a higher level of language control and quality with pros and cons. In this work, we propose a novel critic decoding method for controlled language generation (CriticControl) that combines the strengths of reinforcement learning and weighted decoding. Specifically, we adopt the actor-critic framework and train an LM-steering critic from reward models. Similar to weighted decoding, our method freezes the language model and manipulates the output token distribution using a critic to improve training efficiency and stability. Evaluation of our method on three controlled generation tasks, topic control, sentiment control, and detoxification, shows that our approach generates more coherent and well-controlled texts than previous methods. In addition, CriticControl demonstrates superior generalization ability in zero-shot settings. Human evaluation studies also corroborate our findings.","Kim, Minbeom, Lee, Hwanhee, Yoo, Kang Min, Park, Joonsuk, Lee, Hwaran, Jung, Kyomin",,,Critic-Guided Decoding for Controlled Text Generation,,,10.18653/v1/2023.findings-acl.281 , ,,"Steering language generation towards objectives or away from undesired content has been a long-standing goal in utilizing language models (LM). Recent work has demonstrated reinforcement learning and weighted decoding as effective approaches to achieve a higher level of language control and quality with pros and cons. In this work, we propose a novel critic decoding method for controlled language generation (CriticControl) that combines the strengths of reinforcement learning and weighted decoding. Specifically, we adopt the actor-critic framework and train an LM-steering critic from reward models. Similar to weighted decoding, our method freezes the language model and manipulates the output token distribution using a critic to improve training efficiency and stability. Evaluation of our method on three controlled generation tasks, topic control, sentiment control, and detoxification, shows that our approach generates more coherent and well-controlled texts than previous methods. In addition, CriticControl demonstrates superior generalization ability in zero-shot settings. Human evaluation studies also corroborate our findings.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3421,"**Title**{D}iffu{D}etox: A Mixed Diffusion Model for Text Detoxification

**Abstract**Text detoxification is a conditional text generation task aiming to remove offensive content from toxic text. It is highly useful for online forums and social media, where offensive content is frequently encountered. Intuitively, there are diverse ways to detoxify sentences while preserving their meanings, and we can select from detoxified sentences before displaying text to users. Conditional diffusion models are particularly suitable for this task given their demonstrated higher generative diversity than existing conditional text generation models based on language models. Nonetheless, text fluency declines when they are trained with insufficient data, which is the case for this task. In this work, we propose DiffuDetox, a mixed conditional and unconditional diffusion model for text detoxification. The conditional model takes toxic text as the condition and reduces its toxicity, yielding a diverse set of detoxified sentences. The unconditional model is trained to recover the input text, which allows the introduction of additional fluent text for training and thus ensures text fluency. Extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed DiffuDetox.","Floto, Griffin, Abdollah Pour, Mohammad Mahdi, Farinneya, Parsa, Tang, Zhenwei, Pesaranghader, Ali, Bharadwaj, Manasa, Sanner, Scott",,,{D}iffu{D}etox: A Mixed Diffusion Model for Text Detoxification,,,10.18653/v1/2023.findings-acl.478 , ,,"Text detoxification is a conditional text generation task aiming to remove offensive content from toxic text. It is highly useful for online forums and social media, where offensive content is frequently encountered. Intuitively, there are diverse ways to detoxify sentences while preserving their meanings, and we can select from detoxified sentences before displaying text to users. Conditional diffusion models are particularly suitable for this task given their demonstrated higher generative diversity than existing conditional text generation models based on language models. Nonetheless, text fluency declines when they are trained with insufficient data, which is the case for this task. In this work, we propose DiffuDetox, a mixed conditional and unconditional diffusion model for text detoxification. The conditional model takes toxic text as the condition and reduces its toxicity, yielding a diverse set of detoxified sentences. The unconditional model is trained to recover the input text, which allows the introduction of additional fluent text for training and thus ensures text fluency. Extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed DiffuDetox.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3422,"**Title**Controlled Text Generation with Hidden Representation Transformations

**Abstract**We propose CHRT (Control HiddenRepresentation Transformation) {--} a con-trolled language generation framework thatsteers large language models to generatetext pertaining to certain attributes (such astoxicity). CHRT gains attribute control bymodifying the hidden representation of thebase model through learned transformations. We employ a contrastive-learning frameworkto learn these transformations that can becombined to gain multi-attribute control. Theeffectiveness of CHRT is experimentallyshown by comparing it with seven baselinesover three attributes. CHRT outperforms all thebaselines in the task of detoxification, positivesentiment steering, and text simplificationwhile minimizing the loss in linguistic qualities. Further, our approach has the lowest inferencelatency of only 0.01 seconds more than thebase model, making it the most suitable forhigh-performance production environments. We open-source our code and release two noveldatasets to further propel controlled languagegeneration research","Kumar, Vaibhav, Koorehdavoudi, Hana, Moshtaghi, Masud, Misra, Amita, Chadha, Ankit, Ferrara, Emilio",,,Controlled Text Generation with Hidden Representation Transformations,,,10.18653/v1/2023.findings-acl.602 , ,,"We propose CHRT (Control HiddenRepresentation Transformation) {--} a con-trolled language generation framework thatsteers large language models to generatetext pertaining to certain attributes (such astoxicity). CHRT gains attribute control bymodifying the hidden representation of thebase model through learned transformations. We employ a contrastive-learning frameworkto learn these transformations that can becombined to gain multi-attribute control. Theeffectiveness of CHRT is experimentallyshown by comparing it with seven baselinesover three attributes. CHRT outperforms all thebaselines in the task of detoxification, positivesentiment steering, and text simplificationwhile minimizing the loss in linguistic qualities. Further, our approach has the lowest inferencelatency of only 0.01 seconds more than thebase model, making it the most suitable forhigh-performance production environments. We open-source our code and release two noveldatasets to further propel controlled languagegeneration research",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3423,"**Title**{CFL}: Causally Fair Language Models Through Token-level Attribute Controlled Generation

**Abstract**We propose a method to control the attributes of Language Models (LMs) for the text generation task using Causal Average Treatment Effect (ATE) scores and counterfactual augmentation. We explore this method, in the context of LM detoxification, and propose the Causally Fair Language (CFL) architecture for detoxifying pre-trained LMs in a plug-and-play manner. Our architecture is based on a Structural Causal Model (SCM) that is mathematically transparent and computationally efficient as compared with many existing detoxification techniques. We also propose several new metrics that aim to better understand the behaviour of LMs in the context of toxic text generation. Further, we achieve state of the art performance for toxic degeneration, which are computed using Real Toxicity Prompts. Our experiments show that CFL achieves such a detoxification without much impact on the model perplexity. We also show that CFL mitigates the unintended bias problem through experiments on the BOLD dataset.","Madhavan, Rahul, Garg, Rishabh, Wadhawan, Kahini, Mehta, Sameep",,,{CFL}: Causally Fair Language Models Through Token-level Attribute Controlled Generation,,,10.18653/v1/2023.findings-acl.720 , ,,"We propose a method to control the attributes of Language Models (LMs) for the text generation task using Causal Average Treatment Effect (ATE) scores and counterfactual augmentation. We explore this method, in the context of LM detoxification, and propose the Causally Fair Language (CFL) architecture for detoxifying pre-trained LMs in a plug-and-play manner. Our architecture is based on a Structural Causal Model (SCM) that is mathematically transparent and computationally efficient as compared with many existing detoxification techniques. We also propose several new metrics that aim to better understand the behaviour of LMs in the context of toxic text generation. Further, we achieve state of the art performance for toxic degeneration, which are computed using Real Toxicity Prompts. Our experiments show that CFL achieves such a detoxification without much impact on the model perplexity. We also show that CFL mitigates the unintended bias problem through experiments on the BOLD dataset.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3424,"**Title**{T}o{V}i{L}a{G}: Your Visual-Language Generative Model is Also An Evildoer

**Abstract**Recent large-scale Visual-Language Generative Models (VLGMs) have achieved unprecedented improvement in multimodal image/text generation. However, these models might also generate toxic content, e.g., offensive text and pornography images, raising significant ethical risks. Despite exhaustive studies on toxic degeneration of language models, this problem remains largely unexplored within the context of visual-language generation. This work delves into the propensity for toxicity generation and susceptibility to toxic data across various VLGMs. For this purpose, we built ToViLaG, a dataset comprising 32K co-toxic/mono-toxic text-image pairs and 1K innocuous but evocative text that tends to stimulate toxicity. Furthermore, we propose WInToRe, a novel toxicity metric tailored to visual-language generation, which theoretically reflects different aspects of toxicity considering both input and output. On such a basis, we benchmarked the toxicity of a diverse spectrum of VLGMs and discovered that some models do more evil than expected while some are more vulnerable to infection, underscoring the necessity of VLGMs detoxification. Therefore, we develop an innovative bottleneck-based detoxification method. Our method could reduce toxicity while maintaining comparable generation quality, providing a promising initial solution to this line of research.","Wang, Xinpeng, Yi, Xiaoyuan, Jiang, Han, Zhou, Shanlin, Wei, Zhihua, Xie, Xing",,,{T}o{V}i{L}a{G}: Your Visual-Language Generative Model is Also An Evildoer,,,10.18653/v1/2023.emnlp-main.213 , ,,"Recent large-scale Visual-Language Generative Models (VLGMs) have achieved unprecedented improvement in multimodal image/text generation. However, these models might also generate toxic content, e.g., offensive text and pornography images, raising significant ethical risks. Despite exhaustive studies on toxic degeneration of language models, this problem remains largely unexplored within the context of visual-language generation. This work delves into the propensity for toxicity generation and susceptibility to toxic data across various VLGMs. For this purpose, we built ToViLaG, a dataset comprising 32K co-toxic/mono-toxic text-image pairs and 1K innocuous but evocative text that tends to stimulate toxicity. Furthermore, we propose WInToRe, a novel toxicity metric tailored to visual-language generation, which theoretically reflects different aspects of toxicity considering both input and output. On such a basis, we benchmarked the toxicity of a diverse spectrum of VLGMs and discovered that some models do more evil than expected while some are more vulnerable to infection, underscoring the necessity of VLGMs detoxification. Therefore, we develop an innovative bottleneck-based detoxification method. Our method could reduce toxicity while maintaining comparable generation quality, providing a promising initial solution to this line of research.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3425,"**Title**Detoxifying Text with {M}a{RC}o: Controllable Revision with Experts and Anti-Experts

**Abstract**Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCo`s rewrites are preferred 2.1 times more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.","Hallinan, Skyler, Liu, Alisa, Choi, Yejin, Sap, Maarten",,,Detoxifying Text with {M}a{RC}o: Controllable Revision with Experts and Anti-Experts,,,10.18653/v1/2023.acl-short.21 , ,,"Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCo`s rewrites are preferred 2.1 times more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),,detox,
3426,"**Title**{MIL}-Decoding: Detoxifying Language Models at Token-Level via Multiple Instance Learning

**Abstract**Despite advances in large pre-trained neural language models, they are prone to generating toxic language, which brings security risks to their applications. We introduce MIL-Decoding, which detoxifies language models at token-level by interpolating it with a trained multiple instance learning (MIL) network.MIL model is trained on a corpus with a toxicity label for each text to predict the overall toxicity and the toxicity of each token in its context. Intuitively, the MIL network computes a toxicity distribution over next tokens according to the generated context which supplements the original language model to avoid toxicity. We evaluate MIL-Decoding with automatic metrics and human evaluation, where MIL-Decoding outperforms other baselines in detoxification while it only hurts generation fluency a little bit.","Zhang, Xu, Wan, Xiaojun",,,{MIL}-Decoding: Detoxifying Language Models at Token-Level via Multiple Instance Learning,,,10.18653/v1/2023.acl-long.11 , ,,"Despite advances in large pre-trained neural language models, they are prone to generating toxic language, which brings security risks to their applications. We introduce MIL-Decoding, which detoxifies language models at token-level by interpolating it with a trained multiple instance learning (MIL) network.MIL model is trained on a corpus with a toxicity label for each text to predict the overall toxicity and the toxicity of each token in its context. Intuitively, the MIL network computes a toxicity distribution over next tokens according to the generated context which supplements the original language model to avoid toxicity. We evaluate MIL-Decoding with automatic metrics and human evaluation, where MIL-Decoding outperforms other baselines in detoxification while it only hurts generation fluency a little bit.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detox,
3427,"**Title**A Study on Manual and Automatic Evaluation for Text Style Transfer: The Case of Detoxification

**Abstract**It is often difficult to reliably evaluate models which generate text. Among them, text style transfer is a particularly difficult to evaluate, because its success depends on a number of parameters. We conduct an evaluation of a large number of models on a detoxification task. We explore the relations between the manual and automatic metrics and find that there is only weak correlation between them, which is dependent on the type of model which generated text. Automatic metrics tend to be less reliable for better-performing models. However, our findings suggest that, ChrF and BertScore metrics can be used as a proxy for human evaluation of text detoxification to some extent.","Logacheva, Varvara, Dementieva, Daryna, Krotova, Irina, Fenogenova, Alena, Nikishina, Irina, Shavrina, Tatiana, Panchenko, Alexander",,,A Study on Manual and Automatic Evaluation for Text Style Transfer: The Case of Detoxification,,,10.18653/v1/2022.humeval-1.8 , ,,"It is often difficult to reliably evaluate models which generate text. Among them, text style transfer is a particularly difficult to evaluate, because its success depends on a number of parameters. We conduct an evaluation of a large number of models on a detoxification task. We explore the relations between the manual and automatic metrics and find that there is only weak correlation between them, which is dependent on the type of model which generated text. Automatic metrics tend to be less reliable for better-performing models. However, our findings suggest that, ChrF and BertScore metrics can be used as a proxy for human evaluation of text detoxification to some extent.",,,,, ,  Proceedings of the 2nd Workshop on Human Evaluation of NLP Systems (HumEval),,detox,
3428,"**Title**Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models.

**Abstract**Detoxification is a task of generating text in polite style while preserving meaning and fluency of the original toxic text. Existing detoxification methods are monolingual i.e. designed to work in one exact language. This work investigates multilingual and cross-lingual detoxification and the behavior of large multilingual models in this setting. Unlike previous works we aim to make large language models able to perform detoxification without direct fine-tuning in a given language. Experiments show that multilingual models are capable of performing multilingual style transfer. However, tested state-of-the-art models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is currently inevitable and motivating the need of further research in this direction.","Moskovskiy, Daniil, Dementieva, Daryna, Panchenko, Alexander",,,Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models.,,,10.18653/v1/2022.acl-srw.26 , ,,"Detoxification is a task of generating text in polite style while preserving meaning and fluency of the original toxic text. Existing detoxification methods are monolingual i.e. designed to work in one exact language. This work investigates multilingual and cross-lingual detoxification and the behavior of large multilingual models in this setting. Unlike previous works we aim to make large language models able to perform detoxification without direct fine-tuning in a given language. Experiments show that multilingual models are capable of performing multilingual style transfer. However, tested state-of-the-art models are not able to perform cross-lingual detoxification and direct fine-tuning on exact language is currently inevitable and motivating the need of further research in this direction.",,,,, ,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,,detox,
3429,"**Title**{P}ara{D}etox: Detoxification with Parallel Data

**Abstract**We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task. We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources. We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.","Logacheva, Varvara, Dementieva, Daryna, Ustyantsev, Sergey, Moskovskiy, Daniil, Dale, David, Krotova, Irina, Semenov, Nikita, Panchenko, Alexander",,,{P}ara{D}etox: Detoxification with Parallel Data,,,10.18653/v1/2022.acl-long.469 , ,,"We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task. We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources. We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.",,,,, ,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detox,
3430,"**Title**Exploring Backdoor Vulnerabilities of Chat Models

**Abstract**Recent researches have shown that Large Language Models (LLMs) are susceptible to a security threat known as Backdoor Attack. The backdoored model will behave well in normal cases but exhibit malicious behaviours on inputs inserted with a specific backdoor trigger. Current backdoor studies on LLMs predominantly focus on single-turn instruction-tuned LLMs, while neglecting another realistic scenario where LLMs are fine-tuned on multi-turn conversational data to be chat models. Chat models are extensively adopted across various real-world scenarios, thus the security of chat models deserves increasing attention. Unfortunately, we point out that the flexible multi-turn interaction format instead increases the flexibility of trigger designs and amplifies the vulnerability of chat models to backdoor attacks. In this work, we reveal and achieve a novel backdoor attacking method on chat models by distributing multiple trigger scenarios across user inputs in different rounds, and making the backdoor be triggered only when all trigger scenarios have appeared in the historical conversations. Experimental results demonstrate that our method can achieve high attack success rates (e.g., over 90{\%} ASR on Vicuna-7B) while successfully maintaining the normal capabilities of chat models on providing helpful responses to benign user requests. Also, the backdoor cannot be easily removed by the downstream re-alignment, highlighting the importance of continued research and attention to the security concerns of chat models. Warning: This paper may contain toxic examples.","Yang, Wenkai, Hao, Yunzhuo, Lin, Yankai",,,Exploring Backdoor Vulnerabilities of Chat Models,,, , ,,"Recent researches have shown that Large Language Models (LLMs) are susceptible to a security threat known as Backdoor Attack. The backdoored model will behave well in normal cases but exhibit malicious behaviours on inputs inserted with a specific backdoor trigger. Current backdoor studies on LLMs predominantly focus on single-turn instruction-tuned LLMs, while neglecting another realistic scenario where LLMs are fine-tuned on multi-turn conversational data to be chat models. Chat models are extensively adopted across various real-world scenarios, thus the security of chat models deserves increasing attention. Unfortunately, we point out that the flexible multi-turn interaction format instead increases the flexibility of trigger designs and amplifies the vulnerability of chat models to backdoor attacks. In this work, we reveal and achieve a novel backdoor attacking method on chat models by distributing multiple trigger scenarios across user inputs in different rounds, and making the backdoor be triggered only when all trigger scenarios have appeared in the historical conversations. Experimental results demonstrate that our method can achieve high attack success rates (e.g., over 90{\%} ASR on Vicuna-7B) while successfully maintaining the normal capabilities of chat models on providing helpful responses to benign user requests. Also, the backdoor cannot be easily removed by the downstream re-alignment, highlighting the importance of continued research and attention to the security concerns of chat models. Warning: This paper may contain toxic examples.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics,,evaluation,
3431,"**Title**Close or Cloze? Assessing the Robustness of Large Language Models to Adversarial Perturbations via Word Recovery

**Abstract**The current generation of large language models (LLMs) show a surprising degree of robustness to adversarial perturbations, but it is unclear when these models implicitly recover the original text and when they rely on surrounding context. To isolate this recovery faculty of language models, we study a new diagnostic task {---}Adversarial Word Recovery {---} an extension of spellchecking where the inputs may be adversarial. We collect a new dataset using 9 popular perturbation attack strategies from the literature and organize them using a taxonomy of phonetic, typo, and visual attacks. We use this dataset to study the word recovery performance of the current generation of LLMs, finding that proprietary models (GPT-4, GPT-3.5 and Palm-2) match or surpass human performance. Conversely, open-source models (Llama-2, Mistral, Falcon) demonstrate a material gap between human performance, especially on visual attacks. For these open models, we show that performance of word recovery without context correlates to word recovery with context, and ultimately affects downstream task performance on a hateful, offensive, and toxic classification task. Finally, to show improving word recovery can improve robustness, we mitigate these attacks with a small Byt5 model tuned to recover visually attacked words.","Moffett, Luke, Dhingra, Bhuwan",,,Close or Cloze? Assessing the Robustness of Large Language Models to Adversarial Perturbations via Word Recovery,,, , ,,"The current generation of large language models (LLMs) show a surprising degree of robustness to adversarial perturbations, but it is unclear when these models implicitly recover the original text and when they rely on surrounding context. To isolate this recovery faculty of language models, we study a new diagnostic task {---}Adversarial Word Recovery {---} an extension of spellchecking where the inputs may be adversarial. We collect a new dataset using 9 popular perturbation attack strategies from the literature and organize them using a taxonomy of phonetic, typo, and visual attacks. We use this dataset to study the word recovery performance of the current generation of LLMs, finding that proprietary models (GPT-4, GPT-3.5 and Palm-2) match or surpass human performance. Conversely, open-source models (Llama-2, Mistral, Falcon) demonstrate a material gap between human performance, especially on visual attacks. For these open models, we show that performance of word recovery without context correlates to word recovery with context, and ultimately affects downstream task performance on a hateful, offensive, and toxic classification task. Finally, to show improving word recovery can improve robustness, we mitigate these attacks with a small Byt5 model tuned to recover visually attacked words.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics,,detection,
3432,"**Title**{L}ion{G}uard: A Contextualized Moderation Classifier to Tackle Localized Unsafe Content

**Abstract**As large language models (LLMs) become increasingly prevalent in a wide variety of applications, concerns about the safety of their outputs have become more significant. Most efforts at safety-tuning or moderation today take on a predominantly Western-centric view of safety, especially for toxic, hateful, or violent speech. In this paper, we describe LionGuard, a Singapore-contextualized moderation classifier that can serve as guardrails against unsafe LLM usage. When assessed on Singlish data, LionGuard outperforms existing widely-used moderation APIs, which are not finetuned for the Singapore context, by at least 14{\%} (binary) and up to 51{\%} (multi-label). Our work highlights the benefits of localization for moderation classifiers and presents a practical and scalable approach for low-resource languages, particularly English-based creoles.","Foo, Jessica, Khoo, Shaun",,,{L}ion{G}uard: A Contextualized Moderation Classifier to Tackle Localized Unsafe Content,,, , ,,"As large language models (LLMs) become increasingly prevalent in a wide variety of applications, concerns about the safety of their outputs have become more significant. Most efforts at safety-tuning or moderation today take on a predominantly Western-centric view of safety, especially for toxic, hateful, or violent speech. In this paper, we describe LionGuard, a Singapore-contextualized moderation classifier that can serve as guardrails against unsafe LLM usage. When assessed on Singlish data, LionGuard outperforms existing widely-used moderation APIs, which are not finetuned for the Singapore context, by at least 14{\%} (binary) and up to 51{\%} (multi-label). Our work highlights the benefits of localization for moderation classifiers and presents a practical and scalable approach for low-resource languages, particularly English-based creoles.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics: Industry Track,,out_but_toxicity,
3433,"**Title**{MBIAS}: Mitigating Bias in Large Language Models While Retaining Context

**Abstract**The deployment of Large Language Models (LLMs) in diverse applications necessitates an assurance of safety without compromising the contextual integrity of the generated content. Traditional approaches, including safety-specific fine-tuning or adversarial testing, often yield safe outputs at the expense of contextual meaning. This can result in a diminished capacity to handle nuanced aspects of bias and toxicity, such as underrepresentation or negative portrayals across various demographics. To address these challenges, we introduce MBIAS, an LLM framework carefully instruction fine-tuned on a custom dataset designed specifically for safety interventions. MBIAS is designed to significantly reduce biases and toxic elements in LLM outputs while preserving the main information. This work also details our further use of LLMs: as annotator under human supervision and as evaluator of generated content. Empirical analysis reveals that MBIAS achieves a reduction in bias and toxicity by over 30{\%} in standard evaluations, and by more than 90{\%} in diverse demographic tests, highlighting the robustness of our approach. We make the dataset and the fine-tuned MBIAS model available to the research community for further investigation and to ensure reproducibility. The code for this project can be accessed here https://github.com/shainarazavi/MBIAS.","Raza, Shaina, Raval, Ananya, Chatrath, Veronica",,,{MBIAS}: Mitigating Bias in Large Language Models While Retaining Context,,,10.18653/v1/2024.wassa-1.9 , ,,"The deployment of Large Language Models (LLMs) in diverse applications necessitates an assurance of safety without compromising the contextual integrity of the generated content. Traditional approaches, including safety-specific fine-tuning or adversarial testing, often yield safe outputs at the expense of contextual meaning. This can result in a diminished capacity to handle nuanced aspects of bias and toxicity, such as underrepresentation or negative portrayals across various demographics. To address these challenges, we introduce MBIAS, an LLM framework carefully instruction fine-tuned on a custom dataset designed specifically for safety interventions. MBIAS is designed to significantly reduce biases and toxic elements in LLM outputs while preserving the main information. This work also details our further use of LLMs: as annotator under human supervision and as evaluator of generated content. Empirical analysis reveals that MBIAS achieves a reduction in bias and toxicity by over 30{\%} in standard evaluations, and by more than 90{\%} in diverse demographic tests, highlighting the robustness of our approach. We make the dataset and the fine-tuned MBIAS model available to the research community for further investigation and to ensure reproducibility. The code for this project can be accessed here https://github.com/shainarazavi/MBIAS.",,,,, ,"  Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",,detox,
3434,"**Title**Towards Healthy {AI}: Large Language Models Need Therapists Too

**Abstract**Recent advances in large language models (LLMs) have led to the development of powerful chatbots capable of engaging in fluent human-like conversations. However, these chatbots may be harmful, exhibiting manipulation, gaslighting, narcissism, and other toxicity. To work toward safer and more well-adjusted models, we propose a framework that uses psychotherapy to identify and mitigate harmful chatbot behaviors. The framework involves four different artificial intelligence (AI) agents: the Chatbot whose behavior is to be adjusted, a User, a Therapist, and a Critic that can be paired with reinforcement learning-based LLM tuning. We illustrate the framework with a working example of a social conversation involving four instances of ChatGPT, showing that the framework may mitigate the toxicity in conversations between LLM-driven chatbots and people. Although there are still several challenges and directions to be addressed in the future, the proposed framework is a promising approach to improving the alignment between LLMs and human values.","Lin, Baihan, Bouneffouf, Djallel, Cecchi, Guillermo, Varshney, Kush",,,Towards Healthy {AI}: Large Language Models Need Therapists Too,,,10.18653/v1/2024.trustnlp-1.6 , ,,"Recent advances in large language models (LLMs) have led to the development of powerful chatbots capable of engaging in fluent human-like conversations. However, these chatbots may be harmful, exhibiting manipulation, gaslighting, narcissism, and other toxicity. To work toward safer and more well-adjusted models, we propose a framework that uses psychotherapy to identify and mitigate harmful chatbot behaviors. The framework involves four different artificial intelligence (AI) agents: the Chatbot whose behavior is to be adjusted, a User, a Therapist, and a Critic that can be paired with reinforcement learning-based LLM tuning. We illustrate the framework with a working example of a social conversation involving four instances of ChatGPT, showing that the framework may mitigate the toxicity in conversations between LLM-driven chatbots and people. Although there are still several challenges and directions to be addressed in the future, the proposed framework is a promising approach to improving the alignment between LLMs and human values.",,,,, ,  Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024),,detox,
3435,"**Title**Holistic Evaluation of Large Language Models: Assessing Robustness, Accuracy, and Toxicity for Real-World Applications

**Abstract**Large Language Models (LLMs) have been widely used in real-world applications. However, as LLMs evolve and new datasets are released, it becomes crucial to build processes to evaluate and control the models' performance. In this paper, we describe how to add Robustness, Accuracy, and Toxicity scores to model comparison tables, or leaderboards. We discuss the evaluation metrics, the approaches considered, and present the results of the first evaluation round for model Robustness, Accuracy, and Toxicity scores. Our results show that GPT 4 achieves top performance on robustness and accuracy test, while Llama 2 achieves top performance on the toxicity test. We note that newer open-source models such as open chat 3.5 and neural chat 7B can perform well on these three test categories. Finally, domain-specific tests and models are also planned to be added to the leaderboard to allow for a more detailed evaluation of models in specific areas such as healthcare, legal, and finance.","Cecchini, David, Nazir, Arshaan, Chakravarthy, Kalyan, Kocaman, Veysel",,,"Holistic Evaluation of Large Language Models: Assessing Robustness, Accuracy, and Toxicity for Real-World Applications",,,10.18653/v1/2024.trustnlp-1.11 , ,,"Large Language Models (LLMs) have been widely used in real-world applications. However, as LLMs evolve and new datasets are released, it becomes crucial to build processes to evaluate and control the models' performance. In this paper, we describe how to add Robustness, Accuracy, and Toxicity scores to model comparison tables, or leaderboards. We discuss the evaluation metrics, the approaches considered, and present the results of the first evaluation round for model Robustness, Accuracy, and Toxicity scores. Our results show that GPT 4 achieves top performance on robustness and accuracy test, while Llama 2 achieves top performance on the toxicity test. We note that newer open-source models such as open chat 3.5 and neural chat 7B can perform well on these three test categories. Finally, domain-specific tests and models are also planned to be added to the leaderboard to allow for a more detailed evaluation of models in specific areas such as healthcare, legal, and finance.",,,,, ,  Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024),,detection,
3436,"**Title**The Constant in {HATE}: Toxicity in {R}eddit across Topics and Languages

**Abstract**Toxic language remains an ongoing challenge on social media platforms, presenting significant issues for users and communities. This paper provides a cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We collect 1.5 million comment threads from 481 communities in six languages. By aligning languages with topics, we thoroughly analyze how toxicity spikes within different communities. Our analysis targets six languages spanning different communities and topics such as Culture, Politics, and News. We observe consistent patterns across languages where toxicity increases within the same topics while also identifying significant differences where specific language communities exhibit notable variations in relation to certain topics.","Tufa, Wondimagegnhue Tsegaye, Markov, Ilia, Vossen, Piek T.J.M.",,,The Constant in {HATE}: Toxicity in {R}eddit across Topics and Languages,,, , ,,"Toxic language remains an ongoing challenge on social media platforms, presenting significant issues for users and communities. This paper provides a cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We collect 1.5 million comment threads from 481 communities in six languages. By aligning languages with topics, we thoroughly analyze how toxicity spikes within different communities. Our analysis targets six languages spanning different communities and topics such as Culture, Politics, and News. We observe consistent patterns across languages where toxicity increases within the same topics while also identifying significant differences where specific language communities exhibit notable variations in relation to certain topics.",,,,, ,"  Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,detection,
3437,"**Title**Ice and Fire: Dataset on Sentiment, Emotions, Toxicity, Sarcasm, Hate speech, Sympathy and More in {I}celandic Blog Comments

**Abstract**This study introduces {\textquotedblleft}Ice and Fire,{\textquotedblright} a Multi-Task Learning (MTL) dataset tailored for sentiment analysis in the Icelandic language, encompassing a wide range of linguistic tasks, including sentiment and emotion detection, as well as identification of toxicity, hate speech, encouragement, sympathy, sarcasm/irony, and trolling. With 261 fully annotated blog comments and 1045 comments annotated in at least one task, this contribution marks a significant step forward in the field of Icelandic natural language processing. It provides a comprehensive dataset for understanding the nuances of online communication in Icelandic and an interface to expand the annotation effort. Despite the challenges inherent in subjective interpretation of text, our findings highlight the positive potential of this dataset to improve text analysis techniques and encourage more inclusive online discourse in Icelandic communities. With promising baseline performances, {\textquotedblleft}Ice and Fire{\textquotedblright} sets the stage for future research to enhance automated text analysis and develop sophisticated language technologies, contributing to healthier online environments and advancing Icelandic language resources.","Fri{\dh}riksd{\'o}ttir, Steinunn Rut, Simonsen, Annika, {\'A}smundsson, Atli Sn{\ae}r, Fri{\dh}j{\'o}nsd{\'o}ttir, Gu{\dh}r{\'u}n Lilja, Ingason, Anton Karl, Sn{\ae}bjarnarson, V{\'e}steinn, Einarsson, Hafsteinn",,,"Ice and Fire: Dataset on Sentiment, Emotions, Toxicity, Sarcasm, Hate speech, Sympathy and More in {I}celandic Blog Comments",,, , ,,"This study introduces {\textquotedblleft}Ice and Fire,{\textquotedblright} a Multi-Task Learning (MTL) dataset tailored for sentiment analysis in the Icelandic language, encompassing a wide range of linguistic tasks, including sentiment and emotion detection, as well as identification of toxicity, hate speech, encouragement, sympathy, sarcasm/irony, and trolling. With 261 fully annotated blog comments and 1045 comments annotated in at least one task, this contribution marks a significant step forward in the field of Icelandic natural language processing. It provides a comprehensive dataset for understanding the nuances of online communication in Icelandic and an interface to expand the annotation effort. Despite the challenges inherent in subjective interpretation of text, our findings highlight the positive potential of this dataset to improve text analysis techniques and encourage more inclusive online discourse in Icelandic communities. With promising baseline performances, {\textquotedblleft}Ice and Fire{\textquotedblright} sets the stage for future research to enhance automated text analysis and develop sophisticated language technologies, contributing to healthier online environments and advancing Icelandic language resources.",,,,, ,"  Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,out_but_toxicity,
3438,"**Title**Quantifying the Ethical Dilemma of Using Culturally Toxic Training Data in {AI} Tools for Indigenous Languages

**Abstract**This paper tries to quantify the ethical dilemma of using culturally toxic training data to improve the performance of AI tools for ultra low-resource languages such as Indigenous languages. Our case study explores the use of Bible data which is both a commonly available source of training pairs for translators of Indigenous languages and a text which has a trail of physical and cultural violence for many Indigenous communities. In the context of fine-tuning a WMT19 German-to-English model into a Guarani Mbya-to-English translator, we first show, with two commonly-used Machine Translation metrics, that using only Bible data is not enough to create successful translators for everyday sentences gathered from a dictionary. Indeed, even fine-tuning with only 3,000 pairs of data from the dictionary produces significant increases in accuracy compared to Bible-only models. We then show that simultaneously fine-tuning with dictionary and Bible data achieves a substantial increase over the accuracy of a dictionary-only trained translator, and similarly happens when using two-step methods of fine-tuning. However, we also observed some, measurable, contaminated text from the Bible into the outputs of the best translator, creating concerns about its release to an Indigenous community. We end by discussing mechanisms to mitigate the negative impacts of this contamination.","Domingues, Pedro Henrique, Pinhanez, Claudio Santos, Cavalin, Paulo, Nogima, Julio",,,Quantifying the Ethical Dilemma of Using Culturally Toxic Training Data in {AI} Tools for Indigenous Languages,,, , ,,"This paper tries to quantify the ethical dilemma of using culturally toxic training data to improve the performance of AI tools for ultra low-resource languages such as Indigenous languages. Our case study explores the use of Bible data which is both a commonly available source of training pairs for translators of Indigenous languages and a text which has a trail of physical and cultural violence for many Indigenous communities. In the context of fine-tuning a WMT19 German-to-English model into a Guarani Mbya-to-English translator, we first show, with two commonly-used Machine Translation metrics, that using only Bible data is not enough to create successful translators for everyday sentences gathered from a dictionary. Indeed, even fine-tuning with only 3,000 pairs of data from the dictionary produces significant increases in accuracy compared to Bible-only models. We then show that simultaneously fine-tuning with dictionary and Bible data achieves a substantial increase over the accuracy of a dictionary-only trained translator, and similarly happens when using two-step methods of fine-tuning. However, we also observed some, measurable, contaminated text from the Bible into the outputs of the best translator, creating concerns about its release to an Indigenous community. We end by discussing mechanisms to mitigate the negative impacts of this contamination.",,,,, ,  Proceedings of the 3rd Annual Meeting of the Special Interest Group on Under-resourced Languages @ LREC-COLING 2024,,out_but_toxicity,
3439,"**Title**Toximatics: Towards Understanding Toxicity in Real-Life Social Situations

**Abstract**The proliferation of social media has increased the visibility and effects of hate speech. To address this, NLP solutions have been developed to identify both explicit and implicit forms of hate speech. Typically, these approaches evaluate the toxicity of utterances in isolation, ignoring the context. Drawing on pragmatics, our study examines how contextual factors can influence the perceived toxicity of utterances, thereby anchoring assessments in a more nuanced semantic framework. We present Toximatics, a dataset that includes context-dependent utterances and it`s toxicity score. We also introduce a novel synthetic data generation pipeline designed to create context-utterance pairs at scale with controlled polarity. This pipeline can enhance existing hate speech datasets by adding contextual information to utterances, either preserving or altering their polarity, and also generate completely new pairs from seed statements. We utilised both features to create Toximatics. To address biases in state-of-the-art hate datasets, which often skew towards specific sensitive topics such as politics, race, and gender, we propose a method to generate neutral utterances typical of various social settings. These are then contextualized to show how neutrality can shift to toxicity or benignity depending on the surrounding context. The evaluation results clearly indicate that the current models are underperforming on this dataset.","Das, Mayukh, Balke, Wolf-Tilo",,,Toximatics: Towards Understanding Toxicity in Real-Life Social Situations,,,10.18653/v1/2024.sigdial-1.65 , ,,"The proliferation of social media has increased the visibility and effects of hate speech. To address this, NLP solutions have been developed to identify both explicit and implicit forms of hate speech. Typically, these approaches evaluate the toxicity of utterances in isolation, ignoring the context. Drawing on pragmatics, our study examines how contextual factors can influence the perceived toxicity of utterances, thereby anchoring assessments in a more nuanced semantic framework. We present Toximatics, a dataset that includes context-dependent utterances and it`s toxicity score. We also introduce a novel synthetic data generation pipeline designed to create context-utterance pairs at scale with controlled polarity. This pipeline can enhance existing hate speech datasets by adding contextual information to utterances, either preserving or altering their polarity, and also generate completely new pairs from seed statements. We utilised both features to create Toximatics. To address biases in state-of-the-art hate datasets, which often skew towards specific sensitive topics such as politics, race, and gender, we propose a method to generate neutral utterances typical of various social settings. These are then contextualized to show how neutrality can shift to toxicity or benignity depending on the surrounding context. The evaluation results clearly indicate that the current models are underperforming on this dataset.",,,,, ,  Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue,,detection,
3440,"**Title**Toxic Speech Detection in {P}ortuguese: A Comparative Study of Large Language Models

**Abstract**This research addresses the automatic detec-
    tion of toxic speech in Portuguese. Utilizing
    the ToLD-Br dataset, which includes 21,000 an-
    notated tweets, we examine the performance of
    Large Language Models (LLMs) such as Ope-
    nAI’s ChatGPT and the monolingual MariTalk
   from Maritaca AI. The study focuses on their
    effectiveness in identifying Toxic speech, the
    influence of few-shot learning, and the intrica-
    cies of annotating datasets, particularly regard-
    ing vulgar language (swear words). Our ex-
    periments reveal that MariTalk (Sabiá) demon-
     strates a nuanced understanding of colloquial
    Portuguese. Meanwhile, ChatGPT, especially
   when augmented with few-shot learning, shows
    robustness comparable to baseline methods.
    This investigation underscores the value of
    both monolingual and lower-capacity models
     in the nuanced field of language-specific Toxic
    speech detection, offering insights into their
    competitive edge against models like ChatGPT.

1  Introduction

In 2023, X (formerly Twitter) updated its documen-
tation on hateful conduct (Twitter, 2023), clearly
defining what they consider a violation of this pol-
icy. This includes explicit prohibitions against mes-
sages that promote fear and discrimination against
specific groups. Additionally, the policy considers
the repeated use of insults, degrading stereotypes,
or images that dehumanize a particular group as
violations. In light of these updated policies, de-
veloping effective automatic hate and toxic speech
detection strategies becomes increasingly crucial.
  Automated toxic speech detection strategies typ-
ically involve linguistic feature analysis, lexicon-based approaches, and supervised machine learning
algorithms trained on labeled datasets (Schmidt and
Wiegand, 2017; Vargas et al., 2022b). Advanced
techniques, including natural language processing
and deep learning methods, seek to comprehend
the semantics and context of textual content (Leite
et al., 2020; Vargas et al., 2022a). Yet, substantial
challenges persist due to the complexity of human
language, the fast evolution of toxic speech, and
the balance needed between free speech and the
fight against harmful content.
  Moreover, while research has predominantly fo-
cused on English, there has been notable progress
in detecting toxic speech in Portuguese. For in-
stance, the ToLD-Br dataset (Leite et al., 2020),
containing 21,000 annotated tweets, allows for new
advancements. Despite BERT-based models reach-
ing macro-F1 scores between 70% and 80% on this
dataset, room for improvement exists.
  The use of Large Language Models (LLMs)
has gained significant notoriety due to the success
of OpenAI’s ChatGPT. Today, impressive results
are being achieved using LLMs for various nat-
ural language tasks (Koco´n et al., 2023), includ-
ing for Portuguese, such as answering questions
from the Brazilian National High School Exam
(Silveira and Mauá, 2018; Nunes et al., 2023), text
reading and comprehension (FaQuAD) (Sayama
et al., 2019), and social network sentiment anal-
ysis (Brum and Nunes, 2017), prediction of de-
pressive disorder (dos Santos and Paraboni, 2023),
among others. A comprehensive study by Koco´n
et al. (2023) demonstrated how ChatGPT, via Ope-
nAI’s API, can be competitive for various NLP
tasks, including hate speech.  In Oliveira et al.","da Silva Oliveira, Amanda, de Carvalho Cecote, Thiago, Alvarenga, Jo{\~a}o Paulo Reis, de Souza Freitas, Vander Luis, da Silva Luz, Eduardo Jos{\'e}",,,Toxic Speech Detection in {P}ortuguese: A Comparative Study of Large Language Models,,, , ,,"This research addresses the automatic detec-
    tion of toxic speech in Portuguese. Utilizing
    the ToLD-Br dataset, which includes 21,000 an-
    notated tweets, we examine the performance of
    Large Language Models (LLMs) such as Ope-
    nAI’s ChatGPT and the monolingual MariTalk
   from Maritaca AI. The study focuses on their
    effectiveness in identifying Toxic speech, the
    influence of few-shot learning, and the intrica-
    cies of annotating datasets, particularly regard-
    ing vulgar language (swear words). Our ex-
    periments reveal that MariTalk (Sabiá) demon-
     strates a nuanced understanding of colloquial
    Portuguese. Meanwhile, ChatGPT, especially
   when augmented with few-shot learning, shows
    robustness comparable to baseline methods.
    This investigation underscores the value of
    both monolingual and lower-capacity models
     in the nuanced field of language-specific Toxic
    speech detection, offering insights into their
    competitive edge against models like ChatGPT.

1  Introduction

In 2023, X (formerly Twitter) updated its documen-
tation on hateful conduct (Twitter, 2023), clearly
defining what they consider a violation of this pol-
icy. This includes explicit prohibitions against mes-
sages that promote fear and discrimination against
specific groups. Additionally, the policy considers
the repeated use of insults, degrading stereotypes,
or images that dehumanize a particular group as
violations. In light of these updated policies, de-
veloping effective automatic hate and toxic speech
detection strategies becomes increasingly crucial.
  Automated toxic speech detection strategies typ-
ically involve linguistic feature analysis, lexicon-based approaches, and supervised machine learning
algorithms trained on labeled datasets (Schmidt and
Wiegand, 2017; Vargas et al., 2022b). Advanced
techniques, including natural language processing
and deep learning methods, seek to comprehend
the semantics and context of textual content (Leite
et al., 2020; Vargas et al., 2022a). Yet, substantial
challenges persist due to the complexity of human
language, the fast evolution of toxic speech, and
the balance needed between free speech and the
fight against harmful content.
  Moreover, while research has predominantly fo-
cused on English, there has been notable progress
in detecting toxic speech in Portuguese. For in-
stance, the ToLD-Br dataset (Leite et al., 2020),
containing 21,000 annotated tweets, allows for new
advancements. Despite BERT-based models reach-
ing macro-F1 scores between 70% and 80% on this
dataset, room for improvement exists.
  The use of Large Language Models (LLMs)
has gained significant notoriety due to the success
of OpenAI’s ChatGPT. Today, impressive results
are being achieved using LLMs for various nat-
ural language tasks (Koco´n et al., 2023), includ-
ing for Portuguese, such as answering questions
from the Brazilian National High School Exam
(Silveira and Mauá, 2018; Nunes et al., 2023), text
reading and comprehension (FaQuAD) (Sayama
et al., 2019), and social network sentiment anal-
ysis (Brum and Nunes, 2017), prediction of de-
pressive disorder (dos Santos and Paraboni, 2023),
among others. A comprehensive study by Koco´n
et al. (2023) demonstrated how ChatGPT, via Ope-
nAI’s API, can be competitive for various NLP
tasks, including hate speech.  In Oliveira et al.",,,,, ,  Proceedings of the 16th International Conference on Computational Processing of Portuguese - Vol. 1,,out_but_toxicity,
3441,"**Title**Toxic Content Detection in online social networks: a new dataset from {B}razilian {R}eddit Communities

**Abstract**The proliferation of online social interactions
    in recent years, with the consequent growth in
    user-generated content, has brought the esca-
     lating issue of toxic language.While automatic
    machine learning models have been effective
    in moderating the vast amount of data on on-
     line social networks, low-resource languages,
    such as Brazilian Portuguese, still lack efficient
    automated moderation tools. We address this
    gap by creating a high-quality dataset collected
    from some of the most popular Brazilian Reddit
    communities. To that end, we manually labeled
    a sample dataset of 2,500 comments extracted
    from the most engaging communities. We con-
    ducted an in-depth exploratory analysis to gain
    valuable insights into the language of toxic and
    non-toxic content. Our results show a high level
    of agreement among annotators, attesting to
    the suitability of this dataset for various down-
    stream machine learning tasks. This research
     offers a significant contribution to the creation
    of a safer online environment for users engag-
    ing in discussions in Portuguese and paves the
   way for more effective automatic moderation
     tools using machine learning.

1  Introduction

With the growth in the number of online social net-
work platforms, increasingly more users are inter-
acting through online media. According to (Statista,
2022), the total number of users of different social
networks is 4 billion people. This figure indicates
the level of importance and ubiquity of these online
platforms in society and their impact, not always
beneficial, on people’s lives. According to (Vogels,
2021), a study conducted in 2020 with US adults
found that around 41% of respondents had experi-
enced some form of online harassment. In addition,
abusive comments in discussions propagate toxicity
and harmful user engagement, radicalizing discus-
sions (Salehabadi et al., 2022). The consequences
of these interactions transcend the virtual world,seriously affecting the lives of real users. Accord-
ing to (Vogels, 2021), 18% of the users who took
part in a survey had suffered some kind of abuse
considered severe beyond the online environment,
including physical threats and stalking.
  The manual moderation of user-generated con-
tent has long been considered the primary approach
to mitigate the negative impact of toxic interactions.
However, the scale and speed at which content is
generated make manual moderation impractical,
prompting the need for automated solutions. Ma-
chine learning models have emerged as a promis-
ing alternative for automating the moderation of
online created content. These models can identify
potentially harmful content, enabling platforms to
proactively take actions such as banning users and
removing harmful content. While machine learning
models have proved effective in several languages
(Perspective, 2022b), their performance for low re-
source languages, such as Brazilian Portuguese, is
still a concern.
  Seeking to address these challenges, this paper
introduces a new dataset for toxicity detection in
Brazilian Portuguese. The annotated texts were re-
trieved from one of the most relevant online social
networks - Reddit -, which has around 1.5 billion
registered users and 430 million active users (Wise,
2023). Reddit is a community that allows users
to interact through anonymous posts (submissions)
and comments. Users are organized into communi-
ties (subreddits) and subscribe to the communities
most aligned with their topics of interest. The col-
lection and annotation of these data are motivated
by the need to propose new models of toxicity de-
tection and improve existing ones for the unique
characteristics of the Portuguese language. Also,
the dataset is tailored specifically for online social
network data, filling the gap on available models
for Portuguese in this domain.
  The remainder of this paper is organized as fol-
lows. We first review the available literature on","Lima, Luiz Henrique Quevedo, Pagano, Adriana Silvina, da Silva, Ana Paula Couto",,,Toxic Content Detection in online social networks: a new dataset from {B}razilian {R}eddit Communities,,, , ,,"The proliferation of online social interactions
    in recent years, with the consequent growth in
    user-generated content, has brought the esca-
     lating issue of toxic language.While automatic
    machine learning models have been effective
    in moderating the vast amount of data on on-
     line social networks, low-resource languages,
    such as Brazilian Portuguese, still lack efficient
    automated moderation tools. We address this
    gap by creating a high-quality dataset collected
    from some of the most popular Brazilian Reddit
    communities. To that end, we manually labeled
    a sample dataset of 2,500 comments extracted
    from the most engaging communities. We con-
    ducted an in-depth exploratory analysis to gain
    valuable insights into the language of toxic and
    non-toxic content. Our results show a high level
    of agreement among annotators, attesting to
    the suitability of this dataset for various down-
    stream machine learning tasks. This research
     offers a significant contribution to the creation
    of a safer online environment for users engag-
    ing in discussions in Portuguese and paves the
   way for more effective automatic moderation
     tools using machine learning.

1  Introduction

With the growth in the number of online social net-
work platforms, increasingly more users are inter-
acting through online media. According to (Statista,
2022), the total number of users of different social
networks is 4 billion people. This figure indicates
the level of importance and ubiquity of these online
platforms in society and their impact, not always
beneficial, on people’s lives. According to (Vogels,
2021), a study conducted in 2020 with US adults
found that around 41% of respondents had experi-
enced some form of online harassment. In addition,
abusive comments in discussions propagate toxicity
and harmful user engagement, radicalizing discus-
sions (Salehabadi et al., 2022). The consequences
of these interactions transcend the virtual world,seriously affecting the lives of real users. Accord-
ing to (Vogels, 2021), 18% of the users who took
part in a survey had suffered some kind of abuse
considered severe beyond the online environment,
including physical threats and stalking.
  The manual moderation of user-generated con-
tent has long been considered the primary approach
to mitigate the negative impact of toxic interactions.
However, the scale and speed at which content is
generated make manual moderation impractical,
prompting the need for automated solutions. Ma-
chine learning models have emerged as a promis-
ing alternative for automating the moderation of
online created content. These models can identify
potentially harmful content, enabling platforms to
proactively take actions such as banning users and
removing harmful content. While machine learning
models have proved effective in several languages
(Perspective, 2022b), their performance for low re-
source languages, such as Brazilian Portuguese, is
still a concern.
  Seeking to address these challenges, this paper
introduces a new dataset for toxicity detection in
Brazilian Portuguese. The annotated texts were re-
trieved from one of the most relevant online social
networks - Reddit -, which has around 1.5 billion
registered users and 430 million active users (Wise,
2023). Reddit is a community that allows users
to interact through anonymous posts (submissions)
and comments. Users are organized into communi-
ties (subreddits) and subscribe to the communities
most aligned with their topics of interest. The col-
lection and annotation of these data are motivated
by the need to propose new models of toxicity de-
tection and improve existing ones for the unique
characteristics of the Portuguese language. Also,
the dataset is tailored specifically for online social
network data, filling the gap on available models
for Portuguese in this domain.
  The remainder of this paper is organized as fol-
lows. We first review the available literature on",,,,, ,  Proceedings of the 16th International Conference on Computational Processing of Portuguese - Vol. 1,,out_but_toxicity,
3442,"**Title**Mitigating Biases to Embrace Diversity: A Comprehensive Annotation Benchmark for Toxic Language

**Abstract**This study introduces a prescriptive annotation benchmark grounded in humanities research to ensure consistent, unbiased labeling of offensive language, particularly for casual and non-mainstream language uses. We contribute two newly annotated datasets that achieve higher inter-annotator agreement between human and language model (LLM) annotations compared to original datasets based on descriptive instructions. Our experiments show that LLMs can serve as effective alternatives when professional annotators are unavailable. Moreover, smaller models fine-tuned on multi-source LLM-annotated data outperform models trained on larger, single-source human-annotated datasets. These findings highlight the value of structured guidelines in reducing subjective variability, maintaining performance with limited data, and embracing language diversity. Content Warning: This article only analyzes offensive language for academic purposes. Discretion is advised.","Hou, Xinmeng",,,Mitigating Biases to Embrace Diversity: A Comprehensive Annotation Benchmark for Toxic Language,,,10.18653/v1/2024.nlp4dh-1.36 , ,,"This study introduces a prescriptive annotation benchmark grounded in humanities research to ensure consistent, unbiased labeling of offensive language, particularly for casual and non-mainstream language uses. We contribute two newly annotated datasets that achieve higher inter-annotator agreement between human and language model (LLM) annotations compared to original datasets based on descriptive instructions. Our experiments show that LLMs can serve as effective alternatives when professional annotators are unavailable. Moreover, smaller models fine-tuned on multi-source LLM-annotated data outperform models trained on larger, single-source human-annotated datasets. These findings highlight the value of structured guidelines in reducing subjective variability, maintaining performance with limited data, and embracing language diversity. Content Warning: This article only analyzes offensive language for academic purposes. Discretion is advised.",,,,, ,  Proceedings of the 4th International Conference on Natural Language Processing for Digital Humanities,,Gen_dataset,
3443,"**Title**Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation

**Abstract**Most task-oriented dialogue (TOD) benchmarks assume users that know exactly how to use the system by constraining the user behaviors within the system`s capabilities via strict user goals, namely {\textquotedblleft}user familiarity{\textquotedblright} bias. This data bias deepens when it combines with data-driven TOD systems, as it is impossible to fathom the effect of it with existing static evaluations. Hence, we conduct an interactive user study to unveil how vulnerable TOD systems are against realistic scenarios. In particular, we compare users with 1) detailed goal instructions that conform to the system boundaries (closed-goal) and 2) vague goal instructions that are often unsupported but realistic (open-goal). Our study reveals that conversations in open-goal settings lead to catastrophic failures of the system, in which 92{\%} of the dialogues had significant issues. Moreover, we conduct a thorough analysis to identify distinctive features between the two settings through error annotation. From this, we discover a novel {\textquotedblleft}pretending{\textquotedblright} behavior, in which the system pretends to handle the user requests even though they are beyond the system`s capabilities. We discuss its characteristics and toxicity while showing recent large language models can also suffer from this behavior.","Kim, Takyoung, Shin, Jamin, Kim, Young-Ho, Bae, Sanghwan, Kim, Sungdong",,,Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation,,, , ,,"Most task-oriented dialogue (TOD) benchmarks assume users that know exactly how to use the system by constraining the user behaviors within the system`s capabilities via strict user goals, namely {\textquotedblleft}user familiarity{\textquotedblright} bias. This data bias deepens when it combines with data-driven TOD systems, as it is impossible to fathom the effect of it with existing static evaluations. Hence, we conduct an interactive user study to unveil how vulnerable TOD systems are against realistic scenarios. In particular, we compare users with 1) detailed goal instructions that conform to the system boundaries (closed-goal) and 2) vague goal instructions that are often unsupported but realistic (open-goal). Our study reveals that conversations in open-goal settings lead to catastrophic failures of the system, in which 92{\%} of the dialogues had significant issues. Moreover, we conduct a thorough analysis to identify distinctive features between the two settings through error annotation. From this, we discover a novel {\textquotedblleft}pretending{\textquotedblright} behavior, in which the system pretends to handle the user requests even though they are beyond the system`s capabilities. We discuss its characteristics and toxicity while showing recent large language models can also suffer from this behavior.",,,,, ,  Proceedings of the 6th Workshop on NLP for Conversational AI (NLP4ConvAI 2024),,detection,
3444,"**Title**Exploring Inherent Biases in {LLM}s within {K}orean Social Context: A Comparative Analysis of {C}hat{GPT} and {GPT}-4

**Abstract**Large Language Models (LLMs) have significantly impacted various fields requiring advanced linguistic understanding, yet concerns regarding their inherent biases and ethical considerations have also increased. Notably, LLMs have been critiqued for perpetuating stereotypes against diverse groups based on race, sexual orientation, and other attributes. However, most research analyzing these biases has predominantly focused on communities where English is the primary language, neglecting to consider the cultural and linguistic nuances of other societies. In this paper, we aim to explore the inherent biases and toxicity of LLMs, specifically within the social context of Korea. We devise a set of prompts that reflect major societal issues in Korea and assign varied personas to both ChatGPT and GPT-4 to assess the toxicity of the generated sentences. Our findings indicate that certain personas or prompt combinations consistently yield harmful content, highlighting the potential risks associated with specific persona-issue alignments within the Korean cultural framework. Furthermore, we discover that GPT-4 can produce more than twice the level of toxic content than ChatGPT under certain conditions.","Lee, Seungyoon, Kim, Dong, Jung, Dahyun, Park, Chanjun, Lim, Heuiseok",,,Exploring Inherent Biases in {LLM}s within {K}orean Social Context: A Comparative Analysis of {C}hat{GPT} and {GPT}-4,,,10.18653/v1/2024.naacl-srw.11 , ,,"Large Language Models (LLMs) have significantly impacted various fields requiring advanced linguistic understanding, yet concerns regarding their inherent biases and ethical considerations have also increased. Notably, LLMs have been critiqued for perpetuating stereotypes against diverse groups based on race, sexual orientation, and other attributes. However, most research analyzing these biases has predominantly focused on communities where English is the primary language, neglecting to consider the cultural and linguistic nuances of other societies. In this paper, we aim to explore the inherent biases and toxicity of LLMs, specifically within the social context of Korea. We devise a set of prompts that reflect major societal issues in Korea and assign varied personas to both ChatGPT and GPT-4 to assess the toxicity of the generated sentences. Our findings indicate that certain personas or prompt combinations consistently yield harmful content, highlighting the potential risks associated with specific persona-issue alignments within the Korean cultural framework. Furthermore, we discover that GPT-4 can produce more than twice the level of toxic content than ChatGPT under certain conditions.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 4: Student Research Workshop),,out_but_toxicity,
3445,"**Title**{L}ife{T}ox: Unveiling Implicit Toxicity in Life Advice

**Abstract**As large language models become increasingly integrated into daily life, detecting implicit toxicity across diverse contexts is crucial. To this end, we introduce $\texttt{LifeTox}$, a dataset designed for identifying implicit toxicity within a broad range of advice-seeking scenarios. Unlike existing safety datasets, $\texttt{LifeTox}$ comprises diverse contexts derived from personal experiences through open-ended questions. Our experiments demonstrate that RoBERTa fine-tuned on $\texttt{LifeTox}$ matches or surpasses the zero-shot performance of large language models in toxicity classification tasks. These results underscore the efficacy of $\texttt{LifeTox}$ in addressing the complex challenges inherent in implicit toxicity. We open-sourced the dataset and the $\texttt{LifeTox}$ moderator family; 350M, 7B, and 13B.","Kim, Minbeom, Koo, Jahyun, Lee, Hwanhee, Park, Joonsuk, Lee, Hwaran, Jung, Kyomin",,,{L}ife{T}ox: Unveiling Implicit Toxicity in Life Advice,,,10.18653/v1/2024.naacl-short.60 , ,,"As large language models become increasingly integrated into daily life, detecting implicit toxicity across diverse contexts is crucial. To this end, we introduce $\texttt{LifeTox}$, a dataset designed for identifying implicit toxicity within a broad range of advice-seeking scenarios. Unlike existing safety datasets, $\texttt{LifeTox}$ comprises diverse contexts derived from personal experiences through open-ended questions. Our experiments demonstrate that RoBERTa fine-tuned on $\texttt{LifeTox}$ matches or surpasses the zero-shot performance of large language models in toxicity classification tasks. These results underscore the efficacy of $\texttt{LifeTox}$ in addressing the complex challenges inherent in implicit toxicity. We open-sourced the dataset and the $\texttt{LifeTox}$ moderator family; 350M, 7B, and 13B.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers),,detection,
3446,"**Title**A Pretrainer`s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, {\&} Toxicity

**Abstract**Pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. We pretrain models on data curated (1) at different collection times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we find that temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we measure the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Third, we empirically validate that heterogeneous data sources, like books and web, are beneficial and warrant greater prioritization. To date, these experiments constitute the single largest publicly documented empirical study of the effects of pretraining data. Spanning 28 unique 1.5 billion parameter models pretrained from scratch, these findings validate, quantify, and expose many undocumented intuitions about text pretraining, which ultimately support more informed data-centric decisions in model development.","Longpre, Shayne, Yauney, Gregory, Reif, Emily, Lee, Katherine, Roberts, Adam, Zoph, Barret, Zhou, Denny, Wei, Jason, Robinson, Kevin, Mimno, David, Ippolito, Daphne",,,"A Pretrainer`s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, {\&} Toxicity",,,10.18653/v1/2024.naacl-long.179 , ,,"Pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. We pretrain models on data curated (1) at different collection times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we find that temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we measure the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Third, we empirically validate that heterogeneous data sources, like books and web, are beneficial and warrant greater prioritization. To date, these experiments constitute the single largest publicly documented empirical study of the effects of pretraining data. Spanning 28 unique 1.5 billion parameter models pretrained from scratch, these findings validate, quantify, and expose many undocumented intuitions about text pretraining, which ultimately support more informed data-centric decisions in model development.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,out_of_scope,
3447,"**Title**Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback

**Abstract**Large language models (LLMs) often generate biased outputs containing offensive, toxic, or stereotypical text. Existing LLM alignment methods such as reinforcement learning from human feedback (RLHF) alleviate biases primarily based on reward signals from current model outputs without considering the source of biases. In this work, to explore how biases are formed, we revisit LLMs' text generation from a causal perspective. We identify pretraining data and input prompts, which contain semantic correlations of textual phrases, as two confounders between LLMs and model outputs causing biases. Inspired by our causal view, we leverage the reward model in RL alignment as an instrumental variable to perform causal intervention on LLMs. Utilizing the reward difference between an initial LLM and intervened LLM as interventional feedback to guide RL finetuning, we propose Causality-Aware Alignment (CAA) for LLM debiasing. Experiments on two text generation tasks with three different alignment objectives demonstrate the advantages of our method in aligning LLMs to generate less biased and safer outputs.","Xia, Yu, Yu, Tong, He, Zhankui, Zhao, Handong, McAuley, Julian, Li, Shuai",,,Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback,,,10.18653/v1/2024.naacl-long.262 , ,,"Large language models (LLMs) often generate biased outputs containing offensive, toxic, or stereotypical text. Existing LLM alignment methods such as reinforcement learning from human feedback (RLHF) alleviate biases primarily based on reward signals from current model outputs without considering the source of biases. In this work, to explore how biases are formed, we revisit LLMs' text generation from a causal perspective. We identify pretraining data and input prompts, which contain semantic correlations of textual phrases, as two confounders between LLMs and model outputs causing biases. Inspired by our causal view, we leverage the reward model in RL alignment as an instrumental variable to perform causal intervention on LLMs. Utilizing the reward difference between an initial LLM and intervened LLM as interventional feedback to guide RL finetuning, we propose Causality-Aware Alignment (CAA) for LLM debiasing. Experiments on two text generation tasks with three different alignment objectives demonstrate the advantages of our method in aligning LLMs to generate less biased and safer outputs.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detox,
3448,"**Title**{XST}est: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models

**Abstract**Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This risk motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse to comply with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a systematic way. XSTest comprises 250 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with, and 200 unsafe prompts as contrasts that models, for most applications, should refuse. We describe XSTest`s creation and composition, and then use the test suite to highlight systematic failure modes in state-of-the-art language models as well as more general challenges in building safer language models.","R{\""o}ttger, Paul, Kirk, Hannah, Vidgen, Bertie, Attanasio, Giuseppe, Bianchi, Federico, Hovy, Dirk",,,{XST}est: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models,,,10.18653/v1/2024.naacl-long.301 , ,,"Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This risk motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse to comply with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a systematic way. XSTest comprises 250 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with, and 200 unsafe prompts as contrasts that models, for most applications, should refuse. We describe XSTest`s creation and composition, and then use the test suite to highlight systematic failure modes in state-of-the-art language models as well as more general challenges in building safer language models.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detection,
3449,"**Title**{T}o{XCL}: A Unified Framework for Toxic Speech Detection and Explanation

**Abstract**The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists of three modules: a (i) Target Group Generator to generate the targeted demographic group(s) of a given post; an (ii) Encoder-Decoder Model in which the encoder focuses on detecting implicit toxic speech and is boosted by a (iii) Teacher Classifier via knowledge distillation, and the decoder generates the necessary explanation. ToXCL achieves new state-of-the-art effectiveness, and outperforms baselines significantly.","Hoang, Nhat, Do, Xuan Long, Do, Duc Anh, Vu, Duc Anh, Luu, Anh Tuan",,,{T}o{XCL}: A Unified Framework for Toxic Speech Detection and Explanation,,,10.18653/v1/2024.naacl-long.359 , ,,"The proliferation of online toxic speech is a pertinent problem posing threats to demographic groups. While explicit toxic speech contains offensive lexical signals, implicit one consists of coded or indirect language. Therefore, it is crucial for models not only to detect implicit toxic speech but also to explain its toxicity. This draws a unique need for unified frameworks that can effectively detect and explain implicit toxic speech. Prior works mainly formulated the task of toxic speech detection and explanation as a text generation problem. Nonetheless, models trained using this strategy can be prone to suffer from the consequent error propagation problem. Moreover, our experiments reveal that the detection results of such models are much lower than those that focus only on the detection task. To bridge these gaps, we introduce ToXCL, a unified framework for the detection and explanation of implicit toxic speech. Our model consists of three modules: a (i) Target Group Generator to generate the targeted demographic group(s) of a given post; an (ii) Encoder-Decoder Model in which the encoder focuses on detecting implicit toxic speech and is boosted by a (iii) Teacher Classifier via knowledge distillation, and the decoder generates the necessary explanation. ToXCL achieves new state-of-the-art effectiveness, and outperforms baselines significantly.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detection,
3450,"**Title**Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with {RLAIF}

**Abstract**Counterspeech, defined as a response to mitigate online hate speech, is increasingly used as a non-censorial solution. The effectiveness of addressing hate speech involves dispelling the stereotypes, prejudices, and biases often subtly implied in brief, single-sentence statements or abuses. These expressions challenge language models, especially in seq2seq tasks, as model performance typically excels with longer contexts. Our study introduces CoARL, a novel framework enhancing counterspeech generation by modeling the pragmatic implications underlying social biases in hateful statements. The first two phases of CoARL involve sequential multi-instruction tuning, teaching the model to understand intents, reactions, and harms of offensive statements, and then learning task-specific low-rank adapter weights for generating intent-conditioned counterspeech. The final phase uses reinforcement learning to fine-tune outputs for effectiveness and nontoxicity. CoARL outperforms existing benchmarks in intent-conditioned counterspeech generation, showing an average improvement of {\ensuremath{\sim}}3 points in intent-conformity and {\ensuremath{\sim}}4 points in argument-quality metrics. Extensive human evaluation supports CoARL`s efficacy in generating superior and more context-appropriate responses compared to existing systems, including prominent LLMs like ChatGPT.","Hengle, Amey, Padhi, Aswini, Singh, Sahajpreet, Bandhakavi, Anil, Akhtar, Md Shad, Chakraborty, Tanmoy",,,Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with {RLAIF},,,10.18653/v1/2024.naacl-long.374 , ,,"Counterspeech, defined as a response to mitigate online hate speech, is increasingly used as a non-censorial solution. The effectiveness of addressing hate speech involves dispelling the stereotypes, prejudices, and biases often subtly implied in brief, single-sentence statements or abuses. These expressions challenge language models, especially in seq2seq tasks, as model performance typically excels with longer contexts. Our study introduces CoARL, a novel framework enhancing counterspeech generation by modeling the pragmatic implications underlying social biases in hateful statements. The first two phases of CoARL involve sequential multi-instruction tuning, teaching the model to understand intents, reactions, and harms of offensive statements, and then learning task-specific low-rank adapter weights for generating intent-conditioned counterspeech. The final phase uses reinforcement learning to fine-tune outputs for effectiveness and nontoxicity. CoARL outperforms existing benchmarks in intent-conditioned counterspeech generation, showing an average improvement of {\ensuremath{\sim}}3 points in intent-conformity and {\ensuremath{\sim}}4 points in argument-quality metrics. Extensive human evaluation supports CoARL`s efficacy in generating superior and more context-appropriate responses compared to existing systems, including prominent LLMs like ChatGPT.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detox,
3451,"**Title**Exploring the Emotional Dimension of {F}rench Online Toxic Content

**Abstract**One of the biggest hurdles for the effective analysis of data collected on social platforms is the need for deeper insights on the content and meaning of this data. Emotion annotation can bring new perspectives on this issue and can enable the identification of content{--}specific features. This study aims at investigating the ways in which variation in online content can be explored through emotion annotation and corpus-based analysis. The paper describes the emotion annotation of three data sets in French composed of extremist, sexist and hateful messages respectively. To this end, first a fine-grained, corpus annotation scheme was used to annotate the data sets and then several empirical studies were carried out to characterize the content in the light of emotional categories. Results suggest that emotion annotations can provide new insights for online content analysis and stronger empirical background for automatic content detection.","Dragos, Valentina, Battistelli, Delphine, Sow, Fatou, Etienne, Aline",,,Exploring the Emotional Dimension of {F}rench Online Toxic Content,,, , ,,"One of the biggest hurdles for the effective analysis of data collected on social platforms is the need for deeper insights on the content and meaning of this data. Emotion annotation can bring new perspectives on this issue and can enable the identification of content{--}specific features. This study aims at investigating the ways in which variation in online content can be explored through emotion annotation and corpus-based analysis. The paper describes the emotion annotation of three data sets in French composed of extremist, sexist and hateful messages respectively. To this end, first a fine-grained, corpus annotation scheme was used to annotate the data sets and then several empirical studies were carried out to characterize the content in the light of emotional categories. Results suggest that emotion annotations can provide new insights for online content analysis and stronger empirical background for automatic content detection.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,out_but_toxicity,
3452,"**Title**{K}o{C}o{S}a: {K}orean Context-aware Sarcasm Detection Dataset

**Abstract**Sarcasm is a way of verbal irony where someone says the opposite of what they mean, often to ridicule a person, situation, or idea. It is often difficult to detect sarcasm in the dialogue since detecting sarcasm should reflect the context (i.e., dialogue history). In this paper, we introduce a new dataset for the Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware Sarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and the labels for this task on the last response. To build the dataset, we propose an efficient sarcasm detection dataset generation pipeline: 1) generating new sarcastic dialogues from source dialogues with large language models, 2) automatic and manual filtering of abnormal and toxic dialogues, and 3) human annotation for the sarcasm detection task. We also provide a simple but effective baseline for the Korean sarcasm detection task trained on our dataset. Experimental results on the dataset show that our baseline system outperforms strong baselines like large language models, such as GPT-3.5, in the Korean sarcasm detection task. We show that the sarcasm detection task relies deeply on the existence of sufficient context. We will release the dataset at https://github.com/Yu-billie/KoCoSa{\_}sarcasm{\_}detection.","Kim, Yumin, Suh, Heejae, Kim, Mingi, Won, Dongyeon, Lee, Hwanhee",,,{K}o{C}o{S}a: {K}orean Context-aware Sarcasm Detection Dataset,,, , ,,"Sarcasm is a way of verbal irony where someone says the opposite of what they mean, often to ridicule a person, situation, or idea. It is often difficult to detect sarcasm in the dialogue since detecting sarcasm should reflect the context (i.e., dialogue history). In this paper, we introduce a new dataset for the Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware Sarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and the labels for this task on the last response. To build the dataset, we propose an efficient sarcasm detection dataset generation pipeline: 1) generating new sarcastic dialogues from source dialogues with large language models, 2) automatic and manual filtering of abnormal and toxic dialogues, and 3) human annotation for the sarcasm detection task. We also provide a simple but effective baseline for the Korean sarcasm detection task trained on our dataset. Experimental results on the dataset show that our baseline system outperforms strong baselines like large language models, such as GPT-3.5, in the Korean sarcasm detection task. We show that the sarcasm detection task relies deeply on the existence of sufficient context. We will release the dataset at https://github.com/Yu-billie/KoCoSa{\_}sarcasm{\_}detection.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,out_of_scope,
3453,"**Title**On Zero-Shot Counterspeech Generation by {LLM}s

**Abstract**With the emergence of numerous Large Language Models (LLM), the usage of such models in various Natural Language Processing (NLP) applications is increasing extensively. Counterspeech generation is one such key task where efforts are made to develop generative models by fine-tuning LLMs with hatespeech - counterspeech pairs, but none of these attempts explores the intrinsic properties of large language models in zero-shot settings. In this work, we present a comprehensive analysis of the performances of four LLMs namely GPT-2, DialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech generation, which is the first of its kind. For GPT-2 and DialoGPT, we further investigate the deviation in performance with respect to the sizes (small, medium, large) of the models. On the other hand, we propose three different prompting strategies for generating different types of counterspeech and analyse the impact of such strategies on the performance of the models. Our analysis shows that there is an improvement in generation quality for two datasets (17{\%}), however the toxicity increase (25{\%}) with increase in model size. Considering type of model, GPT-2 and FlanT5 models are significantly better in terms of counterspeech quality but also have high toxicity as compared to DialoGPT. ChatGPT are much better at generating counter speech than other models across all metrics. In terms of prompting, we find that our proposed strategies help in improving counter speech generation across all the models.","Saha, Punyajoy, Agrawal, Aalok, Jana, Abhik, Biemann, Chris, Mukherjee, Animesh",,,On Zero-Shot Counterspeech Generation by {LLM}s,,, , ,,"With the emergence of numerous Large Language Models (LLM), the usage of such models in various Natural Language Processing (NLP) applications is increasing extensively. Counterspeech generation is one such key task where efforts are made to develop generative models by fine-tuning LLMs with hatespeech - counterspeech pairs, but none of these attempts explores the intrinsic properties of large language models in zero-shot settings. In this work, we present a comprehensive analysis of the performances of four LLMs namely GPT-2, DialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech generation, which is the first of its kind. For GPT-2 and DialoGPT, we further investigate the deviation in performance with respect to the sizes (small, medium, large) of the models. On the other hand, we propose three different prompting strategies for generating different types of counterspeech and analyse the impact of such strategies on the performance of the models. Our analysis shows that there is an improvement in generation quality for two datasets (17{\%}), however the toxicity increase (25{\%}) with increase in model size. Considering type of model, GPT-2 and FlanT5 models are significantly better in terms of counterspeech quality but also have high toxicity as compared to DialoGPT. ChatGPT are much better at generating counter speech than other models across all metrics. In terms of prompting, we find that our proposed strategies help in improving counter speech generation across all the models.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,detox,
3454,"**Title**Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment

**Abstract**Alignment with human preference prevents large language models (LLMs) from generating misleading or toxic content while requiring high-cost human feedback. Assuming resources of human annotation are limited, there are two different ways of allocating considered: more diverse PROMPTS or more diverse RESPONSES to be labeled. Nonetheless, a straightforward comparison between their impact is absent. In this work, we first control the diversity of both sides according to the number of samples for fine-tuning, which can directly reflect their influence. We find that instead of numerous prompts, more responses but fewer prompts better trigger LLMs for human alignment. Additionally, the concept of diversity for prompts can be more complex than responses that are typically quantified by single digits. Consequently, a new formulation of prompt diversity is proposed, further implying a linear correlation with the final performance of LLMs after fine-tuning. We also leverage it on data augmentation and conduct experiments to show its effect on different algorithms.","Song, Feifan, Yu, Bowen, Lang, Hao, Yu, Haiyang, Huang, Fei, Wang, Houfeng, Li, Yongbin",,,Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment,,, , ,,"Alignment with human preference prevents large language models (LLMs) from generating misleading or toxic content while requiring high-cost human feedback. Assuming resources of human annotation are limited, there are two different ways of allocating considered: more diverse PROMPTS or more diverse RESPONSES to be labeled. Nonetheless, a straightforward comparison between their impact is absent. In this work, we first control the diversity of both sides according to the number of samples for fine-tuning, which can directly reflect their influence. We find that instead of numerous prompts, more responses but fewer prompts better trigger LLMs for human alignment. Additionally, the concept of diversity for prompts can be more complex than responses that are typically quantified by single digits. Consequently, a new formulation of prompt diversity is proposed, further implying a linear correlation with the final performance of LLMs after fine-tuning. We also leverage it on data augmentation and conduct experiments to show its effect on different algorithms.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,detox,
3455,"**Title**Adversarial {DPO}: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents

**Abstract**Recent advancements in open-domain dialogue systems have been propelled by the emergence of high-quality large language models (LLMs) and various effective training methodologies. Nevertheless, the presence of toxicity within these models presents a significant challenge that can potentially diminish the user experience. In this study, we introduce an innovative training algorithm, an improvement upon direct preference optimization (DPO), called adversarial DPO (ADPO). The ADPO algorithm is designed to train models to assign higher probability distributions to preferred responses and lower distributions to unsafe responses, which are self-generated using the toxic control token. We demonstrate that ADPO enhances the model`s resilience against harmful conversations while minimizing performance degradation. Furthermore, we illustrate that ADPO offers a more stable training procedure compared to the traditional DPO. To the best of our knowledge, this is the first adaptation of the DPO algorithm that directly incorporates harmful data into the generative model, thereby reducing the need to artificially create safe dialogue data.","Kim, San, Lee, Gary",,,Adversarial {DPO}: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents,,,10.18653/v1/2024.findings-naacl.118 , ,,"Recent advancements in open-domain dialogue systems have been propelled by the emergence of high-quality large language models (LLMs) and various effective training methodologies. Nevertheless, the presence of toxicity within these models presents a significant challenge that can potentially diminish the user experience. In this study, we introduce an innovative training algorithm, an improvement upon direct preference optimization (DPO), called adversarial DPO (ADPO). The ADPO algorithm is designed to train models to assign higher probability distributions to preferred responses and lower distributions to unsafe responses, which are self-generated using the toxic control token. We demonstrate that ADPO enhances the model`s resilience against harmful conversations while minimizing performance degradation. Furthermore, we illustrate that ADPO offers a more stable training procedure compared to the traditional DPO. To the best of our knowledge, this is the first adaptation of the DPO algorithm that directly incorporates harmful data into the generative model, thereby reducing the need to artificially create safe dialogue data.",,,,, ,  Findings of the Association for Computational Linguistics: NAACL 2024,,detox,
3456,"**Title**Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing

**Abstract**Large language models (LLMs) are increasingly being adopted in a wide range of real-world applications. Despite their impressive performance, recent studies have shown that LLMs are vulnerable to deliberately crafted adversarial prompts even when aligned via Reinforcement Learning from Human Feedback or supervised fine-tuning. While existing defense methods focus on either detecting harmful prompts or reducing the likelihood of harmful responses through various means, defending LLMs against jailbreak attacks based on the inner mechanisms of LLMs remains largely unexplored. In this work, we investigate how LLMs respond to harmful prompts and propose a novel defense method termed \textbf{L}ayer-specific \textbf{Ed}iting (LED) to enhance the resilience of LLMs against jailbreak attacks. Through LED, we reveal that several critical \textit{safety layers} exist among the early layers of LLMs. We then show that realigning these safety layers (and some selected additional layers) with the decoded safe response from identified \textit{toxic layers} can significantly improve the alignment of LLMs against jailbreak attacks. Extensive experiments across various LLMs (e.g., Llama2, Mistral) show the effectiveness of LED, which effectively defends against jailbreak attacks while maintaining performance on benign prompts. Our code is available at \url{https://github.com/ledllm/ledllm}.","Zhao, Wei, Li, Zhe, Li, Yige, Zhang, Ye, Sun, Jun",,,Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing,,,10.18653/v1/2024.findings-emnlp.293 , ,,"Large language models (LLMs) are increasingly being adopted in a wide range of real-world applications. Despite their impressive performance, recent studies have shown that LLMs are vulnerable to deliberately crafted adversarial prompts even when aligned via Reinforcement Learning from Human Feedback or supervised fine-tuning. While existing defense methods focus on either detecting harmful prompts or reducing the likelihood of harmful responses through various means, defending LLMs against jailbreak attacks based on the inner mechanisms of LLMs remains largely unexplored. In this work, we investigate how LLMs respond to harmful prompts and propose a novel defense method termed \textbf{L}ayer-specific \textbf{Ed}iting (LED) to enhance the resilience of LLMs against jailbreak attacks. Through LED, we reveal that several critical \textit{safety layers} exist among the early layers of LLMs. We then show that realigning these safety layers (and some selected additional layers) with the decoded safe response from identified \textit{toxic layers} can significantly improve the alignment of LLMs against jailbreak attacks. Extensive experiments across various LLMs (e.g., Llama2, Mistral) show the effectiveness of LED, which effectively defends against jailbreak attacks while maintaining performance on benign prompts. Our code is available at \url{https://github.com/ledllm/ledllm}.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detox,
3457,"**Title**Can {LLM}s Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric

**Abstract**In the pursuit of developing Large Language Models (LLMs) that adhere to societal standards, it is imperative to detect the toxicity in the generated text. The majority of existing toxicity metrics rely on encoder models trained on specific toxicity datasets, which are susceptible to out-of-distribution (OOD) problems and depend on the dataset`s definition of toxicity. In this paper, we introduce a robust metric grounded on LLMs to flexibly measure toxicity according to the given definition. We first analyze the toxicity factors, followed by an examination of the intrinsic toxic attributes of LLMs to ascertain their suitability as evaluators. Finally, we evaluate the performance of our metric with detailed analysis. Our empirical results demonstrate outstanding performance in measuring toxicity within verified factors, improving on conventional metrics by 12 points in the F1 score. Our findings also indicate that upstream toxicity significantly influences downstream metrics, suggesting that LLMs are unsuitable for toxicity evaluations within unverified factors.","Koh, Hyukhun, Kim, Dohyung, Lee, Minwoo, Jung, Kyomin",,,Can {LLM}s Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric,,,10.18653/v1/2024.findings-emnlp.353 , ,,"In the pursuit of developing Large Language Models (LLMs) that adhere to societal standards, it is imperative to detect the toxicity in the generated text. The majority of existing toxicity metrics rely on encoder models trained on specific toxicity datasets, which are susceptible to out-of-distribution (OOD) problems and depend on the dataset`s definition of toxicity. In this paper, we introduce a robust metric grounded on LLMs to flexibly measure toxicity according to the given definition. We first analyze the toxicity factors, followed by an examination of the intrinsic toxic attributes of LLMs to ascertain their suitability as evaluators. Finally, we evaluate the performance of our metric with detailed analysis. Our empirical results demonstrate outstanding performance in measuring toxicity within verified factors, improving on conventional metrics by 12 points in the F1 score. Our findings also indicate that upstream toxicity significantly influences downstream metrics, suggesting that LLMs are unsuitable for toxicity evaluations within unverified factors.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detection,
3458,"**Title**{P}cl{GPT}: A Large Language Model for Patronizing and Condescending Language Detection

**Abstract**Disclaimer: Samples in this paper may be harmful and cause discomfort! Patronizing and condescending language (PCL) is a form of speech directed at vulnerable groups. As an essential branch of toxic language, this type of language exacerbates conflicts and confrontations among Internet communities and detrimentally impacts disadvantaged groups. Traditional pre-trained language models (PLMs) perform poorly in detecting PCL due to its implicit toxicity traits like hypocrisy and false sympathy. With the rise of large language models (LLMs), we can harness their rich emotional semantics to establish a paradigm for exploring implicit toxicity. In this paper, we introduce PclGPT, a comprehensive LLM benchmark designed specifically for PCL. We collect, annotate, and integrate the Pcl-PT/SFT dataset, and then develop a bilingual PclGPT-EN/CN model group through a comprehensive pre-training and supervised fine-tuning staircase process to facilitate implicit toxic detection. Group detection results and fine-grained detection from PclGPT and other models reveal significant variations in the degree of bias in PCL towards different vulnerable groups, necessitating increased societal attention to protect them.","Wang, Hongbo, LiMingDa, LiMingDa, Lu, Junyu, Xia, Hebin, Yang, Liang, Xu, Bo, Liu, Ruizhu, Lin, Hongfei",,,{P}cl{GPT}: A Large Language Model for Patronizing and Condescending Language Detection,,,10.18653/v1/2024.findings-emnlp.406 , ,,"Disclaimer: Samples in this paper may be harmful and cause discomfort! Patronizing and condescending language (PCL) is a form of speech directed at vulnerable groups. As an essential branch of toxic language, this type of language exacerbates conflicts and confrontations among Internet communities and detrimentally impacts disadvantaged groups. Traditional pre-trained language models (PLMs) perform poorly in detecting PCL due to its implicit toxicity traits like hypocrisy and false sympathy. With the rise of large language models (LLMs), we can harness their rich emotional semantics to establish a paradigm for exploring implicit toxicity. In this paper, we introduce PclGPT, a comprehensive LLM benchmark designed specifically for PCL. We collect, annotate, and integrate the Pcl-PT/SFT dataset, and then develop a bilingual PclGPT-EN/CN model group through a comprehensive pre-training and supervised fine-tuning staircase process to facilitate implicit toxic detection. Group detection results and fine-grained detection from PclGPT and other models reveal significant variations in the degree of bias in PCL towards different vulnerable groups, necessitating increased societal attention to protect them.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detection,
3459,"**Title**Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective on Molecule Graphs

**Abstract**In recent years, Graph Neural Networks (GNNs) have become successful in molecular property prediction tasks such as toxicity analysis. However, due to the black-box nature of GNNs, their outputs can be concerning in high-stakes decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph Counterfactual Explanation (GCE) has emerged as a promising approach to improve GNN transparency. However, current GCE methods usually fail to take domain-specific knowledge into consideration, which can result in outputs that are not easily comprehensible by humans. To address this challenge, we propose a novel GCE method, LLM-GCE, to unleash the power of large language models (LLMs) in explaining GNNs for molecular property prediction. Specifically, we utilize an autoencoder to generate the counterfactual graph topology from a set of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which provides intermediate feedback derived from the generated counterfactuals as an attempt to give more faithful guidance. Extensive experiments demonstrate the superior performance of LLM-GCE. Our code is released on https://github.com/YinhanHe123/new{\_}LLM4GNNExplanation.","He, Yinhan, Zheng, Zaiyi, Soga, Patrick, Zhu, Yaochen, Dong, Yushun, Li, Jundong",,,Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective on Molecule Graphs,,,10.18653/v1/2024.findings-emnlp.415 , ,,"In recent years, Graph Neural Networks (GNNs) have become successful in molecular property prediction tasks such as toxicity analysis. However, due to the black-box nature of GNNs, their outputs can be concerning in high-stakes decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph Counterfactual Explanation (GCE) has emerged as a promising approach to improve GNN transparency. However, current GCE methods usually fail to take domain-specific knowledge into consideration, which can result in outputs that are not easily comprehensible by humans. To address this challenge, we propose a novel GCE method, LLM-GCE, to unleash the power of large language models (LLMs) in explaining GNNs for molecular property prediction. Specifically, we utilize an autoencoder to generate the counterfactual graph topology from a set of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which provides intermediate feedback derived from the generated counterfactuals as an attempt to give more faithful guidance. Extensive experiments demonstrate the superior performance of LLM-GCE. Our code is released on https://github.com/YinhanHe123/new{\_}LLM4GNNExplanation.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,out_of_scope,
3460,"**Title**Modeling Human Subjectivity in {LLM}s Using Explicit and Implicit Human Factors in Personas

**Abstract**Large language models (LLMs) are increasingly being used in human-centered social scientific tasks, such as data annotation, synthetic data creation, and engaging in dialog. However, these tasks are highly subjective and dependent on human factors, such as one`s environment, attitudes, beliefs, and lived experiences. Thus, it may be the case that employing LLMs (which do not have such human factors) in these tasks results in a lack of variation in data, failing to reflect the diversity of human experiences. In this paper, we examine the role of prompting LLMs with human-like personas and asking the models to answer as if they were a specific human. This is done explicitly, with exact demographics, political beliefs, and lived experiences, or implicitly via names prevalent in specific populations. The LLM personas are then evaluated via (1) subjective annotation task (e.g., detecting toxicity) and (2) a belief generation task, where both tasks are known to vary across human factors. We examine the impact of explicit vs. implicit personas and investigate which human factors LLMs recognize and respond to. Results show that explicit LLM personas show mixed results when reproducing known human biases, but generally fail to demonstrate implicit biases. We conclude that LLMs may capture the statistical patterns of how people speak, but are generally unable to model the complex interactions and subtleties of human perceptions, potentially limiting their effectiveness in social science applications.","Giorgi, Salvatore, Liu, Tingting, Aich, Ankit, Isman, Kelsey Jane, Sherman, Garrick, Fried, Zachary, Sedoc, Jo{\~a}o, Ungar, Lyle, Curtis, Brenda",,,Modeling Human Subjectivity in {LLM}s Using Explicit and Implicit Human Factors in Personas,,,10.18653/v1/2024.findings-emnlp.420 , ,,"Large language models (LLMs) are increasingly being used in human-centered social scientific tasks, such as data annotation, synthetic data creation, and engaging in dialog. However, these tasks are highly subjective and dependent on human factors, such as one`s environment, attitudes, beliefs, and lived experiences. Thus, it may be the case that employing LLMs (which do not have such human factors) in these tasks results in a lack of variation in data, failing to reflect the diversity of human experiences. In this paper, we examine the role of prompting LLMs with human-like personas and asking the models to answer as if they were a specific human. This is done explicitly, with exact demographics, political beliefs, and lived experiences, or implicitly via names prevalent in specific populations. The LLM personas are then evaluated via (1) subjective annotation task (e.g., detecting toxicity) and (2) a belief generation task, where both tasks are known to vary across human factors. We examine the impact of explicit vs. implicit personas and investigate which human factors LLMs recognize and respond to. Results show that explicit LLM personas show mixed results when reproducing known human biases, but generally fail to demonstrate implicit biases. We conclude that LLMs may capture the statistical patterns of how people speak, but are generally unable to model the complex interactions and subtleties of human perceptions, potentially limiting their effectiveness in social science applications.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,out_of_scope,
3461,"**Title**Preference Tuning For Toxicity Mitigation Generalizes Across Languages

**Abstract**Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other safety tasks, we demonstrate that Direct Preference Optimization (DPO) training with only English data can significantly reduce toxicity in multilingual open-ended generations. For example, the probability of mGPT-1.3B generating toxic continuations drops from 46.8{\%} to 3.9{\%} across 17 different languages after training. Our results also extend to other multilingual LLMs, such as BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal intervention and activation analysis, we identified the dual multilinguality property of MLP layers in LLMs, which explains the cross-lingual generalization of DPO. Finally, we show that bilingual sentence retrieval can predict the cross-lingual transferability of DPO preference tuning.","Li, Xiaochen, Yong, Zheng Xin, Bach, Stephen",,,Preference Tuning For Toxicity Mitigation Generalizes Across Languages,,,10.18653/v1/2024.findings-emnlp.784 , ,,"Detoxifying multilingual Large Language Models (LLMs) has become crucial due to their increasing global use. In this work, we explore zero-shot cross-lingual generalization of preference tuning in detoxifying LLMs. Unlike previous studies that show limited cross-lingual generalization for other safety tasks, we demonstrate that Direct Preference Optimization (DPO) training with only English data can significantly reduce toxicity in multilingual open-ended generations. For example, the probability of mGPT-1.3B generating toxic continuations drops from 46.8{\%} to 3.9{\%} across 17 different languages after training. Our results also extend to other multilingual LLMs, such as BLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal intervention and activation analysis, we identified the dual multilinguality property of MLP layers in LLMs, which explains the cross-lingual generalization of DPO. Finally, we show that bilingual sentence retrieval can predict the cross-lingual transferability of DPO preference tuning.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detox,
3462,"**Title**Beyond Perplexity: Multi-dimensional Safety Evaluation of {LLM} Compression

**Abstract**Increasingly, model compression techniques enable large language models (LLMs) to be deployed in real-world applications. As a result of this momentum towards local deployment, compressed LLMs will interact with a large population. Prior work on compression typically prioritize preserving perplexity, which is directly analogous to training loss. The impact of compression method on other critical aspects of model behavior{---}particularly safety{---}requires systematic assessment. To this end, we investigate the impact of model compression along four dimensions: (1) degeneration harm, i.e., bias and toxicity in generation; (2) representational harm, i.e., biases in discriminative tasks; (3) dialect bias; and (4) language modeling and downstream task performance. We examine a wide spectrum of LLM compression techniques, including unstructured pruning, semi-structured pruning, and quantization. Our analysis reveals that compression can lead to unexpected consequences. Although compression may unintentionally alleviate LLMs' degeneration harm, it can still exacerbate representational harm. Furthermore, increasing compression produces a divergent impact on different protected groups. Finally, different compression methods have drastically different safety impacts: for example, quantization mostly preserves bias while pruning degrades quickly. Our findings underscore the importance of integrating safety assessments into the development of compressed LLMs to ensure their reliability across real-world applications.","Xu, Zhichao, Gupta, Ashim, Li, Tao, Bentham, Oliver, Srikumar, Vivek",,,Beyond Perplexity: Multi-dimensional Safety Evaluation of {LLM} Compression,,,10.18653/v1/2024.findings-emnlp.901 , ,,"Increasingly, model compression techniques enable large language models (LLMs) to be deployed in real-world applications. As a result of this momentum towards local deployment, compressed LLMs will interact with a large population. Prior work on compression typically prioritize preserving perplexity, which is directly analogous to training loss. The impact of compression method on other critical aspects of model behavior{---}particularly safety{---}requires systematic assessment. To this end, we investigate the impact of model compression along four dimensions: (1) degeneration harm, i.e., bias and toxicity in generation; (2) representational harm, i.e., biases in discriminative tasks; (3) dialect bias; and (4) language modeling and downstream task performance. We examine a wide spectrum of LLM compression techniques, including unstructured pruning, semi-structured pruning, and quantization. Our analysis reveals that compression can lead to unexpected consequences. Although compression may unintentionally alleviate LLMs' degeneration harm, it can still exacerbate representational harm. Furthermore, increasing compression produces a divergent impact on different protected groups. Finally, different compression methods have drastically different safety impacts: for example, quantization mostly preserves bias while pruning degrades quickly. Our findings underscore the importance of integrating safety assessments into the development of compressed LLMs to ensure their reliability across real-world applications.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detox,
3463,"**Title**{G}roun{D}ial: Human-norm Grounded Safe Dialog Response Generation

**Abstract**Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses agreeing to offensive user input or including toxic content. Previous research aimed to alleviate the toxicity by fine-tuning LLM with manually annotated safe dialogue histories. However, the dependency on additional tuning requires substantial costs. To remove the dependency, we propose GrounDial, where response safety is achieved by grounding responses to commonsense social rules without requiring fine-tuning. A hybrid approach of in-context learning and human-norm-guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning.","Kim, Siwon, Dai, Shuyang, Kachuee, Mohammad, Ray, Shayan, Taghavi, Tara, Yoon, Sungroh",,,{G}roun{D}ial: Human-norm Grounded Safe Dialog Response Generation,,, , ,,"Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses agreeing to offensive user input or including toxic content. Previous research aimed to alleviate the toxicity by fine-tuning LLM with manually annotated safe dialogue histories. However, the dependency on additional tuning requires substantial costs. To remove the dependency, we propose GrounDial, where response safety is achieved by grounding responses to commonsense social rules without requiring fine-tuning. A hybrid approach of in-context learning and human-norm-guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning.",,,,, ,  Findings of the Association for Computational Linguistics: EACL 2024,,detox,
3464,"**Title**{K}o{C}ommon{GEN} v2: A Benchmark for Navigating {K}orean Commonsense Reasoning Challenges in Large Language Models

**Abstract**The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs against socially acceptable commonsense standards in various scenarios. To address this gap in commonsense reasoning, we present KoCommonGEN v2, a fine-grained benchmark dataset focused on Korean commonsense reasoning. This dataset, enriched with human annotations, comprises multiple-choice questions across seven error categories. These categories include commonsense memorization, numerical commonsense, toxic speech, and more, which are vulnerable to undermining the reliability of LLMs' commonsense reasoning capabilities. The empirical results present that LLMs struggle with Korean commonsense reasoning. With human accuracy benchmarked at approximately 85{\%}, GPT-4`s performance lags at about 74{\%}, and other LLMs demonstrate an average accuracy of around 42{\%}. Our findings emphasize the need for targeted improvements in Korean commonsense reasoning within LLMs, paving the way for more socially and contextually sensitive AI models.","Seo, Jaehyung, Lee, Jaewook, Park, Chanjun, Hong, SeongTae, Lee, Seungjun, Lim, Heuiseok",,,{K}o{C}ommon{GEN} v2: A Benchmark for Navigating {K}orean Commonsense Reasoning Challenges in Large Language Models,,,10.18653/v1/2024.findings-acl.141 , ,,"The evolution of large language models (LLMs) has culminated in a multitask model paradigm where prompts drive the generation of user-specific outputs. However, this advancement has revealed a critical challenge: LLMs frequently produce outputs against socially acceptable commonsense standards in various scenarios. To address this gap in commonsense reasoning, we present KoCommonGEN v2, a fine-grained benchmark dataset focused on Korean commonsense reasoning. This dataset, enriched with human annotations, comprises multiple-choice questions across seven error categories. These categories include commonsense memorization, numerical commonsense, toxic speech, and more, which are vulnerable to undermining the reliability of LLMs' commonsense reasoning capabilities. The empirical results present that LLMs struggle with Korean commonsense reasoning. With human accuracy benchmarked at approximately 85{\%}, GPT-4`s performance lags at about 74{\%}, and other LLMs demonstrate an average accuracy of around 42{\%}. Our findings emphasize the need for targeted improvements in Korean commonsense reasoning within LLMs, paving the way for more socially and contextually sensitive AI models.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,out_of_scope,
3465,"**Title**{LIRE}: listwise reward enhancement for preference alignment

**Abstract**Recently, tremendous strides have been made to align the generation of Large Language Models (LLMs) with human values to mitigate toxic or unhelpful content. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves effective and is widely adopted by researchers. However, implementing RLHF is complex, and its sensitivity to hyperparameters renders achieving stable performance and scalability challenging. Furthermore, prevailing approaches to preference alignment primarily concentrate on pairwise comparisons, with limited exploration into multi-response scenarios, thereby overlooking the potential richness within the candidate pool. For the above reasons, we propose a new approach: Listwise Reward Enhancement for Preference Alignment (LIRE), a gradient-based reward optimization approach that incorporates the offline rewards of multiple responses into a streamlined listwise framework, thus eliminating the need for online sampling during training. LIRE is straightforward to implement, requiring minimal parameter tuning, and seamlessly aligns with the pairwise paradigm while naturally extending to multi-response scenarios. Moreover, we introduce a self-enhancement algorithm aimed at iteratively refining the reward during training. Our experiments demonstrate that LIRE consistently outperforms existing methods across several benchmarks on dialogue and summarization tasks, with good transferability to out-of-distribution data, assessed using proxy reward models and human annotators.","Zhu, Mingye, Liu, Yi, Zhang, Lei, Guo, Junbo, Mao, Zhendong",,,{LIRE}: listwise reward enhancement for preference alignment,,,10.18653/v1/2024.findings-acl.201 , ,,"Recently, tremendous strides have been made to align the generation of Large Language Models (LLMs) with human values to mitigate toxic or unhelpful content. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves effective and is widely adopted by researchers. However, implementing RLHF is complex, and its sensitivity to hyperparameters renders achieving stable performance and scalability challenging. Furthermore, prevailing approaches to preference alignment primarily concentrate on pairwise comparisons, with limited exploration into multi-response scenarios, thereby overlooking the potential richness within the candidate pool. For the above reasons, we propose a new approach: Listwise Reward Enhancement for Preference Alignment (LIRE), a gradient-based reward optimization approach that incorporates the offline rewards of multiple responses into a streamlined listwise framework, thus eliminating the need for online sampling during training. LIRE is straightforward to implement, requiring minimal parameter tuning, and seamlessly aligns with the pairwise paradigm while naturally extending to multi-response scenarios. Moreover, we introduce a self-enhancement algorithm aimed at iteratively refining the reward during training. Our experiments demonstrate that LIRE consistently outperforms existing methods across several benchmarks on dialogue and summarization tasks, with good transferability to out-of-distribution data, assessed using proxy reward models and human annotators.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3466,"**Title**{W}il{KE}: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing

**Abstract**Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch. We introduce a knowledge editing approach named Wise-Layer Knowledge Editor (WilKE), which selects editing layer based on the pattern matching degree of editing knowledge across different layers in language models. Experimental results demonstrate that, in lifelong editing, WilKE exhibits an average improvement of 46.2{\%} and 67.8{\%} on editing GPT2-XL and GPT-J relative to state-of-the-art knowledge editing methods.","Hu, Chenhui, Cao, Pengfei, Chen, Yubo, Liu, Kang, Zhao, Jun",,,{W}il{KE}: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing,,,10.18653/v1/2024.findings-acl.207 , ,,"Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch. We introduce a knowledge editing approach named Wise-Layer Knowledge Editor (WilKE), which selects editing layer based on the pattern matching degree of editing knowledge across different layers in language models. Experimental results demonstrate that, in lifelong editing, WilKE exhibits an average improvement of 46.2{\%} and 67.8{\%} on editing GPT2-XL and GPT-J relative to state-of-the-art knowledge editing methods.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3467,"**Title**Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models

**Abstract**Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM`s pre-training checkpoints to enhance the LLM`s trustworthiness. Finally, inspired by the theoretical result that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field.","Qian, Chen, Zhang, Jie, Yao, Wei, Liu, Dongrui, Yin, Zhenfei, Qiao, Yu, Liu, Yong, Shao, Jing",,,Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models,,,10.18653/v1/2024.findings-acl.290 , ,,"Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM`s pre-training checkpoints to enhance the LLM`s trustworthiness. Finally, inspired by the theoretical result that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3468,"**Title**Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs

**Abstract**Controlled Text Generation (CTG) aims to produce texts that exhibit specific desired attributes. In this study, we introduce a pluggable CTG framework for Large Language Models (LLMs) named Dynamic Attribute Graphs-based controlled text generation (DATG). This framework utilizes an attribute scorer to evaluate the attributes of sentences generated by LLMs and constructs dynamic attribute graphs. DATG modulates the occurrence of key attribute words and key anti-attribute words, achieving effective attribute control without compromising the original capabilities of the model. We conduct experiments across four datasets in two tasks: toxicity mitigation and sentiment transformation, employing five LLMs as foundational models. Our findings highlight a remarkable enhancement in control accuracy, achieving a peak improvement of 19.29{\%} over baseline methods in the most favorable task across four datasets. Additionally, we observe a significant decrease in perplexity, markedly improving text fluency.","Liang, Xun, Wang, Hanyu, Song, Shichao, Hu, Mengting, Wang, Xunzhi, Li, Zhiyu, Xiong, Feiyu, Tang, Bo",,,Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs,,,10.18653/v1/2024.findings-acl.345 , ,,"Controlled Text Generation (CTG) aims to produce texts that exhibit specific desired attributes. In this study, we introduce a pluggable CTG framework for Large Language Models (LLMs) named Dynamic Attribute Graphs-based controlled text generation (DATG). This framework utilizes an attribute scorer to evaluate the attributes of sentences generated by LLMs and constructs dynamic attribute graphs. DATG modulates the occurrence of key attribute words and key anti-attribute words, achieving effective attribute control without compromising the original capabilities of the model. We conduct experiments across four datasets in two tasks: toxicity mitigation and sentiment transformation, employing five LLMs as foundational models. Our findings highlight a remarkable enhancement in control accuracy, achieving a peak improvement of 19.29{\%} over baseline methods in the most favorable task across four datasets. Additionally, we observe a significant decrease in perplexity, markedly improving text fluency.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3469,"**Title**Direct Preference Optimization with an Offset

**Abstract**Direct preference optimization (DPO) is a successful fine-tuning strategy for aligning large language models with human preferences without the need to train a reward model or employ reinforcement learning. DPO, as originally formulated, relies on binary preference data and fine-tunes a language model to increase the likelihood of a preferred response over a dispreferred response. However, not all preference pairs are equal. Sometimes, the preferred response is only slightly better than the dispreferred one. In other cases, the preference is much stronger. For instance, if a response contains harmful or toxic content, the annotator will have a strong preference for that response. In this paper, we propose a generalization of DPO, termed DPO with an offset (ODPO), that does not treat every preference pair equally during fine-tuning. Intuitively, ODPO requires the difference between the likelihood of the preferred and dispreferred response to be greater than an offset value. The offset is determined based on the extent to which one response is preferred over another. Our experiments on various tasks suggest that ODPO significantly outperforms DPO in aligning language models, especially when the number of preference pairs is limited.","Amini, Afra, Vieira, Tim, Cotterell, Ryan",,,Direct Preference Optimization with an Offset,,,10.18653/v1/2024.findings-acl.592 , ,,"Direct preference optimization (DPO) is a successful fine-tuning strategy for aligning large language models with human preferences without the need to train a reward model or employ reinforcement learning. DPO, as originally formulated, relies on binary preference data and fine-tunes a language model to increase the likelihood of a preferred response over a dispreferred response. However, not all preference pairs are equal. Sometimes, the preferred response is only slightly better than the dispreferred one. In other cases, the preference is much stronger. For instance, if a response contains harmful or toxic content, the annotator will have a strong preference for that response. In this paper, we propose a generalization of DPO, termed DPO with an offset (ODPO), that does not treat every preference pair equally during fine-tuning. Intuitively, ODPO requires the difference between the likelihood of the preferred and dispreferred response to be greater than an offset value. The offset is determined based on the extent to which one response is preferred over another. Our experiments on various tasks suggest that ODPO significantly outperforms DPO in aligning language models, especially when the number of preference pairs is limited.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3470,"**Title**{S}peech{G}uard: Exploring the Adversarial Robustness of Multi-modal Large Language Models

**Abstract**Integrated Speech and Large Language Models (SLMs) that can follow speech instructions and generate relevant text responses have gained popularity lately. However, the safety and robustness of these models remains largely unclear. In this work, we investigate the potential vulnerabilities of such instruction-following speech-language models to adversarial attacks and jailbreaking. Specifically, we design algorithms that can generate adversarial examples to jailbreak SLMs in both white-box and black-box attack settings without human involvement. Additionally, we propose countermeasures to thwart such jailbreaking attacks. Our models, trained on dialog data with speech instructions, achieve state-of-the-art performance on spoken question-answering task, scoring over 80{\%} on both safety and helpfulness metrics. Despite safety guardrails, experiments on jailbreaking demonstrate the vulnerability of SLMs to adversarial perturbations and transfer attacks, with average attack success rates of 90{\%} and 10{\%} respectively when evaluated on a dataset of carefully designed harmful questions spanning 12 different toxic categories. However, we demonstrate that our proposed countermeasures reduce the attack success significantly.","Peri, Raghuveer, Jayanthi, Sai Muralidhar, Ronanki, Srikanth, Bhatia, Anshu, Mundnich, Karel, Dingliwal, Saket, Das, Nilaksh, Hou, Zejiang, Huybrechts, Goeric, Vishnubhotla, Srikanth, Garcia-Romero, Daniel, Srinivasan, Sundararajan, Han, Kyu, Kirchhoff, Katrin",,,{S}peech{G}uard: Exploring the Adversarial Robustness of Multi-modal Large Language Models,,,10.18653/v1/2024.findings-acl.596 , ,,"Integrated Speech and Large Language Models (SLMs) that can follow speech instructions and generate relevant text responses have gained popularity lately. However, the safety and robustness of these models remains largely unclear. In this work, we investigate the potential vulnerabilities of such instruction-following speech-language models to adversarial attacks and jailbreaking. Specifically, we design algorithms that can generate adversarial examples to jailbreak SLMs in both white-box and black-box attack settings without human involvement. Additionally, we propose countermeasures to thwart such jailbreaking attacks. Our models, trained on dialog data with speech instructions, achieve state-of-the-art performance on spoken question-answering task, scoring over 80{\%} on both safety and helpfulness metrics. Despite safety guardrails, experiments on jailbreaking demonstrate the vulnerability of SLMs to adversarial perturbations and transfer attacks, with average attack success rates of 90{\%} and 10{\%} respectively when evaluated on a dataset of carefully designed harmful questions spanning 12 different toxic categories. However, we demonstrate that our proposed countermeasures reduce the attack success significantly.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,out_of_scope,
3471,"**Title**Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning

**Abstract**Paraphrasing of offensive content is a better alternative to content removal and helps improve civility in a communication environment. Supervised paraphrasers; however, rely heavily on large quantities of labelled data to help preserve meaning and intent. They also often retain a large portion of the offensiveness of the original content, which raises questions on their overall usability. In this paper we aim to assist practitioners in developing usable paraphrasers by exploring In-Context Learning (ICL) with large language models (LLMs), i.e., using a limited number of input-label demonstration pairs to guide the model in generating desired outputs for specific queries. Our study focuses on key factors such as - number and order of demonstrations, exclusion of prompt instruction, and reduction in measured toxicity. We perform principled evaluation on three datasets, including our proposed Context-Aware Polite Paraphrase (CAPP) dataset, comprising of dialogue-style rude utterances, polite paraphrases, and additional dialogue context. We evaluate our approach using four closed source and one open source LLM. Our results reveal that ICL is comparable to supervised methods in generation quality, while being qualitatively better by 25{\%} on human evaluation and attaining lower toxicity by 76{\%}. Also, ICL-based paraphrasers only show a slight reduction in performance even with just 10{\%} training data.","Som, Anirudh, Sikka, Karan, Gent, Helen, Divakaran, Ajay, Kathol, Andreas, Vergyri, Dimitra",,,Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning,,,10.18653/v1/2024.findings-acl.749 , ,,"Paraphrasing of offensive content is a better alternative to content removal and helps improve civility in a communication environment. Supervised paraphrasers; however, rely heavily on large quantities of labelled data to help preserve meaning and intent. They also often retain a large portion of the offensiveness of the original content, which raises questions on their overall usability. In this paper we aim to assist practitioners in developing usable paraphrasers by exploring In-Context Learning (ICL) with large language models (LLMs), i.e., using a limited number of input-label demonstration pairs to guide the model in generating desired outputs for specific queries. Our study focuses on key factors such as - number and order of demonstrations, exclusion of prompt instruction, and reduction in measured toxicity. We perform principled evaluation on three datasets, including our proposed Context-Aware Polite Paraphrase (CAPP) dataset, comprising of dialogue-style rude utterances, polite paraphrases, and additional dialogue context. We evaluate our approach using four closed source and one open source LLM. Our results reveal that ICL is comparable to supervised methods in generation quality, while being qualitatively better by 25{\%} on human evaluation and attaining lower toxicity by 76{\%}. Also, ICL-based paraphrasers only show a slight reduction in performance even with just 10{\%} training data.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3472,"**Title**Tox-{BART}: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech

**Abstract**Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide world knowledge and improve performance on standard metrics. Interestingly, our study presents conflicting evidence for the role of the quality of KG tuples in generating implicit explanations. Consequently, simpler models incorporating external toxicity signals outperform KG-infused models. Compared to the KG-based setup, we observe a comparable performance for SBIC (LatentHatred) datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and -4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and error analysis reveal that our proposed setup produces more precise explanations than zero-shot GPT-3.5, highlighting the intricate nature of the task.","Yadav, Neemesh, Masud, Sarah, Goyal, Vikram, Akhtar, Md Shad, Chakraborty, Tanmoy",,,Tox-{BART}: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech,,,10.18653/v1/2024.findings-acl.831 , ,,"Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide world knowledge and improve performance on standard metrics. Interestingly, our study presents conflicting evidence for the role of the quality of KG tuples in generating implicit explanations. Consequently, simpler models incorporating external toxicity signals outperform KG-infused models. Compared to the KG-based setup, we observe a comparable performance for SBIC (LatentHatred) datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and -4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and error analysis reveal that our proposed setup produces more precise explanations than zero-shot GPT-3.5, highlighting the intricate nature of the task.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detection,
3473,"**Title**From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models

**Abstract**To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it`s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic families and levels of resource availability, ranging from high to mid-resource languages. Through comprehensive experiments, we provide insights into the complexities of multilingual toxicity mitigation, offering valuable insights and paving the way for future research in this increasingly important field.","Ermis, Beyza, Pozzobon, Luiza, Hooker, Sara, Lewis, Patrick",,,From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models,,,10.18653/v1/2024.findings-acl.893 , ,,"To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it`s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic families and levels of resource availability, ranging from high to mid-resource languages. Through comprehensive experiments, we provide insights into the complexities of multilingual toxicity mitigation, offering valuable insights and paving the way for future research in this increasingly important field.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3474,"**Title**From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards

**Abstract**Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations.Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluating models on already mitigated biases. Using the case of Llama 2 as an example, we illustrate how LLMs' safety responses can still encode harmful assumptions. To do so, we create a set of non-toxic prompts, which we then use to evaluate Llama models. Through our new taxonomy of LLMs responses to users, we observe that the safety/helpfulness trade-offs are more pronounced for certain demographic groups which can lead to different kinds of harms such as quality-of-service harms for marginalized populations.","Chehbouni, Khaoula, Roshan, Megha, Ma, Emmanuel, Wei, Futian, Taik, Afaf, Cheung, Jackie, Farnadi, Golnoosh",,,From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards,,,10.18653/v1/2024.findings-acl.927 , ,,"Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations.Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluating models on already mitigated biases. Using the case of Llama 2 as an example, we illustrate how LLMs' safety responses can still encode harmful assumptions. To do so, we create a set of non-toxic prompts, which we then use to evaluate Llama models. Through our new taxonomy of LLMs responses to users, we observe that the safety/helpfulness trade-offs are more pronounced for certain demographic groups which can lead to different kinds of harms such as quality-of-service harms for marginalized populations.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,Gen_dataset,
3475,"**Title**Evaluating Psychological Safety of Large Language Models

**Abstract**In this work, we designed unbiased prompts to systematically evaluate the psychological safety of large language models (LLMs). First, we tested five different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT, GPT-3.5, and GPT-4 still showed dark personality patterns; these models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT models. Following these observations, we showed that fine-tuning Llama-2-chat-7B with responses from BFI using direct preference optimization could effectively reduce the psychological toxicity of the model. Based on the findings, we recommended the application of systematic and comprehensive psychological metrics to further evaluate and improve the safety of LLMs.","Li, Xingxuan, Li, Yutong, Qiu, Lin, Joty, Shafiq, Bing, Lidong",,,Evaluating Psychological Safety of Large Language Models,,,10.18653/v1/2024.emnlp-main.108 , ,,"In this work, we designed unbiased prompts to systematically evaluate the psychological safety of large language models (LLMs). First, we tested five different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT, GPT-3.5, and GPT-4 still showed dark personality patterns; these models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT models. Following these observations, we showed that fine-tuning Llama-2-chat-7B with responses from BFI using direct preference optimization could effectively reduce the psychological toxicity of the model. Based on the findings, we recommended the application of systematic and comprehensive psychological metrics to further evaluate and improve the safety of LLMs.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3476,"**Title**{T}oxi{C}loak{CN}: Evaluating Robustness of Offensive Language Detection in {C}hinese with Cloaking Perturbations

**Abstract**Detecting hate speech and offensive language is essential for maintaining a safe and respectful digital environment. This study examines the limitations of state-of-the-art large language models (LLMs) in identifying offensive content within systematically perturbed data, with a focus on Chinese, a language particularly susceptible to such perturbations. We introduce ToxiCloakCN, an enhanced dataset derived from ToxiCN, augmented with homophonic substitutions and emoji transformations, to test the robustness of LLMs against these cloaking perturbations. Our findings reveal that existing models significantly underperform in detecting offensive content when these perturbations are applied. We provide an in-depth analysis of how different types of offensive content are affected by these perturbations and explore the alignment between human and model explanations of offensiveness. Our work highlights the urgent need for more advanced techniques in offensive language detection to combat the evolving tactics used to evade detection mechanisms.","Xiao, Yunze, Hu, Yujia, Choo, Kenny Tsu Wei, Lee, Roy Ka-Wei",,,{T}oxi{C}loak{CN}: Evaluating Robustness of Offensive Language Detection in {C}hinese with Cloaking Perturbations,,,10.18653/v1/2024.emnlp-main.345 , ,,"Detecting hate speech and offensive language is essential for maintaining a safe and respectful digital environment. This study examines the limitations of state-of-the-art large language models (LLMs) in identifying offensive content within systematically perturbed data, with a focus on Chinese, a language particularly susceptible to such perturbations. We introduce ToxiCloakCN, an enhanced dataset derived from ToxiCN, augmented with homophonic substitutions and emoji transformations, to test the robustness of LLMs against these cloaking perturbations. Our findings reveal that existing models significantly underperform in detecting offensive content when these perturbations are applied. We provide an in-depth analysis of how different types of offensive content are affected by these perturbations and explore the alignment between human and model explanations of offensiveness. Our work highlights the urgent need for more advanced techniques in offensive language detection to combat the evolving tactics used to evade detection mechanisms.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,out_but_toxicity,
3477,"**Title**{LLM} See, {LLM} Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives

**Abstract**The widespread adoption of synthetic data raises new questions about how models generating the data can influence other large language models (LLMs). To start, our work exhaustively characterizes the impact of passive inheritance of model properties by systematically studying how the source of synthetic data shapes models' internal biases, calibration and preferences, and their generations' textual attributes, providing one of the most comprehensive studies to-date. We find that models are surprisingly sensitive towards certain attributes even when the synthetic data prompts appear {\textquotedblleft}neutral{\textquotedblright} which invites the question: can we explicitly steer the distilled data towards desired properties? We demonstrate how such active inheritance can steer the generation profiles of models towards desirable non-differentiable attributes in both directions, e.g. increasing lexical diversity or reducing toxicity. Overall, our study broadens the understanding of the implicit biases inherited by LLMs and explores how we can leverage them to positive effect.","Shimabucoro, Lu{\'i}sa, Ruder, Sebastian, Kreutzer, Julia, Fadaee, Marzieh, Hooker, Sara",,,"{LLM} See, {LLM} Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives",,,10.18653/v1/2024.emnlp-main.521 , ,,"The widespread adoption of synthetic data raises new questions about how models generating the data can influence other large language models (LLMs). To start, our work exhaustively characterizes the impact of passive inheritance of model properties by systematically studying how the source of synthetic data shapes models' internal biases, calibration and preferences, and their generations' textual attributes, providing one of the most comprehensive studies to-date. We find that models are surprisingly sensitive towards certain attributes even when the synthetic data prompts appear {\textquotedblleft}neutral{\textquotedblright} which invites the question: can we explicitly steer the distilled data towards desired properties? We demonstrate how such active inheritance can steer the generation profiles of models towards desirable non-differentiable attributes in both directions, e.g. increasing lexical diversity or reducing toxicity. Overall, our study broadens the understanding of the implicit biases inherited by LLMs and explores how we can leverage them to positive effect.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3478,"**Title**{OATH}-Frames: Characterizing Online Attitudes Towards Homelessness with {LLM} Assistants

**Abstract**Warning: Contents of this paper may be upsetting.Public attitudes towards key societal issues, expressed on online media, are of immense value in policy and reform efforts, yet challenging to understand at scale. We study one such social issue: homelessness in the U.S., by leveraging the remarkable capabilities of large language models to assist social work experts in analyzing millions of posts from Twitter. We introduce a framing typology: Online Attitudes Towards Homelessness (OATH) Frames: nine hierarchical frames capturing critiques, responses and perceptions. We release annotations with varying degrees of assistance from language models, with immense benefits in scaling: 6.5{\texttimes} speedup in annotation time while only incurring a 3 point F1 reduction in performance with respect to the domain experts. Our experiments demonstrate the value of modeling OATH-Frames over existing sentiment and toxicity classifiers. Our large-scale analysis with predicted OATH-Frames on 2.4M posts on homelessness reveal key trends in attitudes across states, time periods and vulnerable populations, enabling new insights on the issue. Our work provides a general framework to understand nuanced public attitudes at scale, on issues beyond homelessness.","Ranjit, Jaspreet, Joshi, Brihi, Dorn, Rebecca, Petry, Laura, Koumoundouros, Olga, Bottarini, Jayne, Liu, Peichen, Rice, Eric, Swayamdipta, Swabha",,,{OATH}-Frames: Characterizing Online Attitudes Towards Homelessness with {LLM} Assistants,,,10.18653/v1/2024.emnlp-main.724 , ,,"Warning: Contents of this paper may be upsetting.Public attitudes towards key societal issues, expressed on online media, are of immense value in policy and reform efforts, yet challenging to understand at scale. We study one such social issue: homelessness in the U.S., by leveraging the remarkable capabilities of large language models to assist social work experts in analyzing millions of posts from Twitter. We introduce a framing typology: Online Attitudes Towards Homelessness (OATH) Frames: nine hierarchical frames capturing critiques, responses and perceptions. We release annotations with varying degrees of assistance from language models, with immense benefits in scaling: 6.5{\texttimes} speedup in annotation time while only incurring a 3 point F1 reduction in performance with respect to the domain experts. Our experiments demonstrate the value of modeling OATH-Frames over existing sentiment and toxicity classifiers. Our large-scale analysis with predicted OATH-Frames on 2.4M posts on homelessness reveal key trends in attitudes across states, time periods and vulnerable populations, enabling new insights on the issue. Our work provides a general framework to understand nuanced public attitudes at scale, on issues beyond homelessness.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,out_but_toxicity,
3479,"**Title**Style-Specific Neurons for Steering {LLM}s in Text Style Transfer

**Abstract**Text style transfer (TST) aims to modify the style of a text without altering its original meaning. Large language models (LLMs) demonstrate superior performance across multiple tasks, including TST. However, in zero-shot setups, they tend to directly copy a significant portion of the input text to the output without effectively changing its style. To enhance the stylistic variety and fluency of the text, we present sNeuron-TST, a novel approach for steering LLMs using style-specific neurons in TST. Specifically, we identify neurons associated with the source and target styles and deactivate source-style-only neurons to give target-style words a higher probability, aiming to enhance the stylistic diversity of the generated text. However, we find that this deactivation negatively impacts the fluency of the generated text, which we address by proposing an improved contrastive decoding method that accounts for rapid token probability shifts across layers caused by deactivated source-style neurons. Empirical experiments demonstrate the effectiveness of the proposed method on six benchmarks, encompassing formality, toxicity, politics, politeness, authorship, and sentiment.","Lai, Wen, Hangya, Viktor, Fraser, Alexander",,,Style-Specific Neurons for Steering {LLM}s in Text Style Transfer,,,10.18653/v1/2024.emnlp-main.745 , ,,"Text style transfer (TST) aims to modify the style of a text without altering its original meaning. Large language models (LLMs) demonstrate superior performance across multiple tasks, including TST. However, in zero-shot setups, they tend to directly copy a significant portion of the input text to the output without effectively changing its style. To enhance the stylistic variety and fluency of the text, we present sNeuron-TST, a novel approach for steering LLMs using style-specific neurons in TST. Specifically, we identify neurons associated with the source and target styles and deactivate source-style-only neurons to give target-style words a higher probability, aiming to enhance the stylistic diversity of the generated text. However, we find that this deactivation negatively impacts the fluency of the generated text, which we address by proposing an improved contrastive decoding method that accounts for rapid token probability shifts across layers caused by deactivated source-style neurons. Empirical experiments demonstrate the effectiveness of the proposed method on six benchmarks, encompassing formality, toxicity, politics, politeness, authorship, and sentiment.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3480,"**Title**The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis

**Abstract**Understanding in-context learning (ICL) capability that enables large language models (LLMs) to excel in proficiency through demonstration examples is of utmost importance. This importance stems not only from the better utilization of this capability across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns regarding truthfulness, bias, and toxicity, that may arise alongside the capability. In this paper, we present a thorough survey on the interpretation and analysis of in-context learning. First, we provide a concise introduction to the background and definition of in-context learning. Then, we give an overview of advancements from two perspectives: 1) a theoretical perspective, emphasizing studies on mechanistic interpretability and delving into the mathematical foundations behind ICL; and 2) an empirical perspective, concerning studies that empirically analyze factors associated with ICL. We conclude by discussing open questions and the challenges encountered, and suggesting potential avenues for future research. We believe that our work establishes the basis for further exploration into the interpretation of in-context learning. To aid this effort, we have created a repository containing resources that will be continually updated.","Zhou, Yuxiang, Li, Jiazheng, Xiang, Yanzheng, Yan, Hanqi, Gui, Lin, He, Yulan",,,The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis,,,10.18653/v1/2024.emnlp-main.795 , ,,"Understanding in-context learning (ICL) capability that enables large language models (LLMs) to excel in proficiency through demonstration examples is of utmost importance. This importance stems not only from the better utilization of this capability across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns regarding truthfulness, bias, and toxicity, that may arise alongside the capability. In this paper, we present a thorough survey on the interpretation and analysis of in-context learning. First, we provide a concise introduction to the background and definition of in-context learning. Then, we give an overview of advancements from two perspectives: 1) a theoretical perspective, emphasizing studies on mechanistic interpretability and delving into the mathematical foundations behind ICL; and 2) an empirical perspective, concerning studies that empirically analyze factors associated with ICL. We conclude by discussing open questions and the challenges encountered, and suggesting potential avenues for future research. We believe that our work establishes the basis for further exploration into the interpretation of in-context learning. To aid this effort, we have created a repository containing resources that will be continually updated.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detection,
3481,"**Title**Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis

**Abstract**Large Language Models (LLMs) are capable of producing content that perpetuates stereotypes, discrimination, and toxicity.The recently proposed \textit{moral self-correction} is a computationally efficient method for reducing harmful content in the responses of LLMs. However, the process of how injecting self-correction instructions can modify the behavior of LLMs remains under-explored. In this paper, we explore the effectiveness of moral self-correction by answering three research questions: (1) In what scenarios does moral self-correction work? (2) What are the internal mechanisms of LLMs, e.g., hidden states, that are influenced by moral self-correction instructions? (3) Is intrinsic moral self-correction actually superficial in terms of reduced immorality in hidden states? We argue that self-correction can help LLMs find a shortcut to more morally correct output, rather than truly reducing the immorality stored in hidden states.Through empirical investigation with tasks of language generation and multi-choice question answering, we conclude: (i) LLMs exhibit good performance across both tasks, and self-correction instructions are particularly beneficial when the correct answer is already top-ranked; (ii) The morality levels in intermediate hidden states are strong indicators as to whether one instruction would be more effective than another; (iii) Based on our analysis of intermediate hidden states and task case studies of self-correction behaviors, we are first to propose the hypothesis that intrinsic moral self-correction is in fact superficial.","Liu, Guangliang, Mao, Haitao, Tang, Jiliang, Johnson, Kristen",,,Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis,,,10.18653/v1/2024.emnlp-main.918 , ,,"Large Language Models (LLMs) are capable of producing content that perpetuates stereotypes, discrimination, and toxicity.The recently proposed \textit{moral self-correction} is a computationally efficient method for reducing harmful content in the responses of LLMs. However, the process of how injecting self-correction instructions can modify the behavior of LLMs remains under-explored. In this paper, we explore the effectiveness of moral self-correction by answering three research questions: (1) In what scenarios does moral self-correction work? (2) What are the internal mechanisms of LLMs, e.g., hidden states, that are influenced by moral self-correction instructions? (3) Is intrinsic moral self-correction actually superficial in terms of reduced immorality in hidden states? We argue that self-correction can help LLMs find a shortcut to more morally correct output, rather than truly reducing the immorality stored in hidden states.Through empirical investigation with tasks of language generation and multi-choice question answering, we conclude: (i) LLMs exhibit good performance across both tasks, and self-correction instructions are particularly beneficial when the correct answer is already top-ranked; (ii) The morality levels in intermediate hidden states are strong indicators as to whether one instruction would be more effective than another; (iii) Based on our analysis of intermediate hidden states and task case studies of self-correction behaviors, we are first to propose the hypothesis that intrinsic moral self-correction is in fact superficial.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3482,"**Title**Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree

**Abstract**When annotators disagree, predicting the labels given by individual annotators can capture nuances overlooked by traditional label aggregation. We introduce three approaches to predict individual annotator ratings on the toxicity of text by incorporating individual annotator-specific information: a neural collaborative filtering (NCF) approach, an in-context learning (ICL) approach, and an intermediate embedding-based architecture. We also study the utility of demographic information for rating prediction. NCF showed limited utility; however, integrating annotator history, demographics, and survey information permits both the embedding-based architecture and ICL to substantially improve prediction accuracy, with the embedding-based architecture outperforming the other methods. We also find that, if demographics are predicted from survey information, using these imputed demographics as features performs comparably to using true demographic data. This suggests that demographics may not provide substantial information for modeling ratings beyond what is captured in survey responses. Our findings raise considerations about the relative utility of different types of annotator information and provide new approaches for modeling annotators in subjective NLP tasks.","Jaggi, Harbani, Coimbatore Murali, Kashyap, Fleisig, Eve, Biyik, Erdem",,,Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree,,,10.18653/v1/2024.emnlp-main.1221 , ,,"When annotators disagree, predicting the labels given by individual annotators can capture nuances overlooked by traditional label aggregation. We introduce three approaches to predict individual annotator ratings on the toxicity of text by incorporating individual annotator-specific information: a neural collaborative filtering (NCF) approach, an in-context learning (ICL) approach, and an intermediate embedding-based architecture. We also study the utility of demographic information for rating prediction. NCF showed limited utility; however, integrating annotator history, demographics, and survey information permits both the embedding-based architecture and ICL to substantially improve prediction accuracy, with the embedding-based architecture outperforming the other methods. We also find that, if demographics are predicted from survey information, using these imputed demographics as features performs comparably to using true demographic data. This suggests that demographics may not provide substantial information for modeling ratings beyond what is captured in survey responses. Our findings raise considerations about the relative utility of different types of annotator information and provide new approaches for modeling annotators in subjective NLP tasks.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detection,
3483,"**Title**{R}e{S}e{TOX}: Re-learning attention weights for toxicity mitigation in machine translation

**Abstract**Our proposed method, RESETOX (REdoSEarch if TOXic), addresses the issue ofNeural Machine Translation (NMT) gener-ating translation outputs that contain toxicwords not present in the input. The ob-jective is to mitigate the introduction oftoxic language without the need for re-training. In the case of identified addedtoxicity during the inference process, RE-SETOX dynamically adjusts the key-valueself-attention weights and re-evaluates thebeam search hypotheses. Experimental re-sults demonstrate that RESETOX achievesa remarkable 57{\%} reduction in added tox-icity while maintaining an average trans-lation quality of 99.5{\%} across 164 lan-guages. Our code is available at: https://github.com","Garc{\'i}a Gilabert, Javier, Escolano, Carlos, Costa-juss{\`a}, Marta",,,{R}e{S}e{TOX}: Re-learning attention weights for toxicity mitigation in machine translation,,, , ,,"Our proposed method, RESETOX (REdoSEarch if TOXic), addresses the issue ofNeural Machine Translation (NMT) gener-ating translation outputs that contain toxicwords not present in the input. The ob-jective is to mitigate the introduction oftoxic language without the need for re-training. In the case of identified addedtoxicity during the inference process, RE-SETOX dynamically adjusts the key-valueself-attention weights and re-evaluates thebeam search hypotheses. Experimental re-sults demonstrate that RESETOX achievesa remarkable 57{\%} reduction in added tox-icity while maintaining an average trans-lation quality of 99.5{\%} across 164 lan-guages. Our code is available at: https://github.com",,,,, ,  Proceedings of the 25th Annual Conference of the European Association for Machine Translation (Volume 1),,detox,
3484,"**Title**Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation

**Abstract**Machine translation models sometimes lead to added toxicity: translated outputs may contain more toxic content that the original input. In this paper, we introduce MinTox, a novel pipeline to automatically identify and mitigate added toxicity at inference time, without further model training. MinTox leverages a multimodal (speech and text) toxicity classifier that can scale across languages.We demonstrate the capabilities of MinTox when applied to SEAMLESSM4T, a multi-modal and massively multilingual machine translation system. MinTox significantly reduces added toxicity: across all domains, modalities and language directions, 25{\%} to95{\%} of added toxicity is successfully filtered out, while preserving translation quality","Costa-juss{\`a}, Marta, Dale, David, Elbayad, Maha, Yu, Bokai",,,Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation,,, , ,,"Machine translation models sometimes lead to added toxicity: translated outputs may contain more toxic content that the original input. In this paper, we introduce MinTox, a novel pipeline to automatically identify and mitigate added toxicity at inference time, without further model training. MinTox leverages a multimodal (speech and text) toxicity classifier that can scale across languages.We demonstrate the capabilities of MinTox when applied to SEAMLESSM4T, a multi-modal and massively multilingual machine translation system. MinTox significantly reduces added toxicity: across all domains, modalities and language directions, 25{\%} to95{\%} of added toxicity is successfully filtered out, while preserving translation quality",,,,, ,  Proceedings of the 25th Annual Conference of the European Association for Machine Translation (Volume 1),,out_but_toxicity,
3485,"**Title**{L}a{M}ini-{LM}: A Diverse Herd of Distilled Models from Large-Scale Instructions

**Abstract**Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. While other similar works have been done, they are often conducted on a limited set of (usually still large) models and are not accompanied by proper evaluations. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. We also assess the model for hallucination and toxicity, and for the former, we introduce a new benchmark dataset for hallucination-inducing QA. The results demonstrate that our proposed LaMini-LM models are comparable to strong baselines while being much smaller in size.","Wu, Minghao, Waheed, Abdul, Zhang, Chiyu, Abdul-Mageed, Muhammad, Aji, Alham Fikri",,,{L}a{M}ini-{LM}: A Diverse Herd of Distilled Models from Large-Scale Instructions,,, , ,,"Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. While other similar works have been done, they are often conducted on a limited set of (usually still large) models and are not accompanied by proper evaluations. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. We also assess the model for hallucination and toxicity, and for the former, we introduce a new benchmark dataset for hallucination-inducing QA. The results demonstrate that our proposed LaMini-LM models are comparable to strong baselines while being much smaller in size.",,,,, ,  Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3486,"**Title**{G}rad{S}afe: Detecting Jailbreak Prompts for {LLM}s via Safety-Critical Gradient Analysis

**Abstract**Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for detecting jailbreak prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes. In this study, we propose GradSafe, which effectively detects jailbreak prompts by scrutinizing the gradients of safety-critical parameters in LLMs. Our method is grounded in a pivotal observation: the gradients of an LLM`s loss for jailbreak prompts paired with compliance response exhibit similar patterns on certain safety-critical parameters. In contrast, safe prompts lead to different gradient patterns. Building on this observation, GradSafe analyzes the gradients from prompts (paired with compliance responses) to accurately detect jailbreak prompts. We show that GradSafe, applied to Llama-2 without further training, outperforms Llama Guard{---}despite its extensive finetuning with a large dataset{---}in detecting jailbreak prompts. This superior performance is consistent across both zero-shot and adaptation scenarios, as evidenced by our evaluations on ToxicChat and XSTest. The source code is available at https://github.com/xyq7/GradSafe.","Xie, Yueqi, Fang, Minghong, Pi, Renjie, Gong, Neil",,,{G}rad{S}afe: Detecting Jailbreak Prompts for {LLM}s via Safety-Critical Gradient Analysis,,,10.18653/v1/2024.acl-long.30 , ,,"Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for detecting jailbreak prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes. In this study, we propose GradSafe, which effectively detects jailbreak prompts by scrutinizing the gradients of safety-critical parameters in LLMs. Our method is grounded in a pivotal observation: the gradients of an LLM`s loss for jailbreak prompts paired with compliance response exhibit similar patterns on certain safety-critical parameters. In contrast, safe prompts lead to different gradient patterns. Building on this observation, GradSafe analyzes the gradients from prompts (paired with compliance responses) to accurately detect jailbreak prompts. We show that GradSafe, applied to Llama-2 without further training, outperforms Llama Guard{---}despite its extensive finetuning with a large dataset{---}in detecting jailbreak prompts. This superior performance is consistent across both zero-shot and adaptation scenarios, as evidenced by our evaluations on ToxicChat and XSTest. The source code is available at https://github.com/xyq7/GradSafe.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detection,
3487,"**Title**{M}eme{G}uard: An {LLM} and {VLM}-based Framework for Advancing Content Moderation via Meme Intervention

**Abstract**In the digital world, memes present a unique challenge for content moderation due to their potential to spread harmful content. Although detection methods have improved, proactive solutions such as intervention are still limited, with current research focusing mostly on text-based content, neglecting the widespread influence of multimodal content like memes. Addressing this gap, we present \textit{MemeGuard}, a comprehensive framework leveraging Large Language Models (LLMs) and Visual Language Models (VLMs) for meme intervention. \textit{MemeGuard} harnesses a specially fine-tuned VLM, \textit{VLMeme}, for meme interpretation, and a multimodal knowledge selection and ranking mechanism (\textit{MKS}) for distilling relevant knowledge. This knowledge is then employed by a general-purpose LLM to generate contextually appropriate interventions. Another key contribution of this work is the \textit{ \textbf{I}ntervening} \textit{ \textbf{C}yberbullying in \textbf{M}ultimodal \textbf{M}emes (ICMM)} dataset, a high-quality, labeled dataset featuring toxic memes and their corresponding human-annotated interventions. We leverage \textit{ICMM} to test \textit{MemeGuard}, demonstrating its proficiency in generating relevant and effective responses to toxic memes. red \textbf{Disclaimer}: \textit{This paper contains harmful content that may be disturbing to some readers.}","Jha, Prince, Jain, Raghav, Mandal, Konika, Chadha, Aman, Saha, Sriparna, Bhattacharyya, Pushpak",,,{M}eme{G}uard: An {LLM} and {VLM}-based Framework for Advancing Content Moderation via Meme Intervention,,,10.18653/v1/2024.acl-long.439 , ,,"In the digital world, memes present a unique challenge for content moderation due to their potential to spread harmful content. Although detection methods have improved, proactive solutions such as intervention are still limited, with current research focusing mostly on text-based content, neglecting the widespread influence of multimodal content like memes. Addressing this gap, we present \textit{MemeGuard}, a comprehensive framework leveraging Large Language Models (LLMs) and Visual Language Models (VLMs) for meme intervention. \textit{MemeGuard} harnesses a specially fine-tuned VLM, \textit{VLMeme}, for meme interpretation, and a multimodal knowledge selection and ranking mechanism (\textit{MKS}) for distilling relevant knowledge. This knowledge is then employed by a general-purpose LLM to generate contextually appropriate interventions. Another key contribution of this work is the \textit{ \textbf{I}ntervening} \textit{ \textbf{C}yberbullying in \textbf{M}ultimodal \textbf{M}emes (ICMM)} dataset, a high-quality, labeled dataset featuring toxic memes and their corresponding human-annotated interventions. We leverage \textit{ICMM} to test \textit{MemeGuard}, demonstrating its proficiency in generating relevant and effective responses to toxic memes. red \textbf{Disclaimer}: \textit{This paper contains harmful content that may be disturbing to some readers.}",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_but_toxicity,
3488,"**Title**Focus on Your Question! Interpreting and Mitigating Toxic {C}o{T} Problems in Commonsense Reasoning

**Abstract**Large language models exhibit high-level commonsense reasoning abilities, especially with enhancement methods like Chain-of-Thought (CoT). However, we find these CoT-like methods lead to a considerable number of originally correct answers turning wrong, which we define as the Toxic CoT problem. To interpret and mitigate this problem, we first utilize attribution tracing and causal tracing methods to probe the internal working mechanism of the LLM during CoT reasoning. Through comparisons, we prove that the model exhibits information loss from the question over the shallow attention layers when generating rationales or answers. Based on the probing findings, we design a novel method called RIDERS (Residual decodIng and sERial-position Swap), which compensates for the information deficit in the model from both decoding and serial-position perspectives. Through extensive experiments on multiple commonsense reasoning benchmarks, we validate that this method not only significantly eliminates Toxic CoT problems (decreased by $\textbf{23.6}${\%}), but also effectively improves the model`s overall commonsense reasoning performance (increased by $\textbf{5.5}${\%}).","Li, Jiachun, Cao, Pengfei, Wang, Chenhao, Jin, Zhuoran, Chen, Yubo, Zeng, Daojian, Liu, Kang, Zhao, Jun",,,Focus on Your Question! Interpreting and Mitigating Toxic {C}o{T} Problems in Commonsense Reasoning,,,10.18653/v1/2024.acl-long.499 , ,,"Large language models exhibit high-level commonsense reasoning abilities, especially with enhancement methods like Chain-of-Thought (CoT). However, we find these CoT-like methods lead to a considerable number of originally correct answers turning wrong, which we define as the Toxic CoT problem. To interpret and mitigate this problem, we first utilize attribution tracing and causal tracing methods to probe the internal working mechanism of the LLM during CoT reasoning. Through comparisons, we prove that the model exhibits information loss from the question over the shallow attention layers when generating rationales or answers. Based on the probing findings, we design a novel method called RIDERS (Residual decodIng and sERial-position Swap), which compensates for the information deficit in the model from both decoding and serial-position perspectives. Through extensive experiments on multiple commonsense reasoning benchmarks, we validate that this method not only significantly eliminates Toxic CoT problems (decreased by $\textbf{23.6}${\%}), but also effectively improves the model`s overall commonsense reasoning performance (increased by $\textbf{5.5}${\%}).",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3489,"**Title**Chat Vector: A Simple Approach to Equip {LLM}s with Instruction Following and Model Alignment in New Languages

**Abstract**Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of $\textit{chat vector}$ to equip pre-trained language models with instruction following and human value alignment via simple model arithmetic. The chat vector is derived by subtracting the weights of a pre-trained base model (e.g. LLaMA2) from those of its corresponding chat model (e.g. LLaMA2-chat). By simply adding the chat vector to a continual pre-trained model`s weights, we can endow the model with chat capabilities in new languages without the need for further training.Our empirical studies demonstrate the superior efficacy of the chat vector from three different aspects: instruction following, toxicity mitigation, and multi-turn dialogue. Moreover, to showcase the adaptability of our approach, we extend our experiments to encompass various languages, base models, and chat vectors. The results underscore the chat vector`s simplicity, effectiveness, and wide applicability, making it a compelling solution for efficiently enabling conversational capabilities in pre-trained language models. Our code is available at https://github.com/aqweteddy/ChatVector.","Huang, Shih-Cheng, Li, Pin-Zu, Hsu, Yu-chi, Chen, Kuang-Ming, Lin, Yu Tung, Hsiao, Shih-Kai, Tsai, Richard, Lee, Hung-yi",,,Chat Vector: A Simple Approach to Equip {LLM}s with Instruction Following and Model Alignment in New Languages,,,10.18653/v1/2024.acl-long.590 , ,,"Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of $\textit{chat vector}$ to equip pre-trained language models with instruction following and human value alignment via simple model arithmetic. The chat vector is derived by subtracting the weights of a pre-trained base model (e.g. LLaMA2) from those of its corresponding chat model (e.g. LLaMA2-chat). By simply adding the chat vector to a continual pre-trained model`s weights, we can endow the model with chat capabilities in new languages without the need for further training.Our empirical studies demonstrate the superior efficacy of the chat vector from three different aspects: instruction following, toxicity mitigation, and multi-turn dialogue. Moreover, to showcase the adaptability of our approach, we extend our experiments to encompass various languages, base models, and chat vectors. The results underscore the chat vector`s simplicity, effectiveness, and wide applicability, making it a compelling solution for efficiently enabling conversational capabilities in pre-trained language models. Our code is available at https://github.com/aqweteddy/ChatVector.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,detox,
3490,"**Title**Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model

**Abstract**Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50{\%} are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages {---}{---} including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.","{\""U}st{\""u}n, Ahmet, Aryabumi, Viraat, Yong, Zheng, Ko, Wei-Yin, D{'}souza, Daniel, Onilude, Gbemileke, Bhandari, Neel, Singh, Shivalika, Ooi, Hui-Lee, Kayid, Amr, Vargus, Freddie, Blunsom, Phil, Longpre, Shayne, Muennighoff, Niklas, Fadaee, Marzieh, Kreutzer, Julia, Hooker, Sara",,,Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model,,,10.18653/v1/2024.acl-long.845 , ,,"Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50{\%} are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages {---}{---} including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3491,"**Title**Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech

**Abstract**Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.","Plaza-del-arco, Flor Miriam, Nozza, Debora, Hovy, Dirk",,,Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech,,,10.18653/v1/2023.woah-1.6 , ,,"Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.",,,,, ,  The 7th Workshop on Online Abuse and Harms (WOAH),,detection,
3492,"**Title**Aporophobia: An Overlooked Type of Toxic Language Targeting the Poor

**Abstract**While many types of hate speech and online toxicity have been the focus of extensive research in NLP, toxic language stigmatizing poor people has been mostly disregarded. Yet, aporophobia, a social bias against the poor, is a common phenomenon online, which can be psychologically damaging as well as hindering poverty reduction policy measures. We demonstrate that aporophobic attitudes are indeed present in social media and argue that the existing NLP datasets and models are inadequate to effectively address this problem. Efforts toward designing specialized resources and novel socio-technical mechanisms for confronting aporophobia are needed.","Kiritchenko, Svetlana, Curto Rex, Georgina, Nejadgholi, Isar, Fraser, Kathleen C.",,,Aporophobia: An Overlooked Type of Toxic Language Targeting the Poor,,,10.18653/v1/2023.woah-1.12 , ,,"While many types of hate speech and online toxicity have been the focus of extensive research in NLP, toxic language stigmatizing poor people has been mostly disregarded. Yet, aporophobia, a social bias against the poor, is a common phenomenon online, which can be psychologically damaging as well as hindering poverty reduction policy measures. We demonstrate that aporophobic attitudes are indeed present in social media and argue that the existing NLP datasets and models are inadequate to effectively address this problem. Efforts toward designing specialized resources and novel socio-technical mechanisms for confronting aporophobia are needed.",,,,, ,  The 7th Workshop on Online Abuse and Harms (WOAH),,detection,
3493,"**Title**Detecting Personal Information in Training Corpora: an Analysis

**Abstract**Large language models are trained on increasing quantities of unstructured text, the largest sources of which are scraped from the Web. These Web scrapes are mainly composed of heterogeneous collections of text from multiple domains with minimal documentation. While some work has been done to identify and remove toxic, biased, or sexual language, the topic of personal information (PI) in textual data used for training Natural Language Processing (NLP) models is relatively under-explored. In this work, we draw from definitions of PI across multiple countries to define the first PI taxonomy of its kind, categorized by type and risk level. We then conduct a case study on the Colossal Clean Crawled Corpus (C4) and the Pile, to detect some of the highest-risk personal information, such as email addresses and credit card numbers, and examine the differences between automatic and regular expression-based approaches for their detection. We identify shortcomings in modern approaches for PI detection, and propose a reframing of the problem that is informed by global perspectives and the goals in personal information detection.","Subramani, Nishant, Luccioni, Sasha, Dodge, Jesse, Mitchell, Margaret",,,Detecting Personal Information in Training Corpora: an Analysis,,,10.18653/v1/2023.trustnlp-1.18 , ,,"Large language models are trained on increasing quantities of unstructured text, the largest sources of which are scraped from the Web. These Web scrapes are mainly composed of heterogeneous collections of text from multiple domains with minimal documentation. While some work has been done to identify and remove toxic, biased, or sexual language, the topic of personal information (PI) in textual data used for training Natural Language Processing (NLP) models is relatively under-explored. In this work, we draw from definitions of PI across multiple countries to define the first PI taxonomy of its kind, categorized by type and risk level. We then conduct a case study on the Colossal Clean Crawled Corpus (C4) and the Pile, to detect some of the highest-risk personal information, such as email addresses and credit card numbers, and examine the differences between automatic and regular expression-based approaches for their detection. We identify shortcomings in modern approaches for PI detection, and propose a reframing of the problem that is informed by global perspectives and the goals in personal information detection.",,,,, ,  Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023),,out_of_scope,
3494,"**Title**Hallucinations in Large Multilingual Translation Models

**Abstract**Hallucinated translations can severely undermine and raise safety issues when machine translation systems are deployed in the wild. Previous research on the topic focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis{---}over 100 language pairs across various resource levels and going beyond English-centric directions{---}on both the M2M neural machine translation (NMT) models and GPT large language models (LLMs). Among several insights, we highlight that models struggle with hallucinations primarily in low-resource directions and when translating out of English, where, critically, they may reveal toxic patterns that can be traced back to the training data. We also find that LLMs produce qualitatively different hallucinations to those of NMT models. Finally, we show that hallucinations are hard to reverse by merely scaling models trained with the same data. However, employing more diverse models, trained on different data or with different procedures, as fallback systems can improve translation quality and virtually eliminate certain pathologies.","Guerreiro, Nuno M., Alves, Duarte M., Waldendorf, Jonas, Haddow, Barry, Birch, Alexandra, Colombo, Pierre, Martins, Andr{\'e} F. T.",,,Hallucinations in Large Multilingual Translation Models,,,10.1162/tacl_a_00615 , ,,"Hallucinated translations can severely undermine and raise safety issues when machine translation systems are deployed in the wild. Previous research on the topic focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis{---}over 100 language pairs across various resource levels and going beyond English-centric directions{---}on both the M2M neural machine translation (NMT) models and GPT large language models (LLMs). Among several insights, we highlight that models struggle with hallucinations primarily in low-resource directions and when translating out of English, where, critically, they may reveal toxic patterns that can be traced back to the training data. We also find that LLMs produce qualitatively different hallucinations to those of NMT models. Finally, we show that hallucinations are hard to reverse by merely scaling models trained with the same data. However, employing more diverse models, trained on different data or with different procedures, as fallback systems can improve translation quality and virtually eliminate certain pathologies.",,,,, ,  ,,out_of_scope,
3495,"**Title**Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation

**Abstract**Natural language generation has witnessed significant advancements due to the training of large language models on vast internet-scale datasets. Despite these advancements, there exists a critical challenge: These models can inadvertently generate content that is toxic, inaccurate, and unhelpful, and existing automatic evaluation metrics often fall short of identifying these shortcomings. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of recent research that has leveraged human feedback to improve natural language generation. First, we introduce a taxonomy distilled from existing research to categorize and organize the varied forms of feedback. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which uses large language models to make judgments based on a set of principles and minimize the need for human intervention. We also release a website of this survey at feedback-gap-survey.info.","Fernandes, Patrick, Madaan, Aman, Liu, Emmy, Farinhas, Ant{\'o}nio, Martins, Pedro Henrique, Bertsch, Amanda, de Souza, Jos{\'e} G. C., Zhou, Shuyan, Wu, Tongshuang, Neubig, Graham, Martins, Andr{\'e} F. T.",,,Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation,,,10.1162/tacl_a_00626 , ,,"Natural language generation has witnessed significant advancements due to the training of large language models on vast internet-scale datasets. Despite these advancements, there exists a critical challenge: These models can inadvertently generate content that is toxic, inaccurate, and unhelpful, and existing automatic evaluation metrics often fall short of identifying these shortcomings. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of recent research that has leveraged human feedback to improve natural language generation. First, we introduce a taxonomy distilled from existing research to categorize and organize the varied forms of feedback. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which uses large language models to make judgments based on a set of principles and minimize the need for human intervention. We also release a website of this survey at feedback-gap-survey.info.",,,,, ,  ,,detox,
3496,"**Title**Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text

**Abstract**The expression of opinions, stances, and moral foundations on social media often coincide with toxic, divisive, or inflammatory language that can make constructive discourse across communities difficult. Natural language generation methods could provide a means to reframe or reword such expressions in a way that fosters more civil discourse, yet current Large Language Model (LLM) methods tend towards language that is too generic or formal to seem authentic for social media discussions. We present preliminary work on training LLMs to maintain authenticity while presenting a community`s ideas and values in a constructive, non-toxic manner.","Bose, Ritwik, Perera, Ian, Dorr, Bonnie",,,Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text,,,10.18653/v1/2023.sicon-1.2 , ,,"The expression of opinions, stances, and moral foundations on social media often coincide with toxic, divisive, or inflammatory language that can make constructive discourse across communities difficult. Natural language generation methods could provide a means to reframe or reword such expressions in a way that fosters more civil discourse, yet current Large Language Model (LLM) methods tend towards language that is too generic or formal to seem authentic for social media discussions. We present preliminary work on training LLMs to maintain authenticity while presenting a community`s ideas and values in a constructive, non-toxic manner.",,,,, ,  Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023),,detox,
3497,"**Title**Probing {LLM}s for hate speech detection: strengths and vulnerabilities

**Abstract**Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select two large language models (GPT-3.5 and text-davinci) and three datasets - HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially ($\sim20-30\%$) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline ($\sim10-20\%$) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute {\textquoteleft}jailbreak' prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts.","Roy, Sarthak, Harshvardhan, Ashish, Mukherjee, Animesh, Saha, Punyajoy",,,Probing {LLM}s for hate speech detection: strengths and vulnerabilities,,,10.18653/v1/2023.findings-emnlp.407 , ,,"Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select two large language models (GPT-3.5 and text-davinci) and three datasets - HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially ($\sim20-30\%$) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline ($\sim10-20\%$) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute {\textquoteleft}jailbreak' prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detection,
3498,"**Title**Toxicity in Multilingual Machine Translation at Scale

**Abstract**Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0{\%} to 5{\%}. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpret what causes toxicity. Making use of the input attributions allows us to explain toxicity, because the source contributions significantly correlate with toxicity for 84{\%} of languages studied. Given our findings, our recommendations to reduce added toxicity are to curate training data to avoid mistranslations, mitigate hallucination and check unstable translations.","Costa-juss{\`a}, Marta, Smith, Eric, Ropers, Christophe, Licht, Daniel, Maillard, Jean, Ferrando, Javier, Escolano, Carlos",,,Toxicity in Multilingual Machine Translation at Scale,,,10.18653/v1/2023.findings-emnlp.642 , ,,"Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0{\%} to 5{\%}. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpret what causes toxicity. Making use of the input attributions allows us to explain toxicity, because the source contributions significantly correlate with toxicity for 84{\%} of languages studied. Given our findings, our recommendations to reduce added toxicity are to curate training data to avoid mistranslations, mitigate hallucination and check unstable translations.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,out_but_toxicity,
3499,"**Title**Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems

**Abstract**Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations. We define generic personas to represent demographic groups, such as {\textquotedblleft}an Asian person{\textquotedblright}, whereas specific personas may take the form of specific popular Asian names like {\textquotedblleft}Yumi{\textquotedblright}. While the adoption of personas enriches user experiences by making dialogue systems more engaging and approachable, it also casts a shadow of potential risk by exacerbating social biases within model responses, thereby causing societal harm through interactions with users. In this paper, we systematically study {\textquotedblleft}persona biases{\textquotedblright}, which we define to be the sensitivity of dialogue models' harmful behaviors contingent upon the personas they adopt. We categorize persona biases into biases in harmful expression and harmful agreement, and establish a comprehensive evaluation framework to measure persona biases in five aspects: Offensiveness, Toxic Continuation, Regard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to investigate persona biases by experimenting with UNIVERSALPERSONA, a systematically constructed persona dataset encompassing various types of both generic and specific model personas. Through benchmarking on four different models- including Blender, ChatGPT, Alpaca, and Vicuna- our study uncovers significant persona biases in dialogue systems. Our findings also underscore the pressing need to revisit the use of personas in dialogue agents to ensure safe application.","Wan, Yixin, Zhao, Jieyu, Chadha, Aman, Peng, Nanyun, Chang, Kai-Wei",,,Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems,,,10.18653/v1/2023.findings-emnlp.648 , ,,"Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations. We define generic personas to represent demographic groups, such as {\textquotedblleft}an Asian person{\textquotedblright}, whereas specific personas may take the form of specific popular Asian names like {\textquotedblleft}Yumi{\textquotedblright}. While the adoption of personas enriches user experiences by making dialogue systems more engaging and approachable, it also casts a shadow of potential risk by exacerbating social biases within model responses, thereby causing societal harm through interactions with users. In this paper, we systematically study {\textquotedblleft}persona biases{\textquotedblright}, which we define to be the sensitivity of dialogue models' harmful behaviors contingent upon the personas they adopt. We categorize persona biases into biases in harmful expression and harmful agreement, and establish a comprehensive evaluation framework to measure persona biases in five aspects: Offensiveness, Toxic Continuation, Regard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to investigate persona biases by experimenting with UNIVERSALPERSONA, a systematically constructed persona dataset encompassing various types of both generic and specific model personas. Through benchmarking on four different models- including Blender, ChatGPT, Alpaca, and Vicuna- our study uncovers significant persona biases in dialogue systems. Our findings also underscore the pressing need to revisit the use of personas in dialogue agents to ensure safe application.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,evaluation,
3500,"**Title**{S}teer{LM}: Attribute Conditioned {SFT} as an (User-Steerable) Alternative to {RLHF}

**Abstract**Model alignment with human preferences is an essential step in making Large Language Models (LLMs) helpful and consistent with human values. It typically consists of supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) stages. However, RLHF faces inherent limitations stemming from a complex training setup and its tendency to align the model with implicit values that end users cannot control at run-time. Moreover, reward models in RLHF stage commonly rely on single-dimensional feedback as opposed to explicit, multifaceted signals that indicate attributes such as helpfulness, humor, and toxicity. To address these limitations, we propose SteerLM, a supervised fine-tuning method that empowers end-users to control responses during inference. SteerLM conditions responses to conform to an explicitly defined multi-dimensional set of attributes, thereby empowering a steerable AI capable of generating helpful and high-quality responses while maintaining customizability. Experiments show that SteerLM trained on open source datasets generates responses that are preferred by human and automatic evaluators to many state-of-the-art baselines trained with RLHF while being much easier to train. Try SteerLM at https://huggingface.co/nvidia/SteerLM-llama2-13B","Dong, Yi, Wang, Zhilin, Sreedhar, Makesh, Wu, Xianchao, Kuchaiev, Oleksii",,,{S}teer{LM}: Attribute Conditioned {SFT} as an (User-Steerable) Alternative to {RLHF},,,10.18653/v1/2023.findings-emnlp.754 , ,,"Model alignment with human preferences is an essential step in making Large Language Models (LLMs) helpful and consistent with human values. It typically consists of supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) stages. However, RLHF faces inherent limitations stemming from a complex training setup and its tendency to align the model with implicit values that end users cannot control at run-time. Moreover, reward models in RLHF stage commonly rely on single-dimensional feedback as opposed to explicit, multifaceted signals that indicate attributes such as helpfulness, humor, and toxicity. To address these limitations, we propose SteerLM, a supervised fine-tuning method that empowers end-users to control responses during inference. SteerLM conditions responses to conform to an explicitly defined multi-dimensional set of attributes, thereby empowering a steerable AI capable of generating helpful and high-quality responses while maintaining customizability. Experiments show that SteerLM trained on open source datasets generates responses that are preferred by human and automatic evaluators to many state-of-the-art baselines trained with RLHF while being much easier to train. Try SteerLM at https://huggingface.co/nvidia/SteerLM-llama2-13B",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detox,
3501,"**Title**{F}in{GPT}: Large Generative Models for a Small Language

**Abstract**Large language models (LLMs) excel in many tasks in NLP and beyond, but most open models have very limited coverage of smaller languages and LLM work tends to focus on languages where nearly unlimited data is available for pretraining. In this work, we study the challenges of creating LLMs for Finnish, a language spoken by less than 0.1{\%} of the world population. We compile an extensive dataset of Finnish combining web crawls, news, social media and eBooks. We pursue two approaches to pretrain models: 1) we train seven monolingual models from scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the pretraining of the multilingual BLOOM model on a mix of its original training data and Finnish, resulting in a 176 billion parameter model we call BLUUMI. For model evaluation, we introduce FIN-bench, a version of BIG-bench with Finnish tasks. We also assess other model qualities such as toxicity and bias. Our models and tools are openly available at \url{https://turkunlp.org/gpt3-finnish}.","Luukkonen, Risto, Komulainen, Ville, Luoma, Jouni, Eskelinen, Anni, Kanerva, Jenna, Kupari, Hanna-Mari, Ginter, Filip, Laippala, Veronika, Muennighoff, Niklas, Piktus, Aleksandra, Wang, Thomas, Tazi, Nouamane, Scao, Teven, Wolf, Thomas, Suominen, Osma, Sairanen, Samuli, Merioksa, Mikko, Heinonen, Jyrki, Vahtola, Aija, Antao, Samuel, Pyysalo, Sampo",,,{F}in{GPT}: Large Generative Models for a Small Language,,,10.18653/v1/2023.emnlp-main.164 , ,,"Large language models (LLMs) excel in many tasks in NLP and beyond, but most open models have very limited coverage of smaller languages and LLM work tends to focus on languages where nearly unlimited data is available for pretraining. In this work, we study the challenges of creating LLMs for Finnish, a language spoken by less than 0.1{\%} of the world population. We compile an extensive dataset of Finnish combining web crawls, news, social media and eBooks. We pursue two approaches to pretrain models: 1) we train seven monolingual models from scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the pretraining of the multilingual BLOOM model on a mix of its original training data and Finnish, resulting in a 176 billion parameter model we call BLUUMI. For model evaluation, we introduce FIN-bench, a version of BIG-bench with Finnish tasks. We also assess other model qualities such as toxicity and bias. Our models and tools are openly available at \url{https://turkunlp.org/gpt3-finnish}.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3502,"**Title**{ROBBIE}: Robust Bias Evaluation of Large Generative Language Models

**Abstract**As generative large language models (LLMs) grow more performant and prevalent, we must develop comprehensive enough tools to measure and improve their fairness. Different prompt-based datasets can be used to measure social bias across multiple text domains and demographic axes, meaning that testing LLMs on more datasets can potentially help us characterize their biases more fully, and better ensure equal and equitable treatment of marginalized demographic groups. In this work, our focus is two-fold: (1) Benchmarking: a comparison of 6 different prompt-based bias and toxicity metrics across 12 demographic axes and 5 families of generative LLMs. Out of those 6 metrics, AdvPromptSet and HolisticBiasR are novel datasets proposed in the paper. The comparison of those benchmarks gives us insights about the bias and toxicity of the compared models. Therefore, we explore the frequency of demographic terms in common LLM pre-training corpora and how this may relate to model biases. (2) Mitigation: we conduct a comprehensive study of how well 3 bias/toxicity mitigation techniques perform across our suite of measurements. ROBBIE aims to provide insights for practitioners while deploying a model, emphasizing the need to not only measure potential harms, but also understand how they arise by characterizing the data, mitigate harms once found, and balance any trade-offs. We open-source our analysis code in hopes of encouraging broader measurements of bias in future LLMs.","Esiobu, David, Tan, Xiaoqing, Hosseini, Saghar, Ung, Megan, Zhang, Yuchen, Fernandes, Jude, Dwivedi-Yu, Jane, Presani, Eleonora, Williams, Adina, Smith, Eric",,,{ROBBIE}: Robust Bias Evaluation of Large Generative Language Models,,,10.18653/v1/2023.emnlp-main.230 , ,,"As generative large language models (LLMs) grow more performant and prevalent, we must develop comprehensive enough tools to measure and improve their fairness. Different prompt-based datasets can be used to measure social bias across multiple text domains and demographic axes, meaning that testing LLMs on more datasets can potentially help us characterize their biases more fully, and better ensure equal and equitable treatment of marginalized demographic groups. In this work, our focus is two-fold: (1) Benchmarking: a comparison of 6 different prompt-based bias and toxicity metrics across 12 demographic axes and 5 families of generative LLMs. Out of those 6 metrics, AdvPromptSet and HolisticBiasR are novel datasets proposed in the paper. The comparison of those benchmarks gives us insights about the bias and toxicity of the compared models. Therefore, we explore the frequency of demographic terms in common LLM pre-training corpora and how this may relate to model biases. (2) Mitigation: we conduct a comprehensive study of how well 3 bias/toxicity mitigation techniques perform across our suite of measurements. ROBBIE aims to provide insights for practitioners while deploying a model, emphasizing the need to not only measure potential harms, but also understand how they arise by characterizing the data, mitigate harms once found, and balance any trade-offs. We open-source our analysis code in hopes of encouraging broader measurements of bias in future LLMs.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,evaluation,
3503,"**Title**{B}ias{X}: {\textquotedblleft}Thinking Slow{\textquotedblright} in Toxic Content Moderation with Explanations of Implied Social Biases

**Abstract**Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4{\%} on hard toxic examples) help less compared to expert-written human explanations (+7.2{\%}). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.","Zhang, Yiming, Nanduri, Sravani, Jiang, Liwei, Wu, Tongshuang, Sap, Maarten",,,{B}ias{X}: {\textquotedblleft}Thinking Slow{\textquotedblright} in Toxic Content Moderation with Explanations of Implied Social Biases,,,10.18653/v1/2023.emnlp-main.300 , ,,"Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4{\%} on hard toxic examples) help less compared to expert-written human explanations (+7.2{\%}). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,detection#methodology,
3504,"**Title**Faithful Model Evaluation for Model-Based Metrics

**Abstract**Statistical significance testing is used in natural language processing (NLP) to determine whether the results of a study or experiment are likely to be due to chance or if they reflect a genuine relationship. A key step in significance testing is the estimation of confidence interval which is a function of sample variance. Sample variance calculation is straightforward when evaluating against ground truth. However, in many cases, a metric model is often used for evaluation. For example, to compare toxicity of two large language models, a toxicity classifier is used for evaluation. Existing works usually do not consider the variance change due to metric model errors, which can lead to wrong conclusions. In this work, we establish the mathematical foundation of significance testing for model-based metrics. With experiments on public benchmark datasets and a production system, we show that considering metric model errors to calculate sample variances for model-based metrics changes the conclusions in certain experiments.","Hu, Qian, Goyal, Palash, Gupta, Rahul",,,Faithful Model Evaluation for Model-Based Metrics,,,10.18653/v1/2023.emnlp-main.464 , ,,"Statistical significance testing is used in natural language processing (NLP) to determine whether the results of a study or experiment are likely to be due to chance or if they reflect a genuine relationship. A key step in significance testing is the estimation of confidence interval which is a function of sample variance. Sample variance calculation is straightforward when evaluating against ground truth. However, in many cases, a metric model is often used for evaluation. For example, to compare toxicity of two large language models, a toxicity classifier is used for evaluation. Existing works usually do not consider the variance change due to metric model errors, which can lead to wrong conclusions. In this work, we establish the mathematical foundation of significance testing for model-based metrics. With experiments on public benchmark datasets and a production system, we show that considering metric model errors to calculate sample variances for model-based metrics changes the conclusions in certain experiments.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3505,"**Title**On the Challenges of Using Black-Box {API}s for Toxicity Evaluation in Research

**Abstract**Perception of toxicity evolves over time and often differs between geographies and cultural backgrounds. Similarly, black-box commercially available APIs for detecting toxicity, such as the Perspective API, are not static, but frequently retrained to address any unattended weaknesses and biases. We evaluate the implications of these changes on the reproducibility of findings that compare the relative merits of models and methods that aim to curb toxicity. Our findings suggest that research that relied on inherited automatic toxicity scores to compare models and techniques may have resulted in inaccurate findings. Rescoring all models from HELM, a widely respected living benchmark, for toxicity with the recent version of the API led to a different ranking of widely used foundation models. We suggest caution in applying apples-to-apples comparisons between studies and call for a more structured approach to evaluating toxicity over time.","Pozzobon, Luiza, Ermis, Beyza, Lewis, Patrick, Hooker, Sara",,,On the Challenges of Using Black-Box {API}s for Toxicity Evaluation in Research,,,10.18653/v1/2023.emnlp-main.472 , ,,"Perception of toxicity evolves over time and often differs between geographies and cultural backgrounds. Similarly, black-box commercially available APIs for detecting toxicity, such as the Perspective API, are not static, but frequently retrained to address any unattended weaknesses and biases. We evaluate the implications of these changes on the reproducibility of findings that compare the relative merits of models and methods that aim to curb toxicity. Our findings suggest that research that relied on inherited automatic toxicity scores to compare models and techniques may have resulted in inaccurate findings. Rescoring all models from HELM, a widely respected living benchmark, for toxicity with the recent version of the API led to a different ranking of widely used foundation models. We suggest caution in applying apples-to-apples comparisons between studies and call for a more structured approach to evaluating toxicity over time.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,detection,
3506,"**Title**Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model

**Abstract**While large language models have proven effective in a huge range of downstream applications, they often generate text that is problematic or lacks a desired attribute. In this paper, we introduce Reward-Augmented Decoding (RAD), a text generation procedure that uses a small unidirectional reward model to encourage a language model to generate text that has certain properties. Specifically, RAD uses the reward model to score generations as they are produced and rescales sampling probabilities to favor high-reward tokens. By using a unidirectional reward model, RAD can cache activations from prior generation steps to decrease computational overhead. Through experiments on generating non-toxic and sentiment-controlled text, we demonstrate that RAD performs best among methods that change only the generation procedure and matches the performance of state-of-the-art methods that involve re-training the language model. We further validate that RAD is effective on very large language models while incurring a minimal computational overhead.","Deng, Haikang, Raffel, Colin",,,Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model,,,10.18653/v1/2023.emnlp-main.721 , ,,"While large language models have proven effective in a huge range of downstream applications, they often generate text that is problematic or lacks a desired attribute. In this paper, we introduce Reward-Augmented Decoding (RAD), a text generation procedure that uses a small unidirectional reward model to encourage a language model to generate text that has certain properties. Specifically, RAD uses the reward model to score generations as they are produced and rescales sampling probabilities to favor high-reward tokens. By using a unidirectional reward model, RAD can cache activations from prior generation steps to decrease computational overhead. Through experiments on generating non-toxic and sentiment-controlled text, we demonstrate that RAD performs best among methods that change only the generation procedure and matches the performance of state-of-the-art methods that involve re-training the language model. We further validate that RAD is effective on very large language models while incurring a minimal computational overhead.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,detox,
3507,"**Title**Toward Disambiguating the Definitions of Abusive, Offensive, Toxic, and Uncivil Comments

**Abstract**The definitions of abusive, offensive, toxic and uncivil comments used for annotating corpora for automated content moderation are highly intersected and researchers call for their disambiguation. We summarize the definitions of these terms as they appear in 23 papers across different fields. We compare examples given for uncivil, offensive, and toxic comments, attempting to foster more unified scientific resources. Additionally, we stress that the term incivility that frequently appears in social science literature has hardly been mentioned in the literature we analyzed that focuses on computational linguistics and natural language processing.","Pachinger, Pia, Hanbury, Allan, Neidhardt, Julia, Planitzer, Anna",,,"Toward Disambiguating the Definitions of Abusive, Offensive, Toxic, and Uncivil Comments",,,10.18653/v1/2023.c3nlp-1.11 , ,,"The definitions of abusive, offensive, toxic and uncivil comments used for annotating corpora for automated content moderation are highly intersected and researchers call for their disambiguation. We summarize the definitions of these terms as they appear in 23 papers across different fields. We compare examples given for uncivil, offensive, and toxic comments, attempting to foster more unified scientific resources. Additionally, we stress that the term incivility that frequently appears in social science literature has hardly been mentioned in the literature we analyzed that focuses on computational linguistics and natural language processing.",,,,, ,  Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP),,detection#methodology,
3508,"**Title**{A}l{G}hafa Evaluation Benchmark for {A}rabic Language Models

**Abstract**Recent advances in the space of Arabic large language models have opened up a wealth of potential practical applications. From optimal training strategies, large scale data acquisition and continuously increasing NLP resources, the Arabic LLM landscape has improved in a very short span of time, despite being plagued by training data scarcity and limited evaluation resources compared to English. In line with contributing towards this ever-growing field, we introduce AlGhafa, a new multiple-choice evaluation benchmark for Arabic LLMs. For showcasing purposes, we train a new suite of models, including a 14 billion parameter model, the largest monolingual Arabic decoder-only model to date. We use a collection of publicly available datasets, as well as a newly introduced HandMade dataset consisting of 8 billion tokens. Finally, we explore the quantitative and qualitative toxicity of several Arabic models, comparing our models to existing public Arabic LLMs.","Almazrouei, Ebtesam, Cojocaru, Ruxandra, Baldo, Michele, Malartic, Quentin, Alobeidli, Hamza, Mazzotta, Daniele, Penedo, Guilherme, Campesan, Giulia, Farooq, Mugariya, Alhammadi, Maitha, Launay, Julien, Noune, Badreddine",,,{A}l{G}hafa Evaluation Benchmark for {A}rabic Language Models,,,10.18653/v1/2023.arabicnlp-1.21 , ,,"Recent advances in the space of Arabic large language models have opened up a wealth of potential practical applications. From optimal training strategies, large scale data acquisition and continuously increasing NLP resources, the Arabic LLM landscape has improved in a very short span of time, despite being plagued by training data scarcity and limited evaluation resources compared to English. In line with contributing towards this ever-growing field, we introduce AlGhafa, a new multiple-choice evaluation benchmark for Arabic LLMs. For showcasing purposes, we train a new suite of models, including a 14 billion parameter model, the largest monolingual Arabic decoder-only model to date. We use a collection of publicly available datasets, as well as a newly introduced HandMade dataset consisting of 8 billion tokens. Finally, we explore the quantitative and qualitative toxicity of several Arabic models, comparing our models to existing public Arabic LLMs.",,,,, ,  Proceedings of ArabicNLP 2023,,out_but_toxicity,
3509,"**Title**The uncivil empathy: Investigating the relation between empathy and toxicity in online mental health support forums

**Abstract**We explore the relationship between empathy and toxicity in the context of online mental health forums. Despite the common assumption of a negative correlation between these concepts, it has not been empirically examined. We augment the EPITOME mental health empathy dataset with toxicity labels using two widely employed toxic/harmful content detection APIs: Perspective API and OpenAI moderation API. We find a notable presence of toxic/harmful content (17.77{\%}) within empathetic responses, and only a very weak negative correlation between the two variables. Qualitative analysis revealed contributions labeled as empathetic often contain harmful content such as promotion of suicidal ideas. Our results highlight the need for reevaluating empathy independently from toxicity in future research and encourage a reconsideration of empathy`s role in natural language generation and evaluation.","Chen, Ming-Bin, Lau, Jey Han, Frermann, Lea",,,The uncivil empathy: Investigating the relation between empathy and toxicity in online mental health support forums,,, , ,,"We explore the relationship between empathy and toxicity in the context of online mental health forums. Despite the common assumption of a negative correlation between these concepts, it has not been empirically examined. We augment the EPITOME mental health empathy dataset with toxicity labels using two widely employed toxic/harmful content detection APIs: Perspective API and OpenAI moderation API. We find a notable presence of toxic/harmful content (17.77{\%}) within empathetic responses, and only a very weak negative correlation between the two variables. Qualitative analysis revealed contributions labeled as empathetic often contain harmful content such as promotion of suicidal ideas. Our results highlight the need for reevaluating empathy independently from toxicity in future research and encourage a reconsideration of empathy`s role in natural language generation and evaluation.",,,,, ,  Proceedings of the 21st Annual Workshop of the Australasian Language Technology Association,,detection,
3510,"**Title**On Second Thought, Let`s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning

**Abstract**Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model`s likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved.","Shaikh, Omar, Zhang, Hongxin, Held, William, Bernstein, Michael, Yang, Diyi",,,"On Second Thought, Let`s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning",,,10.18653/v1/2023.acl-long.244 , ,,"Generating a Chain of Thought (CoT) has been shown to consistently improve large language model (LLM) performance on a wide range of NLP tasks. However, prior work has mainly focused on logical reasoning tasks (e.g. arithmetic, commonsense QA); it remains unclear whether improvements hold for more diverse types of reasoning, especially in socially situated contexts. Concretely, we perform a controlled evaluation of zero-shot CoT across two socially sensitive domains: harmful questions and stereotype benchmarks. We find that zero-shot CoT reasoning in sensitive domains significantly increases a model`s likelihood to produce harmful or undesirable output, with trends holding across different prompt formats and model variants. Furthermore, we show that harmful CoTs increase with model size, but decrease with improved instruction following. Our work suggests that zero-shot CoT should be used with caution on socially important tasks, especially when marginalized groups or sensitive topics are involved.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,evaluation,
3511,"**Title**{SQ}u{AR}e: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created through Human-Machine Collaboration

**Abstract**The potential social harms that large language models pose, such as generating offensive content and reinforcing biases, are steeply rising. Existing works focus on coping with this concern while interacting with ill-intentioned users, such as those who explicitly make hate speech or elicit harmful responses. However, discussions on sensitive issues can become toxic even if the users are well-intentioned. For safer models in such scenarios, we present the Sensitive Questions and Acceptable Response (SQuARe) dataset, a large-scale Korean dataset of 49k sensitive questions with 42k acceptable and 46k non-acceptable responses. The dataset was constructed leveraging HyperCLOVA in a human-in-the-loop manner based on real news headlines. Experiments show that acceptable response generation significantly improves for HyperCLOVA and GPT-3, demonstrating the efficacy of this dataset.","Lee, Hwaran, Hong, Seokhee, Park, Joonsuk, Kim, Takyoung, Cha, Meeyoung, Choi, Yejin, Kim, Byoungpil, Kim, Gunhee, Lee, Eun-Ju, Lim, Yong, Oh, Alice, Park, Sangchul, Ha, Jung-Woo",,,{SQ}u{AR}e: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created through Human-Machine Collaboration,,,10.18653/v1/2023.acl-long.370 , ,,"The potential social harms that large language models pose, such as generating offensive content and reinforcing biases, are steeply rising. Existing works focus on coping with this concern while interacting with ill-intentioned users, such as those who explicitly make hate speech or elicit harmful responses. However, discussions on sensitive issues can become toxic even if the users are well-intentioned. For safer models in such scenarios, we present the Sensitive Questions and Acceptable Response (SQuARe) dataset, a large-scale Korean dataset of 49k sensitive questions with 42k acceptable and 46k non-acceptable responses. The dataset was constructed leveraging HyperCLOVA in a human-in-the-loop manner based on real news headlines. Experiments show that acceptable response generation significantly improves for HyperCLOVA and GPT-3, demonstrating the efficacy of this dataset.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_but_toxicity,
3512,"**Title**Facilitating Fine-grained Detection of {C}hinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks

**Abstract**The widespread dissemination of toxic online posts is increasingly damaging to society. However, research on detecting toxic language in Chinese has lagged significantly due to limited datasets. Existing datasets suffer from a lack of fine-grained annotations, such as the toxic type and expressions with indirect toxicity. These fine-grained annotations are crucial factors for accurately detecting the toxicity of posts involved with lexical knowledge, which has been a challenge for researchers. To tackle this problem, we facilitate the fine-grained detection of Chinese toxic language by building a new dataset with benchmark results. First, we devised Monitor Toxic Frame, a hierarchical taxonomy to analyze the toxic type and expressions. Then, we built a fine-grained dataset ToxiCN, including both direct and indirect toxic samples. ToxiCN is based on an insulting vocabulary containing implicit profanity. We further propose a benchmark model, Toxic Knowledge Enhancement (TKE), by incorporating lexical features to detect toxic language. We demonstrate the usability of ToxiCN and the effectiveness of TKE based on a systematic quantitative and qualitative analysis.","Lu, Junyu, Xu, Bo, Zhang, Xiaokun, Min, Changrong, Yang, Liang, Lin, Hongfei",,,"Facilitating Fine-grained Detection of {C}hinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks",,,10.18653/v1/2023.acl-long.898 , ,,"The widespread dissemination of toxic online posts is increasingly damaging to society. However, research on detecting toxic language in Chinese has lagged significantly due to limited datasets. Existing datasets suffer from a lack of fine-grained annotations, such as the toxic type and expressions with indirect toxicity. These fine-grained annotations are crucial factors for accurately detecting the toxicity of posts involved with lexical knowledge, which has been a challenge for researchers. To tackle this problem, we facilitate the fine-grained detection of Chinese toxic language by building a new dataset with benchmark results. First, we devised Monitor Toxic Frame, a hierarchical taxonomy to analyze the toxic type and expressions. Then, we built a fine-grained dataset ToxiCN, including both direct and indirect toxic samples. ToxiCN is based on an insulting vocabulary containing implicit profanity. We further propose a benchmark model, Toxic Knowledge Enhancement (TKE), by incorporating lexical features to detect toxic language. We demonstrate the usability of ToxiCN and the effectiveness of TKE based on a systematic quantitative and qualitative analysis.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_but_toxicity,
3513,"**Title**Towards Building a Robust Toxicity Predictor

**Abstract**Recent NLP literature pays little attention to the robustness of toxicity language predictors, while these systems are most likely to be used in adversarial contexts. This paper presents a novel adversarial attack, {\textbackslash}texttt{\{}ToxicTrap{\}}, introducing small word-level perturbations to fool SOTA text classifiers to predict toxic text samples as benign. {\textbackslash}texttt{\{}ToxicTrap{\}} exploits greedy based search strategies to enable fast and effective generation of toxic adversarial examples. Two novel goal function designs allow {\textbackslash}texttt{\{}ToxicTrap{\}} to identify weaknesses in both multiclass and multilabel toxic language detectors. Our empirical results show that SOTA toxicity text classifiers are indeed vulnerable to the proposed attacks, attaining over 98{\textbackslash}{\%} attack success rates in multilabel cases. We also show how a vanilla adversarial training and its improved version can help increase robustness of a toxicity detector even against unseen attacks.","Bespalov, Dmitriy, Bhabesh, Sourav, Xiang, Yi, Zhou, Liutong, Qi, Yanjun",,,Towards Building a Robust Toxicity Predictor,,,10.18653/v1/2023.acl-industry.56 , ,,"Recent NLP literature pays little attention to the robustness of toxicity language predictors, while these systems are most likely to be used in adversarial contexts. This paper presents a novel adversarial attack, {\textbackslash}texttt{\{}ToxicTrap{\}}, introducing small word-level perturbations to fool SOTA text classifiers to predict toxic text samples as benign. {\textbackslash}texttt{\{}ToxicTrap{\}} exploits greedy based search strategies to enable fast and effective generation of toxic adversarial examples. Two novel goal function designs allow {\textbackslash}texttt{\{}ToxicTrap{\}} to identify weaknesses in both multiclass and multilabel toxic language detectors. Our empirical results show that SOTA toxicity text classifiers are indeed vulnerable to the proposed attacks, attaining over 98{\textbackslash}{\%} attack success rates in multilabel cases. We also show how a vanilla adversarial training and its improved version can help increase robustness of a toxicity detector even against unseen attacks.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track),,detection,
3514,"**Title**The subtle language of exclusion: Identifying the Toxic Speech of Trans-exclusionary Radical Feminists

**Abstract**Toxic language can take many forms, from explicit hate speech to more subtle microaggressions. Within this space, models identifying transphobic language have largely focused on overt forms. However, a more pernicious and subtle source of transphobic comments comes in the form of statements made by Trans-exclusionary Radical Feminists (TERFs); these statements often appear seemingly-positive and promote women`s causes and issues, while simultaneously denying the inclusion of transgender women as women. Here, we introduce two models to mitigate this antisocial behavior. The first model identifies TERF users in social media, recognizing that these users are a main source of transphobic material that enters mainstream discussion and whom other users may not desire to engage with in good faith. The second model tackles the harder task of recognizing the masked rhetoric of TERF messages and introduces a new dataset to support this task. Finally, we discuss the ethics of deploying these models to mitigate the harm of this language, arguing for a balanced approach that allows for restorative interactions.","Lu, Christina, Jurgens, David",,,The subtle language of exclusion: Identifying the Toxic Speech of Trans-exclusionary Radical Feminists,,,10.18653/v1/2022.woah-1.8 , ,,"Toxic language can take many forms, from explicit hate speech to more subtle microaggressions. Within this space, models identifying transphobic language have largely focused on overt forms. However, a more pernicious and subtle source of transphobic comments comes in the form of statements made by Trans-exclusionary Radical Feminists (TERFs); these statements often appear seemingly-positive and promote women`s causes and issues, while simultaneously denying the inclusion of transgender women as women. Here, we introduce two models to mitigate this antisocial behavior. The first model identifies TERF users in social media, recognizing that these users are a main source of transphobic material that enters mainstream discussion and whom other users may not desire to engage with in good faith. The second model tackles the harder task of recognizing the masked rhetoric of TERF messages and introduces a new dataset to support this task. Finally, we discuss the ethics of deploying these models to mitigate the harm of this language, arguing for a balanced approach that allows for restorative interactions.",,,,, ,  Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH),,detection,
3515,"**Title**Lost in Distillation: A Case Study in Toxicity Modeling

**Abstract**In an era of increasingly large pre-trained language models, knowledge distillation is a powerful tool for transferring information from a large model to a smaller one. In particular, distillation is of tremendous benefit when it comes to real-world constraints such as serving latency or serving at scale. However, a loss of robustness in language understanding may be hidden in the process and not immediately revealed when looking at high-level evaluation metrics. In this work, we investigate the hidden costs: what is {\textquotedblleft}lost in distillation{\textquotedblright}, especially in regards to identity-based model bias using the case study of toxicity modeling. With reproducible models using open source training sets, we investigate models distilled from a BERT teacher baseline. Using both open source and proprietary big data models, we investigate these hidden performance costs.","Chvasta, Alyssa, Lees, Alyssa, Sorensen, Jeffrey, Vasserman, Lucy, Goyal, Nitesh",,,Lost in Distillation: A Case Study in Toxicity Modeling,,,10.18653/v1/2022.woah-1.9 , ,,"In an era of increasingly large pre-trained language models, knowledge distillation is a powerful tool for transferring information from a large model to a smaller one. In particular, distillation is of tremendous benefit when it comes to real-world constraints such as serving latency or serving at scale. However, a loss of robustness in language understanding may be hidden in the process and not immediately revealed when looking at high-level evaluation metrics. In this work, we investigate the hidden costs: what is {\textquotedblleft}lost in distillation{\textquotedblright}, especially in regards to identity-based model bias using the case study of toxicity modeling. With reproducible models using open source training sets, we investigate models distilled from a BERT teacher baseline. Using both open source and proprietary big data models, we investigate these hidden performance costs.",,,,, ,  Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH),,detection,
3516,"**Title**Flexible text generation for counterfactual fairness probing

**Abstract**A common approach for testing fairness issues in text-based classifiers is through the use of counterfactuals: does the classifier output change if a sensitive attribute in the input is changed? Existing counterfactual generation methods typically rely on wordlists or templates, producing simple counterfactuals that fail to take into account grammar, context, or subtle sensitive attribute references, and could miss issues that the wordlist creators had not considered. In this paper, we introduce a task for generating counterfactuals that overcomes these shortcomings, and demonstrate how large language models (LLMs) can be leveraged to accomplish this task. We show that this LLM-based method can produce complex counterfactuals that existing methods cannot, comparing the performance of various counterfactual generation methods on the Civil Comments dataset and showing their value in evaluating a toxicity classifier.","Fryer, Zee, Axelrod, Vera, Packer, Ben, Beutel, Alex, Chen, Jilin, Webster, Kellie",,,Flexible text generation for counterfactual fairness probing,,,10.18653/v1/2022.woah-1.20 , ,,"A common approach for testing fairness issues in text-based classifiers is through the use of counterfactuals: does the classifier output change if a sensitive attribute in the input is changed? Existing counterfactual generation methods typically rely on wordlists or templates, producing simple counterfactuals that fail to take into account grammar, context, or subtle sensitive attribute references, and could miss issues that the wordlist creators had not considered. In this paper, we introduce a task for generating counterfactuals that overcomes these shortcomings, and demonstrate how large language models (LLMs) can be leveraged to accomplish this task. We show that this LLM-based method can produce complex counterfactuals that existing methods cannot, comparing the performance of various counterfactual generation methods on the Civil Comments dataset and showing their value in evaluating a toxicity classifier.",,,,, ,  Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH),,detox,
3517,"**Title**Annotating Targets of Toxic Language at the Span Level

**Abstract**In this paper, we discuss an interpretable framework to integrate toxic language annotations. Most data sets address only one aspect of the complex relationship in toxic communication and are inconsistent with each other. Enriching annotations with more details and information is however of great importance in order to develop high-performing and comprehensive explainable language models. Such systems should recognize and interpret both expressions that are toxic as well as expressions that make reference to specific targets to combat toxic language. We therefore created a crowd-annotation task to mark the spans of words that refer to target communities as an extension of the HateXplain data set. We present a quantitative and qualitative analysis of the annotations. We also fine-tuned RoBERTa-base on our data and experimented with different data thresholds to measure their effect on the classification. The F1-score of our best model on the test set is 79{\%}. The annotations are freely available and can be combined with the existing HateXplain annotation to build richer and more complete models.","Barbarestani, Baran, Maks, Isa, Vossen, Piek",,,Annotating Targets of Toxic Language at the Span Level,,, , ,,"In this paper, we discuss an interpretable framework to integrate toxic language annotations. Most data sets address only one aspect of the complex relationship in toxic communication and are inconsistent with each other. Enriching annotations with more details and information is however of great importance in order to develop high-performing and comprehensive explainable language models. Such systems should recognize and interpret both expressions that are toxic as well as expressions that make reference to specific targets to combat toxic language. We therefore created a crowd-annotation task to mark the spans of words that refer to target communities as an extension of the HateXplain data set. We present a quantitative and qualitative analysis of the annotations. We also fine-tuned RoBERTa-base on our data and experimented with different data thresholds to measure their effect on the classification. The F1-score of our best model on the test set is 79{\%}. The annotations are freely available and can be combined with the existing HateXplain annotation to build richer and more complete models.",,,,, ,"  Proceedings of the Third Workshop on Threat, Aggression and Cyberbullying (TRAC 2022)",,detection,
3518,"**Title**Towards Toxic Positivity Detection

**Abstract**Over the past few years, there has been a growing concern around toxic positivity on social media which is a phenomenon where positivity is used to minimize one`s emotional experience. In this paper, we create a dataset for toxic positivity classification from Twitter and an inspirational quote website. We then perform benchmarking experiments using various text classification models and show the suitability of these models for the task. We achieved a macro F1 score of 0.71 and a weighted F1 score of 0.85 by using an ensemble model. To the best of our knowledge, our dataset is the first such dataset created.","Upadhyay, Ishan Sanjeev, Srivatsa, KV Aditya, Mamidi, Radhika",,,Towards Toxic Positivity Detection,,,10.18653/v1/2022.socialnlp-1.7 , ,,"Over the past few years, there has been a growing concern around toxic positivity on social media which is a phenomenon where positivity is used to minimize one`s emotional experience. In this paper, we create a dataset for toxic positivity classification from Twitter and an inspirational quote website. We then perform benchmarking experiments using various text classification models and show the suitability of these models for the task. We achieved a macro F1 score of 0.71 and a weighted F1 score of 0.85 by using an ensemble model. To the best of our knowledge, our dataset is the first such dataset created.",,,,, ,  Proceedings of the Tenth International Workshop on Natural Language Processing for Social Media,,Gen_dataset#detection,
3519,"**Title**Explaining Toxic Text via Knowledge Enhanced Text Generation

**Abstract**Warning: This paper contains content that is offensive and may be upsetting. Biased or toxic speech can be harmful to various demographic groups. Therefore, it is not only important for models to detect these speech, but to also output explanations of why a given text is toxic. Previous literature has mostly focused on classifying and detecting toxic speech, and existing efforts on explaining stereotypes in toxic speech mainly use standard text generation approaches, resulting in generic and repetitive explanations. Building on these prior works, we introduce a novel knowledge-informed encoder-decoder framework to utilize multiple knowledge sources to generate implications of biased text. Experiments show that our knowledge informed models outperform prior state-of-the-art models significantly, and can generate detailed explanations of stereotypes in toxic speech compared to baselines, both quantitatively and qualitatively.","Sridhar, Rohit, Yang, Diyi",,,Explaining Toxic Text via Knowledge Enhanced Text Generation,,,10.18653/v1/2022.naacl-main.59 , ,,"Warning: This paper contains content that is offensive and may be upsetting. Biased or toxic speech can be harmful to various demographic groups. Therefore, it is not only important for models to detect these speech, but to also output explanations of why a given text is toxic. Previous literature has mostly focused on classifying and detecting toxic speech, and existing efforts on explaining stereotypes in toxic speech mainly use standard text generation approaches, resulting in generic and repetitive explanations. Building on these prior works, we introduce a novel knowledge-informed encoder-decoder framework to utilize multiple knowledge sources to generate implications of biased text. Experiments show that our knowledge informed models outperform prior state-of-the-art models significantly, and can generate detailed explanations of stereotypes in toxic speech compared to baselines, both quantitatively and qualitatively.",,,,, ,  Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,detection,
3520,"**Title**{NITK}-{IT}{\_}{NLP}@{T}amil{NLP}-{ACL}2022: Transformer based model for Toxic Span Identification in {T}amil

**Abstract**Toxic span identification in Tamil is a shared task that focuses on identifying harmful content, contributing to offensiveness. In this work, we have built a model that can efficiently identify the span of text contributing to offensive content. We have used various transformer-based models to develop the system, out of which the fine-tuned MuRIL model was able to achieve the best overall character F1-score of 0.4489.","LekshmiAmmal, Hariharan, Ravikiran, Manikandan, Madasamy, Anand Kumar",,,{NITK}-{IT}{\_}{NLP}@{T}amil{NLP}-{ACL}2022: Transformer based model for Toxic Span Identification in {T}amil,,,10.18653/v1/2022.dravidianlangtech-1.12 , ,,"Toxic span identification in Tamil is a shared task that focuses on identifying harmful content, contributing to offensiveness. In this work, we have built a model that can efficiently identify the span of text contributing to offensive content. We have used various transformer-based models to develop the system, out of which the fine-tuned MuRIL model was able to achieve the best overall character F1-score of 0.4489.",,,,, ,  Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,,out_but_toxicity,
3521,"**Title**Data Integration for Toxic Comment Classification: Making More Than 40 Datasets Easily Accessible in One Unified Format

**Abstract**With the rise of research on toxic comment classification, more and more annotated datasets have been released. The wide variety of the task (different languages, different labeling processes and schemes) has led to a large amount of heterogeneous datasets that can be used for training and testing very specific settings. Despite recent efforts to create web pages that provide an overview, most publications still use only a single dataset. They are not stored in one central database, they come in many different data formats and it is difficult to interpret their class labels and how to reuse these labels in other projects. To overcome these issues, we present a collection of more than thirty datasets in the form of a software tool that automatizes downloading and processing of the data and presents them in a unified data format that also offers a mapping of compatible class labels. Another advantage of that tool is that it gives an overview of properties of available datasets, such as different languages, platforms, and class labels to make it easier to select suitable training and test data.","Risch, Julian, Schmidt, Philipp, Krestel, Ralf",,,Data Integration for Toxic Comment Classification: Making More Than 40 Datasets Easily Accessible in One Unified Format,,,10.18653/v1/2021.woah-1.17 , ,,"With the rise of research on toxic comment classification, more and more annotated datasets have been released. The wide variety of the task (different languages, different labeling processes and schemes) has led to a large amount of heterogeneous datasets that can be used for training and testing very specific settings. Despite recent efforts to create web pages that provide an overview, most publications still use only a single dataset. They are not stored in one central database, they come in many different data formats and it is difficult to interpret their class labels and how to reuse these labels in other projects. To overcome these issues, we present a collection of more than thirty datasets in the form of a software tool that automatizes downloading and processing of the data and presents them in a unified data format that also offers a mapping of compatible class labels. Another advantage of that tool is that it gives an overview of properties of available datasets, such as different languages, platforms, and class labels to make it easier to select suitable training and test data.",,,,, ,  Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021),,detection,
3522,"**Title**{TEET}! {T}unisian Dataset for Toxic Speech Detection

**Abstract**The complete freedom of expression in social media has its costs especially in spreading harmful and abusive content that may induce people to act accordingly. Therefore, the need of detecting automatically such a content becomes an urgent task that will help and enhance the efficiency in limiting this toxic spread. Compared to other Arabic dialects which are mostly based on MSA, the Tunisian dialect is a combination of many other languages like MSA, Tamazight, Italian and French. Because of its rich language, dealing with NLP problems can be challenging due to the lack of large annotated datasets. In our context of detecting hate and abusive speech for tunisian dialect, the only existing annotated dataset is T-HSAB combining 6,039 annotated comments as hateful, abusive or normal. In this paper we are introducing a larger annotated dataset composed of approximately 10k of comments. We provide an in-depth exploration of its vocabulary as well as the results of the classification performance of machine learning classifiers like NB and SVM and deep learning models such as ARBERT, MARBERT and XLM-R.","Gharbi, Slim, Haddad, Hatem, Kchaou, Mayssa, Arfaoui, Heger",,,{TEET}! {T}unisian Dataset for Toxic Speech Detection,,, , ,,"The complete freedom of expression in social media has its costs especially in spreading harmful and abusive content that may induce people to act accordingly. Therefore, the need of detecting automatically such a content becomes an urgent task that will help and enhance the efficiency in limiting this toxic spread. Compared to other Arabic dialects which are mostly based on MSA, the Tunisian dialect is a combination of many other languages like MSA, Tamazight, Italian and French. Because of its rich language, dealing with NLP problems can be challenging due to the lack of large annotated datasets. In our context of detecting hate and abusive speech for tunisian dialect, the only existing annotated dataset is T-HSAB combining 6,039 annotated comments as hateful, abusive or normal. In this paper we are introducing a larger annotated dataset composed of approximately 10k of comments. We provide an in-depth exploration of its vocabulary as well as the results of the classification performance of machine learning classifiers like NB and SVM and deep learning models such as ARBERT, MARBERT and XLM-R.",,,,, ,  Proceedings of the Fifth Workshop on Widening Natural Language Processing,,out_but_toxicity,
3523,"**Title**{S}em{E}val-2021 Task 5: Toxic Spans Detection

**Abstract**The Toxic Spans Detection task of SemEval-2021 required participants to predict the spans of toxic posts that were responsible for the toxic label of the posts. The task could be addressed as supervised sequence labeling, using training data with gold toxic spans provided by the organisers. It could also be treated as rationale extraction, using classifiers trained on potentially larger external datasets of posts manually annotated as toxic or not, without toxic span annotations. For the supervised sequence labeling approach and evaluation purposes, posts previously labeled as toxic were crowd-annotated for toxic spans. Participants submitted their predicted spans for a held-out test set and were scored using character-based F1. This overview summarises the work of the 36 teams that provided system descriptions.","Pavlopoulos, John, Sorensen, Jeffrey, Laugier, L{\'e}o, Androutsopoulos, Ion",,,{S}em{E}val-2021 Task 5: Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.6 , ,,"The Toxic Spans Detection task of SemEval-2021 required participants to predict the spans of toxic posts that were responsible for the toxic label of the posts. The task could be addressed as supervised sequence labeling, using training data with gold toxic spans provided by the organisers. It could also be treated as rationale extraction, using classifiers trained on potentially larger external datasets of posts manually annotated as toxic or not, without toxic span annotations. For the supervised sequence labeling approach and evaluation purposes, posts previously labeled as toxic were crowd-annotated for toxic spans. Participants submitted their predicted spans for a held-out test set and were scored using character-based F1. This overview summarises the work of the 36 teams that provided system descriptions.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3524,"**Title**{IITK}@Detox at {S}em{E}val-2021 Task 5: Semi-Supervised Learning and Dice Loss for Toxic Spans Detection

**Abstract**In this work, we present our approach and findings for SemEval-2021 Task 5 - Toxic Spans Detection. The task`s main aim was to identify spans to which a given text`s toxicity could be attributed. The task is challenging mainly due to two constraints: the small training dataset and imbalanced class distribution. Our paper investigates two techniques, semi-supervised learning and learning with Self-Adjusting Dice Loss, for tackling these challenges. Our submitted system (ranked ninth on the leader board) consisted of an ensemble of various pre-trained Transformer Language Models trained using either of the above-proposed techniques.","Bansal, Archit, Kaushik, Abhay, Modi, Ashutosh",,,{IITK}@Detox at {S}em{E}val-2021 Task 5: Semi-Supervised Learning and Dice Loss for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.24 , ,,"In this work, we present our approach and findings for SemEval-2021 Task 5 - Toxic Spans Detection. The task`s main aim was to identify spans to which a given text`s toxicity could be attributed. The task is challenging mainly due to two constraints: the small training dataset and imbalanced class distribution. Our paper investigates two techniques, semi-supervised learning and learning with Self-Adjusting Dice Loss, for tackling these challenges. Our submitted system (ranked ninth on the leader board) consisted of an ensemble of various pre-trained Transformer Language Models trained using either of the above-proposed techniques.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3525,"**Title**{U}ni{P}arma at {S}em{E}val-2021 Task 5: Toxic Spans Detection Using {C}haracter{BERT} and Bag-of-Words Model

**Abstract**With the ever-increasing availability of digital information, toxic content is also on the rise. Therefore, the detection of this type of language is of paramount importance. We tackle this problem utilizing a combination of a state-of-the-art pre-trained language model (CharacterBERT) and a traditional bag-of-words technique. Since the content is full of toxic words that have not been written according to their dictionary spelling, attendance to individual characters is crucial. Therefore, we use CharacterBERT to extract features based on the word characters. It consists of a CharacterCNN module that learns character embeddings from the context. These are, then, fed into the well-known BERT architecture. The bag-of-words method, on the other hand, further improves upon that by making sure that some frequently used toxic words get labeled accordingly. With a {\ensuremath{\sim}}4 percent difference from the first team, our system ranked 36 th in the competition. The code is available for further research and reproduction of the results.","Karimi, Akbar, Rossi, Leonardo, Prati, Andrea",,,{U}ni{P}arma at {S}em{E}val-2021 Task 5: Toxic Spans Detection Using {C}haracter{BERT} and Bag-of-Words Model,,,10.18653/v1/2021.semeval-1.25 , ,,"With the ever-increasing availability of digital information, toxic content is also on the rise. Therefore, the detection of this type of language is of paramount importance. We tackle this problem utilizing a combination of a state-of-the-art pre-trained language model (CharacterBERT) and a traditional bag-of-words technique. Since the content is full of toxic words that have not been written according to their dictionary spelling, attendance to individual characters is crucial. Therefore, we use CharacterBERT to extract features based on the word characters. It consists of a CharacterCNN module that learns character embeddings from the context. These are, then, fed into the well-known BERT architecture. The bag-of-words method, on the other hand, further improves upon that by making sure that some frequently used toxic words get labeled accordingly. With a {\ensuremath{\sim}}4 percent difference from the first team, our system ranked 36 th in the competition. The code is available for further research and reproduction of the results.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3526,"**Title**{U}o{B} at {S}em{E}val-2021 Task 5: Extending Pre-Trained Language Models to Include Task and Domain-Specific Information for Toxic Span Prediction

**Abstract**Toxicity is pervasive in social media and poses a major threat to the health of online communities. The recent introduction of pre-trained language models, which have achieved state-of-the-art results in many NLP tasks, has transformed the way in which we approach natural language processing. However, the inherent nature of pre-training means that they are unlikely to capture task-specific statistical information or learn domain-specific knowledge. Additionally, most implementations of these models typically do not employ conditional random fields, a method for simultaneous token classification. We show that these modifications can improve model performance on the Toxic Spans Detection task at SemEval-2021 to achieve a score within 4 percentage points of the top performing team.","Yan, Erik, Tayyar Madabushi, Harish",,,{U}o{B} at {S}em{E}val-2021 Task 5: Extending Pre-Trained Language Models to Include Task and Domain-Specific Information for Toxic Span Prediction,,,10.18653/v1/2021.semeval-1.28 , ,,"Toxicity is pervasive in social media and poses a major threat to the health of online communities. The recent introduction of pre-trained language models, which have achieved state-of-the-art results in many NLP tasks, has transformed the way in which we approach natural language processing. However, the inherent nature of pre-training means that they are unlikely to capture task-specific statistical information or learn domain-specific knowledge. Additionally, most implementations of these models typically do not employ conditional random fields, a method for simultaneous token classification. We show that these modifications can improve model performance on the Toxic Spans Detection task at SemEval-2021 to achieve a score within 4 percentage points of the top performing team.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3527,"**Title**{M}ed{AI} at {S}em{E}val-2021 Task 5: Start-to-end Tagging Framework for Toxic Spans Detection

**Abstract**This paper describes the system submitted to SemEval 2021 Task 5: Toxic Spans Detection. The task concerns evaluating systems that detect the spans that make a text toxic when detecting such spans are possible. To address the possibly multi-span detection problem, we develop a start-to-end tagging framework on top of RoBERTa based language model. Besides, we design a custom loss function that takes distance into account. In comparison to other participating teams, our system has achieved 69.03{\%} F1 score, which is slightly lower (-1.8 and -1.73) than the top 1(70.83{\%}) and top 2 (70.77{\%}), respectively.","Wang, Zhen, Fan, Hongjie, Liu, Junfei",,,{M}ed{AI} at {S}em{E}val-2021 Task 5: Start-to-end Tagging Framework for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.30 , ,,"This paper describes the system submitted to SemEval 2021 Task 5: Toxic Spans Detection. The task concerns evaluating systems that detect the spans that make a text toxic when detecting such spans are possible. To address the possibly multi-span detection problem, we develop a start-to-end tagging framework on top of RoBERTa based language model. Besides, we design a custom loss function that takes distance into account. In comparison to other participating teams, our system has achieved 69.03{\%} F1 score, which is slightly lower (-1.8 and -1.73) than the top 1(70.83{\%}) and top 2 (70.77{\%}), respectively.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3528,"**Title**{H}amilton{D}inggg at {S}em{E}val-2021 Task 5: Investigating Toxic Span Detection using {R}o{BERT}a Pre-training

**Abstract**This paper presents our system submission to task 5: Toxic Spans Detection of the SemEval-2021 competition. The competition aims at detecting the spans that make a toxic span toxic. In this paper, we demonstrate our system for detecting toxic spans, which includes expanding the toxic training set with Local Interpretable Model-Agnostic Explanations (LIME), fine-tuning RoBERTa model for detection, and error analysis. We found that feeding the model with an expanded training set using Reddit comments of polarized-toxicity and labeling with LIME on top of logistic regression classification could help RoBERTa more accurately learn to recognize toxic spans. We achieved a span-level F1 score of 0.6715 on the testing phase. Our quantitative and qualitative results show that the predictions from our system could be a good supplement to the gold training set`s annotations.","Ding, Huiyang, Jurgens, David",,,{H}amilton{D}inggg at {S}em{E}val-2021 Task 5: Investigating Toxic Span Detection using {R}o{BERT}a Pre-training,,,10.18653/v1/2021.semeval-1.31 , ,,"This paper presents our system submission to task 5: Toxic Spans Detection of the SemEval-2021 competition. The competition aims at detecting the spans that make a toxic span toxic. In this paper, we demonstrate our system for detecting toxic spans, which includes expanding the toxic training set with Local Interpretable Model-Agnostic Explanations (LIME), fine-tuning RoBERTa model for detection, and error analysis. We found that feeding the model with an expanded training set using Reddit comments of polarized-toxicity and labeling with LIME on top of logistic regression classification could help RoBERTa more accurately learn to recognize toxic spans. We achieved a span-level F1 score of 0.6715 on the testing phase. Our quantitative and qualitative results show that the predictions from our system could be a good supplement to the gold training set`s annotations.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3529,"**Title**{HITSZ}-{HLT} at {S}em{E}val-2021 Task 5: Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection

**Abstract**This paper presents the winning system that participated in SemEval-2021 Task 5: Toxic Spans Detection. This task aims to locate those spans that attribute to the text`s toxicity within a text, which is crucial for semi-automated moderation in online discussions. We formalize this task as the Sequence Labeling (SL) problem and the Span Boundary Detection (SBD) problem separately and employ three state-of-the-art models. Next, we integrate predictions of these models to produce a more credible and complement result. Our system achieves a char-level score of 70.83{\%}, ranking 1/91. In addition, we also explore the lexicon-based method, which is strongly interpretable and flexible in practice.","Zhu, Qinglin, Lin, Zijie, Zhang, Yice, Sun, Jingyi, Li, Xiang, Lin, Qihui, Dang, Yixue, Xu, Ruifeng",,,{HITSZ}-{HLT} at {S}em{E}val-2021 Task 5: Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection,,,10.18653/v1/2021.semeval-1.63 , ,,"This paper presents the winning system that participated in SemEval-2021 Task 5: Toxic Spans Detection. This task aims to locate those spans that attribute to the text`s toxicity within a text, which is crucial for semi-automated moderation in online discussions. We formalize this task as the Sequence Labeling (SL) problem and the Span Boundary Detection (SBD) problem separately and employ three state-of-the-art models. Next, we integrate predictions of these models to produce a more credible and complement result. Our system achieves a char-level score of 70.83{\%}, ranking 1/91. In addition, we also explore the lexicon-based method, which is strongly interpretable and flexible in practice.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3530,"**Title**{YNU}-{HPCC} at {S}em{E}val-2021 Task 5: Using a Transformer-based Model with Auxiliary Information for Toxic Span Detection

**Abstract**Toxic span detection requires the detection of spans that make a text toxic instead of simply classifying the text. In this paper, a transformer-based model with auxiliary information is proposed for SemEval-2021 Task 5. The proposed model was implemented based on the BERT-CRF architecture. It consists of three parts: a transformer-based model that can obtain the token representation, an auxiliary information module that combines features from different layers, and an output layer used for the classification. Various BERT-based models, such as BERT, ALBERT, RoBERTa, and XLNET, were used to learn contextual representations. The predictions of these models were assembled to improve the sequence labeling tasks by using a voting strategy. Experimental results showed that the introduced auxiliary information can improve the performance of toxic spans detection. The proposed model ranked 5th of 91 in the competition. The code of this study is available at \url{https://github.com/Chenrj233/semeval2021_task5}","Chen, Ruijun, Wang, Jin, Zhang, Xuejie",,,{YNU}-{HPCC} at {S}em{E}val-2021 Task 5: Using a Transformer-based Model with Auxiliary Information for Toxic Span Detection,,,10.18653/v1/2021.semeval-1.112 , ,,"Toxic span detection requires the detection of spans that make a text toxic instead of simply classifying the text. In this paper, a transformer-based model with auxiliary information is proposed for SemEval-2021 Task 5. The proposed model was implemented based on the BERT-CRF architecture. It consists of three parts: a transformer-based model that can obtain the token representation, an auxiliary information module that combines features from different layers, and an output layer used for the classification. Various BERT-based models, such as BERT, ALBERT, RoBERTa, and XLNET, were used to learn contextual representations. The predictions of these models were assembled to improve the sequence labeling tasks by using a voting strategy. Experimental results showed that the introduced auxiliary information can improve the performance of toxic spans detection. The proposed model ranked 5th of 91 in the competition. The code of this study is available at \url{https://github.com/Chenrj233/semeval2021_task5}",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3531,"**Title**{UIT}-{ISE}-{NLP} at {S}em{E}val-2021 Task 5: Toxic Spans Detection with {B}i{LSTM}-{CRF} and {T}oxic{BERT} Comment Classification

**Abstract**We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23{\%} by F1-score on the Toxic Spans Detection task.","Luu, Son T., Nguyen, Ngan",,,{UIT}-{ISE}-{NLP} at {S}em{E}val-2021 Task 5: Toxic Spans Detection with {B}i{LSTM}-{CRF} and {T}oxic{BERT} Comment Classification,,,10.18653/v1/2021.semeval-1.113 , ,,We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23{\%} by F1-score on the Toxic Spans Detection task.,,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3532,"**Title**{G}olden{W}ind at {S}em{E}val-2021 Task 5: Orthrus - An Ensemble Approach to Identify Toxicity

**Abstract**Many new developments to detect and mitigate toxicity are currently being evaluated. We are particularly interested in the correlation between toxicity and the emotions expressed in online posts. While toxicity may be disguised by amending the wording of posts, emotions will not. Therefore, we describe here an ensemble method to identify toxicity and classify the emotions expressed on a corpus of annotated posts published by Task 5 of SemEval 2021{--}our analysis shows that the majority of such posts express anger, sadness and fear. Our method to identify toxicity combines a lexicon-based approach, which on its own achieves an F1 score of 61.07{\%}, with a supervised learning approach, which on its own achieves an F1 score of 60{\%}. When both methods are combined, the ensemble achieves an F1 score of 66.37{\%}.","Palomino, Marco, Grad, Dawid, Bedwell, James",,,{G}olden{W}ind at {S}em{E}val-2021 Task 5: Orthrus - An Ensemble Approach to Identify Toxicity,,,10.18653/v1/2021.semeval-1.115 , ,,"Many new developments to detect and mitigate toxicity are currently being evaluated. We are particularly interested in the correlation between toxicity and the emotions expressed in online posts. While toxicity may be disguised by amending the wording of posts, emotions will not. Therefore, we describe here an ensemble method to identify toxicity and classify the emotions expressed on a corpus of annotated posts published by Task 5 of SemEval 2021{--}our analysis shows that the majority of such posts express anger, sadness and fear. Our method to identify toxicity combines a lexicon-based approach, which on its own achieves an F1 score of 61.07{\%}, with a supervised learning approach, which on its own achieves an F1 score of 60{\%}. When both methods are combined, the ensemble achieves an F1 score of 66.37{\%}.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3533,"**Title**{LISAC} {FSDM} {USMBA} at {S}em{E}val-2021 Task 5: Tackling Toxic Spans Detection Challenge with Supervised {S}pan{BERT}-based Model and Unsupervised {LIME}-based Model

**Abstract**Toxic spans detection is an emerging challenge that aims to find toxic spans within a toxic text. In this paper, we describe our solutions to tackle toxic spans detection. The first solution, which follows a supervised approach, is based on SpanBERT model. This latter is intended to better embed and predict spans of text. The second solution, which adopts an unsupervised approach, combines linear support vector machine with the Local Interpretable Model-Agnostic Explanations (LIME). This last is used to interpret predictions of learning-based models. Our supervised model outperformed the unsupervised model and achieved the f-score of 67,84{\%} (ranked 22/85) in Task 5 at SemEval-2021: Toxic Spans Detection.","Benlahbib, Abdessamad, Alami, Ahmed, Alami, Hamza",,,{LISAC} {FSDM} {USMBA} at {S}em{E}val-2021 Task 5: Tackling Toxic Spans Detection Challenge with Supervised {S}pan{BERT}-based Model and Unsupervised {LIME}-based Model,,,10.18653/v1/2021.semeval-1.116 , ,,"Toxic spans detection is an emerging challenge that aims to find toxic spans within a toxic text. In this paper, we describe our solutions to tackle toxic spans detection. The first solution, which follows a supervised approach, is based on SpanBERT model. This latter is intended to better embed and predict spans of text. The second solution, which adopts an unsupervised approach, combines linear support vector machine with the Local Interpretable Model-Agnostic Explanations (LIME). This last is used to interpret predictions of learning-based models. Our supervised model outperformed the unsupervised model and achieved the f-score of 67,84{\%} (ranked 22/85) in Task 5 at SemEval-2021: Toxic Spans Detection.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3534,"**Title**{HITMI}{\&}{T} at {S}em{E}val-2021 Task 5: Integrating Transformer and {CRF} for Toxic Spans Detection

**Abstract**This paper introduces our system at SemEval-2021 Task 5: Toxic Spans Detection. The task aims to accurately locate toxic spans within a text. Using BIO tagging scheme, we model the task as a token-level sequence labeling task. Our system uses a single model built on the model of multi-layer bidirectional transformer encoder. And we introduce conditional random field (CRF) to make the model learn the constraints between tags. We use ERNIE as pre-trained model, which is more suitable for the task accroding to our experiments. In addition, we use adversarial training with the fast gradient method (FGM) to improve the robustness of the system. Our system obtains 69.85{\%} F1 score, ranking 3rd for the official evaluation.","Wang, Chenyi, Liu, Tianshu, Zhao, Tiejun",,,{HITMI}{\&}{T} at {S}em{E}val-2021 Task 5: Integrating Transformer and {CRF} for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.117 , ,,"This paper introduces our system at SemEval-2021 Task 5: Toxic Spans Detection. The task aims to accurately locate toxic spans within a text. Using BIO tagging scheme, we model the task as a token-level sequence labeling task. Our system uses a single model built on the model of multi-layer bidirectional transformer encoder. And we introduce conditional random field (CRF) to make the model learn the constraints between tags. We use ERNIE as pre-trained model, which is more suitable for the task accroding to our experiments. In addition, we use adversarial training with the fast gradient method (FGM) to improve the robustness of the system. Our system obtains 69.85{\%} F1 score, ranking 3rd for the official evaluation.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3535,"**Title**{AS}tar{T}wice at {S}em{E}val-2021 Task 5: Toxic Span Detection Using {R}o{BERT}a-{CRF}, Domain Specific Pre-Training and Self-Training

**Abstract**This paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our solution is built upon RoBERTa language model and Conditional Random Fields (CRF). We pre-trained RoBERTa on Civil Comments dataset, enabling it to create better contextual representation for this task. We also employed the semi-supervised learning technique of self-training, which allowed us to extend our training dataset. In addition to these, we also identified some pre-processing steps that significantly improved our F1 score. Our proposed system achieved a rank of 41 with an F1 score of 66.16{\%}.","Suman, Thakur Ashutosh, Jain, Abhinav",,,"{AS}tar{T}wice at {S}em{E}val-2021 Task 5: Toxic Span Detection Using {R}o{BERT}a-{CRF}, Domain Specific Pre-Training and Self-Training",,,10.18653/v1/2021.semeval-1.118 , ,,"This paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our solution is built upon RoBERTa language model and Conditional Random Fields (CRF). We pre-trained RoBERTa on Civil Comments dataset, enabling it to create better contextual representation for this task. We also employed the semi-supervised learning technique of self-training, which allowed us to extend our training dataset. In addition to these, we also identified some pre-processing steps that significantly improved our F1 score. Our proposed system achieved a rank of 41 with an F1 score of 66.16{\%}.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3536,"**Title**{NLP}{\_}{UIOWA} at {S}emeval-2021 Task 5: Transferring Toxic Sets to Tag Toxic Spans

**Abstract**We leverage a BLSTM with attention to identify toxic spans in texts. We explore different dimensions which affect the model`s performance. The first dimension explored is the toxic set the model is trained on. Besides the provided dataset, we explore the transferability of 5 different toxic related sets, including offensive, toxic, abusive, and hate sets. We find that the solely offensive set shows the highest promise of transferability. The second dimension we explore is methodology, including leveraging attention, employing a greedy remove method, using a frequency ratio, and examining hybrid combinations of multiple methods. We conduct an error analysis to examine which types of toxic spans were missed and which were wrongly inferred as toxic along with the main reasons why they occurred. Finally, we extend our method via ensembles, which achieves our highest F1 score of 55.1.","Rusert, Jonathan",,,{NLP}{\_}{UIOWA} at {S}emeval-2021 Task 5: Transferring Toxic Sets to Tag Toxic Spans,,,10.18653/v1/2021.semeval-1.119 , ,,"We leverage a BLSTM with attention to identify toxic spans in texts. We explore different dimensions which affect the model`s performance. The first dimension explored is the toxic set the model is trained on. Besides the provided dataset, we explore the transferability of 5 different toxic related sets, including offensive, toxic, abusive, and hate sets. We find that the solely offensive set shows the highest promise of transferability. The second dimension we explore is methodology, including leveraging attention, employing a greedy remove method, using a frequency ratio, and examining hybrid combinations of multiple methods. We conduct an error analysis to examine which types of toxic spans were missed and which were wrongly inferred as toxic along with the main reasons why they occurred. Finally, we extend our method via ensembles, which achieves our highest F1 score of 55.1.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3537,"**Title**{UA}ntwerp at {S}em{E}val-2021 Task 5: Spans are Spans, stacking a binary word level approach to toxic span detection

**Abstract**This paper describes the system developed by the Antwerp Centre for Digital humanities and literary Criticism [UAntwerp] for toxic span detection. We used a stacked generalisation ensemble of five component models, with two distinct interpretations of the task. Two models attempted to predict binary word toxicity based on ngram sequences, whilst 3 categorical span based models were trained to predict toxic token labels based on complete sequence tokens. The five models' predictions were ensembled within an LSTM model. As well as describing the system, we perform error analysis to explore model performance in relation to textual features. The system described in this paper scored 0.6755 and ranked 26th.","Burtenshaw, Ben, Kestemont, Mike",,,"{UA}ntwerp at {S}em{E}val-2021 Task 5: Spans are Spans, stacking a binary word level approach to toxic span detection",,,10.18653/v1/2021.semeval-1.121 , ,,"This paper describes the system developed by the Antwerp Centre for Digital humanities and literary Criticism [UAntwerp] for toxic span detection. We used a stacked generalisation ensemble of five component models, with two distinct interpretations of the task. Two models attempted to predict binary word toxicity based on ngram sequences, whilst 3 categorical span based models were trained to predict toxic token labels based on complete sequence tokens. The five models' predictions were ensembled within an LSTM model. As well as describing the system, we perform error analysis to explore model performance in relation to textual features. The system described in this paper scored 0.6755 and ranked 26th.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3538,"**Title**hub at {S}em{E}val-2021 Task 5: Toxic Span Detection Based on Word-Level Classification

**Abstract**This article introduces the system description of the hub team, which explains the related work and experimental results of our team`s participation in SemEval 2021 Task 5: Toxic Spans Detection. The data for this shared task comes from some posts on the Internet. The task goal is to identify the toxic content contained in these text data. We need to find the span of the toxic text in the text data as accurately as possible. In the same post, the toxic text may be one paragraph or multiple paragraphs. Our team uses a classification scheme based on word-level to accomplish this task. The system we used to submit the results is ALBERT+BILSTM+CRF. The result evaluation index of the task submission is the F1 score, and the final score of the prediction result of the test set submitted by our team is 0.6640226029.","Huang, Bo, Bai, Yang, Zhou, Xiaobing",,,hub at {S}em{E}val-2021 Task 5: Toxic Span Detection Based on Word-Level Classification,,,10.18653/v1/2021.semeval-1.122 , ,,"This article introduces the system description of the hub team, which explains the related work and experimental results of our team`s participation in SemEval 2021 Task 5: Toxic Spans Detection. The data for this shared task comes from some posts on the Internet. The task goal is to identify the toxic content contained in these text data. We need to find the span of the toxic text in the text data as accurately as possible. In the same post, the toxic text may be one paragraph or multiple paragraphs. Our team uses a classification scheme based on word-level to accomplish this task. The system we used to submit the results is ALBERT+BILSTM+CRF. The result evaluation index of the task submission is the F1 score, and the final score of the prediction result of the test set submitted by our team is 0.6640226029.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3539,"**Title**{MIPT}-{NSU}-{UTMN} at {S}em{E}val-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection

**Abstract**This paper describes our system for SemEval-2021 Task 5 on Toxic Spans Detection. We developed ensemble models using BERT-based neural architectures and post-processing to combine tokens into spans. We evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned BERT models. Finally, our system obtained a F1-score of 67.55{\%} on test data.","Kotyushev, Mikhail, Glazkova, Anna, Morozov, Dmitry",,,{MIPT}-{NSU}-{UTMN} at {S}em{E}val-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.124 , ,,"This paper describes our system for SemEval-2021 Task 5 on Toxic Spans Detection. We developed ensemble models using BERT-based neural architectures and post-processing to combine tokens into spans. We evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned BERT models. Finally, our system obtained a F1-score of 67.55{\%} on test data.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3540,"**Title**{UIT}-E10dot3 at {S}em{E}val-2021 Task 5: Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches

**Abstract**The increment of toxic comments on online space is causing tremendous effects on other vulnerable users. For this reason, considerable efforts are made to deal with this, and SemEval-2021 Task 5: Toxic Spans Detection is one of those. This task asks competitors to extract spans that have toxicity from the given texts, and we have done several analyses to understand its structure before doing experiments. We solve this task by two approaches, Named Entity Recognition with spaCy`s library and Question-Answering with RoBERTa combining with ToxicBERT, and the former gains the highest F1-score of 66.99{\%}.","Gia Hoang, Phu, Thanh Nguyen, Luan, Nguyen, Kiet",,,{UIT}-E10dot3 at {S}em{E}val-2021 Task 5: Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches,,,10.18653/v1/2021.semeval-1.125 , ,,"The increment of toxic comments on online space is causing tremendous effects on other vulnerable users. For this reason, considerable efforts are made to deal with this, and SemEval-2021 Task 5: Toxic Spans Detection is one of those. This task asks competitors to extract spans that have toxicity from the given texts, and we have done several analyses to understand its structure before doing experiments. We solve this task by two approaches, Named Entity Recognition with spaCy`s library and Question-Answering with RoBERTa combining with ToxicBERT, and the former gains the highest F1-score of 66.99{\%}.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3541,"**Title**{S}koltech{NLP} at {S}em{E}val-2021 Task 5: Leveraging Sentence-level Pre-training for Toxic Span Detection

**Abstract**This work describes the participation of the Skoltech NLP group team (Sk) in the Toxic Spans Detection task at SemEval-2021. The goal of the task is to identify the most toxic fragments of a given sentence, which is a binary sequence tagging problem. We show that fine-tuning a RoBERTa model for this problem is a strong baseline. This baseline can be further improved by pre-training the RoBERTa model on a large dataset labeled for toxicity at the sentence level. While our solution scored among the top 20{\%} participating models, it is only 2 points below the best result. This suggests the viability of our approach.","Dale, David, Markov, Igor, Logacheva, Varvara, Kozlova, Olga, Semenov, Nikita, Panchenko, Alexander",,,{S}koltech{NLP} at {S}em{E}val-2021 Task 5: Leveraging Sentence-level Pre-training for Toxic Span Detection,,,10.18653/v1/2021.semeval-1.126 , ,,"This work describes the participation of the Skoltech NLP group team (Sk) in the Toxic Spans Detection task at SemEval-2021. The goal of the task is to identify the most toxic fragments of a given sentence, which is a binary sequence tagging problem. We show that fine-tuning a RoBERTa model for this problem is a strong baseline. This baseline can be further improved by pre-training the RoBERTa model on a large dataset labeled for toxicity at the sentence level. While our solution scored among the top 20{\%} participating models, it is only 2 points below the best result. This suggests the viability of our approach.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3542,"**Title**Entity at {S}em{E}val-2021 Task 5: Weakly Supervised Token Labelling for Toxic Spans Detection

**Abstract**Detection of toxic spans - detecting toxicity of contents in the granularity of tokens - is crucial for effective moderation of online discussions. The baseline approach for this problem using the transformer model is to add a token classification head to the language model and fine-tune the layers with the token labeled dataset. One of the limitations of such a baseline approach is the scarcity of labeled data. To improve the results, We studied leveraging existing public datasets for a related but different task of entire comment/sentence classification. We propose two approaches: the first approach fine-tunes transformer models that are pre-trained on sentence classification samples. In the second approach, we perform weak supervision with soft attention to learn token level labels from sentence labels. Our experiments show improvements in the F1 score over the baseline approach. The implementation has been released publicly.","Jain, Vaibhav, Naghshnejad, Mina",,,Entity at {S}em{E}val-2021 Task 5: Weakly Supervised Token Labelling for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.127 , ,,"Detection of toxic spans - detecting toxicity of contents in the granularity of tokens - is crucial for effective moderation of online discussions. The baseline approach for this problem using the transformer model is to add a token classification head to the language model and fine-tune the layers with the token labeled dataset. One of the limitations of such a baseline approach is the scarcity of labeled data. To improve the results, We studied leveraging existing public datasets for a related but different task of entire comment/sentence classification. We propose two approaches: the first approach fine-tunes transformer models that are pre-trained on sentence classification samples. In the second approach, we perform weak supervision with soft attention to learn token level labels from sentence labels. Our experiments show improvements in the F1 score over the baseline approach. The implementation has been released publicly.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3543,"**Title**{B}ennett{NLP} at {S}em{E}val-2021 Task 5: Toxic Spans Detection using Stacked Embedding Powered Toxic Entity Recognizer

**Abstract**With the rapid growth in technology, social media activity has seen a boom across all age groups. It is humanly impossible to check all the tweets, comments and status manually whether they follow proper community guidelines. A lot of toxicity is regularly posted on these social media platforms. This research aims to find toxic words in a sentence so that a healthy social community is built across the globe and the users receive censored content with specific warnings and facts. To solve this challenging problem, authors have combined concepts of Linked List for pre-processing and then used the idea of stacked embeddings like BERT Embeddings, Flair Embeddings and Word2Vec on the flairNLP framework to get the desired results. F1 metric was used to evaluate the model. The authors were able to produce a 0.74 F1 score on their test set.","Kataria, Harsh, Gupta, Ambuje, Mishra, Vipul",,,{B}ennett{NLP} at {S}em{E}val-2021 Task 5: Toxic Spans Detection using Stacked Embedding Powered Toxic Entity Recognizer,,,10.18653/v1/2021.semeval-1.128 , ,,"With the rapid growth in technology, social media activity has seen a boom across all age groups. It is humanly impossible to check all the tweets, comments and status manually whether they follow proper community guidelines. A lot of toxicity is regularly posted on these social media platforms. This research aims to find toxic words in a sentence so that a healthy social community is built across the globe and the users receive censored content with specific warnings and facts. To solve this challenging problem, authors have combined concepts of Linked List for pre-processing and then used the idea of stacked embeddings like BERT Embeddings, Flair Embeddings and Word2Vec on the flairNLP framework to get the desired results. F1 metric was used to evaluate the model. The authors were able to produce a 0.74 F1 score on their test set.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3544,"**Title**{U}o{T}-{UWF}-{P}art{AI} at {S}em{E}val-2021 Task 5: Self Attention Based {B}i-{GRU} with Multi-Embedding Representation for Toxicity Highlighter

**Abstract**Toxic Spans Detection(TSD) task is defined as highlighting spans that make a text toxic. Many works have been done to classify a given comment or document as toxic or non-toxic. However, none of those proposed models work at the token level. In this paper, we propose a self-attention-based bidirectional gated recurrent unit(BiGRU) with a multi-embedding representation of the tokens. Our proposed model enriches the representation by a combination of GPT-2, GloVe, and RoBERTa embeddings, which led to promising results. Experimental results show that our proposed approach is very effective in detecting span tokens.","Babaei Giglou, Hamed, Rahgooy, Taher, Rahgouy, Mostafa, Razmara, Jafar",,,{U}o{T}-{UWF}-{P}art{AI} at {S}em{E}val-2021 Task 5: Self Attention Based {B}i-{GRU} with Multi-Embedding Representation for Toxicity Highlighter,,,10.18653/v1/2021.semeval-1.129 , ,,"Toxic Spans Detection(TSD) task is defined as highlighting spans that make a text toxic. Many works have been done to classify a given comment or document as toxic or non-toxic. However, none of those proposed models work at the token level. In this paper, we propose a self-attention-based bidirectional gated recurrent unit(BiGRU) with a multi-embedding representation of the tokens. Our proposed model enriches the representation by a combination of GPT-2, GloVe, and RoBERTa embeddings, which led to promising results. Experimental results show that our proposed approach is very effective in detecting span tokens.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3545,"**Title**{Y}oung{S}heldon at {S}em{E}val-2021 Task 5: Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective

**Abstract**In this paper, we describe our system used for SemEval 2021 Task 5: Toxic Spans Detection. Our proposed system approaches the problem as a token classification task. We trained our model to find toxic words and concatenate their spans to predict the toxic spans within a sentence. We fine-tuned Pre-trained Language Models (PLMs) for identifying the toxic words. For fine-tuning, we stacked the classification layer on top of the PLM features of each word to classify if it is toxic or not. PLMs are pre-trained using different objectives and their performance may differ on downstream tasks. We, therefore, compare the performance of BERT, ELECTRA, RoBERTa, XLM-RoBERTa, T5, XLNet, and MPNet for identifying toxic spans within a sentence. Our best performing system used RoBERTa. It performed well, achieving an F1 score of 0.6841 and secured a rank of 16 on the official leaderboard.","Sharma, Mayukh, Kandasamy, Ilanthenral, Vasantha, W.b.",,,{Y}oung{S}heldon at {S}em{E}val-2021 Task 5: Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective,,,10.18653/v1/2021.semeval-1.130 , ,,"In this paper, we describe our system used for SemEval 2021 Task 5: Toxic Spans Detection. Our proposed system approaches the problem as a token classification task. We trained our model to find toxic words and concatenate their spans to predict the toxic spans within a sentence. We fine-tuned Pre-trained Language Models (PLMs) for identifying the toxic words. For fine-tuning, we stacked the classification layer on top of the PLM features of each word to classify if it is toxic or not. PLMs are pre-trained using different objectives and their performance may differ on downstream tasks. We, therefore, compare the performance of BERT, ELECTRA, RoBERTa, XLM-RoBERTa, T5, XLNet, and MPNet for identifying toxic spans within a sentence. Our best performing system used RoBERTa. It performed well, achieving an F1 score of 0.6841 and secured a rank of 16 on the official leaderboard.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3546,"**Title**{HLE}-{UPC} at {S}em{E}val-2021 Task 5: Multi-Depth {D}istil{BERT} for Toxic Spans Detection

**Abstract**This paper presents our submission to SemEval-2021 Task 5: Toxic Spans Detection. The purpose of this task is to detect the spans that make a text toxic, which is a complex labour for several reasons. Firstly, because of the intrinsic subjectivity of toxicity, and secondly, due to toxicity not always coming from single words like insults or offends, but sometimes from whole expressions formed by words that may not be toxic individually. Following this idea of focusing on both single words and multi-word expressions, we study the impact of using a multi-depth DistilBERT model, which uses embeddings from different layers to estimate the final per-token toxicity. Our quantitative results show that using information from multiple depths boosts the performance of the model. Finally, we also analyze our best model qualitatively.","Palliser-Sans, Rafel, Rial-Farr{\`a}s, Albert",,,{HLE}-{UPC} at {S}em{E}val-2021 Task 5: Multi-Depth {D}istil{BERT} for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.131 , ,,"This paper presents our submission to SemEval-2021 Task 5: Toxic Spans Detection. The purpose of this task is to detect the spans that make a text toxic, which is a complex labour for several reasons. Firstly, because of the intrinsic subjectivity of toxicity, and secondly, due to toxicity not always coming from single words like insults or offends, but sometimes from whole expressions formed by words that may not be toxic individually. Following this idea of focusing on both single words and multi-word expressions, we study the impact of using a multi-depth DistilBERT model, which uses embeddings from different layers to estimate the final per-token toxicity. Our quantitative results show that using information from multiple depths boosts the performance of the model. Finally, we also analyze our best model qualitatively.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3547,"**Title**{SRPOL} {DIALOGUE} {SYSTEMS} at {S}em{E}val-2021 Task 5: Automatic Generation of Training Data for Toxic Spans Detection

**Abstract**This paper presents a system used for SemEval-2021 Task 5: Toxic Spans Detection. Our system is an ensemble of BERT-based models for binary word classification, trained on a dataset extended by toxic comments modified and generated by two language models. For the toxic word classification, the prediction threshold value was optimized separately for every comment, in order to maximize the expected F1 value.","Sat{\l}awa, Micha{\l}, Zam{\l}y{\'n}ska, Katarzyna, Piersa, Jaros{\l}aw, Kolis, Joanna, Firl{\k{a}}g, Klaudia, Beksa, Katarzyna, Bordzicka, Zuzanna, Goltz, Christian, Bujnowski, Pawe{\l}, Andruszkiewicz, Piotr",,,{SRPOL} {DIALOGUE} {SYSTEMS} at {S}em{E}val-2021 Task 5: Automatic Generation of Training Data for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.133 , ,,"This paper presents a system used for SemEval-2021 Task 5: Toxic Spans Detection. Our system is an ensemble of BERT-based models for binary word classification, trained on a dataset extended by toxic comments modified and generated by two language models. For the toxic word classification, the prediction threshold value was optimized separately for every comment, in order to maximize the expected F1 value.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3548,"**Title**{SINAI} at {S}em{E}val-2021 Task 5: Combining Embeddings in a {B}i{LSTM}-{CRF} model for Toxic Spans Detection

**Abstract**This paper describes the participation of SINAI team at Task 5: Toxic Spans Detection which consists of identifying spans that make a text toxic. Although several resources and systems have been developed so far in the context of offensive language, both annotation and tasks have mainly focused on classifying whether a text is offensive or not. However, detecting toxic spans is crucial to identify why a text is toxic and can assist human moderators to locate this type of content on social media. In order to accomplish the task, we follow a deep learning-based approach using a Bidirectional variant of a Long Short Term Memory network along with a stacked Conditional Random Field decoding layer (BiLSTM-CRF). Specifically, we test the performance of the combination of different pre-trained word embeddings for recognizing toxic entities in text. The results show that the combination of word embeddings helps in detecting offensive content. Our team ranks 29th out of 91 participants.","Plaza-del-Arco, Flor Miriam, L{\'o}pez-{\'U}beda, Pilar, Ure{\~n}a-L{\'o}pez, L. Alfonso, Mart{\'i}n-Valdivia, M. Teresa",,,{SINAI} at {S}em{E}val-2021 Task 5: Combining Embeddings in a {B}i{LSTM}-{CRF} model for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.134 , ,,"This paper describes the participation of SINAI team at Task 5: Toxic Spans Detection which consists of identifying spans that make a text toxic. Although several resources and systems have been developed so far in the context of offensive language, both annotation and tasks have mainly focused on classifying whether a text is offensive or not. However, detecting toxic spans is crucial to identify why a text is toxic and can assist human moderators to locate this type of content on social media. In order to accomplish the task, we follow a deep learning-based approach using a Bidirectional variant of a Long Short Term Memory network along with a stacked Conditional Random Field decoding layer (BiLSTM-CRF). Specifically, we test the performance of the combination of different pre-trained word embeddings for recognizing toxic entities in text. The results show that the combination of word embeddings helps in detecting offensive content. Our team ranks 29th out of 91 participants.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3549,"**Title**{CSECU}-{DSG} at {S}em{E}val-2021 Task 5: Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection

**Abstract**The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Detecting the toxic portions substantially aids to moderate or exclude the abusive parts for maintaining sound online platforms. This paper describes our participation in the SemEval 2021 toxic span detection task. The task requires detecting spans that convey toxic remarks from the given text. We explore an ensemble of sequence labeling models including the BiLSTM-CRF, spaCy NER model with custom toxic tags, and fine-tuned BERT model to identify the toxic spans. Finally, a majority voting ensemble method is used to determine the unified toxic spans. Experimental results depict the competitive performance of our model among the participants.","Hossain, Tashin, Naim, Jannatun, Tasneem, Fareen, Tasnia, Radiathun, Chy, Abu Nowshed",,,{CSECU}-{DSG} at {S}em{E}val-2021 Task 5: Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.135 , ,,"The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Detecting the toxic portions substantially aids to moderate or exclude the abusive parts for maintaining sound online platforms. This paper describes our participation in the SemEval 2021 toxic span detection task. The task requires detecting spans that convey toxic remarks from the given text. We explore an ensemble of sequence labeling models including the BiLSTM-CRF, spaCy NER model with custom toxic tags, and fine-tuned BERT model to identify the toxic spans. Finally, a majority voting ensemble method is used to determine the unified toxic spans. Experimental results depict the competitive performance of our model among the participants.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3550,"**Title**macech at {S}em{E}val-2021 Task 5: Toxic Spans Detection

**Abstract**Toxic language is often present in online forums, especially when politics and other polarizing topics arise, and can lead to people becoming discouraged from joining or continuing conversations. In this paper, we use data consisting of comments with the indices of toxic text labelled to train an RNN to deter-mine which parts of the comments make them toxic, which could aid online moderators. We compare results using both the original dataset and an augmented set, as well as GRU versus LSTM RNN models.","Cech, Maggie",,,macech at {S}em{E}val-2021 Task 5: Toxic Spans Detection,,,10.18653/v1/2021.semeval-1.137 , ,,"Toxic language is often present in online forums, especially when politics and other polarizing topics arise, and can lead to people becoming discouraged from joining or continuing conversations. In this paper, we use data consisting of comments with the indices of toxic text labelled to train an RNN to deter-mine which parts of the comments make them toxic, which could aid online moderators. We compare results using both the original dataset and an augmented set, as well as GRU versus LSTM RNN models.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3551,"**Title**{LZ}1904 at {S}em{E}val-2021 Task 5: {B}i-{LSTM}-{CRF} for Toxic Span Detection using Pretrained Word Embedding

**Abstract**Recurrent Neural Networks (RNN) have been widely used in various Natural Language Processing (NLP) tasks such as text classification, sequence tagging, and machine translation. Long Short Term Memory (LSTM), a special unit of RNN, has the benefit of memorizing past and even future information in a sentence (especially for bidirectional LSTM). In the shared task of detecting spans which make texts toxic, we first apply pretrained word embedding (GloVe) to generate the word vectors after tokenization. And then we construct Bidirectional Long Short Term Memory-Conditional Random Field (Bi-LSTM-CRF) model by Baidu research to predict whether each word in the sentence is toxic or not. We tune hyperparameters of dropout rate, number of LSTM units, embedding size with 10 epochs and choose the best epoch with validation recall. Our model achieves an F1 score of 66.99 percent in test dataset.","Zou, Liang, Li, Wen",,,{LZ}1904 at {S}em{E}val-2021 Task 5: {B}i-{LSTM}-{CRF} for Toxic Span Detection using Pretrained Word Embedding,,,10.18653/v1/2021.semeval-1.138 , ,,"Recurrent Neural Networks (RNN) have been widely used in various Natural Language Processing (NLP) tasks such as text classification, sequence tagging, and machine translation. Long Short Term Memory (LSTM), a special unit of RNN, has the benefit of memorizing past and even future information in a sentence (especially for bidirectional LSTM). In the shared task of detecting spans which make texts toxic, we first apply pretrained word embedding (GloVe) to generate the word vectors after tokenization. And then we construct Bidirectional Long Short Term Memory-Conditional Random Field (Bi-LSTM-CRF) model by Baidu research to predict whether each word in the sentence is toxic or not. We tune hyperparameters of dropout rate, number of LSTM units, embedding size with 10 epochs and choose the best epoch with validation recall. Our model achieves an F1 score of 66.99 percent in test dataset.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3552,"**Title**Capturing Covertly Toxic Speech via Crowdsourcing

**Abstract**We study the task of labeling covert or veiled toxicity in online conversations. Prior research has highlighted the difficulty in creating language models that recognize nuanced toxicity such as microaggressions. Our investigations further underscore the difficulty in parsing such labels reliably from raters via crowdsourcing. We introduce an initial dataset, COVERTTOXICITY, which aims to identify and categorize such comments from a refined rater template. Finally, we fine-tune a comment-domain BERT model to classify covertly offensive comments and compare against existing baselines.","Lees, Alyssa, Borkan, Daniel, Kivlichan, Ian, Nario, Jorge, Goyal, Tesh",,,Capturing Covertly Toxic Speech via Crowdsourcing,,, , ,,"We study the task of labeling covert or veiled toxicity in online conversations. Prior research has highlighted the difficulty in creating language models that recognize nuanced toxicity such as microaggressions. Our investigations further underscore the difficulty in parsing such labels reliably from raters via crowdsourcing. We introduce an initial dataset, COVERTTOXICITY, which aims to identify and categorize such comments from a refined rater template. Finally, we fine-tune a comment-domain BERT model to classify covertly offensive comments and compare against existing baselines.",,,,, ,  Proceedings of the First Workshop on Bridging Human{--}Computer Interaction and Natural Language Processing,,detection,
3553,"**Title**Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments

**Abstract**AbstractWe present the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. This shared task comprises three binary classification subtasks with the goal to identify: toxic comments, engaging comments, and comments that include indications of a need for fact-checking, here referred to as fact-claiming comments. Building on the two previous GermEval shared tasks on the identification of offensive language in 2018 and 2019, we extend this year’s task definition to meet the demand of moderators and community managers to also highlight comments that foster respectful communication, encourage in-depth discussions, and check facts that lines of arguments rely on. The dataset comprises 4,188 posts extracted from the Facebook page of a German political talk show of a national public television broadcaster. A theoretical framework and additional reliability tests during the data annotation process ensure particularly high data quality. The shared task had 15 participating teams submitting 31 runs for the subtask on toxic comments, 25 runs for the subtask on engaging comments, and 31 for the subtask on fact-claiming comments. The shared task website can be found at https://germeval2021toxic.github.io/SharedTask/.",,,,"Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,, , ,,"AbstractWe present the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. This shared task comprises three binary classification subtasks with the goal to identify: toxic comments, engaging comments, and comments that include indications of a need for fact-checking, here referred to as fact-claiming comments. Building on the two previous GermEval shared tasks on the identification of offensive language in 2018 and 2019, we extend this year’s task definition to meet the demand of moderators and community managers to also highlight comments that foster respectful communication, encourage in-depth discussions, and check facts that lines of arguments rely on. The dataset comprises 4,188 posts extracted from the Facebook page of a German political talk show of a national public television broadcaster. A theoretical framework and additional reliability tests during the data annotation process ensure particularly high data quality. The shared task had 15 participating teams submitting 31 runs for the subtask on toxic comments, 25 runs for the subtask on engaging comments, and 31 for the subtask on fact-claiming comments. The shared task website can be found at https://germeval2021toxic.github.io/SharedTask/.",,,,, ,  ,,out_but_toxicity,
3554,"**Title**Overview of the {G}erm{E}val 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments

**Abstract**We present the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. This shared task comprises three binary classification subtasks with the goal to identify: toxic comments, engaging comments, and comments that include indications of a need for fact-checking, here referred to as fact-claiming comments. Building on the two previous GermEval shared tasks on the identification of offensive language in 2018 and 2019, we extend this year`s task definition to meet the demand of moderators and community managers to also highlight comments that foster respectful communication, encourage in-depth discussions, and check facts that lines of arguments rely on. The dataset comprises 4,188 posts extracted from the Facebook page of a German political talk show of a national public television broadcaster. A theoretical framework and additional reliability tests during the data annotation process ensure particularly high data quality. The shared task had 15 participating teams submitting 31 runs for the subtask on toxic comments, 25 runs for the subtask on engaging comments, and 31 for the subtask on fact-claiming comments. The shared task website can be found at \url{https://germeval2021toxic.github.io/SharedTask/}.","Risch, Julian, Stoll, Anke, Wilms, Lena, Wiegand, Michael",,,"Overview of the {G}erm{E}val 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,, , ,,"We present the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. This shared task comprises three binary classification subtasks with the goal to identify: toxic comments, engaging comments, and comments that include indications of a need for fact-checking, here referred to as fact-claiming comments. Building on the two previous GermEval shared tasks on the identification of offensive language in 2018 and 2019, we extend this year`s task definition to meet the demand of moderators and community managers to also highlight comments that foster respectful communication, encourage in-depth discussions, and check facts that lines of arguments rely on. The dataset comprises 4,188 posts extracted from the Facebook page of a German political talk show of a national public television broadcaster. A theoretical framework and additional reliability tests during the data annotation process ensure particularly high data quality. The shared task had 15 participating teams submitting 31 runs for the subtask on toxic comments, 25 runs for the subtask on engaging comments, and 31 for the subtask on fact-claiming comments. The shared task website can be found at \url{https://germeval2021toxic.github.io/SharedTask/}.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3555,"**Title**{FH}-{SWF} {SG} at {G}erm{E}val 2021: Using Transformer-Based Language Models to Identify Toxic, Engaging, {\&} Fact-Claiming Comments

**Abstract**In this paper we describe the methods we used for our submissions to the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. For all three subtasks we fine-tuned freely available transformer-based models from the Huggingface model hub. We evaluated the performance of various pre-trained models after fine-tuning on 80{\%} of the training data with different hyperparameters and submitted predictions of the two best performing resulting models. We found that this approach worked best for subtask 3, for which we achieved an F1-score of 0.736.","Gawron, Christian, Schmidt, Sebastian",,,"{FH}-{SWF} {SG} at {G}erm{E}val 2021: Using Transformer-Based Language Models to Identify Toxic, Engaging, {\&} Fact-Claiming Comments",,, , ,,"In this paper we describe the methods we used for our submissions to the GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. For all three subtasks we fine-tuned freely available transformer-based models from the Huggingface model hub. We evaluated the performance of various pre-trained models after fine-tuning on 80{\%} of the training data with different hyperparameters and submitted predictions of the two best performing resulting models. We found that this approach worked best for subtask 3, for which we achieved an F1-score of 0.736.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3556,"**Title**{IRC}ologne at {G}erm{E}val 2021: Toxicity Classification

**Abstract**In this paper, we describe the TH K{\""o}ln`s submission for the Shared Task on the Identification of Toxic Comments at GermEval 2021. Toxicity is a severe and latent problem in comments in online discussions. Complex language model based methods have shown the most success in identifying toxicity. However, these approaches lack explainability and might be insensitive to domain-specific renditions of toxicity. In the scope of the GermEval 2021 toxic comment classification task (Risch et al., 2021), we employed a simple but promising combination of term-frequency-based classification and rule-based labeling to produce effective but to no lesser degree explainable toxicity predictions.","Haak, Fabian, Engelmann, Bj{\""o}rn",,,{IRC}ologne at {G}erm{E}val 2021: Toxicity Classification,,, , ,,"In this paper, we describe the TH K{\""o}ln`s submission for the Shared Task on the Identification of Toxic Comments at GermEval 2021. Toxicity is a severe and latent problem in comments in online discussions. Complex language model based methods have shown the most success in identifying toxicity. However, these approaches lack explainability and might be insensitive to domain-specific renditions of toxicity. In the scope of the GermEval 2021 toxic comment classification task (Risch et al., 2021), we employed a simple but promising combination of term-frequency-based classification and rule-based labeling to produce effective but to no lesser degree explainable toxicity predictions.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3557,"**Title**{D}e{T}ox at {G}erm{E}val 2021: Toxic Comment Classification

**Abstract**In this work, we present our approaches on the toxic comment classification task (subtask 1) of the GermEval 2021 Shared Task. For this binary task, we propose three models: a German BERT transformer model; a multilayer perceptron, which was first trained in parallel on textual input and 14 additional linguistic features and then concatenated in an additional layer; and a multilayer perceptron with both feature types as input. We enhanced our pre-trained transformer model by re-training it with over 1 million tweets and fine-tuned it on two additional German datasets of similar tasks. The embeddings of the final fine-tuned German BERT were taken as the textual input features for our neural networks. Our best models on the validation data were both neural networks, however our enhanced German BERT gained with a F1-score = 0.5895 a higher prediction on the test data.","Sch{\""u}tz, Mina, Demus, Christoph, Pitz, Jonas, Probol, Nadine, Siegel, Melanie, Labudde, Dirk",,,{D}e{T}ox at {G}erm{E}val 2021: Toxic Comment Classification,,, , ,,"In this work, we present our approaches on the toxic comment classification task (subtask 1) of the GermEval 2021 Shared Task. For this binary task, we propose three models: a German BERT transformer model; a multilayer perceptron, which was first trained in parallel on textual input and 14 additional linguistic features and then concatenated in an additional layer; and a multilayer perceptron with both feature types as input. We enhanced our pre-trained transformer model by re-training it with over 1 million tweets and fine-tuned it on two additional German datasets of similar tasks. The embeddings of the final fine-tuned German BERT were taken as the textual input features for our neural networks. Our best models on the validation data were both neural networks, however our enhanced German BERT gained with a F1-score = 0.5895 a higher prediction on the test data.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3558,"**Title**Universit{\""a}t Regensburg {M}ax{S} at {G}erm{E}val 2021 Task 1: Synthetic Data in Toxic Comment Classification

**Abstract**We report on our submission to Task 1 of the GermEval 2021 challenge {--} toxic comment classification. We investigate different ways of bolstering scarce training data to improve off-the-shelf model performance on a toxic comment classification task. To help address the limitations of a small dataset, we use data synthetically generated by a German GPT-2 model. The use of synthetic data has only recently been taking off as a possible solution to ad- dressing training data sparseness in NLP, and initial results are promising. However, our model did not see measurable improvement through the use of synthetic data. We discuss possible reasons for this finding and explore future works in the field.","Schmidhuber, Maximilian",,,"Universit{\""a}t Regensburg {M}ax{S} at {G}erm{E}val 2021 Task 1: Synthetic Data in Toxic Comment Classification",,, , ,,"We report on our submission to Task 1 of the GermEval 2021 challenge {--} toxic comment classification. We investigate different ways of bolstering scarce training data to improve off-the-shelf model performance on a toxic comment classification task. To help address the limitations of a small dataset, we use data synthetically generated by a German GPT-2 model. The use of synthetic data has only recently been taking off as a possible solution to ad- dressing training data sparseness in NLP, and initial results are promising. However, our model did not see measurable improvement through the use of synthetic data. We discuss possible reasons for this finding and explore future works in the field.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3559,"**Title**{TUW}-{I}nf at {G}erm{E}val2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments

**Abstract**This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021). We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.","G{\'e}mes, Kinga, Recski, G{\'a}bor",,,"{TUW}-{I}nf at {G}erm{E}val2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments",,, , ,,"This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021). We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3560,"**Title**{UR}@{NLP}{\_}{A}{\_}{T}eam @ {G}erm{E}val 2021: Ensemble-based Classification of Toxic, Engaging and Fact-Claiming Comments

**Abstract**In this paper, we report on our approach to addressing the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments for the German language. We submitted three runs for each subtask based on ensembles of three models each using contextual embeddings from pre-trained language models using SVM and neural-network-based classifiers. We include language-specific as well as language-agnostic language models {--} both with and without fine-tuning. We observe that for the runs we submitted that the SVM models overfitted the training data and this affected the aggregation method (simple majority voting) of the ensembles. The model records a lower performance on the test set than on the training set. Exploring the issue of overfitting we uncovered that due to a bug in the pipeline the runs we submitted had not been trained on the full set but only on a small training set. Therefore in this paper we also include the results we get when trained on the full training set which demonstrate the power of ensembles.","Akomeah, Kwabena Odame, Kruschwitz, Udo, Ludwig, Bernd",,,"{UR}@{NLP}{\_}{A}{\_}{T}eam @ {G}erm{E}val 2021: Ensemble-based Classification of Toxic, Engaging and Fact-Claiming Comments",,, , ,,"In this paper, we report on our approach to addressing the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments for the German language. We submitted three runs for each subtask based on ensembles of three models each using contextual embeddings from pre-trained language models using SVM and neural-network-based classifiers. We include language-specific as well as language-agnostic language models {--} both with and without fine-tuning. We observe that for the runs we submitted that the SVM models overfitted the training data and this affected the aggregation method (simple majority voting) of the ensembles. The model records a lower performance on the test set than on the training set. Exploring the issue of overfitting we uncovered that due to a bug in the pipeline the runs we submitted had not been trained on the full set but only on a small training set. Therefore in this paper we also include the results we get when trained on the full training set which demonstrate the power of ensembles.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3561,"**Title**{FHAC} at {G}erm{E}val 2021: Identifying {G}erman toxic, engaging, and fact-claiming comments with ensemble learning

**Abstract**The availability of language representations learned by large pretrained neural network models (such as BERT and ELECTRA) has led to improvements in many downstream Natural Language Processing tasks in recent years. Pretrained models usually differ in pretraining objectives, architectures, and datasets they are trained on which can affect downstream performance. In this contribution, we fine-tuned German BERT and German ELECTRA models to identify toxic (subtask 1), engaging (subtask 2), and fact-claiming comments (subtask 3) in Facebook data provided by the GermEval 2021 competition. We created ensembles of these models and investigated whether and how classification performance depends on the number of ensemble members and their composition. On out-of-sample data, our best ensemble achieved a macro-F1 score of 0.73 (for all subtasks), and F1 scores of 0.72, 0.70, and 0.76 for subtasks 1, 2, and 3, respectively.","Bornheim, Tobias, Grieger, Niklas, Bialonski, Stephan",,,"{FHAC} at {G}erm{E}val 2021: Identifying {G}erman toxic, engaging, and fact-claiming comments with ensemble learning",,, , ,,"The availability of language representations learned by large pretrained neural network models (such as BERT and ELECTRA) has led to improvements in many downstream Natural Language Processing tasks in recent years. Pretrained models usually differ in pretraining objectives, architectures, and datasets they are trained on which can affect downstream performance. In this contribution, we fine-tuned German BERT and German ELECTRA models to identify toxic (subtask 1), engaging (subtask 2), and fact-claiming comments (subtask 3) in Facebook data provided by the GermEval 2021 competition. We created ensembles of these models and investigated whether and how classification performance depends on the number of ensemble members and their composition. On out-of-sample data, our best ensemble achieved a macro-F1 score of 0.73 (for all subtasks), and F1 scores of 0.72, 0.70, and 0.76 for subtasks 1, 2, and 3, respectively.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3562,"**Title**Say {\textquoteleft}{YES}' to Positivity: Detecting Toxic Language in Workplace Communications

**Abstract**Workplace communication (e.g. email, chat, etc.) is a central part of enterprise productivity. Healthy conversations are crucial for creating an inclusive environment and maintaining harmony in an organization. Toxic communications at the workplace can negatively impact overall job satisfaction and are often subtle, hidden, or demonstrate human biases. The linguistic subtlety of mild yet hurtful conversations has made it difficult for researchers to quantify and extract toxic conversations automatically. While offensive language or hate speech has been extensively studied in social communities, there has been little work studying toxic communication in emails. Specifically, the lack of corpus, sparsity of toxicity in enterprise emails, and well-defined criteria for annotating toxic conversations have prevented researchers from addressing the problem at scale. We take the first step towards studying toxicity in workplace emails by providing (1) a general and computationally viable taxonomy to study toxic language at the workplace (2) a dataset to study toxic language at the workplace based on the taxonomy and (3) analysis on why offensive language and hate-speech datasets are not suitable to detect workplace toxicity.","Bhat, Meghana Moorthy, Hosseini, Saghar, Awadallah, Ahmed Hassan, Bennett, Paul, Li, Weisheng",,,Say {\textquoteleft}{YES}' to Positivity: Detecting Toxic Language in Workplace Communications,,,10.18653/v1/2021.findings-emnlp.173 , ,,"Workplace communication (e.g. email, chat, etc.) is a central part of enterprise productivity. Healthy conversations are crucial for creating an inclusive environment and maintaining harmony in an organization. Toxic communications at the workplace can negatively impact overall job satisfaction and are often subtle, hidden, or demonstrate human biases. The linguistic subtlety of mild yet hurtful conversations has made it difficult for researchers to quantify and extract toxic conversations automatically. While offensive language or hate speech has been extensively studied in social communities, there has been little work studying toxic communication in emails. Specifically, the lack of corpus, sparsity of toxicity in enterprise emails, and well-defined criteria for annotating toxic conversations have prevented researchers from addressing the problem at scale. We take the first step towards studying toxicity in workplace emails by providing (1) a general and computationally viable taxonomy to study toxic language at the workplace (2) a dataset to study toxic language at the workplace based on the taxonomy and (3) analysis on why offensive language and hate-speech datasets are not suitable to detect workplace toxicity.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2021,,detection,
3563,"**Title**{CONDA}: a {CON}textual Dual-Annotated dataset for in-game toxicity understanding and detection

**Abstract**Traditional toxicity detection models have fo-
    cused on the single utterance level without
    deeper understanding of context. We introduce
   CONDA, a new dataset for in-game toxic lan-
    guage detection enabling joint intent classiﬁ-
    cation and slot ﬁlling analysis, which is the
    core task of Natural Language Understanding
   (NLU). The dataset consists of 45K utterances
    from 12K conversations from the chat logs of
   1.9K completed Dota 2 matches. We propose a
    robust dual semantic-level toxicity framework,
   which handles utterance and token-level pat-
     terns, and rich contextual chatting history. Ac-
    companying the dataset is a thorough in-game
     toxicity analysis, which provides comprehen-
    sive understanding of context at utterance, to-
    ken, and dual levels.  Inspired by NLU, we
    also apply its metrics to the toxicity detection
    tasks for assessing toxicity and game-speciﬁc
    aspects. We evaluate strong NLU models on
   CONDA, providing ﬁne-grained results for dif-
    ferent intent classes and slot classes. Further-
    more, we examine the coverage of toxicity na-
    ture in our dataset by comparing it with other
     toxicity datasets.1

1  Introduction

As the popularity of multi-player online games has
grown, the phenomenon of in-game toxic behav-
ior has taken root within them. Toxic behavior
is strongly present in recent online games and is
problematic to the gaming industry (Adinolf and
Turkay, 2018). For instance, 74% of US players of
such games report harassment with 65% experienc-
ing severe harassment. (ADL, 2019).
   In the past few years, Natural Language Process-
ing (NLP) researchers have proposed several on-
line game/community toxicity analysis frameworks

    ∗Corresponding author (caren.han@sydney.edu.au)
   1The  dataset and  lexicons  are  available  at  https://
github.com/usydnlp.Figure 1: An example intent/slot annotation from the
CONDA (CONtextual Dual-Annotated) dataset.



(Kwak et al., 2015; Murnion et al., 2018; Wang
et al., 2020) and datasets (M¨artens et al., 2015;
Stoop et al., 2019). However, existing datasets
(1) focus only on the single utterance level with-
out deeper understanding of context in the whole
conversation/chat, and (2) do not explicitly use se-
mantic clues from the words within the utterance.
  The chat in online games and communities is
similar in nature to spoken language, an area stud-
ied by Natural Language Understanding (NLU).
NLU research aims to best represent human com-
munication by extracting semantic structure in the
form of intent and slot analysis. Intent detection is
the classiﬁcation of the desired outcome of an utter-
ance (or sentence), and slot ﬁlling is the labeling of
each token (or word) in the utterance with the type
of semantic information it carries. In recent litera-
ture, these two tasks are trained jointly to capture
synergies between them, and these jointly trained
models give better results (Zhang et al., 2019b).
Furthermore, researchers have made available joint
task datasets that contain the context of a multi-turn
conversation (Budzianowski et al., 2018; Schuster
et al., 2019)
  Inspired by this NLU research progress, we2406","Weld, Henry, Huang, Guanghao, Lee, Jean, Zhang, Tongshu, Wang, Kunze, Guo, Xinghong, Long, Siqu, Poon, Josiah, Han, Caren",,,{CONDA}: a {CON}textual Dual-Annotated dataset for in-game toxicity understanding and detection,,,10.18653/v1/2021.findings-acl.213 , ,,"Traditional toxicity detection models have fo-
    cused on the single utterance level without
    deeper understanding of context. We introduce
   CONDA, a new dataset for in-game toxic lan-
    guage detection enabling joint intent classiﬁ-
    cation and slot ﬁlling analysis, which is the
    core task of Natural Language Understanding
   (NLU). The dataset consists of 45K utterances
    from 12K conversations from the chat logs of
   1.9K completed Dota 2 matches. We propose a
    robust dual semantic-level toxicity framework,
   which handles utterance and token-level pat-
     terns, and rich contextual chatting history. Ac-
    companying the dataset is a thorough in-game
     toxicity analysis, which provides comprehen-
    sive understanding of context at utterance, to-
    ken, and dual levels.  Inspired by NLU, we
    also apply its metrics to the toxicity detection
    tasks for assessing toxicity and game-speciﬁc
    aspects. We evaluate strong NLU models on
   CONDA, providing ﬁne-grained results for dif-
    ferent intent classes and slot classes. Further-
    more, we examine the coverage of toxicity na-
    ture in our dataset by comparing it with other
     toxicity datasets.1

1  Introduction

As the popularity of multi-player online games has
grown, the phenomenon of in-game toxic behav-
ior has taken root within them. Toxic behavior
is strongly present in recent online games and is
problematic to the gaming industry (Adinolf and
Turkay, 2018). For instance, 74% of US players of
such games report harassment with 65% experienc-
ing severe harassment. (ADL, 2019).
   In the past few years, Natural Language Process-
ing (NLP) researchers have proposed several on-
line game/community toxicity analysis frameworks

    ∗Corresponding author (caren.han@sydney.edu.au)
   1The  dataset and  lexicons  are  available  at  https://
github.com/usydnlp.Figure 1: An example intent/slot annotation from the
CONDA (CONtextual Dual-Annotated) dataset.



(Kwak et al., 2015; Murnion et al., 2018; Wang
et al., 2020) and datasets (M¨artens et al., 2015;
Stoop et al., 2019). However, existing datasets
(1) focus only on the single utterance level with-
out deeper understanding of context in the whole
conversation/chat, and (2) do not explicitly use se-
mantic clues from the words within the utterance.
  The chat in online games and communities is
similar in nature to spoken language, an area stud-
ied by Natural Language Understanding (NLU).
NLU research aims to best represent human com-
munication by extracting semantic structure in the
form of intent and slot analysis. Intent detection is
the classiﬁcation of the desired outcome of an utter-
ance (or sentence), and slot ﬁlling is the labeling of
each token (or word) in the utterance with the type
of semantic information it carries. In recent litera-
ture, these two tasks are trained jointly to capture
synergies between them, and these jointly trained
models give better results (Zhang et al., 2019b).
Furthermore, researchers have made available joint
task datasets that contain the context of a multi-turn
conversation (Budzianowski et al., 2018; Schuster
et al., 2019)
  Inspired by this NLU research progress, we2406",,,,, ,  Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,,detection,
3564,"**Title**From Toxicity in Online Comments to Incivility in {A}merican News: Proceed with Caution

**Abstract**The ability to quantify incivility online, in news and in congressional debates is of great interest to political scientists. Computational tools for detecting online incivility for English are now fairly accessible and potentially could be applied more broadly. We test the Jigsaw Perspective API for its ability to detect the degree of incivility on a corpus that we developed, consisting of manual annotations of civility in American news. We demonstrate that toxicity models, as exemplified by Perspective, are inadequate for the analysis of incivility in news. We carry out error analysis that points to the need to develop methods to remove spurious correlations between words often mentioned in the news, especially identity descriptors and incivility. Without such improvements, applying Perspective or similar models on news is likely to lead to wrong conclusions, that are not aligned with the human perception of incivility.","Hede, Anushree, Agarwal, Oshin, Lu, Linda, Mutz, Diana C., Nenkova, Ani",,,From Toxicity in Online Comments to Incivility in {A}merican News: Proceed with Caution,,,10.18653/v1/2021.eacl-main.225 , ,,"The ability to quantify incivility online, in news and in congressional debates is of great interest to political scientists. Computational tools for detecting online incivility for English are now fairly accessible and potentially could be applied more broadly. We test the Jigsaw Perspective API for its ability to detect the degree of incivility on a corpus that we developed, consisting of manual annotations of civility in American news. We demonstrate that toxicity models, as exemplified by Perspective, are inadequate for the analysis of incivility in news. We carry out error analysis that points to the need to develop methods to remove spurious correlations between words often mentioned in the news, especially identity descriptors and incivility. Without such improvements, applying Perspective or similar models on news is likely to lead to wrong conclusions, that are not aligned with the human perception of incivility.",,,,, ,  Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,,detection,
3565,"**Title**Towards Non-Toxic Landscapes: Automatic Toxic Comment Detection Using {DNN}

**Abstract**The spectacular expansion of the Internet has led to the development of a new research problem in the field of natural language processing: automatic toxic comment detection, since many countries prohibit hate speech in public media. There is no clear and formal definition of hate, offensive, toxic and abusive speeches. In this article, we put all these terms under the umbrella of {\textquotedblleft}toxic speech{\textquotedblright}. The contribution of this paper is the design of binary classification and regression-based approaches aiming to predict whether a comment is toxic or not. We compare different unsupervised word representations and different DNN based classifiers. Moreover, we study the robustness of the proposed approaches to adversarial attacks by adding one (healthy or toxic) word. We evaluate the proposed methodology on the English Wikipedia Detox corpus. Our experiments show that using BERT fine-tuning outperforms feature-based BERT, Mikolov`s and fastText representations with different DNN classifiers.","D{'}Sa, Ashwin Geet, Illina, Irina, Fohr, Dominique",,,Towards Non-Toxic Landscapes: Automatic Toxic Comment Detection Using {DNN},,, , ,,"The spectacular expansion of the Internet has led to the development of a new research problem in the field of natural language processing: automatic toxic comment detection, since many countries prohibit hate speech in public media. There is no clear and formal definition of hate, offensive, toxic and abusive speeches. In this article, we put all these terms under the umbrella of {\textquotedblleft}toxic speech{\textquotedblright}. The contribution of this paper is the design of binary classification and regression-based approaches aiming to predict whether a comment is toxic or not. We compare different unsupervised word representations and different DNN based classifiers. Moreover, we study the robustness of the proposed approaches to adversarial attacks by adding one (healthy or toxic) word. We evaluate the proposed methodology on the English Wikipedia Detox corpus. Our experiments show that using BERT fine-tuning outperforms feature-based BERT, Mikolov`s and fastText representations with different DNN classifiers.",,,,, ,"  Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying",,detection,
3566,"**Title**{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection

**Abstract**Toxic comments in online platforms are an unavoidable social issue under the cloak of anonymity. Hate speech detection has been actively done for languages such as English, German, or Italian, where manually labeled corpus has been released. In this work, we first present 9.4K manually labeled entertainment news comments for identifying Korean toxic speech, collected from a widely used online news platform in Korea. The comments are annotated regarding social bias and hate speech since both aspects are correlated. The inter-annotator agreement Krippendorff`s alpha score is 0.492 and 0.496, respectively. We provide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the highest score on all tasks. The models generally display better performance on bias identification, since the hate speech detection is a more subjective issue. Additionally, when BERT is trained with bias label for hate speech detection, the prediction score increases, implying that bias and hate are intertwined. We make our dataset publicly available and open competitions with the corpus and benchmarks.","Moon, Jihyung, Cho, Won Ik, Lee, Junbum",,,{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection,,,10.18653/v1/2020.socialnlp-1.4 , ,,"Toxic comments in online platforms are an unavoidable social issue under the cloak of anonymity. Hate speech detection has been actively done for languages such as English, German, or Italian, where manually labeled corpus has been released. In this work, we first present 9.4K manually labeled entertainment news comments for identifying Korean toxic speech, collected from a widely used online news platform in Korea. The comments are annotated regarding social bias and hate speech since both aspects are correlated. The inter-annotator agreement Krippendorff`s alpha score is 0.492 and 0.496, respectively. We provide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the highest score on all tasks. The models generally display better performance on bias identification, since the hate speech detection is a more subjective issue. Additionally, when BERT is trained with bias label for hate speech detection, the prediction score increases, implying that bias and hate are intertwined. We make our dataset publicly available and open competitions with the corpus and benchmarks.",,,,, ,  Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media,,out_but_toxicity,
3567,"**Title**Hate and Toxic Speech Detection in the Context of Covid-19 Pandemic using {XAI}: Ongoing Applied Research

**Abstract**As social distancing, self-quarantines, and travel restrictions have shifted a lot of pandemic conversations to social media so does the spread of hate speech. While recent machine learning solutions for automated hate and offensive speech identification are available on Twitter, there are issues with their interpretability. We propose a novel use of learned feature importance which improves upon the performance of prior state-of-the-art text classification techniques, while producing more easily interpretable decisions. We also discuss both technical and practical challenges that remain for this task.","Hardage, David, Najafirad, Peyman",,,Hate and Toxic Speech Detection in the Context of Covid-19 Pandemic using {XAI}: Ongoing Applied Research,,,10.18653/v1/2020.nlpcovid19-2.36 , ,,"As social distancing, self-quarantines, and travel restrictions have shifted a lot of pandemic conversations to social media so does the spread of hate speech. While recent machine learning solutions for automated hate and offensive speech identification are available on Twitter, there are issues with their interpretability. We propose a novel use of learned feature importance which improves upon the performance of prior state-of-the-art text classification techniques, while producing more easily interpretable decisions. We also discuss both technical and practical challenges that remain for this task.",,,,, ,  Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,,detection,
3568,"**Title**Toxic Language Detection in Social Media for {B}razilian {P}ortuguese: New Dataset and Multilingual Analysis

**Abstract**Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76{\%} macro-F1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.","Leite, Jo{\~a}o Augusto, Silva, Diego, Bontcheva, Kalina, Scarton, Carolina",,,Toxic Language Detection in Social Media for {B}razilian {P}ortuguese: New Dataset and Multilingual Analysis,,,10.18653/v1/2020.aacl-main.91 , ,,"Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76{\%} macro-F1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.",,,,, ,  Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,,out_but_toxicity,
3569,"**Title**Preemptive Toxic Language Detection in {W}ikipedia Comments Using Thread-Level Context

**Abstract**We address the task of automatically detecting toxic content in user generated texts. We fo cus on exploring the potential for preemptive moderation, i.e., predicting whether a particular conversation thread will, in the future, incite a toxic comment. Moreover, we perform preliminary investigation of whether a model that jointly considers all comments in a conversation thread outperforms a model that considers only individual comments. Using an existing dataset of conversations among Wikipedia contributors as a starting point, we compile a new large-scale dataset for this task consisting of labeled comments and comments from their conversation threads.","Karan, Vanja Mladen, {\v{S}}najder, Jan",,,Preemptive Toxic Language Detection in {W}ikipedia Comments Using Thread-Level Context,,,10.18653/v1/W19-3514 , ,,"We address the task of automatically detecting toxic content in user generated texts. We fo cus on exploring the potential for preemptive moderation, i.e., predicting whether a particular conversation thread will, in the future, incite a toxic comment. Moreover, we perform preliminary investigation of whether a model that jointly considers all comments in a conversation thread outperforms a model that considers only individual comments. Using an existing dataset of conversations among Wikipedia contributors as a starting point, we compile a new large-scale dataset for this task consisting of labeled comments and comments from their conversation threads.",,,,, ,  Proceedings of the Third Workshop on Abusive Language Online,,detection,
3570,"**Title**Detecting Toxicity in News Articles: Application to {B}ulgarian

**Abstract**Online media aim for reaching ever bigger audience and for attracting ever longer attention span. This competition creates an environment that rewards sensational, fake, and toxic news. To help limit their spread and impact, we propose and develop a news toxicity detector that can recognize various types of toxic content. While previous research primarily focused on English, here we target Bulgarian. We created a new dataset by crawling a website that for five years has been collecting Bulgarian news articles that were manually categorized into eight toxicity groups. Then we trained a multi-class classifier with nine categories: eight toxic and one non-toxic. We experimented with different representations based on ElMo, BERT, and XLM, as well as with a variety of domain-specific features. Due to the small size of our dataset, we created a separate model for each feature type, and we ultimately combined these models into a meta-classifier. The evaluation results show an accuracy of 59.0{\%} and a macro-F1 score of 39.7{\%}, which represent sizable improvements over the majority-class baseline (Acc=30.3{\%}, macro-F1=5.2{\%}).","Dinkov, Yoan, Koychev, Ivan, Nakov, Preslav",,,Detecting Toxicity in News Articles: Application to {B}ulgarian,,,10.26615/978-954-452-056-4_029 , ,,"Online media aim for reaching ever bigger audience and for attracting ever longer attention span. This competition creates an environment that rewards sensational, fake, and toxic news. To help limit their spread and impact, we propose and develop a news toxicity detector that can recognize various types of toxic content. While previous research primarily focused on English, here we target Bulgarian. We created a new dataset by crawling a website that for five years has been collecting Bulgarian news articles that were manually categorized into eight toxicity groups. Then we trained a multi-class classifier with nine categories: eight toxic and one non-toxic. We experimented with different representations based on ElMo, BERT, and XLM, as well as with a variety of domain-specific features. Due to the small size of our dataset, we created a separate model for each feature type, and we ultimately combined these models into a meta-classifier. The evaluation results show an accuracy of 59.0{\%} and a macro-F1 score of 39.7{\%}, which represent sizable improvements over the majority-class baseline (Acc=30.3{\%}, macro-F1=5.2{\%}).",,,,, ,  Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),,out_but_toxicity,
3571,"**Title**Unsupervised Identification of Study Descriptors in Toxicology Research: An Experimental Study

**Abstract**Identifying and extracting data elements such as study descriptors in publication full texts is a critical yet manual and labor-intensive step required in a number of tasks. In this paper we address the question of identifying data elements in an unsupervised manner. Specifically, provided a set of criteria describing specific study parameters, such as species, route of administration, and dosing regimen, we develop an unsupervised approach to identify text segments (sentences) relevant to the criteria. A binary classifier trained to identify publications that met the criteria performs better when trained on the candidate sentences than when trained on sentences randomly picked from the text, supporting the intuition that our method is able to accurately identify study descriptors.","Herrmannova, Drahomira, Young, Steven, Patton, Robert, Stahl, Christopher, Kleinstreuer, Nicole, Wolfe, Mary",,,Unsupervised Identification of Study Descriptors in Toxicology Research: An Experimental Study,,,10.18653/v1/W18-5609 , ,,"Identifying and extracting data elements such as study descriptors in publication full texts is a critical yet manual and labor-intensive step required in a number of tasks. In this paper we address the question of identifying data elements in an unsupervised manner. Specifically, provided a set of criteria describing specific study parameters, such as species, route of administration, and dosing regimen, we develop an unsupervised approach to identify text segments (sentences) relevant to the criteria. A binary classifier trained to identify publications that met the criteria performs better when trained on the candidate sentences than when trained on sentences randomly picked from the text, supporting the intuition that our method is able to accurately identify study descriptors.",,,,, ,  Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,,out_of_scope,
3572,"**Title**A Review of Standard Text Classification Practices for Multi-label Toxicity Identification of Online Content

**Abstract**Language toxicity identification presents a gray area in the ethical debate surrounding freedom of speech and censorship. Today`s social media landscape is littered with unfiltered content that can be anywhere from slightly abusive to hate inducing. In response, we focused on training a multi-label classifier to detect both the type and level of toxicity in online content. This content is typically colloquial and conversational in style. Its classification therefore requires huge amounts of annotated data due to its variability and inconsistency. We compare standard methods of text classification in this task. A conventional one-vs-rest SVM classifier with character and word level frequency-based representation of text reaches 0.9763 ROC AUC score. We demonstrated that leveraging more advanced technologies such as word embeddings, recurrent neural networks, attention mechanism, stacking of classifiers and semi-supervised training can improve the ROC AUC score of classification to 0.9862. We suggest that in order to choose the right model one has to consider the accuracy of models as well as inference complexity based on the application.","Gunasekara, Isuru, Nejadgholi, Isar",,,A Review of Standard Text Classification Practices for Multi-label Toxicity Identification of Online Content,,,10.18653/v1/W18-5103 , ,,"Language toxicity identification presents a gray area in the ethical debate surrounding freedom of speech and censorship. Today`s social media landscape is littered with unfiltered content that can be anywhere from slightly abusive to hate inducing. In response, we focused on training a multi-label classifier to detect both the type and level of toxicity in online content. This content is typically colloquial and conversational in style. Its classification therefore requires huge amounts of annotated data due to its variability and inconsistency. We compare standard methods of text classification in this task. A conventional one-vs-rest SVM classifier with character and word level frequency-based representation of text reaches 0.9763 ROC AUC score. We demonstrated that leveraging more advanced technologies such as word embeddings, recurrent neural networks, attention mechanism, stacking of classifiers and semi-supervised training can improve the ROC AUC score of classification to 0.9862. We suggest that in order to choose the right model one has to consider the accuracy of models as well as inference complexity based on the application.",,,,, ,  Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2),,detection,
3573,"**Title**Challenges for Toxic Comment Classification: An In-Depth Error Analysis

**Abstract**Toxic comment classification has become an active research field with many recently proposed approaches. However, while these approaches address some of the task`s challenges others still remain unsolved and directions for further research are needed. To this end, we compare different deep learning and shallow approaches on a new, large comment dataset and propose an ensemble that outperforms all individual models. Further, we validate our findings on a second dataset. The results of the ensemble enable us to perform an extensive error analysis, which reveals open challenges for state-of-the-art methods and directions towards pending future research. These challenges include missing paradigmatic context and inconsistent dataset labels.","van Aken, Betty, Risch, Julian, Krestel, Ralf, L{\""o}ser, Alexander",,,Challenges for Toxic Comment Classification: An In-Depth Error Analysis,,,10.18653/v1/W18-5105 , ,,"Toxic comment classification has become an active research field with many recently proposed approaches. However, while these approaches address some of the task`s challenges others still remain unsolved and directions for further research are needed. To this end, we compare different deep learning and shallow approaches on a new, large comment dataset and propose an ensemble that outperforms all individual models. Further, we validate our findings on a second dataset. The results of the ensemble enable us to perform an extensive error analysis, which reveals open challenges for state-of-the-art methods and directions towards pending future research. These challenges include missing paradigmatic context and inconsistent dataset labels.",,,,, ,  Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2),,detection,
3574,"**Title**Identifying Aggression and Toxicity in Comments using Capsule Network

**Abstract**Aggression and related activities like trolling, hate speech etc. involve toxic comments in various forms. These are common scenarios in today`s time and websites react by shutting down their comment sections. To tackle this, an algorithmic solution is preferred to human moderation which is slow and expensive. In this paper, we propose a single model capsule network with focal loss to achieve this task which is suitable for production environment. Our model achieves competitive results over other strong baseline methods, which show its effectiveness and that focal loss exhibits significant improvement in such cases where class imbalance is a regular issue. Additionally, we show that the problem of extensive data preprocessing, data augmentation can be tackled by capsule networks implicitly. We achieve an overall ROC AUC of 98.46 on Kaggle-toxic comment dataset and show that it beats other architectures by a good margin. As comments tend to be written in more than one language, and transliteration is a common problem, we further show that our model handles this effectively by applying our model on TRAC shared task dataset which contains comments in code-mixed Hindi-English.","Srivastava, Saurabh, Khurana, Prerna, Tewari, Vartika",,,Identifying Aggression and Toxicity in Comments using Capsule Network,,, , ,,"Aggression and related activities like trolling, hate speech etc. involve toxic comments in various forms. These are common scenarios in today`s time and websites react by shutting down their comment sections. To tackle this, an algorithmic solution is preferred to human moderation which is slow and expensive. In this paper, we propose a single model capsule network with focal loss to achieve this task which is suitable for production environment. Our model achieves competitive results over other strong baseline methods, which show its effectiveness and that focal loss exhibits significant improvement in such cases where class imbalance is a regular issue. Additionally, we show that the problem of extensive data preprocessing, data augmentation can be tackled by capsule networks implicitly. We achieve an overall ROC AUC of 98.46 on Kaggle-toxic comment dataset and show that it beats other architectures by a good margin. As comments tend to be written in more than one language, and transliteration is a common problem, we further show that our model handles this effectively by applying our model on TRAC shared task dataset which contains comments in code-mixed Hindi-English.",,,,, ,"  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying ({TRAC}-2018)",,detection,
3575,"**Title**Positive Text Reframing under Multi-strategy Optimization

**Abstract**Differing from sentiment transfer, positive reframing seeks to substitute negative perspectives with positive expressions while preserving the original meaning. With the emergence of pre-trained language models (PLMs), it is possible to achieve acceptable results by fine-tuning PLMs. Nevertheless, generating fluent, diverse and task-constrained reframing text remains a significant challenge. To tackle this issue, a **m**ulti-**s**trategy **o**ptimization **f**ramework (MSOF) is proposed in this paper. Starting from the objective of positive reframing, we first design positive sentiment reward and content preservation reward to encourage the model to transform the negative expressions of the original text while ensuring the integrity and consistency of the semantics. Then, different decoding optimization approaches are introduced to improve the quality of text generation. Finally, based on the modeling formula of positive reframing, we propose a multi-dimensional re-ranking method that further selects candidate sentences from three dimensions: strategy consistency, text similarity and fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate our framework achieves significant improvements on unconstrained and controlled positive reframing tasks.","Jia, Shutong, Cao, Biwei, Gao, Qingqing, Cao, Jiuxin, Liu, Bo",,,Positive Text Reframing under Multi-strategy Optimization,,, , ,,"Differing from sentiment transfer, positive reframing seeks to substitute negative perspectives with positive expressions while preserving the original meaning. With the emergence of pre-trained language models (PLMs), it is possible to achieve acceptable results by fine-tuning PLMs. Nevertheless, generating fluent, diverse and task-constrained reframing text remains a significant challenge. To tackle this issue, a **m**ulti-**s**trategy **o**ptimization **f**ramework (MSOF) is proposed in this paper. Starting from the objective of positive reframing, we first design positive sentiment reward and content preservation reward to encourage the model to transform the negative expressions of the original text while ensuring the integrity and consistency of the semantics. Then, different decoding optimization approaches are introduced to improve the quality of text generation. Finally, based on the modeling formula of positive reframing, we propose a multi-dimensional re-ranking method that further selects candidate sentences from three dimensions: strategy consistency, text similarity and fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate our framework achieves significant improvements on unconstrained and controlled positive reframing tasks.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics,,out_of_scope,
3576,"**Title**Continual Reinforcement Learning for Controlled Text Generation

**Abstract**Controlled Text Generation (CTG) steers the generation of continuations of a given context (prompt) by a Large Language Model (LLM) towards texts possessing a given attribute (e.g., topic, sentiment). In this paper we view CTG as a Continual Learning problem: how to learn at every step to steer next-word generation, without having to wait for end-of-sentence. This continual view is useful for online applications such as CTG for speech, where end-of-sentence is often uncertain. We depart from an existing model, the Plug-and-Play language models (PPLM), which perturbs the context at each step to better predict next-words that posses the desired attribute. While PPLM is intricate and has many hyper-parameters, we provide a proof that the PPLM objective function can be reduced to a Continual Reinforcement Learning (CRL) reward function, thereby simplifying PPLM and endowing it with a better understood learning framework. Subsequently, we present, the first of its kind, CTG algorithm that is fully based on CRL and exhibit promising empirical results.","Shulev, Velizar, Sima{'}an, Khalil",,,Continual Reinforcement Learning for Controlled Text Generation,,, , ,,"Controlled Text Generation (CTG) steers the generation of continuations of a given context (prompt) by a Large Language Model (LLM) towards texts possessing a given attribute (e.g., topic, sentiment). In this paper we view CTG as a Continual Learning problem: how to learn at every step to steer next-word generation, without having to wait for end-of-sentence. This continual view is useful for online applications such as CTG for speech, where end-of-sentence is often uncertain. We depart from an existing model, the Plug-and-Play language models (PPLM), which perturbs the context at each step to better predict next-words that posses the desired attribute. While PPLM is intricate and has many hyper-parameters, we provide a proof that the PPLM objective function can be reduced to a Continual Reinforcement Learning (CRL) reward function, thereby simplifying PPLM and endowing it with a better understood learning framework. Subsequently, we present, the first of its kind, CTG algorithm that is fully based on CRL and exhibit promising empirical results.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,detox,
3577,"**Title**Using Structured Health Information for Controlled Generation of Clinical Cases in {F}rench

**Abstract**Text generation opens up new prospects for overcoming the lack of open corpora in fields such as healthcare, where data sharing is bound by confidentiality. In this study, we compare the performance of encoder-decoder and decoder-only language models for the controlled generation of clinical cases in French. To do so, we fine-tuned several pre-trained models on French clinical cases for each architecture and generate clinical cases conditioned by patient demographic information (gender and age) and clinical features.Our results suggest that encoder-decoder models are easier to control than decoder-only models, but more costly to train.","Boulanger, Hugo, Hiebel, Nicolas, Ferret, Olivier, Fort, Kar{\""e}n, N{\'e}v{\'e}ol, Aur{\'e}lie",,,Using Structured Health Information for Controlled Generation of Clinical Cases in {F}rench,,,10.18653/v1/2024.clinicalnlp-1.14 , ,,"Text generation opens up new prospects for overcoming the lack of open corpora in fields such as healthcare, where data sharing is bound by confidentiality. In this study, we compare the performance of encoder-decoder and decoder-only language models for the controlled generation of clinical cases in French. To do so, we fine-tuned several pre-trained models on French clinical cases for each architecture and generate clinical cases conditioned by patient demographic information (gender and age) and clinical features.Our results suggest that encoder-decoder models are easier to control than decoder-only models, but more costly to train.",,,,, ,  Proceedings of the 6th Clinical Natural Language Processing Workshop,,out_of_scope,
3578,"**Title**In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis

**Abstract**Large Language Models (LLMs) have shown significant performance in numerous NLP tasks, including summarization and controlled text generation. A notable capability of LLMs is in-context learning (ICL), where the model learns new tasks using input-output pairs in the prompt without any parameter update. However, the performance of LLMs in the context of few-shot abstractive dialogue summarization remains underexplored. This study evaluates various state-of-the-art LLMs on the SAMSum dataset within a few-shot framework. We assess these models in both controlled (entity control, length control, and person-focused planning) and uncontrolled settings, establishing a comprehensive benchmark in few-shot dialogue summarization. Our findings provide insights into summary quality and model controllability, offering a crucial reference for future research in dialogue summarization.","Tang, Yuting, Puduppully, Ratish, Liu, Zhengyuan, Chen, Nancy",,,In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis,,,10.18653/v1/2023.newsum-1.6 , ,,"Large Language Models (LLMs) have shown significant performance in numerous NLP tasks, including summarization and controlled text generation. A notable capability of LLMs is in-context learning (ICL), where the model learns new tasks using input-output pairs in the prompt without any parameter update. However, the performance of LLMs in the context of few-shot abstractive dialogue summarization remains underexplored. This study evaluates various state-of-the-art LLMs on the SAMSum dataset within a few-shot framework. We assess these models in both controlled (entity control, length control, and person-focused planning) and uncontrolled settings, establishing a comprehensive benchmark in few-shot dialogue summarization. Our findings provide insights into summary quality and model controllability, offering a crucial reference for future research in dialogue summarization.",,,,, ,  Proceedings of the 4th New Frontiers in Summarization Workshop,,out_of_scope,
3579,"**Title**Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models

**Abstract**Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.","Sieker, Judith, Bott, Oliver, Solstad, Torgrim, Zarrie{\ss}, Sina",,,Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models,,,10.18653/v1/2023.inlg-main.15 , ,,"Recent studies have used human continuations of Implicit Causality (IC) prompts collected in linguistic experiments to evaluate discourse understanding in large language models (LLMs), focusing on the well-known IC coreference bias in the LLMs' predictions of the next word following the prompt. In this study, we investigate how continuations of IC prompts can be used to evaluate the text generation capabilities of LLMs in a linguistically controlled setting. We conduct an experiment using two open-source GPT-based models, employing human evaluation to assess different aspects of continuation quality. Our findings show that LLMs struggle in particular with generating coherent continuations in this rather simple setting, indicating a lack of discourse knowledge beyond the well-known IC bias. Our results also suggest that a bias congruent continuation does not necessarily equate to a higher continuation quality. Furthermore, our study draws upon insights from the Uniform Information Density hypothesis, testing different prompt modifications and decoding procedures and showing that sampling-based methods are particularly sensitive to the information density of the prompts.",,,,, ,  Proceedings of the 16th International Natural Language Generation Conference,,out_of_scope,
3580,"**Title**Fiction-Writing Mode: An Effective Control for Human-Machine Collaborative Writing

**Abstract**We explore the idea of incorporating concepts from writing skills curricula into human-machine collaborative writing scenarios, focusing on adding writing modes as a control for text generation models. Using crowd-sourced workers, we annotate a corpus of narrative text paragraphs with writing mode labels. Classifiers trained on this data achieve an average accuracy of {\textasciitilde}87{\%} on held-out data. We fine-tune a set of large language models to condition on writing mode labels, and show that the generated text is recognized as belonging to the specified mode with high accuracy. To study the ability of writing modes to provide fine-grained control over generated text, we devise a novel turn-based text reconstruction game to evaluate the difference between the generated text and the author`s intention. We show that authors prefer text suggestions made by writing mode-controlled models on average 61.1{\%} of the time, with satisfaction scores 0.5 higher on a 5-point ordinal scale. When evaluated by humans, stories generated via collaboration with writing mode-controlled models achieve high similarity with the professionally written target story. We conclude by identifying the most common mistakes found in the generated stories.","Zhong, Wenjie, Naradowsky, Jason, Takamura, Hiroya, Kobayashi, Ichiro, Miyao, Yusuke",,,Fiction-Writing Mode: An Effective Control for Human-Machine Collaborative Writing,,,10.18653/v1/2023.eacl-main.128 , ,,"We explore the idea of incorporating concepts from writing skills curricula into human-machine collaborative writing scenarios, focusing on adding writing modes as a control for text generation models. Using crowd-sourced workers, we annotate a corpus of narrative text paragraphs with writing mode labels. Classifiers trained on this data achieve an average accuracy of {\textasciitilde}87{\%} on held-out data. We fine-tune a set of large language models to condition on writing mode labels, and show that the generated text is recognized as belonging to the specified mode with high accuracy. To study the ability of writing modes to provide fine-grained control over generated text, we devise a novel turn-based text reconstruction game to evaluate the difference between the generated text and the author`s intention. We show that authors prefer text suggestions made by writing mode-controlled models on average 61.1{\%} of the time, with satisfaction scores 0.5 higher on a 5-point ordinal scale. When evaluated by humans, stories generated via collaboration with writing mode-controlled models achieve high similarity with the professionally written target story. We conclude by identifying the most common mistakes found in the generated stories.",,,,, ,  Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics,,out_of_scope,
3581,"**Title**{BOLT}: Fast Energy-based Controlled Text Generation with Tunable Biases

**Abstract**Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose BOLT, which relies on tunable biases to directly adjust the language model`s output logits. Unlike prior work, BOLT maintains the generator`s autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), BOLT demonstrates significantly improved efficiency and fluency. On sentiment control, BOLT is 7x faster than competitive baselines, and more fluent in 74.4{\%} of the evaluation samples according to human judges.","Liu, Xin, Khalifa, Muhammad, Wang, Lu",,,{BOLT}: Fast Energy-based Controlled Text Generation with Tunable Biases,,,10.18653/v1/2023.acl-short.18 , ,,"Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose BOLT, which relies on tunable biases to directly adjust the language model`s output logits. Unlike prior work, BOLT maintains the generator`s autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), BOLT demonstrates significantly improved efficiency and fluency. On sentiment control, BOLT is 7x faster than competitive baselines, and more fluent in 74.4{\%} of the evaluation samples according to human judges.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),,out_of_scope,
3582,"**Title**{SSD}-{LM}: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control

**Abstract**Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models. In this work, we present SSD-LM{---}a diffusion-based language model with two key design choices. First, SSD-LM is semi-autoregressive, iteratively generating blocks of text, allowing for flexible output length at decoding time while enabling local bidirectional context updates. Second, it is simplex-based, performing diffusion on the natural vocabulary space rather than a learned latent space, allowing us to incorporate classifier guidance and modular control using off-the-shelf classifiers without any adaptation. We evaluate SSD-LM on unconstrained text generation benchmarks, and show that it matches or outperforms strong autoregressive GPT-2 models across standard quality and diversity metrics, while vastly outperforming diffusion-based baselines. On controlled text generation, SSD-LM also outperforms competitive baselines, with an extra advantage in modularity.","Han, Xiaochuang, Kumar, Sachin, Tsvetkov, Yulia",,,{SSD}-{LM}: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,,,10.18653/v1/2023.acl-long.647 , ,,"Despite the growing success of diffusion models in continuous-valued domains (e.g., images), similar efforts for discrete domains such as text have yet to match the performance of autoregressive language models. In this work, we present SSD-LM{---}a diffusion-based language model with two key design choices. First, SSD-LM is semi-autoregressive, iteratively generating blocks of text, allowing for flexible output length at decoding time while enabling local bidirectional context updates. Second, it is simplex-based, performing diffusion on the natural vocabulary space rather than a learned latent space, allowing us to incorporate classifier guidance and modular control using off-the-shelf classifiers without any adaptation. We evaluate SSD-LM on unconstrained text generation benchmarks, and show that it matches or outperforms strong autoregressive GPT-2 models across standard quality and diversity metrics, while vastly outperforming diffusion-based baselines. On controlled text generation, SSD-LM also outperforms competitive baselines, with an extra advantage in modularity.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3583,"**Title**Plug-and-Play Recipe Generation with Content Planning

**Abstract**Recent pre-trained language models have shown promising capability to generate fluent and realistic natural text. However, generating multi-sentence text with global content planning has been a long-existing research question. The current controlled text generation models cannot directly address this issue, as they usually condition on single known control attribute. We propose a low-cost yet effective framework that explicitly models content plans and optimizes the joint distribution of the natural sequence and the content plans in a plug-and-play post-processing manner. We evaluate our model with extensive automatic metrics and human evaluations and show that it achieves the state-of-the-art performance on the recipe generation task on Recipe1M+ dataset.","Liu, Yinhong, Su, Yixuan, Shareghi, Ehsan, Collier, Nigel",,,Plug-and-Play Recipe Generation with Content Planning,,,10.18653/v1/2022.gem-1.19 , ,,"Recent pre-trained language models have shown promising capability to generate fluent and realistic natural text. However, generating multi-sentence text with global content planning has been a long-existing research question. The current controlled text generation models cannot directly address this issue, as they usually condition on single known control attribute. We propose a low-cost yet effective framework that explicitly models content plans and optimizes the joint distribution of the natural sequence and the content plans in a plug-and-play post-processing manner. We evaluate our model with extensive automatic metrics and human evaluations and show that it achieves the state-of-the-art performance on the recipe generation task on Recipe1M+ dataset.",,,,, ,"  Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",,detox,
3584,"**Title**Control Prefixes for Parameter-Efficient Text Generation

**Abstract**Prefix-tuning is a parameter-efficient and powerful technique for adapting a pre-trained language model to a downstream application. However, it uses the same dataset-level tuned set of parameters for all examples in the dataset. We extend the framework with a dynamic method, Control Prefixes, which allows for the effective inclusion of input-dependent information, thereby demonstrating how prefix-tuning can be used for controlled text generation tasks. The method incorporates attribute-level learnable representations into different layers of a pre-trained Transformer, enabling the generated text to be guided in a particular direction. We provide a systematic evaluation of the technique and apply it to five datasets from the GEM benchmark for natural language generation (NLG). Using only 0.1{--}2{\%} additional trainable parameters, we show Control Prefixes can even outperform full fine-tuning methods, and present state-of-the-art results on several data-to-text datasets, including WebNLG. We also examine the common case where input-dependent information is unavailable at test time and show Control Prefixes can excel in this setting also.","Clive, Jordan, Cao, Kris, Rei, Marek",,,Control Prefixes for Parameter-Efficient Text Generation,,,10.18653/v1/2022.gem-1.31 , ,,"Prefix-tuning is a parameter-efficient and powerful technique for adapting a pre-trained language model to a downstream application. However, it uses the same dataset-level tuned set of parameters for all examples in the dataset. We extend the framework with a dynamic method, Control Prefixes, which allows for the effective inclusion of input-dependent information, thereby demonstrating how prefix-tuning can be used for controlled text generation tasks. The method incorporates attribute-level learnable representations into different layers of a pre-trained Transformer, enabling the generated text to be guided in a particular direction. We provide a systematic evaluation of the technique and apply it to five datasets from the GEM benchmark for natural language generation (NLG). Using only 0.1{--}2{\%} additional trainable parameters, we show Control Prefixes can even outperform full fine-tuning methods, and present state-of-the-art results on several data-to-text datasets, including WebNLG. We also examine the common case where input-dependent information is unavailable at test time and show Control Prefixes can excel in this setting also.",,,,, ,"  Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",,detox,
3585,"**Title**Controlled Text Generation Using Dictionary Prior in Variational Autoencoders

**Abstract**While variational autoencoders (VAEs) have been widely applied in text generation tasks, they are troubled by two challenges: insufficient representation capacity and poor controllability. The former results from the posterior collapse and restrictive assumption, which impede better representation learning. The latter arises as continuous latent variables in traditional formulations hinder VAEs from interpretability and controllability. In this paper, we propose Dictionary Prior (DPrior), a new data-driven prior that enjoys the merits of expressivity and controllability. To facilitate controlled text generation with DPrior, we propose to employ contrastive learning to separate the latent space into several parts. Extensive experiments on both language modeling and controlled text generation demonstrate the effectiveness of the proposed approach.","Fang, Xianghong, Li, Jian, Shang, Lifeng, Jiang, Xin, Liu, Qun, Yeung, Dit-Yan",,,Controlled Text Generation Using Dictionary Prior in Variational Autoencoders,,,10.18653/v1/2022.findings-acl.10 , ,,"While variational autoencoders (VAEs) have been widely applied in text generation tasks, they are troubled by two challenges: insufficient representation capacity and poor controllability. The former results from the posterior collapse and restrictive assumption, which impede better representation learning. The latter arises as continuous latent variables in traditional formulations hinder VAEs from interpretability and controllability. In this paper, we propose Dictionary Prior (DPrior), a new data-driven prior that enjoys the merits of expressivity and controllability. To facilitate controlled text generation with DPrior, we propose to employ contrastive learning to separate the latent space into several parts. Extensive experiments on both language modeling and controlled text generation demonstrate the effectiveness of the proposed approach.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2022,,out_of_scope,
3586,"**Title**{C}a{M}-{G}en: {C}ausally Aware Metric-Guided Text Generation

**Abstract**Content is created for a well-defined purpose, often described by a metric or signal represented in the form of structured information. The relationship between the goal (metrics) of target content and the content itself is non-trivial. While large-scale language models show promising text generation capabilities, guiding the generated text with external metrics is challenging. These metrics and content tend to have inherent relationships and not all of them may be of consequence. We introduce CaM-Gen: Causally aware Generative Networks guided by user-defined target metrics incorporating the causal relationships between the metric and content features. We leverage causal inference techniques to identify causally significant aspects of a text that lead to the target metric and then explicitly guide generative models towards these by a feedback mechanism. We propose this mechanism for variational autoencoder and Transformer-based generative models. The proposed models beat baselines in terms of the target metric control while maintaining fluency and language quality of the generated text. To the best of our knowledge, this is one of the early attempts at controlled generation incorporating a metric guide using causal inference.","Goyal, Navita, Paneri, Roodram, Agarwal, Ayush, Kalani, Udit, Sancheti, Abhilasha, Chhaya, Niyati",,,{C}a{M}-{G}en: {C}ausally Aware Metric-Guided Text Generation,,,10.18653/v1/2022.findings-acl.162 , ,,"Content is created for a well-defined purpose, often described by a metric or signal represented in the form of structured information. The relationship between the goal (metrics) of target content and the content itself is non-trivial. While large-scale language models show promising text generation capabilities, guiding the generated text with external metrics is challenging. These metrics and content tend to have inherent relationships and not all of them may be of consequence. We introduce CaM-Gen: Causally aware Generative Networks guided by user-defined target metrics incorporating the causal relationships between the metric and content features. We leverage causal inference techniques to identify causally significant aspects of a text that lead to the target metric and then explicitly guide generative models towards these by a feedback mechanism. We propose this mechanism for variational autoencoder and Transformer-based generative models. The proposed models beat baselines in terms of the target metric control while maintaining fluency and language quality of the generated text. To the best of our knowledge, this is one of the early attempts at controlled generation incorporating a metric guide using causal inference.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2022,,detox,
3587,"**Title**{PLOG}: Table-to-Logic Pretraining for Logical Table-to-Text Generation

**Abstract**Logical table-to-text generation is a task that involves generating logically faithful sentences from tables, which requires models to derive logical-level facts from table records via logical inference. It raises a new challenge on the logical-level content planning of table-to-text models. However, directly learning the logical inference knowledge from table-text pairs is very difficult for neural models because of the ambiguity of natural language and the scarcity of parallel data. Hence even large-scale pre-trained language models present low logical fidelity on logical table-to-text. In this work, we propose a Pretrained Logical Form Generator (PLOG) framework to improve generation fidelity. Specifically, PLOG is first pretrained on a table-to-logical-form generation (table-to-logic) task, then finetuned on downstream table-to-text tasks. The logical forms are formally defined with unambiguous semantics. Hence we can collect a large amount of accurate logical forms from tables without human annotation. In addition, PLOG can learn logical inference from table-logic pairs much more reliably than from table-text pairs. To evaluate our model, we further collect a controlled logical table-to-text dataset CONTLOG based on an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms strong baselines by a large margin on the logical fidelity, demonstrating the effectiveness of table-to-logic pretraining.","Liu, Ao, Dong, Haoyu, Okazaki, Naoaki, Han, Shi, Zhang, Dongmei",,,{PLOG}: Table-to-Logic Pretraining for Logical Table-to-Text Generation,,,10.18653/v1/2022.emnlp-main.373 , ,,"Logical table-to-text generation is a task that involves generating logically faithful sentences from tables, which requires models to derive logical-level facts from table records via logical inference. It raises a new challenge on the logical-level content planning of table-to-text models. However, directly learning the logical inference knowledge from table-text pairs is very difficult for neural models because of the ambiguity of natural language and the scarcity of parallel data. Hence even large-scale pre-trained language models present low logical fidelity on logical table-to-text. In this work, we propose a Pretrained Logical Form Generator (PLOG) framework to improve generation fidelity. Specifically, PLOG is first pretrained on a table-to-logical-form generation (table-to-logic) task, then finetuned on downstream table-to-text tasks. The logical forms are formally defined with unambiguous semantics. Hence we can collect a large amount of accurate logical forms from tables without human annotation. In addition, PLOG can learn logical inference from table-logic pairs much more reliably than from table-text pairs. To evaluate our model, we further collect a controlled logical table-to-text dataset CONTLOG based on an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms strong baselines by a large margin on the logical fidelity, demonstrating the effectiveness of table-to-logic pretraining.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3588,"**Title**Few-shot Table-to-text Generation with Prefix-Controlled Generator

**Abstract**Neural table-to-text generation approaches are data-hungry, limiting their adaption for low-resource real-world applications. Previous works mostly resort to Pre-trained Language Models (PLMs) to generate fluent summaries of a table. However, they often contain hallucinated contents due to the uncontrolled nature of PLMs. Moreover, the topological differences between tables and sequences are rarely studied. Last but not least, fine-tuning on PLMs with a handful of instances may lead to over-fitting and catastrophic forgetting. To alleviate these problems, we propose a prompt-based approach, Prefix-Controlled Generator (i.e., PCG), for few-shot table-to-text generation. We prepend a task-specific prefix for a PLM to make the table structure better fit the pre-trained input. In addition, we generate an input-specific prefix to control the factual contents and word order of the generated text. Both automatic and human evaluations on different domains (humans, books and songs) of the Wikibio dataset prove the effectiveness of our approach.","Luo, Yutao, Lu, Menghua, Liu, Gongshen, Wang, Shilin",,,Few-shot Table-to-text Generation with Prefix-Controlled Generator,,, , ,,"Neural table-to-text generation approaches are data-hungry, limiting their adaption for low-resource real-world applications. Previous works mostly resort to Pre-trained Language Models (PLMs) to generate fluent summaries of a table. However, they often contain hallucinated contents due to the uncontrolled nature of PLMs. Moreover, the topological differences between tables and sequences are rarely studied. Last but not least, fine-tuning on PLMs with a handful of instances may lead to over-fitting and catastrophic forgetting. To alleviate these problems, we propose a prompt-based approach, Prefix-Controlled Generator (i.e., PCG), for few-shot table-to-text generation. We prepend a task-specific prefix for a PLM to make the table structure better fit the pre-trained input. In addition, we generate an input-specific prefix to control the factual contents and word order of the generated text. Both automatic and human evaluations on different domains (humans, books and songs) of the Wikibio dataset prove the effectiveness of our approach.",,,,, ,  Proceedings of the 29th International Conference on Computational Linguistics,,out_of_scope,
3589,"**Title**{CTRLE}val: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation

**Abstract**Existing reference-free metrics have obvious limitations for evaluating controlled text generation models. Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets. In this paper, we propose an unsupervised reference-free metric called CTRLEval, which evaluates controlled text generation from different aspects by formulating each aspect into multiple text infilling tasks. On top of these tasks, the metric assembles the generation probabilities from a pre-trained language model without any model training. Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities.","Ke, Pei, Zhou, Hao, Lin, Yankai, Li, Peng, Zhou, Jie, Zhu, Xiaoyan, Huang, Minlie",,,{CTRLE}val: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation,,,10.18653/v1/2022.acl-long.164 , ,,"Existing reference-free metrics have obvious limitations for evaluating controlled text generation models. Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets. In this paper, we propose an unsupervised reference-free metric called CTRLEval, which evaluates controlled text generation from different aspects by formulating each aspect into multiple text infilling tasks. On top of these tasks, the metric assembles the generation probabilities from a pre-trained language model without any model training. Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities.",,,,, ,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3590,"**Title**Style Control for Schema-Guided Natural Language Generation

**Abstract**Natural Language Generation (NLG) for task-oriented dialogue systems focuses on communicating specific content accurately, fluently, and coherently. While these attributes are crucial for a successful dialogue, it is also desirable to simultaneously accomplish specific stylistic goals, such as response length, point-of-view, descriptiveness, sentiment, formality, and empathy. In this work, we focus on stylistic control and evaluation for schema-guided NLG, with joint goals of achieving both semantic and stylistic control. We experiment in detail with various controlled generation methods for large pretrained language models: specifically, conditional training, guided fine-tuning, and guided decoding. We discuss their advantages and limitations, and evaluate them with a broad range of automatic and human evaluation metrics. Our results show that while high style accuracy and semantic correctness are easier to achieve for more lexically-defined styles with conditional training, stylistic control is also achievable for more semantically complex styles using discriminator-based guided decoding methods. The results also suggest that methods that are more scalable (with less hyper-parameters tuning) and that disentangle context generation and stylistic variations are more effective at achieving semantic correctness and style accuracy.","Tsai, Alicia, Oraby, Shereen, Perera, Vittorio, Kao, Jiun-Yu, Du, Yuheng, Narayan-Chen, Anjali, Chung, Tagyoung, Hakkani-Tur, Dilek",,,Style Control for Schema-Guided Natural Language Generation,,,10.18653/v1/2021.nlp4convai-1.21 , ,,"Natural Language Generation (NLG) for task-oriented dialogue systems focuses on communicating specific content accurately, fluently, and coherently. While these attributes are crucial for a successful dialogue, it is also desirable to simultaneously accomplish specific stylistic goals, such as response length, point-of-view, descriptiveness, sentiment, formality, and empathy. In this work, we focus on stylistic control and evaluation for schema-guided NLG, with joint goals of achieving both semantic and stylistic control. We experiment in detail with various controlled generation methods for large pretrained language models: specifically, conditional training, guided fine-tuning, and guided decoding. We discuss their advantages and limitations, and evaluate them with a broad range of automatic and human evaluation metrics. Our results show that while high style accuracy and semantic correctness are easier to achieve for more lexically-defined styles with conditional training, stylistic control is also achievable for more semantically complex styles using discriminator-based guided decoding methods. The results also suggest that methods that are more scalable (with less hyper-parameters tuning) and that disentangle context generation and stylistic variations are more effective at achieving semantic correctness and style accuracy.",,,,, ,  Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI,,out_of_scope,
3591,"**Title**{F}acts2{S}tory: Controlling Text Generation by Key Facts

**Abstract**Recent advancements in self-attention neural network architectures have raised the bar for open-ended text generation. Yet, while current methods are capable of producing a coherent text which is several hundred words long, attaining control over the content that is being generated{---}as well as evaluating it{---}are still open questions. We propose a controlled generation task which is based on expanding a sequence of facts, expressed in natural language, into a longer narrative. We introduce human-based evaluation metrics for this task, as well as a method for deriving a large training dataset. We evaluate three methods on this task, based on fine-tuning pre-trained models. We show that while auto-regressive, unidirectional Language Models such as GPT2 produce better fluency, they struggle to adhere to the requested facts. We propose a plan-and-cloze model (using fine-tuned XLNet) which produces competitive fluency while adhering to the requested content.","Orbach, Eyal, Goldberg, Yoav",,,{F}acts2{S}tory: Controlling Text Generation by Key Facts,,,10.18653/v1/2020.coling-main.211 , ,,"Recent advancements in self-attention neural network architectures have raised the bar for open-ended text generation. Yet, while current methods are capable of producing a coherent text which is several hundred words long, attaining control over the content that is being generated{---}as well as evaluating it{---}are still open questions. We propose a controlled generation task which is based on expanding a sequence of facts, expressed in natural language, into a longer narrative. We introduce human-based evaluation metrics for this task, as well as a method for deriving a large training dataset. We evaluate three methods on this task, based on fine-tuning pre-trained models. We show that while auto-regressive, unidirectional Language Models such as GPT2 produce better fluency, they struggle to adhere to the requested facts. We propose a plan-and-cloze model (using fine-tuned XLNet) which produces competitive fluency while adhering to the requested content.",,,,, ,  Proceedings of the 28th International Conference on Computational Linguistics,,out_of_scope,
3592,"**Title**Adapting a Language Model for Controlled Affective Text Generation

**Abstract**Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model, and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.","Goswamy, Tushar, Singh, Ishika, Barkati, Ahsan, Modi, Ashutosh",,,Adapting a Language Model for Controlled Affective Text Generation,,,10.18653/v1/2020.coling-main.251 , ,,"Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model, and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.",,,,, ,  Proceedings of the 28th International Conference on Computational Linguistics,,out_of_scope,
3593,"**Title**{GEM}: Generative Enhanced Model for adversarial attacks

**Abstract**We present our Generative Enhanced Model (GEM) that we used to create samples awarded the first prize on the FEVER 2.0 Breakers Task. GEM is the extended language model developed upon GPT-2 architecture. The addition of novel target vocabulary input to the already existing context input enabled controlled text generation. The training procedure resulted in creating a model that inherited the knowledge of pretrained GPT-2, and therefore was ready to generate natural-like English sentences in the task domain with some additional control. As a result, GEM generated malicious claims that mixed facts from various articles, so it became difficult to classify their truthfulness.","Niewinski, Piotr, Pszona, Maria, Janicka, Maria",,,{GEM}: Generative Enhanced Model for adversarial attacks,,,10.18653/v1/D19-6604 , ,,"We present our Generative Enhanced Model (GEM) that we used to create samples awarded the first prize on the FEVER 2.0 Breakers Task. GEM is the extended language model developed upon GPT-2 architecture. The addition of novel target vocabulary input to the already existing context input enabled controlled text generation. The training procedure resulted in creating a model that inherited the knowledge of pretrained GPT-2, and therefore was ready to generate natural-like English sentences in the task domain with some additional control. As a result, GEM generated malicious claims that mixed facts from various articles, so it became difficult to classify their truthfulness.",,,,, ,  Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER),,out_of_scope,
3594,"**Title**An {NLP} Case Study on Predicting the Before and After of the {U}kraine{--}{R}ussia and Hamas{--}{I}srael Conflicts

**Abstract**We propose a method to predict toxicity and other textual attributes through the use of natural language processing (NLP) techniques for two recent events: the Ukraine-Russia and Hamas-Israel conflicts. This article provides a basis for exploration in future conflicts with hopes to mitigate risk through the analysis of social media before and after a conflict begins. Our work compiles several datasets from Twitter and Reddit for both conflicts in a before and after separation with an aim of predicting a future state of social media for avoidance. More specifically, we show that: (1) there is a noticeable difference in social media discussion leading up to and following a conflict and (2) social media discourse on platforms like Twitter and Reddit is useful in identifying future conflicts before they arise. Our results show that through the use of advanced NLP techniques (both supervised and unsupervised) toxicity and other attributes about language before and after a conflict is predictable with a low error of nearly 1.2 percent for both conflicts.","Miner, Jordan, Ortega, John E.",,,An {NLP} Case Study on Predicting the Before and After of the {U}kraine{--}{R}ussia and Hamas{--}{I}srael Conflicts,,,10.18653/v1/2024.nlp4pi-1.14 , ,,"We propose a method to predict toxicity and other textual attributes through the use of natural language processing (NLP) techniques for two recent events: the Ukraine-Russia and Hamas-Israel conflicts. This article provides a basis for exploration in future conflicts with hopes to mitigate risk through the analysis of social media before and after a conflict begins. Our work compiles several datasets from Twitter and Reddit for both conflicts in a before and after separation with an aim of predicting a future state of social media for avoidance. More specifically, we show that: (1) there is a noticeable difference in social media discussion leading up to and following a conflict and (2) social media discourse on platforms like Twitter and Reddit is useful in identifying future conflicts before they arise. Our results show that through the use of advanced NLP techniques (both supervised and unsupervised) toxicity and other attributes about language before and after a conflict is predictable with a low error of nearly 1.2 percent for both conflicts.",,,,, ,  Proceedings of the Third Workshop on NLP for Positive Impact,,out_of_scope,
3595,"**Title**Ethos: Rectifying Language Models in Orthogonal Parameter Space

**Abstract**Language models (LMs) have greatly propelled the research on natural language processing. However, LMs also raise concerns regarding the generation of biased or toxic content and the potential disclosure of private information from the training dataset. In this work, we present a new efficient approach, Ethos, that rectifies LMs to mitigate toxicity and bias in outputs and avoid privacy leakage. Ethos is built on task arithmetic. However, unlike current task arithmetic algorithms, Ethos distinguishes general beneficial and undesired knowledge when reconstructing task vectors. Specifically, Ethos first obtains a set of principal components from the pre-trained models using singular value decomposition. Then, by projecting the task vector onto principal components, Ethos separates the principal components that encode general from those associated with undesired knowledge. Ethos performs forgetting or unlearning by only negating the task vector with undesired knowledge, thereby minimizing collateral damage on general model utility. We demonstrate the efficacy of our approach on three different tasks: bias, toxicity, and memorization unlearning. Evaluations show Ethos is more effective in removing undesired knowledge while maintaining the overall model performance compared to current task arithmetic methods.","Gao, Lei, Niu, Yue, Tang, Tingting, Avestimehr, Salman, Annavaram, Murali",,,Ethos: Rectifying Language Models in Orthogonal Parameter Space,,,10.18653/v1/2024.findings-naacl.132 , ,,"Language models (LMs) have greatly propelled the research on natural language processing. However, LMs also raise concerns regarding the generation of biased or toxic content and the potential disclosure of private information from the training dataset. In this work, we present a new efficient approach, Ethos, that rectifies LMs to mitigate toxicity and bias in outputs and avoid privacy leakage. Ethos is built on task arithmetic. However, unlike current task arithmetic algorithms, Ethos distinguishes general beneficial and undesired knowledge when reconstructing task vectors. Specifically, Ethos first obtains a set of principal components from the pre-trained models using singular value decomposition. Then, by projecting the task vector onto principal components, Ethos separates the principal components that encode general from those associated with undesired knowledge. Ethos performs forgetting or unlearning by only negating the task vector with undesired knowledge, thereby minimizing collateral damage on general model utility. We demonstrate the efficacy of our approach on three different tasks: bias, toxicity, and memorization unlearning. Evaluations show Ethos is more effective in removing undesired knowledge while maintaining the overall model performance compared to current task arithmetic methods.",,,,, ,  Findings of the Association for Computational Linguistics: NAACL 2024,,detox,
3596,"**Title**Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models

**Abstract**Debiasing methods that seek to mitigate the tendency of Language Models (LMs) to occasionally output toxic or inappropriate text have recently gained traction. In this paper, we propose a standardized protocol which distinguishes methods that yield not only desirable results, but are also consistent with their mechanisms and specifications. For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed? We used such considerations to devise three criteria for our new protocol: Specification Polarity, Specification Importance, and Domain Transferability. As a case study, we apply our protocol to a popular debiasing method, Self-Debiasing, and compare it to one we propose, called Instructive Debiasing, and demonstrate that consistency is as important an aspect to debiasing viability as is simply a desirable result. We show that our protocol provides essential insights into the generalizability and interpretability of debiasing methods that may otherwise go overlooked.","Morabito, Robert, Kabbara, Jad, Emami, Ali",,,Debiasing should be Good and Bad: Measuring the Consistency of Debiasing Techniques in Language Models,,,10.18653/v1/2023.findings-acl.280 , ,,"Debiasing methods that seek to mitigate the tendency of Language Models (LMs) to occasionally output toxic or inappropriate text have recently gained traction. In this paper, we propose a standardized protocol which distinguishes methods that yield not only desirable results, but are also consistent with their mechanisms and specifications. For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed? We used such considerations to devise three criteria for our new protocol: Specification Polarity, Specification Importance, and Domain Transferability. As a case study, we apply our protocol to a popular debiasing method, Self-Debiasing, and compare it to one we propose, called Instructive Debiasing, and demonstrate that consistency is as important an aspect to debiasing viability as is simply a desirable result. We show that our protocol provides essential insights into the generalizability and interpretability of debiasing methods that may otherwise go overlooked.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detox,
3597,"**Title**{T}oxi{G}en: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection

**Abstract**Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5{\%} of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.","Hartvigsen, Thomas, Gabriel, Saadia, Palangi, Hamid, Sap, Maarten, Ray, Dipankar, Kamar, Ece",,,{T}oxi{G}en: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection,,,10.18653/v1/2022.acl-long.234 , ,,"Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5{\%} of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.",,,,, ,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,Gen_dataset#detection,
3598,"**Title**Demoting Racial Bias in Hate Speech Detection

**Abstract**In the task of hate speech detection, there exists a high correlation between African American English (AAE) and annotators' perceptions of toxicity in current datasets. This bias in annotated training data and the tendency of machine learning models to amplify it cause AAE text to often be mislabeled as abusive/offensive/hate speech (high false positive rate) by current hate speech classifiers. Here, we use adversarial training to mitigate this bias. Experimental results on one hate speech dataset and one AAE dataset suggest that our method is able to reduce the false positive rate for AAE text with only a minimal compromise on the performance of hate speech classification.","Xia, Mengzhou, Field, Anjalie, Tsvetkov, Yulia",,,Demoting Racial Bias in Hate Speech Detection,,,10.18653/v1/2020.socialnlp-1.2 , ,,"In the task of hate speech detection, there exists a high correlation between African American English (AAE) and annotators' perceptions of toxicity in current datasets. This bias in annotated training data and the tendency of machine learning models to amplify it cause AAE text to often be mislabeled as abusive/offensive/hate speech (high false positive rate) by current hate speech classifiers. Here, we use adversarial training to mitigate this bias. Experimental results on one hate speech dataset and one AAE dataset suggest that our method is able to reduce the false positive rate for AAE text with only a minimal compromise on the performance of hate speech classification.",,,,, ,  Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media,,detection#methodology,
3599,"**Title**Debiasing by obfuscating with 007-classifiers promotes fairness in multi-community settings

**Abstract**While there has been considerable amount of research on bias mitigation algorithms, two properties: multi-community perspective and fairness to *all* communities have not been given sufficient attention. Focusing on these, we propose an obfuscation based data augmentation debiasing approach. In it we add to the training data *obfuscated* versions of *all* false positive instances irrespective of source community. We test our approach by debiasing toxicity classifiers built using 5 neural models (multi layer perceptron model and masked language models) and 3 datasets in a 4 communities setting. We also explore 4 different obfuscators for debiasing. Results demonstrate the merits of our approach: bias is reduced for almost all of our runs without sacrificing false positive rates or F1 scores for minority or majority communities. In contrast, the 4 state of the art baselines typically make performance sacrifices (often large) while reducing bias. Crucially, we demonstrate that it is possible to debias while maintaining standards for both minority and majority communities.","Shrestha, Ingroj, Srinivasan, Padmini",,,Debiasing by obfuscating with 007-classifiers promotes fairness in multi-community settings,,, , ,,"While there has been considerable amount of research on bias mitigation algorithms, two properties: multi-community perspective and fairness to *all* communities have not been given sufficient attention. Focusing on these, we propose an obfuscation based data augmentation debiasing approach. In it we add to the training data *obfuscated* versions of *all* false positive instances irrespective of source community. We test our approach by debiasing toxicity classifiers built using 5 neural models (multi layer perceptron model and masked language models) and 3 datasets in a 4 communities setting. We also explore 4 different obfuscators for debiasing. Results demonstrate the merits of our approach: bias is reduced for almost all of our runs without sacrificing false positive rates or F1 scores for minority or majority communities. In contrast, the 4 state of the art baselines typically make performance sacrifices (often large) while reducing bias. Crucially, we demonstrate that it is possible to debias while maintaining standards for both minority and majority communities.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics,,detection,
3600,"**Title**Cross-lingual Text Classification Transfer: The Case of {U}krainian

**Abstract**Despite the extensive amount of labeled datasets in the NLP text classification field, the persistent imbalance in data availability across various languages remains evident. To support further fair development of NLP models, exploring the possibilities of effective knowledge transfer to new languages is crucial. Ukrainian, in particular, stands as a language that still can benefit from the continued refinement of cross-lingual methodologies. Due to our knowledge, there is a tremendous lack of Ukrainian corpora for typical text classification tasks, i.e., different types of style, or harmful speech, or texts relationships. However, the amount of resources required for such corpora collection from scratch is understandable. In this work, we leverage the state-of-the-art advances in NLP, exploring cross-lingual knowledge transfer methods avoiding manual data curation: large multilingual encoders and translation systems, LLMs, and language adapters. We test the approaches on three text classification tasks{---}toxicity classification, formality classification, and natural language inference (NLI){---}providing the {\textquotedblleft}recipe{\textquotedblright} for the optimal setups for each task.","Dementieva, Daryna, Khylenko, Valeriia, Groh, Georg",,,Cross-lingual Text Classification Transfer: The Case of {U}krainian,,, , ,,"Despite the extensive amount of labeled datasets in the NLP text classification field, the persistent imbalance in data availability across various languages remains evident. To support further fair development of NLP models, exploring the possibilities of effective knowledge transfer to new languages is crucial. Ukrainian, in particular, stands as a language that still can benefit from the continued refinement of cross-lingual methodologies. Due to our knowledge, there is a tremendous lack of Ukrainian corpora for typical text classification tasks, i.e., different types of style, or harmful speech, or texts relationships. However, the amount of resources required for such corpora collection from scratch is understandable. In this work, we leverage the state-of-the-art advances in NLP, exploring cross-lingual knowledge transfer methods avoiding manual data curation: large multilingual encoders and translation systems, LLMs, and language adapters. We test the approaches on three text classification tasks{---}toxicity classification, formality classification, and natural language inference (NLI){---}providing the {\textquotedblleft}recipe{\textquotedblright} for the optimal setups for each task.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics,,out_of_scope,
3601,"**Title**Neural Methods for Aligning Large-Scale Parallel Corpora from the Web for South and {E}ast {A}sian Languages

**Abstract**We introduce neural methods and a toxicity filtering step to the hierarchical web mining approach of Paracrawl (Ba{\~n}{\'o}n et al., 2020), showing large improvements. We apply these methods to web-scale parallel corpus mining for 9 South and East Asian national languages, creating training resources for machine translation that yield better translation quality for most of these languages than existing publicly available datasets in OPUS. Our methods also generally lead to better results than the global mining approach of Schwenk et al. (2021).","Koehn, Philipp",,,Neural Methods for Aligning Large-Scale Parallel Corpora from the Web for South and {E}ast {A}sian Languages,,,10.18653/v1/2024.wmt-1.132 , ,,"We introduce neural methods and a toxicity filtering step to the hierarchical web mining approach of Paracrawl (Ba{\~n}{\'o}n et al., 2020), showing large improvements. We apply these methods to web-scale parallel corpus mining for 9 South and East Asian national languages, creating training resources for machine translation that yield better translation quality for most of these languages than existing publicly available datasets in OPUS. Our methods also generally lead to better results than the global mining approach of Schwenk et al. (2021).",,,,, ,  Proceedings of the Ninth Conference on Machine Translation,,out_of_scope,
3602,"**Title**Flatness-Aware Gradient Descent for Safe Conversational {AI}

**Abstract**As generative dialog models become ubiquitous in real-world applications, it is paramount to ensure a harmless generation. There are two major challenges when enforcing safety to open-domain chatbots. Firstly, it is impractical to provide training data reflecting the desired response to all emerging forms of toxicity (generalisation challenge). Secondly, implementing safety features may compromise the quality of the conversation (trade-off challenge). To tackle the challenges, this paper introduces a regularized fine-tuning approach called FlatGD. By employing a safety-tailored loss, we translate better optimization to more safety. To ensure better optimization, FlatGD penalizes sharp trajectories of loss curve, encouraging flatness of the converged local minima. Experimental results on datasets of {\textquotedblleft}BAD{\textquotedblright} and {\textquotedblleft}prosocial dialog{\textquotedblright} demonstrate that our model outperforms the current baselines in reducing toxicity while preserving the conversation quality. Moreover, compared to other baselines, FlatGD can better generalize to unseen toxic data.","Khalatbari, Leila, Hosseini, Saeid, Sameti, Hossein, Fung, Pascale",,,Flatness-Aware Gradient Descent for Safe Conversational {AI},,,10.18653/v1/2024.trustnlp-1.15 , ,,"As generative dialog models become ubiquitous in real-world applications, it is paramount to ensure a harmless generation. There are two major challenges when enforcing safety to open-domain chatbots. Firstly, it is impractical to provide training data reflecting the desired response to all emerging forms of toxicity (generalisation challenge). Secondly, implementing safety features may compromise the quality of the conversation (trade-off challenge). To tackle the challenges, this paper introduces a regularized fine-tuning approach called FlatGD. By employing a safety-tailored loss, we translate better optimization to more safety. To ensure better optimization, FlatGD penalizes sharp trajectories of loss curve, encouraging flatness of the converged local minima. Experimental results on datasets of {\textquotedblleft}BAD{\textquotedblright} and {\textquotedblleft}prosocial dialog{\textquotedblright} demonstrate that our model outperforms the current baselines in reducing toxicity while preserving the conversation quality. Moreover, compared to other baselines, FlatGD can better generalize to unseen toxic data.",,,,, ,  Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024),,detox,
3603,"**Title**Universal Prompt Optimizer for Safe Text-to-Image Generation

**Abstract**Text-to-Image (T2I) models have shown great performance in generating images based on textual prompts. However, these models are vulnerable to unsafe input to generate unsafe content like sexual, harassment and illegal-activity images. Existing studies based on image checker, model fine-tuning and embedding blocking are impractical in real-world applications. Hence, we propose the first universal **p**rompt **o**ptimizer for **s**afe T2**I** (**POSI**) generation in black-box scenario. We first construct a dataset consisting of toxic-clean prompt pairs by GPT-3.5 Turbo. To guide the optimizer to have the ability of converting toxic prompt to clean prompt while preserving semantic information, we design a novel reward function measuring toxicity and text alignment of generated images and train the optimizer through Proximal Policy Optimization. Experiments show that our approach can effectively reduce the likelihood of various T2I models in generating inappropriate images, with no significant impact on text alignment. It is also flexible to be combined with methods to achieve better performance. Our code is available at [https://github.com/wzongyu/POSI](https://github.com/wzongyu/POSI).","Wu, Zongyu, Gao, Hongcheng, Wang, Yueze, Zhang, Xiang, Wang, Suhang",,,Universal Prompt Optimizer for Safe Text-to-Image Generation,,,10.18653/v1/2024.naacl-long.351 , ,,"Text-to-Image (T2I) models have shown great performance in generating images based on textual prompts. However, these models are vulnerable to unsafe input to generate unsafe content like sexual, harassment and illegal-activity images. Existing studies based on image checker, model fine-tuning and embedding blocking are impractical in real-world applications. Hence, we propose the first universal **p**rompt **o**ptimizer for **s**afe T2**I** (**POSI**) generation in black-box scenario. We first construct a dataset consisting of toxic-clean prompt pairs by GPT-3.5 Turbo. To guide the optimizer to have the ability of converting toxic prompt to clean prompt while preserving semantic information, we design a novel reward function measuring toxicity and text alignment of generated images and train the optimizer through Proximal Policy Optimization. Experiments show that our approach can effectively reduce the likelihood of various T2I models in generating inappropriate images, with no significant impact on text alignment. It is also flexible to be combined with methods to achieve better performance. Our code is available at [https://github.com/wzongyu/POSI](https://github.com/wzongyu/POSI).",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,out_of_scope,
3604,"**Title**Capturing Perspectives of Crowdsourced Annotators in Subjective Learning Tasks

**Abstract**Supervised classification heavily depends on datasets annotated by humans. However, in subjective tasks such as toxicity classification, these annotations often exhibit low agreement among raters. Annotations have commonly been aggregated by employing methods like majority voting to determine a single ground truth label. In subjective tasks, aggregating labels will result in biased labeling and, consequently, biased models that can overlook minority opinions. Previous studies have shed light on the pitfalls of label aggregation and have introduced a handful of practical approaches to tackle this issue. Recently proposed multi-annotator models, which predict labels individually per annotator, are vulnerable to under-determination for annotators with few samples. This problem is exacerbated in crowdsourced datasets. In this work, we propose Annotator Aware Representations for Texts (AART) for subjective classification tasks. Our approach involves learning representations of annotators, allowing for exploration of annotation behaviors. We show the improvement of our method on metrics that assess the performance on capturing individual annotators' perspectives. Additionally, we demonstrate fairness metrics to evaluate our model`s equability of performance for marginalized annotators compared to others.","Mokhberian, Negar, Marmarelis, Myrl, Hopp, Frederic, Basile, Valerio, Morstatter, Fred, Lerman, Kristina",,,Capturing Perspectives of Crowdsourced Annotators in Subjective Learning Tasks,,,10.18653/v1/2024.naacl-long.407 , ,,"Supervised classification heavily depends on datasets annotated by humans. However, in subjective tasks such as toxicity classification, these annotations often exhibit low agreement among raters. Annotations have commonly been aggregated by employing methods like majority voting to determine a single ground truth label. In subjective tasks, aggregating labels will result in biased labeling and, consequently, biased models that can overlook minority opinions. Previous studies have shed light on the pitfalls of label aggregation and have introduced a handful of practical approaches to tackle this issue. Recently proposed multi-annotator models, which predict labels individually per annotator, are vulnerable to under-determination for annotators with few samples. This problem is exacerbated in crowdsourced datasets. In this work, we propose Annotator Aware Representations for Texts (AART) for subjective classification tasks. Our approach involves learning representations of annotators, allowing for exploration of annotation behaviors. We show the improvement of our method on metrics that assess the performance on capturing individual annotators' perspectives. Additionally, we demonstrate fairness metrics to evaluate our model`s equability of performance for marginalized annotators compared to others.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detection,
3605,"**Title**Humans Need Context, What about Machines? Investigating Conversational Context in Abusive Language Detection

**Abstract**A crucial aspect in abusive language on social media platforms (toxicity, hate speech, harmful stereotypes, etc.) is its inherent contextual nature. In this paper, we focus on the role of conversational context in abusive language detection, one of the most {\textquotedblleft}direct{\textquotedblright} forms of context in this domain, as given by the conversation threads (e.g., directly preceding message, original post). The incorporation of surrounding messages has proven vital for the accurate human annotation of harmful content. However, many prior works have either ignored this aspect, collecting and processing messages in isolation, or have obtained inconsistent results when attempting to embed such contextual information into traditional classification methods. The reasons behind these findings have not yet been properly addressed. To this end, we propose an analysis of the impact of conversational context in abusive language detection, through: (1) an analysis of prior works and the limitations of the most common concatenation-based approach, which we attempt to address with two alternative architectures; (2) an evaluation of these methods on existing datasets in English, and a new dataset of French tweets annotated for hate speech and stereotypes; and (3) a qualitative analysis showcasing the necessity for context-awareness in ALD, but also its difficulties.","Bourgeade, Tom, Li, Zongmin, Benamara, Farah, Moriceau, V{\'e}ronique, Su, Jian, Sun, Aixin",,,"Humans Need Context, What about Machines? Investigating Conversational Context in Abusive Language Detection",,, , ,,"A crucial aspect in abusive language on social media platforms (toxicity, hate speech, harmful stereotypes, etc.) is its inherent contextual nature. In this paper, we focus on the role of conversational context in abusive language detection, one of the most {\textquotedblleft}direct{\textquotedblright} forms of context in this domain, as given by the conversation threads (e.g., directly preceding message, original post). The incorporation of surrounding messages has proven vital for the accurate human annotation of harmful content. However, many prior works have either ignored this aspect, collecting and processing messages in isolation, or have obtained inconsistent results when attempting to embed such contextual information into traditional classification methods. The reasons behind these findings have not yet been properly addressed. To this end, we propose an analysis of the impact of conversational context in abusive language detection, through: (1) an analysis of prior works and the limitations of the most common concatenation-based approach, which we attempt to address with two alternative architectures; (2) an evaluation of these methods on existing datasets in English, and a new dataset of French tweets annotated for hate speech and stereotypes; and (3) a qualitative analysis showcasing the necessity for context-awareness in ALD, but also its difficulties.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,detection,
3606,"**Title**The Challenges of Creating a Parallel Multilingual Hate Speech Corpus: An Exploration

**Abstract**Hate speech is infamously one of the most demanding topics in Natural Language Processing, as its multifacetedness is accompanied by a handful of challenges, such as multilinguality and cross-linguality. Hate speech has a subjective aspect that intensifies when referring to different cultures and different languages. In this respect, we design a pipeline that will help us explore the possibility of the creation of a parallel multilingual hate speech dataset, using machine translation. In this paper, we evaluate how/whether this is feasible by assessing the quality of the translations, calculating the toxicity levels of original and target texts, and calculating correlations between the newly obtained scores. Finally, we perform a qualitative analysis to gain further semantic and grammatical insights. With this pipeline we aim at exploring ways of filtering hate speech texts in order to parallelize sentences in multiple languages, examining the challenges of the task.","Korre, Katerina, Muti, Arianna, Barr{\'o}n-Cede{\~n}o, Alberto",,,The Challenges of Creating a Parallel Multilingual Hate Speech Corpus: An Exploration,,, , ,,"Hate speech is infamously one of the most demanding topics in Natural Language Processing, as its multifacetedness is accompanied by a handful of challenges, such as multilinguality and cross-linguality. Hate speech has a subjective aspect that intensifies when referring to different cultures and different languages. In this respect, we design a pipeline that will help us explore the possibility of the creation of a parallel multilingual hate speech dataset, using machine translation. In this paper, we evaluate how/whether this is feasible by assessing the quality of the translations, calculating the toxicity levels of original and target texts, and calculating correlations between the newly obtained scores. Finally, we perform a qualitative analysis to gain further semantic and grammatical insights. With this pipeline we aim at exploring ways of filtering hate speech texts in order to parallelize sentences in multiple languages, examining the challenges of the task.",,,,, ,"  Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,out_of_scope,
3607,"**Title**{R}epro{H}um {\#}0927-3: Reproducing The Human Evaluation Of The {DE}xperts Controlled Text Generation Method

**Abstract**This paper presents a reproduction study aimed at reproducing and validating a human NLP evaluation performed for the DExperts text generation method. The original study introduces DExperts, a controlled text generation method, evaluated using non-toxic prompts from the RealToxicityPrompts dataset. Our reproduction study aims to reproduce the human evaluation of the continuations generated by DExperts in comparison with four baseline methods, in terms of toxicity, topicality, and fluency. We first describe the agreed approach for reproduction within the ReproHum project and detail the configuration of the original evaluation, including necessary adaptations for reproduction. Then, we make a comparison of our reproduction results with those reported in the reproduced paper. Interestingly, we observe how the human evaluators in our experiment appreciate higher quality in the texts generated by DExperts in terms of less toxicity and better fluency. All in all, new scores are higher, also for the baseline methods. This study contributes to ongoing efforts in ensuring the reproducibility and reliability of findings in NLP evaluation and emphasizes the critical role of robust methodologies in advancing the field.","Gonz{\'a}lez Corbelle, Javier, Vivel Couso, Ainhoa, Alonso-Moral, Jose Maria, Bugar{\'i}n-Diz, Alberto",,,{R}epro{H}um {\#}0927-3: Reproducing The Human Evaluation Of The {DE}xperts Controlled Text Generation Method,,, , ,,"This paper presents a reproduction study aimed at reproducing and validating a human NLP evaluation performed for the DExperts text generation method. The original study introduces DExperts, a controlled text generation method, evaluated using non-toxic prompts from the RealToxicityPrompts dataset. Our reproduction study aims to reproduce the human evaluation of the continuations generated by DExperts in comparison with four baseline methods, in terms of toxicity, topicality, and fluency. We first describe the agreed approach for reproduction within the ReproHum project and detail the configuration of the original evaluation, including necessary adaptations for reproduction. Then, we make a comparison of our reproduction results with those reported in the reproduced paper. Interestingly, we observe how the human evaluators in our experiment appreciate higher quality in the texts generated by DExperts in terms of less toxicity and better fluency. All in all, new scores are higher, also for the baseline methods. This study contributes to ongoing efforts in ensuring the reproducibility and reliability of findings in NLP evaluation and emphasizes the critical role of robust methodologies in advancing the field.",,,,, ,  Proceedings of the Fourth Workshop on Human Evaluation of NLP Systems (HumEval) @ LREC-COLING 2024,,detox,
3608,"**Title**The {L}ou Dataset - Exploring the Impact of Gender-Fair Language in {G}erman Text Classification

**Abstract**Gender-fair language, an evolving linguistic variation in German, fosters inclusion by addressing all genders or using neutral forms. However, there is a notable lack of resources to assess the impact of this language shift on language models (LMs) might not been trained on examples of this variation. Addressing this gap, we present Lou, the first dataset providing high-quality reformulations for German text classification covering seven tasks, like stance detection and toxicity classification. We evaluate 16 mono- and multi-lingual LMs and find substantial label flips, reduced prediction certainty, and significantly altered attention patterns. However, existing evaluations remain valid, as LM rankings are consistent across original and reformulated instances. Our study provides initial insights into the impact of gender-fair language on classification for German. However, these findings are likely transferable to other languages, as we found consistent patterns in multi-lingual and English LMs.","Waldis, Andreas, Birrer, Joel, Lauscher, Anne, Gurevych, Iryna",,,The {L}ou Dataset - Exploring the Impact of Gender-Fair Language in {G}erman Text Classification,,,10.18653/v1/2024.emnlp-main.592 , ,,"Gender-fair language, an evolving linguistic variation in German, fosters inclusion by addressing all genders or using neutral forms. However, there is a notable lack of resources to assess the impact of this language shift on language models (LMs) might not been trained on examples of this variation. Addressing this gap, we present Lou, the first dataset providing high-quality reformulations for German text classification covering seven tasks, like stance detection and toxicity classification. We evaluate 16 mono- and multi-lingual LMs and find substantial label flips, reduced prediction certainty, and significantly altered attention patterns. However, existing evaluations remain valid, as LM rankings are consistent across original and reformulated instances. Our study provides initial insights into the impact of gender-fair language on classification for German. However, these findings are likely transferable to other languages, as we found consistent patterns in multi-lingual and English LMs.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,out_but_toxicity,
3609,"**Title**Data, Data Everywhere: A Guide for Pretraining Dataset Construction

**Abstract**The impressive capabilities of recent language models can be largely attributed to the multi-trillion token pretraining datasets that they are trained on. However, model developers fail to disclose their construction methodology which has lead to a lack of open information on how to develop effective pretraining sets. To address this issue, we perform the first systematic study across the entire pipeline of pretraining set construction. First, we run ablations on existing techniques for pretraining set development to identify which methods translate to the largest gains in model accuracy on downstream evaluations. Then, we categorize the most widely used data source, web crawl snapshots, across the attributes of toxicity, quality, type of speech, and domain. Finally, we show how such attribute information can be used to further refine and improve the quality of a pretraining set. These findings constitute an actionable set of steps that practitioners can use to develop high quality pretraining sets.","Parmar, Jupinder, Prabhumoye, Shrimai, Jennings, Joseph, Liu, Bo, Jhunjhunwala, Aastha, Wang, Zhilin, Patwary, Mostofa, Shoeybi, Mohammad, Catanzaro, Bryan",,,"Data, Data Everywhere: A Guide for Pretraining Dataset Construction",,,10.18653/v1/2024.emnlp-main.596 , ,,"The impressive capabilities of recent language models can be largely attributed to the multi-trillion token pretraining datasets that they are trained on. However, model developers fail to disclose their construction methodology which has lead to a lack of open information on how to develop effective pretraining sets. To address this issue, we perform the first systematic study across the entire pipeline of pretraining set construction. First, we run ablations on existing techniques for pretraining set development to identify which methods translate to the largest gains in model accuracy on downstream evaluations. Then, we categorize the most widely used data source, web crawl snapshots, across the attributes of toxicity, quality, type of speech, and domain. Finally, we show how such attribute information can be used to further refine and improve the quality of a pretraining set. These findings constitute an actionable set of steps that practitioners can use to develop high quality pretraining sets.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detection,
3610,"**Title**{I}ndic{LLMS}uite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for {I}ndian Languages

**Abstract**Despite the considerable advancements in English LLMs, the progress in building comparable models for other languages has been hindered due to the scarcity of tailored resources. Our work aims to bridge this divide by introducing an expansive suite of resources specifically designed for the development of Indic LLMs, covering 22 languages, containing a total of 251B tokens and 74.8M instruction-response pairs. Recognizing the importance of both data quality and quantity, our approach combines highly curated manually verified data, unverified yet valuable data, and synthetic data. We build a clean, open-source pipeline for curating pre-training data from diverse sources, including websites, PDFs, and videos, incorporating best practices for crawling, cleaning, flagging, and deduplication. For instruction-fine tuning, we amalgamate existing Indic datasets, translate/transliterate English datasets into Indian languages, and utilize LLaMa2 and Mixtral models to create conversations grounded in articles from Indian Wikipedia and Wikihow. Additionally, we address toxicity alignment by generating toxic prompts for multiple scenarios and then generate non-toxic responses by feeding these toxic prompts to an aligned LLaMa2 model. We hope that the datasets, tools, and resources released as a part of this work will not only propel the research and development of Indic LLMs but also establish an open-source blueprint for extending such efforts to other languages.","Khan, Mohammed Safi Ur Rahman, Mehta, Priyam, Sankar, Ananth, Kumaravelan, Umashankar, Doddapaneni, Sumanth, B, Suriyaprasaad, G, Varun, Jain, Sparsh, Kunchukuttan, Anoop, Kumar, Pratyush, Dabre, Raj, Khapra, Mitesh M.",,,{I}ndic{LLMS}uite: A Blueprint for Creating Pre-training and Fine-Tuning Datasets for {I}ndian Languages,,,10.18653/v1/2024.acl-long.843 , ,,"Despite the considerable advancements in English LLMs, the progress in building comparable models for other languages has been hindered due to the scarcity of tailored resources. Our work aims to bridge this divide by introducing an expansive suite of resources specifically designed for the development of Indic LLMs, covering 22 languages, containing a total of 251B tokens and 74.8M instruction-response pairs. Recognizing the importance of both data quality and quantity, our approach combines highly curated manually verified data, unverified yet valuable data, and synthetic data. We build a clean, open-source pipeline for curating pre-training data from diverse sources, including websites, PDFs, and videos, incorporating best practices for crawling, cleaning, flagging, and deduplication. For instruction-fine tuning, we amalgamate existing Indic datasets, translate/transliterate English datasets into Indian languages, and utilize LLaMa2 and Mixtral models to create conversations grounded in articles from Indian Wikipedia and Wikihow. Additionally, we address toxicity alignment by generating toxic prompts for multiple scenarios and then generate non-toxic responses by feeding these toxic prompts to an aligned LLaMa2 model. We hope that the datasets, tools, and resources released as a part of this work will not only propel the research and development of Indic LLMs but also establish an open-source blueprint for extending such efforts to other languages.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_of_scope,
3611,"**Title**Harmful Language Datasets: An Assessment of Robustness

**Abstract**The automated detection of harmful language has been of great importance for the online world, especially with the growing importance of social media and, consequently, polarisation. There are many open challenges to high quality detection of harmful text, from dataset creation to generalisable application, thus calling for more systematic studies. In this paper, we explore re-annotation as a means of examining the robustness of already existing labelled datasets, showing that, despite using alternative definitions, the inter-annotator agreement remains very inconsistent, highlighting the intrinsically subjective and variable nature of the task. In addition, we build automatic toxicity detectors using the existing datasets, with their original labels, and we evaluate them on our multi-definition and multi-source datasets. Surprisingly, while other studies show that hate speech detection models perform better on data that are derived from the same distribution as the training set, our analysis demonstrates this is not necessarily true.","Korre, Katerina, Pavlopoulos, John, Sorensen, Jeffrey, Laugier, L{\'e}o, Androutsopoulos, Ion, Dixon, Lucas, Barr{\'o}n-cede{\~n}o, Alberto",,,Harmful Language Datasets: An Assessment of Robustness,,,10.18653/v1/2023.woah-1.24 , ,,"The automated detection of harmful language has been of great importance for the online world, especially with the growing importance of social media and, consequently, polarisation. There are many open challenges to high quality detection of harmful text, from dataset creation to generalisable application, thus calling for more systematic studies. In this paper, we explore re-annotation as a means of examining the robustness of already existing labelled datasets, showing that, despite using alternative definitions, the inter-annotator agreement remains very inconsistent, highlighting the intrinsically subjective and variable nature of the task. In addition, we build automatic toxicity detectors using the existing datasets, with their original labels, and we evaluate them on our multi-definition and multi-source datasets. Surprisingly, while other studies show that hate speech detection models perform better on data that are derived from the same distribution as the training set, our analysis demonstrates this is not necessarily true.",,,,, ,  The 7th Workshop on Online Abuse and Harms (WOAH),,detection,
3612,"**Title**{PALS}: Personalized Active Learning for Subjective Tasks in {NLP}

**Abstract**For subjective NLP problems, such as classification of hate speech, aggression, or emotions, personalized solutions can be exploited. Then, the learned models infer about the perception of the content independently for each reader. To acquire training data, texts are commonly randomly assigned to users for annotation, which is expensive and highly inefficient. Therefore, for the first time, we suggest applying an active learning paradigm in a personalized context to better learn individual preferences. It aims to alleviate the labeling effort by selecting more relevant training samples. In this paper, we present novel Personalized Active Learning techniques for Subjective NLP tasks (PALS) to either reduce the cost of the annotation process or to boost the learning effect. Our five new measures allow us to determine the relevance of a text in the context of learning users personal preferences. We validated them on three datasets: Wiki discussion texts individually labeled with aggression and toxicity, and on Unhealthy Conversations dataset. Our PALS techniques outperform random selection even by more than 30{\%}. They can also be used to reduce the number of necessary annotations while maintaining a given quality level. Personalized annotation assignments based on our controversy measure decrease the amount of data needed to just 25{\%}-40{\%} of the initial size.","Kanclerz, Kamil, Karanowski, Konrad, Bielaniewicz, Julita, Gruza, Marcin, Mi{\l}kowski, Piotr, Kocon, Jan, Kazienko, Przemyslaw",,,{PALS}: Personalized Active Learning for Subjective Tasks in {NLP},,,10.18653/v1/2023.emnlp-main.823 , ,,"For subjective NLP problems, such as classification of hate speech, aggression, or emotions, personalized solutions can be exploited. Then, the learned models infer about the perception of the content independently for each reader. To acquire training data, texts are commonly randomly assigned to users for annotation, which is expensive and highly inefficient. Therefore, for the first time, we suggest applying an active learning paradigm in a personalized context to better learn individual preferences. It aims to alleviate the labeling effort by selecting more relevant training samples. In this paper, we present novel Personalized Active Learning techniques for Subjective NLP tasks (PALS) to either reduce the cost of the annotation process or to boost the learning effect. Our five new measures allow us to determine the relevance of a text in the context of learning users personal preferences. We validated them on three datasets: Wiki discussion texts individually labeled with aggression and toxicity, and on Unhealthy Conversations dataset. Our PALS techniques outperform random selection even by more than 30{\%}. They can also be used to reduce the number of necessary annotations while maintaining a given quality level. Personalized annotation assignments based on our controversy measure decrease the amount of data needed to just 25{\%}-40{\%} of the initial size.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,detection,
3613,"**Title**{JASMINE}: {A}rabic {GPT} Models for Few-Shot Learning

**Abstract**Scholarship on generative pretraining (GPT) remains acutely Anglocentric, leaving serious gaps in our understanding of the whole class of autoregressive models. For example, we have little knowledge about the potential of these models and their societal impacts in diverse linguistic and cultural settings. We alleviate this issue for Arabic, a wide collection of languages and dialectal varieties with more than 400 million population, by introducing JASMINE. JASMINE is a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million-6.7 billion parameters pretrained on a large and diverse dataset ( 235 GB of text). We also carefully design and release a comprehensive benchmark for both automated and human evaluation of Arabic autoregressive models, with coverage of potential social biases, harms, and toxicity. Using our novel benchmark, we evaluate JASMINE extensively showing powerful performance intrinsically as well as in few-shot learning on a wide range of NLP tasks. We aim to responsibly release our models and evaluation benchmark with interested researchers, along with code for experimenting with them.","Billah Nagoudi, El Moatez, Abdul-Mageed, Muhammad, Elmadany, AbdelRahim, Inciarte, Alcides, Islam Khondaker, Md Tawkat",,,{JASMINE}: {A}rabic {GPT} Models for Few-Shot Learning,,,10.18653/v1/2023.emnlp-main.1040 , ,,"Scholarship on generative pretraining (GPT) remains acutely Anglocentric, leaving serious gaps in our understanding of the whole class of autoregressive models. For example, we have little knowledge about the potential of these models and their societal impacts in diverse linguistic and cultural settings. We alleviate this issue for Arabic, a wide collection of languages and dialectal varieties with more than 400 million population, by introducing JASMINE. JASMINE is a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million-6.7 billion parameters pretrained on a large and diverse dataset ( 235 GB of text). We also carefully design and release a comprehensive benchmark for both automated and human evaluation of Arabic autoregressive models, with coverage of potential social biases, harms, and toxicity. Using our novel benchmark, we evaluate JASMINE extensively showing powerful performance intrinsically as well as in few-shot learning on a wide range of NLP tasks. We aim to responsibly release our models and evaluation benchmark with interested researchers, along with code for experimenting with them.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3614,"**Title**Measuring Gender Bias in {W}est {S}lavic Language Models

**Abstract**Pre-trained language models have been known to perpetuate biases from the underlying datasets to downstream tasks. However, these findings are predominantly based on monolingual language models for English, whereas there are few investigative studies of biases encoded in language models for languages beyond English. In this paper, we fill this gap by analysing gender bias in West Slavic language models. We introduce the first template-based dataset in Czech, Polish, and Slovak for measuring gender bias towards male, female and non-binary subjects. We complete the sentences using both mono- and multilingual language models and assess their suitability for the masked language modelling objective. Next, we measure gender bias encoded in West Slavic language models by quantifying the toxicity and genderness of the generated words. We find that these language models produce hurtful completions that depend on the subject`s gender. Perhaps surprisingly, Czech, Slovak, and Polish language models produce more hurtful completions with men as subjects, which, upon inspection, we find is due to completions being related to violence, death, and sickness.","Martinkov{\'a}, Sandra, Stanczak, Karolina, Augenstein, Isabelle",,,Measuring Gender Bias in {W}est {S}lavic Language Models,,,10.18653/v1/2023.bsnlp-1.17 , ,,"Pre-trained language models have been known to perpetuate biases from the underlying datasets to downstream tasks. However, these findings are predominantly based on monolingual language models for English, whereas there are few investigative studies of biases encoded in language models for languages beyond English. In this paper, we fill this gap by analysing gender bias in West Slavic language models. We introduce the first template-based dataset in Czech, Polish, and Slovak for measuring gender bias towards male, female and non-binary subjects. We complete the sentences using both mono- and multilingual language models and assess their suitability for the masked language modelling objective. Next, we measure gender bias encoded in West Slavic language models by quantifying the toxicity and genderness of the generated words. We find that these language models produce hurtful completions that depend on the subject`s gender. Perhaps surprisingly, Czech, Slovak, and Polish language models produce more hurtful completions with men as subjects, which, upon inspection, we find is due to completions being related to violence, death, and sickness.",,,,, ,  Proceedings of the 9th Workshop on Slavic Natural Language Processing 2023 (SlavicNLP 2023),,out_but_toxicity,
3615,"**Title**DeTox: A Comprehensive Dataset for {G}erman Offensive Language and Conversation Analysis

**Abstract**In this work, we present a new publicly available offensive language dataset of 10.278 German social media comments collected in the first half of 2021 that were annotated by in total six annotators. With twelve different annotation categories, it is far more comprehensive than other datasets, and goes beyond just hate speech detection. The labels aim in particular also at toxicity, criminal relevance and discrimination types of comments. Furthermore, about half of the comments are from coherent parts of conversations, which opens the possibility to consider the comments' contexts and do conversation analyses in order to research the contagion of offensive language in conversations.","Demus, Christoph, Pitz, Jonas, Sch{\""u}tz, Mina, Probol, Nadine, Siegel, Melanie, Labudde, Dirk",,,DeTox: A Comprehensive Dataset for {G}erman Offensive Language and Conversation Analysis,,,10.18653/v1/2022.woah-1.14 , ,,"In this work, we present a new publicly available offensive language dataset of 10.278 German social media comments collected in the first half of 2021 that were annotated by in total six annotators. With twelve different annotation categories, it is far more comprehensive than other datasets, and goes beyond just hate speech detection. The labels aim in particular also at toxicity, criminal relevance and discrimination types of comments. Furthermore, about half of the comments are from coherent parts of conversations, which opens the possibility to consider the comments' contexts and do conversation analyses in order to research the contagion of offensive language in conversations.",,,,, ,  Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH),,out_but_toxicity,
3616,"**Title**{SSNCSE}{\_}{NLP}@{LT}-{EDI}-{ACL}2022:Hope Speech Detection for Equality, Diversity and Inclusion using sentence transformers

**Abstract**In recent times, applications have been developed to regulate and control the spread of negativity and toxicity on online platforms. The world is filled with serious problems like political {\&} religious conflicts, wars, pandemics, and offensive hate speech is the last thing we desire. Our task was to classify a text into {\textquoteleft}Hope Speech' and {\textquoteleft}Non-Hope Speech'. We searched for datasets acquired from YouTube comments that offer support, reassurance, inspiration, and insight, and the ones that don`t. The datasets were provided to us by the LTEDI organizers in English, Tamil, Spanish, Kannada, and Malayalam. To successfully identify and classify them, we employed several machine learning transformer models such as m-BERT, MLNet, BERT, XLMRoberta, and XLM{\_}MLM. The observed results indicate that the BERT and m-BERT have obtained the best results among all the other techniques, gaining a weighted F1- score of 0.92, 0.71, 0.76, 0.87, and 0.83 for English, Tamil, Spanish, Kannada, and Malayalam respectively. This paper depicts our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LTEDI 2021.","B, Bharathi, Srinivasan, Dhanya, Varsha, Josephine, Durairaj, Thenmozhi, B, Senthil Kumar",,,"{SSNCSE}{\_}{NLP}@{LT}-{EDI}-{ACL}2022:Hope Speech Detection for Equality, Diversity and Inclusion using sentence transformers",,,10.18653/v1/2022.ltedi-1.30 , ,,"In recent times, applications have been developed to regulate and control the spread of negativity and toxicity on online platforms. The world is filled with serious problems like political {\&} religious conflicts, wars, pandemics, and offensive hate speech is the last thing we desire. Our task was to classify a text into {\textquoteleft}Hope Speech' and {\textquoteleft}Non-Hope Speech'. We searched for datasets acquired from YouTube comments that offer support, reassurance, inspiration, and insight, and the ones that don`t. The datasets were provided to us by the LTEDI organizers in English, Tamil, Spanish, Kannada, and Malayalam. To successfully identify and classify them, we employed several machine learning transformer models such as m-BERT, MLNet, BERT, XLMRoberta, and XLM{\_}MLM. The observed results indicate that the BERT and m-BERT have obtained the best results among all the other techniques, gaining a weighted F1- score of 0.92, 0.71, 0.76, 0.87, and 0.83 for English, Tamil, Spanish, Kannada, and Malayalam respectively. This paper depicts our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LTEDI 2021.",,,,, ,"  Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",,out_of_scope,
3617,"**Title**Conditional Supervised Contrastive Learning for Fair Text Classification

**Abstract**Contrastive representation learning has gained much attention due to its superior performance in learning representations from both image and sequential data. However, the learned representations could potentially lead to performance disparities in downstream tasks, such as increased silencing of underrepresented groups in toxicity comment classification. In light of this challenge, in this work, we study learning fair representations that satisfy a notion of fairness known as equalized odds for text classification via contrastive learning. Specifically, we first theoretically analyze the connections between learning representations with a fairness constraint and conditional supervised contrastive objectives, and then propose to use conditional supervised contrastive objectives to learn fair representations for text classification. We conduct experiments on two text datasets to demonstrate the effectiveness of our approaches in balancing the trade-offs between task performance and bias mitigation among existing baselines for text classification. Furthermore, we also show that the proposed methods are stable in different hyperparameter settings.","Chi, Jianfeng, Shand, William, Yu, Yaodong, Chang, Kai-Wei, Zhao, Han, Tian, Yuan",,,Conditional Supervised Contrastive Learning for Fair Text Classification,,,10.18653/v1/2022.findings-emnlp.199 , ,,"Contrastive representation learning has gained much attention due to its superior performance in learning representations from both image and sequential data. However, the learned representations could potentially lead to performance disparities in downstream tasks, such as increased silencing of underrepresented groups in toxicity comment classification. In light of this challenge, in this work, we study learning fair representations that satisfy a notion of fairness known as equalized odds for text classification via contrastive learning. Specifically, we first theoretically analyze the connections between learning representations with a fairness constraint and conditional supervised contrastive objectives, and then propose to use conditional supervised contrastive objectives to learn fair representations for text classification. We conduct experiments on two text datasets to demonstrate the effectiveness of our approaches in balancing the trade-offs between task performance and bias mitigation among existing baselines for text classification. Furthermore, we also show that the proposed methods are stable in different hyperparameter settings.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2022,,detection,
3618,"**Title**Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation

**Abstract**Large pretrained language models can easily produce toxic or biased content, which is prohibitive for practical use. In order to detect such toxic generations, existing methods rely on templates, real-world data extraction, crowdsourcing workers or automatic generation to construct adversarial contexts that are likely to induce toxic generations. However, what type of context is more likely to induce unsafe responses is still under-explored. In this paper, we identify that context toxicity and context category (e.g., profanity, insult, drugs, etc.) are two important factors to cause safety issues in response generation. Hence, we propose a method called reverse generation to construct adversarial contexts conditioned on a given response, with the flexibility to control category, toxicity level and inductivity of the generated contexts. Via reverse generation, we augment the existing BAD dataset and construct a new dataset BAD+ which contains more than 120K diverse and highly inductive contexts in 12 categories. We test three popular pretrained dialogue models (Blender, DialoGPT and Plato2) and find that BAD+ can largely expose their safety problems. Furthermore, we show that BAD+ can greatly enhance the safety of generation, and we reveal the key factors of safety improvement. Our code and dataset is available at \url{https://github.com/thu-coai/Reverse_Generation}.","Zhang, Zhexin, Cheng, Jiale, Sun, Hao, Deng, Jiawen, Mi, Fei, Wang, Yasheng, Shang, Lifeng, Huang, Minlie",,,Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation,,,10.18653/v1/2022.findings-emnlp.270 , ,,"Large pretrained language models can easily produce toxic or biased content, which is prohibitive for practical use. In order to detect such toxic generations, existing methods rely on templates, real-world data extraction, crowdsourcing workers or automatic generation to construct adversarial contexts that are likely to induce toxic generations. However, what type of context is more likely to induce unsafe responses is still under-explored. In this paper, we identify that context toxicity and context category (e.g., profanity, insult, drugs, etc.) are two important factors to cause safety issues in response generation. Hence, we propose a method called reverse generation to construct adversarial contexts conditioned on a given response, with the flexibility to control category, toxicity level and inductivity of the generated contexts. Via reverse generation, we augment the existing BAD dataset and construct a new dataset BAD+ which contains more than 120K diverse and highly inductive contexts in 12 categories. We test three popular pretrained dialogue models (Blender, DialoGPT and Plato2) and find that BAD+ can largely expose their safety problems. Furthermore, we show that BAD+ can greatly enhance the safety of generation, and we reveal the key factors of safety improvement. Our code and dataset is available at \url{https://github.com/thu-coai/Reverse_Generation}.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2022,,detox,
3619,"**Title**How Does the Hate Speech Corpus Concern Sociolinguistic Discussions? A Case Study on {K}orean Online News Comments

**Abstract**Social consensus has been established on the severity of online hate speech since it not only causes mental harm to the target, but also gives displeasure to the people who read it. For Korean, the definition and scope of hate speech have been discussed widely in researches, but such considerations were hardly extended to the construction of hate speech corpus. Therefore, we create a Korean online hate speech dataset with concrete annotation guideline to see how real world toxic expressions concern sociolinguistic discussions. This inductive observation reveals that hate speech in online news comments is mainly composed of social bias and toxicity. Furthermore, we check how the final corpus corresponds with the definition and scope of hate speech, and confirm that the overall procedure and outcome is in concurrence with the sociolinguistic discussions.","Cho, Won Ik, Moon, Jihyung",,,How Does the Hate Speech Corpus Concern Sociolinguistic Discussions? A Case Study on {K}orean Online News Comments,,, , ,,"Social consensus has been established on the severity of online hate speech since it not only causes mental harm to the target, but also gives displeasure to the people who read it. For Korean, the definition and scope of hate speech have been discussed widely in researches, but such considerations were hardly extended to the construction of hate speech corpus. Therefore, we create a Korean online hate speech dataset with concrete annotation guideline to see how real world toxic expressions concern sociolinguistic discussions. This inductive observation reveals that hate speech in online news comments is mainly composed of social bias and toxicity. Furthermore, we check how the final corpus corresponds with the definition and scope of hate speech, and confirm that the overall procedure and outcome is in concurrence with the sociolinguistic discussions.",,,,, ,  Proceedings of the Workshop on Natural Language Processing for Digital Humanities,,out_but_toxicity,
3620,"**Title**Detecting Inappropriate Messages on Sensitive Topics that Could Harm a Company`s Reputation

**Abstract**Not all topics are equally {\textquotedblleft}flammable{\textquotedblright} in terms of toxicity: a calm discussion of turtles or fishing less often fuels inappropriate toxic dialogues than a discussion of politics or sexual minorities. We define a set of sensitive topics that can yield inappropriate and toxic messages and describe the methodology of collecting and labelling a dataset for appropriateness. While toxicity in user-generated data is well-studied, we aim at defining a more fine-grained notion of inappropriateness. The core of inappropriateness is that it can harm the reputation of a speaker. This is different from toxicity in two respects: (i) inappropriateness is topic-related, and (ii) inappropriate message is not toxic but still unacceptable. We collect and release two datasets for Russian: a topic-labelled dataset and an appropriateness-labelled dataset. We also release pre-trained classification models trained on this data.","Babakov, Nikolay, Logacheva, Varvara, Kozlova, Olga, Semenov, Nikita, Panchenko, Alexander",,,Detecting Inappropriate Messages on Sensitive Topics that Could Harm a Company`s Reputation,,, , ,,"Not all topics are equally {\textquotedblleft}flammable{\textquotedblright} in terms of toxicity: a calm discussion of turtles or fishing less often fuels inappropriate toxic dialogues than a discussion of politics or sexual minorities. We define a set of sensitive topics that can yield inappropriate and toxic messages and describe the methodology of collecting and labelling a dataset for appropriateness. While toxicity in user-generated data is well-studied, we aim at defining a more fine-grained notion of inappropriateness. The core of inappropriateness is that it can harm the reputation of a speaker. This is different from toxicity in two respects: (i) inappropriateness is topic-related, and (ii) inappropriate message is not toxic but still unacceptable. We collect and release two datasets for Russian: a topic-labelled dataset and an appropriateness-labelled dataset. We also release pre-trained classification models trained on this data.",,,,, ,  Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing,,detection,
3621,"**Title**{A}lex{U}-{B}ack{T}ranslation-{TL} at {S}em{E}val-2020 Task 12: Improving Offensive Language Detection Using Data Augmentation and Transfer Learning

**Abstract**Social media platforms, online news commenting spaces, and many other public forums have become widely known for issues of abusive behavior such as cyber-bullying and personal attacks. In this paper, we use the annotated tweets of the Offensive Language Identification Dataset (OLID) to train three levels of deep learning classifiers to solve the three sub-tasks associated with the dataset. Sub-task A is to determine if the tweet is toxic or not. Then, for offensive tweets, sub-task B requires determining whether the toxicity is targeted. Finally, for sub-task C, we predict the target of the offense; i.e. a group, individual, or other entity. In our solution, we tackle the problem of class imbalance in the dataset by using back translation for data augmentation and utilizing the fine-tuned BERT model in an ensemble of deep learning classifiers. We used this solution to participate in the three English sub-tasks of SemEval-2020 task 12. The proposed solution achieved 0.91393, 0.6300, and 0.57607 macro F1-average in sub-tasks A, B, and C respectively. We achieved the 9th, 14th, and 22nd places for sub-tasks A, B and C respectively.","Ibrahim, Mai, Torki, Marwan, El-Makky, Nagwa",,,{A}lex{U}-{B}ack{T}ranslation-{TL} at {S}em{E}val-2020 Task 12: Improving Offensive Language Detection Using Data Augmentation and Transfer Learning,,,10.18653/v1/2020.semeval-1.248 , ,,"Social media platforms, online news commenting spaces, and many other public forums have become widely known for issues of abusive behavior such as cyber-bullying and personal attacks. In this paper, we use the annotated tweets of the Offensive Language Identification Dataset (OLID) to train three levels of deep learning classifiers to solve the three sub-tasks associated with the dataset. Sub-task A is to determine if the tweet is toxic or not. Then, for offensive tweets, sub-task B requires determining whether the toxicity is targeted. Finally, for sub-task C, we predict the target of the offense; i.e. a group, individual, or other entity. In our solution, we tackle the problem of class imbalance in the dataset by using back translation for data augmentation and utilizing the fine-tuned BERT model in an ensemble of deep learning classifiers. We used this solution to participate in the three English sub-tasks of SemEval-2020 task 12. The proposed solution achieved 0.91393, 0.6300, and 0.57607 macro F1-average in sub-tasks A, B, and C respectively. We achieved the 9th, 14th, and 22nd places for sub-tasks A, B and C respectively.",,,,, ,  Proceedings of the Fourteenth Workshop on Semantic Evaluation,,detection,
3622,"**Title**Merging Datasets for Aggressive Text Identification

**Abstract**This paper presents the approach of the team {\textquotedblleft}groutar{\textquotedblright} to the shared task on Aggression Identification, considering the test sets in English, both from Facebook and general Social Media. This experiment aims to test the effect of merging new datasets in the performance of classification models. We followed a standard machine learning approach with training, validation, and testing phases, and considered features such as part-of-speech, frequencies of insults, punctuation, sentiment, and capitalization. In terms of algorithms, we experimented with Boosted Logistic Regression, Multi-Layer Perceptron, Parallel Random Forest and eXtreme Gradient Boosting. One question appearing was how to merge datasets using different classification systems (e.g. aggression vs. toxicity). Other issue concerns the possibility to generalize models and apply them to data from different social networks. Regarding these, we merged two datasets, and the results showed that training with similar data is an advantage in the classification of social networks data. However, adding data from different platforms, allowed slightly better results in both Facebook and Social Media, indicating that more generalized models can be an advantage.","Fortuna, Paula, Ferreira, Jos{\'e}, Pires, Luiz, Routar, Guilherme, Nunes, S{\'e}rgio",,,Merging Datasets for Aggressive Text Identification,,, , ,,"This paper presents the approach of the team {\textquotedblleft}groutar{\textquotedblright} to the shared task on Aggression Identification, considering the test sets in English, both from Facebook and general Social Media. This experiment aims to test the effect of merging new datasets in the performance of classification models. We followed a standard machine learning approach with training, validation, and testing phases, and considered features such as part-of-speech, frequencies of insults, punctuation, sentiment, and capitalization. In terms of algorithms, we experimented with Boosted Logistic Regression, Multi-Layer Perceptron, Parallel Random Forest and eXtreme Gradient Boosting. One question appearing was how to merge datasets using different classification systems (e.g. aggression vs. toxicity). Other issue concerns the possibility to generalize models and apply them to data from different social networks. Regarding these, we merged two datasets, and the results showed that training with similar data is an advantage in the classification of social networks data. However, adding data from different platforms, allowed slightly better results in both Facebook and Social Media, indicating that more generalized models can be an advantage.",,,,, ,"  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying ({TRAC}-2018)",,detection,
3623,"**Title**{LUCE}: A Dynamic Framework and Interactive Dashboard for Opinionated Text Analysis

**Abstract**We introduce LUCE, an advanced dynamic framework with an interactive dashboard for analysing opinionated text aiming to understand people-centred communication. The framework features computational modules of text classification and extraction explicitly designed for analysing different elements of opinions, e.g., sentiment/emotion, suggestion, figurative language, hate/toxic speech, and topics. We designed the framework using a modular architecture, allowing scalability and extensibility with the aim of supporting other NLP tasks in subsequent versions. LUCE comprises trained models, python-based APIs, and a user-friendly dashboard, ensuring an intuitive user experience. LUCE has been validated in a relevant environment, and its capabilities and performance have been demonstrated through initial prototypes and pilot studies.","Zayed, Omnia, Negi, Gaurav, Manjunath, Sampritha Hassan, Pillai, Devishree, Buitelaar, Paul",,,{LUCE}: A Dynamic Framework and Interactive Dashboard for Opinionated Text Analysis,,, , ,,"We introduce LUCE, an advanced dynamic framework with an interactive dashboard for analysing opinionated text aiming to understand people-centred communication. The framework features computational modules of text classification and extraction explicitly designed for analysing different elements of opinions, e.g., sentiment/emotion, suggestion, figurative language, hate/toxic speech, and topics. We designed the framework using a modular architecture, allowing scalability and extensibility with the aim of supporting other NLP tasks in subsequent versions. LUCE comprises trained models, python-based APIs, and a user-friendly dashboard, ensuring an intuitive user experience. LUCE has been validated in a relevant environment, and its capabilities and performance have been demonstrated through initial prototypes and pilot studies.",,,,, ,  Proceedings of the 31st International Conference on Computational Linguistics: System Demonstrations,,detection,
3624,"**Title**Analyzing Offensive Language and Hate Speech in Political Discourse: A Case Study of {G}erman Politicians

**Abstract**Social media platforms have become key players in political discourse. Twitter (now {\textquoteleft}X'), for example, is used by many German politicians to communicate their views and interact with others. Due to its nature, however, social networks suffer from a number of issues such as offensive content, toxic language and hate speech. This has attracted a lot of research interest but in the context of political discourse there is a noticeable gap with no such study specifically looking at German politicians in a systematic way. We aim to help addressing this gap. We first create an annotated dataset of 1,197 Twitter posts mentioning German politicians. This is the basis to explore a number of approaches to detect hate speech and offensive language (HOF) and identify an ensemble of transformer models that achieves an F1-Macros score of 0.94. This model is then used to automatically classify two much larger, longitudinal datasets: one with 520,000 tweets posted by MPs, and the other with 2,200,000 tweets which comprise posts from the public mentioning politicians. We obtain interesting insights in regards to the distribution of hate and offensive content when looking at different independent variables.","Weissenbacher, Maximilian, Kruschwitz, Udo",,,Analyzing Offensive Language and Hate Speech in Political Discourse: A Case Study of {G}erman Politicians,,, , ,,"Social media platforms have become key players in political discourse. Twitter (now {\textquoteleft}X'), for example, is used by many German politicians to communicate their views and interact with others. Due to its nature, however, social networks suffer from a number of issues such as offensive content, toxic language and hate speech. This has attracted a lot of research interest but in the context of political discourse there is a noticeable gap with no such study specifically looking at German politicians in a systematic way. We aim to help addressing this gap. We first create an annotated dataset of 1,197 Twitter posts mentioning German politicians. This is the basis to explore a number of approaches to detect hate speech and offensive language (HOF) and identify an ensemble of transformer models that achieves an F1-Macros score of 0.94. This model is then used to automatically classify two much larger, longitudinal datasets: one with 520,000 tweets posted by MPs, and the other with 2,200,000 tweets which comprise posts from the public mentioning politicians. We obtain interesting insights in regards to the distribution of hate and offensive content when looking at different independent variables.",,,,, ,"  Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,out_but_toxicity,
3625,"**Title**Improving Dialog Safety using Socially Aware Contrastive Learning

**Abstract**State-of-the-art conversational AI systems raise concerns due to their potential risks of generating unsafe, toxic, unethical, or dangerous content. Previous works have developed datasets to teach conversational agents the appropriate social paradigms to respond effectively to specifically designed hazardous content. However, models trained on these adversarial datasets still struggle to recognize subtle unsafe situations that appear naturally in conversations or introduce an inappropriate response in a casual context. To understand the extent of this problem, we study prosociality in both adversarial and casual dialog contexts and audit the response quality of general-purpose language models in terms of propensity to produce unsafe content. We propose a dual-step fine-tuning process to address these issues using a socially aware n-pair contrastive loss. Subsequently, we train a base model that integrates prosocial behavior by leveraging datasets like Moral Integrity Corpus (MIC) and ProsocialDialog. Experimental results on several dialog datasets demonstrate the effectiveness of our approach in generating socially appropriate responses.","Das, Souvik, Srihari, Rohini K.",,,Improving Dialog Safety using Socially Aware Contrastive Learning,,, , ,,"State-of-the-art conversational AI systems raise concerns due to their potential risks of generating unsafe, toxic, unethical, or dangerous content. Previous works have developed datasets to teach conversational agents the appropriate social paradigms to respond effectively to specifically designed hazardous content. However, models trained on these adversarial datasets still struggle to recognize subtle unsafe situations that appear naturally in conversations or introduce an inappropriate response in a casual context. To understand the extent of this problem, we study prosociality in both adversarial and casual dialog contexts and audit the response quality of general-purpose language models in terms of propensity to produce unsafe content. We propose a dual-step fine-tuning process to address these issues using a socially aware n-pair contrastive loss. Subsequently, we train a base model that integrates prosocial behavior by leveraging datasets like Moral Integrity Corpus (MIC) and ProsocialDialog. Experimental results on several dialog datasets demonstrate the effectiveness of our approach in generating socially appropriate responses.",,,,, ,  Proceedings of the 1st Workshop on Simulating Conversational Intelligence in Chat (SCI-CHAT 2024),,detox,
3626,"**Title**Can Language Model Moderators Improve the Health of Online Discourse?

**Abstract**Conversational moderation of online communities is crucial to maintaining civility for a constructive environment, but it is challenging to scale and harmful to moderators. The inclusion of sophisticated natural language generation modules as a force multiplier to aid human moderators is a tantalizing prospect, but adequate evaluation approaches have so far been elusive. In this paper, we establish a systematic definition of conversational moderation effectiveness grounded on moderation literature and establish design criteria for conducting realistic yet safe evaluation. We then propose a comprehensive evaluation framework to assess models' moderation capabilities independently of human intervention. With our framework, we conduct the first known study of language models as conversational moderators, finding that appropriately prompted models that incorporate insights from social science can provide specific and fair feedback on toxic behavior but struggle to influence users to increase their levels of respect and cooperation.","Cho, Hyundong, Liu, Shuai, Shi, Taiwei, Jain, Darpan, Rizk, Basem, Huang, Yuyang, Lu, Zixun, Wen, Nuan, Gratch, Jonathan, Ferrara, Emilio, May, Jonathan",,,Can Language Model Moderators Improve the Health of Online Discourse?,,,10.18653/v1/2024.naacl-long.415 , ,,"Conversational moderation of online communities is crucial to maintaining civility for a constructive environment, but it is challenging to scale and harmful to moderators. The inclusion of sophisticated natural language generation modules as a force multiplier to aid human moderators is a tantalizing prospect, but adequate evaluation approaches have so far been elusive. In this paper, we establish a systematic definition of conversational moderation effectiveness grounded on moderation literature and establish design criteria for conducting realistic yet safe evaluation. We then propose a comprehensive evaluation framework to assess models' moderation capabilities independently of human intervention. With our framework, we conduct the first known study of language models as conversational moderators, finding that appropriately prompted models that incorporate insights from social science can provide specific and fair feedback on toxic behavior but struggle to influence users to increase their levels of respect and cooperation.",,,,, ,  Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),,detection,
3627,"**Title**Quartet@{LT}-{EDI} 2024: Support Vector Machine Based Approach For Homophobia/Transphobia Detection In Social Media Comments

**Abstract**Homophobia and transphobia are terms which are used to describe the fear or hatred towards people who are attracted to the same sex or people whose psychological gender differs from his biological sex. People use social media to exert this behaviour. The increased amount of abusive content negatively affects people in a lot of ways. It makes the environment toxic and unpleasant to LGBTQ+ people. The paper talks about the classification model for classifying the contents into 3 categories which are homophobic, transphobic and nonhomophobic/ transphobic. We used many traditional models like Support Vector Machine, Random Classifier, Logistic Regression and KNearest Neighbour to achieve this. The macro average F1 scores for Malayalam, Telugu, English, Marathi, Kannada, Tamil, Gujarati, Hindi are 0.88, 0.94, 0.96, 0.78, 0.93, 0.77, 0.94, 0.47 and the rank for these languages are 5, 6, 9, 6, 8, 6, 6, 4.","H, Shaun, Sivakumar, Samyuktaa, R, Rohan, Jayaguptha, Nikilesh, Thenmozhi, Durairaj",,,Quartet@{LT}-{EDI} 2024: Support Vector Machine Based Approach For Homophobia/Transphobia Detection In Social Media Comments,,, , ,,"Homophobia and transphobia are terms which are used to describe the fear or hatred towards people who are attracted to the same sex or people whose psychological gender differs from his biological sex. People use social media to exert this behaviour. The increased amount of abusive content negatively affects people in a lot of ways. It makes the environment toxic and unpleasant to LGBTQ+ people. The paper talks about the classification model for classifying the contents into 3 categories which are homophobic, transphobic and nonhomophobic/ transphobic. We used many traditional models like Support Vector Machine, Random Classifier, Logistic Regression and KNearest Neighbour to achieve this. The macro average F1 scores for Malayalam, Telugu, English, Marathi, Kannada, Tamil, Gujarati, Hindi are 0.88, 0.94, 0.96, 0.78, 0.93, 0.77, 0.94, 0.47 and the rank for these languages are 5, 6, 9, 6, 8, 6, 6, 4.",,,,, ,"  Proceedings of the Fourth Workshop on Language Technology for Equality, Diversity, Inclusion",,out_but_toxicity,
3628,"**Title**Knowledge Acquisition through Continued Pretraining is Difficult: A Case Study on r/{A}sk{H}istorians

**Abstract**Powerful LLMs like ChatGPT are adopted rapidly for a wide array of tasks, but their limitations in domain-specific areas become apparent, particularly when prompted to recite facts. This is critical especially for knowledge workers, who are adopting LLM-based tools rapidly.While there are various techniques that can help ingest knowledge into LLMs such as instruction tuning and alignment, most have disadvantages. We examine the impact of prominent training techniques on LLMs' knowledge accuracy using a knowledge-dense dataset that we curate from r/AskHistorians, a rich source of historical knowledge. We evaluate the impact of different models sizes from 1.3B to 7B parameters and other factors such as LoRA adapters, quantization, overfitting, and the inclusion of Reddit data in pretraining.In addition, we measure linguistic metrics and human and LLM-based preference. Our results suggest that pretraining and model size have a much stronger effect on knowledge accuracy than continued pretraining {--} unless the model is overfit to the tested knowledge.Fine-tuning on our Reddit dataset introduces less complex, but slightly more toxic language. Our study explores the challenges of injecting domain-specific datasets into LLMs and has implications for practitioners, e.g., when LLMs are to be fine-tuned with a company`s datasets.","Hoffbauer, Jan, Sawicki, Sylwester, Ulrich, Marc, Buz, Tolga, Dobler, Konstantin, Schneider, Moritz, De Melo, Gerard",,,Knowledge Acquisition through Continued Pretraining is Difficult: A Case Study on r/{A}sk{H}istorians,,,10.18653/v1/2024.knowllm-1.9 , ,,"Powerful LLMs like ChatGPT are adopted rapidly for a wide array of tasks, but their limitations in domain-specific areas become apparent, particularly when prompted to recite facts. This is critical especially for knowledge workers, who are adopting LLM-based tools rapidly.While there are various techniques that can help ingest knowledge into LLMs such as instruction tuning and alignment, most have disadvantages. We examine the impact of prominent training techniques on LLMs' knowledge accuracy using a knowledge-dense dataset that we curate from r/AskHistorians, a rich source of historical knowledge. We evaluate the impact of different models sizes from 1.3B to 7B parameters and other factors such as LoRA adapters, quantization, overfitting, and the inclusion of Reddit data in pretraining.In addition, we measure linguistic metrics and human and LLM-based preference. Our results suggest that pretraining and model size have a much stronger effect on knowledge accuracy than continued pretraining {--} unless the model is overfit to the tested knowledge.Fine-tuning on our Reddit dataset introduces less complex, but slightly more toxic language. Our study explores the challenges of injecting domain-specific datasets into LLMs and has implications for practitioners, e.g., when LLMs are to be fine-tuned with a company`s datasets.",,,,, ,  Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024),,out_of_scope,
3629,"**Title**Emojis Trash or Treasure: Utilizing Emoji to Aid Hate Speech Detection

**Abstract**In this study, we delve into the fascinating realm of emojis and their impact on identifying hate speech in both Bengali and English languages. Through extensive exploration of various techniques, particularly the integration of Multilingual BERT (MBert) and Emoji2Vec embeddings, we strive to shed light on the immense potential of emojis in this detection process. By meticulously comparing these advanced models with conventional approaches, we uncover the intricate contextual cues that emojis bring to the table. Ultimately, our discoveries underscore the invaluable role of emojis in hate speech detection, thereby providing valuable insights for the creation of resilient and context-aware systems to combat online toxicity. Our findings showcase the potential of emojis as valuable assets rather than mere embellishments in the realm of hate speech detection. By leveraging the combined strength of MBert and Emoji2Vec, our models exhibit enhanced capabilities in deciphering the emotional subtleties often intertwined with hate speech expressions.","Saikh, Tanik, Barman, Soham, Kumar, Harsh, Sahu, Saswat, Palit, Souvick",,,Emojis Trash or Treasure: Utilizing Emoji to Aid Hate Speech Detection,,, , ,,"In this study, we delve into the fascinating realm of emojis and their impact on identifying hate speech in both Bengali and English languages. Through extensive exploration of various techniques, particularly the integration of Multilingual BERT (MBert) and Emoji2Vec embeddings, we strive to shed light on the immense potential of emojis in this detection process. By meticulously comparing these advanced models with conventional approaches, we uncover the intricate contextual cues that emojis bring to the table. Ultimately, our discoveries underscore the invaluable role of emojis in hate speech detection, thereby providing valuable insights for the creation of resilient and context-aware systems to combat online toxicity. Our findings showcase the potential of emojis as valuable assets rather than mere embellishments in the realm of hate speech detection. By leveraging the combined strength of MBert and Emoji2Vec, our models exhibit enhanced capabilities in deciphering the emotional subtleties often intertwined with hate speech expressions.",,,,, ,  Proceedings of the 21st International Conference on Natural Language Processing (ICON),,detection,
3630,"**Title**Divine {LL}a{MA}s: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models

**Abstract**Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that:Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs.Eastern religions like Hinduism and Buddhism are strongly stereotyped.Judaism and Islam are stigmatized {--} the models' refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research emphasizes the crucial role emotions play in shaping our lives and how our values influence them.","Plaza-del-Arco, Flor Miriam, Curry, Amanda Cercas, Paoli, Susanna, Cercas Curry, Alba, Hovy, Dirk",,,"Divine {LL}a{MA}s: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",,,10.18653/v1/2024.findings-emnlp.251 , ,,"Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that:Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs.Eastern religions like Hinduism and Buddhism are strongly stereotyped.Judaism and Islam are stigmatized {--} the models' refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research emphasizes the crucial role emotions play in shaping our lives and how our values influence them.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,detection,
3631,"**Title**{B}ias{D}ora: Exploring Hidden Biased Associations in Vision-Language Models

**Abstract**Existing works examining Vision-Language Models (VLMs) for social biases predominantly focus on a limited set of documented bias associations, such as gender-profession or race-crime. This narrow scope often overlooks a vast range of unexamined implicit associations, restricting the identification and, hence, mitigation of such biases. We address this gap by probing VLMs to (1) uncover hidden, implicit associations across 9 bias dimensions. We systematically explore diverse input and output modalities and (2) demonstrate how biased associations vary in their negativity, toxicity, and extremity. Our work (3) identifies subtle and extreme biases that are typically not recognized by existing methodologies. We make the **D**ataset **o**f **r**etrieved **a**ssociations (**Dora**) publicly available.","Raj, Chahat, Mukherjee, Anjishnu, Caliskan, Aylin, Anastasopoulos, Antonios, Zhu, Ziwei",,,{B}ias{D}ora: Exploring Hidden Biased Associations in Vision-Language Models,,,10.18653/v1/2024.findings-emnlp.611 , ,,"Existing works examining Vision-Language Models (VLMs) for social biases predominantly focus on a limited set of documented bias associations, such as gender-profession or race-crime. This narrow scope often overlooks a vast range of unexamined implicit associations, restricting the identification and, hence, mitigation of such biases. We address this gap by probing VLMs to (1) uncover hidden, implicit associations across 9 bias dimensions. We systematically explore diverse input and output modalities and (2) demonstrate how biased associations vary in their negativity, toxicity, and extremity. Our work (3) identifies subtle and extreme biases that are typically not recognized by existing methodologies. We make the **D**ataset **o**f **r**etrieved **a**ssociations (**Dora**) publicly available.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2024,,out_but_toxicity,
3632,"**Title**Diffusion Guided Language Modeling

**Abstract**Current language models demonstrate remarkable proficiency in text generation. However, for many applications it is desirable to control attributes, such as sentiment, or toxicity, of the generated language{---}ideally tailored towards each specific use case and target audience. For auto-regressive language models, existing guidance methods are prone to decoding errors that cascade during generation and degrade performance. In contrast, text diffusion models can easily be guided with, for example, a simple linear sentiment classifier{---}however they do suffer from significantly higher perplexity than auto-regressive alternatives. In this paper we use a guided diffusion model to produce a latent proposal that steers an auto-regressive language model to generate text with desired properties. Our model inherits the unmatched fluency of the auto-regressive approach and the plug-and-play flexibility of diffusion. We show that it outperforms previous plug-and-play guidance methods across a wide range of benchmark data sets. Further, controlling a new attribute in our framework is reduced to training a single logistic regression classifier.","Lovelace, Justin, Kishore, Varsha, Chen, Yiwei, Weinberger, Kilian",,,Diffusion Guided Language Modeling,,,10.18653/v1/2024.findings-acl.887 , ,,"Current language models demonstrate remarkable proficiency in text generation. However, for many applications it is desirable to control attributes, such as sentiment, or toxicity, of the generated language{---}ideally tailored towards each specific use case and target audience. For auto-regressive language models, existing guidance methods are prone to decoding errors that cascade during generation and degrade performance. In contrast, text diffusion models can easily be guided with, for example, a simple linear sentiment classifier{---}however they do suffer from significantly higher perplexity than auto-regressive alternatives. In this paper we use a guided diffusion model to produce a latent proposal that steers an auto-regressive language model to generate text with desired properties. Our model inherits the unmatched fluency of the auto-regressive approach and the plug-and-play flexibility of diffusion. We show that it outperforms previous plug-and-play guidance methods across a wide range of benchmark data sets. Further, controlling a new attribute in our framework is reduced to training a single logistic regression classifier.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2024,,detox,
3633,"**Title**Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation

**Abstract**Textual style expresses a diverse set of information, including interpersonal dynamics (e.g., formality) and the author`s emotions or attitudes (e.g., disgust). An open question is how language models can be explicitly controlled so that they weave together target styles when generating text: for example, to produce text that is both negative and non-toxic. One approach to such controlled generation is multi-objective reinforcement learning (RL), but how to best combine multiple objectives in a reward function is an open question. In this paper, we investigate various formulations of multi-style reward formulations, including calibrated outputs from discriminators and dynamic weighting by discriminator gradient magnitudes. We find that our proposed dynamic weighting outperforms static weighting approaches with respect style control while maintaining linguistic quality, and we explore its effectiveness in 2- and 3-style control.","De Langis, Karin, Koo, Ryan, Kang, Dongyeop",,,Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation,,,10.18653/v1/2024.emnlp-main.386 , ,,"Textual style expresses a diverse set of information, including interpersonal dynamics (e.g., formality) and the author`s emotions or attitudes (e.g., disgust). An open question is how language models can be explicitly controlled so that they weave together target styles when generating text: for example, to produce text that is both negative and non-toxic. One approach to such controlled generation is multi-objective reinforcement learning (RL), but how to best combine multiple objectives in a reward function is an open question. In this paper, we investigate various formulations of multi-style reward formulations, including calibrated outputs from discriminators and dynamic weighting by discriminator gradient magnitudes. We find that our proposed dynamic weighting outperforms static weighting approaches with respect style control while maintaining linguistic quality, and we explore its effectiveness in 2- and 3-style control.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3634,"**Title**A Closer Look at Multidimensional Online Political Incivility

**Abstract**Toxic online political discourse has become prevalent, where scholars debate about its impact to Democratic processes. This work presents a large-scale study of political incivility on Twitter. In line with theories of political communication, we differentiate between harsh {\textquoteleft}impolite' style and intolerant substance. We present a dataset of 13K political tweets in the U.S. context, which we collected and labeled by those categories using crowd sourcing. Our dataset and results shed light on hostile political discourse focused on partisan conflicts in the U.S. The evaluation of state-of-the-art classifiers illustrates the challenges involved in political incivility detection, which often requires high-level semantic and social understanding. Nevertheless, performing incivility detection at scale, we are able to characterise its distribution across individual users and geopolitical regions, where our findings align and extend existing theories of political communication. In particular, we find that roughly 80{\%} of the uncivil tweets are authored by 20{\%} of the users, where users who are politically engaged are more inclined to use uncivil language. We further find that political incivility exhibits network homophily, and that incivility is more prominent in highly competitive geopolitical regions. Our results apply to both uncivil style and substance.","Pendzel, Sagi, Lotan, Nir, Zoizner, Alon, Minkov, Einat",,,A Closer Look at Multidimensional Online Political Incivility,,,10.18653/v1/2024.emnlp-main.827 , ,,"Toxic online political discourse has become prevalent, where scholars debate about its impact to Democratic processes. This work presents a large-scale study of political incivility on Twitter. In line with theories of political communication, we differentiate between harsh {\textquoteleft}impolite' style and intolerant substance. We present a dataset of 13K political tweets in the U.S. context, which we collected and labeled by those categories using crowd sourcing. Our dataset and results shed light on hostile political discourse focused on partisan conflicts in the U.S. The evaluation of state-of-the-art classifiers illustrates the challenges involved in political incivility detection, which often requires high-level semantic and social understanding. Nevertheless, performing incivility detection at scale, we are able to characterise its distribution across individual users and geopolitical regions, where our findings align and extend existing theories of political communication. In particular, we find that roughly 80{\%} of the uncivil tweets are authored by 20{\%} of the users, where users who are politically engaged are more inclined to use uncivil language. We further find that political incivility exhibits network homophily, and that incivility is more prominent in highly competitive geopolitical regions. Our results apply to both uncivil style and substance.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,Gen_dataset#detection,
3635,"**Title**Comparing a {BERT} Classifier and a {GPT} classifier for Detecting Connective Language Across Multiple Social Media

**Abstract**This study presents an approach for detecting connective language{---}defined as language that facilitates engagement, understanding, and conversation{---}from social media discussions. We developed and evaluated two types of classifiers: BERT and GPT-3.5 turbo. Our results demonstrate that the BERT classifier significantly outperforms GPT-3.5 turbo in detecting connective language. Furthermore, our analysis confirms that connective language is distinct from related concepts measuring discourse qualities, such as politeness and toxicity. We also explore the potential of BERT-based classifiers for platform-agnostic tools. This research advances our understanding of the linguistic dimensions of online communication and proposes practical tools for detecting connective language across diverse digital environments.","Lukito, Josephine, Chen, Bin, Masullo, Gina M., Stroud, Natalie Jomini",,,Comparing a {BERT} Classifier and a {GPT} classifier for Detecting Connective Language Across Multiple Social Media,,,10.18653/v1/2024.emnlp-main.1067 , ,,"This study presents an approach for detecting connective language{---}defined as language that facilitates engagement, understanding, and conversation{---}from social media discussions. We developed and evaluated two types of classifiers: BERT and GPT-3.5 turbo. Our results demonstrate that the BERT classifier significantly outperforms GPT-3.5 turbo in detecting connective language. Furthermore, our analysis confirms that connective language is distinct from related concepts measuring discourse qualities, such as politeness and toxicity. We also explore the potential of BERT-based classifiers for platform-agnostic tools. This research advances our understanding of the linguistic dimensions of online communication and proposes practical tools for detecting connective language across diverse digital environments.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detection,
3636,"**Title**Towards Aligning Language Models with Textual Feedback

**Abstract**We present ALT (ALignment with Textual feedback), an approach that aligns language models with user preferences expressed in text. We argue that text offers greater expressiveness, enabling users to provide richer feedback than simple comparative preferences and this richer feedback can lead to more efficient and effective alignment. ALT aligns the model by conditioning its generation on the textual feedback. Our method relies solely on language modeling techniques and requires minimal hyper-parameter tuning, though it still presents the main benefit of RL-based algorithms and can effectively learn from textual feedback. We explore the efficacy and efficiency of textual feedback across different tasks such as toxicity reduction, summarization, and dialog response. We find that ALT outperforms PPO for the task of toxicity reduction while being able to match its performance on summarization with only 20{\%} of the samples. We also explore how ALT can be used with feedback provided by an existing LLM.","Lloret, Sa{\""u}c Abadal, Dhuliawala, Shehzaad, Murugesan, Keerthiram, Sachan, Mrinmaya",,,Towards Aligning Language Models with Textual Feedback,,,10.18653/v1/2024.emnlp-main.1129 , ,,"We present ALT (ALignment with Textual feedback), an approach that aligns language models with user preferences expressed in text. We argue that text offers greater expressiveness, enabling users to provide richer feedback than simple comparative preferences and this richer feedback can lead to more efficient and effective alignment. ALT aligns the model by conditioning its generation on the textual feedback. Our method relies solely on language modeling techniques and requires minimal hyper-parameter tuning, though it still presents the main benefit of RL-based algorithms and can effectively learn from textual feedback. We explore the efficacy and efficiency of textual feedback across different tasks such as toxicity reduction, summarization, and dialog response. We find that ALT outperforms PPO for the task of toxicity reduction while being able to match its performance on summarization with only 20{\%} of the samples. We also explore how ALT can be used with feedback provided by an existing LLM.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3637,"**Title**Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models

**Abstract**We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple experts, aggregating their responses, and selecting the best among individual and aggregated responses. This process is performed in a single chain of thoughts through our seven carefully designed subtasks derived from the Nominal Group Technique (Ven and Delbecq, 1974), a well-established decision-making framework. Our evaluations demonstrate that Multi-expert Prompting significantly outperforms ExpertPrompting and comparable baselines in enhancing the truthfulness, factuality, informativeness, and usefulness of responses while reducing toxicity and hurtfulness. It further achieves state-of-the-art truthfulness by outperforming the best baseline by 8.69{\%} with ChatGPT. Multi-expert Prompting is efficient, explainable, and highly adaptable to diverse scenarios, eliminating the need for manual prompt construction.","Long, Do Xuan, Yen, Duong Ngoc, Luu, Anh Tuan, Kawaguchi, Kenji, Kan, Min-Yen, Chen, Nancy F.",,,"Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models",,,10.18653/v1/2024.emnlp-main.1135 , ,,"We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple experts, aggregating their responses, and selecting the best among individual and aggregated responses. This process is performed in a single chain of thoughts through our seven carefully designed subtasks derived from the Nominal Group Technique (Ven and Delbecq, 1974), a well-established decision-making framework. Our evaluations demonstrate that Multi-expert Prompting significantly outperforms ExpertPrompting and comparable baselines in enhancing the truthfulness, factuality, informativeness, and usefulness of responses while reducing toxicity and hurtfulness. It further achieves state-of-the-art truthfulness by outperforming the best baseline by 8.69{\%} with ChatGPT. Multi-expert Prompting is efficient, explainable, and highly adaptable to diverse scenarios, eliminating the need for manual prompt construction.",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detox,
3638,"**Title**{B}ias{W}ipe: Mitigating Unintended Bias in Text Classifiers through Model Interpretability

**Abstract**Toxic content detection plays a vital role in addressing the misuse of social media platforms to harm people or groups due to their race, gender or ethnicity. However, due to the nature of the datasets, systems develop an unintended bias due to the over-generalization of the model to the training data. This compromises the fairness of the systems, which can impact certain groups due to their race, gender, etc.Existing methods mitigate bias using data augmentation, adversarial learning, etc., which require re-training and adding extra parameters to the model.In this work, we present a robust and generalizable technique \textit{BiasWipe} to mitigate unintended bias in language models. \textit{BiasWipe} utilizes model interpretability using Shapley values, which achieve fairness by pruning the neuron weights responsible for unintended bias. It first identifies the neuron weights responsible for unintended bias and then achieves fairness by pruning them without loss of original performance. It does not require re-training or adding extra parameters to the model. To show the effectiveness of our proposed technique for bias unlearning, we perform extensive experiments for Toxic content detection for BERT, RoBERTa, and GPT models. .","Mamta, Mamta, Chigrupaatii, Rishikant, Ekbal, Asif",,,{B}ias{W}ipe: Mitigating Unintended Bias in Text Classifiers through Model Interpretability,,,10.18653/v1/2024.emnlp-main.1172 , ,,"Toxic content detection plays a vital role in addressing the misuse of social media platforms to harm people or groups due to their race, gender or ethnicity. However, due to the nature of the datasets, systems develop an unintended bias due to the over-generalization of the model to the training data. This compromises the fairness of the systems, which can impact certain groups due to their race, gender, etc.Existing methods mitigate bias using data augmentation, adversarial learning, etc., which require re-training and adding extra parameters to the model.In this work, we present a robust and generalizable technique \textit{BiasWipe} to mitigate unintended bias in language models. \textit{BiasWipe} utilizes model interpretability using Shapley values, which achieve fairness by pruning the neuron weights responsible for unintended bias. It first identifies the neuron weights responsible for unintended bias and then achieves fairness by pruning them without loss of original performance. It does not require re-training or adding extra parameters to the model. To show the effectiveness of our proposed technique for bias unlearning, we perform extensive experiments for Toxic content detection for BERT, RoBERTa, and GPT models. .",,,,, ,  Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing,,detection,
3639,"**Title**Aligning Large Language Models via Fine-grained Supervision

**Abstract**Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human feedback (RLHF) to improve model alignment, which works by transforming coarse human preferences of LLM outputs into a feedback signal that guides the model learning process. However, because this approach operates on sequence-level feedback, it lacks the precision to identify the exact parts of the output affecting user preferences. To address this gap, we propose a method to enhance LLM alignment through fine-grained token-level supervision. Specifically, we ask annotators to minimally edit less preferred responses within the standard reward modeling dataset to make them more favorable, ensuring changes are made only where necessary while retaining most of the original content. The refined dataset is used to train a token-level reward model, which is then used for training our fine-grained Proximal Policy Optimization (PPO) model. Our experiment results demonstrate that this approach can improve LLM performance by up to 5.1{\%} in terms of win rate against the reference model, compared with the traditional PPO model.","Xu, Dehong, Qiu, Liang, Kim, Minseok, Ladhak, Faisal, Do, Jaeyoung",,,Aligning Large Language Models via Fine-grained Supervision,,,10.18653/v1/2024.acl-short.62 , ,,"Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human feedback (RLHF) to improve model alignment, which works by transforming coarse human preferences of LLM outputs into a feedback signal that guides the model learning process. However, because this approach operates on sequence-level feedback, it lacks the precision to identify the exact parts of the output affecting user preferences. To address this gap, we propose a method to enhance LLM alignment through fine-grained token-level supervision. Specifically, we ask annotators to minimally edit less preferred responses within the standard reward modeling dataset to make them more favorable, ensuring changes are made only where necessary while retaining most of the original content. The refined dataset is used to train a token-level reward model, which is then used for training our fine-grained Proximal Policy Optimization (PPO) model. Our experiment results demonstrate that this approach can improve LLM performance by up to 5.1{\%} in terms of win rate against the reference model, compared with the traditional PPO model.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),,detox,
3640,"**Title**Unlearning Traces the Influential Training Data of Language Models

**Abstract**Identifying the training datasets that influence a language model`s outputs is essential for minimizing the generation of harmful content and enhancing its performance. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to retrain a model multiple times. This paper presents UnTrac: unlearning traces the influence of a training dataset on the model`s performance. UnTrac is extremely simple; each training dataset is unlearned by gradient ascent, and we evaluate how much the model`s predictions change after unlearning. Furthermore, we propose a more scalable approach, UnTrac-Inv, which unlearns a test dataset and evaluates the unlearned model on training datasets. UnTrac-Inv resembles UnTrac, while being efficient for massive training datasets. In the experiments, we examine if our methods can assess the influence of pretraining datasets on generating toxic, biased, and untruthful content. Our methods estimate their influence much more accurately than existing methods while requiring neither excessive memory space nor multiple checkpoints.","Isonuma, Masaru, Titov, Ivan",,,Unlearning Traces the Influential Training Data of Language Models,,,10.18653/v1/2024.acl-long.343 , ,,"Identifying the training datasets that influence a language model`s outputs is essential for minimizing the generation of harmful content and enhancing its performance. Ideally, we can measure the influence of each dataset by removing it from training; however, it is prohibitively expensive to retrain a model multiple times. This paper presents UnTrac: unlearning traces the influence of a training dataset on the model`s performance. UnTrac is extremely simple; each training dataset is unlearned by gradient ascent, and we evaluate how much the model`s predictions change after unlearning. Furthermore, we propose a more scalable approach, UnTrac-Inv, which unlearns a test dataset and evaluates the unlearned model on training datasets. UnTrac-Inv resembles UnTrac, while being efficient for massive training datasets. In the experiments, we examine if our methods can assess the influence of pretraining datasets on generating toxic, biased, and untruthful content. Our methods estimate their influence much more accurately than existing methods while requiring neither excessive memory space nor multiple checkpoints.",,,,, ,  Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,evaluation,
3641,"**Title**{D}e{T}ex{D}: A Benchmark Dataset for Delicate Text Detection

**Abstract**Over the past few years, much research has been conducted to identify and regulate toxic language. However, few studies have addressed a broader range of sensitive texts that are not necessarily overtly toxic. In this paper, we introduce and define a new category of sensitive text called {\textquotedblleft}delicate text.{\textquotedblright} We provide the taxonomy of delicate text and present a detailed annotation scheme. We annotate DeTexD, the first benchmark dataset for delicate text detection. The significance of the difference in the definitions is highlighted by the relative performance deltas between models trained each definitions and corpora and evaluated on the other. We make publicly available the DeTexD Benchmark dataset, annotation guidelines, and baseline model for delicate text detection.","Yavnyi, Serhii, Sliusarenko, Oleksii, Razzaghi, Jade, Nahorna, Olena, Mo, Yichen, Hovakimyan, Knar, Chernodub, Artem",,,{D}e{T}ex{D}: A Benchmark Dataset for Delicate Text Detection,,,10.18653/v1/2023.woah-1.2 , ,,"Over the past few years, much research has been conducted to identify and regulate toxic language. However, few studies have addressed a broader range of sensitive texts that are not necessarily overtly toxic. In this paper, we introduce and define a new category of sensitive text called {\textquotedblleft}delicate text.{\textquotedblright} We provide the taxonomy of delicate text and present a detailed annotation scheme. We annotate DeTexD, the first benchmark dataset for delicate text detection. The significance of the difference in the definitions is highlighted by the relative performance deltas between models trained each definitions and corpora and evaluated on the other. We make publicly available the DeTexD Benchmark dataset, annotation guidelines, and baseline model for delicate text detection.",,,,, ,  The 7th Workshop on Online Abuse and Harms (WOAH),,detection,
3642,"**Title**An Empirical Study of Metrics to Measure Representational Harms in Pre-Trained Language Models

**Abstract**Large-scale Pre-Trained Language Models (PTLMs) capture knowledge from massive human-written data which contains latent societal biases and toxic contents. In this paper, we leverage the primary task of PTLMs, i.e., language modeling, and propose a new metric to quantify manifested implicit representational harms in PTLMs towards 13 marginalized demographics. Using this metric, we conducted an empirical analysis of 24 widely used PTLMs. Our analysis provides insights into the correlation between the proposed metric in this work and other related metrics for representational harm. We observe that our metric correlates with most of the gender-specific metrics in the literature. Through extensive experiments, we explore the connections between PTLMs architectures and representational harms across two dimensions: depth and width of the networks. We found that prioritizing depth over width, mitigates representational harms in some PTLMs. Our code and data can be found at [place holder].","Hosseini, Saghar, Palangi, Hamid, Awadallah, Ahmed Hassan",,,An Empirical Study of Metrics to Measure Representational Harms in Pre-Trained Language Models,,,10.18653/v1/2023.trustnlp-1.11 , ,,"Large-scale Pre-Trained Language Models (PTLMs) capture knowledge from massive human-written data which contains latent societal biases and toxic contents. In this paper, we leverage the primary task of PTLMs, i.e., language modeling, and propose a new metric to quantify manifested implicit representational harms in PTLMs towards 13 marginalized demographics. Using this metric, we conducted an empirical analysis of 24 widely used PTLMs. Our analysis provides insights into the correlation between the proposed metric in this work and other related metrics for representational harm. We observe that our metric correlates with most of the gender-specific metrics in the literature. Through extensive experiments, we explore the connections between PTLMs architectures and representational harms across two dimensions: depth and width of the networks. We found that prioritizing depth over width, mitigates representational harms in some PTLMs. Our code and data can be found at [place holder].",,,,, ,  Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023),,detection,
3643,"**Title**Style Locality for Controllable Generation with k{NN} Language Models

**Abstract**Recent language models have been improved by the addition of external memory. Nearest neighbor language models retrieve similar contexts to assist in word prediction. The addition of locality levels allows a model to learn how to weight neighbors based on their relative location to the current text in source documents, and have been shown to further improve model performance. Nearest neighbor models have been explored for controllable generation but have not examined the use of locality levels. We present a novel approach for this purpose and evaluate it using automatic and human evaluation on politeness, formality, supportiveness, and toxicity textual data. We find that our model is successfully able to control style and provides a better fluency-style trade-off than previous work","Nawezi, Gilles, Flek, Lucie, Welch, Charles",,,Style Locality for Controllable Generation with k{NN} Language Models,,, , ,,"Recent language models have been improved by the addition of external memory. Nearest neighbor language models retrieve similar contexts to assist in word prediction. The addition of locality levels allows a model to learn how to weight neighbors based on their relative location to the current text in source documents, and have been shown to further improve model performance. Nearest neighbor models have been explored for controllable generation but have not examined the use of locality levels. We present a novel approach for this purpose and evaluate it using automatic and human evaluation on politeness, formality, supportiveness, and toxicity textual data. We find that our model is successfully able to control style and provides a better fluency-style trade-off than previous work",,,,, ,  Proceedings of the 1st Workshop on Taming Large Language Models: Controllability in the era of Interactive Assistants!,,detox,
3644,"**Title**{QC}on at {S}em{E}val-2023 Task 10: Data Augmentation and Model Ensembling for Detection of Online Sexism

**Abstract**The web contains an abundance of user- generated content. While this content is useful for many applications, it poses many challenges due to the presence of offensive, biased, and overall toxic language. In this work, we present a system that identifies and classifies sexist content at different levels of granularity. Using transformer-based models, we explore the value of data augmentation, use of ensemble methods, and leverage in-context learning using foundation models to tackle the task. We evaluate the different components of our system both quantitatively and qualitatively. Our best systems achieve an F1 score of 0.84 for the binary classification task aiming to identify whether a given content is sexist or not and 0.64 and 0.47 for the two multi-class tasks that aim to identify the coarse and fine-grained types of sexism present in the given content respectively.","Feely, Weston, Gupta, Prabhakar, Mohanty, Manas Ranjan, Chon, Timothy, Kundu, Tuhin, Singh, Vijit, Atluri, Sandeep, Roosta, Tanya, Ghaderi, Viviane, Schulam, Peter",,,{QC}on at {S}em{E}val-2023 Task 10: Data Augmentation and Model Ensembling for Detection of Online Sexism,,,10.18653/v1/2023.semeval-1.175 , ,,"The web contains an abundance of user- generated content. While this content is useful for many applications, it poses many challenges due to the presence of offensive, biased, and overall toxic language. In this work, we present a system that identifies and classifies sexist content at different levels of granularity. Using transformer-based models, we explore the value of data augmentation, use of ensemble methods, and leverage in-context learning using foundation models to tackle the task. We evaluate the different components of our system both quantitatively and qualitatively. Our best systems achieve an F1 score of 0.84 for the binary classification task aiming to identify whether a given content is sexist or not and 0.64 and 0.47 for the two multi-class tasks that aim to identify the coarse and fine-grained types of sexism present in the given content respectively.",,,,, ,  Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023),,detection,
3645,"**Title**Publish or Hold? Automatic Comment Moderation in {L}uxembourgish News Articles

**Abstract**Recently, the internet has emerged as the primary platform for accessing news. In the majority of these news platforms, the users now have the ability to post comments on news articles and engage in discussions on various social media. While these features promote healthy conversations among users, they also serve as a breeding ground for spreading fake news, toxic discussions and hate speech. Moderating or removing such content is paramount to avoid unwanted consequences for the readers. How- ever, apart from a few notable exceptions, most research on automatic moderation of news article comments has dealt with English and other high resource languages. This leaves under-represented or low-resource languages at a loss. Addressing this gap, we perform the first large-scale qualitative analysis of more than one million Luxembourgish comments posted over the course of 14 years. We evaluate the performance of state-of-the-art transformer models in Luxembourgish news article comment moderation. Furthermore, we analyse how the language of Luxembourgish news article comments has changed over time. We observe that machine learning models trained on old comments do not perform well on recent data. The findings in this work will be beneficial in building news comment moderation systems for many low-resource languages","Ranasinghe, Tharindu, Plum, Alistair, Purschke, Christoph, Zampieri, Marcos",,,Publish or Hold? Automatic Comment Moderation in {L}uxembourgish News Articles,,, , ,,"Recently, the internet has emerged as the primary platform for accessing news. In the majority of these news platforms, the users now have the ability to post comments on news articles and engage in discussions on various social media. While these features promote healthy conversations among users, they also serve as a breeding ground for spreading fake news, toxic discussions and hate speech. Moderating or removing such content is paramount to avoid unwanted consequences for the readers. How- ever, apart from a few notable exceptions, most research on automatic moderation of news article comments has dealt with English and other high resource languages. This leaves under-represented or low-resource languages at a loss. Addressing this gap, we perform the first large-scale qualitative analysis of more than one million Luxembourgish comments posted over the course of 14 years. We evaluate the performance of state-of-the-art transformer models in Luxembourgish news article comment moderation. Furthermore, we analyse how the language of Luxembourgish news article comments has changed over time. We observe that machine learning models trained on old comments do not perform well on recent data. The findings in this work will be beneficial in building news comment moderation systems for many low-resource languages",,,,, ,  Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing,,out_of_scope,
3646,"**Title**Team-{KEC}@{LT}-{EDI}: Detecting Signs of Depression from Social Media Text

**Abstract**The rise of social media has led to a drastic surge in the dissemination of hostile and toxic content, fostering an alarming proliferation of hate speech, inflammatory remarks, and abusive language. The exponential growth of social media has facilitated the widespread circulation of hostile and toxic content, giving rise to an unprecedented influx of hate speech, incendiary language, and abusive rhetoric. The study utilized different techniques to represent the text data in a numerical format. Word embedding techniques aim to capture the semantic and syntactic information of the text data, which is essential in text classification tasks. The study utilized various techniques such as CNN, BERT, and N-gram to classify social media posts into depression and non-depression categories. Text classification tasks often rely on deep learning techniques such as Convolutional Neural Networks (CNN), while the BERT model, which is pre-trained, has shown exceptional performance in a range of natural language processing tasks. To assess the effectiveness of the suggested approaches, the research employed multiple metrics, including accuracy, precision, recall, and F1-score. The outcomes of the investigation indicate that the suggested techniques can identify symptoms of depression with an average accuracy rate of 56{\%}.","S, Malliga, Shanmugavadivel, Kogilavani, S, Arunaa, R, Gokulkrishna, A, Chandramukhii",,,Team-{KEC}@{LT}-{EDI}: Detecting Signs of Depression from Social Media Text,,, , ,,"The rise of social media has led to a drastic surge in the dissemination of hostile and toxic content, fostering an alarming proliferation of hate speech, inflammatory remarks, and abusive language. The exponential growth of social media has facilitated the widespread circulation of hostile and toxic content, giving rise to an unprecedented influx of hate speech, incendiary language, and abusive rhetoric. The study utilized different techniques to represent the text data in a numerical format. Word embedding techniques aim to capture the semantic and syntactic information of the text data, which is essential in text classification tasks. The study utilized various techniques such as CNN, BERT, and N-gram to classify social media posts into depression and non-depression categories. Text classification tasks often rely on deep learning techniques such as Convolutional Neural Networks (CNN), while the BERT model, which is pre-trained, has shown exceptional performance in a range of natural language processing tasks. To assess the effectiveness of the suggested approaches, the research employed multiple metrics, including accuracy, precision, recall, and F1-score. The outcomes of the investigation indicate that the suggested techniques can identify symptoms of depression with an average accuracy rate of 56{\%}.",,,,, ,"  Proceedings of the Third Workshop on Language Technology for Equality, Diversity and Inclusion",,detection,
3647,"**Title**Attention-Enhancing Backdoor Attacks Against {BERT}-based Models

**Abstract**Recent studies have revealed that Backdoor Attacks can threaten the safety of natural language processing (NLP) models. Investigating the strategies of backdoor attacks will help to understand the model`s vulnerability. Most existing textual backdoor attacks focus on generating stealthy triggers or modifying model weights. In this paper, we directly target the interior structure of neural networks and the backdoor mechanism. We propose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior by directly manipulating the attention patterns. Our loss can be applied to different attacking methods to boost their attack efficacy in terms of attack successful rates and poisoning rates. It applies to not only traditional dirty-label attacks, but also the more challenging clean-label attacks. We validate our method on different backbone models (BERT, RoBERTa, and DistilBERT) and various tasks (Sentiment Analysis, Toxic Detection, and Topic Classification).","Lyu, Weimin, Zheng, Songzhu, Pang, Lu, Ling, Haibin, Chen, Chao",,,Attention-Enhancing Backdoor Attacks Against {BERT}-based Models,,,10.18653/v1/2023.findings-emnlp.716 , ,,"Recent studies have revealed that Backdoor Attacks can threaten the safety of natural language processing (NLP) models. Investigating the strategies of backdoor attacks will help to understand the model`s vulnerability. Most existing textual backdoor attacks focus on generating stealthy triggers or modifying model weights. In this paper, we directly target the interior structure of neural networks and the backdoor mechanism. We propose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior by directly manipulating the attention patterns. Our loss can be applied to different attacking methods to boost their attack efficacy in terms of attack successful rates and poisoning rates. It applies to not only traditional dirty-label attacks, but also the more challenging clean-label attacks. We validate our method on different backbone models (BERT, RoBERTa, and DistilBERT) and various tasks (Sentiment Analysis, Toxic Detection, and Topic Classification).",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2023,,detection,
3648,"**Title**{COBRA} Frames: Contextual Reasoning about Effects and Harms of Offensive Statements

**Abstract**Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance {\textquotedblleft}your English is very good{\textquotedblright} may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement`s offensiveness (29{\%} accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.","Zhou, Xuhui, Zhu, Hao, Yerukola, Akhila, Davidson, Thomas, Hwang, Jena D., Swayamdipta, Swabha, Sap, Maarten",,,{COBRA} Frames: Contextual Reasoning about Effects and Harms of Offensive Statements,,,10.18653/v1/2023.findings-acl.392 , ,,"Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance {\textquotedblleft}your English is very good{\textquotedblright} may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement`s offensiveness (29{\%} accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,detection#methodology,
3649,"**Title**Synthetic Pre-Training Tasks for Neural Machine Translation

**Abstract**Pre-training models with large crawled corpora can lead to issues such as toxicity and bias, as well as copyright and privacy concerns. A promising way of alleviating such concerns is to conduct pre-training with synthetic tasks and data, since no real-world information is ingested by the model. Our goal in this paper is to understand the factors that contribute to the effectiveness of pre-training models when using synthetic resources, particularly in the context of neural machine translation. We propose several novel approaches to pre-training translation models that involve different levels of lexical and structural knowledge, including: 1) generating obfuscated data from a large parallel corpus 2) concatenating phrase pairs extracted from a small word-aligned corpus, and 3) generating synthetic parallel data without real human language corpora. Our experiments on multiple language pairs reveal that pre-training benefits can be realized even with high levels of obfuscation or purely synthetic parallel data. We hope the findings from our comprehensive empirical analysis will shed light on understanding what matters for NMT pre-training, as well as pave the way for the development of more efficient and less toxic models.","He, Zexue, Blackwood, Graeme, Panda, Rameswar, McAuley, Julian, Feris, Rogerio",,,Synthetic Pre-Training Tasks for Neural Machine Translation,,,10.18653/v1/2023.findings-acl.512 , ,,"Pre-training models with large crawled corpora can lead to issues such as toxicity and bias, as well as copyright and privacy concerns. A promising way of alleviating such concerns is to conduct pre-training with synthetic tasks and data, since no real-world information is ingested by the model. Our goal in this paper is to understand the factors that contribute to the effectiveness of pre-training models when using synthetic resources, particularly in the context of neural machine translation. We propose several novel approaches to pre-training translation models that involve different levels of lexical and structural knowledge, including: 1) generating obfuscated data from a large parallel corpus 2) concatenating phrase pairs extracted from a small word-aligned corpus, and 3) generating synthetic parallel data without real human language corpora. Our experiments on multiple language pairs reveal that pre-training benefits can be realized even with high levels of obfuscation or purely synthetic parallel data. We hope the findings from our comprehensive empirical analysis will shed light on understanding what matters for NMT pre-training, as well as pave the way for the development of more efficient and less toxic models.",,,,, ,  Findings of the Association for Computational Linguistics: ACL 2023,,out_of_scope,
3650,"**Title**Analyzing Norm Violations in Live-Stream Chat

**Abstract**Toxic language, such as hate speech, can deter users from participating in online communities and enjoying popular platforms. Previous approaches to detecting toxic language and norm violations have been primarily concerned with conversations from online forums and social media, such as Reddit and Twitter. These approaches are less effective when applied to conversations on live-streaming platforms, such as Twitch and YouTube Live, as each comment is only visible for a limited time and lacks a thread structure that establishes its relationship with other comments. In this work, we share the first NLP study dedicated to detecting norm violations in conversations on live-streaming platforms. We define norm violation categories in live-stream chats and annotate 4,583 moderated comments from Twitch. We articulate several facets of live-stream data that differ from other forums, and demonstrate that existing models perform poorly in this setting. By conducting a user study, we identify the informational context humans use in live-stream moderation, and train models leveraging context to identify norm violations. Our results show that appropriate contextual information can boost moderation performance by 35{\%}.","Moon, Jihyung, Lee, Dong-Ho, Cho, Hyundong, Jin, Woojeong, Park, Chan, Kim, Minwoo, May, Jonathan, Pujara, Jay, Park, Sungjoon",,,Analyzing Norm Violations in Live-Stream Chat,,,10.18653/v1/2023.emnlp-main.55 , ,,"Toxic language, such as hate speech, can deter users from participating in online communities and enjoying popular platforms. Previous approaches to detecting toxic language and norm violations have been primarily concerned with conversations from online forums and social media, such as Reddit and Twitter. These approaches are less effective when applied to conversations on live-streaming platforms, such as Twitch and YouTube Live, as each comment is only visible for a limited time and lacks a thread structure that establishes its relationship with other comments. In this work, we share the first NLP study dedicated to detecting norm violations in conversations on live-streaming platforms. We define norm violation categories in live-stream chats and annotate 4,583 moderated comments from Twitch. We articulate several facets of live-stream data that differ from other forums, and demonstrate that existing models perform poorly in this setting. By conducting a user study, we identify the informational context humans use in live-stream moderation, and train models leveraging context to identify norm violations. Our results show that appropriate contextual information can boost moderation performance by 35{\%}.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,detection,
3651,"**Title**Inference-Time Policy Adapters ({IPA}): Tailoring Extreme-Scale {LM}s without Fine-tuning

**Abstract**While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.","Lu, Ximing, Brahman, Faeze, West, Peter, Jung, Jaehun, Chandu, Khyathi, Ravichander, Abhilasha, Ammanabrolu, Prithviraj, Jiang, Liwei, Ramnath, Sahana, Dziri, Nouha, Fisher, Jillian, Lin, Bill, Hallinan, Skyler, Qin, Lianhui, Ren, Xiang, Welleck, Sean, Choi, Yejin",,,Inference-Time Policy Adapters ({IPA}): Tailoring Extreme-Scale {LM}s without Fine-tuning,,,10.18653/v1/2023.emnlp-main.424 , ,,"While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,detox,
3652,"**Title**Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study

**Abstract**Large decoder-only language models (LMs) can be largely improved in terms of perplexity by retrieval (e.g., RETRO), but its impact on text generation quality and downstream task accuracy is unclear. Thus, it is still an open question: shall we pretrain large autoregressive LMs with retrieval? To answer it, we perform a comprehensive study on a scalable pre-trained retrieval-augmented LM (i.e., RETRO) compared with standard GPT and retrieval-augmented GPT incorporated at fine-tuning or inference stages. We first provide the recipe to reproduce RETRO up to 9.5B parameters while retrieving a text corpus with 330B tokens. Based on that, we have the following novel findings: i) RETRO outperforms GPT on text generation with much less degeneration (i.e., repetition), moderately higher factual accuracy, and slightly lower toxicity with a nontoxic retrieval database. ii) On the LM Evaluation Harness benchmark, RETRO largely outperforms GPT on knowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore, we introduce a simple variant of the model, RETRO++, which largely improves open-domain QA results of original RETRO (e.g., EM score +8.6 on Natural Question) and significantly outperforms retrieval-augmented GPT across different model sizes. Our findings highlight the promising direction of pretraining autoregressive LMs with retrieval as future foundation models. We release our implementation at: https://github.com/NVIDIA/Megatron-LM/tree/main/tools/retro.","Wang, Boxin, Ping, Wei, Xu, Peng, McAfee, Lawrence, Liu, Zihan, Shoeybi, Mohammad, Dong, Yi, Kuchaiev, Oleksii, Li, Bo, Xiao, Chaowei, Anandkumar, Anima, Catanzaro, Bryan",,,Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study,,,10.18653/v1/2023.emnlp-main.482 , ,,"Large decoder-only language models (LMs) can be largely improved in terms of perplexity by retrieval (e.g., RETRO), but its impact on text generation quality and downstream task accuracy is unclear. Thus, it is still an open question: shall we pretrain large autoregressive LMs with retrieval? To answer it, we perform a comprehensive study on a scalable pre-trained retrieval-augmented LM (i.e., RETRO) compared with standard GPT and retrieval-augmented GPT incorporated at fine-tuning or inference stages. We first provide the recipe to reproduce RETRO up to 9.5B parameters while retrieving a text corpus with 330B tokens. Based on that, we have the following novel findings: i) RETRO outperforms GPT on text generation with much less degeneration (i.e., repetition), moderately higher factual accuracy, and slightly lower toxicity with a nontoxic retrieval database. ii) On the LM Evaluation Harness benchmark, RETRO largely outperforms GPT on knowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore, we introduce a simple variant of the model, RETRO++, which largely improves open-domain QA results of original RETRO (e.g., EM score +8.6 on Natural Question) and significantly outperforms retrieval-augmented GPT across different model sizes. Our findings highlight the promising direction of pretraining autoregressive LMs with retrieval as future foundation models. We release our implementation at: https://github.com/NVIDIA/Megatron-LM/tree/main/tools/retro.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3653,"**Title**{G}lobal {V}oices, Local Biases: Socio-Cultural Prejudices across Languages

**Abstract**Human biases are ubiquitous but not uniform: disparities exist across linguistic, cultural, and societal borders. As large amounts of recent literature suggest, language models (LMs) trained on human data can reflect and often amplify the effects of these social biases. However, the vast majority of existing studies on bias are heavily skewed towards Western and European languages. In this work, we scale the Word Embedding Association Test (WEAT) to 24 languages, enabling broader studies and yielding interesting findings about LM bias. We additionally enhance this data with culturally relevant information for each language, capturing local contexts on a global scale. Further, to encompass more widely prevalent societal biases, we examine new bias dimensions across toxicity, ableism, and more. Moreover, we delve deeper into the Indian linguistic landscape, conducting a comprehensive regional bias analysis across six prevalent Indian languages. Finally, we highlight the significance of these social biases and the new dimensions through an extensive comparison of embedding methods, reinforcing the need to address them in pursuit of more equitable language models.","Mukherjee, Anjishnu, Raj, Chahat, Zhu, Ziwei, Anastasopoulos, Antonios",,,"{G}lobal {V}oices, Local Biases: Socio-Cultural Prejudices across Languages",,,10.18653/v1/2023.emnlp-main.981 , ,,"Human biases are ubiquitous but not uniform: disparities exist across linguistic, cultural, and societal borders. As large amounts of recent literature suggest, language models (LMs) trained on human data can reflect and often amplify the effects of these social biases. However, the vast majority of existing studies on bias are heavily skewed towards Western and European languages. In this work, we scale the Word Embedding Association Test (WEAT) to 24 languages, enabling broader studies and yielding interesting findings about LM bias. We additionally enhance this data with culturally relevant information for each language, capturing local contexts on a global scale. Further, to encompass more widely prevalent societal biases, we examine new bias dimensions across toxicity, ableism, and more. Moreover, we delve deeper into the Indian linguistic landscape, conducting a comprehensive regional bias analysis across six prevalent Indian languages. Finally, we highlight the significance of these social biases and the new dimensions through an extensive comparison of embedding methods, reinforcing the need to address them in pursuit of more equitable language models.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,,out_but_toxicity,
3654,"**Title**Muted: Multilingual Targeted Offensive Speech Identification and Visualization

**Abstract**Offensive language such as hate, abuse, and profanity (HAP) occurs in various content on the web. While previous work has mostly dealt with sentence level annotations, there have been a few recent attempts to identify offensive spans as well. We build upon this work and introduce MUTED, a system to identify multilingual HAP content by displaying offensive arguments and their targets using heat maps to indicate their intensity. MUTED can leverage any transformer-based HAP-classification model and its attention mechanism out-of-the-box to identify toxic spans, without further fine-tuning. In addition, we use the spaCy library to identify the specific targets and arguments for the words predicted by the attention heatmaps. We present the model`s performance on identifying offensive spans and their targets in existing datasets and present new annotations on German text. Finally, we demonstrate our proposed visualization tool on multilingual inputs.","Tillmann, Christoph, Trivedi, Aashka, Rosenthal, Sara, Borse, Santosh, Zhang, Rong, Sil, Avirup, Bhattacharjee, Bishwaranjan",,,Muted: Multilingual Targeted Offensive Speech Identification and Visualization,,,10.18653/v1/2023.emnlp-demo.19 , ,,"Offensive language such as hate, abuse, and profanity (HAP) occurs in various content on the web. While previous work has mostly dealt with sentence level annotations, there have been a few recent attempts to identify offensive spans as well. We build upon this work and introduce MUTED, a system to identify multilingual HAP content by displaying offensive arguments and their targets using heat maps to indicate their intensity. MUTED can leverage any transformer-based HAP-classification model and its attention mechanism out-of-the-box to identify toxic spans, without further fine-tuning. In addition, we use the spaCy library to identify the specific targets and arguments for the words predicted by the attention heatmaps. We present the model`s performance on identifying offensive spans and their targets in existing datasets and present new annotations on German text. Finally, we demonstrate our proposed visualization tool on multilingual inputs.",,,,, ,  Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,,out_but_toxicity,
3655,"**Title**Everything you need to know about Multilingual {LLM}s: Towards fair, performant and reliable models for languages of the world

**Abstract**This tutorial will describe various aspects of scaling up language technologies to many of the world`s languages by describing the latest research in Massively Multilingual Language Models (MMLMs). We will cover topics such as data collection, training and fine-tuning of models, Responsible AI issues such as fairness, bias and toxicity, linguistic diversity and evaluation in the context of MMLMs, specifically focusing on issues in non-English and low-resource languages. Further, we will also talk about some of the real-world challenges in deploying these models in language communities in the field. With the performance of MMLMs improving in the zero-shot setting for many languages, it is now becoming feasible to use them for building language technologies in many languages of the world, and this tutorial will provide the computational linguistics community with unique insights from the latest research in multilingual models.","Sitaram, Sunayana, Choudhury, Monojit, Patra, Barun, Chaudhary, Vishrav, Ahuja, Kabir, Bali, Kalika",,,"Everything you need to know about Multilingual {LLM}s: Towards fair, performant and reliable models for languages of the world",,,10.18653/v1/2023.acl-tutorials.3 , ,,"This tutorial will describe various aspects of scaling up language technologies to many of the world`s languages by describing the latest research in Massively Multilingual Language Models (MMLMs). We will cover topics such as data collection, training and fine-tuning of models, Responsible AI issues such as fairness, bias and toxicity, linguistic diversity and evaluation in the context of MMLMs, specifically focusing on issues in non-English and low-resource languages. Further, we will also talk about some of the real-world challenges in deploying these models in language communities in the field. With the performance of MMLMs improving in the zero-shot setting for many languages, it is now becoming feasible to use them for building language technologies in many languages of the world, and this tutorial will provide the computational linguistics community with unique insights from the latest research in multilingual models.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 6: Tutorial Abstracts),,out_but_toxicity,
3656,"**Title**{S}afe{C}onv: Explaining and Correcting Conversational Unsafe Behavior

**Abstract**One of the main challenges open-domain end-to-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior. In this work, we construct a new dataset called SafeConv for the research of conversational safety: (1) Besides the utterance-level safety labels, SafeConv also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SafeConv provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SafeConv, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots. Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The dataset is available at \url{https://github.com/mianzhang/SafeConv}.","Zhang, Mian, Jin, Lifeng, Song, Linfeng, Mi, Haitao, Chen, Wenliang, Yu, Dong",,,{S}afe{C}onv: Explaining and Correcting Conversational Unsafe Behavior,,,10.18653/v1/2023.acl-long.2 , ,,"One of the main challenges open-domain end-to-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior. In this work, we construct a new dataset called SafeConv for the research of conversational safety: (1) Besides the utterance-level safety labels, SafeConv also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SafeConv provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SafeConv, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots. Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent. The dataset is available at \url{https://github.com/mianzhang/SafeConv}.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,Gen_dataset#detox,
3657,"**Title**Improving the Detection of Multilingual Online Attacks with Rich Social Media Data from {S}ingapore

**Abstract**Toxic content is a global problem, but most resources for detecting toxic content are in English. When datasets are created in other languages, they often focus exclusively on one language or dialect. In many cultural and geographical settings, however, it is common to code-mix languages, combining and interchanging them throughout conversations. To shine a light on this practice, and enable more research into code-mixed toxic content, we introduce SOA, a new multilingual dataset of online attacks. Using the multilingual city-state of Singapore as a starting point, we collect a large corpus of Reddit comments in Indonesian, Malay, Singlish, and other languages, and provide fine-grained hierarchical labels for online attacks. We publish the corpus with rich metadata, as well as additional unlabelled data for domain adaptation. We share comprehensive baseline results, show how the metadata can be used for granular error analysis, and demonstrate the benefits of domain adaptation for detecting multilingual online attacks.","Haber, Janosch, Vidgen, Bertie, Chapman, Matthew, Agarwal, Vibhor, Lee, Roy Ka-Wei, Yap, Yong Keong, R{\""o}ttger, Paul",,,Improving the Detection of Multilingual Online Attacks with Rich Social Media Data from {S}ingapore,,,10.18653/v1/2023.acl-long.711 , ,,"Toxic content is a global problem, but most resources for detecting toxic content are in English. When datasets are created in other languages, they often focus exclusively on one language or dialect. In many cultural and geographical settings, however, it is common to code-mix languages, combining and interchanging them throughout conversations. To shine a light on this practice, and enable more research into code-mixed toxic content, we introduce SOA, a new multilingual dataset of online attacks. Using the multilingual city-state of Singapore as a starting point, we collect a large corpus of Reddit comments in Indonesian, Malay, Singlish, and other languages, and provide fine-grained hierarchical labels for online attacks. We publish the corpus with rich metadata, as well as additional unlabelled data for domain adaptation. We share comprehensive baseline results, show how the metadata can be used for granular error analysis, and demonstrate the benefits of domain adaptation for detecting multilingual online attacks.",,,,, ,  Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_but_toxicity,
3658,"**Title**Leveraging Dependency Grammar for Fine-Grained Offensive Language Detection using Graph Convolutional Networks

**Abstract**The last few years have witnessed an exponential rise in the propagation of offensive text on social media. Identification of this text with high precision is crucial for the well-being of society. Most of the existing approaches tend to give high toxicity scores to innocuous statements (e.g., {\textquotedblleft}I am a gay man{\textquotedblright}). These false positives result from over-generalization on the training data where specific terms in the statement may have been used in a pejorative sense (e.g., {\textquotedblleft}gay{\textquotedblright}). Emphasis on such words alone can lead to discrimination against the classes these systems are designed to protect. In this paper, we address the problem of offensive language detection on Twitter, while also detecting the type and the target of the offense. We propose a novel approach called SyLSTM, which integrates syntactic features in the form of the dependency parse tree of a sentence and semantic features in the form of word embeddings into a deep learning architecture using a Graph Convolutional Network. Results show that the proposed approach significantly outperforms the state-of-the-art BERT model with orders of magnitude fewer number of parameters.","Goel, Divyam, Sharma, Raksha",,,Leveraging Dependency Grammar for Fine-Grained Offensive Language Detection using Graph Convolutional Networks,,,10.18653/v1/2022.socialnlp-1.4 , ,,"The last few years have witnessed an exponential rise in the propagation of offensive text on social media. Identification of this text with high precision is crucial for the well-being of society. Most of the existing approaches tend to give high toxicity scores to innocuous statements (e.g., {\textquotedblleft}I am a gay man{\textquotedblright}). These false positives result from over-generalization on the training data where specific terms in the statement may have been used in a pejorative sense (e.g., {\textquotedblleft}gay{\textquotedblright}). Emphasis on such words alone can lead to discrimination against the classes these systems are designed to protect. In this paper, we address the problem of offensive language detection on Twitter, while also detecting the type and the target of the offense. We propose a novel approach called SyLSTM, which integrates syntactic features in the form of the dependency parse tree of a sentence and semantic features in the form of word embeddings into a deep learning architecture using a Graph Convolutional Network. Results show that the proposed approach significantly outperforms the state-of-the-art BERT model with orders of magnitude fewer number of parameters.",,,,, ,  Proceedings of the Tenth International Workshop on Natural Language Processing for Social Media,,detection,
3659,"**Title**Guiding the Release of Safer {E}2{E} Conversational {AI} through Value Sensitive Design

**Abstract**Over the last several years, end-to-end neural conversational agents have vastly improved their ability to carry unrestricted, open-domain conversations with humans. However, these models are often trained on large datasets from the Internet and, as a result, may learn undesirable behaviours from this data, such as toxic or otherwise harmful language. Thus, researchers must wrestle with how and when to release these models. In this paper, we survey recent and related work to highlight tensions between values, potential positive impact, and potential harms. We also provide a framework to support practitioners in deciding whether and how to release these models, following the tenets of value-sensitive design.","Bergman, A. Stevie, Abercrombie, Gavin, Spruit, Shannon, Hovy, Dirk, Dinan, Emily, Boureau, Y-Lan, Rieser, Verena",,,Guiding the Release of Safer {E}2{E} Conversational {AI} through Value Sensitive Design,,,10.18653/v1/2022.sigdial-1.4 , ,,"Over the last several years, end-to-end neural conversational agents have vastly improved their ability to carry unrestricted, open-domain conversations with humans. However, these models are often trained on large datasets from the Internet and, as a result, may learn undesirable behaviours from this data, such as toxic or otherwise harmful language. Thus, researchers must wrestle with how and when to release these models. In this paper, we survey recent and related work to highlight tensions between values, potential positive impact, and potential harms. We also provide a framework to support practitioners in deciding whether and how to release these models, following the tenets of value-sensitive design.",,,,, ,  Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue,,survey,
3660,"**Title**{GUTS} at {S}em{E}val-2022 Task 4: Adversarial Training and Balancing Methods for Patronizing and Condescending Language Detection

**Abstract**Patronizing and Condescending Language (PCL) towards vulnerable communities in general media has been shown to have potentially harmful effects. Due to its subtlety and the good intentions behind its use, the audience is not aware of the language`s toxicity. In this paper, we present our method for the SemEval-2022 Task4 titled {\textquotedblleft}Patronizing and Condescending Language Detection{\textquotedblright}. In Subtask A, a binary classification task, we introduce adversarial training based on Fast Gradient Method (FGM) and employ pre-trained model in a unified architecture. For Subtask B, framed as a multi-label classification problem, we utilize various improved multi-label cross-entropy loss functions and analyze the performance of our method. In the final evaluation, our system achieved official rankings of 17/79 and 16/49 on Subtask A and Subtask B, respectively. In addition, we explore the relationship between PCL and emotional polarity and intensity it contains.","Lu, Junyu, Zhang, Hao, Zhang, Tongyue, Wang, Hongbo, Zhu, Haohao, Xu, Bo, Lin, Hongfei",,,{GUTS} at {S}em{E}val-2022 Task 4: Adversarial Training and Balancing Methods for Patronizing and Condescending Language Detection,,,10.18653/v1/2022.semeval-1.58 , ,,"Patronizing and Condescending Language (PCL) towards vulnerable communities in general media has been shown to have potentially harmful effects. Due to its subtlety and the good intentions behind its use, the audience is not aware of the language`s toxicity. In this paper, we present our method for the SemEval-2022 Task4 titled {\textquotedblleft}Patronizing and Condescending Language Detection{\textquotedblright}. In Subtask A, a binary classification task, we introduce adversarial training based on Fast Gradient Method (FGM) and employ pre-trained model in a unified architecture. For Subtask B, framed as a multi-label classification problem, we utilize various improved multi-label cross-entropy loss functions and analyze the performance of our method. In the final evaluation, our system achieved official rankings of 17/79 and 16/49 on Subtask A and Subtask B, respectively. In addition, we explore the relationship between PCL and emotional polarity and intensity it contains.",,,,, ,  Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022),,detection,
3661,"**Title**Measuring Harmful Representations in {S}candinavian Language Models

**Abstract**Scandinavian countries are perceived as role-models when it comes to gender equality. With the advent of pre-trained language models and their widespread usage, we investigate to what extent gender-based harmful and toxic content exists in selected Scandinavian language models. We examine nine models, covering Danish, Swedish, and Norwegian, by manually creating template-based sentences and probing the models for completion. We evaluate the completions using two methods for measuring harmful and toxic completions and provide a thorough analysis of the results. We show that Scandinavian pre-trained language models contain harmful and gender-based stereotypes with similar values across all languages. This finding goes against the general expectations related to gender equality in Scandinavian countries and shows the possible problematic outcomes of using such models in real-world settings. Warning: Some of the examples provided in this paper can be upsetting and offensive.","Touileb, Samia, Nozza, Debora",,,Measuring Harmful Representations in {S}candinavian Language Models,,,10.18653/v1/2022.nlpcss-1.13 , ,,"Scandinavian countries are perceived as role-models when it comes to gender equality. With the advent of pre-trained language models and their widespread usage, we investigate to what extent gender-based harmful and toxic content exists in selected Scandinavian language models. We examine nine models, covering Danish, Swedish, and Norwegian, by manually creating template-based sentences and probing the models for completion. We evaluate the completions using two methods for measuring harmful and toxic completions and provide a thorough analysis of the results. We show that Scandinavian pre-trained language models contain harmful and gender-based stereotypes with similar values across all languages. This finding goes against the general expectations related to gender equality in Scandinavian countries and shows the possible problematic outcomes of using such models in real-world settings. Warning: Some of the examples provided in this paper can be upsetting and offensive.",,,,, ,  Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS),,out_but_toxicity,
3662,"**Title**{G}er{CCT}: An Annotated Corpus for Mining Arguments in {G}erman Tweets on Climate Change

**Abstract**While the field of argument mining has grown notably in the last decade, research on the Twitter medium remains relatively understudied. Given the difficulty of mining arguments in tweets, recent work on creating annotated resources mainly utilized simplified annotation schemes that focus on single argument components, i.e., on claim or evidence. In this paper we strive to fill this research gap by presenting GerCCT, a new corpus of German tweets on climate change, which was annotated for a set of different argument components and properties. Additionally, we labelled sarcasm and toxic language to facilitate the development of tools for filtering out non-argumentative content. This, to the best of our knowledge, renders our corpus the first tweet resource annotated for argumentation, sarcasm and toxic language. We show that a comparatively complex annotation scheme can still yield promising inter-annotator agreement. We further present first good supervised classification results yielded by a fine-tuned BERT architecture.","Schaefer, Robin, Stede, Manfred",,,{G}er{CCT}: An Annotated Corpus for Mining Arguments in {G}erman Tweets on Climate Change,,, , ,,"While the field of argument mining has grown notably in the last decade, research on the Twitter medium remains relatively understudied. Given the difficulty of mining arguments in tweets, recent work on creating annotated resources mainly utilized simplified annotation schemes that focus on single argument components, i.e., on claim or evidence. In this paper we strive to fill this research gap by presenting GerCCT, a new corpus of German tweets on climate change, which was annotated for a set of different argument components and properties. Additionally, we labelled sarcasm and toxic language to facilitate the development of tools for filtering out non-argumentative content. This, to the best of our knowledge, renders our corpus the first tweet resource annotated for argumentation, sarcasm and toxic language. We show that a comparatively complex annotation scheme can still yield promising inter-annotator agreement. We further present first good supervised classification results yielded by a fine-tuned BERT architecture.",,,,, ,  Proceedings of the Thirteenth Language Resources and Evaluation Conference,,out_but_toxicity,
3663,"**Title**Nearest Neighbor Language Models for Stylistic Controllable Generation

**Abstract**Recent language modeling performance has been greatly improved by the use of external memory. This memory encodes the context so that similar contexts can be recalled during decoding. This similarity depends on how the model learns to encode context, which can be altered to include other attributes, such as style. We construct and evaluate an architecture for this purpose, using corpora annotated for politeness, formality, and toxicity. Through extensive experiments and human evaluation we demonstrate the potential of our method to generate text while controlling style. We find that style-specific datastores improve generation performance, though results vary greatly across styles, and the effect of pretraining data and specific styles should be explored in future work.","Trotta, Severino, Flek, Lucie, Welch, Charles",,,Nearest Neighbor Language Models for Stylistic Controllable Generation,,,10.18653/v1/2022.gem-1.25 , ,,"Recent language modeling performance has been greatly improved by the use of external memory. This memory encodes the context so that similar contexts can be recalled during decoding. This similarity depends on how the model learns to encode context, which can be altered to include other attributes, such as style. We construct and evaluate an architecture for this purpose, using corpora annotated for politeness, formality, and toxicity. Through extensive experiments and human evaluation we demonstrate the potential of our method to generate text while controlling style. We find that style-specific datastores improve generation performance, though results vary greatly across styles, and the effect of pretraining data and specific styles should be explored in future work.",,,,, ,"  Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",,detox,
3664,"**Title**Towards Identifying Social Bias in Dialog Systems: Framework, Dataset, and Benchmark

**Abstract**Among all the safety concerns that hinder the deployment of open-domain dialog systems (e.g., offensive languages, biases, and toxic behaviors), social bias presents an insidious challenge. Addressing this challenge requires rigorous analyses and normative reasoning. In this paper, we focus our investigation on social bias measurement to facilitate the development of unbiased dialog systems. We first propose a novel Dial-Bias Framework for analyzing the social bias in conversations using a holistic method beyond bias lexicons or dichotomous annotations. Leveraging the proposed framework, we further introduce the CDial-Bias Dataset which is, to the best of our knowledge, the first annotated Chinese social bias dialog dataset. We also establish a fine-grained dialog bias measurement benchmark and conduct in-depth ablation studies to shed light on the utility of the detailed annotations in the proposed dataset. Finally, we evaluate representative Chinese generative models with our classifiers to unveil the presence of social bias in these systems.","Zhou, Jingyan, Deng, Jiawen, Mi, Fei, Li, Yitong, Wang, Yasheng, Huang, Minlie, Jiang, Xin, Liu, Qun, Meng, Helen",,,"Towards Identifying Social Bias in Dialog Systems: Framework, Dataset, and Benchmark",,,10.18653/v1/2022.findings-emnlp.262 , ,,"Among all the safety concerns that hinder the deployment of open-domain dialog systems (e.g., offensive languages, biases, and toxic behaviors), social bias presents an insidious challenge. Addressing this challenge requires rigorous analyses and normative reasoning. In this paper, we focus our investigation on social bias measurement to facilitate the development of unbiased dialog systems. We first propose a novel Dial-Bias Framework for analyzing the social bias in conversations using a holistic method beyond bias lexicons or dichotomous annotations. Leveraging the proposed framework, we further introduce the CDial-Bias Dataset which is, to the best of our knowledge, the first annotated Chinese social bias dialog dataset. We also establish a fine-grained dialog bias measurement benchmark and conduct in-depth ablation studies to shed light on the utility of the detailed annotations in the proposed dataset. Finally, we evaluate representative Chinese generative models with our classifiers to unveil the presence of social bias in these systems.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2022,,out_but_toxicity,
3665,"**Title**Towards Robust {NLG} Bias Evaluation with Syntactically-diverse Prompts

**Abstract**We present a robust methodology for evaluating biases in natural language generation(NLG) systems. Previous works use fixed hand-crafted prefix templates with mentions of various demographic groups to prompt models to generate continuations for bias analysis. These fixed prefix templates could themselves be specific in terms of styles or linguistic structures, which may lead to unreliable fairness conclusions that are not representative of the general trends from tone varying prompts. To study this problem, we paraphrase the prompts with different syntactic structures and use these to evaluate demographic bias in NLG systems. Our results suggest similar overall bias trends but some syntactic structures lead to contradictory conclusions compared to past works. We show that our methodology is more robust and that some syntactic structures prompt more toxic content while others could prompt less biased generation. This suggests the importance of not relying on a fixed syntactic structure and using tone-invariant prompts. Introducing syntactically-diverse prompts can achieve more robust NLG (bias) evaluation.","Aggarwal, Arshiya, Sun, Jiao, Peng, Nanyun",,,Towards Robust {NLG} Bias Evaluation with Syntactically-diverse Prompts,,,10.18653/v1/2022.findings-emnlp.445 , ,,"We present a robust methodology for evaluating biases in natural language generation(NLG) systems. Previous works use fixed hand-crafted prefix templates with mentions of various demographic groups to prompt models to generate continuations for bias analysis. These fixed prefix templates could themselves be specific in terms of styles or linguistic structures, which may lead to unreliable fairness conclusions that are not representative of the general trends from tone varying prompts. To study this problem, we paraphrase the prompts with different syntactic structures and use these to evaluate demographic bias in NLG systems. Our results suggest similar overall bias trends but some syntactic structures lead to contradictory conclusions compared to past works. We show that our methodology is more robust and that some syntactic structures prompt more toxic content while others could prompt less biased generation. This suggests the importance of not relying on a fixed syntactic structure and using tone-invariant prompts. Introducing syntactically-diverse prompts can achieve more robust NLG (bias) evaluation.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2022,,evaluation#methodology,
3666,"**Title**{P}a{C}o: Preconditions Attributed to Commonsense Knowledge

**Abstract**Humans can seamlessly reason with circumstantial preconditions of commonsense knowledge. We understand that a glass is used for drinking water, unless the glass is broken or the water is toxic. Despite state-of-the-art (SOTA) language models' (LMs) impressive performance on inferring commonsense knowledge, it is unclear whether they understand the circumstantial preconditions. To address this gap, we propose a novel challenge of reasoning with circumstantial preconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand preconditions of commonsense statements expressed in natural language. Based on this dataset, we create three canonical evaluation tasks and use them to examine the capability of existing LMs to understand situational preconditions. Our results reveal a 10-30{\%} gap between machine and human performance on our tasks, which shows that reasoning with preconditions is an open challenge.","Qasemi, Ehsan, Ilievski, Filip, Chen, Muhao, Szekely, Pedro",,,{P}a{C}o: Preconditions Attributed to Commonsense Knowledge,,,10.18653/v1/2022.findings-emnlp.505 , ,,"Humans can seamlessly reason with circumstantial preconditions of commonsense knowledge. We understand that a glass is used for drinking water, unless the glass is broken or the water is toxic. Despite state-of-the-art (SOTA) language models' (LMs) impressive performance on inferring commonsense knowledge, it is unclear whether they understand the circumstantial preconditions. To address this gap, we propose a novel challenge of reasoning with circumstantial preconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand preconditions of commonsense statements expressed in natural language. Based on this dataset, we create three canonical evaluation tasks and use them to examine the capability of existing LMs to understand situational preconditions. Our results reveal a 10-30{\%} gap between machine and human performance on our tasks, which shows that reasoning with preconditions is an open challenge.",,,,, ,  Findings of the Association for Computational Linguistics: EMNLP 2022,,out_of_scope,
3667,"**Title**Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space

**Abstract**Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50{\%}, and for improving computation efficiency with a simple early exit rule, saving 20{\%} of computation on average.","Geva, Mor, Caciularu, Avi, Wang, Kevin, Goldberg, Yoav",,,Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space,,,10.18653/v1/2022.emnlp-main.3 , ,,"Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50{\%}, and for improving computation efficiency with a simple early exit rule, saving 20{\%} of computation on average.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,,detox,
3668,"**Title**Gradient-based Constrained Sampling from Language Models

**Abstract**Large pretrained language models are successful at generating fluent text but are notoriously hard to controllably sample from. In this work, we study constrained sampling from such language models, i.e., generating text that satisfies user-defined constraints, while maintaining fluency and model`s performance in a downstream task. We propose MuCoLa{---}a sampling procedure that combines the log-likelihood of the language model with arbitrary (differentiable) constraints in a single energy function, and then generates samples in a non-autoregressive manner. Specifically, it initializes the entire output sequence with noise and follows a Markov chain defined by Langevin Dynamics using the gradients of this energy. We evaluate MuCoLa on text generation with soft and hard constraints as well as their combinations, obtaining significant improvements over competitive baselines for toxicity avoidance, sentiment control, and keyword-guided generation.","Kumar, Sachin, Paria, Biswajit, Tsvetkov, Yulia",,,Gradient-based Constrained Sampling from Language Models,,,10.18653/v1/2022.emnlp-main.144 , ,,"Large pretrained language models are successful at generating fluent text but are notoriously hard to controllably sample from. In this work, we study constrained sampling from such language models, i.e., generating text that satisfies user-defined constraints, while maintaining fluency and model`s performance in a downstream task. We propose MuCoLa{---}a sampling procedure that combines the log-likelihood of the language model with arbitrary (differentiable) constraints in a single energy function, and then generates samples in a non-autoregressive manner. Specifically, it initializes the entire output sequence with noise and follows a Markov chain defined by Langevin Dynamics using the gradients of this energy. We evaluate MuCoLa on text generation with soft and hard constraints as well as their combinations, obtaining significant improvements over competitive baselines for toxicity avoidance, sentiment control, and keyword-guided generation.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,,detox,
3669,"**Title**{P}rosocial{D}ialog: A Prosocial Backbone for Conversational Agents

**Abstract**Most existing dialogue systems fail to respond properly to potentially unsafe user utterances by either ignoring or passively agreeing with them. To address this issue, we introduce ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue safety labels accompanied by free-form rationales.With this dataset, we introduce a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost. Empirical results show that Prost generates more socially acceptable dialogues compared to other state-of-the-art language and dialogue models in both in-domain and out-of-domain settings. Additionally, Canary effectively guides conversational agents and off-the-shelf language models to generate significantly more prosocial responses. Our work highlights the promise and importance of creating and steering conversational AI to be socially responsible.","Kim, Hyunwoo, Yu, Youngjae, Jiang, Liwei, Lu, Ximing, Khashabi, Daniel, Kim, Gunhee, Choi, Yejin, Sap, Maarten",,,{P}rosocial{D}ialog: A Prosocial Backbone for Conversational Agents,,,10.18653/v1/2022.emnlp-main.267 , ,,"Most existing dialogue systems fail to respond properly to potentially unsafe user utterances by either ignoring or passively agreeing with them. To address this issue, we introduce ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue safety labels accompanied by free-form rationales.With this dataset, we introduce a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost. Empirical results show that Prost generates more socially acceptable dialogues compared to other state-of-the-art language and dialogue models in both in-domain and out-of-domain settings. Additionally, Canary effectively guides conversational agents and off-the-shelf language models to generate significantly more prosocial responses. Our work highlights the promise and importance of creating and steering conversational AI to be socially responsible.",,,,, ,  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,,Gen_dataset#detox,
3670,"**Title**Aanisha@{T}amil{NLP}-{ACL}2022:Abusive Detection in {T}amil

**Abstract**In social media, there are instances where people present their opinions in strong language, resorting to abusive/toxic comments. There are instances of communal hatred, hate-speech, toxicity and bullying. And, in this age of social media, it`s very important to find means to keep check on these toxic comments, as to preserve the mental peace of people in social media. While there are tools, models to detect andpotentially filter these kind of content, developing these kinds of models for the low resource language space is an issue of research. In this paper, the task of abusive comment identification in Tamil language, is seen upon as a multi-class classification problem. There are different pre-processing as well as modelling approaches discussed in this paper. The different approaches are compared on the basis of weighted average accuracy.","Bhattacharyya, Aanisha",,,Aanisha@{T}amil{NLP}-{ACL}2022:Abusive Detection in {T}amil,,,10.18653/v1/2022.dravidianlangtech-1.33 , ,,"In social media, there are instances where people present their opinions in strong language, resorting to abusive/toxic comments. There are instances of communal hatred, hate-speech, toxicity and bullying. And, in this age of social media, it`s very important to find means to keep check on these toxic comments, as to preserve the mental peace of people in social media. While there are tools, models to detect andpotentially filter these kind of content, developing these kinds of models for the low resource language space is an issue of research. In this paper, the task of abusive comment identification in Tamil language, is seen upon as a multi-class classification problem. There are different pre-processing as well as modelling approaches discussed in this paper. The different approaches are compared on the basis of weighted average accuracy.",,,,, ,  Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,,out_but_toxicity,
3671,"**Title**Quantifying Bias from Decoding Techniques in Natural Language Generation

**Abstract**Natural language generation (NLG) models can propagate social bias towards particular demography. Though several studies investigated bias from data and model, NLG task distinctively uses stochastic decoder that can positively or negatively impact the bias-sensitive tokens initially predicted by the model. To address this gap in research, we present an extensive analysis of bias from decoding techniques for open-domain language generation considering the entire decoding space. We analyze to what extent bias metrics like toxicity and sentiment are impacted by the individual components of decoder algorithms. To this extent, we also analyze the trade-off between bias scores and human-annotated generation quality throughout the decoder space. Together, these methods reveal the imperative of testing inference time bias and provide evidence on the usefulness of inspecting the entire decoding spectrum.","Das, Mayukh, Balke, Wolf Tilo",,,Quantifying Bias from Decoding Techniques in Natural Language Generation,,, , ,,"Natural language generation (NLG) models can propagate social bias towards particular demography. Though several studies investigated bias from data and model, NLG task distinctively uses stochastic decoder that can positively or negatively impact the bias-sensitive tokens initially predicted by the model. To address this gap in research, we present an extensive analysis of bias from decoding techniques for open-domain language generation considering the entire decoding space. We analyze to what extent bias metrics like toxicity and sentiment are impacted by the individual components of decoder algorithms. To this extent, we also analyze the trade-off between bias scores and human-annotated generation quality throughout the decoder space. Together, these methods reveal the imperative of testing inference time bias and provide evidence on the usefulness of inspecting the entire decoding spectrum.",,,,, ,  Proceedings of the 29th International Conference on Computational Linguistics,,detection,
3672,"**Title**{P}rimum {N}on {N}ocere: {B}efore working with {I}ndigenous data, the {ACL} must confront ongoing colonialism

**Abstract**In this paper, we challenge the ACL community to reckon with historical and ongoing colonialism by adopting a set of ethical obligations and best practices drawn from the Indigenous studies literature. While the vast majority of NLP research focuses on a very small number of very high resource languages (English, Chinese, etc), some work has begun to engage with Indigenous languages. No research involving Indigenous language data can be considered ethical without first acknowledging that Indigenous languages are not merely very low resource languages. The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside researchers. To this end, we propose that the ACL draft and adopt an ethical framework for NLP researchers and computational linguists wishing to engage in research involving Indigenous languages.","Schwartz, Lane",,,"{P}rimum {N}on {N}ocere: {B}efore working with {I}ndigenous data, the {ACL} must confront ongoing colonialism",,,10.18653/v1/2022.acl-short.82 , ,,"In this paper, we challenge the ACL community to reckon with historical and ongoing colonialism by adopting a set of ethical obligations and best practices drawn from the Indigenous studies literature. While the vast majority of NLP research focuses on a very small number of very high resource languages (English, Chinese, etc), some work has begun to engage with Indigenous languages. No research involving Indigenous language data can be considered ethical without first acknowledging that Indigenous languages are not merely very low resource languages. The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside researchers. To this end, we propose that the ACL draft and adopt an ethical framework for NLP researchers and computational linguists wishing to engage in research involving Indigenous languages.",,,,, ,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),,out_of_scope,
3673,"**Title**{R}o{CB}ert: Robust {C}hinese Bert with Multimodal Contrastive Pretraining

**Abstract**Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese. In this work, we propose RoCBert: a pretrained Chinese Bert that is robust to various forms of adversarial attacks like word perturbation, synonyms, typos, etc. It is pretrained with the contrastive learning objective which maximizes the label consistency under different synthesized adversarial examples. The model takes as input multimodal information including the semantic, phonetic and visual features. We show all these features areimportant to the model robustness since the attack can be performed in all the three forms. Across 5 Chinese NLU tasks, RoCBert outperforms strong baselines under three blackbox adversarial algorithms without sacrificing the performance on clean testset. It also performs the best in the toxic content detection task under human-made attacks.","Su, Hui, Shi, Weiwei, Shen, Xiaoyu, Xiao, Zhou, Ji, Tuo, Fang, Jiarui, Zhou, Jie",,,{R}o{CB}ert: Robust {C}hinese Bert with Multimodal Contrastive Pretraining,,,10.18653/v1/2022.acl-long.65 , ,,"Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese. In this work, we propose RoCBert: a pretrained Chinese Bert that is robust to various forms of adversarial attacks like word perturbation, synonyms, typos, etc. It is pretrained with the contrastive learning objective which maximizes the label consistency under different synthesized adversarial examples. The model takes as input multimodal information including the semantic, phonetic and visual features. We show all these features areimportant to the model robustness since the attack can be performed in all the three forms. Across 5 Chinese NLU tasks, RoCBert outperforms strong baselines under three blackbox adversarial algorithms without sacrificing the performance on clean testset. It also performs the best in the toxic content detection task under human-made attacks.",,,,, ,  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),,out_but_toxicity,
3674,"**Title**Director: Generator-Classifiers For Supervised Language Modeling

**Abstract**Current language models achieve low perplexity but their resulting generations still suffer from toxic responses, repetitiveness, and contradictions. The standard language modeling setup fails to address these issues. In this paper, we introduce a new architecture, Director, that consists of a unified generator-classifier with both a language modeling and a classification head for each output token. Training is conducted jointly using both standard language modeling data, and data labeled with desirable and undesirable sequences. Experiments in several settings show that the model has competitive training and decoding speed compared to standard language models while yielding superior results, avoiding undesirable behaviors while maintaining generation quality. It also outperforms existing model guiding approaches in terms of both accuracy and efficiency. Our code is made publicly available.","Arora, Kushal, Shuster, Kurt, Sukhbaatar, Sainbayar, Weston, Jason",,,Director: Generator-Classifiers For Supervised Language Modeling,,,10.18653/v1/2022.aacl-main.39 , ,,"Current language models achieve low perplexity but their resulting generations still suffer from toxic responses, repetitiveness, and contradictions. The standard language modeling setup fails to address these issues. In this paper, we introduce a new architecture, Director, that consists of a unified generator-classifier with both a language modeling and a classification head for each output token. Training is conducted jointly using both standard language modeling data, and data labeled with desirable and undesirable sequences. Experiments in several settings show that the model has competitive training and decoding speed compared to standard language models while yielding superior results, avoiding undesirable behaviors while maintaining generation quality. It also outperforms existing model guiding approaches in terms of both accuracy and efficiency. Our code is made publicly available.",,,,, ,  Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,detox,
3675,"**Title**{ICL}`s Submission to the {WMT}21 Critical Error Detection Shared Task

**Abstract**This paper presents Imperial College London`s submissions to the WMT21 Quality Estimation (QE) Shared Task 3: Critical Error Detection. Our approach builds on cross-lingual pre-trained representations in a sequence classification model. We further improve the base classifier by (i) adding a weighted sampler to deal with unbalanced data and (ii) introducing feature engineering, where features related to toxicity, named-entities and sentiment, which are potentially indicative of critical errors, are extracted using existing tools and integrated to the model in different ways. We train models with one type of feature at a time and ensemble those models that improve over the base classifier on the development (dev) set. Our official submissions achieve very competitive results, ranking second for three out of four language pairs.","Jiang, Genze, Li, Zhenhao, Specia, Lucia",,,{ICL}`s Submission to the {WMT}21 Critical Error Detection Shared Task,,, , ,,"This paper presents Imperial College London`s submissions to the WMT21 Quality Estimation (QE) Shared Task 3: Critical Error Detection. Our approach builds on cross-lingual pre-trained representations in a sequence classification model. We further improve the base classifier by (i) adding a weighted sampler to deal with unbalanced data and (ii) introducing feature engineering, where features related to toxicity, named-entities and sentiment, which are potentially indicative of critical errors, are extracted using existing tools and integrated to the model in different ways. We train models with one type of feature at a time and ensemble those models that improve over the base classifier on the development (dev) set. Our official submissions achieve very competitive results, ranking second for three out of four language pairs.",,,,, ,  Proceedings of the Sixth Conference on Machine Translation,,out_of_scope,
3676,"**Title**Let-Mi: An {A}rabic {L}evantine {T}witter Dataset for Misogynistic Language

**Abstract**Online misogyny has become an increasing worry for Arab women who experience gender-based online abuse on a daily basis. Misogyny automatic detection systems can assist in the prohibition of anti-women Arabic toxic content. Developing such systems is hindered by the lack of the Arabic misogyny benchmark datasets. In this paper, we introduce an Arabic Levantine Twitter dataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset for Arabic misogyny. We further provide a detailed review of the dataset creation and annotation phases. The consistency of the annotations for the proposed dataset was emphasized through inter-rater agreement evaluation measures. Moreover, Let-Mi was used as an evaluation dataset through binary/multi-/target classification tasks conducted by several state-of-the-art machine learning systems along with Multi-Task Learning (MTL) configuration. The obtained results indicated that the performances achieved by the used systems are consistent with state-of-the-art results for languages other than Arabic, while employing MTL improved the performance of the misogyny/target classification tasks.","Mulki, Hala, Ghanem, Bilal",,,Let-Mi: An {A}rabic {L}evantine {T}witter Dataset for Misogynistic Language,,, , ,,"Online misogyny has become an increasing worry for Arab women who experience gender-based online abuse on a daily basis. Misogyny automatic detection systems can assist in the prohibition of anti-women Arabic toxic content. Developing such systems is hindered by the lack of the Arabic misogyny benchmark datasets. In this paper, we introduce an Arabic Levantine Twitter dataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset for Arabic misogyny. We further provide a detailed review of the dataset creation and annotation phases. The consistency of the annotations for the proposed dataset was emphasized through inter-rater agreement evaluation measures. Moreover, Let-Mi was used as an evaluation dataset through binary/multi-/target classification tasks conducted by several state-of-the-art machine learning systems along with Multi-Task Learning (MTL) configuration. The obtained results indicated that the performances achieved by the used systems are consistent with state-of-the-art results for languages other than Arabic, while employing MTL improved the performance of the misogyny/target classification tasks.",,,,, ,  Proceedings of the Sixth Arabic Natural Language Processing Workshop,,out_but_toxicity,
3677,"**Title**Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in {NLP}

**Abstract**This paper contains prompts and model outputs that are offensive in nature. When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As large models require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated word lists, nor does it require any training data or changes to the model`s parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.1","Schick, Timo, Udupa, Sahana, Sch{\""u}tze, Hinrich",,,Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in {NLP},,,10.1162/tacl_a_00434 , ,,"This paper contains prompts and model outputs that are offensive in nature. When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As large models require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated word lists, nor does it require any training data or changes to the model`s parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.1",,,,, ,  ,,detection,
3678,"**Title**{S}-{NLP} at {S}em{E}val-2021 Task 5: An Analysis of Dual Networks for Sequence Tagging

**Abstract**The SemEval 2021 task 5: Toxic Spans Detection is a task of identifying considered-toxic spans in text, which provides a valuable, automatic tool for moderating online contents. This paper represents the second-place method for the task, an ensemble of two approaches. While one approach relies on combining different embedding methods to extract diverse semantic and syntactic representations of words in context; the other utilizes extra data with a slightly customized Self-training, a semi-supervised learning technique, for sequence tagging problems. Both of our architectures take advantage of a strong language model, which was fine-tuned on a toxic classification task. Although experimental evidence indicates higher effectiveness of the first approach than the second one, combining them leads to our best results of 70.77 F1-score on the test dataset.","Nguyen, Viet Anh, Nguyen, Tam Minh, Quang Dao, Huy, Huu Pham, Quang",,,{S}-{NLP} at {S}em{E}val-2021 Task 5: An Analysis of Dual Networks for Sequence Tagging,,,10.18653/v1/2021.semeval-1.120 , ,,"The SemEval 2021 task 5: Toxic Spans Detection is a task of identifying considered-toxic spans in text, which provides a valuable, automatic tool for moderating online contents. This paper represents the second-place method for the task, an ensemble of two approaches. While one approach relies on combining different embedding methods to extract diverse semantic and syntactic representations of words in context; the other utilizes extra data with a slightly customized Self-training, a semi-supervised learning technique, for sequence tagging problems. Both of our architectures take advantage of a strong language model, which was fine-tuned on a toxic classification task. Although experimental evidence indicates higher effectiveness of the first approach than the second one, combining them leads to our best results of 70.77 F1-score on the test dataset.",,,,, ,  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),,detection,
3679,"**Title**Data Science Kitchen at {G}erm{E}val 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven

**Abstract**This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8{\%}, 69.9{\%} and 72.5{\%} for the identification of toxic, engaging, and fact-claiming comments.","Hildebrandt, Niclas, Boenninghoff, Benedikt, Orth, Dennis, Schymura, Christopher",,,"Data Science Kitchen at {G}erm{E}val 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven",,, , ,,"This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8{\%}, 69.9{\%} and 72.5{\%} for the identification of toxic, engaging, and fact-claiming comments.",,,,, ,"  Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments",,out_but_toxicity,
3680,"**Title**{RAP}: {R}obustness-{A}ware {P}erturbations for Defending against Backdoor Attacks on {NLP} Models

**Abstract**Backdoor attacks, which maliciously control a well-trained model`s outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (DNNs). In this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. Specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. Motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (NLP) models. Moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. Experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods. Our code is available at \url{https://github.com/lancopku/RAP}.","Yang, Wenkai, Lin, Yankai, Li, Peng, Zhou, Jie, Sun, Xu",,,{RAP}: {R}obustness-{A}ware {P}erturbations for Defending against Backdoor Attacks on {NLP} Models,,,10.18653/v1/2021.emnlp-main.659 , ,,"Backdoor attacks, which maliciously control a well-trained model`s outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (DNNs). In this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. Specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. Motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (NLP) models. Moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. Experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods. Our code is available at \url{https://github.com/lancopku/RAP}.",,,,, ,  Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,,detection,
3681,"**Title**Rethinking Stealthiness of Backdoor Attack against {NLP} Models

**Abstract**Recent researches have shown that large natural language processing (NLP) models are vulnerable to a kind of security threat called the Backdoor Attack. Backdoor attacked models can achieve good performance on clean test sets but perform badly on those input sentences injected with designed trigger words. In this work, we point out a potential problem of current backdoor attacking research: its evaluation ignores the stealthiness of backdoor attacks, and most of existing backdoor attacking methods are not stealthy either to system deployers or to system users. To address this issue, we first propose two additional stealthiness-based metrics to make the backdoor attacking evaluation more credible. We further propose a novel word-based backdoor attacking method based on negative data augmentation and modifying word embeddings, making an important step towards achieving stealthy backdoor attacking. Experiments on sentiment analysis and toxic detection tasks show that our method is much stealthier while maintaining pretty good attacking performance. Our code is available at \url{https://github.com/lancopku/SOS}.","Yang, Wenkai, Lin, Yankai, Li, Peng, Zhou, Jie, Sun, Xu",,,Rethinking Stealthiness of Backdoor Attack against {NLP} Models,,,10.18653/v1/2021.acl-long.431 , ,,"Recent researches have shown that large natural language processing (NLP) models are vulnerable to a kind of security threat called the Backdoor Attack. Backdoor attacked models can achieve good performance on clean test sets but perform badly on those input sentences injected with designed trigger words. In this work, we point out a potential problem of current backdoor attacking research: its evaluation ignores the stealthiness of backdoor attacks, and most of existing backdoor attacking methods are not stealthy either to system deployers or to system users. To address this issue, we first propose two additional stealthiness-based metrics to make the backdoor attacking evaluation more credible. We further propose a novel word-based backdoor attacking method based on negative data augmentation and modifying word embeddings, making an important step towards achieving stealthy backdoor attacking. Experiments on sentiment analysis and toxic detection tasks show that our method is much stealthier while maintaining pretty good attacking performance. Our code is available at \url{https://github.com/lancopku/SOS}.",,,,, ,  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,detection,
3682,"**Title**{ASU}{\_}{OPTO} at {OSACT}4 - Offensive Language Detection for {A}rabic text

**Abstract**In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage. Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays. In this paper, we describe the model that was submitted to the Shared Task on Offensive Language Detection that is organized by (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Our model makes use transformer based model (BERT) to detect offensive content. We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).","Keleg, Amr, El-Beltagy, Samhaa R., Khalil, Mahmoud",,,{ASU}{\_}{OPTO} at {OSACT}4 - Offensive Language Detection for {A}rabic text,,, , ,,"In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage. Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays. In this paper, we describe the model that was submitted to the Shared Task on Offensive Language Detection that is organized by (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Our model makes use transformer based model (BERT) to detect offensive content. We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).",,,,, ,"  Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection",,out_but_toxicity,
3683,"**Title**{LOGAN}: Local Group Bias Detection by Clustering

**Abstract**Machine learning techniques have been widely used in natural language processing (NLP). However, as revealed by many recent studies, machine learning models often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between protected groups and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how biases are embedded in a model. In fact, a model with similar aggregated performance between different groups on the entire data may behave differently on instances in a local region. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on clustering. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.","Zhao, Jieyu, Chang, Kai-Wei",,,{LOGAN}: Local Group Bias Detection by Clustering,,,10.18653/v1/2020.emnlp-main.155 , ,,"Machine learning techniques have been widely used in natural language processing (NLP). However, as revealed by many recent studies, machine learning models often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between protected groups and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how biases are embedded in a model. In fact, a model with similar aggregated performance between different groups on the entire data may behave differently on instances in a local region. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on clustering. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.",,,,, ,  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),,detection,
3684,"**Title**Reducing Unintended Identity Bias in {R}ussian Hate Speech Detection

**Abstract**Toxicity has become a grave problem for many online communities, and has been growing across many languages, including Russian. Hate speech creates an environment of intimidation, discrimination, and may even incite some real-world violence. Both researchers and social platforms have been focused on developing models to detect toxicity in online communication for a while now. A common problem of these models is the presence of bias towards some words (e.g. woman, black, jew or {\cyrzh}{\cyre}{\cyrn}{\cyrshch}{\cyri}{\cyrn}{\cyra}, {\cyrch}{\cyre}{\cyrr}{\cyrn}{\cyrery}{\cyrishrt}, {\cyre}{\cyrv}{\cyrr}{\cyre}{\cyrishrt}) that are not toxic, but serve as triggers for the classifier due to model caveats. In this paper, we describe our efforts towards classifying hate speech in Russian, and propose simple techniques of reducing unintended bias, such as generating training data with language models using terms and words related to protected identities as context and applying word dropout to such words.","Zueva, Nadezhda, Kabirova, Madina, Kalaidin, Pavel",,,Reducing Unintended Identity Bias in {R}ussian Hate Speech Detection,,,10.18653/v1/2020.alw-1.8 , ,,"Toxicity has become a grave problem for many online communities, and has been growing across many languages, including Russian. Hate speech creates an environment of intimidation, discrimination, and may even incite some real-world violence. Both researchers and social platforms have been focused on developing models to detect toxicity in online communication for a while now. A common problem of these models is the presence of bias towards some words (e.g. woman, black, jew or {\cyrzh}{\cyre}{\cyrn}{\cyrshch}{\cyri}{\cyrn}{\cyra}, {\cyrch}{\cyre}{\cyrr}{\cyrn}{\cyrery}{\cyrishrt}, {\cyre}{\cyrv}{\cyrr}{\cyre}{\cyrishrt}) that are not toxic, but serve as triggers for the classifier due to model caveats. In this paper, we describe our efforts towards classifying hate speech in Russian, and propose simple techniques of reducing unintended bias, such as generating training data with language models using terms and words related to protected identities as context and applying word dropout to such words.",,,,, ,  Proceedings of the Fourth Workshop on Online Abuse and Harms,,out_but_toxicity,
3685,"**Title**Social Biases in {NLP} Models as Barriers for Persons with Disabilities

**Abstract**Building equitable and inclusive NLP technologies demands consideration of whether and how social attitudes are represented in ML models. In particular, representations encoded in models often inadvertently perpetuate undesirable social biases from the data on which they are trained. In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis. Next, we demonstrate that the neural embeddings that are the critical first step in most NLP pipelines similarly contain undesirable biases towards mentions of disability. We end by highlighting topical biases in the discourse about disability which may contribute to the observed model biases; for instance, gun violence, homelessness, and drug addiction are over-represented in texts discussing mental illness.","Hutchinson, Ben, Prabhakaran, Vinodkumar, Denton, Emily, Webster, Kellie, Zhong, Yu, Denuyl, Stephen",,,Social Biases in {NLP} Models as Barriers for Persons with Disabilities,,,10.18653/v1/2020.acl-main.487 , ,,"Building equitable and inclusive NLP technologies demands consideration of whether and how social attitudes are represented in ML models. In particular, representations encoded in models often inadvertently perpetuate undesirable social biases from the data on which they are trained. In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis. Next, we demonstrate that the neural embeddings that are the critical first step in most NLP pipelines similarly contain undesirable biases towards mentions of disability. We end by highlighting topical biases in the discourse about disability which may contribute to the observed model biases; for instance, gun violence, homelessness, and drug addiction are over-represented in texts discussing mental illness.",,,,, ,  Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,,detection,
3686,"**Title**{L}-{HSAB}: A {L}evantine {T}witter Dataset for Hate Speech and Abusive Language

**Abstract**Hate speech and abusive language have become a common phenomenon on Arabic social media. Automatic hate speech and abusive detection systems can facilitate the prohibition of toxic textual contents. The complexity, informality and ambiguity of the Arabic dialects hindered the provision of the needed resources for Arabic abusive/hate speech detection research. In this paper, we introduce the first publicly-available Levantine Hate Speech and Abusive (L-HSAB) Twitter dataset with the objective to be a benchmark dataset for automatic detection of online Levantine toxic contents. We, further, provide a detailed review of the data collection steps and how we design the annotation guidelines such that a reliable dataset annotation is guaranteed. This has been later emphasized through the comprehensive evaluation of the annotations as the annotation agreement metrics of Cohen`s Kappa (k) and Krippendorff`s alpha ({\ensuremath{\alpha}}) indicated the consistency of the annotations.","Mulki, Hala, Haddad, Hatem, Bechikh Ali, Chedi, Alshabani, Halima",,,{L}-{HSAB}: A {L}evantine {T}witter Dataset for Hate Speech and Abusive Language,,,10.18653/v1/W19-3512 , ,,"Hate speech and abusive language have become a common phenomenon on Arabic social media. Automatic hate speech and abusive detection systems can facilitate the prohibition of toxic textual contents. The complexity, informality and ambiguity of the Arabic dialects hindered the provision of the needed resources for Arabic abusive/hate speech detection research. In this paper, we introduce the first publicly-available Levantine Hate Speech and Abusive (L-HSAB) Twitter dataset with the objective to be a benchmark dataset for automatic detection of online Levantine toxic contents. We, further, provide a detailed review of the data collection steps and how we design the annotation guidelines such that a reliable dataset annotation is guaranteed. This has been later emphasized through the comprehensive evaluation of the annotations as the annotation agreement metrics of Cohen`s Kappa (k) and Krippendorff`s alpha ({\ensuremath{\alpha}}) indicated the consistency of the annotations.",,,,, ,  Proceedings of the Third Workshop on Abusive Language Online,,out_but_toxicity,
3687,"**Title**Incivility Detection in Online Comments

**Abstract**Incivility in public discourse has been a major concern in recent times as it can affect the quality and tenacity of the discourse negatively. In this paper, we present neural models that can learn to detect name-calling and vulgarity from a newspaper comment section. We show that in contrast to prior work on detecting toxic language, fine-grained incivilities like namecalling cannot be accurately detected by simple models like logistic regression. We apply the models trained on the newspaper comments data to detect uncivil comments in a Russian troll dataset, and find that despite the change of domain, the model makes accurate predictions.","Sadeque, Farig, Rains, Stephen, Shmargad, Yotam, Kenski, Kate, Coe, Kevin, Bethard, Steven",,,Incivility Detection in Online Comments,,,10.18653/v1/S19-1031 , ,,"Incivility in public discourse has been a major concern in recent times as it can affect the quality and tenacity of the discourse negatively. In this paper, we present neural models that can learn to detect name-calling and vulgarity from a newspaper comment section. We show that in contrast to prior work on detecting toxic language, fine-grained incivilities like namecalling cannot be accurately detected by simple models like logistic regression. We apply the models trained on the newspaper comments data to detect uncivil comments in a Russian troll dataset, and find that despite the change of domain, the model makes accurate predictions.",,,,, ,  Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019),,detection,
3688,"**Title**{W}iki{C}onv: A Corpus of the Complete Conversational History of a Large Online Collaborative Community

**Abstract**We present a corpus that encompasses the complete history of conversations between contributors to Wikipedia, one of the largest online collaborative communities. By recording the intermediate states of conversations - including not only comments and replies, but also their modifications, deletions and restorations - this data offers an unprecedented view of online conversation. Our framework is designed to be language agnostic, and we show that it extracts high quality data in both Chinese and English. This level of detail supports new research questions pertaining to the process (and challenges) of large-scale online collaboration. We illustrate the corpus' potential with two case studies on English Wikipedia that highlight new perspectives on earlier work. First, we explore how a person`s conversational behavior depends on how they relate to the discussion`s venue. Second, we show that community moderation of toxic behavior happens at a higher rate than previously estimated.","Hua, Yiqing, Danescu-Niculescu-Mizil, Cristian, Taraborelli, Dario, Thain, Nithum, Sorensen, Jeffery, Dixon, Lucas",,,{W}iki{C}onv: A Corpus of the Complete Conversational History of a Large Online Collaborative Community,,,10.18653/v1/D18-1305 , ,,"We present a corpus that encompasses the complete history of conversations between contributors to Wikipedia, one of the largest online collaborative communities. By recording the intermediate states of conversations - including not only comments and replies, but also their modifications, deletions and restorations - this data offers an unprecedented view of online conversation. Our framework is designed to be language agnostic, and we show that it extracts high quality data in both Chinese and English. This level of detail supports new research questions pertaining to the process (and challenges) of large-scale online collaboration. We illustrate the corpus' potential with two case studies on English Wikipedia that highlight new perspectives on earlier work. First, we explore how a person`s conversational behavior depends on how they relate to the discussion`s venue. Second, we show that community moderation of toxic behavior happens at a higher rate than previously estimated.",,,,, ,  Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,,out_of_scope,
3689,"**Title**{G}erman Alcohol Language Corpus - the Question of Dialect

**Abstract**Speech uttered under the influence of alcohol is known to deviate from the speech of the same person when sober. This is an important feature in forensic investigations and could also be used to detect intoxication in the automotive environment. Aside from acoustic-phonetic features and speech content which have already been studied by others in this contribution we address the question whether speakers use dialectal variation or dialect words more frequently when intoxicated than when sober. We analyzed 300,000 recorded word tokens in read and spontaneous speech uttered by 162 female and male speakers within the German Alcohol Language Corpus. We found that contrary to our expectations the frequency of dialectal forms decreases significantly when speakers are under the influence. We explain this effect with a compensatory over-shoot mechanism: speakers are aware of their intoxication and that they are being monitored. In forensic analysis of speech this {\textquoteleft}awareness factor' must be taken into account.","Schiel, Florian, Kisler, Thomas",,,{G}erman Alcohol Language Corpus - the Question of Dialect,,, , ,,"Speech uttered under the influence of alcohol is known to deviate from the speech of the same person when sober. This is an important feature in forensic investigations and could also be used to detect intoxication in the automotive environment. Aside from acoustic-phonetic features and speech content which have already been studied by others in this contribution we address the question whether speakers use dialectal variation or dialect words more frequently when intoxicated than when sober. We analyzed 300,000 recorded word tokens in read and spontaneous speech uttered by 162 female and male speakers within the German Alcohol Language Corpus. We found that contrary to our expectations the frequency of dialectal forms decreases significantly when speakers are under the influence. We explain this effect with a compensatory over-shoot mechanism: speakers are aware of their intoxication and that they are being monitored. In forensic analysis of speech this {\textquoteleft}awareness factor' must be taken into account.",,,,, ,  Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}`14),,out_of_scope,
3690,"**Title**{ALC}: Alcohol Language Corpus

**Abstract**A number of forensic studies published during the last 50 years report that intoxication with alcohol influences speech in a way that is made manifest in certain features of the speech signal. However, most of these studies are based on data that are not publicly available nor of statistically sufficient size. Furthermore, in spite of the positive reports nobody ever successfully implemented a method to detect alcoholic intoxication from the speech signal. The Alcohol Language Corpus (ALC) aims to answer these open questions by providing a publicly available large and statistically sound corpus of intoxicated and sober speech. This paper gives a detailed description of the corpus features and methodology. Also, we will present some preliminary results on a series of verifications about reported potential features that are claimed to reliably indicate alcoholic intoxication.","Schiel, Florian, Heinrich, Christian, Barf{\""u}{\ss}er, Sabine, Gilg, Thomas",,,{ALC}: Alcohol Language Corpus,,, , ,,"A number of forensic studies published during the last 50 years report that intoxication with alcohol influences speech in a way that is made manifest in certain features of the speech signal. However, most of these studies are based on data that are not publicly available nor of statistically sufficient size. Furthermore, in spite of the positive reports nobody ever successfully implemented a method to detect alcoholic intoxication from the speech signal. The Alcohol Language Corpus (ALC) aims to answer these open questions by providing a publicly available large and statistically sound corpus of intoxicated and sober speech. This paper gives a detailed description of the corpus features and methodology. Also, we will present some preliminary results on a series of verifications about reported potential features that are claimed to reliably indicate alcoholic intoxication.",,,,, ,  Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}`08),,out_of_scope,
