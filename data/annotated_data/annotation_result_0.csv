id,text,Authors,Researcher Ids,ORCIDs,title,Volume,Issue,DOI,Document Type,Publication Date,Abstract,ISSN,eISSN,ISBN,Pages,Publisher,Proceedings title,Keywords,label,Comments
3844,"Title:Context Sensitivity Estimation in Toxicity Detection

 User posts whose perceived toxicity depends on the conversational context are rare in current toxicity detection datasets. Hence, toxicity detectors trained on current datasets will also disregard context, making the detection of context-sensitive toxicity a lot harder when it occurs. We constructed and publicly release a dataset of 10k posts with two kinds of toxicity labels per post, obtained from annotators who considered (i) both the current post and the previous one as context, or (ii) only the current post. We introduce a new task, context sensitivity estimation, which aims to identify posts whose perceived toxicity changes if the context (previous post) is also considered. Using the new dataset, we show that systems can be developed for this task. Such systems could be used to enhance toxicity detection datasets with more context-dependent posts, or to suggest when moderators should consider the parent posts, which may not always be necessary and may introduce an additional cost.","Xenos, Alexandros; Pavlopoulos, John; Androutsopoulos, Ion","Pavlopoulos, John/GPP-2913-2022","Pavlopoulos, John/0000-0001-9188-7425; Androutsopoulos, Ion/0009-0000-2969-0509",Context Sensitivity Estimation in Toxicity Detection,,, ,Proceedings Paper ,2021.0,"User posts whose perceived toxicity depends on the conversational context are rare in current toxicity detection datasets. Hence, toxicity detectors trained on current datasets will also disregard context, making the detection of context-sensitive toxicity a lot harder when it occurs. We constructed and publicly release a dataset of 10k posts with two kinds of toxicity labels per post, obtained from annotators who considered (i) both the current post and the previous one as context, or (ii) only the current post. We introduce a new task, context sensitivity estimation, which aims to identify posts whose perceived toxicity changes if the context (previous post) is also considered. Using the new dataset, we show that systems can be developed for this task. Such systems could be used to enhance toxicity detection datasets with more context-dependent posts, or to suggest when moderators should consider the parent posts, which may not always be necessary and may introduce an additional cost.",,,978-1-954085-59-6,140-145, , 5th Workshop on Structured Prediction for NLP (SPNLP) / 5th Workshop on Online Abuse and Harms (WOAH)5th Workshop on Structured Prediction for NLP (SPNLP) / 5th Workshop on Online Abuse and Harms (WOAH),,Gen_dataset#detection#evaluation#methodology,
3845,"Title:COVER: conformational oversampling as data augmentation for molecules

 Training neural networks with small and imbalanced datasets often leads to overfitting and disregard of the minority class. For predictive toxicology, however, models with a good balance between sensitivity and specificity are needed. In this paper we introduce conformational oversampling as a means to balance and oversample datasets for prediction of toxicity. Conformational oversampling enhances a dataset by generation of multiple conformations of a molecule. These conformations can be used to balance, as well as oversample a dataset, thereby increasing the dataset size without the need of artificial samples. We show that conformational oversampling facilitates training of neural networks and provides state-of-the-art results on the Tox21 dataset.","Hemmerich, Jennifer; Asilar, Ece; Ecker, Gerhard F.","ASILAR, Ece/ABC-4577-2020","ASILAR, Ece/0000-0001-5680-599X; Hemmerich, Jennifer/0000-0003-0372-8956; Ecker, Gerhard/0000-0003-4209-6883",COVER: conformational oversampling as data augmentation for molecules,12,1,10.1186/s13321-020-00420-z ,Article ,2020.0,"Training neural networks with small and imbalanced datasets often leads to overfitting and disregard of the minority class. For predictive toxicology, however, models with a good balance between sensitivity and specificity are needed. In this paper we introduce conformational oversampling as a means to balance and oversample datasets for prediction of toxicity. Conformational oversampling enhances a dataset by generation of multiple conformations of a molecule. These conformations can be used to balance, as well as oversample a dataset, thereby increasing the dataset size without the need of artificial samples. We show that conformational oversampling facilitates training of neural networks and provides state-of-the-art results on the Tox21 dataset.",1758-2946,,,, , ,,out_of_scope,
3846,"Title:DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances

 Toxic speech is regarded as one of the crucial issues plaguing online social media today. Most recent work on toxic speech detection is constrained to the modality of text and written conversations with very limited work on toxicity detection from spoken utterances or using the modality of speech. In this paper, we introduce a new dataset DeToxy, the first publicly available toxicity annotated dataset for the English language. DeToxy is sourced from various openly available speech databases and consists of over 2 million utterances. We believe that our dataset would act as a benchmark for the relatively new and unexplored Spoken Language Processing (SLP) task of detecting toxicity from spoken utterances and boost further research in this space. Finally, we also provide strong unimodal baselines for our dataset and compare traditional two-step cascade and End-to-End (E2E) approaches. Our experiments show that in the case of spoken utterances, text-based approaches are largely dependent on gold human-annotated transcripts for their performance and also suffer from the problem of keyword bias. However, the presence of speech files in DeToxy helps facilitates the development of E2E speech models which alleviate both the above-stated problems by better capturing speech clues.","Ghosh, Sreyan; Lepcha, Samden; Sakshi, S.; Shah, Rajiv Ratn; Umesh, S.",,,DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances,,,10.21437/Interspeech.2022-10752 ,Proceedings Paper ,2022.0,"Toxic speech is regarded as one of the crucial issues plaguing online social media today. Most recent work on toxic speech detection is constrained to the modality of text and written conversations with very limited work on toxicity detection from spoken utterances or using the modality of speech. In this paper, we introduce a new dataset DeToxy, the first publicly available toxicity annotated dataset for the English language. DeToxy is sourced from various openly available speech databases and consists of over 2 million utterances. We believe that our dataset would act as a benchmark for the relatively new and unexplored Spoken Language Processing (SLP) task of detecting toxicity from spoken utterances and boost further research in this space. Finally, we also provide strong unimodal baselines for our dataset and compare traditional two-step cascade and End-to-End (E2E) approaches. Our experiments show that in the case of spoken utterances, text-based approaches are largely dependent on gold human-annotated transcripts for their performance and also suffer from the problem of keyword bias. However, the presence of speech files in DeToxy helps facilitates the development of E2E speech models which alleviate both the above-stated problems by better capturing speech clues.",2308-457X,,*****************,5185-5189, , Interspeech ConferenceInterspeech Conference,,Gen_dataset#detox#out_but_toxicity,
3847,"Title:Subversive Toxicity Detection using Sentiment Information

 The presence of toxic content has become a major problem for many online communities. Moderators try to limit this problem by implementing more and more refined comment filters, but toxic users are constantly finding new ways to circumvent them. Our hypothesis is that while modifying toxic content and keywords to fool filters can be easy, hiding sentiment is harder. In this paper, we explore various aspects of sentiment detection and their correlation to toxicity, and use our results to implement a toxicity detection tool. We then test how adding the sentiment information helps detect toxicity in three different real-world datasets, and incorporate subversion to these datasets to simulate a user trying to circumvent the system. Our results show sentiment information has a positive impact on toxicity detection.","Brassard-Gourdeau, Eloi; Khoury, Richard",,,Subversive Toxicity Detection using Sentiment Information,,, ,Proceedings Paper ,2019.0,"The presence of toxic content has become a major problem for many online communities. Moderators try to limit this problem by implementing more and more refined comment filters, but toxic users are constantly finding new ways to circumvent them. Our hypothesis is that while modifying toxic content and keywords to fool filters can be easy, hiding sentiment is harder. In this paper, we explore various aspects of sentiment detection and their correlation to toxicity, and use our results to implement a toxicity detection tool. We then test how adding the sentiment information helps detect toxicity in three different real-world datasets, and incorporate subversion to these datasets to simulate a user trying to circumvent the system. Our results show sentiment information has a positive impact on toxicity detection.",,,978-1-950737-43-7,1-10, , 3rd Workshop on Abusive Language Online3rd Workshop on Abusive Language Online,,Use_dataset#detection#methodology,
3848,"Title:Toxic, Hateful, Offensive or Abusive? What Are We Really Classifying? An Empirical Analysis of Hate Speech Datasets

 The field of the automatic detection of hate speech and related concepts has raised a lot of interest in the last years. Different datasets were annotated and classified by means of applying different machine learning algorithms. However, few efforts were done in order to clarify the applied categories and homogenize different datasets. Our study takes up this demand. We analyze six different publicly available datasets in this field with respect to their similarity and compatibility. We conduct two different experiments. First, we try to make the datasets compatible and represent the dataset classes as Fast Text word vectors analyzing the similarity between different classes in a intra and inter dataset manner. Second, we submit the chosen datasets to the Perspective API Toxicity classifier, achieving different performances depending on the categories and datasets. One of the main conclusions of these experiments is that many different definitions are being used for equivalent concepts, which makes most of the publicly available datasets incompatible. Grounded in our analysis, we provide guidelines for future dataset collection and annotation.","Fortuna, Paula; Soler-Company, Juan; Wanner, Leo",,,"Toxic, Hateful, Offensive or Abusive? What Are We Really Classifying? An Empirical Analysis of Hate Speech Datasets",,, ,Proceedings Paper ,2020.0,"The field of the automatic detection of hate speech and related concepts has raised a lot of interest in the last years. Different datasets were annotated and classified by means of applying different machine learning algorithms. However, few efforts were done in order to clarify the applied categories and homogenize different datasets. Our study takes up this demand. We analyze six different publicly available datasets in this field with respect to their similarity and compatibility. We conduct two different experiments. First, we try to make the datasets compatible and represent the dataset classes as Fast Text word vectors analyzing the similarity between different classes in a intra and inter dataset manner. Second, we submit the chosen datasets to the Perspective API Toxicity classifier, achieving different performances depending on the categories and datasets. One of the main conclusions of these experiments is that many different definitions are being used for equivalent concepts, which makes most of the publicly available datasets incompatible. Grounded in our analysis, we provide guidelines for future dataset collection and annotation.",,,979-10-95546-34-4,6786-6794, , 12th International Conference on Language Resources and Evaluation (LREC)12th International Conference on Language Resources and Evaluation (LREC),,Use_dataset#detection#evaluation,
3849,"Title:Effective data-balancing methods for class-imbalanced genotoxicity datasets using machine learning algorithms and molecular fingerprints

 Machine learning and deep learning approaches have been increasingly used in the field of toxicology through prediction models developed using various toxicity data. However, toxicity data are often class-imbalanced, which hinders the development of machine learning models with good performance. Therefore, in this study, we identified effective data-balancing methods for class-imbalanced genotoxicity datasets using machine learning algorithms and molecular fingerprints. Data-balancing methods, such as random undersampling (RUS), sample weight (SW), synthetic minority oversampling technique (SMOTE), and random oversampling (ROS) were applied to the datasets. Model performance was evaluated using the F1 score on five machine learning algorithms: gradient boosting tree (GBT), random forest (RF), support vector machine (SVM), multi-layer perceptron (MLP) network, and k-nearest neighbors (kNN) in combination with five molecular fingerprints (Morgan, MACCS, RDKit, Pattern, and Layered). The performance was evaluated for each combination of molecular fingerprints, machine learning algorithms, and data-balancing methods. The MACCS-GBT-SMOTE combination model achieved the best F1 score, followed by RDKit-GBT-SW. Thus, this study demonstrated that data balancing conducted using oversampling methods improved the performance of models. The systematic approach used in this study can also be applied to other toxicity datasets, which may facilitate the development of an improved classification model for toxicity screening.","Bae, Su-Yong; Lee, Jonga; Jeong, Jaeseong; Lim, Changwon; Choi, Jinhee",,"Choi, Jinhee/0000-0003-3393-7505; Jeong, Jaeseong/0000-0002-3860-0648",Effective data-balancing methods for class-imbalanced genotoxicity datasets using machine learning algorithms and molecular fingerprints,20,,10.1016/j.comtox.2021.100178 ,Article ,2021.0,"Machine learning and deep learning approaches have been increasingly used in the field of toxicology through prediction models developed using various toxicity data. However, toxicity data are often class-imbalanced, which hinders the development of machine learning models with good performance. Therefore, in this study, we identified effective data-balancing methods for class-imbalanced genotoxicity datasets using machine learning algorithms and molecular fingerprints. Data-balancing methods, such as random undersampling (RUS), sample weight (SW), synthetic minority oversampling technique (SMOTE), and random oversampling (ROS) were applied to the datasets. Model performance was evaluated using the F1 score on five machine learning algorithms: gradient boosting tree (GBT), random forest (RF), support vector machine (SVM), multi-layer perceptron (MLP) network, and k-nearest neighbors (kNN) in combination with five molecular fingerprints (Morgan, MACCS, RDKit, Pattern, and Layered). The performance was evaluated for each combination of molecular fingerprints, machine learning algorithms, and data-balancing methods. The MACCS-GBT-SMOTE combination model achieved the best F1 score, followed by RDKit-GBT-SW. Thus, this study demonstrated that data balancing conducted using oversampling methods improved the performance of models. The systematic approach used in this study can also be applied to other toxicity datasets, which may facilitate the development of an improved classification model for toxicity screening.",2468-1113,,,, , ,,out_of_scope,
3850,"Title:Automated Identification of Toxic Code Reviews Using ToxiCR

 Toxic conversations during software development interactions may have serious repercussions on a Free and Open Source Software (FOSS) development project. For example, victims of toxic conversations may become afraid to express themselves, therefore get demotivated, and may eventually leave the project. Automated filtering of toxic conversations may help a FOSS community maintain healthy interactions among its members. However, off-the-shelf toxicity detectors perform poorly on a software engineering dataset, such as one curated from code review comments. To counter this challenge, we present ToxiCR, a supervised learning based toxicity identification tool for code review interactions. ToxiCR includes a choice to select one of the 10 supervised learning algorithms, an option to select text vectorization techniques, eight preprocessing steps, and a large-scale labeled dataset of 19,651 code review comments. Two out of those eight preprocessing steps are software engineering domain specific. With our rigorous evaluation of the models with various combinations of preprocessing steps and vectorization techniques, we have identified the best combination for our dataset that boosts 95.8% accuracy and an 88.9% F1-score in identifying toxic texts. ToxiCR significantly outperforms existing toxicity detectors on our dataset. We have released our dataset, pre-trainedmodels, evaluation results, and source code publicly, which is available at https://github.com/WSU- SEAL/ToxiCR.","Sarker, Jaydeb; Turzo, Asif Kamal; Dong, Ming; Bosu, Amiangshu",,"Bosu, Amiangshu/0000-0002-3178-6232",Automated Identification of Toxic Code Reviews Using ToxiCR,32,5,10.1145/3583562 ,Article ,2023.0,"Toxic conversations during software development interactions may have serious repercussions on a Free and Open Source Software (FOSS) development project. For example, victims of toxic conversations may become afraid to express themselves, therefore get demotivated, and may eventually leave the project. Automated filtering of toxic conversations may help a FOSS community maintain healthy interactions among its members. However, off-the-shelf toxicity detectors perform poorly on a software engineering dataset, such as one curated from code review comments. To counter this challenge, we present ToxiCR, a supervised learning based toxicity identification tool for code review interactions. ToxiCR includes a choice to select one of the 10 supervised learning algorithms, an option to select text vectorization techniques, eight preprocessing steps, and a large-scale labeled dataset of 19,651 code review comments. Two out of those eight preprocessing steps are software engineering domain specific. With our rigorous evaluation of the models with various combinations of preprocessing steps and vectorization techniques, we have identified the best combination for our dataset that boosts 95.8% accuracy and an 88.9% F1-score in identifying toxic texts. ToxiCR significantly outperforms existing toxicity detectors on our dataset. We have released our dataset, pre-trainedmodels, evaluation results, and source code publicly, which is available at https://github.com/WSU- SEAL/ToxiCR.",1049-331X,1557-7392,,, , ,,Gen_dataset#detection#methodology,
3851,"Title:A Benchmark Study of the Contemporary Toxicity Detectors on Software Engineering Interactions

 Automated filtering of toxic conversations may help an Open-source software (OSS) community to maintain healthy interactions among the project participants. Although, several general purpose tools exist to identify toxic contents, those may incorrectly flag some words commonly used in the Software Engineering (SE) context as toxic (e.g., 'junk', 'kill', and 'dump') and vice versa. To encounter this challenge, an SE specific tool has been proposed by the CMU Strudel Lab (referred as the 'STRUDEL' hereinafter) by combining the output of the Perspective API with the output from a customized version of the Stanford's Politeness detector tool. However, since STRUDEL's evaluation was very limited with only 654 SE text, its practical applicability is unclear. Therefore, this study aims to empirically evaluate the Strudel tool as well as four state-of-the-art general purpose toxicity detectors on a large scale SE dataset. On this goal, we empirically developed a rubric to manually label toxic SE interactions. Using this rubric, we manually labeled a dataset of 6,533 code review comments and 4,140 Gitter messages. The results of our analyses suggest significant degradation of all tools' performances on our datasets. Those degradations were significantly higher on our dataset of formal SE communication such as code review than on our dataset of informal communication such as Gitter messages. Two of the models from our study showed significant performance improvements during 10-fold cross validations after we retrained those on our SE datasets. Based on our manual investigations of the incorrectly classified text, we have identified several recommendations for developing an SE specific toxicity detector.","Sarker, Jaydeb; Turzo, Asif Kamal; Bosu, Amiangshu","Turzo, Asif Kamal/HMP-3568-2023; Bosu, Amiangshu/AAB-1259-2020","Turzo, Asif Kamal/0000-0002-0869-4962;",A Benchmark Study of the Contemporary Toxicity Detectors on Software Engineering Interactions,,,10.1109/APSEC51365.2020.00030 ,Proceedings Paper ,2020.0,"Automated filtering of toxic conversations may help an Open-source software (OSS) community to maintain healthy interactions among the project participants. Although, several general purpose tools exist to identify toxic contents, those may incorrectly flag some words commonly used in the Software Engineering (SE) context as toxic (e.g., 'junk', 'kill', and 'dump') and vice versa. To encounter this challenge, an SE specific tool has been proposed by the CMU Strudel Lab (referred as the 'STRUDEL' hereinafter) by combining the output of the Perspective API with the output from a customized version of the Stanford's Politeness detector tool. However, since STRUDEL's evaluation was very limited with only 654 SE text, its practical applicability is unclear. Therefore, this study aims to empirically evaluate the Strudel tool as well as four state-of-the-art general purpose toxicity detectors on a large scale SE dataset. On this goal, we empirically developed a rubric to manually label toxic SE interactions. Using this rubric, we manually labeled a dataset of 6,533 code review comments and 4,140 Gitter messages. The results of our analyses suggest significant degradation of all tools' performances on our datasets. Those degradations were significantly higher on our dataset of formal SE communication such as code review than on our dataset of informal communication such as Gitter messages. Two of the models from our study showed significant performance improvements during 10-fold cross validations after we retrained those on our SE datasets. Based on our manual investigations of the incorrectly classified text, we have identified several recommendations for developing an SE specific toxicity detector.",1530-1362,,978-1-7281-9553-7,218-227, , 27th Asia-Pacific Software Engineering Conference (APSEC)27th Asia-Pacific Software Engineering Conference (APSEC),,Gen_dataset#detection#evaluation,
3852,"Title:XRBi-GAC: A hybrid deep learning framework for multilingual toxicity detection

 Social media platforms allow people across the globe to share their thoughts and opinions and conveniently communicate with each other. Apart from various advantages of social media, it is also misused by a set of users for hate-mongering with toxic and offensive comments. The majority of the earlier proposed toxicity detection methods are primarily focused on the English language, but there is a lack of research on low-resource languages and multilingual text data. We propose an XRBi-GAC framework comprising XLM-RoBERTa, Bi-GRU with self-attention and capsule networks for multilingual toxic text detection. A loss function is also presented, which fuses the binary cross-entropy loss and focal loss to address the class imbalance problem. We evaluated the proposed framework on two datasets, namely, the Jigsaw Multilingual Toxic Comment dataset and HASOC 2019 dataset and achieved F1-score of 0.865 and 0.829, respectively. The results of the experiments show that the proposed framework has outperformed the state-of-the-art multilingual models XLM-RoBERTa and mBERT on both datasets, which shows the versatility and robustness of the proposed XRBi-GAC framework.","Singh, Nitin Kumar; Singh, Pardeep; Das, Prativa; Chand, Satish",,,XRBi-GAC: A hybrid deep learning framework for multilingual toxicity detection,45,1,10.3233/JIFS-224536 ,Article ,2023.0,"Social media platforms allow people across the globe to share their thoughts and opinions and conveniently communicate with each other. Apart from various advantages of social media, it is also misused by a set of users for hate-mongering with toxic and offensive comments. The majority of the earlier proposed toxicity detection methods are primarily focused on the English language, but there is a lack of research on low-resource languages and multilingual text data. We propose an XRBi-GAC framework comprising XLM-RoBERTa, Bi-GRU with self-attention and capsule networks for multilingual toxic text detection. A loss function is also presented, which fuses the binary cross-entropy loss and focal loss to address the class imbalance problem. We evaluated the proposed framework on two datasets, namely, the Jigsaw Multilingual Toxic Comment dataset and HASOC 2019 dataset and achieved F1-score of 0.865 and 0.829, respectively. The results of the experiments show that the proposed framework has outperformed the state-of-the-art multilingual models XLM-RoBERTa and mBERT on both datasets, which shows the versatility and robustness of the proposed XRBi-GAC framework.",1064-1246,1875-8967,,1409-1421, , ,,Use_dataset#detection#methodology,
3853,"Title:Metal and metal oxide nanoparticle toxicity: moving towards a more holistic structure-activity approach

 The recent emergence of nanotechnology has led to the rapid increase of intentional and unintentional exposure to engineered nanoparticles (NPs), raising concerns over their impact on humans, animals and ecosystems. The demanding experimental assessment of toxicity, compared with NP innovation and time to market, has led to the extensive development of in silico methods, such as SAR models, aiming at providing a more rapid toxicity screening of such NPs. However, such models are usually built upon a limited number of data, making the different approaches case-sensitive. Furthermore, the focus on the predictive capabilities of the models, deem the extraction of scientific knowledge secondary, hindering the mechanistic understanding of toxicity mechanisms. In this paper, we instead shift the focus by using the models as a first step towards induction and extraction of valuable mechanistic information, once the predictive ability of the model has been validated. For this reason, we use a large dataset consisting of 935 toxicity measurements for 45 metal and metal oxide NPs, to build classification nano-SAR models. To the best of the authors' knowledge, this is the largest dataset of individual toxicity measurements for such NPs. Although the dataset is heterogeneous, the models developed are able to accurately classify the NPs based on their toxicity towards a variety of cells and organisms, using the same descriptors. Based on the quality of the results, the potential mechanisms of toxicity are identified and discussed in depth, providing a more holistic approach towards metal and metal oxide NP toxicity. The presented approach aims to trigger a discussion regarding information that could be derived from nano-SAR models, that could pave the way towards a more knowledge-based risk assessment of NPs and guide researchers towards the synthesis of safe-by-design NPs.","Gakis, G. P.; Aviziotis, I. G.; Charitidis, C. A.","Gakis, Giorgos/IWE-1271-2023; Charitidis, Costas/ABI-2340-2022","Gakis, Giorgos/0000-0002-3879-7276; Charitidis, Costas/0000-0003-1367-7603",Metal and metal oxide nanoparticle toxicity: moving towards a more holistic structure-activity approach,10,3,10.1039/d2en00897a ,Article ,2023.0,"The recent emergence of nanotechnology has led to the rapid increase of intentional and unintentional exposure to engineered nanoparticles (NPs), raising concerns over their impact on humans, animals and ecosystems. The demanding experimental assessment of toxicity, compared with NP innovation and time to market, has led to the extensive development of in silico methods, such as SAR models, aiming at providing a more rapid toxicity screening of such NPs. However, such models are usually built upon a limited number of data, making the different approaches case-sensitive. Furthermore, the focus on the predictive capabilities of the models, deem the extraction of scientific knowledge secondary, hindering the mechanistic understanding of toxicity mechanisms. In this paper, we instead shift the focus by using the models as a first step towards induction and extraction of valuable mechanistic information, once the predictive ability of the model has been validated. For this reason, we use a large dataset consisting of 935 toxicity measurements for 45 metal and metal oxide NPs, to build classification nano-SAR models. To the best of the authors' knowledge, this is the largest dataset of individual toxicity measurements for such NPs. Although the dataset is heterogeneous, the models developed are able to accurately classify the NPs based on their toxicity towards a variety of cells and organisms, using the same descriptors. Based on the quality of the results, the potential mechanisms of toxicity are identified and discussed in depth, providing a more holistic approach towards metal and metal oxide NP toxicity. The presented approach aims to trigger a discussion regarding information that could be derived from nano-SAR models, that could pave the way towards a more knowledge-based risk assessment of NPs and guide researchers towards the synthesis of safe-by-design NPs.",2051-8153,2051-8161,,761-780, , ,,out_of_scope,
3854,"Title:Toxicity Detection: Does Context Really Matter?

 Moderation is crucial to promoting healthy online discussions. Although several 'toxicity' detection datasets and models have been published, most of them ignore the context of the posts, implicitly assuming that comments may be judged independently. We investigate this assumption by focusing on two questions: (a) does context affect the human judgement, and (b) does conditioning on context improve performance of toxicity detection systems? We experiment with Wikipedia conversations, limiting the notion of context to the previous post in the thread and the discussion title. We find that context can both amplify or mitigate the perceived toxicity of posts. Moreover, a small but significant subset of manually labeled posts (5% in one of our experiments) end up having the opposite toxicity labels if the annotators are not provided with context. Surprisingly, we also find no evidence that context actually improves the performance of toxicity classifiers, having tried a range of classifiers and mechanisms to make them context aware. This points to the need for larger datasets of comments annotated in context. We make our code and data publicly available.","Pavlopoulos, John; Sorensen, Jeffrey; Dixon, Lucas; Thain, Nithum; Androutsopoulos, Ion","Pavlopoulos, John/GPP-2913-2022; Dixon, Lucas/AFL-2608-2022; Sorensen, Jeffrey/GRE-9983-2022","Pavlopoulos, John/0000-0001-9188-7425; Androutsopoulos, Ion/0009-0000-2969-0509",Toxicity Detection: Does Context Really Matter?,,, ,Proceedings Paper ,2020.0,"Moderation is crucial to promoting healthy online discussions. Although several 'toxicity' detection datasets and models have been published, most of them ignore the context of the posts, implicitly assuming that comments may be judged independently. We investigate this assumption by focusing on two questions: (a) does context affect the human judgement, and (b) does conditioning on context improve performance of toxicity detection systems? We experiment with Wikipedia conversations, limiting the notion of context to the previous post in the thread and the discussion title. We find that context can both amplify or mitigate the perceived toxicity of posts. Moreover, a small but significant subset of manually labeled posts (5% in one of our experiments) end up having the opposite toxicity labels if the annotators are not provided with context. Surprisingly, we also find no evidence that context actually improves the performance of toxicity classifiers, having tried a range of classifiers and mechanisms to make them context aware. This points to the need for larger datasets of comments annotated in context. We make our code and data publicly available.",,,978-1-952148-25-5,4296-4305, , 58th Annual Meeting of the Association-for-Computational-Linguistics (ACL)58th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,Gen_dataset#detection#evaluation#methodology,
3855,"Title:Biomarkers of nanomaterials hazard from multi-layer data

 Nanomaterials have a range of potential applications, however, toxicity remains a concern, limiting application and requiring extensive testing. Here, the authors report on a predictive framework made using a range of tests linking materials properties with toxicity, allowing the prediction of toxicity from physiochemical and biological properties.There is an urgent need to apply effective, data-driven approaches to reliably predict engineered nanomaterial (ENM) toxicity. Here we introduce a predictive computational framework based on the molecular and phenotypic effects of a large panel of ENMs across multiple in vitro and in vivo models. Our methodology allows for the grouping of ENMs based on multi-omics approaches combined with robust toxicity tests. Importantly, we identify mRNA-based toxicity markers and extensively replicate them in multiple independent datasets. We find that models based on combinations of omics-derived features and material intrinsic properties display significantly improved predictive accuracy as compared to physicochemical properties alone.","Fortino, Vittorio; Kinaret, Pia Anneli Sofia; Fratello, Michele; Serra, Angela; Saarimaki, Laura Aliisa; Gallud, Audrey; Gupta, Govind; Vales, Gerard; Correia, Manuel; Rasool, Omid; Ytterberg, Jimmy; Monopoli, Marco; Skoog, Tiina; Ritchie, Peter; Moya, Sergio; Vazquez-Campos, Socorro; Handy, Richard; Grafstrom, Roland; Tran, Lang; Zubarev, Roman; Lahesmaa, Riitta; Dawson, Kenneth; Loeschner, Katrin; Larsen, Erik Husfeldt; Krombach, Fritz; Norppa, Hannu; Kere, Juha; Savolainen, Kai; Alenius, Harri; Fadeel, Bengt; Greco, Dario","Greco, Dario/T-7113-2019; Kere, Juha/A-9179-2008; Löschner, Katrin/AAA-1569-2020; Zubarev, Roman A/W-7891-2018","Greco, Dario/0000-0001-9195-9003; Kere, Juha/0000-0003-1974-0271; Löschner, Katrin/0000-0003-1741-8406; Zubarev, Roman A/0000-0001-9839-2089; Kinaret, Pia/0000-0002-3312-5331; Fortino, Vittorio/0000-0001-8693-5285; Moya, Sergio/0000-0002-7174-1960; Fratello, Michele/0000-0002-3997-2339; Gupta, Govind/0000-0003-4703-418X; Saarimaki, Laura Aliisa/0000-0003-1996-286X; Skoog, Tiina/0000-0002-0148-0654",Biomarkers of nanomaterials hazard from multi-layer data,13,1,10.1038/s41467-022-31609-5 ,Article ,2022.0,"Nanomaterials have a range of potential applications, however, toxicity remains a concern, limiting application and requiring extensive testing. Here, the authors report on a predictive framework made using a range of tests linking materials properties with toxicity, allowing the prediction of toxicity from physiochemical and biological properties.There is an urgent need to apply effective, data-driven approaches to reliably predict engineered nanomaterial (ENM) toxicity. Here we introduce a predictive computational framework based on the molecular and phenotypic effects of a large panel of ENMs across multiple in vitro and in vivo models. Our methodology allows for the grouping of ENMs based on multi-omics approaches combined with robust toxicity tests. Importantly, we identify mRNA-based toxicity markers and extensively replicate them in multiple independent datasets. We find that models based on combinations of omics-derived features and material intrinsic properties display significantly improved predictive accuracy as compared to physicochemical properties alone.",,2041-1723,,, , ,,out_of_scope,
3856,"Title:Revisiting Contextual Toxicity Detection in Conversations

 Understanding toxicity in user conversations is undoubtedly an important problem. Addressing covert or implicit cases of toxicity is particularly hard and requires context. Very fewprevious studies have analysed the influence of conversational context in human perception or in automated detection models. We dive deeper into both these directions. We start by analysing existing contextual datasets and find that toxicity labelling by humans is in general influenced by the conversational structure, polarity, and topic of the context. We then propose to bring these findings into computational detection models by introducing and evaluating (a) neural architectures for contextual toxicity detection that are aware of the conversational structure, and (b) data augmentation strategies that can help model contextual toxicity detection. Our results show the encouraging potential of neural architectures that are aware of the conversation structure. We also demonstrate that such models can benefit from synthetic data, especially in the social media domain.","Anuchitanukul, Atijit; Ive, Julia; Specia, Lucia",,"Ive, Julia/0000-0002-3931-3392",Revisiting Contextual Toxicity Detection in Conversations,15,1,10.1145/3561390 ,Article ,2023.0,"Understanding toxicity in user conversations is undoubtedly an important problem. Addressing covert or implicit cases of toxicity is particularly hard and requires context. Very fewprevious studies have analysed the influence of conversational context in human perception or in automated detection models. We dive deeper into both these directions. We start by analysing existing contextual datasets and find that toxicity labelling by humans is in general influenced by the conversational structure, polarity, and topic of the context. We then propose to bring these findings into computational detection models by introducing and evaluating (a) neural architectures for contextual toxicity detection that are aware of the conversational structure, and (b) data augmentation strategies that can help model contextual toxicity detection. Our results show the encouraging potential of neural architectures that are aware of the conversation structure. We also demonstrate that such models can benefit from synthetic data, especially in the social media domain.",1936-1955,,,, , ,,Use_dataset#detection#evaluation#methodology,
3857,"Title:An Assessment of Deep Learning Models and Word Embeddings for Toxicity Detection within Online Textual Comments

 Today, increasing numbers of people are interacting online and a lot of textual comments are being produced due to the explosion of online communication. However, a paramount inconvenience within online environments is that comments that are shared within digital platforms can hide hazards, such as fake news, insults, harassment, and, more in general, comments that may hurt someone's feelings. In this scenario, the detection of this kind of toxicity has an important role to moderate online communication. Deep learning technologies have recently delivered impressive performance within Natural Language Processing applications encompassing Sentiment Analysis and emotion detection across numerous datasets. Such models do not need any pre-defined hand-picked features, but they learn sophisticated features from the input datasets by themselves. In such a domain, word embeddings have been widely used as a way of representing words in Sentiment Analysis tasks, proving to be very effective. Therefore, in this paper, we investigated the use of deep learning and word embeddings to detect six different types of toxicity within online comments. In doing so, the most suitable deep learning layers and state-of-the-art word embeddings for identifying toxicity are evaluated. The results suggest that Long-Short Term Memory layers in combination with mimicked word embeddings are a good choice for this task.","Dessi, Danilo; Recupero, Diego Reforgiato; Sack, Harald",,"Dessi, Danilo/0000-0003-3843-3285; Sack, Harald/0000-0001-7069-9804; Reforgiato Recupero, Diego/0000-0001-8646-6183",An Assessment of Deep Learning Models and Word Embeddings for Toxicity Detection within Online Textual Comments,10,7,10.3390/electronics10070779 ,Article ,2021.0,"Today, increasing numbers of people are interacting online and a lot of textual comments are being produced due to the explosion of online communication. However, a paramount inconvenience within online environments is that comments that are shared within digital platforms can hide hazards, such as fake news, insults, harassment, and, more in general, comments that may hurt someone's feelings. In this scenario, the detection of this kind of toxicity has an important role to moderate online communication. Deep learning technologies have recently delivered impressive performance within Natural Language Processing applications encompassing Sentiment Analysis and emotion detection across numerous datasets. Such models do not need any pre-defined hand-picked features, but they learn sophisticated features from the input datasets by themselves. In such a domain, word embeddings have been widely used as a way of representing words in Sentiment Analysis tasks, proving to be very effective. Therefore, in this paper, we investigated the use of deep learning and word embeddings to detect six different types of toxicity within online comments. In doing so, the most suitable deep learning layers and state-of-the-art word embeddings for identifying toxicity are evaluated. The results suggest that Long-Short Term Memory layers in combination with mimicked word embeddings are a good choice for this task.",,2079-9292,,, , ,,detection#evaluation,
3858,"Title:Investigating toxicity changes of cross-community redditors from 2 billion posts and comments

 This research investigates changes in online behavior of users who publish in multiple communities on Reddit by measuring their toxicity at two levels. With the aid of crowdsourcing, we built a labeled dataset of 10,083 Reddit comments, then used the dataset to train and fine-tune a Bidirectional Encoder Representations from Transformers (BERT) neural network model. The model predicted the toxicity levels of 87,376,912 posts from 577,835 users and 2,205,581,786 comments from 890,913 users on Reddit over 16 years, from 2005 to 2020. This study utilized the toxicity levels of user content to identify toxicity changes by the user within the same community, across multiple communities, and over time. As for the toxicity detection performance, the BERT model achieved a 91.27% classification accuracy and an area under the receiver operating characteristic curve (AUC) score of 0.963 and outperformed several baseline machine learning and neural network models. The user behavior toxicity analysis showed that 16.11% of users publish toxic posts, and 13.28% of users publish toxic comments. However, results showed that 30.68% of users publishing posts and 81.67% of users publishing comments exhibit changes in their toxicity across different communities, indicating that users adapt their behavior to the communities' norms. Furthermore, time series analysis with the Granger causality test of the volume of links and toxicity in user content showed that toxic comments are Granger caused by links in comments.","Almerekhi, Hind; Kwak, Haewoon; Jansen, Bernard J.","Almerekhi, Hind/ITU-8218-2023","Almerekhi, Hind/0000-0002-3183-2374",Investigating toxicity changes of cross-community redditors from 2 billion posts and comments,8,,10.7717/peerj-cs.1059 ,Article ,2022.0,"This research investigates changes in online behavior of users who publish in multiple communities on Reddit by measuring their toxicity at two levels. With the aid of crowdsourcing, we built a labeled dataset of 10,083 Reddit comments, then used the dataset to train and fine-tune a Bidirectional Encoder Representations from Transformers (BERT) neural network model. The model predicted the toxicity levels of 87,376,912 posts from 577,835 users and 2,205,581,786 comments from 890,913 users on Reddit over 16 years, from 2005 to 2020. This study utilized the toxicity levels of user content to identify toxicity changes by the user within the same community, across multiple communities, and over time. As for the toxicity detection performance, the BERT model achieved a 91.27% classification accuracy and an area under the receiver operating characteristic curve (AUC) score of 0.963 and outperformed several baseline machine learning and neural network models. The user behavior toxicity analysis showed that 16.11% of users publish toxic posts, and 13.28% of users publish toxic comments. However, results showed that 30.68% of users publishing posts and 81.67% of users publishing comments exhibit changes in their toxicity across different communities, indicating that users adapt their behavior to the communities' norms. Furthermore, time series analysis with the Granger causality test of the volume of links and toxicity in user content showed that toxic comments are Granger caused by links in comments.",,2376-5992,,, , ,,Gen_dataset#detection#evaluation#methodology,
3859,"Title:Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection

 The perceived toxicity of language can vary based on someone's identity and beliefs, but this variation is often ignored when collecting toxic language datasets, resulting in dataset and model biases. We seek to understand the who, why, and what behind biases in toxicity annotations. In two online studies with demographically and politically diverse participants, we investigate the effect of annotator identities (who) and beliefs (why), drawing from social psychology research about hate speech, free speech, racist beliefs, political leaning, and more. We disentangle what is annotated as toxic by considering posts with three characteristics: anti-Black language, African American English (AAE) dialect, and vulgarity. Our results show strong associations between annotator identity and beliefs and their ratings of toxicity. Notably, more conservative annotators and those who scored highly on our scale for racist beliefs were less likely to rate anti-Black language as toxic, but more likely to rate AAE as toxic. We additionally present a case study illustrating how a popular toxicity detection system's ratings inherently reflect only specific beliefs and perspectives. Our findings call for contextualizing toxicity labels in social variables, which raises immense implications for toxic language annotation and detection.","Sap, Maarten; Swayamdipta, Swabha; Vianna, Laura; Zhou, Xuhui; Choi, Yejin; Smith, Noah A.",,,Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection,,, ,Proceedings Paper ,2022.0,"The perceived toxicity of language can vary based on someone's identity and beliefs, but this variation is often ignored when collecting toxic language datasets, resulting in dataset and model biases. We seek to understand the who, why, and what behind biases in toxicity annotations. In two online studies with demographically and politically diverse participants, we investigate the effect of annotator identities (who) and beliefs (why), drawing from social psychology research about hate speech, free speech, racist beliefs, political leaning, and more. We disentangle what is annotated as toxic by considering posts with three characteristics: anti-Black language, African American English (AAE) dialect, and vulgarity. Our results show strong associations between annotator identity and beliefs and their ratings of toxicity. Notably, more conservative annotators and those who scored highly on our scale for racist beliefs were less likely to rate anti-Black language as toxic, but more likely to rate AAE as toxic. We additionally present a case study illustrating how a popular toxicity detection system's ratings inherently reflect only specific beliefs and perspectives. Our findings call for contextualizing toxicity labels in social variables, which raises immense implications for toxic language annotation and detection.",,,978-1-955917-71-1,5884-5906, , Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language TechnologiesConference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies,,Use_dataset#detection#evaluation,
3860,"Title:Machine learning prediction of nanoparticle in vitro toxicity: A comparative study of classifiers and ensemble-classifiers using the Copeland Index

 Nano-Particles (NPs) are well established as important components across a broad range of products from cosmetics to electronics. Their utilization is increasing with their significant economic and societal potential yet to be fully realized. Inroads have been made in our understanding of the risks posed to human health and the environment by NPs but this area will require continuous research and monitoring. In recent years Machine Learning (ML) techniques have exploited large datasets and computation power to create breakthroughs in diverse fields from facial recognition to genomics. More recently, ML techniques have been applied to nanotoxicology with very encouraging results. In this study, categories of ML classifiers (rules, trees, lazy, functions and bayes) were compared using datasets from the Safe and Sustainable Nanotechnology (S2NANO) database to investigate their performance in predicting NPs in vitro toxicity. Physicochemical properties, toxicological and quantum-mechanical attributes and in vitro experimental conditions were used as input variables to predict the toxicity of NPs based on cell viability. Voting, an ensemble meta-classifier, was used to combine base models to optimize the classification prediction of toxicity. To facilitate inter-comparison, a Copeland Index was applied that ranks the classifiers according to their performance and suggested the optimal classifier. Neural Network (NN) and Random forest (RF) showed the best performance in the majority of the datasets used in this study. However, the combination of classifiers demonstrated an improved prediction resulting meta-classifier to have higher indices. This proposed Copeland Index can now be used by researchers to identify and clearly prioritize classifiers in order to achieve more accurate classification predictions for NP toxicity for a given dataset.","Furxhi, Irini; Murphy, Finbarr; Mullins, Martin; Poland, Craig A.","Murphy, Finbarr/B-5254-2015; Poland, Craig/AAM-8237-2020","Murphy, Finbarr/0000-0002-7463-7923; Furxhi, Irini/0000-0002-2263-0279; Poland, Craig/0000-0002-5345-1249; mullins, martin/0000-0002-1954-2630",Machine learning prediction of nanoparticle in vitro toxicity: A comparative study of classifiers and ensemble-classifiers using the Copeland Index,312,,10.1016/j.toxlet.2019.05.016 ,Article ,2019.0,"Nano-Particles (NPs) are well established as important components across a broad range of products from cosmetics to electronics. Their utilization is increasing with their significant economic and societal potential yet to be fully realized. Inroads have been made in our understanding of the risks posed to human health and the environment by NPs but this area will require continuous research and monitoring. In recent years Machine Learning (ML) techniques have exploited large datasets and computation power to create breakthroughs in diverse fields from facial recognition to genomics. More recently, ML techniques have been applied to nanotoxicology with very encouraging results. In this study, categories of ML classifiers (rules, trees, lazy, functions and bayes) were compared using datasets from the Safe and Sustainable Nanotechnology (S2NANO) database to investigate their performance in predicting NPs in vitro toxicity. Physicochemical properties, toxicological and quantum-mechanical attributes and in vitro experimental conditions were used as input variables to predict the toxicity of NPs based on cell viability. Voting, an ensemble meta-classifier, was used to combine base models to optimize the classification prediction of toxicity. To facilitate inter-comparison, a Copeland Index was applied that ranks the classifiers according to their performance and suggested the optimal classifier. Neural Network (NN) and Random forest (RF) showed the best performance in the majority of the datasets used in this study. However, the combination of classifiers demonstrated an improved prediction resulting meta-classifier to have higher indices. This proposed Copeland Index can now be used by researchers to identify and clearly prioritize classifiers in order to achieve more accurate classification predictions for NP toxicity for a given dataset.",0378-4274,1879-3169,,157-166, , ,,out_of_scope,
3861,"Title:Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis

 Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76% macro-F1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.","Leite, Joao A.; Silva, Diego F.; Bontcheva, Kalina; Scarton, Carolina","Furtado Silva, Diego/K-3306-2016","Furtado Silva, Diego/0000-0002-5184-9413; Scarton, Carolina/0000-0002-0103-4072",Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis,,, ,Proceedings Paper ,2020.0,"Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76% macro-F1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.",,,978-1-952148-91-0,914-924, , 1st Conference of the Asia-Pacific Chapter of the Association-for-Computational-Linguistics / 10th International Joint Conference on Natural Language Processing (AACL-IJCNLP)1st Conference of the Asia-Pacific Chapter of the Association-for-Computational-Linguistics / 10th International Joint Conference on Natural Language Processing (AACL-IJCNLP),,Gen_dataset#detection#out_but_toxicity,
3862,"Title:Protecting marginalized communities by mitigating discrimination in toxic language detection

 As the harms of online toxic language become more apparent, countering online toxic behavior is an essential application of natural language processing. The first step in managing toxic language risk is identification, but algorithmic approaches have themselves demonstrated bias. Texts containing some demographic identity terms such as gay or Black are more likely to be labeled as toxic in existing toxic language detection datasets. In many machine learning models introduced for toxic language detection, non-toxic comments containing minority and marginalized community-specific identity terms were given unreasonably high toxicity scores. To address the challenge of bias in toxic language detection, we propose a two-step training approach. A pretrained language model with a multitask learning objective will mitigate biases in the toxicity classifier prediction. Experiments demonstrate that jointly training the pretrained language model with a multitask objective can effectively mitigate the impacts of unintended biases and is more robust to model bias towards commonly-attacked identity groups presented in datasets without significantly hurting the model's generalizability.","Faal, Farshid; Schmitt, Ketra; Yu, Jia Yuan","Schmitt, Ketra/GWQ-5329-2022","Faal, Farshid/0000-0002-2555-3221",Protecting marginalized communities by mitigating discrimination in toxic language detection,,,10.1109/ISTAS52410.2021.9629201 ,Proceedings Paper ,2021.0,"As the harms of online toxic language become more apparent, countering online toxic behavior is an essential application of natural language processing. The first step in managing toxic language risk is identification, but algorithmic approaches have themselves demonstrated bias. Texts containing some demographic identity terms such as gay or Black are more likely to be labeled as toxic in existing toxic language detection datasets. In many machine learning models introduced for toxic language detection, non-toxic comments containing minority and marginalized community-specific identity terms were given unreasonably high toxicity scores. To address the challenge of bias in toxic language detection, we propose a two-step training approach. A pretrained language model with a multitask learning objective will mitigate biases in the toxicity classifier prediction. Experiments demonstrate that jointly training the pretrained language model with a multitask objective can effectively mitigate the impacts of unintended biases and is more robust to model bias towards commonly-attacked identity groups presented in datasets without significantly hurting the model's generalizability.",2158-3404,,978-1-6654-3580-2,, , IEEE International Symposium on Technology and Society (ISTAS) - Technological Stewardship and Responsible InnovationIEEE International Symposium on Technology and Society (ISTAS) - Technological Stewardship and Responsible Innovation,,detection#methodology,
3863,"Title:Fortifying Toxic Speech Detectors Against Veiled Toxicity

 Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector's training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity.(1)Warning: this paper contains examples that may be offensive or upsetting.","Han, Xiaochuang; Tsvetkov, Yulia",,,Fortifying Toxic Speech Detectors Against Veiled Toxicity,,, ,Proceedings Paper ,2020.0,"Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector's training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity.(1)Warning: this paper contains examples that may be offensive or upsetting.",,,978-1-952148-60-6,7732-7739, , Conference on Empirical Methods in Natural Language Processing (EMNLP)Conference on Empirical Methods in Natural Language Processing (EMNLP),,Use_dataset#detection#methodology,
3864,"Title:Overview of DETOXIS at IberLEF 2021: DEtection of TOXicity in comments In Spanish

 In this paper we present the DETOXIS task, DEtection of TOxicity in comments In Spanish, which took place as part of the IberLEF 2021 Workshop on Iberian Languages Evaluation Forum at the SEPLN 2021 Conference. We describe the NewsCom-TOX dataset used for training and testing the systems, the metrics applied for their evaluation and the results obtained by the submitted approaches. We also provide an error analysis of the results of these systems.","Taule, Mariona; Ariza, Alejandro; Notre, Montserrat; Amigo, Enrique; Rosso, Paolo","Taulé, Mariona/G-9732-2015","Taulé, Mariona/0000-0003-0089-940X; Ariza-Casabona, Alejandro/0000-0002-3388-2316",Overview of DETOXIS at IberLEF 2021: DEtection of TOXicity in comments In Spanish,,67,10.26342/2021-67-18 ,Article ,2021.0,"In this paper we present the DETOXIS task, DEtection of TOxicity in comments In Spanish, which took place as part of the IberLEF 2021 Workshop on Iberian Languages Evaluation Forum at the SEPLN 2021 Conference. We describe the NewsCom-TOX dataset used for training and testing the systems, the metrics applied for their evaluation and the results obtained by the submitted approaches. We also provide an error analysis of the results of these systems.",1135-5948,1989-7553,,209-221, , ,,Use_dataset#detection#out_but_toxicity,
3865,"Title:Multilingual Sentiment Analysis and Toxicity Detection for Text Messages in Russian

 In this paper, we discuss an approach to sentiment analysis and emotion identification for user comments. The solution is threefold: 1) topic detection, 2) sentiment evaluation, 3) toxicity detection and toxic spans localization. The lack of significantly large training data for the Russian language is handled by utilizing multilingual word embeddings, the adversarial domain adaptation model, and data augmentation. We present an overview of various preprocessing pipelines for topic modeling and highlight the LDA-Mallet model which demonstrates the best performance. For sentiment analysis and toxicity detection, we examine the efficacy of a support vector machine and a deep neural network with a multilingual language model and adversarial domain adaptation that allows us to train algorithms with datasets in the English language. All methods are tested with a dataset of user comments to various online-courses and adjusted to provide support for the development of a virtual dialogue assistant for conducting virtual exams.","Bogoradnikova, Darya; Makhnytkina, Olesia; Matveev, Anton; Zakharova, Anastasia; Akulov, Artem","Makhnytkina, Olesia/F-2283-2017; Matveev, Anton/U-8423-2019","Makhnytkina, Olesia/0000-0002-8992-9654; Matveev, Anton/0000-0001-7494-8329",Multilingual Sentiment Analysis and Toxicity Detection for Text Messages in Russian,,, ,Proceedings Paper ,2021.0,"In this paper, we discuss an approach to sentiment analysis and emotion identification for user comments. The solution is threefold: 1) topic detection, 2) sentiment evaluation, 3) toxicity detection and toxic spans localization. The lack of significantly large training data for the Russian language is handled by utilizing multilingual word embeddings, the adversarial domain adaptation model, and data augmentation. We present an overview of various preprocessing pipelines for topic modeling and highlight the LDA-Mallet model which demonstrates the best performance. For sentiment analysis and toxicity detection, we examine the efficacy of a support vector machine and a deep neural network with a multilingual language model and adversarial domain adaptation that allows us to train algorithms with datasets in the English language. All methods are tested with a dataset of user comments to various online-courses and adjusted to provide support for the development of a virtual dialogue assistant for conducting virtual exams.",2305-7254,2343-0737,978-952-69244-5-8,55-64, , 29th Conference of Open-Innovations Association (FRUCT)29th Conference of Open-Innovations Association (FRUCT),,detection#methodology#out_but_toxicity,
3866,"Title:Machine learning algorithms for outcome prediction in (chemo)radiotherapy: An empirical comparison of classifiers

 PurposeMachine learning classification algorithms (classifiers) for prediction of treatment response are becoming more popular in radiotherapy literature. General Machine learning literature provides evidence in favor of some classifier families (random forest, support vector machine, gradient boosting) in terms of classification performance. The purpose of this study is to compare such classifiers specifically for (chemo)radiotherapy datasets and to estimate their average discriminative performance for radiation treatment outcome prediction.MethodsWe collected 12 datasets (3496 patients) from prior studies on post-(chemo)radiotherapy toxicity, survival, or tumor control with clinical, dosimetric, or blood biomarker features from multiple institutions and for different tumor sites, that is, (non-)small-cell lung cancer, head and neck cancer, and meningioma. Six common classification algorithms with built-in feature selection (decision tree, random forest, neural network, support vector machine, elastic net logistic regression, LogitBoost) were applied on each dataset using the popular open-source R package caret. The R code and documentation for the analysis are available online (). All classifiers were run on each dataset in a 100-repeated nested fivefold cross-validation with hyperparameter tuning. Performance metrics (AUC, calibration slope and intercept, accuracy, Cohen's kappa, and Brier score) were computed. We ranked classifiers by AUC to determine which classifier is likely to also perform well in future studies. We simulated the benefit for potential investigators to select a certain classifier for a new dataset based on our study (pre-selection based on other datasets) or estimating the best classifier for a dataset (set-specific selection based on information from the new dataset) compared with uninformed classifier selection (random selection).ResultsRandom forest (best in 6/12 datasets) and elastic net logistic regression (best in 4/12 datasets) showed the overall best discrimination, but there was no single best classifier across datasets. Both classifiers had a median AUC rank of 2. Preselection and set-specific selection yielded a significant average AUC improvement of 0.02 and 0.02 over random selection with an average AUC rank improvement of 0.42 and 0.66, respectively.ConclusionRandom forest and elastic net logistic regression yield higher discriminative performance in (chemo)radiotherapy outcome and toxicity prediction than other studied classifiers. Thus, one of these two classifiers should be the first choice for investigators when building classification models or to benchmark one's own modeling results against. Our results also show that an informed preselection of classifiers based on existing datasets can improve discrimination over random selection.","Deist, Timo M.; Dankers, Frank J. W. M.; Valdes, Gilmer; Wijsman, Robin; Hsu, I-Chow; Oberije, Cary; Lustberg, Tim; van Soest, Johan; Hoebers, Frank; Jochems, Arthur; El Naqa, Issam; Wee, Leonard; Morin, Olivier; Raleigh, David R.; Bots, Wouter; Kaanders, Johannes H.; Belderbos, Jose; Kwint, Margriet; Solberg, Timothy; Monshouwer, Rene; Bussink, Johan; Dekker, Andre; Lambin, Philippe","Monshouwer, R./L-4527-2015; Wee, Leonard/AAH-3548-2019; Naqa, Issam El/T-3066-2019; Oberije, Cary/ABA-6178-2020; van Soest, Johan/G-3586-2013; Wijsman, Robin/N-5603-2015; Kaanders, Hans/A-7432-2014; Dekker, Andre/AAE-4830-2019; Dankers, Frank/M-6658-2015; Bussink, Jan/N-3584-2014","Wee, Leonard/0000-0003-1612-9055; Naqa, Issam El/0000-0001-6023-1132; Oberije, Cary/0000-0003-0749-5117; Kaanders, Hans/0000-0001-5374-9558; Dekker, Andre/0000-0002-0422-7996; Dankers, Frank/0009-0000-1354-3723; Solberg, Timothy/0000-0001-8829-7774; Hoebers, Frank/0000-0002-4317-9181; van Soest, Johan/0000-0003-2548-0330; Lambin, Philippe/0000-0001-7961-0191; Bussink, Johan/0000-0002-5751-4796",Machine learning algorithms for outcome prediction in (chemo)radiotherapy: An empirical comparison of classifiers,45,7,10.1002/mp.12967 ,Article ,2018.0,"PurposeMachine learning classification algorithms (classifiers) for prediction of treatment response are becoming more popular in radiotherapy literature. General Machine learning literature provides evidence in favor of some classifier families (random forest, support vector machine, gradient boosting) in terms of classification performance. The purpose of this study is to compare such classifiers specifically for (chemo)radiotherapy datasets and to estimate their average discriminative performance for radiation treatment outcome prediction.MethodsWe collected 12 datasets (3496 patients) from prior studies on post-(chemo)radiotherapy toxicity, survival, or tumor control with clinical, dosimetric, or blood biomarker features from multiple institutions and for different tumor sites, that is, (non-)small-cell lung cancer, head and neck cancer, and meningioma. Six common classification algorithms with built-in feature selection (decision tree, random forest, neural network, support vector machine, elastic net logistic regression, LogitBoost) were applied on each dataset using the popular open-source R package caret. The R code and documentation for the analysis are available online (). All classifiers were run on each dataset in a 100-repeated nested fivefold cross-validation with hyperparameter tuning. Performance metrics (AUC, calibration slope and intercept, accuracy, Cohen's kappa, and Brier score) were computed. We ranked classifiers by AUC to determine which classifier is likely to also perform well in future studies. We simulated the benefit for potential investigators to select a certain classifier for a new dataset based on our study (pre-selection based on other datasets) or estimating the best classifier for a dataset (set-specific selection based on information from the new dataset) compared with uninformed classifier selection (random selection).ResultsRandom forest (best in 6/12 datasets) and elastic net logistic regression (best in 4/12 datasets) showed the overall best discrimination, but there was no single best classifier across datasets. Both classifiers had a median AUC rank of 2. Preselection and set-specific selection yielded a significant average AUC improvement of 0.02 and 0.02 over random selection with an average AUC rank improvement of 0.42 and 0.66, respectively.ConclusionRandom forest and elastic net logistic regression yield higher discriminative performance in (chemo)radiotherapy outcome and toxicity prediction than other studied classifiers. Thus, one of these two classifiers should be the first choice for investigators when building classification models or to benchmark one's own modeling results against. Our results also show that an informed preselection of classifiers based on existing datasets can improve discrimination over random selection.",0094-2405,2473-4209,,3449-3459, , ,,,
3867,"Title:Curation of datasets, assessment of their quality and completeness, and nanoSAR classification model development for metallic nanoparticles

 Applications of machine learning techniques for the prediction of nanotoxicity are expected to reduce time and cost of nanosafety assessments. However, due to the rapid increases in literature data quantity and heterogeneity on nanomaterials, efficient screening of data based on their quality and completeness are becoming more important for the development of reliable nanostructure-activity relationship (nanoSAR) models. Herein, we have curated a nanosafety dataset of metallic NPs, with 2005 rows and 31 columns extracted from literature data mining of 63 published articles and gap filling by adapting data from manufacturer specification or references on the same nanomaterials. By using PChem scores based on physicochemical data quality and completeness, five datasets with different qualities and degrees of completeness were generated and used for the development of toxicity classification models of metallic NPs. Comparisons of these models, built with support vector machine and random forest algorithms, confirmed us that the datasets with higher quality and completeness (i.e., higher PChem score) produced better performing nanoSAR models than those with lower PChem scores. Further analysis of relative attribute importance showed that the physicochemical properties, core size and surface charge, and the experimental conditions of toxicity assays, dose and cell lines, are the four most important attributes to the toxicity of metallic NPs.","Trinh, Tung X.; Ha, My Kieu; Choi, Jang Sik; Byun, Hyung Gi; Yoon, Tae Hyun","Ha, My/AAD-6310-2021","Ha, My/0000-0002-6262-341X; Trinh, Xuan-Tung/0000-0002-8961-2876","Curation of datasets, assessment of their quality and completeness, and nanoSAR classification model development for metallic nanoparticles",5,8,10.1039/c8en00061a ,Article ,2018.0,"Applications of machine learning techniques for the prediction of nanotoxicity are expected to reduce time and cost of nanosafety assessments. However, due to the rapid increases in literature data quantity and heterogeneity on nanomaterials, efficient screening of data based on their quality and completeness are becoming more important for the development of reliable nanostructure-activity relationship (nanoSAR) models. Herein, we have curated a nanosafety dataset of metallic NPs, with 2005 rows and 31 columns extracted from literature data mining of 63 published articles and gap filling by adapting data from manufacturer specification or references on the same nanomaterials. By using PChem scores based on physicochemical data quality and completeness, five datasets with different qualities and degrees of completeness were generated and used for the development of toxicity classification models of metallic NPs. Comparisons of these models, built with support vector machine and random forest algorithms, confirmed us that the datasets with higher quality and completeness (i.e., higher PChem score) produced better performing nanoSAR models than those with lower PChem scores. Further analysis of relative attribute importance showed that the physicochemical properties, core size and surface charge, and the experimental conditions of toxicity assays, dose and cell lines, are the four most important attributes to the toxicity of metallic NPs.",2051-8153,2051-8161,,1902-1910, , ,,out_of_scope,
3868,"Title:Protein-Based Data Augmentation for the Prediction of Peptide Toxicity Using Deep Learning

 Peptides have a promising pharmaceutical value with its small side effect and high specificity. While their unclear toxicity is one of the key bottlenecks preventing them from being widely used in clinical practice. To save time and labor, many computation-aided models have been proposed to do binary classification of peptide toxicity. However, limited by the availability of datasets about peptide toxicity, it is hard to improve the performance of computational aided models. Given the situation that there are a substantial number of available protein toxicity data, we proposed a simple deep learning model with convolution layer and LSTM and applied protein-based data augmentation on it. Experimental results show there is an obvious increase in precision using protein-based data augmentation on the proposed deep learning model.","Cai, Jianxiu; Wang, Yapeng; Siu, Shirley W. I.",,,Protein-Based Data Augmentation for the Prediction of Peptide Toxicity Using Deep Learning,,,10.1109/ICBCB57893.2023.10246599 ,Proceedings Paper ,2023.0,"Peptides have a promising pharmaceutical value with its small side effect and high specificity. While their unclear toxicity is one of the key bottlenecks preventing them from being widely used in clinical practice. To save time and labor, many computation-aided models have been proposed to do binary classification of peptide toxicity. However, limited by the availability of datasets about peptide toxicity, it is hard to improve the performance of computational aided models. Given the situation that there are a substantial number of available protein toxicity data, we proposed a simple deep learning model with convolution layer and LSTM and applied protein-based data augmentation on it. Experimental results show there is an obvious increase in precision using protein-based data augmentation on the proposed deep learning model.",,,979-8-3503-9787-1,136-140, , 11th International Conference on Bioinformatics and Computational Biology (ICBCB)11th International Conference on Bioinformatics and Computational Biology (ICBCB),,out_of_scope,
3869,"Title:Social Media Toxicity Classification Using Deep Learning: Real-World Application UK Brexit

 Social media has become an essential facet of modern society, wherein people share their opinions on a wide variety of topics. Social media is quickly becoming indispensable for a majority of people, and many cases of social media addiction have been documented. Social media platforms such as Twitter have demonstrated over the years the value they provide, such as connecting people from all over the world with different backgrounds. However, they have also shown harmful side effects that can have serious consequences. One such harmful side effect of social media is the immense toxicity that can be found in various discussions. The word toxic has become synonymous with online hate speech, internet trolling, and sometimes outrage culture. In this study, we build an efficient model to detect and classify toxicity in social media from user-generated content using the Bidirectional Encoder Representations from Transformers (BERT). The BERT pre-trained model and three of its variants has been fine-tuned on a well-known labeled toxic comment dataset, Kaggle public dataset (Toxic Comment Classification Challenge). Moreover, we test the proposed models with two datasets collected from Twitter from two different periods to detect toxicity in user-generated content (tweets) using hashtages belonging to the UK Brexit. The results showed that the proposed model can efficiently classify and analyze toxic tweets.","Fan, Hong; Du, Wu; Dahou, Abdelghani; Ewees, Ahmed A.; Yousri, Dalia; Abd Elaziz, Mohamed; Elsheikh, Ammar H.; Abualigah, Laith; Al-qaness, Mohammed A. A.",", mohamed/AAH-8886-2019; Yousri, Dalia/L-2678-2019; yousri, dalia/AAY-5345-2021; Dahou, Abdelghani/ACG-1247-2022; Elsheikh, Ammar/JQI-5341-2023; Abualigah, Laith/ABC-9695-2020; Al-qaness, Mohammed/ABE-7552-2020",", mohamed/0000-0002-7682-6269; yousri, dalia/0000-0001-6551-2371; Dahou, Abdelghani/0000-0003-4561-2185; Elsheikh, Ammar/0000-0003-0944-4938; Abualigah, Laith/0000-0002-2203-4549; Al-qaness, Mohammed/0000-0002-6956-7641",Social Media Toxicity Classification Using Deep Learning: Real-World Application UK Brexit,10,11,10.3390/electronics10111332 ,Article ,2021.0,"Social media has become an essential facet of modern society, wherein people share their opinions on a wide variety of topics. Social media is quickly becoming indispensable for a majority of people, and many cases of social media addiction have been documented. Social media platforms such as Twitter have demonstrated over the years the value they provide, such as connecting people from all over the world with different backgrounds. However, they have also shown harmful side effects that can have serious consequences. One such harmful side effect of social media is the immense toxicity that can be found in various discussions. The word toxic has become synonymous with online hate speech, internet trolling, and sometimes outrage culture. In this study, we build an efficient model to detect and classify toxicity in social media from user-generated content using the Bidirectional Encoder Representations from Transformers (BERT). The BERT pre-trained model and three of its variants has been fine-tuned on a well-known labeled toxic comment dataset, Kaggle public dataset (Toxic Comment Classification Challenge). Moreover, we test the proposed models with two datasets collected from Twitter from two different periods to detect toxicity in user-generated content (tweets) using hashtages belonging to the UK Brexit. The results showed that the proposed model can efficiently classify and analyze toxic tweets.",,2079-9292,,, , ,,Gen_dataset#Use_dataset#detection,
3870,"Title:ToxinPred2: an improved method for predicting toxicity of proteins

 Proteins/peptides have shown to be promising therapeutic agents for a variety of diseases. However, toxicity is one of the obstacles in protein/peptide-based therapy. The current study describes a web-based tool, ToxinPred2, developed for predicting the toxicity of proteins. This is an update of ToxinPred developed mainly for predicting toxicity of peptides and small proteins. The method has been trained, tested and evaluated on three datasets curated from the recent release of the SwissProt. To provide unbiased evaluation, we performed internal validation on 80% of the data and external validation on the remaining 20% of data. We have implemented the following techniques for predicting protein toxicity; (i) Basic Local Alignment Search Tool-based similarity, (ii) Motif-EmeRging and with Classes-Identification-based motif search and (iii) Prediction models. Similarity and motif-based techniques achieved a high probability of correct prediction with poor sensitivity/coverage, whereas models based on machine-learning techniques achieved balance sensitivity and specificity with reasonably high accuracy. Finally, we developed a hybrid method that combined all three approaches and achieved a maximum area under receiver operating characteristic curve around 0.99 with Matthews correlation coefficient 0.91 on the validation dataset. In addition, we developed models on alternate and realistic datasets. The best machine learning models have been implemented in the web server named 'ToxinPred2', which is available at https://webs.iiitd.edu.in/raghava/toxinpred2/ and a standalone version at https://github.com/raghavagps/toxinpred2. This is a general method developed for predicting the toxicity of proteins regardless of their source of origin.","Sharma, Neelam; Naorem, Leimarembi Devi; Jain, Shipra; Raghava, Gajendra P. S.","Raghava, Gajendra/B-1717-2009","Raghava, Gajendra/0000-0002-8902-2876; Jain, Shipra/0000-0002-7045-5188; Sharma, Neelam/0000-0002-1765-3644",ToxinPred2: an improved method for predicting toxicity of proteins,23,5,10.1093/bib/bbac174 ,Article ,2022.0,"Proteins/peptides have shown to be promising therapeutic agents for a variety of diseases. However, toxicity is one of the obstacles in protein/peptide-based therapy. The current study describes a web-based tool, ToxinPred2, developed for predicting the toxicity of proteins. This is an update of ToxinPred developed mainly for predicting toxicity of peptides and small proteins. The method has been trained, tested and evaluated on three datasets curated from the recent release of the SwissProt. To provide unbiased evaluation, we performed internal validation on 80% of the data and external validation on the remaining 20% of data. We have implemented the following techniques for predicting protein toxicity; (i) Basic Local Alignment Search Tool-based similarity, (ii) Motif-EmeRging and with Classes-Identification-based motif search and (iii) Prediction models. Similarity and motif-based techniques achieved a high probability of correct prediction with poor sensitivity/coverage, whereas models based on machine-learning techniques achieved balance sensitivity and specificity with reasonably high accuracy. Finally, we developed a hybrid method that combined all three approaches and achieved a maximum area under receiver operating characteristic curve around 0.99 with Matthews correlation coefficient 0.91 on the validation dataset. In addition, we developed models on alternate and realistic datasets. The best machine learning models have been implemented in the web server named 'ToxinPred2', which is available at https://webs.iiitd.edu.in/raghava/toxinpred2/ and a standalone version at https://github.com/raghavagps/toxinpred2. This is a general method developed for predicting the toxicity of proteins regardless of their source of origin.",1467-5463,1477-4054,,, , ,,out_of_scope,
3871,"Title:Boosting Tree-Assisted Multitask Deep Learning for Small Scientific Datasets

 Machine learning approaches have had tremendous success in various disciplines. However, such success highly depends on the size and quality of datasets. Scientific datasets are often small and difficult to collect. Currently, improving machine learning performance for small scientific datasets remains a major challenge in many academic fields, such as bioinformatics or medical science. Gradient boosting decision tree (GBDT) is typically optimal for small datasets, while deep learning often performs better for large datasets. This work reports a boosting tree-assisted multitask deep learning (BTAMDL) architecture that integrates GBDT and multitask deep learning (MDL) to achieve near-optimal predictions for small datasets when there exists a large dataset that is well correlated to the small datasets. Two BTAMDL models are constructed, one utilizing purely MDL output as GBDT input while the other admitting additional features in GBDT input. The proposed BTAMDL models are validated on four categories of datasets, including toxicity, partition coefficient, solubility, and solvation. It is found that the proposed BTAMDL models outperform the current state-of-the-art methods in various applications involving small datasets.","Jiang, Jian; Wang, Rui; Wang, Menglun; Gao, Kaifu; Duc Duy Nguyen; Wei, Guo-Wei","Wang, Rui/ACY-8149-2022; Nguyen, Duc/A-3716-2017","Wang, Rui/0000-0002-7402-6372; Nguyen, Duc/0000-0002-5921-8851; Wei, Guowei/0000-0002-5781-2937",Boosting Tree-Assisted Multitask Deep Learning for Small Scientific Datasets,60,3,10.1021/acs.jcim.9b01184 ,Article ,2020.0,"Machine learning approaches have had tremendous success in various disciplines. However, such success highly depends on the size and quality of datasets. Scientific datasets are often small and difficult to collect. Currently, improving machine learning performance for small scientific datasets remains a major challenge in many academic fields, such as bioinformatics or medical science. Gradient boosting decision tree (GBDT) is typically optimal for small datasets, while deep learning often performs better for large datasets. This work reports a boosting tree-assisted multitask deep learning (BTAMDL) architecture that integrates GBDT and multitask deep learning (MDL) to achieve near-optimal predictions for small datasets when there exists a large dataset that is well correlated to the small datasets. Two BTAMDL models are constructed, one utilizing purely MDL output as GBDT input while the other admitting additional features in GBDT input. The proposed BTAMDL models are validated on four categories of datasets, including toxicity, partition coefficient, solubility, and solvation. It is found that the proposed BTAMDL models outperform the current state-of-the-art methods in various applications involving small datasets.",1549-9596,1549-960X,,1235-1244, , ,,out_of_scope,
3872,"Title:IN VIVO TOXICITY OF NITROAROMATICS: A COMPREHENSIVE QUANTITATIVE STRUCTURE-ACTIVITY RELATIONSHIP STUDY

 The toxicity data of 90 nitroaromatic compounds related to their 50% lethal dose concentration for rats (LD50) were analyzed to develop quantitative structure-activity relationship (QSAR) models. Quantum-chemically calculated descriptors together with molecular descriptors generated by DRAGON, PaDEL, and HiT-QSAR software were utilized to build QSAR models. Quality and validity of the models were determined by internal and external validation techniques. The results show that the toxicity of nitroaromatic compounds depends on various factors, such as the number of nitro-groups, the topological state, and the presence of certain structural fragments. The developed models based on the largest (to date) dataset of nitroaromatics in vivo toxicity showed a good predictive ability. The results provide important input that could be applied in a preliminary assessment of nitroaromatic compounds' toxicity to mammals. (C) 2017 SETAC.","Gooch, Aminah; Sizochenko, Natalia; Rasulev, Bakhtiyor; Gorb, Leonid; Leszczynski, Jerzy","Sizochenko, Natalia/C-5293-2016; Rasulev, Bakhtiyor/A-3030-2008; Gooch, Aminah/P-6100-2015; Gorb, Leonid/AAP-3278-2020","Sizochenko, Natalia/0000-0002-7039-7969; Rasulev, Bakhtiyor/0000-0002-7845-4884; Gooch, Aminah/0000-0002-0031-9260;",IN VIVO TOXICITY OF NITROAROMATICS: A COMPREHENSIVE QUANTITATIVE STRUCTURE-ACTIVITY RELATIONSHIP STUDY,36,8,10.1002/etc.3761 ,Article ,2017.0,"The toxicity data of 90 nitroaromatic compounds related to their 50% lethal dose concentration for rats (LD50) were analyzed to develop quantitative structure-activity relationship (QSAR) models. Quantum-chemically calculated descriptors together with molecular descriptors generated by DRAGON, PaDEL, and HiT-QSAR software were utilized to build QSAR models. Quality and validity of the models were determined by internal and external validation techniques. The results show that the toxicity of nitroaromatic compounds depends on various factors, such as the number of nitro-groups, the topological state, and the presence of certain structural fragments. The developed models based on the largest (to date) dataset of nitroaromatics in vivo toxicity showed a good predictive ability. The results provide important input that could be applied in a preliminary assessment of nitroaromatic compounds' toxicity to mammals. (C) 2017 SETAC.",0730-7268,1552-8618,,2227-2233, , ,,out_of_scope,
3873,"Title:OLID-BR: offensive language identification dataset for Brazilian Portuguese

 Social media has revolutionized the manner in which our society is interconnected. While this extensive connectivity offers numerous benefits, it is also accompanied by significant drawbacks, particularly in terms of the proliferation of fake news and the vast dissemination of hate speech. Identifying offensive comments is a critical task for ensuring the safety of users, which is why industry and academia have been working on developing solutions to this problem. Prior research on hate speech detection has predominantly focused on the English language, with few studies devoted to other languages such as Portuguese. This paper introduces the Offensive Language Identification Dataset for Brazilian Portuguese (OLID-BR), a high-quality NLP dataset for offensive language detection, which we make publicly available. The dataset contains 6,354 (extendable to 13,538) comments labeled using a fine-grained three-layer annotation schema compatible with datasets in other languages, which allows the training of multilingual/cross-lingual models. The five NLP tasks available in OLID-BR allow the detection of offensive comments, the classification of the types of offenses such as racism, LGBTQphobia, sexism, xenophobia, and so on, the identification of the type and the target of offensive comments, and the extraction of toxic spans of offensive comments. All those tasks can enhance the capabilities of content moderation systems by providing deep contextual analysis or highlighting the spans that make a text toxic. We further experiment with and evaluate the dataset using state-of-the-art BERT-based and NER models, which demonstrates the usefulness of OLID-BR for the development of toxicity detection systems for Portuguese texts.","Trajano, Douglas; Bordini, Rafael H.; Vieira, Renata","Vieira, Renata/N-5102-2018","Vieira, Renata/0000-0003-2449-5477",OLID-BR: offensive language identification dataset for Brazilian Portuguese,,,10.1007/s10579-023-09657-0 ,Article; Early Access ,,"Social media has revolutionized the manner in which our society is interconnected. While this extensive connectivity offers numerous benefits, it is also accompanied by significant drawbacks, particularly in terms of the proliferation of fake news and the vast dissemination of hate speech. Identifying offensive comments is a critical task for ensuring the safety of users, which is why industry and academia have been working on developing solutions to this problem. Prior research on hate speech detection has predominantly focused on the English language, with few studies devoted to other languages such as Portuguese. This paper introduces the Offensive Language Identification Dataset for Brazilian Portuguese (OLID-BR), a high-quality NLP dataset for offensive language detection, which we make publicly available. The dataset contains 6,354 (extendable to 13,538) comments labeled using a fine-grained three-layer annotation schema compatible with datasets in other languages, which allows the training of multilingual/cross-lingual models. The five NLP tasks available in OLID-BR allow the detection of offensive comments, the classification of the types of offenses such as racism, LGBTQphobia, sexism, xenophobia, and so on, the identification of the type and the target of offensive comments, and the extraction of toxic spans of offensive comments. All those tasks can enhance the capabilities of content moderation systems by providing deep contextual analysis or highlighting the spans that make a text toxic. We further experiment with and evaluate the dataset using state-of-the-art BERT-based and NER models, which demonstrates the usefulness of OLID-BR for the development of toxicity detection systems for Portuguese texts.",1574-020X,1574-0218,,, , ,,Gen_dataset#methodology#out_but_toxicity,
3874,"Title:Using kNN model for automatic feature selection

 This paper proposes a kNN model-based feature selection method aimed at improving the efficiency and effectiveness of the ReliefF method by: (1) using a kNN model as the starter selection, aimed at choosing a set of more meaningful representatives to replace the original data for feature selection; (2) integration of the Heterogeneous Value Difference Metric to handle heterogeneous applications - those with both ordinal and nominal features; and (3) presenting a simple method of difference function calculation based on inductive information in each representative obtained by kNN model, We have evaluated the performance of the proposed kNN model-based feature selection method on toxicity dataset Phenols with two different endpoints. Experimental results indicate that the proposed feature selection method has a significant improvement in the classification accuracy for the trial dataset.","Guo, GD; Neagu, D; Cronin, MTD","Neagu, Daniel/AAJ-9766-2021","Neagu, Daniel/0000-0002-7038-106X; Cronin, Mark/0000-0002-6207-4158",Using kNN model for automatic feature selection,3686,, ,Article; Proceedings Paper ,2005.0,"This paper proposes a kNN model-based feature selection method aimed at improving the efficiency and effectiveness of the ReliefF method by: (1) using a kNN model as the starter selection, aimed at choosing a set of more meaningful representatives to replace the original data for feature selection; (2) integration of the Heterogeneous Value Difference Metric to handle heterogeneous applications - those with both ordinal and nominal features; and (3) presenting a simple method of difference function calculation based on inductive information in each representative obtained by kNN model, We have evaluated the performance of the proposed kNN model-based feature selection method on toxicity dataset Phenols with two different endpoints. Experimental results indicate that the proposed feature selection method has a significant improvement in the classification accuracy for the trial dataset.",0302-9743,1611-3349,3-540-28757-4,410-419, , 3rd International Conference on Advances in Pattern Recognition3rd International Conference on Advances in Pattern Recognition,,out_of_scope,
3875,"Title:Quantifying the Intensity of Toxicity for Discussions and Speakers

 In this work, from YouTube News-show multimodal dataset with dyadic speakers having heated discussions, we analyze the toxicity through audio-visual signals. Firstly, as different speakers may contribute differently towards the toxicity, we propose a speaker-wise toxicity score revealing individual proportionate contribution. As discussions with disagreements may reflect some signals of toxicity, in order to identify discussions needing more attention we categorize discussions into binary high-low toxicity levels. By analyzing visual features, we show that the levels correlate with facial expressions as Upper Lid Raiser (associated with 'surprise'), Dimpler (associated with 'contempt'), and Lip Corner Depressor (associated with 'disgust') remain statistically significant in separating high-low intensities of disrespect. Secondly, we investigate the impact of audio-based features such as pitch and intensity that can significantly elicit disrespect, and utilize the signals in classifying disrespect and non-disrespect samples by applying logistic regression model achieving 79.86% accuracy. Our findings shed light on the potential of utilizing audio-visual signals in adding important context towards understanding toxic discussions.","Samrose, Samiha; Hoque, Ehsan",,,Quantifying the Intensity of Toxicity for Discussions and Speakers,,,10.1109/ACIIW52867.2021.9666258 ,Proceedings Paper ,2021.0,"In this work, from YouTube News-show multimodal dataset with dyadic speakers having heated discussions, we analyze the toxicity through audio-visual signals. Firstly, as different speakers may contribute differently towards the toxicity, we propose a speaker-wise toxicity score revealing individual proportionate contribution. As discussions with disagreements may reflect some signals of toxicity, in order to identify discussions needing more attention we categorize discussions into binary high-low toxicity levels. By analyzing visual features, we show that the levels correlate with facial expressions as Upper Lid Raiser (associated with 'surprise'), Dimpler (associated with 'contempt'), and Lip Corner Depressor (associated with 'disgust') remain statistically significant in separating high-low intensities of disrespect. Secondly, we investigate the impact of audio-based features such as pitch and intensity that can significantly elicit disrespect, and utilize the signals in classifying disrespect and non-disrespect samples by applying logistic regression model achieving 79.86% accuracy. Our findings shed light on the potential of utilizing audio-visual signals in adding important context towards understanding toxic discussions.",,,978-1-6654-0021-3,, , 9th International Conference on Affective Computing and Intelligent Interaction (ACII)9th International Conference on Affective Computing and Intelligent Interaction (ACII),,detection#methodology#out_but_toxicity,
3876,"Title:Viral vitriol: Predictors and contagion of online toxicity in World of Tanks

 Toxic behaviors are pervasive in online games and can be harmful to building a positive online environment. Guided by the social identity model of deindividuation, this study represents one of the first efforts to examine the antecedents of toxicity in team-based online games using longitudinal behavioral data. It fills two important gaps in existing research, by 1) exploring non-verbal and behavioral dimensions of toxicity, and 2) examining team-level in addition to individual-level predictors. Employing a large-scale behavioral dataset from the popular game World of Tanks, we found that, in general, experienced and skillful players are more likely to commit toxic behaviors. Teams that are losing, or have a high internal skill disparity among their members tend to breed toxicity. In addition, this study provides empirical evidence that toxicity is contagious among players, especially toxic behaviors in one's own teams and in clan battles.","Shen, Cuihua; Sun, Qiusi; Kim, Taeyoung; Wolff, Grace; Ratan, Rabindra; Williams, Dmitri","Williams, Dmitri/AAH-8084-2020","Williams, Dmitri/0000-0001-7995-4429; Sun, Qiusi/0000-0002-1199-2004",Viral vitriol: Predictors and contagion of online toxicity in World of Tanks,108,,10.1016/j.chb.2020.106343 ,Article ,2020.0,"Toxic behaviors are pervasive in online games and can be harmful to building a positive online environment. Guided by the social identity model of deindividuation, this study represents one of the first efforts to examine the antecedents of toxicity in team-based online games using longitudinal behavioral data. It fills two important gaps in existing research, by 1) exploring non-verbal and behavioral dimensions of toxicity, and 2) examining team-level in addition to individual-level predictors. Employing a large-scale behavioral dataset from the popular game World of Tanks, we found that, in general, experienced and skillful players are more likely to commit toxic behaviors. Teams that are losing, or have a high internal skill disparity among their members tend to breed toxicity. In addition, this study provides empirical evidence that toxicity is contagious among players, especially toxic behaviors in one's own teams and in clan battles.",0747-5632,1873-7692,,, , ,,Use_dataset#detection,
3877,"Title:Conformational Oversampling as Data Augmentation for Molecules

 Toxicological datasets tend to be small and imbalanced. This quickly causes models to overfit and disregard the minority class. To solve this issue we generate conformations of molecules. Thereby, we can balance datasets as well as increase their size. Using this approach on the Tox21 Challenge data we observed conformational oversampling to be a viable approach to train datasets, increasing the balanced accuracy of trained models.","Hemmerich, Jennifer; Asilar, Ece; Ecker, Gerhard F.","ASILAR, Ece/ABC-4577-2020","ASILAR, Ece/0000-0001-5680-599X; Hemmerich, Jennifer/0000-0003-0372-8956; Ecker, Gerhard/0000-0003-4209-6883",Conformational Oversampling as Data Augmentation for Molecules,11731,,10.1007/978-3-030-30493-5_74 ,Proceedings Paper ,2019.0,"Toxicological datasets tend to be small and imbalanced. This quickly causes models to overfit and disregard the minority class. To solve this issue we generate conformations of molecules. Thereby, we can balance datasets as well as increase their size. Using this approach on the Tox21 Challenge data we observed conformational oversampling to be a viable approach to train datasets, increasing the balanced accuracy of trained models.",0302-9743,1611-3349,978-3-030-30493-5; 978-3-030-30492-8,788-792, , 28th International Conference on Artificial Neural Networks (ICANN)28th International Conference on Artificial Neural Networks (ICANN),,out_of_scope,
3878,"Title:Toxicity Detection Using State of the Art Natural Language Methodologies

 In this paper, the studies carried out to detect objectionable expressions in any text will be explained. Experiments were performed with Sentence transformers, supervised machine learning algorithms, and Bert transformer architecture trained in English, and the results were observed. To prepare the dataset used in the experiments, the natural language processing and machine learning methodologies of the toxic and non-toxic contents in the labeled text data obtained from the Kaggle platform are explained, and then the methods and performances of the models trained using this dataset are summarized in this paper.","Keskin, Enes Faruk; Acikgoz, Erkut; Dogan, Gulustan",,,Toxicity Detection Using State of the Art Natural Language Methodologies,,,10.1109/ICCRE57112.2023.10155587 ,Proceedings Paper ,2023.0,"In this paper, the studies carried out to detect objectionable expressions in any text will be explained. Experiments were performed with Sentence transformers, supervised machine learning algorithms, and Bert transformer architecture trained in English, and the results were observed. To prepare the dataset used in the experiments, the natural language processing and machine learning methodologies of the toxic and non-toxic contents in the labeled text data obtained from the Kaggle platform are explained, and then the methods and performances of the models trained using this dataset are summarized in this paper.",2835-3714,,979-8-3503-4565-0,16-20, , 8th International Conference on Control and Robotics Engineering (ICCRE)8th International Conference on Control and Robotics Engineering (ICCRE),,Use_dataset#detection,
3879,"Title:Imbalanced Toxic Comments Classification using Data Augmentation and Deep Learning

 Recently cyber-bullying and online harassment have become two of the most serious issues in many public online communities. In this paper, we use data from Wikipedia talk page edits to train multi-label classifier that detects different types of toxicity in online user-generated content. We present different data augmentation techniques to overcome the data imbalance problem in the Wikipedia dataset. The proposed solution is an ensemble of three models: convolutional neural network (CNN), bidirectional long short-term memory (LSTM) and bidirectional gated recurrent units (GRU). We divide the classification problem into two steps, first we determine whether or not the input is toxic then we find the types of toxicity present in the toxic content. The evaluation results show that the proposed ensemble approach provides the highest accuracy among all considered algorithms. It achieves 0.828 F-1-score for toxic/non-toxic classification and 0.872 for toxicity types prediction.","Ibrahim, Mai; Torki, Marwan; El-Makky, Nagwa",,"Torki, Marwan/0000-0002-6149-1718",Imbalanced Toxic Comments Classification using Data Augmentation and Deep Learning,,,10.1109/ICMLA.2018.00141 ,Proceedings Paper ,2018.0,"Recently cyber-bullying and online harassment have become two of the most serious issues in many public online communities. In this paper, we use data from Wikipedia talk page edits to train multi-label classifier that detects different types of toxicity in online user-generated content. We present different data augmentation techniques to overcome the data imbalance problem in the Wikipedia dataset. The proposed solution is an ensemble of three models: convolutional neural network (CNN), bidirectional long short-term memory (LSTM) and bidirectional gated recurrent units (GRU). We divide the classification problem into two steps, first we determine whether or not the input is toxic then we find the types of toxicity present in the toxic content. The evaluation results show that the proposed ensemble approach provides the highest accuracy among all considered algorithms. It achieves 0.828 F-1-score for toxic/non-toxic classification and 0.872 for toxicity types prediction.",,,978-1-5386-6805-4,875-878, , 17th IEEE International Conference on Machine Learning and Applications (IEEE ICMLA)17th IEEE International Conference on Machine Learning and Applications (IEEE ICMLA),,Use_dataset#detection#methodology,
3880,"Title:Chemometric Evaluation of the Link between Acute Toxicity, Health Issues and Physicochemical Properties of Silver Nanoparticles

 The present study's objective is to focus on some developments in the field of statistical models of a complex system, like nanoparticles responses in the environmental media. An important problem that still needs to be studied and interpreted is the relations between physicochemical parameters of the nanoparticles like primary size, primary hydrophobic diameter, zeta potential, etc. with respective toxicity values. It holds true especially for silver nanoparticle systems due to their known bactericidal effect and wide distribution in practice. The present study deals with the data for physicochemical and toxicity parameters of 94 different silver nanoparticle systems in order to reveal specific relations between physicochemical properties and acute toxicity readings using multivariate statistical methods. Searching for these specific relationships between physicochemical parameters and toxicity responses is the novel element in the present study. This has focused our study toward developing a model that describes the relationship between physicochemical properties and toxicity of silver NPs based on a dataset gathered from the literature. It is shown that the systems studied could be divided into four patterns (clusters) of similarity depending not only on the physicochemical indicators related to particles size but also by their acute toxicity. The acute toxicity is strongly correlated to the zeta potential of the particles if the whole data set is considered.","Nedyalkova, Miroslava; Dimitrov, Dimitar; Donkova, Borjana; Simeonov, Vasil","Donkova, Borjana/AAM-3448-2021; Nedyalkova, Miroslava/AAU-1615-2020","Donkova, Borjana/0000-0001-7414-390X; Nedyalkova, Miroslava/0000-0003-0793-3340","Chemometric Evaluation of the Link between Acute Toxicity, Health Issues and Physicochemical Properties of Silver Nanoparticles",11,9,10.3390/sym11091159 ,Article ,2019.0,"The present study's objective is to focus on some developments in the field of statistical models of a complex system, like nanoparticles responses in the environmental media. An important problem that still needs to be studied and interpreted is the relations between physicochemical parameters of the nanoparticles like primary size, primary hydrophobic diameter, zeta potential, etc. with respective toxicity values. It holds true especially for silver nanoparticle systems due to their known bactericidal effect and wide distribution in practice. The present study deals with the data for physicochemical and toxicity parameters of 94 different silver nanoparticle systems in order to reveal specific relations between physicochemical properties and acute toxicity readings using multivariate statistical methods. Searching for these specific relationships between physicochemical parameters and toxicity responses is the novel element in the present study. This has focused our study toward developing a model that describes the relationship between physicochemical properties and toxicity of silver NPs based on a dataset gathered from the literature. It is shown that the systems studied could be divided into four patterns (clusters) of similarity depending not only on the physicochemical indicators related to particles size but also by their acute toxicity. The acute toxicity is strongly correlated to the zeta potential of the particles if the whole data set is considered.",,2073-8994,,, , ,,out_of_scope,
3881,"Title:Characterization of Emotional Contagion in Collaborative Decision Support Systems

 This research is focused on the analysis of how emotional aspects of people participating in decision-making through group discussions in online platforms manifest themselves. A particular emphasis is on the toxicity levels of discussions on various issues. Three platforms have been chosen for a comparative study: the first is a Reddit-like online forum, the second is Polis, where participants may vote on issues and is touted as a forum for computational democracy, and the third is called the Deliberatorium, developed at the Center for Collective Intelligence at the Massachusetts Institute of Technology. These platforms have their own specific structures that aid in group discussions on various issues. An important question that has been examined in this paper is how to characterize the contagion of toxicity in the three platforms and the extent to which their structures inhibit it. Our approach has been to first extract two sets of actual data from the three platforms: a control group and an experimental group where in the latter, an intervention is used by inserting an empathy statement to inhibit toxicity. Toxicity levels (determined using Google Perspective API) were compared using sample data from the three platforms. We use generative models that extend the sample datasets by adding synthetic nodes (artificial entries in group discussions) from the three platforms based on parameter values of popularity, novelty, root-bias, and reciprocity among participants. Two additional parameters of node type and toxicity score were added to these synthetic nodes. The generative models help in extending existing datasets to determine the contagion of toxicity in the platform. This is achieved by developing an index for toxicity contagion, ECtox expressed as a percentage of the total number of nodes. The idea of developing this index has been adapted from work in ecological studies where contagion of a certain type of land patch is examined in the presence of several different patch types. We use this metric to assess toxicity contagion in both the control and experimental groups of the three platforms. With the intervention of the empathy statement, Deliberatorium had an improvement in ECtox from 1.309% to 1.297%. In Forum, however, ECtox actually increased from 1.711% to 1.951%. Finally, in Polis, there was an improvement in ECtox from 1.750% to 1.663%. Thus, for Deliberatorium, the flow of toxicity is the least. We infer that there are inherent structural constructs in the design of the Deliberatorium, and that may naturally inhibit toxicity in group discussions.","Sircar, Arnab; Klein, Mark",,,Characterization of Emotional Contagion in Collaborative Decision Support Systems,,,10.1109/CIC56439.2022.00025 ,Proceedings Paper ,2022.0,"This research is focused on the analysis of how emotional aspects of people participating in decision-making through group discussions in online platforms manifest themselves. A particular emphasis is on the toxicity levels of discussions on various issues. Three platforms have been chosen for a comparative study: the first is a Reddit-like online forum, the second is Polis, where participants may vote on issues and is touted as a forum for computational democracy, and the third is called the Deliberatorium, developed at the Center for Collective Intelligence at the Massachusetts Institute of Technology. These platforms have their own specific structures that aid in group discussions on various issues. An important question that has been examined in this paper is how to characterize the contagion of toxicity in the three platforms and the extent to which their structures inhibit it. Our approach has been to first extract two sets of actual data from the three platforms: a control group and an experimental group where in the latter, an intervention is used by inserting an empathy statement to inhibit toxicity. Toxicity levels (determined using Google Perspective API) were compared using sample data from the three platforms. We use generative models that extend the sample datasets by adding synthetic nodes (artificial entries in group discussions) from the three platforms based on parameter values of popularity, novelty, root-bias, and reciprocity among participants. Two additional parameters of node type and toxicity score were added to these synthetic nodes. The generative models help in extending existing datasets to determine the contagion of toxicity in the platform. This is achieved by developing an index for toxicity contagion, ECtox expressed as a percentage of the total number of nodes. The idea of developing this index has been adapted from work in ecological studies where contagion of a certain type of land patch is examined in the presence of several different patch types. We use this metric to assess toxicity contagion in both the control and experimental groups of the three platforms. With the intervention of the empathy statement, Deliberatorium had an improvement in ECtox from 1.309% to 1.297%. In Forum, however, ECtox actually increased from 1.711% to 1.951%. Finally, in Polis, there was an improvement in ECtox from 1.750% to 1.663%. Thus, for Deliberatorium, the flow of toxicity is the least. We infer that there are inherent structural constructs in the design of the Deliberatorium, and that may naturally inhibit toxicity in group discussions.",,,978-1-6654-7300-2,109-116, , IEEE 8th International Conference on Collaboration and Internet Computing (CIC)IEEE 8th International Conference on Collaboration and Internet Computing (CIC),,Use_dataset#detection#evaluation#methodology,
3882,"Title:Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets

 Language models can generate harmful and biased outputs and exhibit undesirable behavior according to a given cultural context. We propose a Process for Adapting Language Models to Society (PALMS) with ValuesTargeted Datasets, an iterative process to significantly change model behavior by crafting and fine-tuning on a dataset that reflects a predetermined set of target values. We evaluate our process using three metrics: quantitative metrics with human evaluations that score output adherence to a target value, toxicity scoring on outputs; and qualitative metrics analyzing the most common word associated with a given social category. Through each iteration, we add additional training dataset examples based on observed shortcomings from evaluations. PALMS performs significantly better on all metrics compared to baseline and control models for a broad range of GPT-3 language model sizes without compromising capability integrity. We find that the effectiveness of PALMS increases with model size. We show that significantly adjusting language model behavior is feasible with a small, hand-curated dataset.","Solaiman, Irene; Dennison, Christy",,,Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets,34,, ,Proceedings Paper ,2021.0,"Language models can generate harmful and biased outputs and exhibit undesirable behavior according to a given cultural context. We propose a Process for Adapting Language Models to Society (PALMS) with ValuesTargeted Datasets, an iterative process to significantly change model behavior by crafting and fine-tuning on a dataset that reflects a predetermined set of target values. We evaluate our process using three metrics: quantitative metrics with human evaluations that score output adherence to a target value, toxicity scoring on outputs; and qualitative metrics analyzing the most common word associated with a given social category. Through each iteration, we add additional training dataset examples based on observed shortcomings from evaluations. PALMS performs significantly better on all metrics compared to baseline and control models for a broad range of GPT-3 language model sizes without compromising capability integrity. We find that the effectiveness of PALMS increases with model size. We show that significantly adjusting language model behavior is feasible with a small, hand-curated dataset.",1049-5258,,*****************,, , 35th Conference on Neural Information Processing Systems (NeurIPS)35th Conference on Neural Information Processing Systems (NeurIPS),,detox#evaluation#methodology,
3883,"Title:Integrating computational methods to predict mutagenicity of aromatic azo compounds

 Azo dyes have several industrial uses. However, these azo dyes and their degradation products showed mutagenicity, inducing damage in environmental and human systems. Computational methods are proposed as cheap and rapid alternatives to predict the toxicity of azo dyes. A benchmark dataset of Ames data for 354 azo dyes was employed to develop three classification strategies using knowledge-based methods and docking simulations. Results were compared and integrated with three models from the literature, developing a series of consensus strategies. The good results confirm the usefulness of in silico methods as a support for experimental methods to predict the mutagenicity of azo compounds.","Gadaleta, Domenico; Porta, Nicola; Vrontaki, Eleni; Manganelli, Serena; Manganaro, Alberto; Sello, Guido; Honma, Masamitsu; Benfenati, Emilio","Benfenati, Emilio/AAA-9022-2020; Gadaleta, Domenico/ABG-3259-2020","Benfenati, Emilio/0000-0002-3976-5989; Gadaleta, Domenico/0000-0002-3154-5930; Vrontaki, Eleni/0000-0002-8798-2873; Manganaro, Alberto/0000-0002-0280-7401; Porta, Nicola/0000-0002-6005-4372",Integrating computational methods to predict mutagenicity of aromatic azo compounds,35,4,10.1080/10590501.2017.1391521 ,Review ,2017.0,"Azo dyes have several industrial uses. However, these azo dyes and their degradation products showed mutagenicity, inducing damage in environmental and human systems. Computational methods are proposed as cheap and rapid alternatives to predict the toxicity of azo dyes. A benchmark dataset of Ames data for 354 azo dyes was employed to develop three classification strategies using knowledge-based methods and docking simulations. Results were compared and integrated with three models from the literature, developing a series of consensus strategies. The good results confirm the usefulness of in silico methods as a support for experimental methods to predict the mutagenicity of azo compounds.",1059-0501,1532-4095,,239-257, , ,,out_of_scope,
3884,"Title:Mitigating Biases in Toxic Language Detection through Invariant Rationalization

 Automatic detection of toxic language plays an essential role in protecting social media users, especially minority groups, from verbal abuse. However, biases toward some attributes, including gender, race, and dialect, exist in most training datasets for toxicity detection. The biases make the learned models unfair and can even exacerbate the marginalization of people. Considering that current debiasing methods for general natural language understanding tasks cannot effectively mitigate the biases in the toxicity detectors, we propose to use invariant rationalization (INVRAT), a game-theoretic framework consisting of a rationale generator and predictors, to rule out the spurious correlation of certain syntactic patterns (e.g., identity mentions, dialect) to toxicity labels. We empirically show that our method yields lower false positive rate in both lexical and dialectal attributes than previous debiasing methods.(1)","Chuang, Yung-Sung; Gao, Mingye; Luo, Hongyin; Glass, James; Lee, Hung-yi; Chen, Yun-Nung; Lp, Shang-Wen","Chuang, Yung-Sung/HSH-6375-2023","Chuang, Yung-Sung/0000-0002-1723-5063",Mitigating Biases in Toxic Language Detection through Invariant Rationalization,,, ,Proceedings Paper ,2021.0,"Automatic detection of toxic language plays an essential role in protecting social media users, especially minority groups, from verbal abuse. However, biases toward some attributes, including gender, race, and dialect, exist in most training datasets for toxicity detection. The biases make the learned models unfair and can even exacerbate the marginalization of people. Considering that current debiasing methods for general natural language understanding tasks cannot effectively mitigate the biases in the toxicity detectors, we propose to use invariant rationalization (INVRAT), a game-theoretic framework consisting of a rationale generator and predictors, to rule out the spurious correlation of certain syntactic patterns (e.g., identity mentions, dialect) to toxicity labels. We empirically show that our method yields lower false positive rate in both lexical and dialectal attributes than previous debiasing methods.(1)",,,978-1-954085-59-6,114-120, , 5th Workshop on Structured Prediction for NLP (SPNLP) / 5th Workshop on Online Abuse and Harms (WOAH)5th Workshop on Structured Prediction for NLP (SPNLP) / 5th Workshop on Online Abuse and Harms (WOAH),,detection#evaluation#methodology,
3885,"Title:Multivariate statistical analysis for selecting optimal descriptors in the toxicity modeling of nanomaterials

 The present study is based on the application of a multivariate statistical analysis approach for the selection of optimal descriptors of nanomaterials with the objective of robust qualitative modeling of their toxicity. A novel data mining protocol has been developed for the selection of an optimal subset of descriptors of nanomaterials by using the well-known multivariate method principal component analysis (PCA). The selected subsets of descriptors were validated for qualitative modeling of the toxicity of nanomaterials in the PC space. The analysis and validation of the proposed schemes were based on five decisive nanomaterial toxicity data sets available in the published literature. Optimal descriptors were selected on the basis of the maximum loading criteria and using a threshold value of cumulative variance <= 90% on PC directions. A maximum inter-class separation(B) and the minimum intra-classes separation(A) were obtained for toxic vs. nontoxic nanomaterials in the PC space with the selected subsets of optimal descriptors compared to their other combinations for each of the datasets.","Jha, Sunil Kr; Yoon, T. H.; Pan, Zhaoqing","Jha, Sunil Kumar/C-1511-2012; Jha, Sunil/AAZ-7636-2020","Jha, Sunil/0000-0002-6955-1244",Multivariate statistical analysis for selecting optimal descriptors in the toxicity modeling of nanomaterials,99,,10.1016/j.compbiomed.2018.06.012 ,Article ,2018.0,The present study is based on the application of a multivariate statistical analysis approach for the selection of optimal descriptors of nanomaterials with the objective of robust qualitative modeling of their toxicity. A novel data mining protocol has been developed for the selection of an optimal subset of descriptors of nanomaterials by using the well-known multivariate method principal component analysis (PCA). The selected subsets of descriptors were validated for qualitative modeling of the toxicity of nanomaterials in the PC space. The analysis and validation of the proposed schemes were based on five decisive nanomaterial toxicity data sets available in the published literature. Optimal descriptors were selected on the basis of the maximum loading criteria and using a threshold value of cumulative variance <= 90% on PC directions. A maximum inter-class separation(B) and the minimum intra-classes separation(A) were obtained for toxic vs. nontoxic nanomaterials in the PC space with the selected subsets of optimal descriptors compared to their other combinations for each of the datasets.,0010-4825,1879-0534,,161-172, , ,,out_of_scope,
3886,"Title:Toxicity Prediction in Cancer Using Multiple Instance Learning in a Multi-task Framework

 Treatments of cancer cause severe side effects called toxicities. Reduction of such effects is crucial in cancer care. To impact care, we need to predict toxicities at fortnightly intervals. This toxicity data differs from traditional time series data as toxicities can be caused by one treatment on a given day alone, and thus it is necessary to consider the effect of the singular data vector causing toxicity. We model the data before prediction points using the multiple instance learning, where each bag is composed of multiple instances associated with daily treatments and patient-specific attributes, such as chemotherapy, radiotherapy, age and cancer types. We then formulate a Bayesian multi-task framework to enhance toxicity prediction at each prediction point. The use of the prior allows factors to be shared across task predictors. Our proposed method simultaneously captures the heterogeneity of daily treatments and performs toxicity prediction at different prediction points. Our method was evaluated on a real-word dataset of more than 2000 cancer patients and had achieved a better prediction accuracy in terms of AUC than the state-of-art baselines.","Li, Cheng; Gupta, Sunil; Rana, Santu; Luo, Wei; Venkatesh, Svetha; Ashely, David; Dinh Phung","Luo, Wei/A-6043-2011; Phung, Dinh Q/D-1328-2012; Rana, Santu/R-2992-2019; , ChengLi/S-2430-2019","Luo, Wei/0000-0002-4711-7543; Phung, Dinh Q/0000-0002-9977-8247; Rana, Santu/0000-0003-2247-850X; , ChengLi/0000-0001-8140-2826; venkatesh, svetha/0000-0001-8675-6631; Li, Cheng/0000-0002-6188-2970; gupta, sunil/0000-0002-4669-9940",Toxicity Prediction in Cancer Using Multiple Instance Learning in a Multi-task Framework,9651,,10.1007/978-3-319-31753-3_13 ,Proceedings Paper ,2016.0,"Treatments of cancer cause severe side effects called toxicities. Reduction of such effects is crucial in cancer care. To impact care, we need to predict toxicities at fortnightly intervals. This toxicity data differs from traditional time series data as toxicities can be caused by one treatment on a given day alone, and thus it is necessary to consider the effect of the singular data vector causing toxicity. We model the data before prediction points using the multiple instance learning, where each bag is composed of multiple instances associated with daily treatments and patient-specific attributes, such as chemotherapy, radiotherapy, age and cancer types. We then formulate a Bayesian multi-task framework to enhance toxicity prediction at each prediction point. The use of the prior allows factors to be shared across task predictors. Our proposed method simultaneously captures the heterogeneity of daily treatments and performs toxicity prediction at different prediction points. Our method was evaluated on a real-word dataset of more than 2000 cancer patients and had achieved a better prediction accuracy in terms of AUC than the state-of-art baselines.",2945-9133,1611-3349,978-3-319-31753-3; 978-3-319-31752-6,152-164, , 20th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)20th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD),,out_of_scope,
3887,"Title:Toxic Comment Detection: Analyzing the Combination of Text and Emojis

 Detection of toxicity in online commentary is a growing branch of Natural Language Processing (NLP). Most research in the area rely only on text-based toxic comment detection. We propose a machine learning approach for detecting the toxicity of a comment by analyzing both the text and the emojis within the comment. Our approach utilizes word embeddings derived from GloVe and emoji2vec to train a bidirectional Long Short Term Memory (biLSTM) model. We also create a new labeled dataset with comments with text and emojis. The accuracy score of our model on preliminary data is 0.911.","Aquino, Michael; Ortiz, Yasiris; Rashid, Arif; Tumlin, Anne M.; Artan, N. Sertac; Dong, Ziqian; Gu, Huanying",,,Toxic Comment Detection: Analyzing the Combination of Text and Emojis,,,10.1109/MASS52906.2021.00097 ,Proceedings Paper ,2021.0,Detection of toxicity in online commentary is a growing branch of Natural Language Processing (NLP). Most research in the area rely only on text-based toxic comment detection. We propose a machine learning approach for detecting the toxicity of a comment by analyzing both the text and the emojis within the comment. Our approach utilizes word embeddings derived from GloVe and emoji2vec to train a bidirectional Long Short Term Memory (biLSTM) model. We also create a new labeled dataset with comments with text and emojis. The accuracy score of our model on preliminary data is 0.911.,2155-6806,,978-1-6654-4935-9,661-662, , 18th IEEE International Conference on Mobile Ad hoc and Smart Systems (IEEE MASS)18th IEEE International Conference on Mobile Ad hoc and Smart Systems (IEEE MASS),,Gen_dataset#detection#methodology,
3888,"Title:Demographics Should Not Be the Reason of Toxicity: Mitigating Discrimination in Text Classifications with Instance Weighting

 With the recent proliferation of the use of text classifications, researchers have found that there are certain unintended biases in text classification datasets. For example, texts containing some demographic identity-terms (e.g., gay, black) are more likely to be abusive in existing abusive language detection datasets. As a result, models trained with these datasets may consider sentences like She makes me happy to be gay as abusive simply because of the word gay. In this paper, we formalize the unintended biases in text classification datasets as a kind of selection bias from the non-discrimination distribution to the discrimination distribution. Based on this formalization, we further propose a model-agnostic debiasing training framework by recovering the non-discrimination distribution using instance weighting, which does not require any extra resources or annotations apart from a pre-defined set of demographic identity-terms. Experiments demonstrate that our method can effectively alleviate the impacts of the unintended biases without significantly hurting models' generalization ability.","Zhang, Guanhua; Bai, Bing; Zhan, Junqi; Bai, Kun; Zhu, Conghui; Zhao, Tiejun",,,Demographics Should Not Be the Reason of Toxicity: Mitigating Discrimination in Text Classifications with Instance Weighting,,, ,Proceedings Paper ,2020.0,"With the recent proliferation of the use of text classifications, researchers have found that there are certain unintended biases in text classification datasets. For example, texts containing some demographic identity-terms (e.g., gay, black) are more likely to be abusive in existing abusive language detection datasets. As a result, models trained with these datasets may consider sentences like She makes me happy to be gay as abusive simply because of the word gay. In this paper, we formalize the unintended biases in text classification datasets as a kind of selection bias from the non-discrimination distribution to the discrimination distribution. Based on this formalization, we further propose a model-agnostic debiasing training framework by recovering the non-discrimination distribution using instance weighting, which does not require any extra resources or annotations apart from a pre-defined set of demographic identity-terms. Experiments demonstrate that our method can effectively alleviate the impacts of the unintended biases without significantly hurting models' generalization ability.",,,978-1-952148-25-5,4134-4145, , 58th Annual Meeting of the Association-for-Computational-Linguistics (ACL)58th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,detection#evaluation#methodology,
3889,"Title:TOXIGEN: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection

 Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create TOXIGEN, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model (Brown et al., 2020). Controlling machine generation in this way allows TOXIGEN to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of TOXIGEN and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that TOXIGEN can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.","Hartvigsen, Thomas; Gabriel, Saadia; Palangi, Hamid; Sap, Maarten; Ray, Dipankar; Kamar, Ece",,"Hartvigsen, Thomas/0000-0002-5288-2792",TOXIGEN: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection,,, ,Proceedings Paper ,2022.0,"Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create TOXIGEN, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model (Brown et al., 2020). Controlling machine generation in this way allows TOXIGEN to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of TOXIGEN and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that TOXIGEN can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.",,,978-1-955917-21-6,3309-3326, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,Gen_dataset#Use_dataset#detection#evaluation#methodology,
3890,"Title:ToxML, a data exchange standard with content controlled vocabulary used to build better (Q)SAR models

 Development of accurate quantitative structure-activity relationship (QSAR) models requires the availability of high quality validated data. International regulations such as REACH in Europe will now accept (Q)SAR-based evaluations for risk assessment. The number of toxicity datasets available for those wishing to share knowledge, or to use for data mining and modelling, is continually expanding. The challenge is the current use of a multitude of different data formats. The issues of comparing or combining disparate data apply both to public and proprietary sources. The ToxML project addresses the need for a common data exchange standard that allows the representation and communication of these data in a well-structured electronic format. It is an open standard based on Extensible Markup Language (XML). Supporting information for overall toxicity endpoint data can be included within ToxML files. This makes it possible to assess the quality and detail of the data used in a model. The data file model allows the aggregation of experimental data to the compound level in the detail needed to support (Q)SAR work. The standard is published on a website together with tools to view, edit and download it.","Ali, M.; Patel, M.; Wilkinson, D.; Judson, P.; Cross, K.; Bower, D.","Judson, Philip/HNC-3520-2023","Patel, Mukesh/0000-0003-1557-662X; Cross, Kevin/0000-0002-2462-0533","ToxML, a data exchange standard with content controlled vocabulary used to build better (Q)SAR models",24,6,10.1080/1062936X.2013.783506 ,Article ,2013.0,"Development of accurate quantitative structure-activity relationship (QSAR) models requires the availability of high quality validated data. International regulations such as REACH in Europe will now accept (Q)SAR-based evaluations for risk assessment. The number of toxicity datasets available for those wishing to share knowledge, or to use for data mining and modelling, is continually expanding. The challenge is the current use of a multitude of different data formats. The issues of comparing or combining disparate data apply both to public and proprietary sources. The ToxML project addresses the need for a common data exchange standard that allows the representation and communication of these data in a well-structured electronic format. It is an open standard based on Extensible Markup Language (XML). Supporting information for overall toxicity endpoint data can be included within ToxML files. This makes it possible to assess the quality and detail of the data used in a model. The data file model allows the aggregation of experimental data to the compound level in the detail needed to support (Q)SAR work. The standard is published on a website together with tools to view, edit and download it.",1062-936X,,,695-704, , ,,out_of_scope,
3891,"Title:Application of atomic electrostatic potential descriptors for predicting the eco-toxicity of ionic liquids towards leukemia rat cell line

 The toxicity assessment of ionic liquids (ILs) towards the environment and living organisms has received great attention. Nevertheless, the huge number of ILs makes the toxicity data collection expensive and time-consuming, which motivates modeling development to fill data gaps of ILs toxicity. The group contribution (GC) method has been extensively applied for the estimation of various properties of ionic liquids. This study proposed a novel method, named the non-integer group contribution (NGC) method, which creatively utilizes the atomic electrostatic potential descriptors for modeling. Specifically, the average values of electrostatic potential (AV(EP)) and the electrostatic potential surface area (SEP) of atoms in the cations and anions of ILs were calculated and used to obtain the group descriptors in this work. Two NGC models were developed to predict the toxicity of ILs. Results show that both proposed models have satisfactory predictability. In contrast, the NGC-2 model based on SEP descriptors exhibits better predictability due to its higher coefficient of determination (R-2 = 0.927), the lower average absolute relative deviation (AARD = 11.257 %) and root mean square error (RMSE = 0.261) for the entire dataset. The NGC-2 model also shows better performance than the traditional GC method, demonstrating its advanced superiority. Therefore, the proposed approach has high potential in terms of generalization and applicability for predicting the property of compounds. (c) 2022 Elsevier Ltd. All rights reserved.","Kang, Xuejing; Zhao, Yongsheng; Zhang, Hongzhong; Chen, Zhongbing","Chen, Zhongbing/H-5001-2018","Chen, Zhongbing/0000-0001-8801-4842",Application of atomic electrostatic potential descriptors for predicting the eco-toxicity of ionic liquids towards leukemia rat cell line,260,,10.1016/j.ces.2022.117941 ,Article ,2022.0,"The toxicity assessment of ionic liquids (ILs) towards the environment and living organisms has received great attention. Nevertheless, the huge number of ILs makes the toxicity data collection expensive and time-consuming, which motivates modeling development to fill data gaps of ILs toxicity. The group contribution (GC) method has been extensively applied for the estimation of various properties of ionic liquids. This study proposed a novel method, named the non-integer group contribution (NGC) method, which creatively utilizes the atomic electrostatic potential descriptors for modeling. Specifically, the average values of electrostatic potential (AV(EP)) and the electrostatic potential surface area (SEP) of atoms in the cations and anions of ILs were calculated and used to obtain the group descriptors in this work. Two NGC models were developed to predict the toxicity of ILs. Results show that both proposed models have satisfactory predictability. In contrast, the NGC-2 model based on SEP descriptors exhibits better predictability due to its higher coefficient of determination (R-2 = 0.927), the lower average absolute relative deviation (AARD = 11.257 %) and root mean square error (RMSE = 0.261) for the entire dataset. The NGC-2 model also shows better performance than the traditional GC method, demonstrating its advanced superiority. Therefore, the proposed approach has high potential in terms of generalization and applicability for predicting the property of compounds. (c) 2022 Elsevier Ltd. All rights reserved.",0009-2509,1873-4405,,, , ,,out_of_scope,
3892,"Title:How well do hate speech, toxicity, abusive and offensive language classification models generalize across datasets?

 A considerable body of research deals with the automatic identification of hate speech and related phenomena. However, cross-dataset model generalization remains a challenge. In this context, we address two still open central questions: (i) to what extent does the generalization depend on the model and the composition and annotation of the training data in terms of different categories?, and (ii) do specific features of the datasets or models influence the generalization potential? To answer (i), we experiment with BERT, ALBERT, fastText, and SVM models trained on nine common public English datasets, whose class (or category) labels are standardized (and thus made comparable), in intra-and cross-dataset setups. The experiments show that indeed the generalization varies from model to model and that some of the categories (e.g., ?toxic?, ?abusive?, or ?offensive?) serve better as cross-dataset training categories than others (e.g., ?hate speech?). To answer (ii), we use a Random Forest model for assessing the relevance of different model and dataset features during the prediction of the performance of 450 BERT, 450 ALBERT, 450 fastText, and 348 SVM binary abusive language classifiers (1698 in total). We find that in order to generalize well, a model already needs to perform well in an intra-dataset scenario. Furthermore, we find that some other parameters are equally decisive for the success of the generalization, including, e.g., the training and target categories and the percentage of the out-of-domain vocabulary.","Fortuna, Paula; Soler-Company, Juan; Wanner, Leo",,,"How well do hate speech, toxicity, abusive and offensive language classification models generalize across datasets?",58,3,10.1016/j.ipm.2021.102524 ,Article ,2021.0,"A considerable body of research deals with the automatic identification of hate speech and related phenomena. However, cross-dataset model generalization remains a challenge. In this context, we address two still open central questions: (i) to what extent does the generalization depend on the model and the composition and annotation of the training data in terms of different categories?, and (ii) do specific features of the datasets or models influence the generalization potential? To answer (i), we experiment with BERT, ALBERT, fastText, and SVM models trained on nine common public English datasets, whose class (or category) labels are standardized (and thus made comparable), in intra-and cross-dataset setups. The experiments show that indeed the generalization varies from model to model and that some of the categories (e.g., ?toxic?, ?abusive?, or ?offensive?) serve better as cross-dataset training categories than others (e.g., ?hate speech?). To answer (ii), we use a Random Forest model for assessing the relevance of different model and dataset features during the prediction of the performance of 450 BERT, 450 ALBERT, 450 fastText, and 348 SVM binary abusive language classifiers (1698 in total). We find that in order to generalize well, a model already needs to perform well in an intra-dataset scenario. Furthermore, we find that some other parameters are equally decisive for the success of the generalization, including, e.g., the training and target categories and the percentage of the out-of-domain vocabulary.",0306-4573,1873-5371,,, , ,,detection#evaluation#methodology,
3893,"Title:LTARM: A novel temporal association rule mining method to understand toxicities in a routine cancer treatment

 Cancer is a worldwide problem and one of the leading causes of death. Increasing prevalence of cancer, particularly in developing countries, demands better understandings of the effectiveness and adverse consequences of different cancer treatment regimes in real patient populations. Current understandings of cancer treatment toxicities are often derived from either clean patient cohorts or coarse population statistics. Thus, it is difficult to get up-to-date and local assessments of treatment toxicities for specific cancer centers. To address these problems, we propose a novel and efficient method for discovering toxicity progression patterns in the form of temporal association rules (TARs). A temporal association rule is defined as a rule where the diagnosis codes in the right hand side (e.g., a combination of toxicities/complications) are temporally occurred after the diagnosis codes in the left hand side (e.g., a particular type of cancer treatment). Our method develops a lattice structure to efficiently discover TARs. More specifically, the lattice structure is first constructed to store all frequent diagnosis codes in the dataset. It is then traversed using the paternity relations among nodes to generate TARs. Our extensive experiments show the effectiveness of the proposed method in discovering major toxicity patterns in comparison with the temporal comorbidity analysis. In addition, our method significantly outperforms existing methods for mining TARs in terms of runtime. (C) 2018 Elsevier B.V. All rights reserved.","Dang Nguyen; Luo, Wei; Dinh Phung; Venkatesh, Svetha","Nguyen, Dang/AAW-8823-2021; Nguyen, Dang/IAQ-4160-2023; Luo, Wei/A-6043-2011; Phung, Dinh Q/D-1328-2012","Luo, Wei/0000-0002-4711-7543; Phung, Dinh Q/0000-0002-9977-8247; Nguyen, Dang/0000-0002-0401-988X; venkatesh, svetha/0000-0001-8675-6631",LTARM: A novel temporal association rule mining method to understand toxicities in a routine cancer treatment,161,,10.1016/j.knosys.2018.07.031 ,Article ,2018.0,"Cancer is a worldwide problem and one of the leading causes of death. Increasing prevalence of cancer, particularly in developing countries, demands better understandings of the effectiveness and adverse consequences of different cancer treatment regimes in real patient populations. Current understandings of cancer treatment toxicities are often derived from either clean patient cohorts or coarse population statistics. Thus, it is difficult to get up-to-date and local assessments of treatment toxicities for specific cancer centers. To address these problems, we propose a novel and efficient method for discovering toxicity progression patterns in the form of temporal association rules (TARs). A temporal association rule is defined as a rule where the diagnosis codes in the right hand side (e.g., a combination of toxicities/complications) are temporally occurred after the diagnosis codes in the left hand side (e.g., a particular type of cancer treatment). Our method develops a lattice structure to efficiently discover TARs. More specifically, the lattice structure is first constructed to store all frequent diagnosis codes in the dataset. It is then traversed using the paternity relations among nodes to generate TARs. Our extensive experiments show the effectiveness of the proposed method in discovering major toxicity patterns in comparison with the temporal comorbidity analysis. In addition, our method significantly outperforms existing methods for mining TARs in terms of runtime. (C) 2018 Elsevier B.V. All rights reserved.",0950-7051,1872-7409,,313-328, , ,,out_of_scope,
3894,"Title:Dataset for Estimated Closures of Scallop (Pecten maximus) Production Areas Due to Phycotoxin Contamination along the French Coasts of the Eastern English Channel

 Commercial bans due to harmful algal blooms (HABs), which are natural events, question the sustainability of human activities in marine and coastal areas. A risk assessment of these bans is important to support decision-making to better manage and mitigate their impacts. However, data are sparse and difficult to collect. The dataset presented in this paper includes estimated closures of scallop fishing areas due to HAB toxicity along the French coasts of the English Channel. The closure data were simulated for each scallop (Pecten maximus) fishing area through an algorithm applied to the in situ dataset from the French monitoring network REPHYTOX. The methodology of the production of closure data consists of comparing phycotoxin concentration in scallop to regulatory thresholds of phycotoxins, and then, simulating the number and duration of closures based on the monitoring strategies and closure mechanisms as defined in the regulations. These data only cover closures related to regulatory threshold exceedances of phycotoxins in shellfish. Closures induced by the lack of sampling or other reasons (e.g., failures in toxin analysis) are not included in the dataset because of the lack of information. Data are produced during the scallop fishing season. Facing the non-existence of such a closure database due to the lack of centralized management of local closure decrees, this dataset can be used to analyse the management strategies to deal with HABs and to highlight the governance challenges related to these strategies. It is also useful to study the link between the ecological and the socioeconomic dimensions of HABs, and to describe how toxin concentrations in shellfish translate into socioeconomic impacts and management challenges. This methodology can be applied to other species, other areas and other economic activities.","Chenouf, Sarra; Merzereaud, Mathieu; Raux, Pascal; Perez Agundez, Jose Antonio",,"Chenouf, Sarra/0000-0001-8680-4103; Perez Agundez, Jose A./0000-0002-2458-574X; Raux, Pascal/0000-0002-7902-1028",Dataset for Estimated Closures of Scallop (Pecten maximus) Production Areas Due to Phycotoxin Contamination along the French Coasts of the Eastern English Channel,7,8,10.3390/data7080103 ,Article; Data Paper ,2022.0,"Commercial bans due to harmful algal blooms (HABs), which are natural events, question the sustainability of human activities in marine and coastal areas. A risk assessment of these bans is important to support decision-making to better manage and mitigate their impacts. However, data are sparse and difficult to collect. The dataset presented in this paper includes estimated closures of scallop fishing areas due to HAB toxicity along the French coasts of the English Channel. The closure data were simulated for each scallop (Pecten maximus) fishing area through an algorithm applied to the in situ dataset from the French monitoring network REPHYTOX. The methodology of the production of closure data consists of comparing phycotoxin concentration in scallop to regulatory thresholds of phycotoxins, and then, simulating the number and duration of closures based on the monitoring strategies and closure mechanisms as defined in the regulations. These data only cover closures related to regulatory threshold exceedances of phycotoxins in shellfish. Closures induced by the lack of sampling or other reasons (e.g., failures in toxin analysis) are not included in the dataset because of the lack of information. Data are produced during the scallop fishing season. Facing the non-existence of such a closure database due to the lack of centralized management of local closure decrees, this dataset can be used to analyse the management strategies to deal with HABs and to highlight the governance challenges related to these strategies. It is also useful to study the link between the ecological and the socioeconomic dimensions of HABs, and to describe how toxin concentrations in shellfish translate into socioeconomic impacts and management challenges. This methodology can be applied to other species, other areas and other economic activities.",,2306-5729,,, , ,,out_of_scope,
3895,"Title:Modeling the toxicity of ionic liquids based on deep learning method

 This work proposed a hybrid molecular descriptor combined with deep learning method to model and evaluate the rational application of ionic liquids (ILs) through deep convolutional neural networks (DCNN). A total toxicity dataset of ILs against the leukemia rat cell line (ICP-81) was collected from the literature. The MACCS fingerprint and sigma profiles of the ILs were calculated using the RDKit packet and the COSMO-SAC model, respectively. The hyperparameters of the DCNN model were optimized by combining Bayesian optimization and local search algorithm. The importance of the feature descriptors was determined based on their influence on the DCNN model. The obtained results showed that the proposed model had a satisfactory prediction accuracy, and the coefficient of determination (R2) for the train set and test set were 0.972 and 0.965. This work provides guidance for the screening of ILs and their rational application in the industry.","Fan, Dingchao; Xue, Ke; Liu, Yangyang; Zhu, Wenguang; Chen, Yusen; Cui, Peizhe; Sun, Shiqin; Qi, Jianguang; Zhu, Zhaoyou; Wang, Yinglong","wang, wang/JQW-3034-2023; Yang, Jie/JDM-6213-2023; xu, chen/JNE-5010-2023; zhou, yang/JED-3951-2023; li, xiang/JCN-9316-2023; Wang, Minghao/JMD-0670-2023; Zhou, heng/JCN-6493-2023; Liu, yujing/JQI-7225-2023; Wang, He/JCO-3900-2023; WANG, YING/JLM-9219-2023; Liu, Jie/JCP-1070-2023; wang, xiaoqiang/JMT-2783-2023; zhang, hao/JOJ-7093-2023; Yang, Jing/JFK-4046-2023; yang, li/JGM-1009-2023; liu, xiao/JLL-2119-2023; zhang, chen/JES-0371-2023; zhang, xinyu/JKI-8403-2023; zhang, yan/JGL-8022-2023; Wang, Han/JJF-2614-2023; chen, xu/JNT-3068-2023; Li, Lei/JPE-6543-2023; Zhang, Yun/JCN-7026-2023; wang, xi/JNT-5162-2023; chen, Chen/JKJ-2122-2023; lei, lei/JSL-3106-2023; Zhang, Yuting/JRW-3937-2023; Zhang, Shiwei/JIY-4344-2023; Yang, Fan/JMA-9594-2023; Li, Wei/JLL-4365-2023; Chen, Yu/JLL-0171-2023; yang, peng/JEZ-8452-2023; yuan, lin/JDW-7387-2023; li, Li/JPA-0218-2023; liu, yang/JMB-9083-2023; chen, gang/JRX-1197-2023; Zhang, Wei/JKI-3565-2023; wu, p/JDW-5015-2023; Li, Yao/JJC-2927-2023; wang, KiKi/JFZ-3334-2023","Yang, Jie/0000-0002-3941-0053; Yang, Jing/0009-0004-8274-9863;",Modeling the toxicity of ionic liquids based on deep learning method,176,,10.1016/j.compchemeng.2023.108293 ,Article ,2023.0,"This work proposed a hybrid molecular descriptor combined with deep learning method to model and evaluate the rational application of ionic liquids (ILs) through deep convolutional neural networks (DCNN). A total toxicity dataset of ILs against the leukemia rat cell line (ICP-81) was collected from the literature. The MACCS fingerprint and sigma profiles of the ILs were calculated using the RDKit packet and the COSMO-SAC model, respectively. The hyperparameters of the DCNN model were optimized by combining Bayesian optimization and local search algorithm. The importance of the feature descriptors was determined based on their influence on the DCNN model. The obtained results showed that the proposed model had a satisfactory prediction accuracy, and the coefficient of determination (R2) for the train set and test set were 0.972 and 0.965. This work provides guidance for the screening of ILs and their rational application in the industry.",0098-1354,1873-4375,,, , ,,out_of_scope,
3896,"Title:Machine learning and materials modelling interpretation of in vivo toxicological response to TiO2 nanoparticles library (UV and non-UV exposure)

 Assessing the risks of nanomaterials/nanoparticles (NMs/NPs) under various environmental conditions requires a more systematic approach, including the comparison of effects across many NMs with identified different but related characters/descriptors. Hence, there is an urgent need to provide coherent (eco)toxicological datasets containing comprehensive toxicity information relating to a diverse spectra of NPs characters. These datasets are test benches for developing holistic methodologies with broader applicability. In the present study we assessed the effects of a custom design Fe-doped TiO2 NPs library, using the soil invertebrate Enchytraeus crypticus (Oligochaeta), via a 5-day pulse via aqueous exposure followed by a 21-days recovery period in soil (survival, reproduction assessment). Obviously, when testing TiO2, realistic conditions should include UV exposure. The 11 Fe-TiO2 library contains NPs of size range between 5-27 nm with varying %Fe (enabling the photoactivation of TiO2 at energy wavelengths in the visible-light range). The NPs were each described by 122 descriptors, being a mixture of measured and atomistic model descriptors. The data were explored using single and univariate statistical methods, combined with machine learning and multiscale modelling techniques. An iterative pruning process was adopted for identifying automatically the most significant descriptors. TiO2 NPs toxicity decreased when combined with UV. Notably, the short-term water exposure induced lasting biological responses even after longer-term recovery in clean exposure. The correspondence with Fe-content correlated with the band-gap hence the reduction of UV oxidative stress. The inclusion of both measured and modelled materials data benefitted the explanation of the results, when combined with machine learning.","Gomes, Susana I. L.; Amorim, Monica J. B.; Pokhrel, Suman; Madler, Lutz; Fasano, Matteo; Chiavazzo, Eliodoro; Asinari, Pietro; Janes, Jaak; Tamm, Kaido; Burk, Jaanus; Scott-Fordsmand, Janeck J.","Gomes, Susana I L/K-1918-2013; Pokhrel, Suman/I-5861-2013; Fasano, Matteo/HJI-8843-2023; Gomes, Susana Cardoso/GQZ-8654-2022; Scott-Fordsmand, Janeck J/J-6019-2013; Amorim, Mónica J.B./G-8590-2011; Asinari, Pietro/C-5297-2012; Madler, Lutz/F-2982-2013","Gomes, Susana I L/0000-0001-7537-2341; Pokhrel, Suman/0000-0001-5712-2824; Fasano, Matteo/0000-0002-3997-3681; Scott-Fordsmand, Janeck J/0000-0002-2260-1224; Amorim, Mónica J.B./0000-0001-8137-3295; Chiavazzo, Eliodoro/0000-0001-6165-7434; Asinari, Pietro/0000-0003-1814-3846; Madler, Lutz/0000-0002-7073-0733",Machine learning and materials modelling interpretation of in vivo toxicological response to TiO2 nanoparticles library (UV and non-UV exposure),13,35,10.1039/d1nr03231c ,Article ,2021.0,"Assessing the risks of nanomaterials/nanoparticles (NMs/NPs) under various environmental conditions requires a more systematic approach, including the comparison of effects across many NMs with identified different but related characters/descriptors. Hence, there is an urgent need to provide coherent (eco)toxicological datasets containing comprehensive toxicity information relating to a diverse spectra of NPs characters. These datasets are test benches for developing holistic methodologies with broader applicability. In the present study we assessed the effects of a custom design Fe-doped TiO2 NPs library, using the soil invertebrate Enchytraeus crypticus (Oligochaeta), via a 5-day pulse via aqueous exposure followed by a 21-days recovery period in soil (survival, reproduction assessment). Obviously, when testing TiO2, realistic conditions should include UV exposure. The 11 Fe-TiO2 library contains NPs of size range between 5-27 nm with varying %Fe (enabling the photoactivation of TiO2 at energy wavelengths in the visible-light range). The NPs were each described by 122 descriptors, being a mixture of measured and atomistic model descriptors. The data were explored using single and univariate statistical methods, combined with machine learning and multiscale modelling techniques. An iterative pruning process was adopted for identifying automatically the most significant descriptors. TiO2 NPs toxicity decreased when combined with UV. Notably, the short-term water exposure induced lasting biological responses even after longer-term recovery in clean exposure. The correspondence with Fe-content correlated with the band-gap hence the reduction of UV oxidative stress. The inclusion of both measured and modelled materials data benefitted the explanation of the results, when combined with machine learning.",2040-3364,2040-3372,,14666-14678, , ,,out_of_scope,
3897,"Title:A Deep Convolutional Autoencoder for Automatic Motion Artifact Removal in Electrodermal Activity

 Objective: This study aimed to develop a robust and data driven automatic motion artifacts (MA) removal technique from electrodermal activity (EDA) signal. Methods: we proposed a deep convolutional autoencoder (DCAE) approach for automatic MA removal in EDA signals. Our model was trained using several publicly available datasets that were collected using a wide variety of stimuli to cause EDA reactions; the sample size was large (N = 385 subjects). We trained and validated our DCAE network using both Gaussian white noise (GWN) and realistic MA data records collected using a novel circuitry in our lab. We further evaluated and compared the performance of our DCAE model with the existing methods on two independent and unseen datasets called Chon lab motion artifact dataset II (CMAD II) and central nervous system oxygen toxicity dataset (CNS-OT). Results: Our DCAE model showed significantly higher signal-to-noise-power-ratio improvement (SNRimp) and lower mean squared error (MSE) when compared with that of the three previous methods (averaged SNRimp=35.25dB, and MSE =0.028 on the MA-corrupted data). Moreover, the reconstructed EDAs from the CMAD II dataset had a mean correlation value of 0.78 (statistically significantly higher when compared with other methods) with the reference clean data from the motionless hand, whereas the raw MA-corrupted data had a correlation value of only 0.68. Conclusion: The results presented in the paper indicates that our DCAE can remove MAs with higher intensity where the existing methods fails. Significance: Proposed DCAE model can be used to recover a significant amount of otherwise discarded EDA data.","Hossain, Md-Billal; Posada-Quintero, Hugo F.; Chon, Ki H.","Posada-Quintero, Hugo F./E-2581-2016; Hossain, Md Billal/AAT-6811-2021","Posada-Quintero, Hugo F./0000-0003-4514-4772; Hossain, Md Billal/0000-0002-2344-8321",A Deep Convolutional Autoencoder for Automatic Motion Artifact Removal in Electrodermal Activity,69,12,10.1109/TBME.2022.3174509 ,Article ,2022.0,"Objective: This study aimed to develop a robust and data driven automatic motion artifacts (MA) removal technique from electrodermal activity (EDA) signal. Methods: we proposed a deep convolutional autoencoder (DCAE) approach for automatic MA removal in EDA signals. Our model was trained using several publicly available datasets that were collected using a wide variety of stimuli to cause EDA reactions; the sample size was large (N = 385 subjects). We trained and validated our DCAE network using both Gaussian white noise (GWN) and realistic MA data records collected using a novel circuitry in our lab. We further evaluated and compared the performance of our DCAE model with the existing methods on two independent and unseen datasets called Chon lab motion artifact dataset II (CMAD II) and central nervous system oxygen toxicity dataset (CNS-OT). Results: Our DCAE model showed significantly higher signal-to-noise-power-ratio improvement (SNRimp) and lower mean squared error (MSE) when compared with that of the three previous methods (averaged SNRimp=35.25dB, and MSE =0.028 on the MA-corrupted data). Moreover, the reconstructed EDAs from the CMAD II dataset had a mean correlation value of 0.78 (statistically significantly higher when compared with other methods) with the reference clean data from the motionless hand, whereas the raw MA-corrupted data had a correlation value of only 0.68. Conclusion: The results presented in the paper indicates that our DCAE can remove MAs with higher intensity where the existing methods fails. Significance: Proposed DCAE model can be used to recover a significant amount of otherwise discarded EDA data.",0018-9294,1558-2531,,3601-3611, , ,,out_of_scope,
3898,"Title:Assessing the ecotoxicity of ionic liquids on Vibrio fischeri using electrostatic potential descriptors

 Ionic liquids (ILs) have attracted increasing attention both in the scientific community and the industry in the past two decades. Their risk of being inevitable released to ecosystem lights up the urgent research on their toxicity to the environment. To reduce the time and capital consumption on testing tremendous ILs ecotoxicity experimentally, it is essential to construct predictive models for estimating their toxicity. The objective of this study is to provide a new approach for evaluating the ecotoxicity of ILs. A comprehensive ecotoxicity dataset for Vibrio fischeri involving 142 ILs, was collected and investigated. The electrostatic potential surface areas (S-EP) of separate cations and anions of ILs were firstly applied to develop predictive models for ecotoxicity on Vibrio fischeri. In addition, an intelligent algorithm named extreme learning machine (ELM) was employed to establish the predictive model. The squared correlation coefficients (R-2), the average absolute error (AAE%) and the rootmean-square error (RMSE) of the developed model are 0.9272, 0.2101 and 0.3262 for the entire set, respectively. The proposed approach based on the high R-2 and low deviation has remarkable potential for predicting ILs ecotoxicity on Vibrio fischeri.","Kang, Xuejing; Chen, Zhongbing; Zhao, Yongsheng","Chen, Zhongbing/H-5001-2018","Chen, Zhongbing/0000-0001-8801-4842",Assessing the ecotoxicity of ionic liquids on Vibrio fischeri using electrostatic potential descriptors,397,,10.1016/j.jhazmat.2020.122761 ,Article ,2020.0,"Ionic liquids (ILs) have attracted increasing attention both in the scientific community and the industry in the past two decades. Their risk of being inevitable released to ecosystem lights up the urgent research on their toxicity to the environment. To reduce the time and capital consumption on testing tremendous ILs ecotoxicity experimentally, it is essential to construct predictive models for estimating their toxicity. The objective of this study is to provide a new approach for evaluating the ecotoxicity of ILs. A comprehensive ecotoxicity dataset for Vibrio fischeri involving 142 ILs, was collected and investigated. The electrostatic potential surface areas (S-EP) of separate cations and anions of ILs were firstly applied to develop predictive models for ecotoxicity on Vibrio fischeri. In addition, an intelligent algorithm named extreme learning machine (ELM) was employed to establish the predictive model. The squared correlation coefficients (R-2), the average absolute error (AAE%) and the rootmean-square error (RMSE) of the developed model are 0.9272, 0.2101 and 0.3262 for the entire set, respectively. The proposed approach based on the high R-2 and low deviation has remarkable potential for predicting ILs ecotoxicity on Vibrio fischeri.",0304-3894,1873-3336,,, , ,,out_of_scope,
3899,"Title:Jury Learning: Integrating Dissenting Voices into Machine Learning Models

 Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups' labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifer's prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators' models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent. A field evaluation finds that practitioners construct diverse juries that alter 14% of classification outcomes.","Gordon, Mitchell L.; Lam, Michelle S.; Park, Joon Sung; Patel, Kayur; Hancock, Jeff T.; Hashimoto, Tatsunori; Bernstein, Michael S.",,"Bernstein, Michael/0000-0001-8020-9434; Gordon, Mitchell/0000-0003-1008-2321; Hancock, Jeffrey/0000-0001-5367-2677",Jury Learning: Integrating Dissenting Voices into Machine Learning Models,,,10.1145/3491102.3502004 ,Proceedings Paper ,2022.0,"Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups' labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifer's prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators' models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent. A field evaluation finds that practitioners construct diverse juries that alter 14% of classification outcomes.",,,978-1-4503-9157-3,, , CHI Conference on Human Factors in Computing Systems (CHI)CHI Conference on Human Factors in Computing Systems (CHI),,detection#evaluation#methodology,
3900,"Title:AMR-CNN: Abstract Meaning Representation with Convolution Neural Network for Toxic Content Detection

 Recognizing the offensive, abusive, and profanity of multimedia content on the web has been a challenge to keep the web environment for user's freedom of speech. As profanity filtering function has been developed and applied in text, audio, and video context in platforms such as social media, entertainment, and education, the number of methods to trick the web-based application also has been increased and became a new issue to be solved. Compared to commonly developed toxic content detection systems that use lexicon and keyword-based detection, this work tries to embrace a different approach by the meaning of the sentence. Meaning representation is a way to grasp the meaning of linguistic input. This work proposed a data-driven approach utilizing Abstract meaning Representation to extract the meaning of the online text content into a convolutional neural network to detect level profanity. This work implements the proposed model in two kinds of datasets from the Offensive Language Identification Dataset and other datasets from the Offensive Hate dataset merged with the Twitter Sentiment Analysis dataset. The results indicate that the proposed model performs effectively, and can achieve a satisfactory accuracy in recognizing the level of online text content toxicity.","Elbasani, Ermal; Kim, Jeong-Dong",,"Kim, Jeong-Dong/0000-0002-5113-221X",AMR-CNN: Abstract Meaning Representation with Convolution Neural Network for Toxic Content Detection,21,3,10.13052/jwe1540-9589.2135 ,Article ,2022.0,"Recognizing the offensive, abusive, and profanity of multimedia content on the web has been a challenge to keep the web environment for user's freedom of speech. As profanity filtering function has been developed and applied in text, audio, and video context in platforms such as social media, entertainment, and education, the number of methods to trick the web-based application also has been increased and became a new issue to be solved. Compared to commonly developed toxic content detection systems that use lexicon and keyword-based detection, this work tries to embrace a different approach by the meaning of the sentence. Meaning representation is a way to grasp the meaning of linguistic input. This work proposed a data-driven approach utilizing Abstract meaning Representation to extract the meaning of the online text content into a convolutional neural network to detect level profanity. This work implements the proposed model in two kinds of datasets from the Offensive Language Identification Dataset and other datasets from the Offensive Hate dataset merged with the Twitter Sentiment Analysis dataset. The results indicate that the proposed model performs effectively, and can achieve a satisfactory accuracy in recognizing the level of online text content toxicity.",1540-9589,1544-5976,,677-692, , ,,Use_dataset#detection#methodology,
3901,"Title:A study towards contextual understanding of toxicity in online conversations

 Identifying and annotating toxic online content on social media platforms is an extremely challenging problem. Work that studies toxicity in online content has predominantly focused on comments as independent entities. However, comments on social media are inherently conversational, and therefore, understanding and judging the comments fundamentally requires access to the context in which they are made. We introduce a study and resulting annotated dataset where we devise a number of controlled experiments on the importance of context and other observable confounders - namely gender, age and political orientation - towards the perception of toxicity in online content. Our analysis clearly shows the significance of context and the effect of observable confounders on annotations. Namely, we observe that the ratio of toxic to non-toxic judgements can be very different for each control group, and a higher proportion of samples are judged toxic in the presence of contextual information.","Madhyastha, Pranava; Founta, Antigoni; Specia, Lucia",,"Madhyastha, Pranava/0000-0002-4438-8161",A study towards contextual understanding of toxicity in online conversations,,,10.1017/S1351324923000414 ,Article; Early Access ,,"Identifying and annotating toxic online content on social media platforms is an extremely challenging problem. Work that studies toxicity in online content has predominantly focused on comments as independent entities. However, comments on social media are inherently conversational, and therefore, understanding and judging the comments fundamentally requires access to the context in which they are made. We introduce a study and resulting annotated dataset where we devise a number of controlled experiments on the importance of context and other observable confounders - namely gender, age and political orientation - towards the perception of toxicity in online content. Our analysis clearly shows the significance of context and the effect of observable confounders on annotations. Namely, we observe that the ratio of toxic to non-toxic judgements can be very different for each control group, and a higher proportion of samples are judged toxic in the presence of contextual information.",1351-3249,1469-8110,,, , ,,Gen_dataset#detection#evaluation,
3902,"Title:Detecting Aggression and Toxicity using a Multi Dimension Capsule Network

 In the era of social media, hate speech, trolling and verbal abuse have become a common issue. We present an approach to automatically classify such statements, using a new deep learning architecture. Our model comprises of a Multi Dimension Capsule Network that generates the representation of sentences which we use for classification. We further provide an analysis of our model's interpretation of such statements. We compare the results of our model with state-of-art classification algorithms and demonstrate our model's ability. It also has the capability to handle comments that are written in both Hindi and English, which are provided in the TRAC dataset. We also compare results on Kaggle's Toxic comment classification dataset.","Srivastava, Saurabh; Khurana, Prerna",,,Detecting Aggression and Toxicity using a Multi Dimension Capsule Network,,, ,Proceedings Paper ,2019.0,"In the era of social media, hate speech, trolling and verbal abuse have become a common issue. We present an approach to automatically classify such statements, using a new deep learning architecture. Our model comprises of a Multi Dimension Capsule Network that generates the representation of sentences which we use for classification. We further provide an analysis of our model's interpretation of such statements. We compare the results of our model with state-of-art classification algorithms and demonstrate our model's ability. It also has the capability to handle comments that are written in both Hindi and English, which are provided in the TRAC dataset. We also compare results on Kaggle's Toxic comment classification dataset.",,,978-1-950737-43-7,157-162, , 3rd Workshop on Abusive Language Online3rd Workshop on Abusive Language Online,,Use_dataset#detection#methodology,
3903,"Title:Analysis of the benefits of imputation models over traditional QSAR models for toxicity prediction

 Recently, imputation techniques have been adapted to predict activity values among sparse bioactivity matrices, showing improvements in predictive performance over traditional QSAR models. These models are able to use experimental activity values for auxiliary assays when predicting the activity of a test compound on a specific assay. In this study, we tested three different multi-task imputation techniques on three classification-based toxicity datasets: two of small scale (12 assays each) and one large scale with 417 assays. Moreover, we analyzed in detail the improvements shown by the imputation models. We found that test compounds that were dissimilar to training compounds, as well as test compounds with a large number of experimental values for other assays, showed the largest improvements. We also investigated the impact of sparsity on the improvements seen as well as the relatedness of the assays being considered. Our results show that even a small amount of additional information can provide imputation methods with a strong boost in predictive performance over traditional single task and multi-task predictive models.","Walter, Moritz; Allen, Luke N.; de la Vega de Leon, Antonio; Webb, Samuel J.; Gillet, Valerie J.",,,Analysis of the benefits of imputation models over traditional QSAR models for toxicity prediction,14,1,10.1186/s13321-022-00611-w ,Article ,2022.0,"Recently, imputation techniques have been adapted to predict activity values among sparse bioactivity matrices, showing improvements in predictive performance over traditional QSAR models. These models are able to use experimental activity values for auxiliary assays when predicting the activity of a test compound on a specific assay. In this study, we tested three different multi-task imputation techniques on three classification-based toxicity datasets: two of small scale (12 assays each) and one large scale with 417 assays. Moreover, we analyzed in detail the improvements shown by the imputation models. We found that test compounds that were dissimilar to training compounds, as well as test compounds with a large number of experimental values for other assays, showed the largest improvements. We also investigated the impact of sparsity on the improvements seen as well as the relatedness of the assays being considered. Our results show that even a small amount of additional information can provide imputation methods with a strong boost in predictive performance over traditional single task and multi-task predictive models.",1758-2946,,,, , ,,out_of_scope,
3904,"Title:Methodology of aiQSAR: a group-specific approach to QSAR modelling

 BackgroundSeveral QSAR methodology developments have shown promise in recent years. These include the consensus approach to generate the final prediction of a model, utilizing new, advanced machine learning algorithms and streamlining, standardization and automation of various QSAR steps. One approach that seems under-explored is at-the-runtime generation of local models specific to individual compounds. This approach was quite likely limited by the computational requirements, but with current increases in processing power and the widespread availability of cluster-computing infrastructure, this limitation is no longer that severe.ResultsWe propose a new QSAR methodology: aiQSAR, whose aim is to generate endpoint predictions directly from the input dataset by building an array of local models generated at-the-runtime and specific for each compound in the dataset. The local group of each compound is selected on the basis of fingerprint similarities and the final prediction is calculated by integrating the results of a number of autonomous mathematical models. The method is applicable to regression, binary classification and multi-class classification and was tested on one dataset for each endpoint type: bioconcentration factor (BCF) for regression, Ames test for binary classification and Environmental Protection Agency (EPA) acute rat oral toxicity ranking for multi-class classification. As part of this method, the applicability domain of each prediction is assessed through the applicability domain measure, calculated on the basis of the fingerprint similarities in each local group of compounds.ConclusionsWe outline the methodology for a new QSAR-based predictive tool whose advantages are automation, group-specific approach to modelling and simplicity of execution. Our aim now will be to develop this method into a stand-alone software tool. We hope that eventual adoption of our tool would make QSAR modelling more accessible and transparent. Our methodology could be used as an initial modelling step, to predict new compounds by simply loading the training dataset as an input. Predictions could then be further evaluated and refined either by other tools or through optimization of aiQSAR parameters.","Vukovic, Kristijan; Gadaleta, Domenico; Benfenati, Emilio","Benfenati, Emilio/AAA-9022-2020; Gadaleta, Domenico/ABG-3259-2020","Benfenati, Emilio/0000-0002-3976-5989; Gadaleta, Domenico/0000-0002-3154-5930; Vukovic, Kristijan/0000-0001-8606-4715",Methodology of aiQSAR: a group-specific approach to QSAR modelling,11,,10.1186/s13321-019-0350-y ,Article ,2019.0,"BackgroundSeveral QSAR methodology developments have shown promise in recent years. These include the consensus approach to generate the final prediction of a model, utilizing new, advanced machine learning algorithms and streamlining, standardization and automation of various QSAR steps. One approach that seems under-explored is at-the-runtime generation of local models specific to individual compounds. This approach was quite likely limited by the computational requirements, but with current increases in processing power and the widespread availability of cluster-computing infrastructure, this limitation is no longer that severe.ResultsWe propose a new QSAR methodology: aiQSAR, whose aim is to generate endpoint predictions directly from the input dataset by building an array of local models generated at-the-runtime and specific for each compound in the dataset. The local group of each compound is selected on the basis of fingerprint similarities and the final prediction is calculated by integrating the results of a number of autonomous mathematical models. The method is applicable to regression, binary classification and multi-class classification and was tested on one dataset for each endpoint type: bioconcentration factor (BCF) for regression, Ames test for binary classification and Environmental Protection Agency (EPA) acute rat oral toxicity ranking for multi-class classification. As part of this method, the applicability domain of each prediction is assessed through the applicability domain measure, calculated on the basis of the fingerprint similarities in each local group of compounds.ConclusionsWe outline the methodology for a new QSAR-based predictive tool whose advantages are automation, group-specific approach to modelling and simplicity of execution. Our aim now will be to develop this method into a stand-alone software tool. We hope that eventual adoption of our tool would make QSAR modelling more accessible and transparent. Our methodology could be used as an initial modelling step, to predict new compounds by simply loading the training dataset as an input. Predictions could then be further evaluated and refined either by other tools or through optimization of aiQSAR parameters.",1758-2946,,,, , ,,out_of_scope,
3905,"Title:Developing a socio-computational approach to examine toxicity propagation and regulation in COVID-19 discourse on YouTube

 As the novel coronavirus (COVID-19) continues to ravage the world at an unprecedented rate, formal recommendations from medical experts are becoming muffled by the avalanche of toxic content posted on social media platforms. This high level of toxic content prevents the dissemination of important and time-sensitive information and jeopardizes the sense of community that online social networks (OSNs) seek to cultivate. In this article, we present techniques to analyze toxic content and actors that propagated it on YouTube during the initial months after COVID-19 information was made public. Our dataset consists of 544 channels, 3,488 videos, 453,111 commenters, and 849,689 comments. We applied topic modeling based on Latent Dirichlet Allocation (LDA) to identify dominant topics and evolving trends within the comments on relevant videos. We conducted social network analysis (SNA) to detect influential commenters, and toxicity analysis to measure the health of the network. SNA allows us to identify the top toxic users in the network, which led to the creation of experiments simulating the impact of removal of these users on toxicity in the network. Through this work, we demonstrate not only how to identify toxic content related to COVID-19 on YouTube and the actors who propagated this toxicity, but also how social media companies and policy makers can use this work. This work is novel in that we devised a set of experiments in an attempt to show how if social media platforms eliminate certain toxic users, they can improve the overall health of the network by reducing the overall toxicity level.","Obadimu, Adewale; Khaund, Tuja; Mead, Esther; Marcoux, Thomas; Agarwal, Nitin","Mead, Esther/AFQ-6652-2022","Marcoux, Thomas/0000-0001-8443-6618",Developing a socio-computational approach to examine toxicity propagation and regulation in COVID-19 discourse on YouTube,58,5,10.1016/j.ipm.2021.102660 ,Article ,2021.0,"As the novel coronavirus (COVID-19) continues to ravage the world at an unprecedented rate, formal recommendations from medical experts are becoming muffled by the avalanche of toxic content posted on social media platforms. This high level of toxic content prevents the dissemination of important and time-sensitive information and jeopardizes the sense of community that online social networks (OSNs) seek to cultivate. In this article, we present techniques to analyze toxic content and actors that propagated it on YouTube during the initial months after COVID-19 information was made public. Our dataset consists of 544 channels, 3,488 videos, 453,111 commenters, and 849,689 comments. We applied topic modeling based on Latent Dirichlet Allocation (LDA) to identify dominant topics and evolving trends within the comments on relevant videos. We conducted social network analysis (SNA) to detect influential commenters, and toxicity analysis to measure the health of the network. SNA allows us to identify the top toxic users in the network, which led to the creation of experiments simulating the impact of removal of these users on toxicity in the network. Through this work, we demonstrate not only how to identify toxic content related to COVID-19 on YouTube and the actors who propagated this toxicity, but also how social media companies and policy makers can use this work. This work is novel in that we devised a set of experiments in an attempt to show how if social media platforms eliminate certain toxic users, they can improve the overall health of the network by reducing the overall toxicity level.",0306-4573,1873-5371,,, , ,,Gen_dataset#detection#methodology,
3906,"Title:A Comparative Analysis of Feature Selection Algorithms on Classification of Gene Microarray Dataset

 Analysis of gene expression is important in many fields of biological research in order to retrieve the required information. As the time advances, the illness in general and cancer in particular have become more and more complex and complicated, in detecting, analyzing and curing. Cancer research is one of the major research areas in the medical field. Accurate prediction of different tumor types has great value in providing better treatment and toxicity minimization on the patients. To minimize it, the data mining algorithms are important tool and the most extensively used approach to classify gene expression data and plays an important role for cancer classification. One of the major challenges is to discover how to extract useful information from datasets. This research is based on recent advances in the machine learning based microarray gene expression data analysis with three feature selection algorithms.","Jeyachidra, J.; Punithavalli, M.",,,A Comparative Analysis of Feature Selection Algorithms on Classification of Gene Microarray Dataset,,, ,Proceedings Paper ,2013.0,"Analysis of gene expression is important in many fields of biological research in order to retrieve the required information. As the time advances, the illness in general and cancer in particular have become more and more complex and complicated, in detecting, analyzing and curing. Cancer research is one of the major research areas in the medical field. Accurate prediction of different tumor types has great value in providing better treatment and toxicity minimization on the patients. To minimize it, the data mining algorithms are important tool and the most extensively used approach to classify gene expression data and plays an important role for cancer classification. One of the major challenges is to discover how to extract useful information from datasets. This research is based on recent advances in the machine learning based microarray gene expression data analysis with three feature selection algorithms.",,,978-1-4673-5786-9; 978-1-4673-5787-6,1088-1093, , International Conference on Information Communication and Embedded Systems (ICICES)International Conference on Information Communication and Embedded Systems (ICICES),,out_of_scope,
3907,"Title:A CT-based radiomics model for predicting feeding tube insertion in oropharyngeal cancer

 Patients with oropharyngeal cancer (OPC) treated with chemoradiation suffer treatment-related toxicities which can lead to nutritional deficiencies and weight loss. As a result, many of these patients will require supportive care interventions, such as a feeding tube. We aimed to develop a machine learning model to predict feeding tube insertion in patients with OPC (n=343). A total of 116 patients (34%) required a feeding tube. Primary gross tumor volumes were contoured on planning CT images for patients prior to treatment. PyRadiomics was used to compute 1212 radiomic features from these volumes on the original and filtered images. The dataset was split into independent training (n=244) and testing ( n=99) datasets. LASSO feature selection was applied to select the optimal features to predict feeding tube insertion. Support vector machine (SVM) and random forest (RF) classifiers were built using the selected features on the training dataset. The machine learning models' performances were assessed in the testing dataset based on the metric of the AUC. Through feature selection, seven predictive features were selected. This included one original texture, two filtered first order, three filtered texture, and one clinical feature. The top performing classifier was the RF model which achieved an AUC of 0.69 [95% CI: 0.57-0.80] in the testing dataset. To the best of our knowledge, this is the first study to use radiomics to predict feeding tube insertion. This model could assist physicians in identifying patients who may benefit from prophylactic feeding tube insertion, ultimately improving quality of life for patients with OPC.","Chinnery, Tricia; Lang, Pencilla; Nichols, Anthony; Mattonen, Sarah",,"Nichols, Anthony/0000-0002-0760-980X",A CT-based radiomics model for predicting feeding tube insertion in oropharyngeal cancer,12033,,10.1117/12.2611502 ,Proceedings Paper ,2022.0,"Patients with oropharyngeal cancer (OPC) treated with chemoradiation suffer treatment-related toxicities which can lead to nutritional deficiencies and weight loss. As a result, many of these patients will require supportive care interventions, such as a feeding tube. We aimed to develop a machine learning model to predict feeding tube insertion in patients with OPC (n=343). A total of 116 patients (34%) required a feeding tube. Primary gross tumor volumes were contoured on planning CT images for patients prior to treatment. PyRadiomics was used to compute 1212 radiomic features from these volumes on the original and filtered images. The dataset was split into independent training (n=244) and testing ( n=99) datasets. LASSO feature selection was applied to select the optimal features to predict feeding tube insertion. Support vector machine (SVM) and random forest (RF) classifiers were built using the selected features on the training dataset. The machine learning models' performances were assessed in the testing dataset based on the metric of the AUC. Through feature selection, seven predictive features were selected. This included one original texture, two filtered first order, three filtered texture, and one clinical feature. The top performing classifier was the RF model which achieved an AUC of 0.69 [95% CI: 0.57-0.80] in the testing dataset. To the best of our knowledge, this is the first study to use radiomics to predict feeding tube insertion. This model could assist physicians in identifying patients who may benefit from prophylactic feeding tube insertion, ultimately improving quality of life for patients with OPC.",0277-786X,1996-756X,978-1-5106-4942-2; 978-1-5106-4941-5,, , Conference on Medical Imaging - Computer-Aided DiagnosisConference on Medical Imaging - Computer-Aided Diagnosis,,out_of_scope,
3908,"Title:Machine Learning and Lexicon Approach to Texts Processing in the Detection of Degrees of Toxicity in Online Discussions

 This article focuses on the problem of detecting toxicity in online discussions. Toxicity is currently a serious problem when people are largely influenced by opinions on social networks. We offer a solution based on classification models using machine learning methods to classify short texts on social networks into multiple degrees of toxicity. The classification models used both classic methods of machine learning, such as naive Bayes and SVM (support vector machine) as well ensemble methods, such as bagging and RF (random forest). The models were created using text data, which we extracted from social networks in the Slovak language. The labelling of our dataset of short texts into multiple classes-the degrees of toxicity-was provided automatically by our method based on the lexicon approach to texts processing. This lexicon method required creating a dictionary of toxic words in the Slovak language, which is another contribution of the work. Finally, an application was created based on the learned machine learning models, which can be used to detect the degree of toxicity of new social network comments as well as for experimentation with various machine learning methods. We achieved the best results using an SVM-average value of accuracy = 0.89 and F1 = 0.79. This model also outperformed the ensemble learning by the RF and Bagging methods; however, the ensemble learning methods achieved better results than the naive Bayes method.","Machova, Kristina; Mach, Marian; Adamisin, Kamil","Mach, Marian/AAH-4686-2019","Mach, Marian/0000-0001-7612-9204; Machova, Kristina/0000-0002-7741-4039",Machine Learning and Lexicon Approach to Texts Processing in the Detection of Degrees of Toxicity in Online Discussions,22,17,10.3390/s22176468 ,Article ,2022.0,"This article focuses on the problem of detecting toxicity in online discussions. Toxicity is currently a serious problem when people are largely influenced by opinions on social networks. We offer a solution based on classification models using machine learning methods to classify short texts on social networks into multiple degrees of toxicity. The classification models used both classic methods of machine learning, such as naive Bayes and SVM (support vector machine) as well ensemble methods, such as bagging and RF (random forest). The models were created using text data, which we extracted from social networks in the Slovak language. The labelling of our dataset of short texts into multiple classes-the degrees of toxicity-was provided automatically by our method based on the lexicon approach to texts processing. This lexicon method required creating a dictionary of toxic words in the Slovak language, which is another contribution of the work. Finally, an application was created based on the learned machine learning models, which can be used to detect the degree of toxicity of new social network comments as well as for experimentation with various machine learning methods. We achieved the best results using an SVM-average value of accuracy = 0.89 and F1 = 0.79. This model also outperformed the ensemble learning by the RF and Bagging methods; however, the ensemble learning methods achieved better results than the naive Bayes method.",,1424-8220,,, , ,,Gen_dataset#detection#methodology#out_but_toxicity,
3909,"Title:Integrated method of compromise-based ant colony algorithm and rough set theory and its application in toxicity mechanism classification

 Attribute discretization and reduction are two key issues in rough set theory. However, almost all previous studies consider them as two separate steps, which can not capture an inherent relationship between them. In this paper, a bi-objective optimization problem is constructed for simultaneous attribute discretization and reduction. A novel compromise-based ant colony algorithm (CACA) for simultaneously solving attribute discretization and reduction is proposed, which adopts a distance metric to stepwise approach the ideal solution. To improve efficiency of the proposed method, both the cut information and attribute information are adopted to dynamically calculate heuristic information, and a local search strategy is also embedded. The grade of nature spearmint essence (NSE), wine and glass classification problems are used as three test datasets to demonstrate the validity of the proposed CACA. Furthermore, the proposed method is applied to two toxicity mechanism classification problems: the classification of three narcosis mechanisms of aquatic toxicity for 194 organic compounds and the classification of four action modes of 221 phenols. The obtained results illustrate that the proposed method has better prediction performance than linear discriminant analysis, radial basis function neural network and support vector machine. (C) 2007 Published by Elsevier B.V.","He, Yijun; Chen, Dezhao; Zhao, Weixiang","Dubova, Olena/V-5646-2017","Dubova, Olena/0000-0002-0130-4394",Integrated method of compromise-based ant colony algorithm and rough set theory and its application in toxicity mechanism classification,92,1,10.1016/j.chemolab.2007.11.008 ,Article ,2008.0,"Attribute discretization and reduction are two key issues in rough set theory. However, almost all previous studies consider them as two separate steps, which can not capture an inherent relationship between them. In this paper, a bi-objective optimization problem is constructed for simultaneous attribute discretization and reduction. A novel compromise-based ant colony algorithm (CACA) for simultaneously solving attribute discretization and reduction is proposed, which adopts a distance metric to stepwise approach the ideal solution. To improve efficiency of the proposed method, both the cut information and attribute information are adopted to dynamically calculate heuristic information, and a local search strategy is also embedded. The grade of nature spearmint essence (NSE), wine and glass classification problems are used as three test datasets to demonstrate the validity of the proposed CACA. Furthermore, the proposed method is applied to two toxicity mechanism classification problems: the classification of three narcosis mechanisms of aquatic toxicity for 194 organic compounds and the classification of four action modes of 221 phenols. The obtained results illustrate that the proposed method has better prediction performance than linear discriminant analysis, radial basis function neural network and support vector machine. (C) 2007 Published by Elsevier B.V.",0169-7439,1873-3239,,22-32, , ,,out_of_scope,
3910,"Title:Fine Tuning BERT for Unethical Behavior Classification

 Social media allows people to express themselves, however, there exists a threat of abuse and harassment. This threat leads to a negative impact on society which results in a change in people behaviour and they stop expressing their ideas freely. Classification of unethical behaviour in comments is a multi-label classification task. Due to the limited availability of the dataset, training does not yield worthy accuracies. Hence, a large training corpus is needed. This work, therefore, proposes to supplement training data by making use of transfer learning. Bi-directional Encoder Representations from Transformers (BERT) pre-trained model is fine-tuned to detect unethical users' behaviour. The approach used in this work achieved competitive accuracy for the task of multi-label classification on the toxicity dataset of Wikipedia Comments Corpus.","Fatima, Syeda Faizan; Latif, Seemab; Latif, Rabia",,,Fine Tuning BERT for Unethical Behavior Classification,,,10.1109/ICoDT252288.2021.9441540 ,Proceedings Paper ,2021.0,"Social media allows people to express themselves, however, there exists a threat of abuse and harassment. This threat leads to a negative impact on society which results in a change in people behaviour and they stop expressing their ideas freely. Classification of unethical behaviour in comments is a multi-label classification task. Due to the limited availability of the dataset, training does not yield worthy accuracies. Hence, a large training corpus is needed. This work, therefore, proposes to supplement training data by making use of transfer learning. Bi-directional Encoder Representations from Transformers (BERT) pre-trained model is fine-tuned to detect unethical users' behaviour. The approach used in this work achieved competitive accuracy for the task of multi-label classification on the toxicity dataset of Wikipedia Comments Corpus.",,,978-1-6654-1285-8,, , IEEE International Conference on Digital Futures and Transformative Technologies (ICoDT2)IEEE International Conference on Digital Futures and Transformative Technologies (ICoDT2),,Use_dataset#detection,
3911,"Title:On Online Hate Speech Detection. Effects of Negated Data Construction

 In the era of social media and mobile internet, the design of automatic tools for online detection of hate speech and/or abusive language becomes crucial for society and community empowerment. Nowadays of current technology in this respect is still limited and many service providers arc still relying on the manual check. This paper aims to advance in this topic by leveraging novel natural language processing, machine learning, and feature engineering techniques. The proposed approach advocates a classification-like technique that makes use of a special data design procedure. The latter enforces a balanced training scheme by exploring the negativity of the original dataset. This generates new transfer learning paradigms, Two classification schemes using convolution neural network and LSTN architecture that use FastText embeddings as input features are contrasted with baseline models constituted of Logistic regression and Naives' Bayes classifiers. Wikipedia Comment dataset constituted of Personal Attack, Aggression and Toxicity data are employed to test the validity and usefulness of the proposal.","Abderrouaf, Cheniki; Oussalah, Mourad",,,On Online Hate Speech Detection. Effects of Negated Data Construction,,, ,Proceedings Paper ,2019.0,"In the era of social media and mobile internet, the design of automatic tools for online detection of hate speech and/or abusive language becomes crucial for society and community empowerment. Nowadays of current technology in this respect is still limited and many service providers arc still relying on the manual check. This paper aims to advance in this topic by leveraging novel natural language processing, machine learning, and feature engineering techniques. The proposed approach advocates a classification-like technique that makes use of a special data design procedure. The latter enforces a balanced training scheme by exploring the negativity of the original dataset. This generates new transfer learning paradigms, Two classification schemes using convolution neural network and LSTN architecture that use FastText embeddings as input features are contrasted with baseline models constituted of Logistic regression and Naives' Bayes classifiers. Wikipedia Comment dataset constituted of Personal Attack, Aggression and Toxicity data are employed to test the validity and usefulness of the proposal.",2639-1589,,978-1-7281-0858-2,5595-5602, , IEEE International Conference on Big Data (Big Data)IEEE International Conference on Big Data (Big Data),,Use_dataset#detection,
3912,"Title:Fighting Adversarial Attacks on Online Abusive Language Moderation

 Lack of moderation in online conversations may result in personal aggression, harassment or cyberbullying. Such kind of hostility is usually expressed by using profanity or abusive language. On the basis of this assumption, recently Google has developed a machine-learning model to detect hostility within a comment. The model is able to assess to what extent abusive language is poisoning a conversation, obtaining a toxicity score for the comment. Unfortunately, it has been suggested that such a toxicity model can be deceived by adversarial attacks that manipulate the text sequence of the abusive language. In this paper we aim to fight this anomaly; firstly we characterise two types of adversarial attacks, one using obfuscation and the other using polarity transformations. Then, we propose a two-stage approach to disarm such attacks by coupling a text deobfuscation method and the toxicity scoring model. The approach was validated on a dataset of approximately 24000 distorted comments showing that it is feasible to restore the toxicity score of the adversarial variants. We anticipate that combining machine learning and text pattern recognition methods operating on different layers of linguistic features, will help to foster aggression-safe online conversations despite the adversary challenges inherent to the versatile nature of written language.","Rodriguez, Nestor; Rojas-Galeano, Sergio",,,Fighting Adversarial Attacks on Online Abusive Language Moderation,915,,10.1007/978-3-030-00350-0_40 ,Proceedings Paper ,2018.0,"Lack of moderation in online conversations may result in personal aggression, harassment or cyberbullying. Such kind of hostility is usually expressed by using profanity or abusive language. On the basis of this assumption, recently Google has developed a machine-learning model to detect hostility within a comment. The model is able to assess to what extent abusive language is poisoning a conversation, obtaining a toxicity score for the comment. Unfortunately, it has been suggested that such a toxicity model can be deceived by adversarial attacks that manipulate the text sequence of the abusive language. In this paper we aim to fight this anomaly; firstly we characterise two types of adversarial attacks, one using obfuscation and the other using polarity transformations. Then, we propose a two-stage approach to disarm such attacks by coupling a text deobfuscation method and the toxicity scoring model. The approach was validated on a dataset of approximately 24000 distorted comments showing that it is feasible to restore the toxicity score of the adversarial variants. We anticipate that combining machine learning and text pattern recognition methods operating on different layers of linguistic features, will help to foster aggression-safe online conversations despite the adversary challenges inherent to the versatile nature of written language.",1865-0929,1865-0937,978-3-030-00350-0; 978-3-030-00349-4,480-493, , 5th Workshop on Engineering Applications (WEA)5th Workshop on Engineering Applications (WEA),,detection#evaluation#methodology,
3913,"Title:Development of benchmark datasets for text mining and sentiment analysis to accelerate regulatory literature review

 In the field of regulatory science, reviewing literature is an essential and important step, which most of the time is conducted by manually reading hundreds of articles. Although this process is highly time-consuming and labor-intensive, most output of this process is not well transformed into machine-readable format. The limited availability of data has largely constrained the artificial intelligence (AI) system development to facilitate this literature reviewing in the regulatory process.In the past decade, AI has revolutionized the area of text mining as many deep learning approaches have been developed to search, annotate, and classify relevant documents. After the great advancement of AI algorithms, a lack of high-quality data instead of the algorithms has recently become the bottleneck of AI system development.Herein, we constructed two large benchmark datasets, Chlorine Efficacy dataset (CHE) and Chlorine Safety dataset (CHS), under a regulatory scenario that sought to assess the antiseptic efficacy and toxicity of chlorine. For each dataset, similar to 10,000 scientific articles were initially collected, manually reviewed, and their relevance to the review task were labeled. To ensure high data quality, each paper was labeled by a consensus among multiple experienced reviewers. The overall relevance rate was 27.21% (2,663 of 9,788) for CHE and 7.50% (761 of 10,153) for CHS, respectively. Furthermore, the relevant articles were categorized into five subgroups based on the focus of their content.Next, we developed an attention-based classification language model using these two datasets. The proposed classification model yielded 0.857 and 0.908 of Area Under the Curve (AUC) for CHE and CHS dataset, respectively. This performance was significantly better than permutation test (p < 10E-9), demonstrating that the labeling processes were valid. To conclude, our datasets can be used as benchmark to develop AI systems, which can further facilitate the literature review process in regulatory science.","Wu, Leihong; Chen, Si; Guo, Lei; Shpyleva, Svitlana; Harris, Kelly; Fahmi, Tariq; Flanigan, Timothy; Tong, Weida; Xu, Joshua; Ren, Zhen",,,Development of benchmark datasets for text mining and sentiment analysis to accelerate regulatory literature review,137,,10.1016/j.yrtph.2022.105287 ,Review ,2023.0,"In the field of regulatory science, reviewing literature is an essential and important step, which most of the time is conducted by manually reading hundreds of articles. Although this process is highly time-consuming and labor-intensive, most output of this process is not well transformed into machine-readable format. The limited availability of data has largely constrained the artificial intelligence (AI) system development to facilitate this literature reviewing in the regulatory process.In the past decade, AI has revolutionized the area of text mining as many deep learning approaches have been developed to search, annotate, and classify relevant documents. After the great advancement of AI algorithms, a lack of high-quality data instead of the algorithms has recently become the bottleneck of AI system development.Herein, we constructed two large benchmark datasets, Chlorine Efficacy dataset (CHE) and Chlorine Safety dataset (CHS), under a regulatory scenario that sought to assess the antiseptic efficacy and toxicity of chlorine. For each dataset, similar to 10,000 scientific articles were initially collected, manually reviewed, and their relevance to the review task were labeled. To ensure high data quality, each paper was labeled by a consensus among multiple experienced reviewers. The overall relevance rate was 27.21% (2,663 of 9,788) for CHE and 7.50% (761 of 10,153) for CHS, respectively. Furthermore, the relevant articles were categorized into five subgroups based on the focus of their content.Next, we developed an attention-based classification language model using these two datasets. The proposed classification model yielded 0.857 and 0.908 of Area Under the Curve (AUC) for CHE and CHS dataset, respectively. This performance was significantly better than permutation test (p < 10E-9), demonstrating that the labeling processes were valid. To conclude, our datasets can be used as benchmark to develop AI systems, which can further facilitate the literature review process in regulatory science.",0273-2300,1096-0295,,, , ,,out_of_scope,
3914,"Title:MOSAIC_SSD: A NEW WEB TOOL FOR SPECIES SENSITIVITY DISTRIBUTION TO INCLUDE CENSORED DATA BY MAXIMUM LIKELIHOOD

 Censored data are seldom taken into account in species sensitivity distribution (SSD) analysis. However, they are found in virtually every dataset and sometimes represent the better part of the data. Stringent recommendations on data quality often entail discarding a lot of these meaningful data, resulting in datasets of reduced size which lack representativeness of any realistic community. However, it is reasonably simple to include censored data in SSD by using an extension of the standard maximum likelihood method. The authors detail this approach based on the use of the R-package fitdistrplus, dedicated to the fit of parametric probability distributions. The authors present the new Web tool MOSAIC_SSD, that can fit an SSD on datasets containing any type of data, censored or not. The MOSAIC_SSD Web tool predicts any hazardous concentration and provides bootstrap confidence intervals on the predictions. Finally, the authors illustrate the added value of including censored data in SSD, taking examples from published data. (C) 2014 SETAC","King, Guillaume Kon Kam; Veber, Philippe; Charles, Sandrine; Delignette-Muller, Marie Laure","KING, Guillaume KON KAM/AAK-5430-2021; Veber, Philippe/M-2918-2015; CHARLES, Sandrine/B-3907-2016","Kon Kam King, Guillaume/0000-0001-9267-8043; CHARLES, Sandrine/0000-0003-4604-0166; Delignette-Muller, Marie Laure/0000-0001-5453-3994",MOSAIC_SSD: A NEW WEB TOOL FOR SPECIES SENSITIVITY DISTRIBUTION TO INCLUDE CENSORED DATA BY MAXIMUM LIKELIHOOD,33,9,10.1002/etc.2644 ,Article ,2014.0,"Censored data are seldom taken into account in species sensitivity distribution (SSD) analysis. However, they are found in virtually every dataset and sometimes represent the better part of the data. Stringent recommendations on data quality often entail discarding a lot of these meaningful data, resulting in datasets of reduced size which lack representativeness of any realistic community. However, it is reasonably simple to include censored data in SSD by using an extension of the standard maximum likelihood method. The authors detail this approach based on the use of the R-package fitdistrplus, dedicated to the fit of parametric probability distributions. The authors present the new Web tool MOSAIC_SSD, that can fit an SSD on datasets containing any type of data, censored or not. The MOSAIC_SSD Web tool predicts any hazardous concentration and provides bootstrap confidence intervals on the predictions. Finally, the authors illustrate the added value of including censored data in SSD, taking examples from published data. (C) 2014 SETAC",0730-7268,1552-8618,,2133-2139, , ,,out_of_scope,
3915,"Title:Machine Learning for Ionic Liquid Toxicity Prediction

 In addition to proper physicochemical properties, low toxicity is also desirable when seeking suitable ionic liquids (ILs) for specific applications. In this context, machine learning (ML) models were developed to predict the IL toxicity in leukemia rat cell line (IPC-81) based on an extended experimental dataset. Following a systematic procedure including framework construction, hyper-parameter optimization, model training, and evaluation, the feedforward neural network (FNN) and support vector machine (SVM) algorithms were adopted to predict the toxicity of ILs directly from their molecular structures. Based on the ML structures optimized by the five-fold cross validation, two ML models were established and evaluated using IL structural descriptors as inputs. It was observed that both models exhibited high predictive accuracy, with the SVM model observed to be slightly better than the FNN model. For the SVM model, the determination coefficients were 0.9289 and 0.9202 for the training and test sets, respectively. The satisfactory predictive performance and generalization ability make our models useful for the computer-aided molecular design (CAMD) of environmentally friendly ILs.","Wang, Zihao; Song, Zhen; Zhou, Teng","Song, Zhen/ABI-7655-2020; Zhou, Teng/O-2936-2019; Wang, Zihao/AAJ-3541-2020","Song, Zhen/0000-0001-9219-1833; Zhou, Teng/0000-0003-1941-5348; Wang, Zihao/0000-0001-6953-0470",Machine Learning for Ionic Liquid Toxicity Prediction,9,1,10.3390/pr9010065 ,Article ,2021.0,"In addition to proper physicochemical properties, low toxicity is also desirable when seeking suitable ionic liquids (ILs) for specific applications. In this context, machine learning (ML) models were developed to predict the IL toxicity in leukemia rat cell line (IPC-81) based on an extended experimental dataset. Following a systematic procedure including framework construction, hyper-parameter optimization, model training, and evaluation, the feedforward neural network (FNN) and support vector machine (SVM) algorithms were adopted to predict the toxicity of ILs directly from their molecular structures. Based on the ML structures optimized by the five-fold cross validation, two ML models were established and evaluated using IL structural descriptors as inputs. It was observed that both models exhibited high predictive accuracy, with the SVM model observed to be slightly better than the FNN model. For the SVM model, the determination coefficients were 0.9289 and 0.9202 for the training and test sets, respectively. The satisfactory predictive performance and generalization ability make our models useful for the computer-aided molecular design (CAMD) of environmentally friendly ILs.",,2227-9717,,, , ,,out_of_scope,
3916,"Title:Species sensitivity distributions of micro- and nanoplastics in soil based on particle characteristics

 Micro-and nanoplastics are released into the soil through various anthropogenic activities; however, research on ecological risk assessment (ERA) of soil microplastics is limited. In this study, the species sensitivity distributions (SSDs) of representative groups of soil biota were analyzed to determine their sensitivity to microplastic prop-erties. A total of 411 datasets from apical endpoint data within 74 studies were classified and utilized in SSD estimation. The hazardous concentrations for 5% of species for microplastics was 88.18 (40.71-191.00) mg/kg soil. It has been established that small-sized microplastics are more toxic to soil organisms than larger micro -plastics. Most microplastics were spherical and polystyrene, exhibiting the most adverse effects among all the microplastic types assessed herein. The results suggest that physical characteristics of microplastics are important toxicity determinants in soil ecosystems. Given the potential for adverse environmental effects, further effective management strategies should urgently be employed in these areas. This study provided an integrated perspective of microplastic ecotoxicity in soil. In addition, SSDs were estimated using larger datasets and for more species than in previous studies. This is the first study to consider microplastic properties for estimating SSD.","Kim, Dokyung; Kim, Haemi; An, Youn-Joo",,,Species sensitivity distributions of micro- and nanoplastics in soil based on particle characteristics,452,,10.1016/j.jhazmat.2023.131229 ,Article ,2023.0,"Micro-and nanoplastics are released into the soil through various anthropogenic activities; however, research on ecological risk assessment (ERA) of soil microplastics is limited. In this study, the species sensitivity distributions (SSDs) of representative groups of soil biota were analyzed to determine their sensitivity to microplastic prop-erties. A total of 411 datasets from apical endpoint data within 74 studies were classified and utilized in SSD estimation. The hazardous concentrations for 5% of species for microplastics was 88.18 (40.71-191.00) mg/kg soil. It has been established that small-sized microplastics are more toxic to soil organisms than larger micro -plastics. Most microplastics were spherical and polystyrene, exhibiting the most adverse effects among all the microplastic types assessed herein. The results suggest that physical characteristics of microplastics are important toxicity determinants in soil ecosystems. Given the potential for adverse environmental effects, further effective management strategies should urgently be employed in these areas. This study provided an integrated perspective of microplastic ecotoxicity in soil. In addition, SSDs were estimated using larger datasets and for more species than in previous studies. This is the first study to consider microplastic properties for estimating SSD.",0304-3894,1873-3336,,, , ,,out_of_scope,
3917,"Title:Challenges in Automated Debiasing for Toxic Language Detection

 Warning: this paper contains content that may be offensive or upsetting.Biased associations have been a challenge in the development of classifiers for detecting toxic language, hindering both fairness and accuracy. As potential solutions, we investigate recently introduced debiasing methods for text classification datasets and models, as applied to toxic language detection. Our focus is on lexical (e.g., swear words, slurs, identity mentions) and dialectal markers (specifically African American English). Our comprehensive experiments establish that existing methods are limited in their ability to prevent biased behavior in current toxicity detectors. We then propose an automatic, dialect-aware data correction method, as a proof-of-concept study. Despite the use of synthetic labels, this method reduces dialectal associations with toxicity. Overall, our findings show that debiasing a model trained on biased toxic language data is not as effective as simply relabeling the data to remove existing biases.","Zhou, Xuhui; Sap, Maarten; Swayamdipta, Swabha; Smith, Noah A.; Choi, Yejin",,"Sap, Maarten/0000-0002-0701-4654",Challenges in Automated Debiasing for Toxic Language Detection,,, ,Proceedings Paper ,2021.0,"Warning: this paper contains content that may be offensive or upsetting.Biased associations have been a challenge in the development of classifiers for detecting toxic language, hindering both fairness and accuracy. As potential solutions, we investigate recently introduced debiasing methods for text classification datasets and models, as applied to toxic language detection. Our focus is on lexical (e.g., swear words, slurs, identity mentions) and dialectal markers (specifically African American English). Our comprehensive experiments establish that existing methods are limited in their ability to prevent biased behavior in current toxicity detectors. We then propose an automatic, dialect-aware data correction method, as a proof-of-concept study. Despite the use of synthetic labels, this method reduces dialectal associations with toxicity. Overall, our findings show that debiasing a model trained on biased toxic language data is not as effective as simply relabeling the data to remove existing biases.",,,978-1-954085-02-2,3143-3155, , 16th Conference of the European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)16th Conference of the European-Chapter-of-the-Association-for-Computational-Linguistics (EACL),,detection#evaluation#methodology,
3918,"Title:Improved Design of Bayesian Networks for Modelling Toxicity Risk in Breast Radiotherapy using Dynamic Discretization

 This study investigates the dynamic discretization approach with the purpose of improving probabilistic causal models for the task of toxicity risk assessment in breast radiotherapy. We considered a probabilistic causal model such as Bayesian Networks, and implemented a modified version of Fenton & Neil's dynamic discretization algorithm to validate and analyze these models in terms of performance. Our implementation performs discretization at the data- or distribution-level. This approach is shown to provide significant improvement over static methods when assessing distribution fit via relative entropy error, as well as being very computationally efficient. Predictive performance was compared across four distinct datasets using Bayesian Networks, and dynamic discretization was not found to consistently outperform static techniques despite generating discretizations with significantly better fit to their underlying distributions.","Ciunkiewicz, Philip; Yanushkevich, Svetlana; Roumeliotis, Michael; Stenhouse, Kailyn; McGeachy, Philip; Quirk, Sarah; Grendarova, Petra","Yanushkevich, Svetlana/AAS-1052-2021; Stenhouse, Kailyn/JSL-4610-2023","Yanushkevich, Svetlana/0000-0003-4794-9849; Stenhouse, Kailyn/0000-0001-5286-0211",Improved Design of Bayesian Networks for Modelling Toxicity Risk in Breast Radiotherapy using Dynamic Discretization,,,10.1109/IJCNN55064.2022.9892531 ,Proceedings Paper ,2022.0,"This study investigates the dynamic discretization approach with the purpose of improving probabilistic causal models for the task of toxicity risk assessment in breast radiotherapy. We considered a probabilistic causal model such as Bayesian Networks, and implemented a modified version of Fenton & Neil's dynamic discretization algorithm to validate and analyze these models in terms of performance. Our implementation performs discretization at the data- or distribution-level. This approach is shown to provide significant improvement over static methods when assessing distribution fit via relative entropy error, as well as being very computationally efficient. Predictive performance was compared across four distinct datasets using Bayesian Networks, and dynamic discretization was not found to consistently outperform static techniques despite generating discretizations with significantly better fit to their underlying distributions.",2161-4393,,978-1-7281-8671-9,, , IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World Congress on Computational Intelligence (IEEE WCCI) / International Joint Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary Computation (IEEE CEC)IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World Congress on Computational Intelligence (IEEE WCCI) / International Joint Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary Computation (IEEE CEC),,out_of_scope,
3919,"Title:Probing the toxicity of nanoparticles: a unified in silico machine learning model based on perturbation theory

 Nanoparticles (NPs) are part of our daily life, having a wide range of applications in engineering, physics, chemistry, and biomedicine. However, there are serious concerns regarding the harmful effects that NPs can cause to the different biological systems and their ecosystems. Toxicity testing is an essential step for assessing the potential risks of the NPs, but the experimental assays are often very expensive and usually too slow to flag the number of NPs that may cause adverse effects. In silico models centered on quantitative structure-activity/toxicity relationships (QSAR/QSTR) are alternative tools that have become valuable supports to risk assessment, rationalizing the search for safer NPs. In this work, we develop a unified QSTR-perturbation model based on artificial neural networks, aimed at simultaneously predicting general toxicity profiles of NPs under diverse experimental conditions. The model is derived from 54,371NP-NP pair cases generated by applying the perturbation theory to a set of 260 unique NPs, and showed an accuracy higher than 97% in both training and validation sets. Physicochemical interpretation of the different descriptors in the model are additionally provided. The QSTR-perturbation model is then employed to predict the toxic effects of several NPs not included in the original dataset. The theoretical results obtained for this independent set are strongly consistent with the experimental evidence found in the literature, suggesting that the present QSTR-perturbation model can be viewed as a promising and reliable computational tool for probing the toxicity of NPs.","Concu, Riccardo; Kleandrova, Valeria V.; Speck-Planche, Alejandro; Cordeiro, M. Natalia D. S.","Cordeiro, Natália/ISV-0249-2023; Concu, Riccardo/D-5138-2013; Speck-Planche, Alejandro/D-6805-2014; Kleandrova, Valeria V./P-8378-2019; Cordeiro, Maria Natália D. S./A-7413-2012","Cordeiro, Natália/0000-0003-3375-8670; Concu, Riccardo/0000-0002-0301-9407; Speck-Planche, Alejandro/0000-0002-9544-9016; Kleandrova, Valeria V./0000-0002-1928-853X; Cordeiro, Maria Natália D. S./0000-0003-3375-8670",Probing the toxicity of nanoparticles: a unified in silico machine learning model based on perturbation theory,11,7,10.1080/17435390.2017.1379567 ,Article ,2017.0,"Nanoparticles (NPs) are part of our daily life, having a wide range of applications in engineering, physics, chemistry, and biomedicine. However, there are serious concerns regarding the harmful effects that NPs can cause to the different biological systems and their ecosystems. Toxicity testing is an essential step for assessing the potential risks of the NPs, but the experimental assays are often very expensive and usually too slow to flag the number of NPs that may cause adverse effects. In silico models centered on quantitative structure-activity/toxicity relationships (QSAR/QSTR) are alternative tools that have become valuable supports to risk assessment, rationalizing the search for safer NPs. In this work, we develop a unified QSTR-perturbation model based on artificial neural networks, aimed at simultaneously predicting general toxicity profiles of NPs under diverse experimental conditions. The model is derived from 54,371NP-NP pair cases generated by applying the perturbation theory to a set of 260 unique NPs, and showed an accuracy higher than 97% in both training and validation sets. Physicochemical interpretation of the different descriptors in the model are additionally provided. The QSTR-perturbation model is then employed to predict the toxic effects of several NPs not included in the original dataset. The theoretical results obtained for this independent set are strongly consistent with the experimental evidence found in the literature, suggesting that the present QSTR-perturbation model can be viewed as a promising and reliable computational tool for probing the toxicity of NPs.",1743-5390,1743-5404,,891-906, , ,,out_of_scope,
3920,"Title:Hit'em Where it Hurts: A Live Security Exercise on Cyber Situational Awareness

 Live security exercises are a powerful educational tool to motivate students to excel and foster research and development of novel security solutions. Our insight is to design a live security exercise to provide interesting datasets in a specific area of security research. In this paper we validated this insight, and we present the design of a novel kind of live security competition centered on the concept of Cyber Situational Awareness. The competition was carried out in December 2010, and involved 72 teams (900 students) spread across 16 countries, making it the largest educational live security exercise ever performed. We present both the innovative design of this competition and the novel dataset we collected. In addition, we define Cyber Situational Awareness metrics to characterize the toxicity and effectiveness of the attacks performed by the participants with respect to the missions carried out by the targets of the attack.","Doupe, Adam; Egele, Manuel; Caillat, Benjamin; Stringhini, Gianluca; Yakin, Gorkem; Zand, Ali; Cavedon, Ludovico; Vigna, Giovanni",,"Doupe, Adam/0000-0003-2634-3901",Hit'em Where it Hurts: A Live Security Exercise on Cyber Situational Awareness,,, ,Proceedings Paper ,2011.0,"Live security exercises are a powerful educational tool to motivate students to excel and foster research and development of novel security solutions. Our insight is to design a live security exercise to provide interesting datasets in a specific area of security research. In this paper we validated this insight, and we present the design of a novel kind of live security competition centered on the concept of Cyber Situational Awareness. The competition was carried out in December 2010, and involved 72 teams (900 students) spread across 16 countries, making it the largest educational live security exercise ever performed. We present both the innovative design of this competition and the novel dataset we collected. In addition, we define Cyber Situational Awareness metrics to characterize the toxicity and effectiveness of the attacks performed by the participants with respect to the missions carried out by the targets of the attack.",,,978-1-4503-0672-0,51-61, , 27th Annual Computer Security Applications Conference (ACSAC))27th Annual Computer Security Applications Conference (ACSAC)),,out_of_scope,
3921,"Title:Methods for Detoxification of Texts for the Russian Language

 We introduce the first study of the automatic detoxification of Russian texts to combat offensive language. This kind of textual style transfer can be used for processing toxic content on social media or for eliminating toxicity in automatically generated texts. While much work has been done for the English language in this field, there are no works on detoxification for the Russian language. We suggest two types of models-an approach based on BERT architecture that performs local corrections and a supervised approach based on a pretrained GPT-2 language model. We compare these methods with several baselines. In addition, we provide the training datasets and describe the evaluation setup and metrics for automatic and manual evaluation. The results show that the tested approaches can be successfully used for detoxification, although there is room for improvement.","Dementieva, Daryna; Moskovskiy, Daniil; Logacheva, Varvara; Dale, David; Kozlova, Olga; Semenov, Nikita; Panchenko, Alexander","Panchenko, Alexander/T-7560-2017","Panchenko, Alexander/0000-0001-6097-6118; Dementieva, Daryna/0000-0003-0929-4140",Methods for Detoxification of Texts for the Russian Language,5,9,10.3390/mti5090054 ,Article ,2021.0,"We introduce the first study of the automatic detoxification of Russian texts to combat offensive language. This kind of textual style transfer can be used for processing toxic content on social media or for eliminating toxicity in automatically generated texts. While much work has been done for the English language in this field, there are no works on detoxification for the Russian language. We suggest two types of models-an approach based on BERT architecture that performs local corrections and a supervised approach based on a pretrained GPT-2 language model. We compare these methods with several baselines. In addition, we provide the training datasets and describe the evaluation setup and metrics for automatic and manual evaluation. The results show that the tested approaches can be successfully used for detoxification, although there is room for improvement.",,2414-4088,,, , ,,Gen_dataset#detection#out_but_toxicity,
3922,"Title:Mitigating Toxic Degeneration with Empathetic Data: Exploring the Relationship Between Toxicity and Empathy

 Content Warning: This paper includes examples of religious-based discriminatory language that may be offensive and upsetting.Large pre-trained neural language models have supported the effectiveness of many NLP tasks, yet are still prone to generating toxic language hindering the safety of their use. Using empathetic data, we improve over recent work on controllable text generation that aims to reduce the toxicity of generated text. We find we are able to dramatically reduce the size of finetuning data to 7.5-30k samples while at the same time making significant improvements over state-of-the-art toxicity mitigation of up to 3.4% absolute reduction (26% relative) from the original work on 2.3m samples, by strategically sampling data based on empathy scores. We observe that the degree of improvement is subject to specific communication components of empathy. In particular, the cognitive components of empathy significantly beat the original dataset in almost all experiments, while emotional empathy was tied to less improvement and even underperforming random samples of the original data. This is a particularly implicative insight for NLP work concerning empathy as until recently the research and resources built for it have exclusively considered empathy as an emotional concept.","Lahnala, Allison; Welch, Charles; Neuendorf, Bela; Flek, Lucie","Welch, Charles/HOF-8635-2023","Welch, Charles/0000-0002-3489-2882",Mitigating Toxic Degeneration with Empathetic Data: Exploring the Relationship Between Toxicity and Empathy,,, ,Proceedings Paper ,2022.0,"Content Warning: This paper includes examples of religious-based discriminatory language that may be offensive and upsetting.Large pre-trained neural language models have supported the effectiveness of many NLP tasks, yet are still prone to generating toxic language hindering the safety of their use. Using empathetic data, we improve over recent work on controllable text generation that aims to reduce the toxicity of generated text. We find we are able to dramatically reduce the size of finetuning data to 7.5-30k samples while at the same time making significant improvements over state-of-the-art toxicity mitigation of up to 3.4% absolute reduction (26% relative) from the original work on 2.3m samples, by strategically sampling data based on empathy scores. We observe that the degree of improvement is subject to specific communication components of empathy. In particular, the cognitive components of empathy significantly beat the original dataset in almost all experiments, while emotional empathy was tied to less improvement and even underperforming random samples of the original data. This is a particularly implicative insight for NLP work concerning empathy as until recently the research and resources built for it have exclusively considered empathy as an emotional concept.",,,978-1-955917-71-1,4926-4938, , Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language TechnologiesConference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies,,detox#evaluation#methodology,
3923,"Title:Comparison of machine learning algorithms and oversampling techniques for urinary toxicity prediction after prostate cancer radiotherapy

 Prostate cancer radiotherapy unavoidably involves the irradiation not only of the target volume, but also of healthy organs-at-risk, neighboring the prostate, likely causing adverse, toxicity-related side-effects. Specifically, in the case of urinary toxicity, these side effects might be associated with a variety of dosimetric, clinical and genetic factors, making its prediction particularly challenging. Given the inconsistency of available data concerning radiation-induced toxicity, it is crucial to develop robust models with superior predictive performance in order to perform tailored treatments. Machine Learning techniques emerge as appealing in this context, nevertheless without any consensus on the best algorithms to be used. This work proposes a comparison of several machine-learning strategies together with different minority class oversampling techniques for prediction of urinary toxicity following prostate cancer radiotherapy using dosimetric and clinical data. The performance of these classifiers was evaluated on the original dataset and using four different synthetic oversampling techniques. The area under the ROC curve (AUC) and the F-measure were employed to evaluate their performance. Results suggest that, regardless of the technique, oversampling always increases the prediction performance of the models (p=0.004). Overall, oversampling with Synthetic Minority Oversampling Technique (SMOTE) followed by Edited Nearest Neighbour algorithm (ENN) together with Regularized Discriminant Analysis (RDA) classifier provide the best performance (AUC=0.71).","Mylona, Eugenia; Lebreton, Clement; Fontaine, Pierre; Supiot, Stephane; Magne, Nicolas; Crehange, Gilles; de Crevoisier, Renaud; Acosta, Oscar","de Crevoisier, Renaud/ABD-7321-2020; Supiot, Stéphane/M-1586-2015; Acosta, Oscar/A-5935-2012; Mylona, Eugenia/AAP-8913-2020","Supiot, Stéphane/0000-0003-2094-1708; Mylona, Eugenia/0000-0002-1275-6249; Acosta, Oscar/0000-0002-5447-1479",Comparison of machine learning algorithms and oversampling techniques for urinary toxicity prediction after prostate cancer radiotherapy,,,10.1109/BIBE.2019.00180 ,Proceedings Paper ,2019.0,"Prostate cancer radiotherapy unavoidably involves the irradiation not only of the target volume, but also of healthy organs-at-risk, neighboring the prostate, likely causing adverse, toxicity-related side-effects. Specifically, in the case of urinary toxicity, these side effects might be associated with a variety of dosimetric, clinical and genetic factors, making its prediction particularly challenging. Given the inconsistency of available data concerning radiation-induced toxicity, it is crucial to develop robust models with superior predictive performance in order to perform tailored treatments. Machine Learning techniques emerge as appealing in this context, nevertheless without any consensus on the best algorithms to be used. This work proposes a comparison of several machine-learning strategies together with different minority class oversampling techniques for prediction of urinary toxicity following prostate cancer radiotherapy using dosimetric and clinical data. The performance of these classifiers was evaluated on the original dataset and using four different synthetic oversampling techniques. The area under the ROC curve (AUC) and the F-measure were employed to evaluate their performance. Results suggest that, regardless of the technique, oversampling always increases the prediction performance of the models (p=0.004). Overall, oversampling with Synthetic Minority Oversampling Technique (SMOTE) followed by Edited Nearest Neighbour algorithm (ENN) together with Regularized Discriminant Analysis (RDA) classifier provide the best performance (AUC=0.71).",2471-7819,,978-1-7281-4617-1,964-971, , 19th Annual IEEE International Conference on Bioinformatics and Bioengineering (BIBE)19th Annual IEEE International Conference on Bioinformatics and Bioengineering (BIBE),,out_of_scope,
3924,"Title:Effect of Dataset Size and Train/Test Split Ratios in QSAR/QSPR Multiclass Classification

 Applied datasets can vary from a few hundred to thousands of samples in typical quantitative structure-activity/property (QSAR/QSPR) relationships and classification. However, the size of the datasets and the train/test split ratios can greatly affect the outcome of the models, and thus the classification performance itself. We compared several combinations of dataset sizes and split ratios with five different machine learning algorithms to find the differences or similarities and to select the best parameter settings in nonbinary (multiclass) classification. It is also known that the models are ranked differently according to the performance merit(s) used. Here, 25 performance parameters were calculated for each model, then factorial ANOVA was applied to compare the results. The results clearly show the differences not just between the applied machine learning algorithms but also between the dataset sizes and to a lesser extent the train/test split ratios. The XGBoost algorithm could outperform the others, even in multiclass modeling. The performance parameters reacted differently to the change of the sample set size; some of them were much more sensitive to this factor than the others. Moreover, significant differences could be detected between train/test split ratios as well, exerting a great effect on the test validation of our models.","Racz, Anita; Bajusz, David; Heberger, Karoly","Heberger, Karoly/A-4195-2011; Bajusz, Dávid/G-4199-2015; Racz, Anita/V-4262-2017","Heberger, Karoly/0000-0003-0965-939X; Bajusz, Dávid/0000-0003-4277-9481; Racz, Anita/0000-0001-8271-9841",Effect of Dataset Size and Train/Test Split Ratios in QSAR/QSPR Multiclass Classification,26,4,10.3390/molecules26041111 ,Article ,2021.0,"Applied datasets can vary from a few hundred to thousands of samples in typical quantitative structure-activity/property (QSAR/QSPR) relationships and classification. However, the size of the datasets and the train/test split ratios can greatly affect the outcome of the models, and thus the classification performance itself. We compared several combinations of dataset sizes and split ratios with five different machine learning algorithms to find the differences or similarities and to select the best parameter settings in nonbinary (multiclass) classification. It is also known that the models are ranked differently according to the performance merit(s) used. Here, 25 performance parameters were calculated for each model, then factorial ANOVA was applied to compare the results. The results clearly show the differences not just between the applied machine learning algorithms but also between the dataset sizes and to a lesser extent the train/test split ratios. The XGBoost algorithm could outperform the others, even in multiclass modeling. The performance parameters reacted differently to the change of the sample set size; some of them were much more sensitive to this factor than the others. Moreover, significant differences could be detected between train/test split ratios as well, exerting a great effect on the test validation of our models.",,1420-3049,,, , ,,out_of_scope,
3925,"Title:BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation

 Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices.","Dhamala, Jwala; Sun, Tony; Kumar, Varun; Krishna, Satyapriya; Pruksachatkun, Yada; Chang, Kai-Wei; Gupta, Rahul",,,BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation,,,10.1145/3442188.3445924 ,Proceedings Paper ,2021.0,"Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices.",,,978-1-4503-8309-7,862-872, ," ACM Conference on Fairness, Accountability, and Transparency (FAccT)ACM Conference on Fairness, Accountability, and Transparency (FAccT)",,Gen_dataset#evaluation#methodology,
3926,"Title:Toxic Fake News Detection and Classification for Combating COVID-19 Misinformation

 The emergence of COVID-19 has led to a surge in fake news on social media, with toxic fake news having adverse effects on individuals, society, and governments. Detecting toxic fake news is crucial, but little prior research has been done in this area. This study aims to address this gap and identify toxic fake news to save time spent on examining nontoxic fake news. To achieve this, multiple datasets were collected from different online social networking platforms such as Facebook and Twitter. The latest samples were obtained by collecting data based on the topmost keywords extracted from the existing datasets. The instances were then labeled as toxic/nontoxic using toxicity analysis, and traditional machine-learning (ML) techniques such as linear support vector machine (SVM), conventional random forest (RF), and transformer-based ML techniques such as bidirectional encoder representations from transformers (BERT) were employed to design a toxic-fake news detection (FND) and classification system. As per the experiments, the linear SVM method outperformed BERT SVM, RF, and BERT RF with an accuracy of 92% and -score, -score, and -score of 95%, 85%, and 87%, respectively. Upon comparison, the proposed approach has either suppressed or achieved results very close to the state-of-the-art techniques in the literature by recording the best values on performance metrics such as accuracy, F1-score, precision, and recall for linear SVM. Overall, the proposed methods have shown promising results and urge further research to restrain toxic fake news. In contrast to prior research, the presented methodology leverages toxicity-oriented attributes and BERT-based sequence representations to discern toxic counterfeit news articles from nontoxic ones across social media platforms.","Wani, Mudasir Ahmad; ELAffendi, Mohammad; Shakil, Kashish Ara; Abuhaimed, Ibrahem Mohammed; Nayyar, Anand; Hussain, Amir; Abd El-Latif, Ahmed A.","Shakil, Kashish/ABK-8677-2022; Nayyar, Anand/F-3732-2015","Shakil, Kashish/0000-0003-2323-5104; Nayyar, Anand/0000-0002-9821-6146",Toxic Fake News Detection and Classification for Combating COVID-19 Misinformation,,,10.1109/TCSS.2023.3276764 ,Article; Early Access ,,"The emergence of COVID-19 has led to a surge in fake news on social media, with toxic fake news having adverse effects on individuals, society, and governments. Detecting toxic fake news is crucial, but little prior research has been done in this area. This study aims to address this gap and identify toxic fake news to save time spent on examining nontoxic fake news. To achieve this, multiple datasets were collected from different online social networking platforms such as Facebook and Twitter. The latest samples were obtained by collecting data based on the topmost keywords extracted from the existing datasets. The instances were then labeled as toxic/nontoxic using toxicity analysis, and traditional machine-learning (ML) techniques such as linear support vector machine (SVM), conventional random forest (RF), and transformer-based ML techniques such as bidirectional encoder representations from transformers (BERT) were employed to design a toxic-fake news detection (FND) and classification system. As per the experiments, the linear SVM method outperformed BERT SVM, RF, and BERT RF with an accuracy of 92% and -score, -score, and -score of 95%, 85%, and 87%, respectively. Upon comparison, the proposed approach has either suppressed or achieved results very close to the state-of-the-art techniques in the literature by recording the best values on performance metrics such as accuracy, F1-score, precision, and recall for linear SVM. Overall, the proposed methods have shown promising results and urge further research to restrain toxic fake news. In contrast to prior research, the presented methodology leverages toxicity-oriented attributes and BERT-based sequence representations to discern toxic counterfeit news articles from nontoxic ones across social media platforms.",2329-924X,,,, , ,,Gen_dataset#detection#methodology,
3927,"Title:Marker-controlled watershed with deep edge emphasis and optimized H-minima transform for automatic segmentation of densely cultivated 3D cell nuclei

 Background The segmentation of 3D cell nuclei is essential in many tasks, such as targeted molecular radiotherapies (MRT) for metastatic tumours, toxicity screening, and the observation of proliferating cells. In recent years, one popular method for automatic segmentation of nuclei has been deep learning enhanced marker-controlled watershed transform. In this method, convolutional neural networks (CNNs) have been used to create nuclei masks and markers, and the watershed algorithm for the instance segmentation. We studied whether this method could be improved for the segmentation of densely cultivated 3D nuclei via developing multiple system configurations in which we studied the effect of edge emphasizing CNNs, and optimized H-minima transform for mask and marker generation, respectively. Results The dataset used for training and evaluation consisted of twelve in vitro cultivated densely packed 3D human carcinoma cell spheroids imaged using a confocal microscope. With this dataset, the evaluation was performed using a cross-validation scheme. In addition, four independent datasets were used for evaluation. The datasets were resampled near isotropic for our experiments. The baseline deep learning enhanced marker-controlled watershed obtained an average of 0.69 Panoptic Quality (PQ) and 0.66 Aggregated Jaccard Index (AJI) over the twelve spheroids. Using a system configuration, which was otherwise the same but used 3D-based edge emphasizing CNNs and optimized H-minima transform, the scores increased to 0.76 and 0.77, respectively. When using the independent datasets for evaluation, the best performing system configuration was shown to outperform or equal the baseline and a set of well-known cell segmentation approaches. Conclusions The use of edge emphasizing U-Nets and optimized H-minima transform can improve the marker-controlled watershed transform for segmentation of densely cultivated 3D cell nuclei. A novel dataset of twelve spheroids was introduced to the public.","Kaseva, Tuomas; Omidali, Bahareh; Hippelainen, Eero; Makela, Teemu; Wilppu, Ulla; Sofiev, Alexey; Merivaara, Arto; Yliperttula, Marjo; Savolainen, Sauli; Salli, Eero","Salli, Eero/HKN-6485-2023","Salli, Eero/0000-0002-8797-6094; Merivaara, Arto/0000-0002-3917-3107; , Sauli/0000-0001-8085-322X",Marker-controlled watershed with deep edge emphasis and optimized H-minima transform for automatic segmentation of densely cultivated 3D cell nuclei,23,1,10.1186/s12859-022-04827-3 ,Article ,2022.0,"Background The segmentation of 3D cell nuclei is essential in many tasks, such as targeted molecular radiotherapies (MRT) for metastatic tumours, toxicity screening, and the observation of proliferating cells. In recent years, one popular method for automatic segmentation of nuclei has been deep learning enhanced marker-controlled watershed transform. In this method, convolutional neural networks (CNNs) have been used to create nuclei masks and markers, and the watershed algorithm for the instance segmentation. We studied whether this method could be improved for the segmentation of densely cultivated 3D nuclei via developing multiple system configurations in which we studied the effect of edge emphasizing CNNs, and optimized H-minima transform for mask and marker generation, respectively. Results The dataset used for training and evaluation consisted of twelve in vitro cultivated densely packed 3D human carcinoma cell spheroids imaged using a confocal microscope. With this dataset, the evaluation was performed using a cross-validation scheme. In addition, four independent datasets were used for evaluation. The datasets were resampled near isotropic for our experiments. The baseline deep learning enhanced marker-controlled watershed obtained an average of 0.69 Panoptic Quality (PQ) and 0.66 Aggregated Jaccard Index (AJI) over the twelve spheroids. Using a system configuration, which was otherwise the same but used 3D-based edge emphasizing CNNs and optimized H-minima transform, the scores increased to 0.76 and 0.77, respectively. When using the independent datasets for evaluation, the best performing system configuration was shown to outperform or equal the baseline and a set of well-known cell segmentation approaches. Conclusions The use of edge emphasizing U-Nets and optimized H-minima transform can improve the marker-controlled watershed transform for segmentation of densely cultivated 3D cell nuclei. A novel dataset of twelve spheroids was introduced to the public.",1471-2105,,,, , ,,out_of_scope,
3928,"Title:Detecting Toxicity with Bidirectional Gated Recurrent Unit Networks

 As large amounts of data keep being generated by users on social media platforms, some of the information can be considered as harmful. These kinds of textual information can be generated in forums, online discussions or any other communication exchange in an online medium. As such, it is sometimes difficult to filter out what information is actually meaningful. Detecting these harmful pieces of information can help in providing a means of online moderation so that a safe discussion can be maintained, which helps in preventing issues such as cyber bullying. Using the Kaggle Jigsaw dataset of comments that are classified as toxic labels, we can implement deep learning models to implicitly extract textual features from the comments and solve this supervised learning problem. This paper focuses on using the variations of recurrent neural networks, with the main focus on using bidirectional gated recurrent units, and evaluating their performances against each other.","Kumar, Vinayak; Tripathy, B. K.","Tripathy, B. K./O-1604-2018","Tripathy, B. K./0000-0003-3455-4549",Detecting Toxicity with Bidirectional Gated Recurrent Unit Networks,1034,,10.1007/978-981-15-1084-7_57 ,Proceedings Paper ,2020.0,"As large amounts of data keep being generated by users on social media platforms, some of the information can be considered as harmful. These kinds of textual information can be generated in forums, online discussions or any other communication exchange in an online medium. As such, it is sometimes difficult to filter out what information is actually meaningful. Detecting these harmful pieces of information can help in providing a means of online moderation so that a safe discussion can be maintained, which helps in preventing issues such as cyber bullying. Using the Kaggle Jigsaw dataset of comments that are classified as toxic labels, we can implement deep learning models to implicitly extract textual features from the comments and solve this supervised learning problem. This paper focuses on using the variations of recurrent neural networks, with the main focus on using bidirectional gated recurrent units, and evaluating their performances against each other.",2194-5357,2194-5365,978-981-15-1084-7; 978-981-15-1083-0,591-600, , 3rd International Conference on Intelligent Computing and Communication (ICICC)3rd International Conference on Intelligent Computing and Communication (ICICC),,Use_dataset#detection,
3929,"Title:Subgroup Discovery Analysis of Treatment Patterns in Lung Cancer Patients

 Lung cancer is the leading cause of cancer death. More than 236,740 new cases of lung cancer patients are expected in 2022, with an estimation of more than 130,180 deaths. Improving the survival rates or the patient's quality of life is partially covered by a common element: treatments. Cancer treatments are well known for the toxic outcomes and secondary effects on the patients. These toxicities cause different health problems that impact the patient's quality of life. Reducing toxicities without a decline on the positive survival effect is an important goal that aims to be pursued from the clinical perspective.On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with treatment patterns found in clinical data, would allow to validate the patterns found, as well as discovering alternative treatment patterns.In this work, we have analyzed a dataset containing lung cancer patients information including patients' data, prescribed treatments and outcomes obtained. Using a Subgroup Discovery method we identify patterns based on cancer stage while relying on treatment outcomes. Results are compared with clinical guidelines and analyzed based on statistical and medical relevance using Subgroup Discovery metrics.","Gomez-Bravo, Daniel; Garcia, Aaron; Vigueras, Guillermo; Rios-Sanchez, Belen; Otero, Belen; Hernandez, Roberto; Torrente, Maria; Menasalvas, Ernestina; Provencio, Mariano; Rodriguez Gonzalez, Alejandro","Provencio, Mariano/ABE-8586-2020; Vigueras, Guillermo/I-1772-2015","Provencio, Mariano/0000-0001-9053-9197; Vigueras, Guillermo/0000-0003-0162-5267",Subgroup Discovery Analysis of Treatment Patterns in Lung Cancer Patients,,,10.1109/CBMS55023.2022.00082 ,Proceedings Paper ,2022.0,"Lung cancer is the leading cause of cancer death. More than 236,740 new cases of lung cancer patients are expected in 2022, with an estimation of more than 130,180 deaths. Improving the survival rates or the patient's quality of life is partially covered by a common element: treatments. Cancer treatments are well known for the toxic outcomes and secondary effects on the patients. These toxicities cause different health problems that impact the patient's quality of life. Reducing toxicities without a decline on the positive survival effect is an important goal that aims to be pursued from the clinical perspective.On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with treatment patterns found in clinical data, would allow to validate the patterns found, as well as discovering alternative treatment patterns.In this work, we have analyzed a dataset containing lung cancer patients information including patients' data, prescribed treatments and outcomes obtained. Using a Subgroup Discovery method we identify patterns based on cancer stage while relying on treatment outcomes. Results are compared with clinical guidelines and analyzed based on statistical and medical relevance using Subgroup Discovery metrics.",2372-9198,,978-1-6654-6770-4,422-428, , 35th IEEE International Symposium on Computer-Based Medical Systems (CBMS)35th IEEE International Symposium on Computer-Based Medical Systems (CBMS),,out_of_scope,
3930,"Title:Bladder Runner: Visual Analytics for the Exploration of RT-Induced Bladder Toxicity in a Cohort Study

 We present the Bladder Runner, a novel tool to enable detailed visual exploration and analysis of the impact of bladder shape variation on the accuracy of dose delivery, during the course of prostate cancer radiotherapy (RT). Our tool enables the investigation of individual patients and cohorts through the entire treatment process, and it can give indications of RT-induced complications for the patient. In prostate cancer RT treatment, despite the design of an initial plan prior to dose administration, bladder toxicity remains very common. The main reason is that the dose is delivered in multiple fractions over a period of weeks, during which, the anatomical variation of the bladder - due to differences in urinary filling - causes deviations between planned and delivered doses. Clinical researchers want to correlate bladder shape variations to dose deviations and toxicity risk through cohort studies, to understand which specific bladder shape characteristics are more prone to side effects. This is currently done with Dose-Volume Histograms (DVHs), which provide limited, qualitative insight. The effect of bladder variation on dose delivery and the resulting toxicity cannot be currently examined with the DVHs. To address this need, we designed and implemented the Bladder Runner, which incorporates visualization strategies in a highly interactive environment with multiple linked views. Individual patients can be explored and analyzed through the entire treatment period, while inter-patient and temporal exploration, analysis and comparison are also supported. We demonstrate the applicability of our presented tool with a usage scenario, employing a dataset of 29 patients followed through the course of the treatment, across 13 time points. We conducted an evaluation with three clinical researchers working on the investigation of RT-induced bladder toxicity. All participants agreed that Bladder Runner provides better understanding and new opportunities for the exploration and analysis of the involved cohort data.","Raidou, R. G.; Casares-Magaz, O.; Amirkhanov, A.; Moiseenko, V.; Muren, L. P.; Einck, J. P.; Vilanova, A.; Groeller, M. E.","Gröller, Eduard/AAH-2111-2020","Gröller, Eduard/0000-0002-8569-4149; Muren, Ludvig/0000-0002-7418-5832; Amirkhanov, Aleksandr/0000-0003-4552-8469; Raidou, Renata Georgia/0000-0003-2468-0664",Bladder Runner: Visual Analytics for the Exploration of RT-Induced Bladder Toxicity in a Cohort Study,37,3,10.1111/cgf.13413 ,Article; Proceedings Paper ,2018.0,"We present the Bladder Runner, a novel tool to enable detailed visual exploration and analysis of the impact of bladder shape variation on the accuracy of dose delivery, during the course of prostate cancer radiotherapy (RT). Our tool enables the investigation of individual patients and cohorts through the entire treatment process, and it can give indications of RT-induced complications for the patient. In prostate cancer RT treatment, despite the design of an initial plan prior to dose administration, bladder toxicity remains very common. The main reason is that the dose is delivered in multiple fractions over a period of weeks, during which, the anatomical variation of the bladder - due to differences in urinary filling - causes deviations between planned and delivered doses. Clinical researchers want to correlate bladder shape variations to dose deviations and toxicity risk through cohort studies, to understand which specific bladder shape characteristics are more prone to side effects. This is currently done with Dose-Volume Histograms (DVHs), which provide limited, qualitative insight. The effect of bladder variation on dose delivery and the resulting toxicity cannot be currently examined with the DVHs. To address this need, we designed and implemented the Bladder Runner, which incorporates visualization strategies in a highly interactive environment with multiple linked views. Individual patients can be explored and analyzed through the entire treatment period, while inter-patient and temporal exploration, analysis and comparison are also supported. We demonstrate the applicability of our presented tool with a usage scenario, employing a dataset of 29 patients followed through the course of the treatment, across 13 time points. We conducted an evaluation with three clinical researchers working on the investigation of RT-induced bladder toxicity. All participants agreed that Bladder Runner provides better understanding and new opportunities for the exploration and analysis of the involved cohort data.",0167-7055,1467-8659,,205-216, , 20th Eurographics/IEEE VGTC Conference on Visualization (EuroVis)20th Eurographics/IEEE VGTC Conference on Visualization (EuroVis),,out_of_scope,
3931,"Title:On the Design and Tuning of Machine Learning Models for Language Toxicity Classification in Online Platforms

 One of the most concerning drawbacks derived from the lack of supervision in online platforms is their exploitation by misbehaving users to deliver offending (toxic) messages while remaining unknown themselves. Given the huge volumes of data handled by these platforms, the detection of toxicity in exchanged comments and messages has naturally called for the adoption of machine learning models to automate this task. In the last few years Deep Learning models and related techniques have played a major role in this regard due to their superior modeling capabilities, which have made them stand out as the prevailing choice in the related literature. By addressing a toxicity classification problem over a real dataset, this work aims at throwing light on two aspects of this noted dominance of Deep Learning models: (1) an empirical assessment of their predictive gains with respect to traditional Shallow Learning models; and (2) the impact of using different text embedding methods and data augmentation techniques in this classification task. Our findings reveal that in our case study the application of non-optimized Shallow and Deep Learning models attains very competitive accuracy scores, thus leaving a narrow improvement margin for the fine-grained refinement of the models or the addition of data augmentation techniques.","Rybinski, Maciej; Miller, William; Del Ser, Javier; Nekane Bilbao, Miren; Aldana-Montes, Jose F.","Del Ser, Javier/AAA-2965-2021","Del Ser, Javier/0000-0002-1260-9775; BILBAO MARON, MIREN NEKANE/0000-0002-0519-8728",On the Design and Tuning of Machine Learning Models for Language Toxicity Classification in Online Platforms,798,,10.1007/978-3-319-99626-4_29 ,Proceedings Paper ,2018.0,"One of the most concerning drawbacks derived from the lack of supervision in online platforms is their exploitation by misbehaving users to deliver offending (toxic) messages while remaining unknown themselves. Given the huge volumes of data handled by these platforms, the detection of toxicity in exchanged comments and messages has naturally called for the adoption of machine learning models to automate this task. In the last few years Deep Learning models and related techniques have played a major role in this regard due to their superior modeling capabilities, which have made them stand out as the prevailing choice in the related literature. By addressing a toxicity classification problem over a real dataset, this work aims at throwing light on two aspects of this noted dominance of Deep Learning models: (1) an empirical assessment of their predictive gains with respect to traditional Shallow Learning models; and (2) the impact of using different text embedding methods and data augmentation techniques in this classification task. Our findings reveal that in our case study the application of non-optimized Shallow and Deep Learning models attains very competitive accuracy scores, thus leaving a narrow improvement margin for the fine-grained refinement of the models or the addition of data augmentation techniques.",1860-949X,1860-9503,978-3-319-99626-4; 978-3-319-99625-7,329-343, , 12th International Symposium on Intelligent Distributed Computing (IDC)12th International Symposium on Intelligent Distributed Computing (IDC),,detection#evaluation,
3932,"Title:Classifying the toxicity of pesticides to honey bees via support vector machines with random walk graph kernels

 Pesticides benefit agriculture by increasing crop yield, quality, and security. However, pesticides may inadvertently harm bees, which are valuable as pollinators. Thus, candidate pesticides in development pipelines must be assessed for toxicity to bees. Leveraging a dataset of 382 molecules with toxicity labels from honey bee exposure experiments, we train a support vector machine (SVM) to predict the toxicity of pesticides to honey bees. We compare two representations of the pesticide molecules: (i) a random walk feature vector listing counts of length-L walks on the molecular graph with each vertex- and edge-label sequence and (ii) the Molecular ACCess System (MACCS) structural key fingerprint (FP), a bit vector indicating the presence/absence of a list of pre-defined subgraph patterns in the molecular graph. We explicitly construct the MACCS FPs but rely on the fixed-length-L random walk graph kernel (RWGK) in place of the dot product for the random walk representation. The L-RWGK-SVM achieves an accuracy, precision, recall, and F1 score (mean over 2000 runs) of 0.81, 0.68, 0.71, and 0.69, respectively, on the test data set-with L = 4 being the mode optimal walk length. The MACCS-FP-SVM performs on par/marginally better than the L-RWGK-SVM, lends more interpretability, but varies more in performance. We interpret the MACCS-FP-SVM by illuminating which subgraph patterns in the molecules tend to strongly push them toward the toxic/non-toxic side of the separating hyperplane. Published under an exclusive license by AIP Publishing.","Yang, Ping; Henle, E. Adrian; Fern, Xiaoli Z.; Simon, Cory M.",,"Yang, Ping/0000-0003-0105-6172; Simon, Cory/0000-0002-8181-9178",Classifying the toxicity of pesticides to honey bees via support vector machines with random walk graph kernels,157,3,10.1063/5.0090573 ,Article ,2022.0,"Pesticides benefit agriculture by increasing crop yield, quality, and security. However, pesticides may inadvertently harm bees, which are valuable as pollinators. Thus, candidate pesticides in development pipelines must be assessed for toxicity to bees. Leveraging a dataset of 382 molecules with toxicity labels from honey bee exposure experiments, we train a support vector machine (SVM) to predict the toxicity of pesticides to honey bees. We compare two representations of the pesticide molecules: (i) a random walk feature vector listing counts of length-L walks on the molecular graph with each vertex- and edge-label sequence and (ii) the Molecular ACCess System (MACCS) structural key fingerprint (FP), a bit vector indicating the presence/absence of a list of pre-defined subgraph patterns in the molecular graph. We explicitly construct the MACCS FPs but rely on the fixed-length-L random walk graph kernel (RWGK) in place of the dot product for the random walk representation. The L-RWGK-SVM achieves an accuracy, precision, recall, and F1 score (mean over 2000 runs) of 0.81, 0.68, 0.71, and 0.69, respectively, on the test data set-with L = 4 being the mode optimal walk length. The MACCS-FP-SVM performs on par/marginally better than the L-RWGK-SVM, lends more interpretability, but varies more in performance. We interpret the MACCS-FP-SVM by illuminating which subgraph patterns in the molecules tend to strongly push them toward the toxic/non-toxic side of the separating hyperplane. Published under an exclusive license by AIP Publishing.",0021-9606,1089-7690,,, , ,,out_of_scope,
3933,"Title:Weight Poisoning Attacks on Pre-trained Models

 Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then tine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct weight poisoning attacks where pre-trained weights are injected with vulnerabilities that expose backdoors afterfine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method, which we call RIPPLe, and an initialization procedure, which we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, arid wain detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks. Code to reproduce our experiments is available at https://github.corn/neulab/RIPPLe.","Kurita, Keita; Michel, Paul; Neubig, Graham",,,Weight Poisoning Attacks on Pre-trained Models,,, ,Proceedings Paper ,2020.0,"Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then tine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct weight poisoning attacks where pre-trained weights are injected with vulnerabilities that expose backdoors afterfine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method, which we call RIPPLe, and an initialization procedure, which we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, arid wain detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks. Code to reproduce our experiments is available at https://github.corn/neulab/RIPPLe.",,,978-1-952148-25-5,2793-2806, , 58th Annual Meeting of the Association-for-Computational-Linguistics (ACL)58th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,evaluation#methodology,
3934,"Title:The hybrid of semisupervised manifold learning and spectrum kernel for classification

 Manifold learning classification, as an advanced semisupervised learning algorithm in recent years, has gained great popularity in a variety of fields. Moreover, kernel methods are a group of algorithms for pattern analysis, the task of which is to find and study general types of relations in datasets. Thus, under the framework of kernel methods, manifold learning classifier has been introduced and explored to directly detect the intrinsic similarity by local and global information hidden in datasets. Two validation approaches were used to evaluate the performance of our models. Experiments indicate that the proposed model can be considered as an effective and alternative modeling algorithm, and it could be further applied to the areas of biochemical science, environmental analysis, clinical, etc.Manifold learning classification, as an advanced semisupervised learning algorithm, has gained great popularity in various fields. Under the framework of kernel methods, manifold learning classifier has been introduced and explored to directly detect the intrinsic similarity by local and global information hidden in datasets. The results indicate that the proposed model can be considered as an effective and alternative modeling algorithm, and it could be further applied to the areas of biochemical science, environmental analysis, clinical, etc.","Shen, Liang; Xu, Qingsong; Cao, Dongsheng; Liang, Yizeng; Dai, Hongshuai","Dai, Hongshuai/GYE-3253-2022","Cao, Dongsheng/0000-0003-3604-3785",The hybrid of semisupervised manifold learning and spectrum kernel for classification,32,2,10.1002/cem.2955 ,Article ,2018.0,"Manifold learning classification, as an advanced semisupervised learning algorithm in recent years, has gained great popularity in a variety of fields. Moreover, kernel methods are a group of algorithms for pattern analysis, the task of which is to find and study general types of relations in datasets. Thus, under the framework of kernel methods, manifold learning classifier has been introduced and explored to directly detect the intrinsic similarity by local and global information hidden in datasets. Two validation approaches were used to evaluate the performance of our models. Experiments indicate that the proposed model can be considered as an effective and alternative modeling algorithm, and it could be further applied to the areas of biochemical science, environmental analysis, clinical, etc.Manifold learning classification, as an advanced semisupervised learning algorithm, has gained great popularity in various fields. Under the framework of kernel methods, manifold learning classifier has been introduced and explored to directly detect the intrinsic similarity by local and global information hidden in datasets. The results indicate that the proposed model can be considered as an effective and alternative modeling algorithm, and it could be further applied to the areas of biochemical science, environmental analysis, clinical, etc.",0886-9383,1099-128X,,, , ,,out_of_scope,
3935,"Title:Bias Mitigation for Toxicity Detection via Sequential Decisions

 Increased social media use has contributed to the greater prevalence of abusive, rude, and offensive textual comments. Machine learning models have been developed to detect toxic comments online, yet these models tend to show biases against users with marginalized or minority identities (e.g., females and African Americans). Established research in debiasing toxicity classifiers often (1) takes a static or batch approach, assuming that all information is available and then making a one-time decision; and (2) uses a generic strategy to mitigate different biases (e.g., gender and racial biases) that assumes the biases are independent of one another. However, in real scenarios, the input typically arrives as a sequence of comments/words over time instead of all at once. Thus, decisions based on partial information must be made while additional input is arriving. Moreover, social bias is complex by nature. Each type of bias is defined within its unique context, which, consistent with intersectionality theory within the social sciences, might be correlated with the contexts of other forms of bias. In this work, we consider debiasing toxicity detection as a sequential decision-making process where different biases can be interdependent. In particular, we study debiasing toxicity detection with two aims: (1) to examine whether different biases tend to correlate with each other; and (2) to investigate how to jointly mitigate these correlated biases in an interactive manner to minimize the total amount of bias. At the core of our approach is a framework built upon theories of sequential Markov Decision Processes that seeks to maximize the prediction accuracy and minimize the bias measures tailored to individual biases. Evaluations on two benchmark datasets empirically validate the hypothesis that biases tend to be correlated and corroborate the effectiveness of the proposed sequential debiasing strategy.","Cheng, Lu; Mosallanezhad, Ahmadreza; Silva, Yasin N.; Hall, Deborah L.; Liu, Huan","liu, huan/JEO-4705-2023; liu, huan/JKI-3764-2023","Hall, Deborah/0000-0003-2450-3596; Cheng, Lu/0000-0002-2503-2522",Bias Mitigation for Toxicity Detection via Sequential Decisions,,,10.1145/3477495.3531945 ,Proceedings Paper ,2022.0,"Increased social media use has contributed to the greater prevalence of abusive, rude, and offensive textual comments. Machine learning models have been developed to detect toxic comments online, yet these models tend to show biases against users with marginalized or minority identities (e.g., females and African Americans). Established research in debiasing toxicity classifiers often (1) takes a static or batch approach, assuming that all information is available and then making a one-time decision; and (2) uses a generic strategy to mitigate different biases (e.g., gender and racial biases) that assumes the biases are independent of one another. However, in real scenarios, the input typically arrives as a sequence of comments/words over time instead of all at once. Thus, decisions based on partial information must be made while additional input is arriving. Moreover, social bias is complex by nature. Each type of bias is defined within its unique context, which, consistent with intersectionality theory within the social sciences, might be correlated with the contexts of other forms of bias. In this work, we consider debiasing toxicity detection as a sequential decision-making process where different biases can be interdependent. In particular, we study debiasing toxicity detection with two aims: (1) to examine whether different biases tend to correlate with each other; and (2) to investigate how to jointly mitigate these correlated biases in an interactive manner to minimize the total amount of bias. At the core of our approach is a framework built upon theories of sequential Markov Decision Processes that seeks to maximize the prediction accuracy and minimize the bias measures tailored to individual biases. Evaluations on two benchmark datasets empirically validate the hypothesis that biases tend to be correlated and corroborate the effectiveness of the proposed sequential debiasing strategy.",,,978-1-4503-8732-3,1750-1760, , 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),,detection#evaluation#methodology,
3936,"Title:Derivation and representation of dose-volume response from large clinical trial data sets: an example from the RADAR prostate radiotherapy trial

 Large multicentre radiotherapy trials incorporating assessment of multiple outcomes at multiple timepoints can generate extensive datasets. We have investigated graphical techniques for presentation of this data and the associated underlying dose-volume response information, necessary for guiding statistical analyses and translating outcomes to future patient treatments. A relational database was used to archive reviewed plan data for patients accrued to the TROG 03.04 RADAR trial. Viewing software was used to clean and enhance the data. Scripts were developed to export arbitrary dose-histogram data which was combined with clinical toxicity data with a median follow-up of 72 months. Graphical representations of dose-volume response developed include prevalence atlasing, univariate logistic regression and dose-volume-point odds ratios, and continuous cut-point derivation via ROC analysis. These representations indicate variable association of toxicities across structures and time-points.","Ebert, M. A.; Foo, K.; Haworth, A.; Gulliford, S. L.; Kearvall, R.; Kennedy, A.; Richardson, S.; Krawiec, M.; Stewart, N.; Joseph, D. J.; Denham, J. W.","Ebert, Martin/O-4039-2014; Haworth, Annette/AAV-1028-2020; DENHAM, JAMES/G-7505-2013","Ebert, Martin/0000-0002-6875-0719; Haworth, Annette/0000-0003-1382-7747; DENHAM, JAMES/0000-0002-4177-9503",Derivation and representation of dose-volume response from large clinical trial data sets: an example from the RADAR prostate radiotherapy trial,489,,10.1088/1742-6596/489/1/012090 ,Proceedings Paper ,2014.0,"Large multicentre radiotherapy trials incorporating assessment of multiple outcomes at multiple timepoints can generate extensive datasets. We have investigated graphical techniques for presentation of this data and the associated underlying dose-volume response information, necessary for guiding statistical analyses and translating outcomes to future patient treatments. A relational database was used to archive reviewed plan data for patients accrued to the TROG 03.04 RADAR trial. Viewing software was used to clean and enhance the data. Scripts were developed to export arbitrary dose-histogram data which was combined with clinical toxicity data with a median follow-up of 72 months. Graphical representations of dose-volume response developed include prevalence atlasing, univariate logistic regression and dose-volume-point odds ratios, and continuous cut-point derivation via ROC analysis. These representations indicate variable association of toxicities across structures and time-points.",1742-6588,1742-6596,*****************,, , 17th International Conference on the Use of Computers in Radiation Therapy (ICCR)17th International Conference on the Use of Computers in Radiation Therapy (ICCR),,out_of_scope,
3937,"Title:Intelligent Multi-Lingual Cyber-Hate Detection in Online Social Networks: Taxonomy, Approaches, Datasets, and Open Challenges

 Sentiment Analysis, also known as opinion mining, is the area of Natural Language Processing that aims to extract human perceptions, thoughts, and beliefs from unstructured textual content. It has become a useful, attractive, and challenging research area concerning the emergence and rise of social media and the mass volume of individuals' reviews, comments, and feedback. One of the major problems, apparent and evident in social media, is the toxic online textual content. People from diverse cultural backgrounds and beliefs access Internet sites, concealing and disguising their identity under a cloud of anonymity. Due to users' freedom and anonymity, as well as a lack of regulation governed by social media, cyber toxicity and bullying speech are major issues that need an automated system to be detected and prevented. There is diverse research in different languages and approaches in this area, but the lack of a comprehensive study to investigate them from all aspects is tangible. In this manuscript, a comprehensive multi-lingual and systematic review of cyber-hate sentiment analysis is presented. It states the definition, properties, and taxonomy of cyberbullying and how often each type occurs. In addition, it presents the most recent popular cyberbullying benchmark datasets in different languages, showing their number of classes (Binary/Multiple), discussing the applied algorithms, and how they were evaluated. It also provides the challenges, solutions, as well as future directions.","Gamal, Donia; Alfonse, Marco; Jimenez-Zafra, Salud Maria; Aref, Mostafa","Gamal, Donia/AAC-1127-2021","Gamal, Donia/0000-0002-0740-3086; Jimenez-Zafra, Salud Maria/0000-0003-3274-8825; Alfonse, Marco/0000-0003-0722-3218","Intelligent Multi-Lingual Cyber-Hate Detection in Online Social Networks: Taxonomy, Approaches, Datasets, and Open Challenges",7,2,10.3390/bdcc7020058 ,Article ,2023.0,"Sentiment Analysis, also known as opinion mining, is the area of Natural Language Processing that aims to extract human perceptions, thoughts, and beliefs from unstructured textual content. It has become a useful, attractive, and challenging research area concerning the emergence and rise of social media and the mass volume of individuals' reviews, comments, and feedback. One of the major problems, apparent and evident in social media, is the toxic online textual content. People from diverse cultural backgrounds and beliefs access Internet sites, concealing and disguising their identity under a cloud of anonymity. Due to users' freedom and anonymity, as well as a lack of regulation governed by social media, cyber toxicity and bullying speech are major issues that need an automated system to be detected and prevented. There is diverse research in different languages and approaches in this area, but the lack of a comprehensive study to investigate them from all aspects is tangible. In this manuscript, a comprehensive multi-lingual and systematic review of cyber-hate sentiment analysis is presented. It states the definition, properties, and taxonomy of cyberbullying and how often each type occurs. In addition, it presents the most recent popular cyberbullying benchmark datasets in different languages, showing their number of classes (Binary/Multiple), discussing the applied algorithms, and how they were evaluated. It also provides the challenges, solutions, as well as future directions.",,2504-2289,,, , ,,Use_dataset#detection#evaluation#methodology,
3938,"Title:Exploring predictive QSAR models using Quantum Topological Molecular Similarity (QTMS) descriptors for toxicity of nitroaromatics to Saccharomyces cerevisiae

 In view of the widespread industrial use of nitroaromatics and their consequent ecotoxicological hazard potential, we constructed predictive Quantitative Structure-Activity Relationship (QSAR) models for the toxicity of nitroaromatics to the ecologically important species Saccharomyces cerevisiae. We used Quantum Topological Molecular Similarity (QTMS) descriptors along with electrophilicity index (E-LUMO) and lipid water partition coefficient (log K-ow) as predictor variables. The QTMS descriptors were calculated at B3LYP/6-311 + G(2d,p) level of theory. QTMS descriptors were employed to complement the deficiency of E-LUMO in setting up predictive QSAR models from the view point of external validation. The dataset was divided into a training set (18 compounds) and test set (six compounds) in a ratio of three to one. Partial Least Square (PLS) models were developed based on the training set compounds. The predictive capacity of the models was assessed by the test compounds. The models were also validated by a randomisation test and leave-one-seventh-out crossvalidation test. The results suggest that Bond Critical Point (BCP) descriptors can develop predictive QSAR models for nitroaromatic toxicity to Saccharomyces cerevisiae when used along with E-LUMO and log K-OW, The diagnostic potential of QTMS descriptors could also reveal the importance of the nitro group for nitroaromatic toxicity.","Roy, Kunal; Popelier, Paul L. A.","Roy, Kunal/S-5381-2019; Roy, Kunal/B-1673-2009; Popelier, Paul/AAO-9596-2021","Roy, Kunal/0000-0003-4486-8074; Roy, Kunal/0000-0003-4486-8074; Popelier, Paul/0000-0001-9053-1363",Exploring predictive QSAR models using Quantum Topological Molecular Similarity (QTMS) descriptors for toxicity of nitroaromatics to Saccharomyces cerevisiae,27,8,10.1002/qsar.200810028 ,Article ,2008.0,"In view of the widespread industrial use of nitroaromatics and their consequent ecotoxicological hazard potential, we constructed predictive Quantitative Structure-Activity Relationship (QSAR) models for the toxicity of nitroaromatics to the ecologically important species Saccharomyces cerevisiae. We used Quantum Topological Molecular Similarity (QTMS) descriptors along with electrophilicity index (E-LUMO) and lipid water partition coefficient (log K-ow) as predictor variables. The QTMS descriptors were calculated at B3LYP/6-311 + G(2d,p) level of theory. QTMS descriptors were employed to complement the deficiency of E-LUMO in setting up predictive QSAR models from the view point of external validation. The dataset was divided into a training set (18 compounds) and test set (six compounds) in a ratio of three to one. Partial Least Square (PLS) models were developed based on the training set compounds. The predictive capacity of the models was assessed by the test compounds. The models were also validated by a randomisation test and leave-one-seventh-out crossvalidation test. The results suggest that Bond Critical Point (BCP) descriptors can develop predictive QSAR models for nitroaromatic toxicity to Saccharomyces cerevisiae when used along with E-LUMO and log K-OW, The diagnostic potential of QTMS descriptors could also reveal the importance of the nitro group for nitroaromatic toxicity.",1611-020X,1611-0218,,1006-1012, , ,,out_of_scope,
3939,"Title:Clustering-based Pattern Discovery in Lung Cancer Treatments

 Lung cancer is the leading cause of cancer death. More than 238,340 new cases of lung cancer patients are expected in 2023, with an estimation of more than 127,070 deaths. Choosing the correct treatment is an important element to enhance the probability of survival and to improve patient's quality of life. Cancer treatments might provoke secondary effects. These toxicities cause different health problems that impact the patient's quality of life. Hence, reducing treatments toxicities while maintaining or improving their effectiveness is an important goal that aims to be pursued from the clinical perspective.On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with treatment patterns found in clinical data, would allow to validate the patterns found, as well as discovering alternative treatment patterns.In this work, we have analyzed a dataset containing lung cancer patients information including patients' data, prescribed treatments and their outcomes. Using a Chi-square test and K-Modes clustering algorithm in combination with Pattern Discovery metrics we identify patterns, within the clusters, based on cancer stage and treatment outcomes. Obtained results are analyzed based on statistical and clinical relevance and compared with lung cancer clinical guidelines. The comparison reveals that all patterns found coincide with clinical guidelines recommendations, assessing the validity of the proposed method for pattern discovery in a clinical dataset.","Gomez-Bravo, Daniel; Garcia, Aaron; Viguems, Guillermo; Rios-Sanchez, Belem; Perez-Garcia, Alejandra; Ospina, Vanessa; Torrente, Maria; Menasalvas, Ernestina; Provencio, Mariano; Rodriguez-Gonzalez, Alejandro",,,Clustering-based Pattern Discovery in Lung Cancer Treatments,,,10.1109/CBMS58004.2023.00130 ,Proceedings Paper ,2023.0,"Lung cancer is the leading cause of cancer death. More than 238,340 new cases of lung cancer patients are expected in 2023, with an estimation of more than 127,070 deaths. Choosing the correct treatment is an important element to enhance the probability of survival and to improve patient's quality of life. Cancer treatments might provoke secondary effects. These toxicities cause different health problems that impact the patient's quality of life. Hence, reducing treatments toxicities while maintaining or improving their effectiveness is an important goal that aims to be pursued from the clinical perspective.On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with treatment patterns found in clinical data, would allow to validate the patterns found, as well as discovering alternative treatment patterns.In this work, we have analyzed a dataset containing lung cancer patients information including patients' data, prescribed treatments and their outcomes. Using a Chi-square test and K-Modes clustering algorithm in combination with Pattern Discovery metrics we identify patterns, within the clusters, based on cancer stage and treatment outcomes. Obtained results are analyzed based on statistical and clinical relevance and compared with lung cancer clinical guidelines. The comparison reveals that all patterns found coincide with clinical guidelines recommendations, assessing the validity of the proposed method for pattern discovery in a clinical dataset.",2372-9198,,979-8-3503-1224-9,694-699, , 36th IEEE International Symposium on Computer-Based Medical Systems (CBMS)36th IEEE International Symposium on Computer-Based Medical Systems (CBMS),,out_of_scope,
3940,"Title:Support vector inductive logic programming

 In this paper we explore a topic which is at the intersection of two areas of Machine Learning: namely Support Vector Machines (SVMs) and Inductive Logic Programming (ILP). We propose a general method for constructing kernels for Support Vector Inductive Logic Programming (SVILP). The kernel not only captures the semantic and syntactic relational information contained in the data but also provides the flexibility of using arbitrary forms of structured and non-structured data coded in a relational way. While specialised kernels have been developed for strings, trees and graphs our approach uses declarative background knowledge to provide the learning bias. The use of explicitly encoded background knowledge distinguishes SVILP from existing relational kernels which in ILP-terms work purely at the atomic generalisation level. The SVILP approach is a form of generalisation relative to background knowledge, though the final combining function for the ILP-learned clauses is an SVM rather than a logical conjunction. We evaluate SVILP empirically against related approaches, including an industry-standard toxin predictor called TOPKAT. Evaluation is conducted on a new broad-ranging toxicity dataset (DSSTox). The experimental results demonstrate that our approach significantly outperforms all other approaches in the study.","Muggleton, S; Lodhi, H; Amini, A; Sternberg, MJE",,"Sternberg, Michael/0000-0002-1884-5445",Support vector inductive logic programming,3735,, ,Article; Proceedings Paper ,2005.0,"In this paper we explore a topic which is at the intersection of two areas of Machine Learning: namely Support Vector Machines (SVMs) and Inductive Logic Programming (ILP). We propose a general method for constructing kernels for Support Vector Inductive Logic Programming (SVILP). The kernel not only captures the semantic and syntactic relational information contained in the data but also provides the flexibility of using arbitrary forms of structured and non-structured data coded in a relational way. While specialised kernels have been developed for strings, trees and graphs our approach uses declarative background knowledge to provide the learning bias. The use of explicitly encoded background knowledge distinguishes SVILP from existing relational kernels which in ILP-terms work purely at the atomic generalisation level. The SVILP approach is a form of generalisation relative to background knowledge, though the final combining function for the ILP-learned clauses is an SVM rather than a logical conjunction. We evaluate SVILP empirically against related approaches, including an industry-standard toxin predictor called TOPKAT. Evaluation is conducted on a new broad-ranging toxicity dataset (DSSTox). The experimental results demonstrate that our approach significantly outperforms all other approaches in the study.",0302-9743,1611-3349,3-540-29230-6,163-175, , 8th International Conference on Discovery Science8th International Conference on Discovery Science,,out_of_scope,
3941,"Title:Longitudinal fan-beam computed tomography dataset for head-and-neck squamous cell carcinoma patients

 Purpose To describe in detail a dataset consisting of longitudinal fan-beam computed tomography (CT) imaging to visualize anatomical changes in head-and-neck squamous cell carcinoma (HNSCC) patients throughout radiotherapy (RT) treatment course. Acquisition and validation methods This dataset consists of CT images from 31 HNSCC patients who underwent volumetric modulated arc therapy (VMAT). Patients had three CT scans acquired throughout the duration of the radiation treatment course. Pretreatment planning CT scans with a median of 13 days before treatment (range: 2-27), mid-treatment CT at 22 days after start of treatment (range: 13-38), and post-treatment CT 65 days after start of treatment (range: 35-192). Patients received RT treatment to a total dose of 58-70 Gy, using daily 2.0-2.20 Gy, fractions for 30-35 fractions. The fan-beam CT images were acquired using a Siemens 16-slice CT scanner head protocol with 120 kV and current of 400 mAs. A helical scan with 1 rotation per second was used with a slice thickness of 2 mm and table increment of 1.2 mm. In addition to the imaging data, contours of anatomical structures for RT, demographic, and outcome measurements are provided. Data format and usage notes The dataset with DICOM files including images, RTSTRUCT files, and RTDOSE files can be found and publicly accessed in the Cancer Imaging Archive (TCIA, ) as collection Head-and-neck squamous cell carcinoma patients with CT taken during pretreatment, mid-treatment, and post-treatment (HNSCC-3DCT-RT). Discussion This is the first dataset to date in TCIA which provides a collection of multiple CT imaging studies (pretreatment, mid-treatment, and post-treatment) throughout the treatment course. The dataset can serve a wide array of research projects including (but not limited to): quantitative imaging assessment, investigation on anatomical changes with treatment progress, dosimetry of target volumes and/or normal structures due to anatomical changes occurring during treatment, investigation of RT toxicity, and concurrent chemotherapy and RT effects on head-and-neck patients.","Bejarano, Tatiana; De Ornelas-Couto, Mariluz; Mihaylov, Ivaylo B.",,,Longitudinal fan-beam computed tomography dataset for head-and-neck squamous cell carcinoma patients,46,5,10.1002/mp.13460 ,Article ,2019.0,"Purpose To describe in detail a dataset consisting of longitudinal fan-beam computed tomography (CT) imaging to visualize anatomical changes in head-and-neck squamous cell carcinoma (HNSCC) patients throughout radiotherapy (RT) treatment course. Acquisition and validation methods This dataset consists of CT images from 31 HNSCC patients who underwent volumetric modulated arc therapy (VMAT). Patients had three CT scans acquired throughout the duration of the radiation treatment course. Pretreatment planning CT scans with a median of 13 days before treatment (range: 2-27), mid-treatment CT at 22 days after start of treatment (range: 13-38), and post-treatment CT 65 days after start of treatment (range: 35-192). Patients received RT treatment to a total dose of 58-70 Gy, using daily 2.0-2.20 Gy, fractions for 30-35 fractions. The fan-beam CT images were acquired using a Siemens 16-slice CT scanner head protocol with 120 kV and current of 400 mAs. A helical scan with 1 rotation per second was used with a slice thickness of 2 mm and table increment of 1.2 mm. In addition to the imaging data, contours of anatomical structures for RT, demographic, and outcome measurements are provided. Data format and usage notes The dataset with DICOM files including images, RTSTRUCT files, and RTDOSE files can be found and publicly accessed in the Cancer Imaging Archive (TCIA, ) as collection Head-and-neck squamous cell carcinoma patients with CT taken during pretreatment, mid-treatment, and post-treatment (HNSCC-3DCT-RT). Discussion This is the first dataset to date in TCIA which provides a collection of multiple CT imaging studies (pretreatment, mid-treatment, and post-treatment) throughout the treatment course. The dataset can serve a wide array of research projects including (but not limited to): quantitative imaging assessment, investigation on anatomical changes with treatment progress, dosimetry of target volumes and/or normal structures due to anatomical changes occurring during treatment, investigation of RT toxicity, and concurrent chemotherapy and RT effects on head-and-neck patients.",0094-2405,2473-4209,,2526-2537, , ,,out_of_scope,
3942,"Title:A Virus Has No Religion: Analyzing Islamophobia on Twitter During the COVID-19 Outbreak

 The COVID-19 pandemic has disrupted people's lives driving them to act in fear, anxiety, and anger, leading to worldwide racist events in the physical world and online social networks. Though there are works focusing on Sinophobia during the COVID-19 pandemic, less attention has been given to the recent surge in Islamophobia. A large number of positive cases arising out of the religious Tablighi Jamaat gathering has driven people towards forming anti-Muslim communities around hashtags like #coronajihad, #tablighijamaatvirus on Twitter. In addition to the online spaces, the rise in Islamophobia has also resulted in increased hate crimes in the real world. Hence, has also resulted in increased hate crimes in the real world. Hence, an investigation is required to create interventions. To the best of our knowledge, we present the first large-scale quantitative study linking Islamophobia with COVID-19.In this paper, we present CoronaBias dataset which focuses on anti-Muslim hate spanning four months, with over 410, 990 tweets from 244, 229 unique users. We use this dataset to perform longitudinal analysis. We find the relation between the trend on Twitter with the offline events that happened over time, measure the qualitative changes in the context associated with the Muslim community, and perform macro and micro topic analysis to find prevalent topics. We also explore the nature of the content, focusing on the toxicity of the URLs shared within the tweets present in the CoronaBias dataset. Apart from the content-based analysis, we focus on user analysis, revealing that the portrayal of religion as a symbol of patriotism played a crucial role in deciding how the Muslim community was perceived during the pandemic. Through these experiments, we reveal the existence of anti-Muslim rhetoric around COVID-19 in the Indian sub-continent.","Chandra, Mohit; Reddy, Manvith; Sehgal, Shradha; Gupta, Saurabh; Buduru, Arun Balaji; Kumaraguru, Ponnurangam",,"Chandra, Mohit/0000-0001-5030-6647",A Virus Has No Religion: Analyzing Islamophobia on Twitter During the COVID-19 Outbreak,,,10.1145/3465336.3475111 ,Proceedings Paper ,2021.0,"The COVID-19 pandemic has disrupted people's lives driving them to act in fear, anxiety, and anger, leading to worldwide racist events in the physical world and online social networks. Though there are works focusing on Sinophobia during the COVID-19 pandemic, less attention has been given to the recent surge in Islamophobia. A large number of positive cases arising out of the religious Tablighi Jamaat gathering has driven people towards forming anti-Muslim communities around hashtags like #coronajihad, #tablighijamaatvirus on Twitter. In addition to the online spaces, the rise in Islamophobia has also resulted in increased hate crimes in the real world. Hence, has also resulted in increased hate crimes in the real world. Hence, an investigation is required to create interventions. To the best of our knowledge, we present the first large-scale quantitative study linking Islamophobia with COVID-19.In this paper, we present CoronaBias dataset which focuses on anti-Muslim hate spanning four months, with over 410, 990 tweets from 244, 229 unique users. We use this dataset to perform longitudinal analysis. We find the relation between the trend on Twitter with the offline events that happened over time, measure the qualitative changes in the context associated with the Muslim community, and perform macro and micro topic analysis to find prevalent topics. We also explore the nature of the content, focusing on the toxicity of the URLs shared within the tweets present in the CoronaBias dataset. Apart from the content-based analysis, we focus on user analysis, revealing that the portrayal of religion as a symbol of patriotism played a crucial role in deciding how the Muslim community was perceived during the pandemic. Through these experiments, we reveal the existence of anti-Muslim rhetoric around COVID-19 in the Indian sub-continent.",,,978-1-4503-8551-0,67-77, , 32nd ACM Conference on Hypertext and Social Media (HT)32nd ACM Conference on Hypertext and Social Media (HT),,Gen_dataset#evaluation#methodology,
3943,"Title:Evolutionary Feature Scaling in K-Nearest Neighbors Based on Label Dispersion Minimization

 K-Nearest Neighbors (KNN) has remained one of the most popular methods for supervised machine learning tasks. However, its performance often depends on the characteristics of the dataset and on appropriate feature scaling. In this paper, we explore characteristics of a dataset that make it suitable for being used within KNN. As part of this, two new measures for dataset dispersion, called mean neighborhood target standard deviation (MNTSD), and mean neighborhood target entropy (MNTE) are formulated to determine the expeced performance while using KNN regressors and classifiers, respectively. It is empirically demonstrated that these measures of dispersion can be indicative of the performance of KNN regression and classification. This idea is further used to learn feature weights that help improve the accuracy of KNN classification and regression. For this, it is argued that the MNTSD and MNTE, when used to learn feature weights, cannot be optimized using gradient-based optimization methods and we develop optimization strategies based on metaheuristic methods, namely genetic algorithms and particle swarm optimization. The feature-weighting method is tried in both regression and classification contexts on publicly available datasets, and the performance is compared to KNN without feature weighting. The results indicate that the performance of KNN with appropriate feature weighting leads to better performance.","Basak, Suryoday; Huber, Manfred",,"Huber, Manfred/0009-0007-0294-9147",Evolutionary Feature Scaling in K-Nearest Neighbors Based on Label Dispersion Minimization,,,10.1109/smc42975.2020.9282834 ,Proceedings Paper ,2020.0,"K-Nearest Neighbors (KNN) has remained one of the most popular methods for supervised machine learning tasks. However, its performance often depends on the characteristics of the dataset and on appropriate feature scaling. In this paper, we explore characteristics of a dataset that make it suitable for being used within KNN. As part of this, two new measures for dataset dispersion, called mean neighborhood target standard deviation (MNTSD), and mean neighborhood target entropy (MNTE) are formulated to determine the expeced performance while using KNN regressors and classifiers, respectively. It is empirically demonstrated that these measures of dispersion can be indicative of the performance of KNN regression and classification. This idea is further used to learn feature weights that help improve the accuracy of KNN classification and regression. For this, it is argued that the MNTSD and MNTE, when used to learn feature weights, cannot be optimized using gradient-based optimization methods and we develop optimization strategies based on metaheuristic methods, namely genetic algorithms and particle swarm optimization. The feature-weighting method is tried in both regression and classification contexts on publicly available datasets, and the performance is compared to KNN without feature weighting. The results indicate that the performance of KNN with appropriate feature weighting leads to better performance.",1062-922X,,978-1-7281-8526-2,928-935, ," IEEE International Conference on Systems, Man, and Cybernetics (SMC)IEEE International Conference on Systems, Man, and Cybernetics (SMC)",,out_of_scope,
3944,"Title:SSNCSE_NLP@LT-EDI-ACL2022:Hope Speech Detection for Equality, Diversity and Inclusion using sentence transformers

 In recent times, applications have been developed to regulate and control the spread of negativity and toxicity on online platforms. The world is filled with serious problems like political & religious conflicts, wars, pandemics, and offensive hate speech is the last thing we desire. Our task was to classify a text into `Hope Speech' and `Non-Hope Speech'. We searched for datasets acquired from YouTube comments that offer support, reassurance, inspiration, and insight, and the ones that don't. The datasets were provided to us by the LTEDI organizers in English, Tamil, Spanish, Kannada, and Malayalam. To successfully identify and classify them, we employed several machine learning transformer models such as m-BERT, MLNet, BERT, XLMRoberta, and XLM_MLM. The observed results indicate that the BERT and m-BERT have obtained the best results among all the other techniques, gaining a weighted F1-score of 0.92, 0.71, 0.76, 0.87, and 0.83 for English, Tamil, Spanish, Kannada, and Malayalam respectively. This paper depicts our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LTEDI 2021.","Srinivasan, Dhanya; Varsha, Josephine; Bharathi, B.; Thenmozhi, D.; Kumar, B. Senthil","B., Bharathi/GXV-8824-2022; B, Senthil Kumar/ABB-1924-2022","B., Bharathi/0000-0001-7279-5357; B, Senthil Kumar/0000-0003-0835-5271","SSNCSE_NLP@LT-EDI-ACL2022:Hope Speech Detection for Equality, Diversity and Inclusion using sentence transformers",,, ,Proceedings Paper ,2022.0,"In recent times, applications have been developed to regulate and control the spread of negativity and toxicity on online platforms. The world is filled with serious problems like political & religious conflicts, wars, pandemics, and offensive hate speech is the last thing we desire. Our task was to classify a text into `Hope Speech' and `Non-Hope Speech'. We searched for datasets acquired from YouTube comments that offer support, reassurance, inspiration, and insight, and the ones that don't. The datasets were provided to us by the LTEDI organizers in English, Tamil, Spanish, Kannada, and Malayalam. To successfully identify and classify them, we employed several machine learning transformer models such as m-BERT, MLNet, BERT, XLMRoberta, and XLM_MLM. The observed results indicate that the BERT and m-BERT have obtained the best results among all the other techniques, gaining a weighted F1-score of 0.92, 0.71, 0.76, 0.87, and 0.83 for English, Tamil, Spanish, Kannada, and Malayalam respectively. This paper depicts our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LTEDI 2021.",,,978-1-955917-43-8,218-222, ," 2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)",,out_but_toxicity,
3945,"Title:An Automated Toxicity Classification on Social Media Using LSTM and Word Embedding

 The automated identification of toxicity in texts is a crucial area in text analysis since the social media world is replete with unfiltered content that ranges from mildly abusive to downright hateful. Researchers have found an unintended bias and unfairness caused by training datasets, which caused an inaccurate classification of toxic words in context. In this paper, several approaches for locating toxicity in texts are assessed and presented aiming to enhance the overall quality of text classification. General unsupervised methods were used depending on the state-of-art models and external embeddings to improve the accuracy while relieving bias and enhancing F1-score. Suggested approaches used a combination of long short-term memory (LSTM) deep learning model with Glove word embeddings and LSTM with word embeddings generated by the Bidirectional Encoder Representations from Transformers (BERT), respectively. These models were trained and tested on large secondary qualitative data containing a large number of comments classified as toxic or not. Results found that acceptable accuracy of 94% and an F1-score of 0.89 were achieved using LSTM with BERT word embeddings in the binary classification of comments (toxic and nontoxic). A combination of LSTM and BERT performed better than both LSTM unaccompanied and LSTM with Glove word embedding. This paper tries to solve the problem of classifying comments with high accuracy by pertaining models with larger corpora of text (high-quality word embedding) rather than the training data solely.","Alsharef, Ahmad; Aggarwal, Karan; Sonia; Koundal, Deepika; Alyami, Hashem; Ameyed, Darine","Koundal, Deepika/I-9927-2019; Aggarwal, Karan Kumar/AAR-5617-2020","Koundal, Deepika/0000-0003-1688-8772; , Sonia/0000-0002-0779-8065; Alsharef, Ahmad/0000-0002-9113-7859",An Automated Toxicity Classification on Social Media Using LSTM and Word Embedding,2022,,10.1155/2022/8467349 ,Article ,2022.0,"The automated identification of toxicity in texts is a crucial area in text analysis since the social media world is replete with unfiltered content that ranges from mildly abusive to downright hateful. Researchers have found an unintended bias and unfairness caused by training datasets, which caused an inaccurate classification of toxic words in context. In this paper, several approaches for locating toxicity in texts are assessed and presented aiming to enhance the overall quality of text classification. General unsupervised methods were used depending on the state-of-art models and external embeddings to improve the accuracy while relieving bias and enhancing F1-score. Suggested approaches used a combination of long short-term memory (LSTM) deep learning model with Glove word embeddings and LSTM with word embeddings generated by the Bidirectional Encoder Representations from Transformers (BERT), respectively. These models were trained and tested on large secondary qualitative data containing a large number of comments classified as toxic or not. Results found that acceptable accuracy of 94% and an F1-score of 0.89 were achieved using LSTM with BERT word embeddings in the binary classification of comments (toxic and nontoxic). A combination of LSTM and BERT performed better than both LSTM unaccompanied and LSTM with Glove word embedding. This paper tries to solve the problem of classifying comments with high accuracy by pertaining models with larger corpora of text (high-quality word embedding) rather than the training data solely.",1687-5265,1687-5273,,, , ,,detection#methodology,
3946,"Title:Multi-source data modelling: Integrating related data to improve model performance

 Traditional methods in Data Mining cannot be applied to all types of data with equal success. Innovative methods for model creation are needed to address the lack of model performance for data from which it is difficult to extract relationships. This paper proposes a set of algorithms that allow the integration of data from multiple datasets that are related, as well as results from the implementation of these techniques using data from the field of Predictive Toxicology. The results show significant improvements when related data is used to aid in the model creation process, both overall and in specific data ranges. The proposed algorithms have potential for use within any field where multiple datasets exist, particularly in fields combining computing, chemistry and biology.","Trundle, Paul R.; Neagu, Daniel C.; Chaudhry, Qasim","Chaudhry, Qasim/L-8389-2015; Neagu, Daniel/AAJ-9766-2021","Neagu, Daniel/0000-0002-7038-106X",Multi-source data modelling: Integrating related data to improve model performance,4571,, ,Proceedings Paper ,2007.0,"Traditional methods in Data Mining cannot be applied to all types of data with equal success. Innovative methods for model creation are needed to address the lack of model performance for data from which it is difficult to extract relationships. This paper proposes a set of algorithms that allow the integration of data from multiple datasets that are related, as well as results from the implementation of these techniques using data from the field of Predictive Toxicology. The results show significant improvements when related data is used to aid in the model creation process, both overall and in specific data ranges. The proposed algorithms have potential for use within any field where multiple datasets exist, particularly in fields combining computing, chemistry and biology.",0302-9743,,978-3-540-73498-7,32-+, , 5th International Conference on Machine Learning and Data Mining in Pattern Recognition5th International Conference on Machine Learning and Data Mining in Pattern Recognition,,out_of_scope,
3947,"Title:Feasibility of markerless 3D position monitoring of the central airways using kilovoltage projection images: Managing the risks of central lung stereotactic radiotherapy

 Background and purpose: Central lung stereotactic body radiotherapy (SBRT) can cause proximal bronchial tree (PBT) toxicity. Information on PBT position relative to the high-dose could aid risk management. We investigated template matching + triangulation for high-frequency markerless 3D PBT position monitoring.Materials and methods: Kilovoltage projections of a moving phantom (full-fan cone-beam CT [CBCT, 15 frames/second] without MV irradiation: 889 images/dataset + CBCT and 7 frames/second fluoroscopy with MV irradiation) and ten patients undergoing free-breathing stereotactic/hypofractionated lung irradiation (full-fan CBCT without MV irradiation, 470-500 images/dataset) were retrospectively analyzed. 2D PBT reference templates (1 filtered digitally reconstructed radiograph/degrees) were created from planning CT data. Using normalized cross-correlation, templates were matched to projection images for 2D position. Multiple registrations were triangulated for 3D position.Results: For the phantom, 2D right/left PBT position could be determined in 86.6/75.1% of the CBCT dataset without MV irradiation, and 3D position (excluding first 20 degrees due to the minimum triangulation angle) in 84.7/72.7%. With MV irradiation, this was up to 2% less. For right/left PBT, root-mean-square errors of measured versus known position were 0.5/0.8, 0.4-0.5/0.7, and 0.4/0.5-0.6 mm for left-right, superior-inferior, and anterior-posterior directions, respectively. 2D PBT position was determined in, on average, 89.8% of each patient dataset (range: 79.4-99.2%), and 3D position (excluding first 20 degrees) in 85.1% (range: 67.9-99.6%). Motion was mainly superior-inferior (range: 4.5-13.6 mm, average: 8.5 mm).Conclusions: High-frequency 3D PBT position verification during free-breathing is technically feasible using markerless template matching + triangulation of kilovoltage projection images acquired during gantry rotation. Applications include organ-at-risk position monitoring during central lung SBRT. (C) 2018 Elsevier B.V. All rights reserved.","Hazelaar, Colien; van der Weide, Lineke; Mostafavi, Hassan; Slotman, Ben J.; Verbakel, Wilko F. A. R.; Dahele, Max","Slotman, Ben/HCH-2301-2022","Slotman, Ben/0000-0002-9902-4592; Dahele, Max/0000-0002-2594-1486",Feasibility of markerless 3D position monitoring of the central airways using kilovoltage projection images: Managing the risks of central lung stereotactic radiotherapy,129,2,10.1016/j.radonc.2018.08.007 ,Article ,2018.0,"Background and purpose: Central lung stereotactic body radiotherapy (SBRT) can cause proximal bronchial tree (PBT) toxicity. Information on PBT position relative to the high-dose could aid risk management. We investigated template matching + triangulation for high-frequency markerless 3D PBT position monitoring.Materials and methods: Kilovoltage projections of a moving phantom (full-fan cone-beam CT [CBCT, 15 frames/second] without MV irradiation: 889 images/dataset + CBCT and 7 frames/second fluoroscopy with MV irradiation) and ten patients undergoing free-breathing stereotactic/hypofractionated lung irradiation (full-fan CBCT without MV irradiation, 470-500 images/dataset) were retrospectively analyzed. 2D PBT reference templates (1 filtered digitally reconstructed radiograph/degrees) were created from planning CT data. Using normalized cross-correlation, templates were matched to projection images for 2D position. Multiple registrations were triangulated for 3D position.Results: For the phantom, 2D right/left PBT position could be determined in 86.6/75.1% of the CBCT dataset without MV irradiation, and 3D position (excluding first 20 degrees due to the minimum triangulation angle) in 84.7/72.7%. With MV irradiation, this was up to 2% less. For right/left PBT, root-mean-square errors of measured versus known position were 0.5/0.8, 0.4-0.5/0.7, and 0.4/0.5-0.6 mm for left-right, superior-inferior, and anterior-posterior directions, respectively. 2D PBT position was determined in, on average, 89.8% of each patient dataset (range: 79.4-99.2%), and 3D position (excluding first 20 degrees) in 85.1% (range: 67.9-99.6%). Motion was mainly superior-inferior (range: 4.5-13.6 mm, average: 8.5 mm).Conclusions: High-frequency 3D PBT position verification during free-breathing is technically feasible using markerless template matching + triangulation of kilovoltage projection images acquired during gantry rotation. Applications include organ-at-risk position monitoring during central lung SBRT. (C) 2018 Elsevier B.V. All rights reserved.",0167-8140,1879-0887,,234-241, , ,,out_of_scope,
3948,"Title:Understanding mechanism governing the inflammatory potential of metal oxide nanoparticles using periodic table-based descriptors: a nano-QSAR approach

 Metal oxide nanoparticles (MeOxNPs) can be made safer by understanding the interaction between the immune system and nanoparticles. A nano-quantitative structure-activity relationship (nano-QSAR) model can be used to evaluate nanoparticle risk quickly and conveniently. The present work attempts to develop nano-QSAR models to determine the inflammatory potential of MeOxNPs based on the THP-1 cell line. A comprehensive dataset comprising 32 MeOxNPs was used to develop a regression model with fold change (FC) of pro-inflammatory cytokine interleukin (IL)-1beta (IL-1b) release in the THP-1 cell line as the endpoint. Further, the same number of MeOx NPs with varying doses was modelled for the cell viability [-ln(p/(1-p))] endpoint. The results obtained from regression models were statistically significant. The descriptors obtained from the developed predictive models inferred that dose, electronegativity and the presence of metal ions and oxygen can be responsible for IL-1 & beta; leakage from the THP-1 cell line. Based on our results, we can conclude that periodic table-based descriptors, incorporated into the QSAR models, are reliable for modelling pro-inflammatory potential. Researchers can use these comprehensive results to design metal oxide nanoparticles with lower toxicity and determine the cause of pro-inflammatory conditions induced by MeOxNPs.","Roy, J.; Roy, K.","Roy, Kunal/B-1673-2009; Roy, Joyita/IZP-9036-2023","Roy, Kunal/0000-0003-4486-8074;",Understanding mechanism governing the inflammatory potential of metal oxide nanoparticles using periodic table-based descriptors: a nano-QSAR approach,34,6,10.1080/1062936X.2023.2227557 ,Article ,2023.0,"Metal oxide nanoparticles (MeOxNPs) can be made safer by understanding the interaction between the immune system and nanoparticles. A nano-quantitative structure-activity relationship (nano-QSAR) model can be used to evaluate nanoparticle risk quickly and conveniently. The present work attempts to develop nano-QSAR models to determine the inflammatory potential of MeOxNPs based on the THP-1 cell line. A comprehensive dataset comprising 32 MeOxNPs was used to develop a regression model with fold change (FC) of pro-inflammatory cytokine interleukin (IL)-1beta (IL-1b) release in the THP-1 cell line as the endpoint. Further, the same number of MeOx NPs with varying doses was modelled for the cell viability [-ln(p/(1-p))] endpoint. The results obtained from regression models were statistically significant. The descriptors obtained from the developed predictive models inferred that dose, electronegativity and the presence of metal ions and oxygen can be responsible for IL-1 & beta; leakage from the THP-1 cell line. Based on our results, we can conclude that periodic table-based descriptors, incorporated into the QSAR models, are reliable for modelling pro-inflammatory potential. Researchers can use these comprehensive results to design metal oxide nanoparticles with lower toxicity and determine the cause of pro-inflammatory conditions induced by MeOxNPs.",1062-936X,1029-046X,,459-474, , ,,out_of_scope,
3949,"Title:Is it a Qoincidence?: An Exploratory Study of QAnon on Voat

 Online fringe communities offer fertile grounds to users seeking and sharing ideas fueling suspicion of mainstream news and conspiracy theories. Among these, the QAnon conspiracy theory emerged in 2017 on 4chan, broadly supporting the idea that powerful politicians, aristocrats, and celebrities are closely engaged in a global pedophile ring. Simultaneously, governments are thought to be controlled by puppet masters, as democratically elected officials serve as a fake showroom of democracy.This paper provides an empirical exploratory analysis of the QAnon community on Voat.co, a Reddit-esque news aggregator, which has captured the interest of the press for its toxicity and for providing a platform to QAnon followers. More precisely, we analyze a large dataset from /v/GreatAwakening, the most popular QAnon-related subverse (the Voat equivalent of a subreddit), to characterize activity and user engagement. To further understand the discourse around QAnon, we study the most popular named entities mentioned in the posts, along with the most prominent topics of discussion, which focus on US politics, Donald Trump, and world events. We also use word embeddings to identify narratives around QAnon-specific keywords. Our graph visualization shows that some of the QAnon-related ones are closely related to those from the Pizzagate conspiracy theory and so-called drops by Q. Finally, we analyze content toxicity, finding that discussions on /v/GreatAwakening are less toxic than in the broad Voat community.","Papasavva, Antonis; Blackburn, Jeremy; Stringhini, Gianluca; Zannettou, Savvas; De Cristofaro, Emiliano","De Cristofaro, Emiliano/GRR-4082-2022",,Is it a Qoincidence?: An Exploratory Study of QAnon on Voat,,,10.1145/3442381.3450036 ,Proceedings Paper ,2021.0,"Online fringe communities offer fertile grounds to users seeking and sharing ideas fueling suspicion of mainstream news and conspiracy theories. Among these, the QAnon conspiracy theory emerged in 2017 on 4chan, broadly supporting the idea that powerful politicians, aristocrats, and celebrities are closely engaged in a global pedophile ring. Simultaneously, governments are thought to be controlled by puppet masters, as democratically elected officials serve as a fake showroom of democracy.This paper provides an empirical exploratory analysis of the QAnon community on Voat.co, a Reddit-esque news aggregator, which has captured the interest of the press for its toxicity and for providing a platform to QAnon followers. More precisely, we analyze a large dataset from /v/GreatAwakening, the most popular QAnon-related subverse (the Voat equivalent of a subreddit), to characterize activity and user engagement. To further understand the discourse around QAnon, we study the most popular named entities mentioned in the posts, along with the most prominent topics of discussion, which focus on US politics, Donald Trump, and world events. We also use word embeddings to identify narratives around QAnon-specific keywords. Our graph visualization shows that some of the QAnon-related ones are closely related to those from the Pizzagate conspiracy theory and so-called drops by Q. Finally, we analyze content toxicity, finding that discussions on /v/GreatAwakening are less toxic than in the broad Voat community.",,,978-1-4503-8312-7,460-471, , 30th World Wide Web Conference (WWW)30th World Wide Web Conference (WWW),,evaluation,
3950,"Title:The effect of rectal retractor on intrafraction motion of the prostate

 Rectal retractors (RR) are used in prostate radiotherapy to retract part of the rectal wall further from the prostate in order to lower the rectal dose and toxicity. The aim of this study was to investigate the effect of RR on intrafraction motion of the prostate. Intrafraction motion of the prostate with RR and without it was recorded with electromagnetic real-time tracking system. Intrafractional motion data of 260 RR fractions and 351 non-RR fractions from 22 patients was analyzed. 3D and unidirectional motion patterns between RR and non-RR fraction datasets were compared in terms of percentage time at displacement. 1, 2, 3, 4, 5 and 6mmover 6 and 10 min of tracking time. Temporal patterns of the prostate motion were evaluated by re-binning the motion data in 1 min time intervals. The percentage time at displacement was larger in RR data compared to non-RR data in every direction (except anterior) and for every motion magnitude considered. For non-RR fractions the percentage of time of. 1, 2, 3, 4, 5 and 6mm3Ddisplacements within 10 min of tracking time were 44.8%, 16.0%, 6.4%, 2.9%, 1.4% and 0.5%, respectively. For RR fractions the corresponding percentages were 69.6%, 32.8%, 15.3%, 7.4%, 3.7% and 2.2%, respectively. The difference in 3D motion between the datasets was statistically significant (p < 0.03). Largest increase in the motion was seen in inferior and posterior directions when the RR was used. Motion increased linearly as a function of elapsed tracking time in both RR and non-RR datasets but the increase was more rapid in RR fractions. The use of RR increases the intrafraction motion of the prostate which can lead to inaccurate treatment localization and delivery thus questioning the justification of its use.","Vanhanen, A.; Kapanen, M.",,"Kapanen, Mika/0000-0003-2686-060X",The effect of rectal retractor on intrafraction motion of the prostate,2,3,10.1088/2057-1976/2/3/035021 ,Article ,2016.0,"Rectal retractors (RR) are used in prostate radiotherapy to retract part of the rectal wall further from the prostate in order to lower the rectal dose and toxicity. The aim of this study was to investigate the effect of RR on intrafraction motion of the prostate. Intrafraction motion of the prostate with RR and without it was recorded with electromagnetic real-time tracking system. Intrafractional motion data of 260 RR fractions and 351 non-RR fractions from 22 patients was analyzed. 3D and unidirectional motion patterns between RR and non-RR fraction datasets were compared in terms of percentage time at displacement. 1, 2, 3, 4, 5 and 6mmover 6 and 10 min of tracking time. Temporal patterns of the prostate motion were evaluated by re-binning the motion data in 1 min time intervals. The percentage time at displacement was larger in RR data compared to non-RR data in every direction (except anterior) and for every motion magnitude considered. For non-RR fractions the percentage of time of. 1, 2, 3, 4, 5 and 6mm3Ddisplacements within 10 min of tracking time were 44.8%, 16.0%, 6.4%, 2.9%, 1.4% and 0.5%, respectively. For RR fractions the corresponding percentages were 69.6%, 32.8%, 15.3%, 7.4%, 3.7% and 2.2%, respectively. The difference in 3D motion between the datasets was statistically significant (p < 0.03). Largest increase in the motion was seen in inferior and posterior directions when the RR was used. Motion increased linearly as a function of elapsed tracking time in both RR and non-RR datasets but the increase was more rapid in RR fractions. The use of RR increases the intrafraction motion of the prostate which can lead to inaccurate treatment localization and delivery thus questioning the justification of its use.",2057-1976,,,, , ,,out_of_scope,
3951,"Title:An improved FMM neural network for classification of gene expression data

 Gene microarray experiment can monitor the expression of thousands of genes simultaneously. Using the promising technology, accurate classification of tumor subtypes becomes possible, allowing for specific treatment that maximizes efficacy and minimizes toxicity. Meanwhile, optimal genes selected from microarray data will contribute to diagnostic and prognostic of tumors in low cost. In this paper, we propose an improved FMM (fuzzy Min-Max) neural network classifier which provides higher performance than the original one. The improved one can automatically reduce redundant hyperboxes thus it can solve difficulty of setting the parameter 0 value and is able to select discriminating genes. Finally we apply our improved classifier on the small, round blue-cell tumors dataset and get good results.","Juan, Liu; Fei, Luo; Yongqiong, Zhu",,,An improved FMM neural network for classification of gene expression data,40,, ,Proceedings Paper ,2007.0,"Gene microarray experiment can monitor the expression of thousands of genes simultaneously. Using the promising technology, accurate classification of tumor subtypes becomes possible, allowing for specific treatment that maximizes efficacy and minimizes toxicity. Meanwhile, optimal genes selected from microarray data will contribute to diagnostic and prognostic of tumors in low cost. In this paper, we propose an improved FMM (fuzzy Min-Max) neural network classifier which provides higher performance than the original one. The improved one can automatically reduce redundant hyperboxes thus it can solve difficulty of setting the parameter 0 value and is able to select discriminating genes. Finally we apply our improved classifier on the small, round blue-cell tumors dataset and get good results.",1615-3871,,978-3-540-71440-8,65-+, , 2nd International Conference on Fuzzy Information and Engineering (ICFIE 2007)2nd International Conference on Fuzzy Information and Engineering (ICFIE 2007),,out_of_scope,
3952,"Title:From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer

 We study the task of toxic spans detection, which concerns the detection of the spans that make a text toxic, when detecting such spans is possible. We introduce a dataset for this task, TOXICSPANS, which we release publicly. By experimenting with several methods, we show that sequence labeling models perform best. Moreover, methods that add generic rationale extraction mechanisms on top of classifiers trained to predict if a post is toxic or not are also surprisingly promising. Finally, we use TOXICSPANS and systems trained on it, to provide further analysis of state-of-the-art toxic to non-toxic transfer systems, as well as of human performance on that latter task. Our work highlights challenges in finer toxicity detection and mitigation.","Pavlopoulos, John; Laugier, Leo; Xenos, Alexandros; Sorensen, Jeffrey; Androutsopoulos, Ion",,"Androutsopoulos, Ion/0009-0000-2969-0509",From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer,,, ,Proceedings Paper ,2022.0,"We study the task of toxic spans detection, which concerns the detection of the spans that make a text toxic, when detecting such spans is possible. We introduce a dataset for this task, TOXICSPANS, which we release publicly. By experimenting with several methods, we show that sequence labeling models perform best. Moreover, methods that add generic rationale extraction mechanisms on top of classifiers trained to predict if a post is toxic or not are also surprisingly promising. Finally, we use TOXICSPANS and systems trained on it, to provide further analysis of state-of-the-art toxic to non-toxic transfer systems, as well as of human performance on that latter task. Our work highlights challenges in finer toxicity detection and mitigation.",,,978-1-955917-21-6,3721-3734, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,Use_dataset#detection,
3953,"Title:The Risk of Racial Bias in Hate Speech Detection

 We investigate how annotators' insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose dialect and race priming as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet's dialect they are significantly less likely to label the tweet as offensive.","Sap, Maarten; Card, Dallas; Gabriel, Saadia; Choi, Yejin; Smith, Noah A.",,"Card, Dallas/0000-0001-5573-8836; Sap, Maarten/0000-0002-0701-4654",The Risk of Racial Bias in Hate Speech Detection,,, ,Proceedings Paper ,2019.0,"We investigate how annotators' insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose dialect and race priming as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet's dialect they are significantly less likely to label the tweet as offensive.",,,978-1-950737-48-2,1668-1678, , 57th Annual Meeting of the Association-for-Computational-Linguistics (ACL)57th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,detection#evaluation#methodology,
3954,"Title:Automatic Cardiac Structure Contouring for Small Datasets with Cascaded Deep Learning Models

 Cardiac structure contouring is a time consuming and tedious manual activity used for radiotherapeutic dose toxicity planning. We developed an automatic cardiac structure segmentation pipeline for use in low-dose non-contrast planning CT based on deep learning algorithms for small datasets. Fifty CT scans were retrospectively selected and the whole heart, ventricles and atria were contoured. A two stage deep learning pipeline was trained on 41 non contrast planning CTs, tuned with 3 CT scans and validated on 6 CT scans. In the first stage, An InceptionResNetV2 network was used to identify the slices that contained cardiac structures. The second stage consisted of three deep learning models trained on the images containing cardiac structures to segment the structures. The three deep learning models predicted the segmentations/contours on axial, coronal and sagittal images and are combined to create the final prediction. The final accuracy of the pipeline was quantified on 6 volumes by calculating the Dice similarity coefficient (DC), 95% Hausdorff distance (95% HD) and volume ratios between predicted and ground truth volumes. Median DC and 95% HD of 0.96, 0.88, 0.92, 0.80 and 0.82, and 1.86, 2.98, 2.02, 6.16 and 6.46 were achieved for the whole heart, right and left ventricle, and right and left atria respectively. The median differences in volume were -4, -1, + 5, -16 and -20% for the whole heart, right and left ventricle, and right and left atria respectively. The automatic contouring pipeline achieves good results for whole heart and ventricles. Robust automatic contouring with deep learning methods seems viable for local centers with small datasets.","van den Oever, L. B.; Spoor, D. S.; Crijns, A. P. G.; Vliegenthart, R.; Oudkerk, M.; Veldhuis, R. N. J.; de Bock, G. H.; van Ooijen, P. M. A.","de Bock, Geertruida Hendrika/F-6529-2014; van Ooijen, Peter/G-1146-2012","de Bock, Geertruida Hendrika/0000-0003-3104-4471; van Ooijen, Peter/0000-0002-8995-1210",Automatic Cardiac Structure Contouring for Small Datasets with Cascaded Deep Learning Models,46,5,10.1007/s10916-022-01810-6 ,Article ,2022.0,"Cardiac structure contouring is a time consuming and tedious manual activity used for radiotherapeutic dose toxicity planning. We developed an automatic cardiac structure segmentation pipeline for use in low-dose non-contrast planning CT based on deep learning algorithms for small datasets. Fifty CT scans were retrospectively selected and the whole heart, ventricles and atria were contoured. A two stage deep learning pipeline was trained on 41 non contrast planning CTs, tuned with 3 CT scans and validated on 6 CT scans. In the first stage, An InceptionResNetV2 network was used to identify the slices that contained cardiac structures. The second stage consisted of three deep learning models trained on the images containing cardiac structures to segment the structures. The three deep learning models predicted the segmentations/contours on axial, coronal and sagittal images and are combined to create the final prediction. The final accuracy of the pipeline was quantified on 6 volumes by calculating the Dice similarity coefficient (DC), 95% Hausdorff distance (95% HD) and volume ratios between predicted and ground truth volumes. Median DC and 95% HD of 0.96, 0.88, 0.92, 0.80 and 0.82, and 1.86, 2.98, 2.02, 6.16 and 6.46 were achieved for the whole heart, right and left ventricle, and right and left atria respectively. The median differences in volume were -4, -1, + 5, -16 and -20% for the whole heart, right and left ventricle, and right and left atria respectively. The automatic contouring pipeline achieves good results for whole heart and ventricles. Robust automatic contouring with deep learning methods seems viable for local centers with small datasets.",0148-5598,1573-689X,,, , ,,out_of_scope,
3955,"Title:KRAKENX: software for the generation of alignment-independent 3D descriptors

 The KRAKENX software calculates a large variety of molecular descriptors based on quantum chemistry computations. The program supports over 2000 three-dimensional descriptors that are calculated from the output of different quantum chemistry packages. The current implementation supports semi-empirical MOPAC-based computations and primarily focuses on orientation-independent descriptors that have been discussed in the literature. The descriptor performance has been exemplified using a number of large and diverse datasets and can be seen to produce parsimonious linear models. The software can be run on multiple platforms and is available to academics free of charge.","Venkatraman, Vishwesh; Alsberg, Bjorn Kare","Alsberg, Bjørn K/E-3781-2014","Venkatraman, Vishwesh/0000-0001-7609-2245",KRAKENX: software for the generation of alignment-independent 3D descriptors,22,4,10.1007/s00894-016-2957-5 ,Article ,2016.0,The KRAKENX software calculates a large variety of molecular descriptors based on quantum chemistry computations. The program supports over 2000 three-dimensional descriptors that are calculated from the output of different quantum chemistry packages. The current implementation supports semi-empirical MOPAC-based computations and primarily focuses on orientation-independent descriptors that have been discussed in the literature. The descriptor performance has been exemplified using a number of large and diverse datasets and can be seen to produce parsimonious linear models. The software can be run on multiple platforms and is available to academics free of charge.,1610-2940,0948-5023,,, , ,,out_of_scope,
3956,"Title:Toxicity in the Decentralized Web and the Potential for Model Sharing

 The Decentralised Web (DW) is an evolving concept, which encompasses technologies aimed at providing greater transparency and openness on the web. The DW relies on independent servers (aka instances) that mesh together in a peer-to-peer fashion to deliver a range of services (e.g. micro-blogs, image sharing, video streaming). However, toxic content moderation in this decentralised context is challenging. This is because there is no central entity that can define toxicity, nor a large central pool of data that can be used to build universal classifiers. It is therefore unsurprising that there have been several high-profile cases of the DW being misused to coordinate and disseminate harmful material. Using a dataset of 9.9M posts from 117K users on Pleroma (a popular DW microblogging service), we quantify the presence of toxic content. We find that toxic content is prevalent and spreads rapidly between instances. We show that automating per-instance content moderation is challenging due to the lack of sufficient training data available and the effort required in labelling. We therefore propose and evaluate ModPair, a model sharing system that effectively detects toxic content, gaining an average per-instance macro-F1 score 0.89.","Bin Zia, Haris; Raman, Aravindh; Castro, Ignacio; Anaobi, Ishaku Hassan; De Cristofaro, Emiliano; Sastry, Nishanth; Tyson, Gareth","De Cristofaro, Emiliano/GRR-4082-2022","Sastry, Nishanth/0000-0002-4053-0386",Toxicity in the Decentralized Web and the Potential for Model Sharing,6,2,10.1145/3530901 ,Article; Proceedings Paper ,2022.0,"The Decentralised Web (DW) is an evolving concept, which encompasses technologies aimed at providing greater transparency and openness on the web. The DW relies on independent servers (aka instances) that mesh together in a peer-to-peer fashion to deliver a range of services (e.g. micro-blogs, image sharing, video streaming). However, toxic content moderation in this decentralised context is challenging. This is because there is no central entity that can define toxicity, nor a large central pool of data that can be used to build universal classifiers. It is therefore unsurprising that there have been several high-profile cases of the DW being misused to coordinate and disseminate harmful material. Using a dataset of 9.9M posts from 117K users on Pleroma (a popular DW microblogging service), we quantify the presence of toxic content. We find that toxic content is prevalent and spreads rapidly between instances. We show that automating per-instance content moderation is challenging due to the lack of sufficient training data available and the effort required in labelling. We therefore propose and evaluate ModPair, a model sharing system that effectively detects toxic content, gaining an average per-instance macro-F1 score 0.89.",,2476-1249,,, , ACM SIGMETRICS/Performance conferenceACM SIGMETRICS/Performance conference,,Gen_dataset#evaluation,
3957,"Title:Analyzing the Usage of Standards in Radiation Therapy Clinical Studies

 Standards for scoring adverse effects after radiation therapy (RT) is crucial for integrated, consistent, and accurate analysis of toxicity results at large scale and across multiple studies. This project aims to investigate the usage of the three most commonly used standards in published RT clinical studies by developing a text-mining based analysis method. We develop and compare two text-mining methods, one based on regular expressions and one based on Naive Bayes Classifier, to analyze published full articles in terms of their adoption of standards in RT. The full dataset includes published articles identified in MEDLINE between January 2010 and August 2015. A radiation oncology physician reviewed all the articles in the training/validation subset and produced the usage trending data manually as gold standard for validation. The regular-expression based method reported classifications and overall usage trends that are comparable to those of the domain expert. The CTCAE standard is becoming the overall most commonly used standards over time, but the pace of adoption seems very slow. Further examination of the results indicates that the usage vary by disease type. It suggests that further efforts are needed to improve and harmonize the standards for adverse effects scoring in RT research community.","Zhen, Y.; Jiang, Y.; Yuan, L.; Kirkpartrick, J.; Wu, J.; Ge, Y.","jiang, yu/HGU-0029-2022; Zhen, Yi/AAI-5413-2021","Zhen, Yi/0000-0001-8677-5082",Analyzing the Usage of Standards in Radiation Therapy Clinical Studies,,, ,Proceedings Paper ,2017.0,"Standards for scoring adverse effects after radiation therapy (RT) is crucial for integrated, consistent, and accurate analysis of toxicity results at large scale and across multiple studies. This project aims to investigate the usage of the three most commonly used standards in published RT clinical studies by developing a text-mining based analysis method. We develop and compare two text-mining methods, one based on regular expressions and one based on Naive Bayes Classifier, to analyze published full articles in terms of their adoption of standards in RT. The full dataset includes published articles identified in MEDLINE between January 2010 and August 2015. A radiation oncology physician reviewed all the articles in the training/validation subset and produced the usage trending data manually as gold standard for validation. The regular-expression based method reported classifications and overall usage trends that are comparable to those of the domain expert. The CTCAE standard is becoming the overall most commonly used standards over time, but the pace of adoption seems very slow. Further examination of the results indicates that the usage vary by disease type. It suggests that further efforts are needed to improve and harmonize the standards for adverse effects scoring in RT research community.",,,978-1-5090-4179-4,349-352, , 4th IEEE EMBS International Conference on Biomedical and Health Informatics (BHI)4th IEEE EMBS International Conference on Biomedical and Health Informatics (BHI),,out_of_scope,
3958,"Title:PSA-Net: Deep learning-based physician style-aware segmentation network for postoperative prostate cancer clinical target volumes

 Purpose: Automatic segmentation of medical images with deep learning (DL) algorithms has proven highly successful in recent times. With most of these automation networks, inter-observer variation is an acknowledged problem that leads to suboptimal results. This problem is even more significant in segmenting postoperative clinical target volumes (CTV) because they lack a macroscopic visible tumor in the image. This study, using postoperative prostate CTV segmentation as the test case, tries to determine 1) whether physician styles are consistent and learnable, 2) whether physician style affects treatment outcome and toxicity, and 3) how to explicitly deal with different physician styles in DL-assisted CTV segmentation to facilitate its clinical acceptance. Methods: A dataset of 373 postoperative prostate cancer patients from UT Southwestern Medical Center was used for this study. We used another 83 patients from Mayo Clinic to validate the developed model and its adaptability. To determine whether physician styles are consistent and learnable, we trained a 3D convolutional neural network classifier to identify which physician had contoured a CTV from just the contour and the corresponding CT scan. Next, we evaluated whether adapting automatic segmentation to specific physician styles would be clinically feasible based on a lack of difference between outcomes. Here, biochemical progression-free survival (BCFS) and grade 3+ genitourinary and gastrointestinal toxicity were estimated with the Kaplan-Meier method and compared between physician styles with the log rank test and subsequently with a multivariate Cox regression. When we found no statistically significant differences in outcome or toxicity between contouring styles, we proposed a concept called physician style-aware (PSA) segmentation by developing an encodermultidecoder network with perceptual loss to model different physician styles of CTV segmentation. Results: The classification network captured the different physician styles with 87% accuracy. Subsequent outcome analysis showed no differences in BCFS and grade 3+ toxicity among physicians. With the proposed physician style-aware network (PSA-Net), Dice similarity coefficient (DSC) accuracy for all physicians was 3.4% higher on average than with a general model that does not differentiate physician styles. We show that these stylistic contouring variations also exist between institutions that follow the same segmentation guidelines, and we show the proposed method's effectiveness in adapting to new institutional styles. We observed an accuracy improvement of 5% in terms of DSC when adapting to the style of a separate institution. Conclusion: The performance of the classification network established that physician styles are learnable, and the lack of difference between outcomes among physicians shows that the network can feasibly adapt to different styles in the clinic. Therefore, we developed a novel PSA-Net model that can produce contours specific to the treating physician, thus improving segmentation accuracy and avoiding the need to train multiple models to achieve different style segmentations. We successfully validated this model on data from a separate institution, thus supporting the model's generalizability to diverse datasets.","Balagopal, Anjali; Morgan, Howard; Dohopolski, Michael; Timmerman, Ramsey; Shan, Jie; Heitjan, Daniel F.; Liu, Wei; Nguyen, Dan; Hannan, Raquibul; Garant, Aurelie; Desai, Neil; Jiang, Steve","Jiang, Steve/GRO-3951-2022; Dohopolski, Michael/ABG-2224-2021","Dohopolski, Michael/0000-0002-9043-1490",PSA-Net: Deep learning-based physician style-aware segmentation network for postoperative prostate cancer clinical target volumes,121,,10.1016/j.artmed.2021.102195 ,Article ,2021.0,"Purpose: Automatic segmentation of medical images with deep learning (DL) algorithms has proven highly successful in recent times. With most of these automation networks, inter-observer variation is an acknowledged problem that leads to suboptimal results. This problem is even more significant in segmenting postoperative clinical target volumes (CTV) because they lack a macroscopic visible tumor in the image. This study, using postoperative prostate CTV segmentation as the test case, tries to determine 1) whether physician styles are consistent and learnable, 2) whether physician style affects treatment outcome and toxicity, and 3) how to explicitly deal with different physician styles in DL-assisted CTV segmentation to facilitate its clinical acceptance. Methods: A dataset of 373 postoperative prostate cancer patients from UT Southwestern Medical Center was used for this study. We used another 83 patients from Mayo Clinic to validate the developed model and its adaptability. To determine whether physician styles are consistent and learnable, we trained a 3D convolutional neural network classifier to identify which physician had contoured a CTV from just the contour and the corresponding CT scan. Next, we evaluated whether adapting automatic segmentation to specific physician styles would be clinically feasible based on a lack of difference between outcomes. Here, biochemical progression-free survival (BCFS) and grade 3+ genitourinary and gastrointestinal toxicity were estimated with the Kaplan-Meier method and compared between physician styles with the log rank test and subsequently with a multivariate Cox regression. When we found no statistically significant differences in outcome or toxicity between contouring styles, we proposed a concept called physician style-aware (PSA) segmentation by developing an encodermultidecoder network with perceptual loss to model different physician styles of CTV segmentation. Results: The classification network captured the different physician styles with 87% accuracy. Subsequent outcome analysis showed no differences in BCFS and grade 3+ toxicity among physicians. With the proposed physician style-aware network (PSA-Net), Dice similarity coefficient (DSC) accuracy for all physicians was 3.4% higher on average than with a general model that does not differentiate physician styles. We show that these stylistic contouring variations also exist between institutions that follow the same segmentation guidelines, and we show the proposed method's effectiveness in adapting to new institutional styles. We observed an accuracy improvement of 5% in terms of DSC when adapting to the style of a separate institution. Conclusion: The performance of the classification network established that physician styles are learnable, and the lack of difference between outcomes among physicians shows that the network can feasibly adapt to different styles in the clinic. Therefore, we developed a novel PSA-Net model that can produce contours specific to the treating physician, thus improving segmentation accuracy and avoiding the need to train multiple models to achieve different style segmentations. We successfully validated this model on data from a separate institution, thus supporting the model's generalizability to diverse datasets.",0933-3657,1873-2860,,, , ,,out_of_scope,
3959,"100    Title:Can CBCT-Based Delta Radiomics Predict N...
Name: Abstract, dtype: object","Jose, N.; Varghese, A. J.; Thomas, H. M.; Irodi, A.; Paul, J. C.; Mathew, M.; Isiah, R.; John, S.; Godson, H. F.; Peace, T. B.; Pavamani, S. P.; Devadhas, D.; Sasidharan, B. K.",,"Varghese, Amal Joseph/0009-0000-2844-7611",Can CBCT-Based Delta Radiomics Predict Normal Lung Toxicity during Thoracic Radiation?,114,3, ,Meeting Abstract ,2022.0,"Delta radiomics which refers to longitudinal changes of radiomic features over time has shown the potential to predict treatment response. However, its role in predicting normal lung toxicity has not been studied extensively. This study evaluates the potential for CBCT based delta radiomics in predicting radiotherapy induced lung parenchymal changes during thoracic radiotherapy.",0360-3016,1879-355X,,E118-E119, , Annual Meeting of the American-Society-for-Radiation-Oncology (ASTRO)Annual Meeting of the American-Society-for-Radiation-Oncology (ASTRO),,out_of_scope,
3960,"Title:Context-Based Patterns in Machine Learning Bias and Fairness Metrics: A Sensitive Attributes-Based Approach

 The majority of current approaches for bias and fairness identification or mitigation in machine learning models are applications for a particular issue that fails to account for the connection between the application context and its associated sensitive attributes, which contributes to the recognition of consistent patterns in the application of bias and fairness metrics. This can be used to drive the development of future models, with the sensitive attribute acting as a connecting element to these metrics. Hence, this study aims to analyze patterns in several metrics for identifying bias and fairness, applying the gender-sensitive attribute as a case study, for three different areas of applications in machine learning models: computer vision, natural language processing, and recommendation systems. The gender attribute case study has been used in computer vision, natural language processing, and recommendation systems. The method entailed creating use cases for facial recognition in the FairFace dataset, message toxicity in the Jigsaw dataset, and movie recommendations in the MovieLens100K dataset, then developing models based on the VGG19, BERT, and Wide Deep architectures and evaluating them using the accuracy, precision, recall, and F1-score classification metrics, as well as assessing their outcomes using fourteen fairness metrics. Certain metrics disclosed bias and fairness, while others did not, revealing a consistent pattern for the same sensitive attribute across different application domains, and similarities for the statistical parity, PPR disparity, and error disparity metrics across domains, indicating fairness related to the studied sensitive attribute. Some attributes, on the other hand, did not follow this pattern. As a result, we conclude that the sensitive attribute may play a crucial role in defining the fairness metrics for a specific context.","Pagano, Tiago P.; Loureiro, Rafael B.; Lisboa, Fernanda V. N.; Cruz, Gustavo O. R.; Peixoto, Rodrigo M.; Guimaraes, Guilherme A. de Sousa; Oliveira, Ewerton L. S.; Winkler, Ingrid; Nascimento, Erick G. Sperandio","Winkler, Ingrid/AAU-9884-2020; Bessa Loureiro, Rafael/IQW-6029-2023; Giovani Sperandio Nascimento, Erick/ABC-8551-2021","Winkler, Ingrid/0000-0001-6505-6636; Bessa Loureiro, Rafael/0000-0002-2404-0643; Giovani Sperandio Nascimento, Erick/0000-0003-2219-0290; de Oliveira, Ewerton/0000-0002-3160-3571; Palma Pagano, Tiago/0000-0003-2457-9064; Peixoto, Rodrigo/0000-0001-6405-1593; Nascimento Lisboa, Fernanda Vitoria/0000-0001-5203-2408",Context-Based Patterns in Machine Learning Bias and Fairness Metrics: A Sensitive Attributes-Based Approach,7,1,10.3390/bdcc7010027 ,Article ,2023.0,"The majority of current approaches for bias and fairness identification or mitigation in machine learning models are applications for a particular issue that fails to account for the connection between the application context and its associated sensitive attributes, which contributes to the recognition of consistent patterns in the application of bias and fairness metrics. This can be used to drive the development of future models, with the sensitive attribute acting as a connecting element to these metrics. Hence, this study aims to analyze patterns in several metrics for identifying bias and fairness, applying the gender-sensitive attribute as a case study, for three different areas of applications in machine learning models: computer vision, natural language processing, and recommendation systems. The gender attribute case study has been used in computer vision, natural language processing, and recommendation systems. The method entailed creating use cases for facial recognition in the FairFace dataset, message toxicity in the Jigsaw dataset, and movie recommendations in the MovieLens100K dataset, then developing models based on the VGG19, BERT, and Wide Deep architectures and evaluating them using the accuracy, precision, recall, and F1-score classification metrics, as well as assessing their outcomes using fourteen fairness metrics. Certain metrics disclosed bias and fairness, while others did not, revealing a consistent pattern for the same sensitive attribute across different application domains, and similarities for the statistical parity, PPR disparity, and error disparity metrics across domains, indicating fairness related to the studied sensitive attribute. Some attributes, on the other hand, did not follow this pattern. As a result, we conclude that the sensitive attribute may play a crucial role in defining the fairness metrics for a specific context.",,2504-2289,,, , ,,Use_dataset#evaluation,
3961,"Title:Detoxifying Language Models Risks Marginalizing Minority Voices

 Language models (LMs) must be both safe and equitable to be responsibly deployed in practice. With safety in mind, numerous detoxification techniques (e.g., Dathathri et al. 2020; Krause et al. 2020) have been proposed to mitigate toxic LM generations. In this work, we show that these detoxification techniques hurt equity: they decrease the utility of LMs on language used by marginalized groups (e.g., African-American English and minority identity mentions). In particular, we perform automatic and human evaluations of text generation quality when LMs are conditioned on inputs with different dialects and group identifiers. We find that detoxification makes LMs more brittle to distribution shift, especially on language used by marginalized groups. We identify that these failures stem from detoxification methods exploiting spurious correlations in toxicity datasets. Overall, our results highlight the tension between the controllability and distributional robustness of LMs.","Xu, Albert; Pathak, Eshaan; Wallace, Eric; Gururangan, Suchin; Sap, Maarten; Klein, Dan",,,Detoxifying Language Models Risks Marginalizing Minority Voices,,, ,Proceedings Paper ,2021.0,"Language models (LMs) must be both safe and equitable to be responsibly deployed in practice. With safety in mind, numerous detoxification techniques (e.g., Dathathri et al. 2020; Krause et al. 2020) have been proposed to mitigate toxic LM generations. In this work, we show that these detoxification techniques hurt equity: they decrease the utility of LMs on language used by marginalized groups (e.g., African-American English and minority identity mentions). In particular, we perform automatic and human evaluations of text generation quality when LMs are conditioned on inputs with different dialects and group identifiers. We find that detoxification makes LMs more brittle to distribution shift, especially on language used by marginalized groups. We identify that these failures stem from detoxification methods exploiting spurious correlations in toxicity datasets. Overall, our results highlight the tension between the controllability and distributional robustness of LMs.",,,978-1-954085-46-6,2390-2397, , Conference of the North-American-Chapter of the Association-for-Computational-Linguistics - Human Language Technologies (NAACL-HLT)Conference of the North-American-Chapter of the Association-for-Computational-Linguistics - Human Language Technologies (NAACL-HLT),,Use_dataset#detox#evaluation#methodology,
3962,"Title:A Deceiving Charm of Feature Selection: The Microarray Case Study

 Microarray analysis has become a significant use of machine learning in molecular biology. Datasets obtained from this method consist of tens of thousands of attributes usually describing tens of objects. Such setting makes the use of some form of feature selection an inevitable step of analysis mostly to reduce the feature set to manageable size, but also to obtain an biological insight in the mechanisms of the investigated process. In this paper we present a reanalysis of a previously published late radiation toxicity prediction problem. On that lurid example we show how futile it may be to rely on non-validated feature selection and how even advanced algorithms fail to distinguish between noise and signal when the latter is weak. We also propose methods of detecting and dealing with mentioned problems.","Kursa, Miron B.; Rudnicki, Witold R.","Rudnicki, Witold R/B-6670-2012; Kursa, Miron/B-4405-2013","Rudnicki, Witold R/0000-0002-7928-4944; Kursa, Miron/0000-0001-7672-648X",A Deceiving Charm of Feature Selection: The Microarray Case Study,103,, 10.1007/978-3-642-23169-8,Article; Book Chapter ,2011.0,"Microarray analysis has become a significant use of machine learning in molecular biology. Datasets obtained from this method consist of tens of thousands of attributes usually describing tens of objects. Such setting makes the use of some form of feature selection an inevitable step of analysis mostly to reduce the feature set to manageable size, but also to obtain an biological insight in the mechanisms of the investigated process. In this paper we present a reanalysis of a previously published late radiation toxicity prediction problem. On that lurid example we show how futile it may be to rely on non-validated feature selection and how even advanced algorithms fail to distinguish between noise and signal when the latter is weak. We also propose methods of detecting and dealing with mentioned problems.",1867-5662,,978-3-642-23168-1,145-152, , ,,out_of_scope,
3963,"Title:Misogynoir: challenges in detecting intersectional hate

 Misogynoir is a term that refers to the anti-Black forms of misogyny that Black women experience. To explore how current automated hate speech detection approaches perform in detecting this type of hate, we evaluated the performance of two state-of-the-art detection tools, HateSonar and Google's Perspective API, on a balanced dataset of 300 tweets, half of which are examples of misogynoir and half of which are examples of supporting Black women and an imbalanced dataset of 3138 tweets of which 162 tweets are examples of misogynoir and 2976 tweets are examples of allyship tweets. We aim to determine if these tools flag these messages under any of their classifications of hateful speech (e.g. hate speech, offensive language, toxicity etc.). Close analysis of the classifications and errors shows that current hate speech detection tools are ineffective in detecting misogynoir. They lack sensitivity to context, which is an essential component for misogynoir detection. We found that tweets likely to be classified as hate speech explicitly reference racism or sexism or use profane or aggressive words. Subtle tweets without references to these topics are more challenging to classify. We find that the lack of sensitivity to context may make such tools not only ineffective but potentially harmful to Black women.","Kwarteng, Joseph; Perfumi, Serena Coppolino; Farrell, Tracie; Third, Aisling; Fernandez, Miriam",,"Kwarteng, Joseph/0000-0001-6576-5678",Misogynoir: challenges in detecting intersectional hate,12,1,10.1007/s13278-022-00993-7 ,Article ,2022.0,"Misogynoir is a term that refers to the anti-Black forms of misogyny that Black women experience. To explore how current automated hate speech detection approaches perform in detecting this type of hate, we evaluated the performance of two state-of-the-art detection tools, HateSonar and Google's Perspective API, on a balanced dataset of 300 tweets, half of which are examples of misogynoir and half of which are examples of supporting Black women and an imbalanced dataset of 3138 tweets of which 162 tweets are examples of misogynoir and 2976 tweets are examples of allyship tweets. We aim to determine if these tools flag these messages under any of their classifications of hateful speech (e.g. hate speech, offensive language, toxicity etc.). Close analysis of the classifications and errors shows that current hate speech detection tools are ineffective in detecting misogynoir. They lack sensitivity to context, which is an essential component for misogynoir detection. We found that tweets likely to be classified as hate speech explicitly reference racism or sexism or use profane or aggressive words. Subtle tweets without references to these topics are more challenging to classify. We find that the lack of sensitivity to context may make such tools not only ineffective but potentially harmful to Black women.",1869-5450,1869-5469,,, , ,,Use_dataset#detection#methodology,
3964,"Title:Prioritizing municipal lead mitigation projects as a relaxed knapsack optimization: a method and case study

 Lead pipe remediation budgets are limited and ought to maximize public health impact. This goal implies a nontrivial optimization problem; lead service lines connect water mains to individual houses, but any realistic replacement strategy must batch replacements at a larger scale. Additionally, planners typically lack a principled method for comparing the relative public health value of potential interventions and often plan projects based on nonhealth factors. This paper describes a simple process for estimating child health impact at a parcel level by cleaning and synthesizing municipal datasets that are commonly available but seldom joined due to data quality issues. Using geocoding as the core record linkage mechanism, parcel-level toxicity data can be combined with school enrollment records to indicate where young children and lead lines coexist. A harm metric of estimated exposure-years is described at the parcel level, which can then be aggregated to the project level and minimized globally by posing project selection as a 0/1 knapsack problem. Simplifying for use by nonexperts, the implied linear programming relaxation is solved with the greedy algorithm; ordering projects by benefit cost ratio produces a priority list that planners can then consider holistically alongside harder to quantify factors. A case study demonstrates the successful application of this framework to a small U.S. city's existing data to prioritize federal infrastructure funding.","Slavitt, Isaac",,"Slavitt, Isaac/0000-0002-7418-9876",Prioritizing municipal lead mitigation projects as a relaxed knapsack optimization: a method and case study,30,6,10.1111/itor.13212 ,Article ,2023.0,"Lead pipe remediation budgets are limited and ought to maximize public health impact. This goal implies a nontrivial optimization problem; lead service lines connect water mains to individual houses, but any realistic replacement strategy must batch replacements at a larger scale. Additionally, planners typically lack a principled method for comparing the relative public health value of potential interventions and often plan projects based on nonhealth factors. This paper describes a simple process for estimating child health impact at a parcel level by cleaning and synthesizing municipal datasets that are commonly available but seldom joined due to data quality issues. Using geocoding as the core record linkage mechanism, parcel-level toxicity data can be combined with school enrollment records to indicate where young children and lead lines coexist. A harm metric of estimated exposure-years is described at the parcel level, which can then be aggregated to the project level and minimized globally by posing project selection as a 0/1 knapsack problem. Simplifying for use by nonexperts, the implied linear programming relaxation is solved with the greedy algorithm; ordering projects by benefit cost ratio produces a priority list that planners can then consider holistically alongside harder to quantify factors. A case study demonstrates the successful application of this framework to a small U.S. city's existing data to prioritize federal infrastructure funding.",0969-6016,1475-3995,,3719-3737, , ,,out_of_scope,
3965,"Title:Systematic Poisoning Attacks on and Defenses for Machine Learning in Healthcare

 Machine learning is being used in a wide range of application domains to discover patterns in large datasets. Increasingly, the results of machine learning drive critical decisions in applications related to healthcare and biomedicine. Such health-related applications are often sensitive, and thus, any security breach would be catastrophic. Naturally, the integrity of the results computed by machine learning is of great importance. Recent research has shown that some machine-learning algorithms can be compromised by augmenting their training datasets with malicious data, leading to a new class of attacks called poisoning attacks. Hindrance of a diagnosis may have life-threatening consequences and could cause distrust. On the other hand, not only may a false diagnosis prompt users to distrust the machine-learning algorithm and even abandon the entire system but also such a false positive classification may cause patient distress. In this paper, we present a systematic, algorithm-independent approach for mounting poisoning attacks across a wide range of machine-learning algorithms and healthcare datasets. The proposed attack procedure generates input data, which, when added to the training set, can either cause the results of machine learning to have targeted errors (e.g., increase the likelihood of classification into a specific class), or simply introduce arbitrary errors ( incorrect classification). These attacks may be applied to both fixed and evolving datasets. They can be applied even when only statistics of the training dataset are available or, in some cases, even without access to the training dataset, although at a lower efficacy. We establish the effectiveness of the proposed attacks using a suite of six machine-learning algorithms and five healthcare datasets. Finally, we present countermeasures against the proposed generic attacks that are based on tracking and detecting deviations in various accuracy metrics, and benchmark their effectiveness.","Mozaffari-Kermani, Mehran; Sur-Kolay, Susmita; Raghunathan, Anand; Jha, Niraj K.","Raghunathan, Anand/HLQ-2491-2023; Mozaffari Kermani, Mehran/IAR-5293-2023","Mozaffari Kermani, Mehran/0000-0003-4513-3109; Raghunathan, Anand/0000-0002-4624-564X",Systematic Poisoning Attacks on and Defenses for Machine Learning in Healthcare,19,6,10.1109/JBHI.2014.2344095 ,Article ,2015.0,"Machine learning is being used in a wide range of application domains to discover patterns in large datasets. Increasingly, the results of machine learning drive critical decisions in applications related to healthcare and biomedicine. Such health-related applications are often sensitive, and thus, any security breach would be catastrophic. Naturally, the integrity of the results computed by machine learning is of great importance. Recent research has shown that some machine-learning algorithms can be compromised by augmenting their training datasets with malicious data, leading to a new class of attacks called poisoning attacks. Hindrance of a diagnosis may have life-threatening consequences and could cause distrust. On the other hand, not only may a false diagnosis prompt users to distrust the machine-learning algorithm and even abandon the entire system but also such a false positive classification may cause patient distress. In this paper, we present a systematic, algorithm-independent approach for mounting poisoning attacks across a wide range of machine-learning algorithms and healthcare datasets. The proposed attack procedure generates input data, which, when added to the training set, can either cause the results of machine learning to have targeted errors (e.g., increase the likelihood of classification into a specific class), or simply introduce arbitrary errors ( incorrect classification). These attacks may be applied to both fixed and evolving datasets. They can be applied even when only statistics of the training dataset are available or, in some cases, even without access to the training dataset, although at a lower efficacy. We establish the effectiveness of the proposed attacks using a suite of six machine-learning algorithms and five healthcare datasets. Finally, we present countermeasures against the proposed generic attacks that are based on tracking and detecting deviations in various accuracy metrics, and benchmark their effectiveness.",2168-2194,,,1893-1905, , ,,,
3966,"Title:Context-Aware Deep Markov Random Fields for Fake News Detection

 Fake news is a serious problem, which has received considerable attention from both industry and academic communities. Over the past years, many fake news detection approaches have been introduced, and most of the existing methods rely on either news content or the social context of the news dissemination process on social media platforms. In this work, we propose a generic model that is able to take into account both the news content and the social context for the identification of fake news. Specifically, we explore different aspects of the news content by using both shallow and deep representations. The shallow representations are produced with word2vec and doc2vec models while the deep representations are generated via transformer-based models. These representations are able to jointly or separately address four individual tasks, namely bias detection, clickbait detection, sentiment analysis, and toxicity detection. In addition, we make use of graph convolutional neural networks and mean-field layers in order to exploit the underlying structural information of the news articles. That way, we are able to take into account the inherent correlation between the articles by leveraging their social context information. Experiments on widely-used benchmark datasets indicate the effectiveness of the proposed method.","Do, Tien Huu; Berneman, Marc; Patro, Jasabanta; Bekoulis, Giannis; Deligiannis, Nikos","Do, Tien/IVU-9134-2023","Bekoulis, Giannis/0000-0003-3377-2675; patro, jasabanta/0000-0003-2461-9679; Do Huu, Tien/0000-0002-7346-5496; Deligiannis, Nikolaos/0000-0001-9300-5860; Berneman, Marc/0000-0002-3821-1933",Context-Aware Deep Markov Random Fields for Fake News Detection,9,,10.1109/ACCESS.2021.3113877 ,Article ,2021.0,"Fake news is a serious problem, which has received considerable attention from both industry and academic communities. Over the past years, many fake news detection approaches have been introduced, and most of the existing methods rely on either news content or the social context of the news dissemination process on social media platforms. In this work, we propose a generic model that is able to take into account both the news content and the social context for the identification of fake news. Specifically, we explore different aspects of the news content by using both shallow and deep representations. The shallow representations are produced with word2vec and doc2vec models while the deep representations are generated via transformer-based models. These representations are able to jointly or separately address four individual tasks, namely bias detection, clickbait detection, sentiment analysis, and toxicity detection. In addition, we make use of graph convolutional neural networks and mean-field layers in order to exploit the underlying structural information of the news articles. That way, we are able to take into account the inherent correlation between the articles by leveraging their social context information. Experiments on widely-used benchmark datasets indicate the effectiveness of the proposed method.",2169-3536,,,130042-130054, , ,,out_of_scope,
3967,"Title:Hate speech, toxicity detection in online social media: a recent survey of state of the art and opportunities

 Information and communication technology has evolved dramatically, and now the majority of people are using internet and sharing their opinion more openly, which has led to the creation, collection and circulation of hate speech over multiple platforms. The anonymity and movability given by these social media platforms allow people to hide themselves behind a screen and spread the hate effortlessly. Online hate speech (OHS) recognition can play a vital role in stopping such activities and can thus restore the position of public platforms as the open marketplace of ideas. To study hate speech detection in social media, we surveyed the related available datasets on the web-based platform. We further analyzed approximately 200 research papers indexed in the different journals from 2010 to 2022. The papers were divided into various sections and approaches used in OHS detection, i.e., feature selection, traditional machine learning (ML) and deep learning (DL). Based on the selected 111 papers, we found that 44 articles used traditional ML and 35 used DL-based approaches. We concluded that most authors used SVM, Naive Bayes, Decision Tree in ML and CNN, LSTM in the DL approach. This survey contributes by providing a systematic approach to help researchers identify a new research direction in online hate speech.","Anjum, Rahul; Katarya, Rahul",,"Katarya, Prof. Rahul/0000-0001-7763-291X","Hate speech, toxicity detection in online social media: a recent survey of state of the art and opportunities",,,10.1007/s10207-023-00755-2 ,Article; Early Access ,,"Information and communication technology has evolved dramatically, and now the majority of people are using internet and sharing their opinion more openly, which has led to the creation, collection and circulation of hate speech over multiple platforms. The anonymity and movability given by these social media platforms allow people to hide themselves behind a screen and spread the hate effortlessly. Online hate speech (OHS) recognition can play a vital role in stopping such activities and can thus restore the position of public platforms as the open marketplace of ideas. To study hate speech detection in social media, we surveyed the related available datasets on the web-based platform. We further analyzed approximately 200 research papers indexed in the different journals from 2010 to 2022. The papers were divided into various sections and approaches used in OHS detection, i.e., feature selection, traditional machine learning (ML) and deep learning (DL). Based on the selected 111 papers, we found that 44 articles used traditional ML and 35 used DL-based approaches. We concluded that most authors used SVM, Naive Bayes, Decision Tree in ML and CNN, LSTM in the DL approach. This survey contributes by providing a systematic approach to help researchers identify a new research direction in online hate speech.",1615-5262,1615-5270,,, , ,,Use_dataset#survey,
3968,"Title:Gene Expression Profiles based Human Cancer Diseases Classification

 Cancers are a large family of diseases that involve abnormal cell growth with the potential to spread to other parts of the body. A cancer disease in any of its forms represents a major cause of death worldwide. In cancer diagnosis, classification of different tumor types is of the greatest significance. Accuracy for prediction of various tumor types gives better treatment and minimization of toxicity on patients. Accordingly, creating methodologies that can effectively differentiate between cancer subtypes is essential. This paper presents a new methodology to classify Human cancer diseases based on the gene expression profiles. The proposed methodology combines both Information gain (IG) and Deep Genetic Algorithm (DGA). It first uses IG for feature selection, then uses Genetic Algorithm (GA) for feature reduction and finally uses Genetic Programming (GP) for cancer types' classification. The proposed system is evaluated by classifYing cancer diseases in seven cancer datasets and the results are compared with most recent approaches.","Salem, Hanaa; Attiya, Gamal; El-Fishawy, Nawal","Salem Marie, Hanaa/AAF-3631-2021; Attiya, Gamal/AAE-8414-2021","Salem Marie, Hanaa/0000-0002-8714-567X;",Gene Expression Profiles based Human Cancer Diseases Classification,,, ,Proceedings Paper ,2015.0,"Cancers are a large family of diseases that involve abnormal cell growth with the potential to spread to other parts of the body. A cancer disease in any of its forms represents a major cause of death worldwide. In cancer diagnosis, classification of different tumor types is of the greatest significance. Accuracy for prediction of various tumor types gives better treatment and minimization of toxicity on patients. Accordingly, creating methodologies that can effectively differentiate between cancer subtypes is essential. This paper presents a new methodology to classify Human cancer diseases based on the gene expression profiles. The proposed methodology combines both Information gain (IG) and Deep Genetic Algorithm (DGA). It first uses IG for feature selection, then uses Genetic Algorithm (GA) for feature reduction and finally uses Genetic Programming (GP) for cancer types' classification. The proposed system is evaluated by classifYing cancer diseases in seven cancer datasets and the results are compared with most recent approaches.",,,978-1-5090-0275-7,181-187, , 11th International Computer Engineering Conference (ICENCO)11th International Computer Engineering Conference (ICENCO),,out_of_scope,
3969,"Title:Decomposing a Recurrent Neural Network into Modules for Enabling Reusability and Replacement

 Can we take a recurrent neural network (RNN) trained to translate between languages and augment it to support a new natural language without retraining the model from scratch? Can we fix the faulty behavior of the RNN by replacing portions associated with the faulty behavior? Recent works on decomposing a fully connected neural network (FCNN) and convolutional neural network (CNN) into modules have shown the value of engineering deep models in this manner, which is standard in traditional SE but foreign for deep learning models. However, prior works focus on the image-based multiclass classification problems and cannot be applied to RNN due to (a) different layer structures, (b) loop structures, (c) different types of input-output architectures, and (d) usage of both nonlinear and logistic activation functions. In this work, we propose the first approach to decompose an RNN into modules. We study different types of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN modules can be reused and replaced in various scenarios. We evaluate our approach against 5 canonical datasets (i.e., Math QA, Brown Corpus, Wiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset. We found that decomposing a trained model has a small cost (Accuracy: -0.6%, BLEU score: +0.10%). Also, the decomposed modules can be reused and replaced without needing to retrain.","Imtiaz, Sayem Mohammad; Batole, Fraol; Singh, Astha; Pan, Rangeet; Cruz, Breno Dantas; Rajan, Hridesh",,,Decomposing a Recurrent Neural Network into Modules for Enabling Reusability and Replacement,,,10.1109/ICSE48619.2023.00093 ,Proceedings Paper ,2023.0,"Can we take a recurrent neural network (RNN) trained to translate between languages and augment it to support a new natural language without retraining the model from scratch? Can we fix the faulty behavior of the RNN by replacing portions associated with the faulty behavior? Recent works on decomposing a fully connected neural network (FCNN) and convolutional neural network (CNN) into modules have shown the value of engineering deep models in this manner, which is standard in traditional SE but foreign for deep learning models. However, prior works focus on the image-based multiclass classification problems and cannot be applied to RNN due to (a) different layer structures, (b) loop structures, (c) different types of input-output architectures, and (d) usage of both nonlinear and logistic activation functions. In this work, we propose the first approach to decompose an RNN into modules. We study different types of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN modules can be reused and replaced in various scenarios. We evaluate our approach against 5 canonical datasets (i.e., Math QA, Brown Corpus, Wiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset. We found that decomposing a trained model has a small cost (Accuracy: -0.6%, BLEU score: +0.10%). Also, the decomposed modules can be reused and replaced without needing to retrain.",0270-5257,,978-1-6654-5701-9,1020-1032, , 45th IEEE/ACM International Conference on Software Engineering (ICSE)45th IEEE/ACM International Conference on Software Engineering (ICSE),,out_of_scope,
3970,"Title:Cancer Classification using Fuzzy C-Means with Feature Selection

 For many years, cancer classification to detect cancer at early stage of treatment has improved. Cancer classification is used for the treatment of cancer has entered the challenge to target specific therapy for each type of cancer pathogens in an effort to maximize efficacy and minimize toxicity. In general, cancer data consists of many features. However, not all of these features are informative. Therefore, among these features, Fisher's Ratio is applied to select the most informative features which form new data. Data on which feature selection has not been and has been performed are classified using Fuzzy C-Means. The experiment reveals that optimization which based on classification with feature selection increases the accuracy. Results show that, without doing feature selection, the accuracy is 82.92 % while with feature selection, the best accuracy is 89.68 % obtained by using 150 features. The results show the difference between all the dataset used and the dataset using feature selection.","Rachman, Arvan Aulia; Rustam, Zuherman","Rustam, Zuherman/K-7894-2017","Rustam, Zuherman/0000-0001-7143-9633",Cancer Classification using Fuzzy C-Means with Feature Selection,,, ,Proceedings Paper ,2016.0,"For many years, cancer classification to detect cancer at early stage of treatment has improved. Cancer classification is used for the treatment of cancer has entered the challenge to target specific therapy for each type of cancer pathogens in an effort to maximize efficacy and minimize toxicity. In general, cancer data consists of many features. However, not all of these features are informative. Therefore, among these features, Fisher's Ratio is applied to select the most informative features which form new data. Data on which feature selection has not been and has been performed are classified using Fuzzy C-Means. The experiment reveals that optimization which based on classification with feature selection increases the accuracy. Results show that, without doing feature selection, the accuracy is 82.92 % while with feature selection, the best accuracy is 89.68 % obtained by using 150 features. The results show the difference between all the dataset used and the dataset using feature selection.",,,978-1-5090-3385-0,31-34, ," 12th International Conference on Mathematics, Statistics, and Their Applications (ICMSA)12th International Conference on Mathematics, Statistics, and Their Applications (ICMSA)",,out_of_scope,
3971,"Title:Information Extraction from Nanotoxicity Related Publications

 High-quality experimental data are important when developing predictive models for studying nanomaterial environmental impact (NEI). Given that raw data from experimental laboratories and manufacturing workplaces are usually proprietary and small-scaled, extracting information from publications is an attractive alternative for collecting data. We developed an information extraction system that can extract useful information from full-text nanotoxicity related publications. This information extraction system consists of five components: raw data transformation into machine readable format, data preprocessing, ontology-based named entity recognition, rule-based numerical attribute extraction from both tables and unstructured text, and relation extraction among entities and attributes. The information extraction system is applied on a dataset made of 94 publications, and results in an acceptable accuracy. By storing extracted data into a table according to relations among the data, a dataset that can be used to predict nanomaterial environmental impact is obtained. Such a system is unique in current nanomaterial community, and can help nanomaterial scientists and practitioners quickly locate useful information they need without spending lots of time reading articles.","Xiao, Lemin; Tang, Kaizhi; Liu, Xiong; Yang, Hui; Chen, Zheng; Xu, Roger","Liu, Xiong/O-3480-2019","Liu, Xiong/0000-0003-4522-7228",Information Extraction from Nanotoxicity Related Publications,,, ,Proceedings Paper ,2013.0,"High-quality experimental data are important when developing predictive models for studying nanomaterial environmental impact (NEI). Given that raw data from experimental laboratories and manufacturing workplaces are usually proprietary and small-scaled, extracting information from publications is an attractive alternative for collecting data. We developed an information extraction system that can extract useful information from full-text nanotoxicity related publications. This information extraction system consists of five components: raw data transformation into machine readable format, data preprocessing, ontology-based named entity recognition, rule-based numerical attribute extraction from both tables and unstructured text, and relation extraction among entities and attributes. The information extraction system is applied on a dataset made of 94 publications, and results in an acceptable accuracy. By storing extracted data into a table according to relations among the data, a dataset that can be used to predict nanomaterial environmental impact is obtained. Such a system is unique in current nanomaterial community, and can help nanomaterial scientists and practitioners quickly locate useful information they need without spending lots of time reading articles.",2156-1125,2156-1133,978-1-4799-1309-1; 978-1-4799-1310-7,, , IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM)IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM),,out_of_scope,
3972,"Title:Cyberbullying Detection in Social Networks: A Comparison Between Machine Learning and Transfer Learning Approaches

 Information and Communication Technologies fueled social networking and facilitated communication. However, cyberbullying on the platform had detrimental ramifications. The user-dependent mechanisms like reporting, blocking, and removing bullying posts online is manual and ineffective. Bag-of-words text representation without metadata limited cyberbullying post text classification. This research developed an automatic system for cyberbullying detection with two approaches: Conventional Machine Learning and Transfer Learning. This research adopted AMiCA data encompassing significant amount of cyberbullying context and structured annotation process. Textual, sentiment and emotional, static and contextual word embeddings, psycholinguistics, term lists, and toxicity features were used in the conventional Machine Learning approach. This study was the first to use toxicity features to detect cyberbullying. This study is also the first to use the latest psycholinguistics features from the Linguistic Inquiry and Word (LIWC) 2022 tool, as well as Empath's lexicon, to detect cyberbullying. The contextual embeddings of ggeluBert, tnBert, and DistilBert have alike performance, however DistilBert embeddings were elected for higher F-measure. Textual features, DistilBert embeddings, and toxicity features that struck new benchmark were the top three unique features when fed individually. The model's performance was boosted to F-measure of 64.8% after feeding with a combination of textual, sentiment, DistilBert embeddings, psycholinguistics, and toxicity features to the Logistic Regression model that outperforms Linear SVC with faster training time and efficient handling of high-dimensionality features. Transfer Learning approach was by fine-tuning optimized version Pre-trained Language Models namely, DistilBert, DistilRoBerta, and Electra-small which were found to have speedier training computation than their base form. The fine-tuned DistilBert resulted with the highest F-measure of 72.42%, surpassing CML. Our research concluded that Transfer Learning was the best for uplifted performance and lesser effort as feature engineering and resampling was omitted.","Teng, Teoh Hwai; Varathan, Kasturi Dewi",,"Varathan, Kasturi Dewi/0000-0003-3421-4501; Teoh, Hwai Teng/0000-0001-9456-3194",Cyberbullying Detection in Social Networks: A Comparison Between Machine Learning and Transfer Learning Approaches,11,,10.1109/ACCESS.2023.3275130 ,Article ,2023.0,"Information and Communication Technologies fueled social networking and facilitated communication. However, cyberbullying on the platform had detrimental ramifications. The user-dependent mechanisms like reporting, blocking, and removing bullying posts online is manual and ineffective. Bag-of-words text representation without metadata limited cyberbullying post text classification. This research developed an automatic system for cyberbullying detection with two approaches: Conventional Machine Learning and Transfer Learning. This research adopted AMiCA data encompassing significant amount of cyberbullying context and structured annotation process. Textual, sentiment and emotional, static and contextual word embeddings, psycholinguistics, term lists, and toxicity features were used in the conventional Machine Learning approach. This study was the first to use toxicity features to detect cyberbullying. This study is also the first to use the latest psycholinguistics features from the Linguistic Inquiry and Word (LIWC) 2022 tool, as well as Empath's lexicon, to detect cyberbullying. The contextual embeddings of ggeluBert, tnBert, and DistilBert have alike performance, however DistilBert embeddings were elected for higher F-measure. Textual features, DistilBert embeddings, and toxicity features that struck new benchmark were the top three unique features when fed individually. The model's performance was boosted to F-measure of 64.8% after feeding with a combination of textual, sentiment, DistilBert embeddings, psycholinguistics, and toxicity features to the Logistic Regression model that outperforms Linear SVC with faster training time and efficient handling of high-dimensionality features. Transfer Learning approach was by fine-tuning optimized version Pre-trained Language Models namely, DistilBert, DistilRoBerta, and Electra-small which were found to have speedier training computation than their base form. The fine-tuned DistilBert resulted with the highest F-measure of 72.42%, surpassing CML. Our research concluded that Transfer Learning was the best for uplifted performance and lesser effort as feature engineering and resampling was omitted.",2169-3536,,,55533-55560, , ,,detection#methodology,
3973,"Title:First Steps in Quantifying Toxicity and Verbal Violence on Twitter

 Online harassment is a continuing problem, endemic to many social media platforms and other means of web-based communications, and few means exist to analyze web content for instances of verbal violence and aggression. We are developing a scale of online aggression that can be applied to Twitter posts ( tweets) and that is based on existing measures of trait aggression and cyberbullying. For the purpose of testing and validating our scale, we are relying on Mechanical Turk, an Amazon Web Service, through which we can enlist and pay workers to code our dataset of tweets. Preliminary results suggest that aggression in tweets is difficult for human coders to identify and that we have not reached consensus about what constitutes harassment online. We discuss our preliminary results and propose next steps such as scale modification and automated classifier development.","Guberman, Joshua; Schmitz, Carol; Hemphill, Libby","Hemphill, Libby/AAH-7062-2019","Hemphill, Libby/0000-0002-3793-7281; Guberman, Joshua/0000-0002-5424-4508",First Steps in Quantifying Toxicity and Verbal Violence on Twitter,,,10.1145/2818052.2869107 ,Proceedings Paper ,2016.0,"Online harassment is a continuing problem, endemic to many social media platforms and other means of web-based communications, and few means exist to analyze web content for instances of verbal violence and aggression. We are developing a scale of online aggression that can be applied to Twitter posts ( tweets) and that is based on existing measures of trait aggression and cyberbullying. For the purpose of testing and validating our scale, we are relying on Mechanical Turk, an Amazon Web Service, through which we can enlist and pay workers to code our dataset of tweets. Preliminary results suggest that aggression in tweets is difficult for human coders to identify and that we have not reached consensus about what constitutes harassment online. We discuss our preliminary results and propose next steps such as scale modification and automated classifier development.",,,978-1-4503-3950-6,277-280, , 19th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW)19th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW),,evaluation,
3974,"Title:A unified in silico model based on perturbation theory for assessing the genotoxicity of metal oxide nanoparticles

 Nanomaterials (NMs) are an ever-increasing field of interest, due to their wide range of applications in science and technology. However, despite providing solutions to many societal problems and challenges, NMs are associated with adverse effects with potential severe damages towards biological species and their ecosystems. Particularly, it has been confirmed that NMs may induce serious genotoxic effects on various biological targets. Given the difficulties of experimental assays for estimating the genotoxicity of many NMs on diverse biological targets, development of alternative methodologies is crucial to establish their level of safety. In silico modelling approaches, such as Quantitative Structure-Toxicity Relationships (QSTR), are now considered a promising solution for such purpose. In this work, a perturbation theory machine learning (PTML) based QSTR approach is proposed for predicting the genotoxicity of metal oxide NMs under various experimental assay conditions. The application of such perturbation approach to 6084 NM-NM pair cases, set up from 78 unique NMs, afforded a final PTML-QSTR model with an accuracy better than 96% for both training and test sets. This model was then used to predict the genotoxicity of some NMs not included in the modelling dataset. The results for this independent data set were in excellent agreement with the experimental ones. Overall, that thus suggests that the derived PTML-QSTR model is a reliable in silico tool to rapidly and cost-efficiently assess the genotoxicity of metal oxide NMs. Finally, and most importantly, the model provides important insights regarding the mechanism of the genotoxicity triggered by these NMs. (C) 2019 Elsevier Ltd. All rights reserved.","Halder, Amit Kumar; Melo, Andre; Cordeiro, M. Natalia D. S.","Cordeiro, Maria Natália D. S./A-7413-2012; Melo, André/D-5490-2013; Cordeiro, Natália/ISV-0249-2023; HALDER, AMIT KUMAR/V-3914-2017","Cordeiro, Maria Natália D. S./0000-0003-3375-8670; Melo, André/0000-0001-6455-7834; Cordeiro, Natália/0000-0003-3375-8670; HALDER, AMIT KUMAR/0000-0002-4818-9047",A unified in silico model based on perturbation theory for assessing the genotoxicity of metal oxide nanoparticles,244,,10.1016/j.chemosphere.2019.125489 ,Article ,2020.0,"Nanomaterials (NMs) are an ever-increasing field of interest, due to their wide range of applications in science and technology. However, despite providing solutions to many societal problems and challenges, NMs are associated with adverse effects with potential severe damages towards biological species and their ecosystems. Particularly, it has been confirmed that NMs may induce serious genotoxic effects on various biological targets. Given the difficulties of experimental assays for estimating the genotoxicity of many NMs on diverse biological targets, development of alternative methodologies is crucial to establish their level of safety. In silico modelling approaches, such as Quantitative Structure-Toxicity Relationships (QSTR), are now considered a promising solution for such purpose. In this work, a perturbation theory machine learning (PTML) based QSTR approach is proposed for predicting the genotoxicity of metal oxide NMs under various experimental assay conditions. The application of such perturbation approach to 6084 NM-NM pair cases, set up from 78 unique NMs, afforded a final PTML-QSTR model with an accuracy better than 96% for both training and test sets. This model was then used to predict the genotoxicity of some NMs not included in the modelling dataset. The results for this independent data set were in excellent agreement with the experimental ones. Overall, that thus suggests that the derived PTML-QSTR model is a reliable in silico tool to rapidly and cost-efficiently assess the genotoxicity of metal oxide NMs. Finally, and most importantly, the model provides important insights regarding the mechanism of the genotoxicity triggered by these NMs. (C) 2019 Elsevier Ltd. All rights reserved.",0045-6535,1879-1298,,, , ,,out_of_scope,
3975,"Title:Kinetochore tracking in 3D from lattice light-sheet imaging data with KiT

 Motivation: Lattice light-sheet microscopy (LLSM) is revolutionizing cell biology since it enables fast, high-resolution extended imaging in three dimensions combined with a drastic reduction in photo-toxicity and bleaching. However, analysis of such datasets still remains a major challenge.Results: Automated tracking of kinetochores, the protein complex facilitating and controlling microtubule attachment of the chromosomes within the mitotic spindle, provides quantitative assessment of chromosome dynamics in mitosis. Here, we extend existing open-source kinetochore tracking software (KiT) to track (and pair) kinetochores throughout prometaphase to anaphase in LLSM data. One of the key improvements is a regularization term in the objective function to enforce biological information about the number of kinetochores in a human mitotic cell, as well as improved diagnostic tools. This software provides quantitative insights into how kinetochores robustly ensure congression and segregation of chromosomes during mitosis.","Harrison, Jonathan U.; Sen, Onur; McAinsh, Andrew D.; Burroughs, Nigel J.","McAinsh, Andrew D/A-5941-2014","Sen, Onur/0000-0002-6685-7010; Harrison, Jonathan/0000-0002-2748-9921",Kinetochore tracking in 3D from lattice light-sheet imaging data with KiT,38,12,10.1093/bioinformatics/btac330 ,Article ,2022.0,"Motivation: Lattice light-sheet microscopy (LLSM) is revolutionizing cell biology since it enables fast, high-resolution extended imaging in three dimensions combined with a drastic reduction in photo-toxicity and bleaching. However, analysis of such datasets still remains a major challenge.Results: Automated tracking of kinetochores, the protein complex facilitating and controlling microtubule attachment of the chromosomes within the mitotic spindle, provides quantitative assessment of chromosome dynamics in mitosis. Here, we extend existing open-source kinetochore tracking software (KiT) to track (and pair) kinetochores throughout prometaphase to anaphase in LLSM data. One of the key improvements is a regularization term in the objective function to enforce biological information about the number of kinetochores in a human mitotic cell, as well as improved diagnostic tools. This software provides quantitative insights into how kinetochores robustly ensure congression and segregation of chromosomes during mitosis.",1367-4803,1367-4811,,3315-3317, , ,,out_of_scope,
3976,"Title:Toxicity of engineered metal oxide nanomaterials mediated by nano-bio-eco-interactions: a review and perspective

 Along with the expanding use of engineered metal oxide nanomaterials (MONMs), there is a growing concern over their unintentional adverse toxicological effects on human health and the environment upon release and exposure. It is inevitable that biota will be exposed to nanomaterials, through intentional administration or inadvertent contact under such circumstances. Therefore, a thorough investigation of the potential nanotoxicity of MONMs at the nano-bio-eco interface is urgently needed. In general, nanomaterials interact with their surrounding environments, biotic and abiotic, immediately upon introduction into the environment. The behavior and fate of MONMs are influenced by the dynamics of the environment. Thus, understanding the interactions at the nano-bio-eco interface is necessary for selecting and designing MONMs with minimum adverse impacts. Despite the limitations of currently available techniques, careful characterization of nanomaterials and the choosing of methodologies that promote further risk assessment promise more reliable and accurate data output. Conventional toxicological analysis techniques lack the power to handle the large datasets generated from in vitro/in vivo observations. This paper provides a comprehensive review of the recent experimental and theoretical studies on the toxicity of MONMs mediated by two-way or three-way interactions. In the Perspectives, we also call for more open collaborations between industry, academia, and research labs to facilitate nano-toxicological studies focused specifically on interactions at the nano-bio-eco interface, leading to safe and effective nanotechnology for commercial, environmental, and medicinal use.","He, Xiaojia; Aker, Winfred G.; Fu, Peter P.; Hwang, Huey-Min","He, Xiaojia/AAR-1776-2021","He, Xiaojia/0000-0001-8274-5564",Toxicity of engineered metal oxide nanomaterials mediated by nano-bio-eco-interactions: a review and perspective,2,6,10.1039/c5en00094g ,Review ,2015.0,"Along with the expanding use of engineered metal oxide nanomaterials (MONMs), there is a growing concern over their unintentional adverse toxicological effects on human health and the environment upon release and exposure. It is inevitable that biota will be exposed to nanomaterials, through intentional administration or inadvertent contact under such circumstances. Therefore, a thorough investigation of the potential nanotoxicity of MONMs at the nano-bio-eco interface is urgently needed. In general, nanomaterials interact with their surrounding environments, biotic and abiotic, immediately upon introduction into the environment. The behavior and fate of MONMs are influenced by the dynamics of the environment. Thus, understanding the interactions at the nano-bio-eco interface is necessary for selecting and designing MONMs with minimum adverse impacts. Despite the limitations of currently available techniques, careful characterization of nanomaterials and the choosing of methodologies that promote further risk assessment promise more reliable and accurate data output. Conventional toxicological analysis techniques lack the power to handle the large datasets generated from in vitro/in vivo observations. This paper provides a comprehensive review of the recent experimental and theoretical studies on the toxicity of MONMs mediated by two-way or three-way interactions. In the Perspectives, we also call for more open collaborations between industry, academia, and research labs to facilitate nano-toxicological studies focused specifically on interactions at the nano-bio-eco interface, leading to safe and effective nanotechnology for commercial, environmental, and medicinal use.",2051-8153,2051-8161,,564-582, , ,,out_of_scope,
3977,"Title:A Factor Analysis Approach for Clustering Patient Reported Outcomes

 Background: In the field of radiation oncology, the use of extensive patient reported outcomes is increasingly common to measure adverse side effects after radiotherapy in cancer patients. Factor analysis has the potential to identify an optimal number of latent factors (i.e., symptom groups). However, the ultimate goal of treatment response modeling is to understand the relationship between treatment variables such as radiation dose and symptom groups resulting from FA. Hence, it is crucial to identify clinically more relevant symptom groups and improved response variables from those symptom groups for a quantitative analysis.Objectives: The goal of this study is to design a computational method for finding clinically relevant symptom groups from PROs and to test associations between symptom groups and radiation dose.Methods: We propose a novel approach where exploratory factor analysis is followed by confirmatory factor analysis to determine the relevant number of symptom groups. We also propose to use a combination of symptoms in a symptom group identified as a new response variable in linear regression analysis to investigate the relationship between the symptom group and dose-volume variables.Results: We analyzed patient-reported gastrointestinal symptom profiles from 3 datasets in prostate cancer patients treated with radiotherapy. The final structural model of each dataset was validated using the other two datasets and compared to four other existing FA methods. Our systematic EFA-CFA approach provided clinically more relevant solutions than other methods, resulting in new clinically relevant outcome variables that enabled a quantitative analysis. As a result, statistically significant correlations were found between some dose volume variables to relevant anatomic structures and symptom groups identified by FA.Conclusions: Our proposed method can aid in the process of understanding PROs and provide a basis for improving our understanding of radiation-induced side effects.","Oh, Jung Hun; Thor, Maria; Olsson, Caroline; Skokic, Viktor; Jornsten, Rebecka; Alsadius, David; Pettersson, Niclas; Steineck, Gunnar; Deasy, Joseph O.","Olsson, Caroline E/B-1264-2013; Steineck, Gunnar/W-1515-2019","Steineck, Gunnar/0000-0002-0787-3969; Pettersson, Niclas/0000-0003-4962-0799; Olsson, Caroline/0000-0003-3254-8903; Deasy, Joseph/0000-0002-9437-266X; Oh, Jung Hun/0000-0001-8791-2755",A Factor Analysis Approach for Clustering Patient Reported Outcomes,55,5,10.3414/ME16-01-0035 ,Article ,2016.0,"Background: In the field of radiation oncology, the use of extensive patient reported outcomes is increasingly common to measure adverse side effects after radiotherapy in cancer patients. Factor analysis has the potential to identify an optimal number of latent factors (i.e., symptom groups). However, the ultimate goal of treatment response modeling is to understand the relationship between treatment variables such as radiation dose and symptom groups resulting from FA. Hence, it is crucial to identify clinically more relevant symptom groups and improved response variables from those symptom groups for a quantitative analysis.Objectives: The goal of this study is to design a computational method for finding clinically relevant symptom groups from PROs and to test associations between symptom groups and radiation dose.Methods: We propose a novel approach where exploratory factor analysis is followed by confirmatory factor analysis to determine the relevant number of symptom groups. We also propose to use a combination of symptoms in a symptom group identified as a new response variable in linear regression analysis to investigate the relationship between the symptom group and dose-volume variables.Results: We analyzed patient-reported gastrointestinal symptom profiles from 3 datasets in prostate cancer patients treated with radiotherapy. The final structural model of each dataset was validated using the other two datasets and compared to four other existing FA methods. Our systematic EFA-CFA approach provided clinically more relevant solutions than other methods, resulting in new clinically relevant outcome variables that enabled a quantitative analysis. As a result, statistically significant correlations were found between some dose volume variables to relevant anatomic structures and symptom groups identified by FA.Conclusions: Our proposed method can aid in the process of understanding PROs and provide a basis for improving our understanding of radiation-induced side effects.",0026-1270,,,431-439, , ,,out_of_scope,
3978,"Title:ATSE: a peptide toxicity predictor by exploiting structural and evolutionary information based on graph neural network and attention mechanism

 Motivation: Peptides have recently emerged as promising therapeutic agents against various diseases. For both research and safety regulation purposes, it is of high importance to develop computational methods to accurately predict the potential toxicity of peptides within the vast number of candidate peptides. Results: In this study, we proposed ATSE, a peptide toxicity predictor by exploiting structural and evolutionary information based on graph neural networks and attention mechanism. More specifically, it consists of four modules: (i) a sequence processing module for converting peptide sequences to molecular graphs and evolutionary profiles, (ii) a feature extraction module designed to learn discriminative features from graph structural information and evolutionary information, (iii) an attention module employed to optimize the features and (iv) an output module determining a peptide as toxic or non-toxic, using optimized features from the attention module. Conclusion: Comparative studies demonstrate that the proposed ATSE significantly outperforms all other competing methods. We found that structural information is complementary to the evolutionary information, effectively improving the predictive performance. Importantly, the data-driven features learned by ATSE can be interpreted and visualized, providing additional information for further analysis. Moreover, we present a user-friendly online computational platform that implements the proposed ATSE, which is now available at http://server.malab.cn/ATSE . We expect that it can be a powerful and useful tool for researchers of interest.","Wei, Lesong; Ye, Xiucai; Xue, Yuyang; Sakurai, Tetsuya; Wei, Leyi","Wei, Leyi/Q-5699-2018","Wei, Leyi/0000-0003-1444-190X; Xue, Yuyang/0000-0002-2281-9418",ATSE: a peptide toxicity predictor by exploiting structural and evolutionary information based on graph neural network and attention mechanism,22,5,10.1093/bib/bbab041 ,Article ,2021.0,"Motivation: Peptides have recently emerged as promising therapeutic agents against various diseases. For both research and safety regulation purposes, it is of high importance to develop computational methods to accurately predict the potential toxicity of peptides within the vast number of candidate peptides. Results: In this study, we proposed ATSE, a peptide toxicity predictor by exploiting structural and evolutionary information based on graph neural networks and attention mechanism. More specifically, it consists of four modules: (i) a sequence processing module for converting peptide sequences to molecular graphs and evolutionary profiles, (ii) a feature extraction module designed to learn discriminative features from graph structural information and evolutionary information, (iii) an attention module employed to optimize the features and (iv) an output module determining a peptide as toxic or non-toxic, using optimized features from the attention module. Conclusion: Comparative studies demonstrate that the proposed ATSE significantly outperforms all other competing methods. We found that structural information is complementary to the evolutionary information, effectively improving the predictive performance. Importantly, the data-driven features learned by ATSE can be interpreted and visualized, providing additional information for further analysis. Moreover, we present a user-friendly online computational platform that implements the proposed ATSE, which is now available at http://server.malab.cn/ATSE . We expect that it can be a powerful and useful tool for researchers of interest.",1467-5463,1477-4054,,, , ,,out_of_scope,
3979,"Title:Spans Detection of Toxic Phrases in Arabic Tweets

 In this paper, we investigate and develop different techniques and deep learning models to detect the spans of characters within an Arabic content that drive a model to classify it as being toxic. Incorporating a model capable of providing such a detailed output into an automated toxicity detection system would significantly reduce the amount of time required to investigate measures taken by automated systems against contents classified as toxic. The dataset used in this study contains 1800 tweets and was originally used for sentiment analysis, however it was re-annotated on the character level to match the requirements of this work. The proposed approach has achieved 0.8289 on the modified F1-score metric and is based on both word2vec word embeddings and BERT-base pooled embeddings. To our knowledge, this is the first effort aiming at approaching this task in Arabic contents.","Radman, Azzam; Atros, Mohammed; Duwairi, Rehab",,,Spans Detection of Toxic Phrases in Arabic Tweets,,,10.1109/ICICS55353.2022.9811228 ,Proceedings Paper ,2022.0,"In this paper, we investigate and develop different techniques and deep learning models to detect the spans of characters within an Arabic content that drive a model to classify it as being toxic. Incorporating a model capable of providing such a detailed output into an automated toxicity detection system would significantly reduce the amount of time required to investigate measures taken by automated systems against contents classified as toxic. The dataset used in this study contains 1800 tweets and was originally used for sentiment analysis, however it was re-annotated on the character level to match the requirements of this work. The proposed approach has achieved 0.8289 on the modified F1-score metric and is based on both word2vec word embeddings and BERT-base pooled embeddings. To our knowledge, this is the first effort aiming at approaching this task in Arabic contents.",2471-125X,,978-1-6654-8097-0,315-320, , 13th International Conference on Information and Communication Systems (ICICS)13th International Conference on Information and Communication Systems (ICICS),,Gen_dataset#detection#out_but_toxicity,
3980,"Title:Maximum likelihood inference for multivariate frailty models using an automated Monte Carlo EM algorithm

 We present a maximum likelihood estimation procedure for the multivariate frailty model. The estimation is based on a Monte Carlo EM algorithm. The expectation step is approximated by averaging over random samples drawn from the posterior distribution of the frailties using rejection sampling. The maximization step reduces to a standard partial likelihood maximization. We also propose a simple rule based on the relative change in the parameter estimates to decide on sample size in each iteration and a stopping time for the algorithm. An important new concept is acquiring absolute convergence of the algorithm through sample size determination and an efficient sampling technique. The method is illustrated using a rat carcinogenesis dataset and data on vase lifetimes of cut roses. The estimation results are compared with approximate inference based on penalized partial likelihood using these two examples. Unlike the penalized partial likelihood estimation, the proposed full maximum likelihood estimation method accounts for all the uncertainty while estimating standard errors for the parameters.","Ripatti, S; Larsen, K; Palmgren, J","Ripatti, Samuli/H-9446-2014","Ripatti, Samuli/0000-0002-0504-1202; Palmgren, Juni/0000-0002-9031-8615",Maximum likelihood inference for multivariate frailty models using an automated Monte Carlo EM algorithm,8,4,10.1023/A:1020566821163 ,Article ,2002.0,"We present a maximum likelihood estimation procedure for the multivariate frailty model. The estimation is based on a Monte Carlo EM algorithm. The expectation step is approximated by averaging over random samples drawn from the posterior distribution of the frailties using rejection sampling. The maximization step reduces to a standard partial likelihood maximization. We also propose a simple rule based on the relative change in the parameter estimates to decide on sample size in each iteration and a stopping time for the algorithm. An important new concept is acquiring absolute convergence of the algorithm through sample size determination and an efficient sampling technique. The method is illustrated using a rat carcinogenesis dataset and data on vase lifetimes of cut roses. The estimation results are compared with approximate inference based on penalized partial likelihood using these two examples. Unlike the penalized partial likelihood estimation, the proposed full maximum likelihood estimation method accounts for all the uncertainty while estimating standard errors for the parameters.",1380-7870,1572-9249,,349-360, , ,,out_of_scope,
3981,"Title:Transcriptional Responses to Ultraviolet and Ionizing Radiation: An Approach Based on Graph Curvature

 More than half of all cancer patients receive radiotherapy in their treatment process. However, our understanding of abnormal transcriptional responses to radiation remains poor. In this study, we employ an extended definition of Ollivier-Ricci curvature based on LI-Wasserstein distance to investigate genes and biological processes associated with ionizing radiation (IR) and ultraviolet radiation (UV) exposure using a microarray dataset. Gene expression levels were modeled on a gene interaction topology downloaded from the Human Protein Reference Database (HPRD). This was performed for IR, UV, and mock datasets, separately. The difference curvature value between IR and mock graphs (also between UV and mock) for each gene was used as a metric to estimate the extent to which the gene responds to radiation. We found that in comparison of the top 200 genes identified from IR and UV graphs, about 20 similar to 30% genes were overlapping. Through gene ontology enrichment analysis, we found that the metabolic-related biological process was highly associated with both IR and UV radiation exposure.","Chen, Yongxin; Oh, Jung Hun; Sandhu, Romeil; Lee, Sangkyu; Deasy, Joseph O.; Tannenbaum, Allen",,"Oh, Jung Hun/0000-0001-8791-2755; Deasy, Joseph/0000-0002-9437-266X",Transcriptional Responses to Ultraviolet and Ionizing Radiation: An Approach Based on Graph Curvature,,, ,Proceedings Paper ,2016.0,"More than half of all cancer patients receive radiotherapy in their treatment process. However, our understanding of abnormal transcriptional responses to radiation remains poor. In this study, we employ an extended definition of Ollivier-Ricci curvature based on LI-Wasserstein distance to investigate genes and biological processes associated with ionizing radiation (IR) and ultraviolet radiation (UV) exposure using a microarray dataset. Gene expression levels were modeled on a gene interaction topology downloaded from the Human Protein Reference Database (HPRD). This was performed for IR, UV, and mock datasets, separately. The difference curvature value between IR and mock graphs (also between UV and mock) for each gene was used as a metric to estimate the extent to which the gene responds to radiation. We found that in comparison of the top 200 genes identified from IR and UV graphs, about 20 similar to 30% genes were overlapping. Through gene ontology enrichment analysis, we found that the metabolic-related biological process was highly associated with both IR and UV radiation exposure.",2156-1125,2156-1133,978-1-5090-1610-5,1302-1306, , IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM)IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM),,out_of_scope,
3982,"Title:Audio-based Toxic Language Classification using Self-attentive Convolutional Neural Network

 The monumental increase in online social interaction activities such as social networking or online gaming is often riddled by hostile or aggressive behavior that can lead to unsolicited manifestations of cyberbullying or harassment. In this work, we develop an audio-based toxic language classifier using self-attentive Convolutional Neural Networks (CNNs). As definitions of hostility or toxicity can vary depending on the platform or application, in this work we take a more general approach for identifying toxic utterances, one that does not depend on individual lexicon terms, but rather considers the entire acoustical context of the short verse or utterance. In the proposed architecture, the self-attention mechanism captures the temporal dependency of the verbal content by summarizing all the relevant information from different regions of the utterance. The proposed audio-based self-attentive CNN model is evaluated on a public and an internal dataset and achieves 75% accuracy, 79% precision, and 80% recall in identifying toxic speech recordings.","Yousefi, Midia; Emmanouilidou, Dimitra",,,Audio-based Toxic Language Classification using Self-attentive Convolutional Neural Network,,, ,Proceedings Paper ,2021.0,"The monumental increase in online social interaction activities such as social networking or online gaming is often riddled by hostile or aggressive behavior that can lead to unsolicited manifestations of cyberbullying or harassment. In this work, we develop an audio-based toxic language classifier using self-attentive Convolutional Neural Networks (CNNs). As definitions of hostility or toxicity can vary depending on the platform or application, in this work we take a more general approach for identifying toxic utterances, one that does not depend on individual lexicon terms, but rather considers the entire acoustical context of the short verse or utterance. In the proposed architecture, the self-attention mechanism captures the temporal dependency of the verbal content by summarizing all the relevant information from different regions of the utterance. The proposed audio-based self-attentive CNN model is evaluated on a public and an internal dataset and achieves 75% accuracy, 79% precision, and 80% recall in identifying toxic speech recordings.",2076-1465,,978-9-0827-9706-0,11-15, , 29th European Signal Processing Conference (EUSIPCO)29th European Signal Processing Conference (EUSIPCO),,detection#out_but_toxicity,
3983,"Title:Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training

 Prior work on Data-To-Text Generation, the task of converting knowledge graph (KG) triples into natural text, focused on domain-specific benchmark datasets. In this paper, however, we verbalize the entire English Wiki-data KG, and discuss the unique challenges associated with a broad, open-domain, large-scale verbalization. We further show that verbalizing a comprehensive, encyclopedic KG like Wiki-data can be used to integrate structured KGs and natural language corpora. In contrast to the many architectures that have been developed to integrate these two sources, our approach converts the KG into natural text, allowing it to be seamlessly integrated into existing language models. It carries the further advantages of improved factual accuracy and reduced toxicity in the resulting language model. We evaluate this approach by augmenting the retrieval corpus in a retrieval language model and showing significant improvements on the knowledge intensive tasks of open domain QA and the LAMA knowledge probe.","Agarwal, Oshin; Ge, Heming; Shakeri, Siamak; Al-Rfou, Rami",,,Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training,,, ,Proceedings Paper ,2021.0,"Prior work on Data-To-Text Generation, the task of converting knowledge graph (KG) triples into natural text, focused on domain-specific benchmark datasets. In this paper, however, we verbalize the entire English Wiki-data KG, and discuss the unique challenges associated with a broad, open-domain, large-scale verbalization. We further show that verbalizing a comprehensive, encyclopedic KG like Wiki-data can be used to integrate structured KGs and natural language corpora. In contrast to the many architectures that have been developed to integrate these two sources, our approach converts the KG into natural text, allowing it to be seamlessly integrated into existing language models. It carries the further advantages of improved factual accuracy and reduced toxicity in the resulting language model. We evaluate this approach by augmenting the retrieval corpus in a retrieval language model and showing significant improvements on the knowledge intensive tasks of open domain QA and the LAMA knowledge probe.",,,978-1-954085-46-6,3554-3565, , Conference of the North-American-Chapter of the Association-for-Computational-Linguistics - Human Language Technologies (NAACL-HLT)Conference of the North-American-Chapter of the Association-for-Computational-Linguistics - Human Language Technologies (NAACL-HLT),,detox#methodology,
3984,"Title:Measuring and Mitigating Unintended Bias in Text Classification

 We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our definition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.","Dixon, Lucas; Li, John; Sorensen, Jeffrey; Thain, Nithum; Vasserman, Lucy","Sorensen, Jeffrey/GRE-9983-2022; Dixon, Lucas/AFL-2608-2022",,Measuring and Mitigating Unintended Bias in Text Classification,,,10.1145/3278721.3278729 ,Proceedings Paper ,2018.0,"We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our definition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.",,,978-1-4503-6012-8,67-73, ," AAAI/ACM Conference on AI, Ethics, and Society (AIES)AAAI/ACM Conference on AI, Ethics, and Society (AIES)",,Use_dataset#evaluation,
3985,"Title:Civil Rephrases Of Toxic Texts With Self-Supervised Transformers

 Platforms that support online commentary, from social networks to news sites, are increasingly leveraging machine learning to assist their moderation efforts. But this process does not typically provide feedback to the author that would help them contribute according to the community guidelines. This is prohibitively time-consuming for human moderators to do, and computational approaches are still nascent. This work focuses on models that can help suggest rephrasings of toxic comments in a more civil manner. Inspired by recent progress in unpaired sequence-to-sequence tasks, a self-supervised learning model is introduced, called CAE-T5(1). CAE-T5 employs a pre-trained text-to-text transformer, which is fine tuned with a denoising and cyclic auto-encoder loss. Experimenting with the largest toxicity detection dataset to date (Civil Comments) our model generates sentences that are more fluent and better at preserving the initial content compared to earlier text style transfer systems which we compare with using several scoring systems and human evaluation.","Laugier, Leo; Pavlopoulos, John; Sorensen, Jeffrey; Dixon, Lucas","Dixon, Lucas/AFL-2608-2022",,Civil Rephrases Of Toxic Texts With Self-Supervised Transformers,,, ,Proceedings Paper ,2021.0,"Platforms that support online commentary, from social networks to news sites, are increasingly leveraging machine learning to assist their moderation efforts. But this process does not typically provide feedback to the author that would help them contribute according to the community guidelines. This is prohibitively time-consuming for human moderators to do, and computational approaches are still nascent. This work focuses on models that can help suggest rephrasings of toxic comments in a more civil manner. Inspired by recent progress in unpaired sequence-to-sequence tasks, a self-supervised learning model is introduced, called CAE-T5(1). CAE-T5 employs a pre-trained text-to-text transformer, which is fine tuned with a denoising and cyclic auto-encoder loss. Experimenting with the largest toxicity detection dataset to date (Civil Comments) our model generates sentences that are more fluent and better at preserving the initial content compared to earlier text style transfer systems which we compare with using several scoring systems and human evaluation.",,,978-1-954085-02-2,1442-1461, , 16th Conference of the European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)16th Conference of the European-Chapter-of-the-Association-for-Computational-Linguistics (EACL),,detox#methodology,
3986,"Title:Exploring genetic influences on adverse outcome pathways using heuristic simulation and graph data science

 Adverse outcome pathways provide a powerful tool for understanding the biological signaling cascades that lead to disease outcomes following toxicity. The framework outlines downstream responses known as key events, culminating in a clinically significant adverse outcome as a final result of the toxic exposure. Here we use the AOP framework combined with artificial intelligence methods to gain novel insights into genetic mechanisms that underlie toxicity-mediated adverse health outcomes. Specifically, we focus on liver cancer as a case study with diverse underlying mechanisms that are clinically significant. Our approach uses two complementary AI techniques: Generative modeling via automated machine learning and genetic algorithms, and graph machine learning. We used data from the US Environmental Protection Agency's Adverse Outcome Pathway Database (AOP-DB; aopdb.epa.gov) and the UK Biobank's genetic data repository. We use the AOP-DB to extract disease-specific AOPs and build graph neural networks used in our final analyses. We use the UK Biobank to retrieve real-world genotype and phenotype data, where genotypes are based on single nucleotide polymorphism data extracted from the AOP-DB, and phenotypes are case/control cohorts for the disease of interest (liver cancer) corresponding to those adverse outcome pathways. We also use propensity score matching to appropriately sample based on important covariates (demographics, comorbidities, and social deprivation indices) and to balance the case and control populations in our machine language training/testing datasets. Finally, we describe a novel putative risk factor for LC that depends on genetic variation in both the aryl-hydrocarbon receptor (AHR) and ATP binding cassette subfamily B member 11 (ABCB11) genes.","Romano, Joseph D.; Mei, Liang; Senn, Jonathan; Moore, Jason H.; Mortensen, Holly M.","Rasga, Celia Maria/IZE-6627-2023","Rasga, Celia Maria/0000-0002-9969-6241",Exploring genetic influences on adverse outcome pathways using heuristic simulation and graph data science,25,,10.1016/j.comtox.2023.100261 ,Article ,2023.0,"Adverse outcome pathways provide a powerful tool for understanding the biological signaling cascades that lead to disease outcomes following toxicity. The framework outlines downstream responses known as key events, culminating in a clinically significant adverse outcome as a final result of the toxic exposure. Here we use the AOP framework combined with artificial intelligence methods to gain novel insights into genetic mechanisms that underlie toxicity-mediated adverse health outcomes. Specifically, we focus on liver cancer as a case study with diverse underlying mechanisms that are clinically significant. Our approach uses two complementary AI techniques: Generative modeling via automated machine learning and genetic algorithms, and graph machine learning. We used data from the US Environmental Protection Agency's Adverse Outcome Pathway Database (AOP-DB; aopdb.epa.gov) and the UK Biobank's genetic data repository. We use the AOP-DB to extract disease-specific AOPs and build graph neural networks used in our final analyses. We use the UK Biobank to retrieve real-world genotype and phenotype data, where genotypes are based on single nucleotide polymorphism data extracted from the AOP-DB, and phenotypes are case/control cohorts for the disease of interest (liver cancer) corresponding to those adverse outcome pathways. We also use propensity score matching to appropriately sample based on important covariates (demographics, comorbidities, and social deprivation indices) and to balance the case and control populations in our machine language training/testing datasets. Finally, we describe a novel putative risk factor for LC that depends on genetic variation in both the aryl-hydrocarbon receptor (AHR) and ATP binding cassette subfamily B member 11 (ABCB11) genes.",2468-1113,,,, , ,,out_of_scope,
3987,"Title:De novo transcriptome assembly of fluorine accumulator tea plant Camellia sinensis with fluoride treatments

 Tea plant (Camellia sinensis) is a typical fluoride (F) hyperaccumulator enriching most F in old leaves. There is association between the risk of fluorosis and excessive consumption of teas prepared using the old leaves. It is meaningful to develop methods for controlling F levels in tea leaves. We generated a comprehensive RNA-seq dataset from tea plants grown at various F levels for different durations by hydroponics, aiming at providing information on mechanism of F metabolism in tea plant. Besides raw reads of the RNA-seq dataset, we present assembled unigenes and aligned unigenes with annotations versus the Gene Ontology (GO) databases, Kyoto Encyclopaedia of Genes and Genomes (KEGG) databases, and Nonredundant (Nr) protein databases with low e-values. 69,488 unigenes were obtained in total, in which 40,894 were given Nr annotations.","Li, Qing-Sheng; Li, Xu-Min; Qiao, Ru-Ying; Shen, En-Hui; Lin, Xiao-Ming; Lu, Jian-Liang; Ye, Jian-Hui; Liang, Yue-Rong; Zheng, Xin-Qiang","Zhao, Xuan/JMR-2135-2023; , jllu/GZL-3912-2022","Li, Qing-sheng/0000-0003-0307-1261",De novo transcriptome assembly of fluorine accumulator tea plant Camellia sinensis with fluoride treatments,5,,10.1038/sdata.2018.194 ,Article; Data Paper ,2018.0,"Tea plant (Camellia sinensis) is a typical fluoride (F) hyperaccumulator enriching most F in old leaves. There is association between the risk of fluorosis and excessive consumption of teas prepared using the old leaves. It is meaningful to develop methods for controlling F levels in tea leaves. We generated a comprehensive RNA-seq dataset from tea plants grown at various F levels for different durations by hydroponics, aiming at providing information on mechanism of F metabolism in tea plant. Besides raw reads of the RNA-seq dataset, we present assembled unigenes and aligned unigenes with annotations versus the Gene Ontology (GO) databases, Kyoto Encyclopaedia of Genes and Genomes (KEGG) databases, and Nonredundant (Nr) protein databases with low e-values. 69,488 unigenes were obtained in total, in which 40,894 were given Nr annotations.",,2052-4463,,, , ,,out_of_scope,
3988,"Title:Development of valuable predictive read-across models based on real-life (sparse) nanotoxicity data

 In view of the rapidly growing number of synthesized nanoparticles as well as public concerns about their potential negative impacts on human health and the environment, there is an urgent need to address current risk assessment data gaps. Thus, the development of comprehensive computational methods (e.g., read-across methods) for filling data gaps that meet realistic data needs is crucial. The present study proposes a new quantitative read-across approach based on linear algebra (i.e., one/two-point-slope formula) and one of the most widely used unsupervised pattern recognition methods (i.e., principal component analysis). The applicability and usefulness of the newly developed read-across algorithm for pre-screening hazard assessment of nanomaterials are confirmed by using three literature nanotoxicity datasets. The findings from this study clearly indicate that the proposed read-across approach provides reasonably accurate and statistically significant results of estimations of nanotoxicity data. Therefore, the method can be used for prioritizing current and future nanoparticles for the purpose of further testing and risk assessment.","Gajewicz, A.",,"Gajewicz, Agnieszka/0000-0001-7702-210X",Development of valuable predictive read-across models based on real-life (sparse) nanotoxicity data,4,6,10.1039/c7en00102a ,Article ,2017.0,"In view of the rapidly growing number of synthesized nanoparticles as well as public concerns about their potential negative impacts on human health and the environment, there is an urgent need to address current risk assessment data gaps. Thus, the development of comprehensive computational methods (e.g., read-across methods) for filling data gaps that meet realistic data needs is crucial. The present study proposes a new quantitative read-across approach based on linear algebra (i.e., one/two-point-slope formula) and one of the most widely used unsupervised pattern recognition methods (i.e., principal component analysis). The applicability and usefulness of the newly developed read-across algorithm for pre-screening hazard assessment of nanomaterials are confirmed by using three literature nanotoxicity datasets. The findings from this study clearly indicate that the proposed read-across approach provides reasonably accurate and statistically significant results of estimations of nanotoxicity data. Therefore, the method can be used for prioritizing current and future nanoparticles for the purpose of further testing and risk assessment.",2051-8153,2051-8161,,1389-1403, , ,,out_of_scope,
3989,"Title:Complementary PLS and KNN algorithms for improved 3D-QSDAR consensus modeling of AhR binding

 Multiple validation techniques (Y-scrambling, complete training/test set randomization, determination of the dependence of R-test(2) on the number of randomization cycles, etc.) aimed to improve the reliability of the modeling process were utilized and their effect on the statistical parameters of the models was evaluated. A consensus partial least squares (PLS)-similarity based k-nearest neighbors (KNN) model utilizing 3D-SDAR (three dimensional spectral data-activity relationship) fingerprint descriptors for prediction of the log(1/EC50) values of a dataset of 94 aryl hydrocarbon receptor binders was developed. This consensus model was constructed from a PLS model utilizing 10 ppm x 10 ppm x 0.5 angstrom bins and 7 latent variables (R-test(2) of 0.617), and a KNN model using 2 ppm x 2 ppm x 0.5 angstrom bins and 6 neighbors (R-test(2) of 0.622). Compared to individual models, improvement in predictive performance of approximately 10.5% (R-test(2) of 0.685) was observed. Further experiments indicated that this improvement is likely an outcome of the complementarity of the information contained in 3D-SDAR matrices of different granularity. For similarly sized data sets of Aryl hydrocarbon (AhR) binders the consensus KNN and PLS models compare favorably to earlier reports. The ability of 3D-QSDAR (three dimensional quantitative spectral data-activity relationship) to provide structural interpretation was illustrated by a projection of the most frequently occurring bins on the standard coordinate space, thus allowing identification of structural features related to toxicity.","Slavov, Svetoslav H.; Pearce, Bruce A.; Buzatu, Dan A.; Wilkes, Jon G.; Beger, Richard D.",,,Complementary PLS and KNN algorithms for improved 3D-QSDAR consensus modeling of AhR binding,5,,10.1186/1758-2946-5-47 ,Article ,2013.0,"Multiple validation techniques (Y-scrambling, complete training/test set randomization, determination of the dependence of R-test(2) on the number of randomization cycles, etc.) aimed to improve the reliability of the modeling process were utilized and their effect on the statistical parameters of the models was evaluated. A consensus partial least squares (PLS)-similarity based k-nearest neighbors (KNN) model utilizing 3D-SDAR (three dimensional spectral data-activity relationship) fingerprint descriptors for prediction of the log(1/EC50) values of a dataset of 94 aryl hydrocarbon receptor binders was developed. This consensus model was constructed from a PLS model utilizing 10 ppm x 10 ppm x 0.5 angstrom bins and 7 latent variables (R-test(2) of 0.617), and a KNN model using 2 ppm x 2 ppm x 0.5 angstrom bins and 6 neighbors (R-test(2) of 0.622). Compared to individual models, improvement in predictive performance of approximately 10.5% (R-test(2) of 0.685) was observed. Further experiments indicated that this improvement is likely an outcome of the complementarity of the information contained in 3D-SDAR matrices of different granularity. For similarly sized data sets of Aryl hydrocarbon (AhR) binders the consensus KNN and PLS models compare favorably to earlier reports. The ability of 3D-QSDAR (three dimensional quantitative spectral data-activity relationship) to provide structural interpretation was illustrated by a projection of the most frequently occurring bins on the standard coordinate space, thus allowing identification of structural features related to toxicity.",1758-2946,,,, , ,,out_of_scope,
3990,"Title:EVILSEED: A Guided Approach to Finding Malicious Web Pages

 Malicious web pages that use drive-by download attacks or social engineering techniques to install unwanted software on a user's computer have become the main avenue for the propagation of malicious code. To search for malicious web pages, the first step is typically to use a crawler to collect URLs that are live on the Internet. Then, fast prefiltering techniques are employed to reduce the amount of pages that need to be examined by more precise, but slower, analysis tools (such as honeyclients). While effective, these techniques require a substantial amount of resources. A key reason is that the crawler encounters many pages on the web that are benign, that is, the toxicity of the stream of URLs being analyzed is low.In this paper, we present EVILSEED, an approach to search the web more efficiently for pages that are likely malicious. EVILSEED starts from an initial seed of known, malicious web pages. Using this seed, our system automatically generates search engines queries to identify other malicious pages that are similar or related to the ones in the initial seed. By doing so, EVILSEED leverages the crawling infrastructure of search engines to retrieve URLs that are much more likely to be malicious than a random page on the web. In other words EVILSEED increases the toxicity of the input URL stream. Also, we envision that the features that EVILSEED presents could be directly applied by search engines in their prefilters. We have implemented our approach, and we evaluated it on a large-scale dataset. The results show that EVILSEED is able to identify malicious web pages more efficiently when compared to crawler-based approaches.","Invernizzi, Luca; Comparetti, Paolo Milani; Benvenuti, Stefano; Kruegel, Christopher; Cova, Marco; Vigna, Giovanni","Invernizzi, Luca/Y-3210-2019",,EVILSEED: A Guided Approach to Finding Malicious Web Pages,,,10.1109/SP.2012.33 ,Proceedings Paper ,2012.0,"Malicious web pages that use drive-by download attacks or social engineering techniques to install unwanted software on a user's computer have become the main avenue for the propagation of malicious code. To search for malicious web pages, the first step is typically to use a crawler to collect URLs that are live on the Internet. Then, fast prefiltering techniques are employed to reduce the amount of pages that need to be examined by more precise, but slower, analysis tools (such as honeyclients). While effective, these techniques require a substantial amount of resources. A key reason is that the crawler encounters many pages on the web that are benign, that is, the toxicity of the stream of URLs being analyzed is low.In this paper, we present EVILSEED, an approach to search the web more efficiently for pages that are likely malicious. EVILSEED starts from an initial seed of known, malicious web pages. Using this seed, our system automatically generates search engines queries to identify other malicious pages that are similar or related to the ones in the initial seed. By doing so, EVILSEED leverages the crawling infrastructure of search engines to retrieve URLs that are much more likely to be malicious than a random page on the web. In other words EVILSEED increases the toxicity of the input URL stream. Also, we envision that the features that EVILSEED presents could be directly applied by search engines in their prefilters. We have implemented our approach, and we evaluated it on a large-scale dataset. The results show that EVILSEED is able to identify malicious web pages more efficiently when compared to crawler-based approaches.",1081-6011,,978-0-7695-4681-0,428-442, , 33rd IEEE Symposium on Security and Privacy (SP)33rd IEEE Symposium on Security and Privacy (SP),,out_of_scope,
3991,"Title:Development of a 3D CNN-based AI Model for Automated Segmentation of the Prostatic Urethra

 Rationale and Objective: The combined use of prostate cancer radiotherapy and MRI planning is increasingly being used in the treatment of clinically significant prostate cancers. The radiotherapy dosage quantity is limited by toxicity in organs with de-novo genitourinary toxicity occurrence remaining unperturbed. Estimation of the urethral radiation dose via anatomical contouring may improve our understanding of genitourinary toxicity and its related symptoms. Yet, urethral delineation remains an expert-dependent and time-consuming procedure. In this study, we aim to develop a fully automated segmentation tool for the prostatic urethra.Materials and Methods: This study incorporated 939 patients' T2-weighted MRI scans (train/validation/test/excluded: 657/141/140/1 patients), including in-house and public PROSTATE-x datasets, and their corresponding ground truth urethral contours from an expert genitourinary radiologist. The AI model was developed using MONAI framework and was based on a 3D-UNet. AI model performance was determined by Dice score (volume-based) and the Centerline Distance (CLD) between the prediction and ground truth centers (slice-based). All predictions were compared to ground truth in a systematic failure analysis to elucidate the model's strengths and weaknesses. The Wilcoxon-rank sum test was used for pair-wise comparison of group differences.Results: The overall organ-adjusted Dice score for this model was 0.61 and overall CLD was 2.56 mm. When comparing prostates with symmetrical (n = 117) and asymmetrical (n = 23) benign prostate hyperplasia (BPH), the AI model performed better on symmetrical prostates compared to asymmetrical in both Dice score (0.64 vs. 0.51 respectively, p < 0.05) and mean CLD (2.3 mm vs. 3.8 mm respectively, p < 0.05). When calculating location-specific performance, the performance was highest at the apex and lowest at the base location of the prostate for Dice and CLD. Dice location dependence: symmetrical (Apex, Mid, Base: 0.69 vs. 0.67 vs. 0.54 respectively, p < 0.05) and asymmetrical (Apex, Mid, Base: 0.68 vs. 0.52 vs. 0.39 respectively, p < 0.05). CLD location dependence: symmetrical (Apex, Mid, Base: 1.43 mm vs. 2.15 mm vs. 3.28 mm, p < 0.05) and asymmetrical (Apex, Mid, Base: 1.83 mm vs. 3.1 mm vs. 6.24 mm, p < 0.05).Conclusion: We developed a fully automated prostatic urethra segmentation AI tool yielding its best performance in prostate glands with symmetric BPH features. This system can potentially be used to assist treatment planning in patients who can undergo whole gland radiation therapy or ablative focal therapy.","Belue, Mason J.; Harmon, Stephanie A.; Patel, Krishnan; Daryanani, Asha; Yilmaz, Enis Cagatay; Pinto, Peter A.; Wood, Bradford J.; Citrin, Deborah E.; Choyke, Peter L.; Turkbey, Baris","Patel, Krishnan/HMV-7587-2023; Wood, Bradford Johns/M-7995-2017","Wood, Bradford Johns/0000-0002-4297-0051; Citrin, Deborah/0000-0002-4391-2734; Yilmaz, Enis Cagatay/0000-0001-5301-3137; Patel, Krishnan/0000-0003-2120-1939",Development of a 3D CNN-based AI Model for Automated Segmentation of the Prostatic Urethra,29,9,10.1016/j.acra.2022.01.009 ,Article ,2022.0,"Rationale and Objective: The combined use of prostate cancer radiotherapy and MRI planning is increasingly being used in the treatment of clinically significant prostate cancers. The radiotherapy dosage quantity is limited by toxicity in organs with de-novo genitourinary toxicity occurrence remaining unperturbed. Estimation of the urethral radiation dose via anatomical contouring may improve our understanding of genitourinary toxicity and its related symptoms. Yet, urethral delineation remains an expert-dependent and time-consuming procedure. In this study, we aim to develop a fully automated segmentation tool for the prostatic urethra.Materials and Methods: This study incorporated 939 patients' T2-weighted MRI scans (train/validation/test/excluded: 657/141/140/1 patients), including in-house and public PROSTATE-x datasets, and their corresponding ground truth urethral contours from an expert genitourinary radiologist. The AI model was developed using MONAI framework and was based on a 3D-UNet. AI model performance was determined by Dice score (volume-based) and the Centerline Distance (CLD) between the prediction and ground truth centers (slice-based). All predictions were compared to ground truth in a systematic failure analysis to elucidate the model's strengths and weaknesses. The Wilcoxon-rank sum test was used for pair-wise comparison of group differences.Results: The overall organ-adjusted Dice score for this model was 0.61 and overall CLD was 2.56 mm. When comparing prostates with symmetrical (n = 117) and asymmetrical (n = 23) benign prostate hyperplasia (BPH), the AI model performed better on symmetrical prostates compared to asymmetrical in both Dice score (0.64 vs. 0.51 respectively, p < 0.05) and mean CLD (2.3 mm vs. 3.8 mm respectively, p < 0.05). When calculating location-specific performance, the performance was highest at the apex and lowest at the base location of the prostate for Dice and CLD. Dice location dependence: symmetrical (Apex, Mid, Base: 0.69 vs. 0.67 vs. 0.54 respectively, p < 0.05) and asymmetrical (Apex, Mid, Base: 0.68 vs. 0.52 vs. 0.39 respectively, p < 0.05). CLD location dependence: symmetrical (Apex, Mid, Base: 1.43 mm vs. 2.15 mm vs. 3.28 mm, p < 0.05) and asymmetrical (Apex, Mid, Base: 1.83 mm vs. 3.1 mm vs. 6.24 mm, p < 0.05).Conclusion: We developed a fully automated prostatic urethra segmentation AI tool yielding its best performance in prostate glands with symmetric BPH features. This system can potentially be used to assist treatment planning in patients who can undergo whole gland radiation therapy or ablative focal therapy.",1076-6332,1878-4046,,1404-1412, , ,,out_of_scope,
3992,"Title:Hierarchical Reinforcement Learning for Open-Domain Dialog

 Open-domain dialog generation is a challenging problem; maximum likelihood training can lead to repetitive outputs, models have difficulty tracking long-term conversational goals, and training on standard movie or online datasets may lead to the generation of inappropriate, biased, or offensive text. Reinforcement Learning (RL) is a powerful framework that could potentially address these issues, for example by allowing a dialog model to optimize for reducing toxicity and repetitiveness. However, previous approaches which apply RL to open-domain dialog generation do so at the word level, making it difficult for the model to learn proper credit assignment for long-term conversational rewards. In this paper, we propose a novel approach to hierarchical reinforcement learning (HRL), VHRL, which uses policy gradients to tune the utterance-level embedding of a variational sequence model. This hierarchical approach provides greater flexibility for learning long-term, conversational rewards. We use self-play and RL to optimize for a set of human-centered conversation metrics, and show that our approach provides significant improvements - in terms of both human evaluation and automatic metrics - over state-of-the-art dialog models, including Transformers.","Saleh, Abdelrhman; Jaques, Natasha; Ghandeharioun, Asma; Shen, Judy Hanwen; Picard, Rosalind",,"Jaques, Natasha/0000-0002-8413-9469",Hierarchical Reinforcement Learning for Open-Domain Dialog,34,, ,Proceedings Paper ,2020.0,"Open-domain dialog generation is a challenging problem; maximum likelihood training can lead to repetitive outputs, models have difficulty tracking long-term conversational goals, and training on standard movie or online datasets may lead to the generation of inappropriate, biased, or offensive text. Reinforcement Learning (RL) is a powerful framework that could potentially address these issues, for example by allowing a dialog model to optimize for reducing toxicity and repetitiveness. However, previous approaches which apply RL to open-domain dialog generation do so at the word level, making it difficult for the model to learn proper credit assignment for long-term conversational rewards. In this paper, we propose a novel approach to hierarchical reinforcement learning (HRL), VHRL, which uses policy gradients to tune the utterance-level embedding of a variational sequence model. This hierarchical approach provides greater flexibility for learning long-term, conversational rewards. We use self-play and RL to optimize for a set of human-centered conversation metrics, and show that our approach provides significant improvements - in terms of both human evaluation and automatic metrics - over state-of-the-art dialog models, including Transformers.",2159-5399,2374-3468,978-1-57735-835-0,8741-8748, , 34th AAAI Conference on Artificial Intelligence / 32nd Innovative Applications of Artificial Intelligence Conference / 10th AAAI Symposium on Educational Advances in Artificial Intelligence34th AAAI Conference on Artificial Intelligence / 32nd Innovative Applications of Artificial Intelligence Conference / 10th AAAI Symposium on Educational Advances in Artificial Intelligence,,detox#methodology,
3993,"Title:A Multitask Approach to Learn Molecular Properties

 The endeavors to pursue a robust multitask model to resolve intertask correlations have lasted for many years. A multitask deep neural network, as the most widely used multitask framework, however, experiences several issues such as inconsistent performance improvement over the independent model benchmark. The research aims to introduce an alternative framework by using the problem transformation methods. We build our multitask models essentially based on the stacking of a base regressor and classifier, where the multitarget predictions are realized from an additional training stage on the expanded molecular feature space. The model architecture is implemented on the QM9, Alchemy, and Tox21 datasets, by using a variety of baseline machine learning techniques. The resultant multitask performance shows 1 to 10% enhancement of forecasting precision, with the task prediction accuracy being consistently improved over the independent single-target models. The proposed method demonstrates a notable superiority in tackling the intertarget dependence and, moreover, a great potential to simulate a wide range of molecular properties under the transformation framework.","Tan, Zheng; Li, Yan; Shi, Weimei; Yang, Shiqing","Shi, Weimei/IXN-4174-2023","TAN, Zheng/0000-0001-9491-6770",A Multitask Approach to Learn Molecular Properties,61,8,10.1021/acs.jcim.1c00646 ,Article ,2021.0,"The endeavors to pursue a robust multitask model to resolve intertask correlations have lasted for many years. A multitask deep neural network, as the most widely used multitask framework, however, experiences several issues such as inconsistent performance improvement over the independent model benchmark. The research aims to introduce an alternative framework by using the problem transformation methods. We build our multitask models essentially based on the stacking of a base regressor and classifier, where the multitarget predictions are realized from an additional training stage on the expanded molecular feature space. The model architecture is implemented on the QM9, Alchemy, and Tox21 datasets, by using a variety of baseline machine learning techniques. The resultant multitask performance shows 1 to 10% enhancement of forecasting precision, with the task prediction accuracy being consistently improved over the independent single-target models. The proposed method demonstrates a notable superiority in tackling the intertarget dependence and, moreover, a great potential to simulate a wide range of molecular properties under the transformation framework.",1549-9596,1549-960X,,3824-3834, , ,,out_of_scope,
3994,"Title:Toxic Comment Detection in Online Discussions

 Comment sections of online news platforms are an essential space to express opinions and discuss political topics. In contrast to other online posts, news discussions are related to particular news articles, comments refer to each other, and individual conversations emerge. However, the misuse by spammers, haters, and trolls makes costly content moderation necessary. Sentiment analysis can not only support moderation but also help to understand the dynamics of online discussions. A subtask of content moderation is the identification of toxic comments. To this end, we describe the concept of toxicity and characterize its subclasses. Further, we present various deep learning approaches, including datasets and architectures, tailored to sentiment analysis in online discussions. One way to make these approaches more comprehensible and trustworthy is fine-grained instead of binary comment classification. On the downside, more classes require more training data. Therefore, we propose to augment training data by using transfer learning. We discuss real-world applications, such as semi-automated comment moderation and troll detection. Finally, we outline future challenges and current limitations in light of most recent research publications.","Risch, Julian; Krestel, Ralf",,"Krestel, Ralf/0000-0002-5036-8589",Toxic Comment Detection in Online Discussions,,,10.1007/978-981-15-1216-2_4 10.1007/978-981-15-1216-2,Article; Book Chapter ,2020.0,"Comment sections of online news platforms are an essential space to express opinions and discuss political topics. In contrast to other online posts, news discussions are related to particular news articles, comments refer to each other, and individual conversations emerge. However, the misuse by spammers, haters, and trolls makes costly content moderation necessary. Sentiment analysis can not only support moderation but also help to understand the dynamics of online discussions. A subtask of content moderation is the identification of toxic comments. To this end, we describe the concept of toxicity and characterize its subclasses. Further, we present various deep learning approaches, including datasets and architectures, tailored to sentiment analysis in online discussions. One way to make these approaches more comprehensible and trustworthy is fine-grained instead of binary comment classification. On the downside, more classes require more training data. Therefore, we propose to augment training data by using transfer learning. We discuss real-world applications, such as semi-automated comment moderation and troll detection. Finally, we outline future challenges and current limitations in light of most recent research publications.",2524-7565,2524-7573,978-981-15-1216-2; 978-981-15-1215-5,85-109, , ,,Use_dataset#evaluation,
3995,"Title:Neural Word Decomposition Models for Abusive Language Detection

 User generated text on social media often suffers from a lot of undesired characteristics including hatespeech, abusive language, insults etc. that are targeted to attack or abuse a specific group of people. Often such text is written differently compared to traditional text such as news involving either explicit mention of abusive words, obfuscated words and typological errors or implicit abuse i.e., indicating or targeting negative stereotypes. Thus, processing this text poses several robustness challenges when we apply natural language processing techniques developed for traditional text. For example, using word or token based models to process such text can treat two spelling variants of a word as two different words. Following recent work, we analyze how character, subword and byte pair encoding (BPE) models can be aid some of the challenges posed by user generated text. In our work, we analyze the effectiveness of each of the above techniques, compare and contrast various word decomposition techniques when used in combination with others. We experiment with finetuning large pretrained language models, and demonstrate their robustness to domain shift by studying Wikipedia attack, toxicity and Twitter hatespeech datasets.","Bodapati, Sravan Babu; Gella, Spandana; Al-Onaizan, Yaser",,,Neural Word Decomposition Models for Abusive Language Detection,,, ,Proceedings Paper ,2019.0,"User generated text on social media often suffers from a lot of undesired characteristics including hatespeech, abusive language, insults etc. that are targeted to attack or abuse a specific group of people. Often such text is written differently compared to traditional text such as news involving either explicit mention of abusive words, obfuscated words and typological errors or implicit abuse i.e., indicating or targeting negative stereotypes. Thus, processing this text poses several robustness challenges when we apply natural language processing techniques developed for traditional text. For example, using word or token based models to process such text can treat two spelling variants of a word as two different words. Following recent work, we analyze how character, subword and byte pair encoding (BPE) models can be aid some of the challenges posed by user generated text. In our work, we analyze the effectiveness of each of the above techniques, compare and contrast various word decomposition techniques when used in combination with others. We experiment with finetuning large pretrained language models, and demonstrate their robustness to domain shift by studying Wikipedia attack, toxicity and Twitter hatespeech datasets.",,,978-1-950737-43-7,135-145, , 3rd Workshop on Abusive Language Online3rd Workshop on Abusive Language Online,,evaluation,
3996,"Title:DiffCoEx: a simple and sensitive method to find differentially coexpressed gene modules

 Background: Large microarray datasets have enabled gene regulation to be studied through coexpression analysis. While numerous methods have been developed for identifying differentially expressed genes between two conditions, the field of differential coexpression analysis is still relatively new. More specifically, there is so far no sensitive and untargeted method to identify gene modules (also known as gene sets or clusters) that are differentially coexpressed between two conditions. Here, sensitive and untargeted means that the method should be able to construct de novo modules by grouping genes based on shared, but subtle, differential correlation patterns.Results: We present DiffCoEx, a novel method for identifying correlation pattern changes, which builds on the commonly used Weighted Gene Coexpression Network Analysis (WGCNA) framework for coexpression analysis. We demonstrate its usefulness by identifying biologically relevant, differentially coexpressed modules in a rat cancer dataset.Conclusions: DiffCoEx is a simple and sensitive method to identify gene coexpression differences between multiple conditions.","Tesson, Bruno M.; Breitling, Rainer; Jansen, Ritsert C.","Jansen, Ritsert C/C-1160-2013","Jansen, Ritsert C/0000-0003-2977-9110; Breitling, Rainer/0000-0001-7173-0922",DiffCoEx: a simple and sensitive method to find differentially coexpressed gene modules,11,,10.1186/1471-2105-11-497 ,Article ,2010.0,"Background: Large microarray datasets have enabled gene regulation to be studied through coexpression analysis. While numerous methods have been developed for identifying differentially expressed genes between two conditions, the field of differential coexpression analysis is still relatively new. More specifically, there is so far no sensitive and untargeted method to identify gene modules (also known as gene sets or clusters) that are differentially coexpressed between two conditions. Here, sensitive and untargeted means that the method should be able to construct de novo modules by grouping genes based on shared, but subtle, differential correlation patterns.Results: We present DiffCoEx, a novel method for identifying correlation pattern changes, which builds on the commonly used Weighted Gene Coexpression Network Analysis (WGCNA) framework for coexpression analysis. We demonstrate its usefulness by identifying biologically relevant, differentially coexpressed modules in a rat cancer dataset.Conclusions: DiffCoEx is a simple and sensitive method to identify gene coexpression differences between multiple conditions.",1471-2105,,,, , ,,out_of_scope,
3997,"Title:Automating Predictive Toxicology Using ComptoxAI

 ComptoxAI is a new data infrastructure for computational and artificial intelligence research in predictive toxicology. Here, we describe and showcase ComptoxAI's graph structured knowledge base in the context of three real-world use cases, demonstrating that it can rapidly answer complex questions about toxicology that are infeasible using previous technologies and data resources. These use-cases each demonstrate a tool for information retrieval from the knowledge base being used to solve a specific task: The shortest path  module is used to identify mechanistic links between perfluorooctanoic acid (PFOA) exposure and nonalcoholic fatty liver disease; the expand network  module identifies communities that are linked to dioxin toxicity; and the quantitative structure-activity relationship (QSAR) dataset generator predicts pregnane X receptor agonism in a set of 4,021 pesticide ingredients. The contents of ComptoxAI's source data are rigorously aggregated from a diverse array of public third-party databases, and ComptoxAI is designed as a free, public, and open-source toolkit to enable diverse classes of users including biomedical researchers, public health and regulatory officials, and the general public to predict toxicology of unknowns and modes of action.","Romano, Joseph D.; Hao, Yun; Moore, Jason H.; Penning, Trevor M.",,"Penning, Trevor/0000-0002-3937-1066; Hao, Yun/0000-0002-1684-0085; Romano, Joseph/0000-0002-7999-4399",Automating Predictive Toxicology Using ComptoxAI,35,8,10.1021/acs.chemrestox.2c00074 ,Article ,2022.0,"ComptoxAI is a new data infrastructure for computational and artificial intelligence research in predictive toxicology. Here, we describe and showcase ComptoxAI's graph structured knowledge base in the context of three real-world use cases, demonstrating that it can rapidly answer complex questions about toxicology that are infeasible using previous technologies and data resources. These use-cases each demonstrate a tool for information retrieval from the knowledge base being used to solve a specific task: The shortest path  module is used to identify mechanistic links between perfluorooctanoic acid (PFOA) exposure and nonalcoholic fatty liver disease; the expand network  module identifies communities that are linked to dioxin toxicity; and the quantitative structure-activity relationship (QSAR) dataset generator predicts pregnane X receptor agonism in a set of 4,021 pesticide ingredients. The contents of ComptoxAI's source data are rigorously aggregated from a diverse array of public third-party databases, and ComptoxAI is designed as a free, public, and open-source toolkit to enable diverse classes of users including biomedical researchers, public health and regulatory officials, and the general public to predict toxicology of unknowns and modes of action.",0893-228X,1520-5010,,1370-1382, , ,,out_of_scope,
3998,"Title:Multi-atlas-based auto-segmentation for prostatic urethra using novel prediction of deformable image registration accuracy

 Purpose Accurate identification of the prostatic urethra and bladder can help determine dosing and evaluate urinary toxicity during intensity-modulated radiation therapy (IMRT) planning in patients with localized prostate cancer. However, it is challenging to locate the prostatic urethra in planning computed tomography (pCT). In the present study, we developed a multiatlas-based auto-segmentation method for prostatic urethra identification using deformable image registration accuracy prediction with machine learning (ML) and assessed its feasibility.Methods We examined 120 patients with prostate cancer treated with IMRT. All patients underwent temporary urinary catheter placement for identification and contouring of the prostatic urethra in pCT images (ground truth). Our method comprises the following three steps: (a) select four atlas datasets from the atlas datasets using the deformable image registration (DIR) accuracy prediction model, (b) deform them by structure-based DIR, (3) and propagate urethra contour using displacement vector field calculated by the DIR. In (a), for identifying suitable datasets, we used the trained support vector machine regression (SVR) model and five feature descriptors (e.g., prostate volume) to increase DIR accuracy. This method was trained/validated using 100 patients and performance was evaluated within an independent test set of 20 patients. Fivefold cross-validation was used to optimize the hype parameters of the DIR accuracy prediction model. We assessed the accuracy of our method by comparing it with those of two others: Acostas method-based patient selection (previous study method, by Acosta et al.), and the Waterman's method (defines the prostatic urethra based on the center of the prostate, by Waterman et al.). We used the centerlines distance (CLD) between the ground truth and the predicted prostatic urethra as the evaluation index.Results The CLD in the entire prostatic urethra was 2.09 +/- 0.89 mm (our proposed method), 2.77 +/- 0.99 mm (Acosta et al., P = 0.022), and 3.47 +/- 1.19 mm (Waterman et al., P < 0.001); our proposed method showed the highest accuracy. In segmented CLD, CLD in the top 1/3 segment was highly improved from that of Waterman et.al. and was slightly improved from that of Acosta et.al., with results of 2.49 +/- 1.78 mm (our proposed method), 2.95 +/- 1.75 mm (Acosta et al., P = 0.42), and 5.76 +/- 3.09 mm (Waterman et al., P < 0.001).Conclusions We developed a DIR accuracy prediction model-based multiatlas-based auto-segmentation method for prostatic urethra identification. Our method identified prostatic urethra with mean error of 2.09 mm, likely due to combined effects of SVR model employment in patient selection, modified atlas dataset characteristics and DIR algorithm. Our method has potential utility in prostate cancer IMRT and can replace use of temporary indwelling urinary catheters.","Takagi, Hisamichi; Kadoya, Noriyuki; Kajikawa, Tomohiro; Tanaka, Shohei; Takayama, Yoshiki; Chiba, Takahito; Ito, Kengo; Dobashi, Suguru; Takeda, Ken; Jingu, Keiichi","Takeda, Ken/L-1914-2019","Tanaka, Shohei/0000-0002-4257-5342",Multi-atlas-based auto-segmentation for prostatic urethra using novel prediction of deformable image registration accuracy,47,7,10.1002/mp.14154 ,Article ,2020.0,"Purpose Accurate identification of the prostatic urethra and bladder can help determine dosing and evaluate urinary toxicity during intensity-modulated radiation therapy (IMRT) planning in patients with localized prostate cancer. However, it is challenging to locate the prostatic urethra in planning computed tomography (pCT). In the present study, we developed a multiatlas-based auto-segmentation method for prostatic urethra identification using deformable image registration accuracy prediction with machine learning (ML) and assessed its feasibility.Methods We examined 120 patients with prostate cancer treated with IMRT. All patients underwent temporary urinary catheter placement for identification and contouring of the prostatic urethra in pCT images (ground truth). Our method comprises the following three steps: (a) select four atlas datasets from the atlas datasets using the deformable image registration (DIR) accuracy prediction model, (b) deform them by structure-based DIR, (3) and propagate urethra contour using displacement vector field calculated by the DIR. In (a), for identifying suitable datasets, we used the trained support vector machine regression (SVR) model and five feature descriptors (e.g., prostate volume) to increase DIR accuracy. This method was trained/validated using 100 patients and performance was evaluated within an independent test set of 20 patients. Fivefold cross-validation was used to optimize the hype parameters of the DIR accuracy prediction model. We assessed the accuracy of our method by comparing it with those of two others: Acostas method-based patient selection (previous study method, by Acosta et al.), and the Waterman's method (defines the prostatic urethra based on the center of the prostate, by Waterman et al.). We used the centerlines distance (CLD) between the ground truth and the predicted prostatic urethra as the evaluation index.Results The CLD in the entire prostatic urethra was 2.09 +/- 0.89 mm (our proposed method), 2.77 +/- 0.99 mm (Acosta et al., P = 0.022), and 3.47 +/- 1.19 mm (Waterman et al., P < 0.001); our proposed method showed the highest accuracy. In segmented CLD, CLD in the top 1/3 segment was highly improved from that of Waterman et.al. and was slightly improved from that of Acosta et.al., with results of 2.49 +/- 1.78 mm (our proposed method), 2.95 +/- 1.75 mm (Acosta et al., P = 0.42), and 5.76 +/- 3.09 mm (Waterman et al., P < 0.001).Conclusions We developed a DIR accuracy prediction model-based multiatlas-based auto-segmentation method for prostatic urethra identification. Our method identified prostatic urethra with mean error of 2.09 mm, likely due to combined effects of SVR model employment in patient selection, modified atlas dataset characteristics and DIR algorithm. Our method has potential utility in prostate cancer IMRT and can replace use of temporary indwelling urinary catheters.",0094-2405,2473-4209,,3023-3031, , ,,out_of_scope,
3999,"Title:Towards a Safer Conversation Space: Detection of Toxic Content in Social Media (Student Consortium)

 With content on social media turning increasingly toxic, it has attracted intensive research in the Natural Language Processing domain to detect aggression, hate, profanity, insult, cyberbullying and other personal attacks. Unlike most of the work in toxic content detection where the nature of toxicity is determined, we treat the detection of toxic content as a binary classification task. Here, we have explored Support Vector Machine, Boosting and deep neural networks for classification. We have trained the model on twitter datasets. With a goal of better predictive performance, our approach uses a majority voting ensemble to aggregate the predictions of individual classifiers.","Sahana, B. S.; Sandhya, G.; Tanuja, R. S.; Ellur, Sushma; Ajina, A.",,,Towards a Safer Conversation Space: Detection of Toxic Content in Social Media (Student Consortium),,,10.1109/BigMM50055.2020.00052 ,Proceedings Paper ,2020.0,"With content on social media turning increasingly toxic, it has attracted intensive research in the Natural Language Processing domain to detect aggression, hate, profanity, insult, cyberbullying and other personal attacks. Unlike most of the work in toxic content detection where the nature of toxicity is determined, we treat the detection of toxic content as a binary classification task. Here, we have explored Support Vector Machine, Boosting and deep neural networks for classification. We have trained the model on twitter datasets. With a goal of better predictive performance, our approach uses a majority voting ensemble to aggregate the predictions of individual classifiers.",,,978-1-7281-9325-0,297-301, , 6th IEEE International Conference on Multimedia Big Data (Big MM)6th IEEE International Conference on Multimedia Big Data (Big MM),,Use_dataset#detection,
4000,"Title:BERT-based ensemble learning for multi-aspect hate speech detection

 The social media world nowadays is overwhelmed with unfiltered content ranging from cyberbullying and cyberstalking to hate speech. Therefore, identifying and cleaning up such toxic language presents a big challenge and an active area of research. This study is dedicated to multi-aspect hate speech detection based on classifying text in multi-labels including 'identity hate', 'threat', 'insult', 'obscene', 'toxic' and 'severe toxic'. The proposed approach is based on the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model combined with Deep Learning (DL) models to compose several ensemble learning architectures. The DL models used are built by stacking Bidirectional Long-Short Term Memory (Bi-LSTM) and/or Bidirectional Gated Recurrent Unit (Bi-GRU) on GloVe and FastText word embeddings. Whereby, these models and BERT are trained individually on multi-label hateful dataset and used in combination for hate speech detection tasks on social media. Thus, we demonstrate that encoding texts by using recent word embedding techniques as FastText and GloVe alongside Bi-LSTM and Bi-GRU can create models that, when combined with BERT, can enhance the ROC-AUC score to 98.63%.","Mazari, Ahmed Cherif; Boudoukhani, Nesrine; Djeffal, Abdelhamid","Mazari, Ahmed Cherif/AAA-9472-2022","Mazari, Ahmed Cherif/0000-0002-6021-9413",BERT-based ensemble learning for multi-aspect hate speech detection,,,10.1007/s10586-022-03956-x ,Article; Early Access ,,"The social media world nowadays is overwhelmed with unfiltered content ranging from cyberbullying and cyberstalking to hate speech. Therefore, identifying and cleaning up such toxic language presents a big challenge and an active area of research. This study is dedicated to multi-aspect hate speech detection based on classifying text in multi-labels including 'identity hate', 'threat', 'insult', 'obscene', 'toxic' and 'severe toxic'. The proposed approach is based on the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model combined with Deep Learning (DL) models to compose several ensemble learning architectures. The DL models used are built by stacking Bidirectional Long-Short Term Memory (Bi-LSTM) and/or Bidirectional Gated Recurrent Unit (Bi-GRU) on GloVe and FastText word embeddings. Whereby, these models and BERT are trained individually on multi-label hateful dataset and used in combination for hate speech detection tasks on social media. Thus, we demonstrate that encoding texts by using recent word embedding techniques as FastText and GloVe alongside Bi-LSTM and Bi-GRU can create models that, when combined with BERT, can enhance the ROC-AUC score to 98.63%.",1386-7857,1573-7543,,, , ,,Use_dataset#detection,
4001,"Title:Measuring Fairness of Text Classifiers via Prediction Sensitivity

 With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions. Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system. In this work, we propose a new formulation - ACCUMULATED PREDICTION SENSITIVITY, which measures fairness in machine learning models based on the model's prediction sensitivity to perturbations in input features. The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group. We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness. It also correlates well with humans' perception of fairness. We conduct experiments on two text classification datasets - JIGSAW TOXICITY, and BIAS IN BIOS, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome. We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric.","Krishna, Satyapriya; Gupta, Rahul; Verma, Apurv; Dhamala, Jwala; Pruksachatkun, Yada; Chang, Kai-Wei",,,Measuring Fairness of Text Classifiers via Prediction Sensitivity,,, ,Proceedings Paper ,2022.0,"With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions. Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system. In this work, we propose a new formulation - ACCUMULATED PREDICTION SENSITIVITY, which measures fairness in machine learning models based on the model's prediction sensitivity to perturbations in input features. The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group. We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness. It also correlates well with humans' perception of fairness. We conduct experiments on two text classification datasets - JIGSAW TOXICITY, and BIAS IN BIOS, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome. We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric.",,,978-1-955917-21-6,5830-5842, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,detection#evaluation,
4002,"Title:Visual Data Exploration of Soil Bacteria Susceptible to Engineered Nanomaterials

 The impact of ZnO and TiO2 nanoparticles (NPs) on soil bacterial communities for different exposure times and NP doses was explored via data visualization techniques. Interrelationships between NP and responses of bacterial taxa were illustrated by bipartite graphs, allowing fast identification of important soil bacterial taxa that are susceptible to NPs. Hierarchical clustering and nonmetric multi-dimensional scaling (NMDS) of the dataset demonstrated that, high dose of ZnO and TiO2 NPs caused significant compositional changes in soil bacterial communities. The suitability of family level for NP impact assessment was demonstrated by the simplified NMDSs and the distance correlation between NP impacts summarized at different taxonomic levels. The present study demonstrates that visual exploration could potentially assist in knowledge discovery and interpretation of data on soil bacterial communities exposed to NPs and thus evaluate potential environmental impacts.","Liu, Rong; Ge, Yuan; Holden, Patricia A.; Cohen, Yoram","Ge, Yuan/D-2997-2009","Ge, Yuan/0000-0003-0234-5638",Visual Data Exploration of Soil Bacteria Susceptible to Engineered Nanomaterials,,, ,Proceedings Paper ,2014.0,"The impact of ZnO and TiO2 nanoparticles (NPs) on soil bacterial communities for different exposure times and NP doses was explored via data visualization techniques. Interrelationships between NP and responses of bacterial taxa were illustrated by bipartite graphs, allowing fast identification of important soil bacterial taxa that are susceptible to NPs. Hierarchical clustering and nonmetric multi-dimensional scaling (NMDS) of the dataset demonstrated that, high dose of ZnO and TiO2 NPs caused significant compositional changes in soil bacterial communities. The suitability of family level for NP impact assessment was demonstrated by the simplified NMDSs and the distance correlation between NP impacts summarized at different taxonomic levels. The present study demonstrates that visual exploration could potentially assist in knowledge discovery and interpretation of data on soil bacterial communities exposed to NPs and thus evaluate potential environmental impacts.",2156-1125,2156-1133,978-1-4799-5669-2,, , IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM)IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM),,out_of_scope,
4003,"Title:A Fully Deep Learning Paradigm for Pneumoconiosis Staging on Chest Radiographs

 Pneumoconiosis staging has been a very challenging task, both for certified radiologists and computer-aided detection algorithms. Although deep learning has shown proven advantages in the detection of pneumoconiosis, it remains challenging in pneumoconiosis staging due to the stage ambiguity of pneumoconiosis and noisy samples caused by misdiagnosis when they are used in training deep learning models. In this article, we propose a fully deep learning pneumoconiosis staging paradigm that comprises a segmentation procedure and a staging procedure. The segmentation procedure extracts lung fields in chest radiographs through an Asymmetric Encoder-Decoder Network (AED-Net) that can mitigate the domain shift between multiple datasets. The staging procedure classifies the lung fields into four stages through our proposed deep log-normal label distribution learning and focal staging loss. The two cascaded procedures can effectively solve the problem of model overfitting caused by stage ambiguity and noisy labels of pneumoconiosis. Besides, we collect a clinical chest radiograph dataset of pneumoconiosis from the certified radiologist's diagnostic reports. The experimental results on this novel pneumoconiosis dataset confirm that the proposed deep pneumoconiosis staging paradigm achieves an Accuracy of 90.4%, a Precision of 84.8%, a Sensitivity of 78.4%, a Specificity of 95.6%, an F1-score of 80.9% and an Area Under the Curve (AUC) of 96%. In particular, we achieve 68.4% Precision, 76.5% Sensitivity, 95% Specificity, 72.2% F1-score and 89% AUC on the early pneumoconiosis 'stage-1'.","Sun, Wenjian; Wu, Dongsheng; Luo, Yang; Liu, Lu; Zhang, Hongjing; Wu, Shuang; Zhang, Yan; Wang, Chenglong; Zheng, Houjun; Shen, Jiang; Luo, Chunbo","Sun, Wenjian/JDI-9502-2023",,A Fully Deep Learning Paradigm for Pneumoconiosis Staging on Chest Radiographs,26,10,10.1109/JBHI.2022.3190923 ,Article ,2022.0,"Pneumoconiosis staging has been a very challenging task, both for certified radiologists and computer-aided detection algorithms. Although deep learning has shown proven advantages in the detection of pneumoconiosis, it remains challenging in pneumoconiosis staging due to the stage ambiguity of pneumoconiosis and noisy samples caused by misdiagnosis when they are used in training deep learning models. In this article, we propose a fully deep learning pneumoconiosis staging paradigm that comprises a segmentation procedure and a staging procedure. The segmentation procedure extracts lung fields in chest radiographs through an Asymmetric Encoder-Decoder Network (AED-Net) that can mitigate the domain shift between multiple datasets. The staging procedure classifies the lung fields into four stages through our proposed deep log-normal label distribution learning and focal staging loss. The two cascaded procedures can effectively solve the problem of model overfitting caused by stage ambiguity and noisy labels of pneumoconiosis. Besides, we collect a clinical chest radiograph dataset of pneumoconiosis from the certified radiologist's diagnostic reports. The experimental results on this novel pneumoconiosis dataset confirm that the proposed deep pneumoconiosis staging paradigm achieves an Accuracy of 90.4%, a Precision of 84.8%, a Sensitivity of 78.4%, a Specificity of 95.6%, an F1-score of 80.9% and an Area Under the Curve (AUC) of 96%. In particular, we achieve 68.4% Precision, 76.5% Sensitivity, 95% Specificity, 72.2% F1-score and 89% AUC on the early pneumoconiosis 'stage-1'.",2168-2194,2168-2208,,5154-5164, , ,,out_of_scope,
4004,"Title:A Novel Hybrid Method of Gene Selection and Its Application on Tumor Classification

 Microarray gene expression profile data is used to accurately predict different tumor types, which has great value in providing better treatment and toxicity minimization on the patients. However, it is difficult to classify different tumor types using microarray data because the number of samples is much smaller than the number of genes. It has been proved that a small feature gene subset can improve classification accuracy, so feature gene selection and extraction algorithm is very important in tumor classification. In this paper, a novel hybrid gene selection method is proposed to find a feature gene subset so that the feature genes related to certain cancer can be kept and the redundant genes can be leave out. In the proposed method, we combine the advantages of the PCA and the LDA and proposed a novel feature gene extraction scheme. We also compared several kinds of parametric and non-parametric feature gene selection methods. We use the SVM as the classifier in the experiment and compare the performance of three common SVM kernels. Their differences are analyzed. Using the n-fold cross validation, the proposed algorithm is carried out on three published benchmark tumor datasets and experimental results show that this algorithm leads to better classification performance than other methods.","You, Zhuhong; Wang, Shulin; Gui, Jie; Zhang, Shanwen","You, Zhu-Hong/AAI-6862-2020; You, Zhu-Hong/A-4056-2011","You, Zhu-Hong/0000-0003-1266-2696",A Novel Hybrid Method of Gene Selection and Its Application on Tumor Classification,5227,, ,Proceedings Paper ,2008.0,"Microarray gene expression profile data is used to accurately predict different tumor types, which has great value in providing better treatment and toxicity minimization on the patients. However, it is difficult to classify different tumor types using microarray data because the number of samples is much smaller than the number of genes. It has been proved that a small feature gene subset can improve classification accuracy, so feature gene selection and extraction algorithm is very important in tumor classification. In this paper, a novel hybrid gene selection method is proposed to find a feature gene subset so that the feature genes related to certain cancer can be kept and the redundant genes can be leave out. In the proposed method, we combine the advantages of the PCA and the LDA and proposed a novel feature gene extraction scheme. We also compared several kinds of parametric and non-parametric feature gene selection methods. We use the SVM as the classifier in the experiment and compare the performance of three common SVM kernels. Their differences are analyzed. Using the n-fold cross validation, the proposed algorithm is carried out on three published benchmark tumor datasets and experimental results show that this algorithm leads to better classification performance than other methods.",0302-9743,1611-3349,978-3-540-85983-3,1055-1068, , 4th International Conference on Intelligent Computing4th International Conference on Intelligent Computing,,out_of_scope,
4005,"Title:First multi-target QSAR model for predicting the cytotoxicity of acrylic acid-based dental monomers

 Objective: Acrylic acid derivatives are frequently used as dental monomers and their cy- totoxicity towards various cell lines is well documented. This study aims to probe the structural and physicochemical attributes responsible for higher toxicity of dental mono- mers, using quantitative structure-activity relationships (QSAR) modeling approaches. Methods: A regression-based linear single-target QSAR (st-QSAR) model was developed with a comparatively small dataset containing 39 compounds, the cytotoxicity of which has been assessed over the Hela S3 cell line. By contrast, a classification-based multi-target QSAR model was developed with 138 compounds, the cytotoxicity of which has been re- ported against 18 different cell lines. Both models were set up following rigorous validation protocols confirming their statistical significance and robustness. Results: The performance of the linear mt-QSAR model, developed with various feature selection and post-selection similarity searching-based schemes, superseded that of all non-linear models produced with six machine learning methods by hyperparameter opti- mization. The final derived st-QSAR and mt-QSAR linear models are shown to be highly predictive, as well as revealing the crucial structural and physicochemical factors re- sponsible for higher cytotoxicity of the dental monomers. Significance: This study is the first attempt on unveiling the cytotoxicity of dental mono- mers over several cell lines by means of a single multi-target QSAR model. Further, such a model is ready to get widespread applicability in the screening of new monomers, judging from its almost accurate predictions over diverse experimental assay conditions. (c) 2021 The Academy of Dental Materials. Published by Elsevier Inc. All rights reserved.","Halder, Amit Kumar; Delgado, Antonio H. S.; Cordeiro, M. Natalia D. S.","Cordeiro, Natália/ISV-0249-2023; Cordeiro, Maria Natália D. S./A-7413-2012","Cordeiro, Natália/0000-0003-3375-8670; Cordeiro, Maria Natália D. S./0000-0003-3375-8670; Delgado, Antonio/0000-0001-7902-6104",First multi-target QSAR model for predicting the cytotoxicity of acrylic acid-based dental monomers,38,2,10.1016/j.dental.2021.12.014 ,Article ,2022.0,"Objective: Acrylic acid derivatives are frequently used as dental monomers and their cy- totoxicity towards various cell lines is well documented. This study aims to probe the structural and physicochemical attributes responsible for higher toxicity of dental mono- mers, using quantitative structure-activity relationships (QSAR) modeling approaches. Methods: A regression-based linear single-target QSAR (st-QSAR) model was developed with a comparatively small dataset containing 39 compounds, the cytotoxicity of which has been assessed over the Hela S3 cell line. By contrast, a classification-based multi-target QSAR model was developed with 138 compounds, the cytotoxicity of which has been re- ported against 18 different cell lines. Both models were set up following rigorous validation protocols confirming their statistical significance and robustness. Results: The performance of the linear mt-QSAR model, developed with various feature selection and post-selection similarity searching-based schemes, superseded that of all non-linear models produced with six machine learning methods by hyperparameter opti- mization. The final derived st-QSAR and mt-QSAR linear models are shown to be highly predictive, as well as revealing the crucial structural and physicochemical factors re- sponsible for higher cytotoxicity of the dental monomers. Significance: This study is the first attempt on unveiling the cytotoxicity of dental mono- mers over several cell lines by means of a single multi-target QSAR model. Further, such a model is ready to get widespread applicability in the screening of new monomers, judging from its almost accurate predictions over diverse experimental assay conditions. (c) 2021 The Academy of Dental Materials. Published by Elsevier Inc. All rights reserved.",0109-5641,1879-0097,,333-346, , ,,out_of_scope,
4006,"Title:Bioinformatics Resource Manager: a systems biology web tool for microRNA and omics data integration

 BackgroundThe Bioinformatics Resource Manager (BRM) is a web-based tool developed to facilitate identifier conversion and data integration for Homo sapiens (human), Mus musculus (mouse), Rattus norvegicus (rat), Danio rerio (zebrafish), and Macaca mulatta (macaque), as well as perform orthologous conversions among the supported species. In addition to providing a robust means of identifier conversion, BRM also incorporates a suite of microRNA (miRNA)-target databases upon which to query target genes or to perform reverse target lookups using gene identifiers.ResultsBRM has the capability to perform cross-species identifier lookups across common identifier types, directly integrate datasets across platform or species by performing identifier retrievals in the background, and retrieve miRNA targets from multiple databases simultaneously and integrate the resulting gene targets with experimental mRNA data. Here we use workflows provided in BRM to integrate RNA sequencing data across species to identify common biomarkers of exposure after treatment of human lung cells and zebrafish to benzo[a]pyrene (BAP). We further use the miRNA Target workflow to experimentally determine the role of miRNAs as regulators of BAP toxicity and identify the predicted functional consequences of miRNA-target regulation in our system. The output from BRM can easily and directly be uploaded to freely available visualization tools for further analysis. From these examples, we were able to identify an important role for several miRNAs as potential regulators of BAP toxicity in human lung cells associated with cell migration, cell communication, cell junction assembly and regulation of cell death.ConclusionsOverall, BRM provides bioinformatics tools to assist biologists having minimal programming skills with analysis and integration of high-content omics' data from various transcriptomic and proteomic platforms. BRM workflows were developed in Java and other open-source technologies and are served publicly using Apache Tomcat at https://cbb.pnnl.gov/brm/.","Brown, Joseph; Phillips, Aaron R.; Lewis, David A.; Mans, Michael-Andres; Chang, Yvonne; Tanguay, Robert L.; Peterson, Elena S.; Waters, Katrina M.; Tilton, Susan C.",,"Chang, Yvonne/0000-0001-5967-3099; Tilton, Susan/0000-0002-5427-6462",Bioinformatics Resource Manager: a systems biology web tool for microRNA and omics data integration,20,,10.1186/s12859-019-2805-6 ,Article ,2019.0,"BackgroundThe Bioinformatics Resource Manager (BRM) is a web-based tool developed to facilitate identifier conversion and data integration for Homo sapiens (human), Mus musculus (mouse), Rattus norvegicus (rat), Danio rerio (zebrafish), and Macaca mulatta (macaque), as well as perform orthologous conversions among the supported species. In addition to providing a robust means of identifier conversion, BRM also incorporates a suite of microRNA (miRNA)-target databases upon which to query target genes or to perform reverse target lookups using gene identifiers.ResultsBRM has the capability to perform cross-species identifier lookups across common identifier types, directly integrate datasets across platform or species by performing identifier retrievals in the background, and retrieve miRNA targets from multiple databases simultaneously and integrate the resulting gene targets with experimental mRNA data. Here we use workflows provided in BRM to integrate RNA sequencing data across species to identify common biomarkers of exposure after treatment of human lung cells and zebrafish to benzo[a]pyrene (BAP). We further use the miRNA Target workflow to experimentally determine the role of miRNAs as regulators of BAP toxicity and identify the predicted functional consequences of miRNA-target regulation in our system. The output from BRM can easily and directly be uploaded to freely available visualization tools for further analysis. From these examples, we were able to identify an important role for several miRNAs as potential regulators of BAP toxicity in human lung cells associated with cell migration, cell communication, cell junction assembly and regulation of cell death.ConclusionsOverall, BRM provides bioinformatics tools to assist biologists having minimal programming skills with analysis and integration of high-content omics' data from various transcriptomic and proteomic platforms. BRM workflows were developed in Java and other open-source technologies and are served publicly using Apache Tomcat at https://cbb.pnnl.gov/brm/.",1471-2105,,,, , ,,out_of_scope,
4007,"Title:Algorithm for analysis of administrative pediatric cancer hospitalization data according to indication for admission

 Background: Childhood cancer relies heavily on inpatient hospital services to deliver tumor-directed therapy and manage toxicities. Hospitalizations have increased over the past decade, though not uniformly across childhood cancer diagnoses. Analysis of the reasons for admission of children with cancer could enhance comparison of resource use between cancers, and allow clinical practice data to be interpreted more readily. Such comparisons using nationwide data sources are difficult because of numerous subdivisions in the International Classification of Diseases Clinical Modification (ICD-9) system and inherent complexities of treatments. This study aimed to develop a systematic approach to classifying cancer-related admissions in administrative data into categories that reflected clinical practice and predicted resource use.Methods: We developed a multistep algorithm to stratify indications for childhood cancer admissions in the Kids Inpatient Databases from 2003, 2006 and 2009 into clinically meaningful categories. This algorithm assumed that primary discharge diagnoses of cancer or cytopenia were insufficient, and relied on procedure codes and secondary diagnoses in these scenarios. Clinical Classification Software developed by the Healthcare Cost and Utilization Project was first used to sort thousands of ICD-9 codes into 5 mutually exclusive diagnosis categories and 3 mutually exclusive procedure categories, and validation was performed by comparison with the ICD-9 codes in the final admission indication. Mean cost, length of stay, and costs per day were compared between categories of indication for admission.Results: A cohort of 202,995 cancer-related admissions was grouped into four categories of indication for admission: chemotherapy (N=77,791, 38%), to undergo a procedure (N=30,858, 15%), treatment for infection (N=30,380, 15%), or treatment for other toxicities (N=43,408, 21.4%). The positive predictive value for the algorithm was >95% for each category. Admissions for procedures had higher mean hospital costs, longer hospital stays, and higher costs per day compared with other admission reasons (p<0.001).Conclusions: This is the first description of a method for grouping indications for childhood cancer admission within an administrative dataset into clinically relevant categories. This algorithm provides a framework for more detailed analyses of pediatric hospitalization data by cancer type.","Russell, Heidi V.; Okcu, M. Fatih; Kamdar, Kala; Shah, Mona D.; Kim, Eugene; Swint, J. Michael; Chan, Wenyaw; Du, Xianglin L.; Franzini, Luisa; Ho, Vivian",,"Kim, Eugene/0000-0001-7959-5614; Ho, Vivian/0000-0002-5979-8155",Algorithm for analysis of administrative pediatric cancer hospitalization data according to indication for admission,14,,10.1186/1472-6947-14-88 ,Article ,2014.0,"Background: Childhood cancer relies heavily on inpatient hospital services to deliver tumor-directed therapy and manage toxicities. Hospitalizations have increased over the past decade, though not uniformly across childhood cancer diagnoses. Analysis of the reasons for admission of children with cancer could enhance comparison of resource use between cancers, and allow clinical practice data to be interpreted more readily. Such comparisons using nationwide data sources are difficult because of numerous subdivisions in the International Classification of Diseases Clinical Modification (ICD-9) system and inherent complexities of treatments. This study aimed to develop a systematic approach to classifying cancer-related admissions in administrative data into categories that reflected clinical practice and predicted resource use.Methods: We developed a multistep algorithm to stratify indications for childhood cancer admissions in the Kids Inpatient Databases from 2003, 2006 and 2009 into clinically meaningful categories. This algorithm assumed that primary discharge diagnoses of cancer or cytopenia were insufficient, and relied on procedure codes and secondary diagnoses in these scenarios. Clinical Classification Software developed by the Healthcare Cost and Utilization Project was first used to sort thousands of ICD-9 codes into 5 mutually exclusive diagnosis categories and 3 mutually exclusive procedure categories, and validation was performed by comparison with the ICD-9 codes in the final admission indication. Mean cost, length of stay, and costs per day were compared between categories of indication for admission.Results: A cohort of 202,995 cancer-related admissions was grouped into four categories of indication for admission: chemotherapy (N=77,791, 38%), to undergo a procedure (N=30,858, 15%), treatment for infection (N=30,380, 15%), or treatment for other toxicities (N=43,408, 21.4%). The positive predictive value for the algorithm was >95% for each category. Admissions for procedures had higher mean hospital costs, longer hospital stays, and higher costs per day compared with other admission reasons (p<0.001).Conclusions: This is the first description of a method for grouping indications for childhood cancer admission within an administrative dataset into clinically relevant categories. This algorithm provides a framework for more detailed analyses of pediatric hospitalization data by cancer type.",,1472-6947,,, , ,,out_of_scope,
4008,"Title:Information Fusion of Image Analysis, Video Object Tracking, and Data Mining of Biological Images using the Open Source MATLAB Toolbox Gait-CAD

 Automated imaging has become a commonplace and widespread technique for researchers aiming to increase both biological and medical knowledge. Systematic high-throughput screening approaches produce a vast amount of data that needs to be quantified automatically. To address this problem, we present an extended version of the open-source MATLAB toolbox Gait-CAD providing integrated tools for automated image analysis, video object tracking and data mining. Gait-CAD offers a convenient graphical user interface (GUI) and is shipped with a great selection of predefined, customizable plugins for both image analysis and data mining. The plugin-based architecture and templates for customized tools provide easy expandability in order to develop comprehensive data-analysis pipelines. Process automation via batch-files and macro recording functionality enables the handling of large datasets like multi-dimensional 2D or 3D images and videos. The scope of the presented tools ranges from automated high-throughput toxicity testing in zebrafish embryos to cellular analysis tasks in developmental biology. In both examples, the toolbox is successfully applied for pre-processing, normalization, segmentation and tracking of spatio-temporal microscopy images, as well as for subsequent data mining and report generation. As automatically acquired images tend to differ in each recording, researchers can significantly accelerate parameter adjustments, process automation and result visualization by using the presented software. The toolbox is not limited to these applications, but they already reveal the great potential of the extended Gait-CAD release. The presented toolbox is a powerful instrument for data analysis in life sciences. A user-friendly GUI provides functionality to create sophisticated approaches even for users with limited programming knowledge. Licensed under the GNU General Public License (GNU-GPL), the toolkit is freely available and can be downloaded at http://sourceforge.net/projects/gait-cad/.","Stegmaier, J.; Alshut, R.; Reischl, M.; Mikut, R.","Reischl, Markus/H-6970-2013; Mikut, Ralf/A-5949-2013","Reischl, Markus/0000-0002-7780-6374; Mikut, Ralf/0000-0001-9100-5496; Stegmaier, Johannes/0000-0003-4072-3759","Information Fusion of Image Analysis, Video Object Tracking, and Data Mining of Biological Images using the Open Source MATLAB Toolbox Gait-CAD",57,,10.1515/bmt-2012-4073 ,Article ,2012.0,"Automated imaging has become a commonplace and widespread technique for researchers aiming to increase both biological and medical knowledge. Systematic high-throughput screening approaches produce a vast amount of data that needs to be quantified automatically. To address this problem, we present an extended version of the open-source MATLAB toolbox Gait-CAD providing integrated tools for automated image analysis, video object tracking and data mining. Gait-CAD offers a convenient graphical user interface (GUI) and is shipped with a great selection of predefined, customizable plugins for both image analysis and data mining. The plugin-based architecture and templates for customized tools provide easy expandability in order to develop comprehensive data-analysis pipelines. Process automation via batch-files and macro recording functionality enables the handling of large datasets like multi-dimensional 2D or 3D images and videos. The scope of the presented tools ranges from automated high-throughput toxicity testing in zebrafish embryos to cellular analysis tasks in developmental biology. In both examples, the toolbox is successfully applied for pre-processing, normalization, segmentation and tracking of spatio-temporal microscopy images, as well as for subsequent data mining and report generation. As automatically acquired images tend to differ in each recording, researchers can significantly accelerate parameter adjustments, process automation and result visualization by using the presented software. The toolbox is not limited to these applications, but they already reveal the great potential of the extended Gait-CAD release. The presented toolbox is a powerful instrument for data analysis in life sciences. A user-friendly GUI provides functionality to create sophisticated approaches even for users with limited programming knowledge. Licensed under the GNU General Public License (GNU-GPL), the toolkit is freely available and can be downloaded at http://sourceforge.net/projects/gait-cad/.",0013-5585,1862-278X,,458-461, , ,,out_of_scope,
4009,"Title:MANAGING CLASS IMBALANCE IN MULTI-ORGAN CT SEGMENTATION IN HEAD AND NECK CANCER PATIENTS

 Radiotherapy planning of head and neck cancer patients requires an accurate delineation of several organs at risk (OAR) from planning CT images in order to determine a dose plan which reduces toxicity and salvages normal tissue. However training a single deep neural network for multiple organs is highly sensitive to class imbalance and variability in size between several structures within the head and neck region. In this paper, we propose a single-class segmentation model for each OAR in order to handle class imbalance issues during training across output classes (one class per structure), where there exists a severe disparity between 12 OAR. Based on a U-net architecture, we present a transfer learning approach between similar OAR to leverage common learned features, as well as a simple weight averaging strategy to initialize a model as the average of multiple models, each trained on a separate organ. Experiments performed on an internal dataset of 200 H&N cancer patients treated with external beam radiotherapy, show the proposed model presents a significant improvement compared to the baseline multi-organ segmentation model, which attempts to simultaneously train several OAR. The proposed model yields an overall Dice score of 0.75 +/- 0.12, by using both transfer learning across OAR and a weight averaging strategy, indicating that a reasonable segmentation performance can be achieved by leveraging additional data from surrounding structures, limiting the uncertainty in ground-truth annotations.","Cros, Samuel; Vorontsov, Eugene; Kadoury, Samuel",,,MANAGING CLASS IMBALANCE IN MULTI-ORGAN CT SEGMENTATION IN HEAD AND NECK CANCER PATIENTS,,,10.1109/ISBI48211.2021.9433991 ,Proceedings Paper ,2021.0,"Radiotherapy planning of head and neck cancer patients requires an accurate delineation of several organs at risk (OAR) from planning CT images in order to determine a dose plan which reduces toxicity and salvages normal tissue. However training a single deep neural network for multiple organs is highly sensitive to class imbalance and variability in size between several structures within the head and neck region. In this paper, we propose a single-class segmentation model for each OAR in order to handle class imbalance issues during training across output classes (one class per structure), where there exists a severe disparity between 12 OAR. Based on a U-net architecture, we present a transfer learning approach between similar OAR to leverage common learned features, as well as a simple weight averaging strategy to initialize a model as the average of multiple models, each trained on a separate organ. Experiments performed on an internal dataset of 200 H&N cancer patients treated with external beam radiotherapy, show the proposed model presents a significant improvement compared to the baseline multi-organ segmentation model, which attempts to simultaneously train several OAR. The proposed model yields an overall Dice score of 0.75 +/- 0.12, by using both transfer learning across OAR and a weight averaging strategy, indicating that a reasonable segmentation performance can be achieved by leveraging additional data from surrounding structures, limiting the uncertainty in ground-truth annotations.",1945-7928,,978-1-6654-1246-9,1360-1364, , 18th IEEE International Symposium on Biomedical Imaging (ISBI)18th IEEE International Symposium on Biomedical Imaging (ISBI),,out_of_scope,
4010,"Title:Health and environmental safety of nanomaterials: O Data, Where Art Thou?

 Nanotechnology keeps drawing attention due to the great tunable properties of nanomaterials in comparison to their bulk conventional materials. The growth of nanotechnology in combination with the digitization era has led to an increased need of safety related data. In addition to safety, new data-driven paradigms on safe and sustainable by design materials are stressing the necessity of data even more. Data is a fundamental asset to the scientific community in studying and analysing the entire life-cycle of nanomaterials. Unfortunately, data exist in a scattered fashion, in different sources and formats. To our knowledge, there is no study focusing on aspects of actual data-structure knowledge that exists in literature and databases. The purpose of this review research is to transparently and comprehensively, display to the nanoscience community the datasets readily available for machine learning purposes making it convenient and more efficient for the next users such as modellers or data curators to retrieve information. We systematically recorded the features and descriptors available in the datasets and provide synopsised information on their ranges, forms and metrics in the supplementary material.","Furxhi, Irini",,,"Health and environmental safety of nanomaterials: O Data, Where Art Thou?",25,,10.1016/j.impact.2021.100378 ,Review ,2022.0,"Nanotechnology keeps drawing attention due to the great tunable properties of nanomaterials in comparison to their bulk conventional materials. The growth of nanotechnology in combination with the digitization era has led to an increased need of safety related data. In addition to safety, new data-driven paradigms on safe and sustainable by design materials are stressing the necessity of data even more. Data is a fundamental asset to the scientific community in studying and analysing the entire life-cycle of nanomaterials. Unfortunately, data exist in a scattered fashion, in different sources and formats. To our knowledge, there is no study focusing on aspects of actual data-structure knowledge that exists in literature and databases. The purpose of this review research is to transparently and comprehensively, display to the nanoscience community the datasets readily available for machine learning purposes making it convenient and more efficient for the next users such as modellers or data curators to retrieve information. We systematically recorded the features and descriptors available in the datasets and provide synopsised information on their ranges, forms and metrics in the supplementary material.",2452-0748,,,, , ,,out_of_scope,
4011,"Title:AlexNet architecture based convolutional neural network for toxic comments classification

 Today online networking has become an indispensable part of life for people all over the world. It is dif-ficult for users to reduce their internet/online communications, as the flow of information increases everyday. While the free flow of information benefits online communications, the high toxicity of online communication is a drawback. Toxic texts are described as disrespectful or insulting messages that make the recipient feel uncomfortable. Deep Learning based Convolutional Neural Networks (CNN) have given exceptional outcomes in Computer Vision Domain, and AlexNet has proven to be the leading architecture in image classification and object detection problems. This article presents a 3-tier CNN architecture that is inspired by the AlexNet model to classify the toxic comments on the Wikipedia forum available in the Google Jigsaw dataset. Fast text-crawl-300d-2 m is used to formulate the pre-trained word embeddings matrix. The Exponential Linear Unit (ELU) activation function is applied in the Convolutional blocks for faster convergence. Dropout is used sufficiently along with different layers of the network to prevent overfitting. From the simulation and subsequent comparative analysis, it is found that the proposed model achieved a decent average accuracy of 98.505% and an average F1 score of 0.79. ROC-AUC score is used as an evaluation parameter. The value of ROC-AUC for the proposed model is approximately 0.9854, which shows that the said model differentiates between the comment classes more accurately. (c) 2022 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","Singh, Inderpreet; Goyal, Gulshan; Chandel, Anmol",,,AlexNet architecture based convolutional neural network for toxic comments classification,34,9,10.1016/j.jksuci.2022.06.007 ,Article ,2022.0,"Today online networking has become an indispensable part of life for people all over the world. It is dif-ficult for users to reduce their internet/online communications, as the flow of information increases everyday. While the free flow of information benefits online communications, the high toxicity of online communication is a drawback. Toxic texts are described as disrespectful or insulting messages that make the recipient feel uncomfortable. Deep Learning based Convolutional Neural Networks (CNN) have given exceptional outcomes in Computer Vision Domain, and AlexNet has proven to be the leading architecture in image classification and object detection problems. This article presents a 3-tier CNN architecture that is inspired by the AlexNet model to classify the toxic comments on the Wikipedia forum available in the Google Jigsaw dataset. Fast text-crawl-300d-2 m is used to formulate the pre-trained word embeddings matrix. The Exponential Linear Unit (ELU) activation function is applied in the Convolutional blocks for faster convergence. Dropout is used sufficiently along with different layers of the network to prevent overfitting. From the simulation and subsequent comparative analysis, it is found that the proposed model achieved a decent average accuracy of 98.505% and an average F1 score of 0.79. ROC-AUC score is used as an evaluation parameter. The value of ROC-AUC for the proposed model is approximately 0.9854, which shows that the said model differentiates between the comment classes more accurately. (c) 2022 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",1319-1578,2213-1248,,7547-7558, , ,,detection#methodology,
4012,"Title:Inference for the dependent competing risks model with masked causes of failure

 The competing risks model is useful in settings in which individuals/units may die/fail for different reasons. The cause specific hazard rates are taken to be piecewise constant functions. A complication arises when some of the failures are masked within a group of possible causes. Traditionally, statistical inference is performed under the assumption that the failure causes act independently on each item. In this paper we propose an EM-based approach which allows for dependent competing risks and produces estimators for the sub-distribution functions. We also discuss identifiability of parameters if none of the masked items have their cause of failure clarified in a second stage analysis (e.g. autopsy). The procedures proposed are illustrated with two datasets.","Craiu, RV; Reiser, B","Reiser, Benjamin/G-6591-2012","Reiser, Benjamin/0000-0002-9797-9029",Inference for the dependent competing risks model with masked causes of failure,12,1,10.1007/s10985-005-7218-3 ,Article ,2006.0,"The competing risks model is useful in settings in which individuals/units may die/fail for different reasons. The cause specific hazard rates are taken to be piecewise constant functions. A complication arises when some of the failures are masked within a group of possible causes. Traditionally, statistical inference is performed under the assumption that the failure causes act independently on each item. In this paper we propose an EM-based approach which allows for dependent competing risks and produces estimators for the sub-distribution functions. We also discuss identifiability of parameters if none of the masked items have their cause of failure clarified in a second stage analysis (e.g. autopsy). The procedures proposed are illustrated with two datasets.",1380-7870,,,21-33, , ,,out_of_scope,
4013,"Title:Monte Carlo-based lung cancer treatment planning incorporating PET-defined target volumes

 Despite the well-known benefits of positron emission tomography (PET) imaging in lung cancer diagnosis and staging, the poor spatial resolution of PET has limited its use in radiotherapy planning. Methods used for segmenting tumor from normal tissue, such as threshold boundaries using a fraction of the standardized uptake value (SUV), are subject to uncertainties. The issue of respiratory motion in the thorax confounds the problem of accurate target definition. In this work, we evaluate how changing the PET-defined target volume by varying the threshold value in the segmentation process impacts target and normal lung tissue doses. For each of eight lung cancer patients we retrospectively generated multiple PET-target volumes; each target volume corresponds to those voxels with intensities above a given threshold level, defined by a percentage of the maximum voxel intensity. PET-defined targets were compared to those from CT; CT targets comprise a composite volume generated from breath-hold inhale and exhale datasets; the CT dataset therefore also includes the extents of tumor motion. Treatment plans using Monte Carlo dose calculation were generated for all targets; the dose uniformity was approximately 100 +/- 5% within the internal target volume (ITV) ( formed by a uniform 8-mm expansion of the composite gross target volume (GTV)). In all cases differences were observed in the generalized equivalent uniform doses (gEUDs) to the targets and in the mean lung doses (MLDs) and normal tissue complication probabilities (NTCPs) to the normal lung tissues. The magnitudes of the dose differences were found to depend on the target volume, location, and amount of irradiated normal lung tissue, and in many instances were clinically meaningful ( greater than a single 2 Gy fraction). For those patients studied, results indicate that accurate dosimetry using PET volumes is highly dependent on accurate target segmentation. Further study with correlation to clinical outcome will be helpful in determining how to apply these various PET and CT volumes in treatment planning, to potentially improve local tumor control and reduce normal tissue toxicities.","Chetty, Indrin J.; Fernando, Shaneli; Kessler, Marc L.; Mcshan, Daniel L.; Brooks, Cassandra; Haken, Randall K. Ten; Kong, Feng-Ming Spring","Wang, Weili/D-1546-2011; Kong, Feng-Ming/Y-2825-2019","Kong, Feng-Ming/0000-0003-2652-098X",Monte Carlo-based lung cancer treatment planning incorporating PET-defined target volumes,6,4,10.1120/jacmp.2026.25363 ,Article ,2005.0,"Despite the well-known benefits of positron emission tomography (PET) imaging in lung cancer diagnosis and staging, the poor spatial resolution of PET has limited its use in radiotherapy planning. Methods used for segmenting tumor from normal tissue, such as threshold boundaries using a fraction of the standardized uptake value (SUV), are subject to uncertainties. The issue of respiratory motion in the thorax confounds the problem of accurate target definition. In this work, we evaluate how changing the PET-defined target volume by varying the threshold value in the segmentation process impacts target and normal lung tissue doses. For each of eight lung cancer patients we retrospectively generated multiple PET-target volumes; each target volume corresponds to those voxels with intensities above a given threshold level, defined by a percentage of the maximum voxel intensity. PET-defined targets were compared to those from CT; CT targets comprise a composite volume generated from breath-hold inhale and exhale datasets; the CT dataset therefore also includes the extents of tumor motion. Treatment plans using Monte Carlo dose calculation were generated for all targets; the dose uniformity was approximately 100 +/- 5% within the internal target volume (ITV) ( formed by a uniform 8-mm expansion of the composite gross target volume (GTV)). In all cases differences were observed in the generalized equivalent uniform doses (gEUDs) to the targets and in the mean lung doses (MLDs) and normal tissue complication probabilities (NTCPs) to the normal lung tissues. The magnitudes of the dose differences were found to depend on the target volume, location, and amount of irradiated normal lung tissue, and in many instances were clinically meaningful ( greater than a single 2 Gy fraction). For those patients studied, results indicate that accurate dosimetry using PET volumes is highly dependent on accurate target segmentation. Further study with correlation to clinical outcome will be helpful in determining how to apply these various PET and CT volumes in treatment planning, to potentially improve local tumor control and reduce normal tissue toxicities.",1526-9914,,,65-76, , ,,out_of_scope,
4014,"Title:The aquatic animals' transcriptome resource for comparative functional analysis

 Background: Aquatic animals have great economic and ecological importance. Among them, non-model organisms have been studied regarding eco-toxicity, stress biology, and environmental adaptation. Due to recent advances in next-generation sequencing techniques, large amounts of RNA-seq data for aquatic animals are publicly available. However, currently there is no comprehensive resource exist for the analysis, unification, and integration of these datasets. This study utilizes computational approaches to build a new resource of transcriptomic maps for aquatic animals. This aquatic animal transcriptome map database dbATM provides de novo assembly of transcriptome, gene annotation and comparative analysis of more than twenty aquatic organisms without draft genome.Results: To improve the assembly quality, three computational tools (Trinity, Oases and SOAPdenovo-Trans) were employed to enhance individual transcriptome assembly, and CAP3 and CD-HIT-EST software were then used to merge these three assembled transcriptomes. In addition, functional annotation analysis provides valuable clues to gene characteristics, including full-length transcript coding regions, conserved domains, gene ontology and KEGG pathways. Furthermore, all aquatic animal genes are essential for comparative genomics tasks such as constructing homologous gene groups and blast databases and phylogenetic analysis.Conclusion: In conclusion, we establish a resource for non model organism aquatic animals, which is great economic and ecological importance and provide transcriptomic information including functional annotation and comparative transcriptome analysis.","Chou, Chih-Hung; Huang, Hsi-Yuan; Huang, Wei-Chih; Hsu, Sheng-Da; Hsiao, Chung-Der; Liu, Chia-Yu; Chen, Yu-Hung; Liu, Yu-Chen; Huang, Wei-Yun; Lee, Meng-Lin; Chen, Yi-Chang; Huang, Hsien-Da","Hsu, Sheng-Da/F-4576-2010; Lee, Meng-Lin/ISV-1810-2023; Chou, Chih-Hung/K-9077-2015; Liu, Yuchen/AAH-6098-2021; Huang, Hsien-Da/AAA-7376-2019; Hsiao, Chung-Der/W-4535-2019","Hsu, Sheng-Da/0000-0002-8214-1696; Lee, Meng-Lin/0000-0002-0707-5967; Chou, Chih-Hung/0000-0001-5714-1718; Hsiao, Chung-Der/0000-0002-6398-8672; Liu, Yu-Chen/0000-0002-2750-0182",The aquatic animals' transcriptome resource for comparative functional analysis,19,,10.1186/s12864-018-4463-x ,Article; Proceedings Paper ,2018.0,"Background: Aquatic animals have great economic and ecological importance. Among them, non-model organisms have been studied regarding eco-toxicity, stress biology, and environmental adaptation. Due to recent advances in next-generation sequencing techniques, large amounts of RNA-seq data for aquatic animals are publicly available. However, currently there is no comprehensive resource exist for the analysis, unification, and integration of these datasets. This study utilizes computational approaches to build a new resource of transcriptomic maps for aquatic animals. This aquatic animal transcriptome map database dbATM provides de novo assembly of transcriptome, gene annotation and comparative analysis of more than twenty aquatic organisms without draft genome.Results: To improve the assembly quality, three computational tools (Trinity, Oases and SOAPdenovo-Trans) were employed to enhance individual transcriptome assembly, and CAP3 and CD-HIT-EST software were then used to merge these three assembled transcriptomes. In addition, functional annotation analysis provides valuable clues to gene characteristics, including full-length transcript coding regions, conserved domains, gene ontology and KEGG pathways. Furthermore, all aquatic animal genes are essential for comparative genomics tasks such as constructing homologous gene groups and blast databases and phylogenetic analysis.Conclusion: In conclusion, we establish a resource for non model organism aquatic animals, which is great economic and ecological importance and provide transcriptomic information including functional annotation and comparative transcriptome analysis.",1471-2164,,,, , 16th Asia Pacific Bioinformatics Conference (APBC) - Genomics16th Asia Pacific Bioinformatics Conference (APBC) - Genomics,,out_of_scope,
4015,"Title:Hippocampus substructure segmentation using morphological vision transformer learning.

 The hippocampus plays a crucial role in memory and cognition. Because of the associated toxicity from whole brain radiotherapy, more advanced treatment planning techniques prioritize hippocampal avoidance, which depends on an accurate segmentation of the small and complexly shaped hippocampus. To achieve accurate segmentation of the anterior and posterior regions of the hippocampus from T1 weighted (T1w) MR images, we developed a novel model, Hippo-Net, which uses a cascaded model strategy. The proposed model consists of two major parts: (1) a localization model is used to detect the volume-of-interest (VOI) of hippocampus. (2) An end-to-end morphological vision transformer network (Franchietal2020Pattern Recognit.102107246, Ranemetal2022 IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW) pp 3710-3719) is used to perform substructures segmentation within the hippocampus VOI. The substructures include the anterior and posterior regions of the hippocampus, which are defined as the hippocampus proper and parts of the subiculum. The vision transformer incorporates the dominant features extracted from MR images, which are further improved by learning-based morphological operators. The integration of these morphological operators into the vision transformer increases the accuracy and ability to separate hippocampus structure into its two distinct substructures. A total of 260 T1w MRI datasets from medical segmentation decathlon dataset were used in this study. We conducted a five-fold cross-validation on the first 200 T1w MR images and then performed a hold-out test on the remaining 60 T1w MR images with the model trained on the first 200 images. In five-fold cross-validation, the Dice similarity coefficients were 0.900 ± 0.029 and 0.886 ± 0.031 for the hippocampus proper and parts of the subiculum, respectively. The mean surface distances (MSDs) were 0.426 ± 0.115 mm and 0.401 ± 0.100 mm for the hippocampus proper and parts of the subiculum, respectively. The proposed method showed great promise in automatically delineating hippocampus substructures on T1w MR images. It may facilitate the current clinical workflow and reduce the physicians' effort.","Lei, Yang; Ding, Yifu; Qiu, Richard L J; Wang, Tonghe; Roper, Justin; Fu, Yabo; Shu, Hui-Kuo; Mao, Hui; Yang, Xiaofeng",,,Hippocampus substructure segmentation using morphological vision transformer learning.,68,23,10.1088/1361-6560/ad0d45 ,Journal Article ,2023.0,"The hippocampus plays a crucial role in memory and cognition. Because of the associated toxicity from whole brain radiotherapy, more advanced treatment planning techniques prioritize hippocampal avoidance, which depends on an accurate segmentation of the small and complexly shaped hippocampus. To achieve accurate segmentation of the anterior and posterior regions of the hippocampus from T1 weighted (T1w) MR images, we developed a novel model, Hippo-Net, which uses a cascaded model strategy. The proposed model consists of two major parts: (1) a localization model is used to detect the volume-of-interest (VOI) of hippocampus. (2) An end-to-end morphological vision transformer network (Franchietal2020Pattern Recognit.102107246, Ranemetal2022 IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW) pp 3710-3719) is used to perform substructures segmentation within the hippocampus VOI. The substructures include the anterior and posterior regions of the hippocampus, which are defined as the hippocampus proper and parts of the subiculum. The vision transformer incorporates the dominant features extracted from MR images, which are further improved by learning-based morphological operators. The integration of these morphological operators into the vision transformer increases the accuracy and ability to separate hippocampus structure into its two distinct substructures. A total of 260 T1w MRI datasets from medical segmentation decathlon dataset were used in this study. We conducted a five-fold cross-validation on the first 200 T1w MR images and then performed a hold-out test on the remaining 60 T1w MR images with the model trained on the first 200 images. In five-fold cross-validation, the Dice similarity coefficients were 0.900 ± 0.029 and 0.886 ± 0.031 for the hippocampus proper and parts of the subiculum, respectively. The mean surface distances (MSDs) were 0.426 ± 0.115 mm and 0.401 ± 0.100 mm for the hippocampus proper and parts of the subiculum, respectively. The proposed method showed great promise in automatically delineating hippocampus substructures on T1w MR images. It may facilitate the current clinical workflow and reduce the physicians' effort.",,1361-6560,,, , ,,out_of_scope,
4016,"Title:Clinically applicable deep learning framework for organs at risk delineation in CT images

 Radiation therapy is one of the most widely used therapies for cancer treatment. A critical step in radiation therapy planning is to accurately delineate all organs at risk (OARs) to minimize potential adverse effects to healthy surrounding organs. However, manually delineating OARs based on computed tomography images is time-consuming and error-prone. Here, we present a deep learning model to automatically delineate OARs in head and neck, trained on a dataset of 215 computed tomography scans with 28 OARs manually delineated by experienced radiation oncologists. On a hold-out dataset of 100 computed tomography scans, our model achieves an average Dice similarity coefficient of 78.34% across the 28 OARs, significantly outperforming human experts and the previous state-of-the-art method by 10.05% and 5.18%, respectively. Our model takes only a few seconds to delineate an entire scan, compared to over half an hour by human experts. These findings demonstrate the potential for deep learning to improve the quality and reduce the treatment planning time of radiation therapy. To keep radiation therapy from damaging healthy tissue, expert radiologists have to segment CT scans into individual organs. A new deep learning-based method for delineating organs in the area of head and neck performs faster and more accurately than human experts.","Tang, Hao; Chen, Xuming; Liu, Yang; Lu, Zhipeng; You, Junhua; Yang, Mingzhou; Yao, Shengyu; Zhao, Guoqi; Xu, Yi; Chen, Tingfeng; Liu, Yong; Xie, Xiaohui","sun, chen/JCP-0396-2023","Chen, Xuming/0000-0002-1876-4573; Xie, Xiaohui/0000-0002-5479-6345",Clinically applicable deep learning framework for organs at risk delineation in CT images,1,10,10.1038/s42256-019-0099-z ,Article ,2019.0,"Radiation therapy is one of the most widely used therapies for cancer treatment. A critical step in radiation therapy planning is to accurately delineate all organs at risk (OARs) to minimize potential adverse effects to healthy surrounding organs. However, manually delineating OARs based on computed tomography images is time-consuming and error-prone. Here, we present a deep learning model to automatically delineate OARs in head and neck, trained on a dataset of 215 computed tomography scans with 28 OARs manually delineated by experienced radiation oncologists. On a hold-out dataset of 100 computed tomography scans, our model achieves an average Dice similarity coefficient of 78.34% across the 28 OARs, significantly outperforming human experts and the previous state-of-the-art method by 10.05% and 5.18%, respectively. Our model takes only a few seconds to delineate an entire scan, compared to over half an hour by human experts. These findings demonstrate the potential for deep learning to improve the quality and reduce the treatment planning time of radiation therapy. To keep radiation therapy from damaging healthy tissue, expert radiologists have to segment CT scans into individual organs. A new deep learning-based method for delineating organs in the area of head and neck performs faster and more accurately than human experts.",,2522-5839,,480-491, , ,,out_of_scope,
4017,"Title:Multi-atlas and unsupervised learning approach to perirectal space segmentation in CT images

 Perirectal space segmentation in computed tomography images aids in quantifying radiation dose received by healthy tissues and toxicity during the course of radiation therapy treatment of the prostate. Radiation dose normalised by tissue volume facilitates predicting outcomes or possible harmful side effects of radiation therapy treatment. Manual segmentation of the perirectal space is time consuming and challenging in the presence of inter-patient anatomical variability and may suffer from inter- and intra-observer variabilities. However automatic or semi-automatic segmentation of the perirectal space in CT images is a challenging task due to inter patient anatomical variability, contrast variability and imaging artifacts. In the model presented here, a volume of interest is obtained in a multi-atlas based segmentation approach. Un-supervised learning in the volume of interest with a Gaussian-mixture-modeling based clustering approach is adopted to achieve a soft segmentation of the perirectal space. Probabilities from soft clustering are further refined by rigid registration of the multi-atlas mask in a probabilistic domain. A maximum a posteriori approach is adopted to achieve a binary segmentation from the refined probabilities. A mean volume similarity value of 97% and a mean surface difference of 3.06 +/- 0.51 mm is achieved in a leave-one-patient-out validation framework with a subset of a clinical trial dataset. Qualitative results show a good approximation of the perirectal space volume compared to the ground truth.","Ghose, Soumya; Denham, James W.; Ebert, Martin A.; Kennedy, Angel; Mitra, Jhimli; Dowling, Jason A.","Ghose, Soumya/C-8767-2014; Dowling, Jason/A-1420-2008; Ebert, Martin/O-4039-2014; DENHAM, JAMES/G-7505-2013","Dowling, Jason/0000-0001-9349-2275; Ebert, Martin/0000-0002-6875-0719; DENHAM, JAMES/0000-0002-4177-9503",Multi-atlas and unsupervised learning approach to perirectal space segmentation in CT images,39,4,10.1007/s13246-016-0496-0 ,Article ,2016.0,"Perirectal space segmentation in computed tomography images aids in quantifying radiation dose received by healthy tissues and toxicity during the course of radiation therapy treatment of the prostate. Radiation dose normalised by tissue volume facilitates predicting outcomes or possible harmful side effects of radiation therapy treatment. Manual segmentation of the perirectal space is time consuming and challenging in the presence of inter-patient anatomical variability and may suffer from inter- and intra-observer variabilities. However automatic or semi-automatic segmentation of the perirectal space in CT images is a challenging task due to inter patient anatomical variability, contrast variability and imaging artifacts. In the model presented here, a volume of interest is obtained in a multi-atlas based segmentation approach. Un-supervised learning in the volume of interest with a Gaussian-mixture-modeling based clustering approach is adopted to achieve a soft segmentation of the perirectal space. Probabilities from soft clustering are further refined by rigid registration of the multi-atlas mask in a probabilistic domain. A maximum a posteriori approach is adopted to achieve a binary segmentation from the refined probabilities. A mean volume similarity value of 97% and a mean surface difference of 3.06 +/- 0.51 mm is achieved in a leave-one-patient-out validation framework with a subset of a clinical trial dataset. Qualitative results show a good approximation of the perirectal space volume compared to the ground truth.",0158-9938,1879-5447,,933-941, , ,,out_of_scope,
4018,"Title:Management of gastrointestinal symptoms in advanced cancer patients: the rapid learning cancer clinic model.

 PURPOSE OF REVIEW: Gastrointestinal symptoms are prevalent, often persistent, and detrimental to patients' quality of life. This review discusses evaluation of gastrointestinal symptoms as patient-reported outcomes (PROs) and presents an information technology-based system for symptom monitoring and management. The electronic PRO (ePRO) system is then placed within the larger context of rapid learning healthcare, a concept currently under development in which data obtained through both research and clinical care continuously build large datasets for analysis, seed future research, fuel expansion of the evidence base, and support clinical decision-making.RECENT FINDINGS: PROs are increasingly recognized as valid measures of symptoms, functional status, and quality of life. They have demonstrated prognostic significance and are being developed as a component of toxicity reporting in clinical trials. Recent studies have validated an information technology-based approach for collecting ePROs in routine clinical care. The system is feasible and acceptable; electronic and paper-based data, collected on validated assessment instruments, are equivalent; ePRO collection supports real-time symptom monitoring and management. The ePRO system represents a first step toward implementing rapid learning healthcare at the clinic level.SUMMARY: ePROs provide a rich source of information to support monitoring and clinical management of troubling symptoms such as gastrointestinal complaints.","Abernethy, Amy P; Wheeler, Jane L; Zafar, S Yousuf",,"Abernethy, Amy/0000-0001-6930-8722; Zafar, S. Yousuf/0000-0002-9039-5258",Management of gastrointestinal symptoms in advanced cancer patients: the rapid learning cancer clinic model.,4,1,10.1097/SPC.0b013e32833575fd ,"Journal Article; Research Support, Non-U.S. Gov't; Review ",2010.0,"PURPOSE OF REVIEW: Gastrointestinal symptoms are prevalent, often persistent, and detrimental to patients' quality of life. This review discusses evaluation of gastrointestinal symptoms as patient-reported outcomes (PROs) and presents an information technology-based system for symptom monitoring and management. The electronic PRO (ePRO) system is then placed within the larger context of rapid learning healthcare, a concept currently under development in which data obtained through both research and clinical care continuously build large datasets for analysis, seed future research, fuel expansion of the evidence base, and support clinical decision-making.RECENT FINDINGS: PROs are increasingly recognized as valid measures of symptoms, functional status, and quality of life. They have demonstrated prognostic significance and are being developed as a component of toxicity reporting in clinical trials. Recent studies have validated an information technology-based approach for collecting ePROs in routine clinical care. The system is feasible and acceptable; electronic and paper-based data, collected on validated assessment instruments, are equivalent; ePRO collection supports real-time symptom monitoring and management. The ePRO system represents a first step toward implementing rapid learning healthcare at the clinic level.SUMMARY: ePROs provide a rich source of information to support monitoring and clinical management of troubling symptoms such as gastrointestinal complaints.",,1751-4266,,36-45, , ,,out_of_scope,
4019,"Title:Study of Nematic Transition Temperatures in Themotropic Liquid Crystal Using Heuristic Method and Radial Basis Function Neural Networks and Support Vector Machine

 Quantitative Structure-Property Relationships (QSPRs) models have been successfully developed for the prediction of the nematic transition temperatures (T-N) of 42 thermotropic liquid crystals. Heuristic Method (HM) and Radial Basis Function Neural Networks (RBFNNs) and Support Vector Machine (SVM) were utilized to Construct the linear and non-linear QSPRs models. respectively. Comparing the whole results obtained front the three models, the RBFNNs model was much better. The optimal QSPRs model which was established based on RBFNNs gave a square correlation coefficient (R-2) of 0.984, 0.953, 0.973, and Root-Mean Square (RMS) error of 2.19, 4.13, and 2.99 for the training set, the test set, and the whole set, respectively. Some analysis to the dataset and evaluation were done in the paper. All the results indicated that the proposed QSPRs model was robust and satisfactory.","Gong, Zhiguo; Zhang, Ruisheng; Xia, Binbin; Hu, Rongjing; Fan, Botao",,"Zhang, Ruisheng/0000-0002-6585-2656",Study of Nematic Transition Temperatures in Themotropic Liquid Crystal Using Heuristic Method and Radial Basis Function Neural Networks and Support Vector Machine,27,11-12,10.1002/qsar.200860027 ,Article ,2008.0,"Quantitative Structure-Property Relationships (QSPRs) models have been successfully developed for the prediction of the nematic transition temperatures (T-N) of 42 thermotropic liquid crystals. Heuristic Method (HM) and Radial Basis Function Neural Networks (RBFNNs) and Support Vector Machine (SVM) were utilized to Construct the linear and non-linear QSPRs models. respectively. Comparing the whole results obtained front the three models, the RBFNNs model was much better. The optimal QSPRs model which was established based on RBFNNs gave a square correlation coefficient (R-2) of 0.984, 0.953, 0.973, and Root-Mean Square (RMS) error of 2.19, 4.13, and 2.99 for the training set, the test set, and the whole set, respectively. Some analysis to the dataset and evaluation were done in the paper. All the results indicated that the proposed QSPRs model was robust and satisfactory.",1611-020X,1611-0218,,1282-1290, , ,,out_of_scope,
4020,"Title:PEARC '22: Practice and Experience in Advanced Research Computing Proceedings

 The growing prevalence of online hate speech is concerning, given the massive growth of online platforms. Hate speech is defined as language that attacks, humiliates, or incites violence against specific groups. According to research, there is a link between online hate speech and real-world crimes, as well as victims' deteriorating mental health. To combat the online prevalence of abusive speech, hate speech detection models based on machine learning and natural language processing are being developed to automatically detect the toxicity of online content. However, current models tend to mislabel African American English (AAE) text as hate speech at a significantly higher rate than texts written in Standard American English (SAE). To confirm the existence of systematic racism within these models, I evaluate a logical regression model and a BERT model. Then, I determine the efficacy of the bias reduction method for the BERT model and the correlation between model performance and reduced bias.","Youn, Jennie; Bowen, Anne",,,PEARC '22: Practice and Experience in Advanced Research Computing Proceedings,,,10.1145/3491418.3535185 ,Proceedings Paper ,2022.0,"The growing prevalence of online hate speech is concerning, given the massive growth of online platforms. Hate speech is defined as language that attacks, humiliates, or incites violence against specific groups. According to research, there is a link between online hate speech and real-world crimes, as well as victims' deteriorating mental health. To combat the online prevalence of abusive speech, hate speech detection models based on machine learning and natural language processing are being developed to automatically detect the toxicity of online content. However, current models tend to mislabel African American English (AAE) text as hate speech at a significantly higher rate than texts written in Standard American English (SAE). To confirm the existence of systematic racism within these models, I evaluate a logical regression model and a BERT model. Then, I determine the efficacy of the bias reduction method for the BERT model and the correlation between model performance and reduced bias.",,,978-1-4503-9161-0,, ," Conference on Practice and Experience in Advanced Research Computing (PEARC) - Revolutionary - Computing, Connections, YouConference on Practice and Experience in Advanced Research Computing (PEARC) - Revolutionary - Computing, Connections, You",,detection#evaluation,
4021,"Title:Highly-Bespoke Robust Printed Neuromorphic Circuits

 With the rapid growth of the Internet of Things, smart fast-moving consumer products, and wearable devices, requirements such as flexibility, non-toxicity, and low cost are desperately required. However, these requirements are usually beyond the reach of conventional rigid silicon technologies. In this regard, printed electronics offers a promising alternative. Combined with neuromorphic computing, printed neuromorphic circuits offer not only the aforementioned properties, but also compensate for some of the weaknesses of printed electronics, such as manufacturing variations, low device count, and high latency. Generally, (printed) neuromorphic circuits express their functionality through printed resistor crossbars to emulate matrix multiplication, and nonlinear circuitry to express activation functions. The values of the former are usually learned, while the latter is designed beforehand and considered fixed in training for all tasks. The additive manufacturing feature of printed electronics allows the design of highly-bespoke designs. In the case of printed neuromorphic circuits, the circuit is optimized to a particular dataset. Moreover, we explore an approach to learn not only the values of the crossbar resistances, but also the parameterization of the nonlinear components for a bespoke implementation. While providing additional flexibility of the functionality to be expressed, this will also allow an increased robustness against printing variation. The experiments show that the accuracy and robustness of printed neuromorphic circuits can be improved by 26% and 75% respectively under 10% variation of circuit components.","Zhao, Haibin; Sapui, Brojogopal; Hefenbrock, Michael; Yang, Zhidong; Beigl, Michael; Tahoori, Mehdi B.","ZHAO, Haibin/HGB-7979-2022",,Highly-Bespoke Robust Printed Neuromorphic Circuits,,, ,Proceedings Paper ,2023.0,"With the rapid growth of the Internet of Things, smart fast-moving consumer products, and wearable devices, requirements such as flexibility, non-toxicity, and low cost are desperately required. However, these requirements are usually beyond the reach of conventional rigid silicon technologies. In this regard, printed electronics offers a promising alternative. Combined with neuromorphic computing, printed neuromorphic circuits offer not only the aforementioned properties, but also compensate for some of the weaknesses of printed electronics, such as manufacturing variations, low device count, and high latency. Generally, (printed) neuromorphic circuits express their functionality through printed resistor crossbars to emulate matrix multiplication, and nonlinear circuitry to express activation functions. The values of the former are usually learned, while the latter is designed beforehand and considered fixed in training for all tasks. The additive manufacturing feature of printed electronics allows the design of highly-bespoke designs. In the case of printed neuromorphic circuits, the circuit is optimized to a particular dataset. Moreover, we explore an approach to learn not only the values of the crossbar resistances, but also the parameterization of the nonlinear components for a bespoke implementation. While providing additional flexibility of the functionality to be expressed, this will also allow an increased robustness against printing variation. The experiments show that the accuracy and robustness of printed neuromorphic circuits can be improved by 26% and 75% respectively under 10% variation of circuit components.",1530-1591,,979-8-3503-9624-9,, ," Design, Automation and Test in Europe Conference and Exhibition (DATE)Design, Automation and Test in Europe Conference and Exhibition (DATE)",,out_of_scope,
4022,"Title:Immunoinformatics aided approach for predicting potent cytotoxic T cell epitopes of respiratory syncytial virus

 Respiratory syncytial virus (RSV) is an infectious viral pathogen that causing serious respiratory infection in adults and neonates. The only approved therapies for RSV are the monoclonal antibodies palivizumab and its derivative motavizumab. Both treatments are expensive and require a hospital setting for administration. A vaccine represents a safe, effective and cheaper alternative for preventing RSV infection. In silico prediction methods have proven to be valuable in speeding up the process of vaccine design. In this study, reverse vaccinology methods were used to predict the cytotoxic T lymphocytes (CTL) epitopes from the entire proteome of RSV strain A. From amongst 3402 predicted binders to 12 high frequency alleles from the Immune Epitope Database (IEDB), 567 had positive processing scores while 327 epitopes were predicted to be immunogenic. A thorough examination of the 327 epitopes for possible antigenicity, allergenicity and toxicity resulted in 95 epitopes with desirable properties. A BLASTp analysis revealed 94 unique and non-homologous epitopes that were subjected to molecular docking across the 12 high frequency alleles. The final dataset of 70 epitopes contained 13 experimentally proven and 57 unique epitopes from a total of 11 RSV proteins. From our findings on selected T-cell-specific RSV antigen epitopes, notably the four epitopes confirmed to exhibit stable binding by molecular dynamics. The prediction pipeline used in this study represents an effective way to screen the immunogenic epitopes from other pathogens.Communicated by Ramaswamy H. Sarma","Anandhan, Gayathri; Narkhede, Yogesh B.; Mohan, Manikandan; Paramasivam, Premasudha",,"Mohan, Manikandan/0000-0002-0132-7510; Narkhede, Yogesh/0000-0003-4358-2912",Immunoinformatics aided approach for predicting potent cytotoxic T cell epitopes of respiratory syncytial virus,,,10.1080/07391102.2023.2191136 ,Article; Early Access ,,"Respiratory syncytial virus (RSV) is an infectious viral pathogen that causing serious respiratory infection in adults and neonates. The only approved therapies for RSV are the monoclonal antibodies palivizumab and its derivative motavizumab. Both treatments are expensive and require a hospital setting for administration. A vaccine represents a safe, effective and cheaper alternative for preventing RSV infection. In silico prediction methods have proven to be valuable in speeding up the process of vaccine design. In this study, reverse vaccinology methods were used to predict the cytotoxic T lymphocytes (CTL) epitopes from the entire proteome of RSV strain A. From amongst 3402 predicted binders to 12 high frequency alleles from the Immune Epitope Database (IEDB), 567 had positive processing scores while 327 epitopes were predicted to be immunogenic. A thorough examination of the 327 epitopes for possible antigenicity, allergenicity and toxicity resulted in 95 epitopes with desirable properties. A BLASTp analysis revealed 94 unique and non-homologous epitopes that were subjected to molecular docking across the 12 high frequency alleles. The final dataset of 70 epitopes contained 13 experimentally proven and 57 unique epitopes from a total of 11 RSV proteins. From our findings on selected T-cell-specific RSV antigen epitopes, notably the four epitopes confirmed to exhibit stable binding by molecular dynamics. The prediction pipeline used in this study represents an effective way to screen the immunogenic epitopes from other pathogens.Communicated by Ramaswamy H. Sarma",0739-1102,1538-0254,,, , ,,out_of_scope,
4023,"Title:Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making

 A growing literature on human-AI decision-making investigates strategies for combining human judgment with statistical models to improve decision-making. Research in this area often evaluates proposed improvements to models, interfaces, or workflows by demonstrating improved predictive performance on ground truth labels. However, this practice overlooks a key difference between human judgments and model predictions. Whereas humans commonly reason about broader phenomena of interest in a decision including latent constructs that are not directly observable, such as disease status, the toxicity of online comments, or future job performance - predictive models target proxy labels that are readily available in existing datasets. Predictive models' reliance on simplistic proxies for these nuanced phenomena makes them vulnerable to various sources of statistical bias. In this paper, we identify five sources of target variable bias that can impact the validity of proxy labels in human-AI decision-making tasks. We develop a causal framework to disentangle the relationship between each bias and clarify which are of concern in specific human-AI decision-making tasks. We demonstrate how our framework can be used to articulate implicit assumptions made in prior modeling work, and we recommend evaluation strategies for verifying whether these assumptions hold in practice. We then leverage our framework to re-examine the designs of prior human subjects experiments that investigate human-AI decision-making, finding that only a small fraction of studies examine factors related to target variable bias. We conclude by discussing opportunities to better address target variable bias in future research.","Guerdan, Luke; Coston, Amanda; Wu, Zhiwei Steven; Holstein, Kenneth",,"Holstein, Ken/0000-0001-6730-922X",Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making,,,10.1145/3593013.3594036 ,Proceedings Paper ,2023.0,"A growing literature on human-AI decision-making investigates strategies for combining human judgment with statistical models to improve decision-making. Research in this area often evaluates proposed improvements to models, interfaces, or workflows by demonstrating improved predictive performance on ground truth labels. However, this practice overlooks a key difference between human judgments and model predictions. Whereas humans commonly reason about broader phenomena of interest in a decision including latent constructs that are not directly observable, such as disease status, the toxicity of online comments, or future job performance - predictive models target proxy labels that are readily available in existing datasets. Predictive models' reliance on simplistic proxies for these nuanced phenomena makes them vulnerable to various sources of statistical bias. In this paper, we identify five sources of target variable bias that can impact the validity of proxy labels in human-AI decision-making tasks. We develop a causal framework to disentangle the relationship between each bias and clarify which are of concern in specific human-AI decision-making tasks. We demonstrate how our framework can be used to articulate implicit assumptions made in prior modeling work, and we recommend evaluation strategies for verifying whether these assumptions hold in practice. We then leverage our framework to re-examine the designs of prior human subjects experiments that investigate human-AI decision-making, finding that only a small fraction of studies examine factors related to target variable bias. We conclude by discussing opportunities to better address target variable bias in future research.",,,978-1-4503-7252-7,688-704, ," 6th ACM Conference on Fairness, Accountability, and Transparency (FAccT)6th ACM Conference on Fairness, Accountability, and Transparency (FAccT)",,evaluation#methodology,
4024,"Title:Revealing the metabolome of animal tissues using 1H nuclear magnetic resonance spectroscopy.

 The measurement of tissue-specific metabolic fingerprints can be of particular interest when investigating disease processes, mechanisms of toxicity, or when knowledge of the metabolic interactions between different organs is required. This chapter presents several optimized protocols for the extraction of metabolites from animal tissues, their analysis by 1H nuclear magnetic resonance (NMR) spectroscopy, and the subsequent spectral preprocessing required for an NMR-based metabolomics experiment. First, the three critical steps in the preparation of tissue extracts for NMR analysis are described, including both a perchloric acid protocol for the extraction of polar metabolites, and a methanol:chloroform protocol for extraction of polar and lipophilic metabolites. Then a series of NMR experiments are described including a standard one-dimensional (1D) 1H NMR study, a 1D 1H Carr-Purcell-Meiboom-Gill spin-echo experiment, and a two-dimensional 1H-1H J-resolved NMR experiment. The advantages and limitations of each experiment for metabolomics research are discussed. Analysis of the resulting NMR datasets is typically conducted in two phases comprising low level spectral preprocessing and high level multivariate analysis. NMR spectral preprocessing is a critical step that converts raw NMR spectra into an appropriate data format for multivariate analysis. A detailed protocol for preprocessing NMR data, using ProMetab software, is presented. Because a plethora of algorithms exist for multivariate analyses, which can be used to construct classification models or for biomarker discovery, this is beyond the scope of the current chapter.","Viant, Mark R","Viant, Mark R/B-6339-2009","Viant, Mark R/0000-0001-5898-4119",Revealing the metabolome of animal tissues using 1H nuclear magnetic resonance spectroscopy.,358,,10.1007/978-1-59745-244-1_13 ,"Evaluation Study; Journal Article; Research Support, Non-U.S. Gov't ",2007.0,"The measurement of tissue-specific metabolic fingerprints can be of particular interest when investigating disease processes, mechanisms of toxicity, or when knowledge of the metabolic interactions between different organs is required. This chapter presents several optimized protocols for the extraction of metabolites from animal tissues, their analysis by 1H nuclear magnetic resonance (NMR) spectroscopy, and the subsequent spectral preprocessing required for an NMR-based metabolomics experiment. First, the three critical steps in the preparation of tissue extracts for NMR analysis are described, including both a perchloric acid protocol for the extraction of polar metabolites, and a methanol:chloroform protocol for extraction of polar and lipophilic metabolites. Then a series of NMR experiments are described including a standard one-dimensional (1D) 1H NMR study, a 1D 1H Carr-Purcell-Meiboom-Gill spin-echo experiment, and a two-dimensional 1H-1H J-resolved NMR experiment. The advantages and limitations of each experiment for metabolomics research are discussed. Analysis of the resulting NMR datasets is typically conducted in two phases comprising low level spectral preprocessing and high level multivariate analysis. NMR spectral preprocessing is a critical step that converts raw NMR spectra into an appropriate data format for multivariate analysis. A detailed protocol for preprocessing NMR data, using ProMetab software, is presented. Because a plethora of algorithms exist for multivariate analyses, which can be used to construct classification models or for biomarker discovery, this is beyond the scope of the current chapter.",1064-3745,,,229-46, , ,,out_of_scope,
4025,"Title:An Intelligent Hazardous Waste Detection and Classification Model Using Ensemble Learning Techniques

 Proper waste management models using recent technologies like computer vision, machine learning (ML), and deep learning (DL) are needed to effectively handle the massive quantity of increasing waste. Therefore, waste classification becomes a crucial topic which helps to categorize waste into hazardous or non-hazardous ones and thereby assist in the decision making of the waste management process. This study concentrates on the design of hazardous waste detection and classification using ensemble learn-ing (HWDC-EL) technique to reduce toxicity and improve human health. The goal of the HWDC-EL technique is to detect the multiple classes of wastes, particularly hazardous and non-hazardous wastes. The HWDC-EL technique involves the ensemble of three feature extractors using Model Averaging technique namely discrete local binary patterns (DLBP), Effi-cientNet, and DenseNet121. In addition, the flower pollination algorithm (FPA) based hyperparameter optimizers are used to optimally adjust the parameters involved in the EfficientNet and DenseNet121 models. Moreover, a weighted voting-based ensemble classifier is derived using three machine learning algorithms namely support vector machine (SVM), extreme learning machine (ELM), and gradient boosting tree (GBT). The performance of the HWDC-EL technique is tested using a benchmark Garbage dataset and it obtains a maximum accuracy of 98.85%.","Al Duhayyim, Mesfer; Alotaibi, Saud S.; Al-Otaibi, Shaha; Al-Wesabi, Fahd N.; Othman, Mahmoud; Yaseen, Ishfaq; Rizwanullah, Mohammed; Motwakel, Abdelwahed","Al Duhayyim, Mesfer/AGP-7942-2022; Al-Wesabi, Fahd N./AAV-6279-2020; Alotaibi, Saud/AAE-5224-2019; Motwakel, Dr. Abdelwahed/AFM-6103-2022","Al Duhayyim, Mesfer/0000-0003-4024-271X; Al-Wesabi, Fahd N./0000-0002-4389-4927; Alotaibi, Saud/0000-0003-1082-513X; Motwakel, Dr. Abdelwahed/0000-0003-4084-5457",An Intelligent Hazardous Waste Detection and Classification Model Using Ensemble Learning Techniques,74,2,10.32604/cmc.2023.033250 ,Article ,2023.0,"Proper waste management models using recent technologies like computer vision, machine learning (ML), and deep learning (DL) are needed to effectively handle the massive quantity of increasing waste. Therefore, waste classification becomes a crucial topic which helps to categorize waste into hazardous or non-hazardous ones and thereby assist in the decision making of the waste management process. This study concentrates on the design of hazardous waste detection and classification using ensemble learn-ing (HWDC-EL) technique to reduce toxicity and improve human health. The goal of the HWDC-EL technique is to detect the multiple classes of wastes, particularly hazardous and non-hazardous wastes. The HWDC-EL technique involves the ensemble of three feature extractors using Model Averaging technique namely discrete local binary patterns (DLBP), Effi-cientNet, and DenseNet121. In addition, the flower pollination algorithm (FPA) based hyperparameter optimizers are used to optimally adjust the parameters involved in the EfficientNet and DenseNet121 models. Moreover, a weighted voting-based ensemble classifier is derived using three machine learning algorithms namely support vector machine (SVM), extreme learning machine (ELM), and gradient boosting tree (GBT). The performance of the HWDC-EL technique is tested using a benchmark Garbage dataset and it obtains a maximum accuracy of 98.85%.",1546-2218,1546-2226,,3315-3332, , ,,out_of_scope,
4026,"Title:Source-specific risk assessment for cadmium in wheat and maize: Towards an enrichment model for China

 Cadmium (Cd) pollution of agricultural soil is of public concern due to its high potential toxicity and mobility. This study aimed to reveal the risk of Cd accumulation in soil and wheat/maize systems, with a specific focus on the source-specific ecological risk, human health risk and Cd enrichment model. For this we investigated more than 6100 paired soil and grain samples with 216 datasets including soil Cd contents, soil pH and grain Cd contents of 85 sites from China. The results showed that mining activities, sewage irrigation, industrial activities and agricultural practices were the critical factors causing Cd accumulation in wheat and maize cultivated sites. Thereinto, mining activities contributed to a higher Cd accumulation risk in the southwest China and Middle Yellow River regions; sewage irrigation influenced the Cd accumulation in the North China Plain. In addition, the investigated sites were classified into different categories by comparing their soil and grain Cd contents with the Chinese soil screening values and food safety values, respectively. Cd enrichment models were developed to predict the Cd levels in wheat and maize grains. The results showed that the models exhibited a good performance for predicting the grain Cd contents among safe and warning sites of wheat ( R 2 = 0.61 and 0.72, respectively); while the well-fitted model for maize was prone to the overestimated sites ( R 2 = 0.77). This study will provide national viewpoints for the risk assessments and prediction of Cd accumulation in soil and wheat/maize systems. (c) 2022 The Research Center for Eco-Environmental Sciences, Chinese Academy of Sciences. Published by Elsevier B.V.","Zhuang, Zhong; Wang, Qiqi; Huang, Siyu; NinoSavala, Andrea Giovanna; Wan, Yanan; Li, Huafen; Schweiger, Andreas H.; Fangmeier, Andreas; Franzaring, Juergen","wang, qi/ITT-9652-2023; wang, qi/HTN-8786-2023; wang, qi/IAN-4150-2023; Schweiger, Andreas/E-6282-2019","wang, qi/0000-0002-2794-6897; Franzaring, Jurgen/0000-0002-9198-2147; Schweiger, Andreas/0000-0003-2656-5918; Nino Savala, Andrea Giovanna/0000-0002-1337-4840",Source-specific risk assessment for cadmium in wheat and maize: Towards an enrichment model for China,125,,10.1016/j.jes.2022.02.024 ,Article ,2023.0,"Cadmium (Cd) pollution of agricultural soil is of public concern due to its high potential toxicity and mobility. This study aimed to reveal the risk of Cd accumulation in soil and wheat/maize systems, with a specific focus on the source-specific ecological risk, human health risk and Cd enrichment model. For this we investigated more than 6100 paired soil and grain samples with 216 datasets including soil Cd contents, soil pH and grain Cd contents of 85 sites from China. The results showed that mining activities, sewage irrigation, industrial activities and agricultural practices were the critical factors causing Cd accumulation in wheat and maize cultivated sites. Thereinto, mining activities contributed to a higher Cd accumulation risk in the southwest China and Middle Yellow River regions; sewage irrigation influenced the Cd accumulation in the North China Plain. In addition, the investigated sites were classified into different categories by comparing their soil and grain Cd contents with the Chinese soil screening values and food safety values, respectively. Cd enrichment models were developed to predict the Cd levels in wheat and maize grains. The results showed that the models exhibited a good performance for predicting the grain Cd contents among safe and warning sites of wheat ( R 2 = 0.61 and 0.72, respectively); while the well-fitted model for maize was prone to the overestimated sites ( R 2 = 0.77). This study will provide national viewpoints for the risk assessments and prediction of Cd accumulation in soil and wheat/maize systems. (c) 2022 The Research Center for Eco-Environmental Sciences, Chinese Academy of Sciences. Published by Elsevier B.V.",1001-0742,1878-7320,,723-734, , ,,out_of_scope,
4027,"Title:Grapevine Nutritional Disorder Detection Using Image Processing

 Vine nutrition is a key element of vineyard management. Nutrient disorders affect vine growth, crop yield, berry composition, and wine quality. Each vineyard may have a unique combination of soil type, vine age, canopy architecture, cultivar and rootstock. Therefore nutritional requirements vary between vineyards and even locations within a vineyard. Nutritional disorders can be detected visually on leaves, fruits, stems or roots. The advancement of image processing and machine learning has made it feasible to develop rapid tools to assess vine nutritional disorders using these symptoms. This paper presents our proposed method of using a smartphone app to capture and analyse images of vine leaves for identifying nutritional disorders of grapevines rapidly and conveniently. Nutrient deficiency/toxicity symptoms were created in hydroponically grown grapevines of both red and white varieties. RGB (red, green, and blue) images of old and young leaves were taken weekly to track the progression of symptoms. A benchmarked dataset was developed through a laboratory based nutrient analysis of the petioles. A wide range of features (e.g., texture, smoothness, contrast and shape) were selected for the following customised machine learning techniques. Our proposed algorithm was developed to identify specific deficiency and toxicity symptoms through training and testing process. The support vector machine has achieved a 98.99% average accuracy in the testing.","Rahaman, D. M. Motiur; Baby, Tintu; Oczkowski, Alex; Paul, Manoranjan; Zheng, Lihong; Schmidtke, Leigh M.; Holzapfel, Bruno P.; Walker, Rob R.; Rogiers, Suzy Y.","Zheng, Lihong/ACI-9716-2022; Rogiers, Suzy/AAO-3360-2020; Schmidtke, Leigh/A-4355-2012; Paul, Manoranjan/AAD-4047-2021; Walker, Rob R/C-2764-2015","Zheng, Lihong/0000-0001-5728-4356; Schmidtke, Leigh/0000-0001-9765-5510; Paul, Manoranjan/0000-0001-6870-5056; Baby, Tintu/0000-0001-8417-0995; Walker, Rob/0000-0002-1409-7937; /0000-0002-4618-1148; Rogiers, Suzy/0000-0001-6637-3561",Grapevine Nutritional Disorder Detection Using Image Processing,11854,,10.1007/978-3-030-34879-3_15 ,Proceedings Paper ,2019.0,"Vine nutrition is a key element of vineyard management. Nutrient disorders affect vine growth, crop yield, berry composition, and wine quality. Each vineyard may have a unique combination of soil type, vine age, canopy architecture, cultivar and rootstock. Therefore nutritional requirements vary between vineyards and even locations within a vineyard. Nutritional disorders can be detected visually on leaves, fruits, stems or roots. The advancement of image processing and machine learning has made it feasible to develop rapid tools to assess vine nutritional disorders using these symptoms. This paper presents our proposed method of using a smartphone app to capture and analyse images of vine leaves for identifying nutritional disorders of grapevines rapidly and conveniently. Nutrient deficiency/toxicity symptoms were created in hydroponically grown grapevines of both red and white varieties. RGB (red, green, and blue) images of old and young leaves were taken weekly to track the progression of symptoms. A benchmarked dataset was developed through a laboratory based nutrient analysis of the petioles. A wide range of features (e.g., texture, smoothness, contrast and shape) were selected for the following customised machine learning techniques. Our proposed algorithm was developed to identify specific deficiency and toxicity symptoms through training and testing process. The support vector machine has achieved a 98.99% average accuracy in the testing.",0302-9743,1611-3349,978-3-030-34879-3; 978-3-030-34878-6,184-196, , 9th Pacific-Rim Symposium on Image and Video Technology (PSIVT)9th Pacific-Rim Symposium on Image and Video Technology (PSIVT),,out_of_scope,
4028,"Title:A test of association between spatially defined exposure patterns and health outcome risk contours

 Advances in the availability of geographically referenced health and environmental quality data of high spatial resolution have created new opportunities in environmental epidemiology. Novel statistical methods for linking health, exposure, and hazards are required to underpin the development of public health tracking. A test for the association between spatial contours of health risk and exposure is outlined. This test is examined using, as an example, the spatial contours of congenital malformation risk obtained from a routine dataset in the vicinity of a landfill site and an exposure model based on exponential reduction with distance from the site. Spatial contours of risk of congenital malformation were simulated using the exposure model stated and a given population pattern. These were compared with the corresponding expected risk derived from routine birth data to yield relative risk contours. For each simulation three test statistics were devised: the slope of the regression line of standardized relative risk on exposure level, the proportion of standardized relative risks above zero, and the mean standardized relative risk of individuals not subject to exposure. The distributions of these test statistics (under the null no exposure from site and alternative hypotheses) were determined from a simulation exercise. A comparison of receiver operator characteristic (ROC) curves between those relating to the proposed test and those relating to a widely used method proposed by Stone (1988) demonstrated our test to be more efficient. Formal statistical testing of the concordance between spatial contours of risk and environmental exposure enables optimal use of spatial data.","Read, Jessica; Matthews, Ian; Nix, Barry",,,A test of association between spatially defined exposure patterns and health outcome risk contours,70,24,10.1080/15287390701601210 ,Article ,2007.0,"Advances in the availability of geographically referenced health and environmental quality data of high spatial resolution have created new opportunities in environmental epidemiology. Novel statistical methods for linking health, exposure, and hazards are required to underpin the development of public health tracking. A test for the association between spatial contours of health risk and exposure is outlined. This test is examined using, as an example, the spatial contours of congenital malformation risk obtained from a routine dataset in the vicinity of a landfill site and an exposure model based on exponential reduction with distance from the site. Spatial contours of risk of congenital malformation were simulated using the exposure model stated and a given population pattern. These were compared with the corresponding expected risk derived from routine birth data to yield relative risk contours. For each simulation three test statistics were devised: the slope of the regression line of standardized relative risk on exposure level, the proportion of standardized relative risks above zero, and the mean standardized relative risk of individuals not subject to exposure. The distributions of these test statistics (under the null no exposure from site and alternative hypotheses) were determined from a simulation exercise. A comparison of receiver operator characteristic (ROC) curves between those relating to the proposed test and those relating to a widely used method proposed by Stone (1988) demonstrated our test to be more efficient. Formal statistical testing of the concordance between spatial contours of risk and environmental exposure enables optimal use of spatial data.",1528-7394,,,2056-2063, , ,,out_of_scope,
4029,"Title:Multiple Adverse Effects Prediction in Longitudinal Cancer Treatment

 Adverse effects, such as voice change and fatigue, are prevalent in cancer treatment duration. These adverse effects have been significant burden for patients physically and emotionally. Predicting multiple adverse effects becomes important for patients and oncologists. In this paper, we formulate the prediction of multiple adverse effects in cancer treatment as a longitudinal multiple-output regression problem. The correlated multiple outputs are first decoupled to uncorrelated ones in a new output space. We then propose a comprehensive framework to capture the empirical loss between the predicted value and the ground truth in the transformed space and the temporal smoothness at neighboring prediction points. Experiments were performed on one synthetic data and two real-world datasets including radiotherapy and chemotherapy treatments. Results in terms of root mean square errors (RMSE) and R-value show that our proposed approach is promising for the longitudinal multiple-output regression problem.","Li, Cheng; Gupta, Sunil; Rana, Santu; Nguyen, Vu; Venkatesh, Svetha; Ashley, David; Livingston, Trish","Rana, Santu/R-2992-2019; Nguyen, Vu/AAQ-5062-2020; , ChengLi/S-2430-2019; Nguyen, Vu/HGV-1806-2022; Nguyễn, Vũ/HMD-5059-2023","Rana, Santu/0000-0003-2247-850X; Nguyen, Vu/0000-0002-0294-4561; , ChengLi/0000-0001-8140-2826; venkatesh, svetha/0000-0001-8675-6631; gupta, sunil/0000-0002-4669-9940",Multiple Adverse Effects Prediction in Longitudinal Cancer Treatment,,, ,Proceedings Paper ,2016.0,"Adverse effects, such as voice change and fatigue, are prevalent in cancer treatment duration. These adverse effects have been significant burden for patients physically and emotionally. Predicting multiple adverse effects becomes important for patients and oncologists. In this paper, we formulate the prediction of multiple adverse effects in cancer treatment as a longitudinal multiple-output regression problem. The correlated multiple outputs are first decoupled to uncorrelated ones in a new output space. We then propose a comprehensive framework to capture the empirical loss between the predicted value and the ground truth in the transformed space and the temporal smoothness at neighboring prediction points. Experiments were performed on one synthetic data and two real-world datasets including radiotherapy and chemotherapy treatments. Results in terms of root mean square errors (RMSE) and R-value show that our proposed approach is promising for the longitudinal multiple-output regression problem.",1051-4651,,978-1-5090-4847-2,3156-3161, , 23rd International Conference on Pattern Recognition (ICPR)23rd International Conference on Pattern Recognition (ICPR),,out_of_scope,
4030,"Title:Learning Personal Human Biases and Representations for Subjective Tasks in Natural Language Processing

 Many tasks in natural language processing like offensive, toxic, or emotional text classification are subjective by nature. Humans tend to perceive textual content in their own individual way. Existing methods commonly rely on the agreed output values, the same for all consumers. Here, we propose personalized solutions to subjective tasks. Our four new deep learning models take into account not only the content but also the specificity of a given human. The models represent different approaches to learning the representation and processing data about text readers. The experiments were carried out on four datasets: Wikipedia discussion texts labelled with attack, aggression, and toxicity, as well as opinions annotated with ten numerical emotional categories. Emotional data was considered as multivariate regression (multitask), whereas Wikipedia data as independent classifications. All our models based on human biases and their representations significantly improve the prediction quality in subjective tasks evaluated from the individual's perspective.","Kocon, Jan; Gruza, Marcin; Bielaniewicz, Julita; Grimling, Damian; Kanclerz, Kamil; Milkowski, Piotr; Kazienko, Przemyslaw","Kocon, Jan/IXN-3388-2023; Kazienko, Przemysław/F-1849-2014; Kocon, Jan/AAW-6404-2021; Kanclerz, Kamil/ABD-3695-2021","Kocon, Jan/0000-0002-7665-6896; Kazienko, Przemysław/0000-0001-5868-356X; Kocon, Jan/0000-0002-7665-6896; Kanclerz, Kamil/0000-0002-7375-7544",Learning Personal Human Biases and Representations for Subjective Tasks in Natural Language Processing,,,10.1109/ICDM51629.2021.00140 ,Proceedings Paper ,2021.0,"Many tasks in natural language processing like offensive, toxic, or emotional text classification are subjective by nature. Humans tend to perceive textual content in their own individual way. Existing methods commonly rely on the agreed output values, the same for all consumers. Here, we propose personalized solutions to subjective tasks. Our four new deep learning models take into account not only the content but also the specificity of a given human. The models represent different approaches to learning the representation and processing data about text readers. The experiments were carried out on four datasets: Wikipedia discussion texts labelled with attack, aggression, and toxicity, as well as opinions annotated with ten numerical emotional categories. Emotional data was considered as multivariate regression (multitask), whereas Wikipedia data as independent classifications. All our models based on human biases and their representations significantly improve the prediction quality in subjective tasks evaluated from the individual's perspective.",1550-4786,,978-1-6654-2398-4,1168-1173, , 21st IEEE International Conference on Data Mining (IEEE ICDM)21st IEEE International Conference on Data Mining (IEEE ICDM),,detection#evaluation#methodology,
4031,"Title:A Supervised Multi-class Multi-labelWord Embeddings Approach for Toxic Comment Classification

 Nowadays, communications made by using the modern Internet-based opportunities have revolutionized the way people exchange information, allowing real-time discussions among a huge number of users. However, the advantages offered by such powerful instruments of communication are sometimes jeopardized by the dangers related to personal attacks that lead many people to leave a discussion that they were participating. Such a problem is related to the so-called toxic comments, i.e., personal attacks, verbal bullying and, more generally, an aggressive way in which many people participate in a discussion, which brings some participants to abandon it. By exploiting the Apache Spark big data framework and several word embeddings, this paper presents an approach able to operate a multi-class multi-label classification of a discussion within a range of six classes of toxicity. We evaluate such an approach by classifying a dataset of comments taken from the Wikipedia's talk page, according to a Kaggle challenge. The experimental results prove that, through the adoption of different sets of word embeddings, our supervised approach outperforms the state-of-the-art that operate by exploiting the canonical bag-of-word model. In addition, the adoption of a word embeddings defined in a similar scenario (i.e., discussions related to e-learning videos), proves that it is possible to improve the performance with respect to solutions employing state-of-the-art word embeddings.","Carta, Salvatore; Corriga, Andrea; Mulas, Riccardo; Recupero, Diego; Saia, Roberto",,,A Supervised Multi-class Multi-labelWord Embeddings Approach for Toxic Comment Classification,,,10.5220/0008110901050112 ,Proceedings Paper ,2019.0,"Nowadays, communications made by using the modern Internet-based opportunities have revolutionized the way people exchange information, allowing real-time discussions among a huge number of users. However, the advantages offered by such powerful instruments of communication are sometimes jeopardized by the dangers related to personal attacks that lead many people to leave a discussion that they were participating. Such a problem is related to the so-called toxic comments, i.e., personal attacks, verbal bullying and, more generally, an aggressive way in which many people participate in a discussion, which brings some participants to abandon it. By exploiting the Apache Spark big data framework and several word embeddings, this paper presents an approach able to operate a multi-class multi-label classification of a discussion within a range of six classes of toxicity. We evaluate such an approach by classifying a dataset of comments taken from the Wikipedia's talk page, according to a Kaggle challenge. The experimental results prove that, through the adoption of different sets of word embeddings, our supervised approach outperforms the state-of-the-art that operate by exploiting the canonical bag-of-word model. In addition, the adoption of a word embeddings defined in a similar scenario (i.e., discussions related to e-learning videos), proves that it is possible to improve the performance with respect to solutions employing state-of-the-art word embeddings.",,,978-989-758-382-7,105-112, ," 11th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K) / 11th International Conference on Knowledge Discovery and Information Retrieval (KDIR)11th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K) / 11th International Conference on Knowledge Discovery and Information Retrieval (KDIR)",,Use_dataset#detection#methodology,
4032,"Title:NPA: an R package for computing network perturbation amplitudes using gene expression data and two-layer networks

 Background High-throughput gene expression technologies provide complex datasets reflecting mechanisms perturbed in an experiment, typically in a treatment versus control design. Analysis of these information-rich data can be guided based on a priori knowledge, such as networks of related proteins or genes. Assessing the response of a specific mechanism and investigating its biological basis is extremely important in systems toxicology; as compounds or treatment need to be assessed with respect to a predefined set of key mechanisms that could lead to toxicity. Two-layer networks are suitable for this task, and a robust computational methodology specifically addressing those needs was previously published. The NPA package () implements the algorithm, and a data package of eight two-layer networks representing key mechanisms, such as xenobiotic metabolism, apoptosis, or epithelial immune innate activation, is provided. Results Gene expression data from an animal study are analyzed using the package and its network models. The functionalities are implemented using R6 classes, making the use of the package seamless and intuitive. The various network responses are analyzed using the leading node analysis, and an overall perturbation, called the Biological Impact Factor, is computed. Conclusions The NPA package implements the published network perturbation amplitude methodology and provides a set of two-layer networks encoded in the Biological Expression Language.","Martin, Florian; Gubian, Sylvain; Talikka, Marja; Hoeng, Julia; Peitsch, Manuel C.",,,NPA: an R package for computing network perturbation amplitudes using gene expression data and two-layer networks,20,1,10.1186/s12859-019-3016-x ,Article ,2019.0,"Background High-throughput gene expression technologies provide complex datasets reflecting mechanisms perturbed in an experiment, typically in a treatment versus control design. Analysis of these information-rich data can be guided based on a priori knowledge, such as networks of related proteins or genes. Assessing the response of a specific mechanism and investigating its biological basis is extremely important in systems toxicology; as compounds or treatment need to be assessed with respect to a predefined set of key mechanisms that could lead to toxicity. Two-layer networks are suitable for this task, and a robust computational methodology specifically addressing those needs was previously published. The NPA package () implements the algorithm, and a data package of eight two-layer networks representing key mechanisms, such as xenobiotic metabolism, apoptosis, or epithelial immune innate activation, is provided. Results Gene expression data from an animal study are analyzed using the package and its network models. The functionalities are implemented using R6 classes, making the use of the package seamless and intuitive. The various network responses are analyzed using the leading node analysis, and an overall perturbation, called the Biological Impact Factor, is computed. Conclusions The NPA package implements the published network perturbation amplitude methodology and provides a set of two-layer networks encoded in the Biological Expression Language.",1471-2105,,,, , ,,out_of_scope,
4033,"Title:Zeta potentials (ζ) of metal oxide nanoparticles: A meta-analysis of experimental data and a predictive neural networks modeling

 Zeta potential is usually measured to estimate the surface charge and the stability of nanomaterials, as changes in these characteristics directly influence the biological activity of a given nanoparticle. Nowadays, theoretical methods are commonly used for a pre-screening safety assessments of nanomaterials. At the same time, the consistency of data on zeta potential measurements in the context of environmental impact is an important challenge. The inconsistency of data measurements leads to inaccuracies in predictive modeling. In this article, we report a new curated dataset of zeta potentials measured for 208 silica- and metal oxide nanoparticles in different media. We discuss the data curation framework for zeta potentials designed to assess the quality and usefulness of the literature data for further computational modeling. We also provide an analysis of specific trends for the datapoints harvested from different literature sources. In addition to that, we present for the first time a structure-property relationship model for nanoparticles (nano-SPR) that predicts values of zeta potential values measured in different environmental conditions (i.e., biological media and pH).","Sizochenko, Natalia; Mikolajczyk, Alicja; Syzochenko, Michael; Puzyn, Tomasz; Leszczynski, Jerzy",,,Zeta potentials (ζ) of metal oxide nanoparticles: A meta-analysis of experimental data and a predictive neural networks modeling,22,,10.1016/j.impact.2021.100317 ,Article ,2021.0,"Zeta potential is usually measured to estimate the surface charge and the stability of nanomaterials, as changes in these characteristics directly influence the biological activity of a given nanoparticle. Nowadays, theoretical methods are commonly used for a pre-screening safety assessments of nanomaterials. At the same time, the consistency of data on zeta potential measurements in the context of environmental impact is an important challenge. The inconsistency of data measurements leads to inaccuracies in predictive modeling. In this article, we report a new curated dataset of zeta potentials measured for 208 silica- and metal oxide nanoparticles in different media. We discuss the data curation framework for zeta potentials designed to assess the quality and usefulness of the literature data for further computational modeling. We also provide an analysis of specific trends for the datapoints harvested from different literature sources. In addition to that, we present for the first time a structure-property relationship model for nanoparticles (nano-SPR) that predicts values of zeta potential values measured in different environmental conditions (i.e., biological media and pH).",2452-0748,,,, , ,,out_of_scope,
4034,"Title:Analysis methodology and development of a statistical tool for biodistribution data from internal contamination with actinides

 The aim of this work was to develop a computational tool that integrates several statistical analysis features for biodistribution data from internal contamination experiments. These data represent actinide levels in biological compartments as a function of time and are derived from activity measurements in tissues and excreta. These experiments aim at assessing the influence of different contamination conditions (e.g. intake route or radioelement) on the biological behavior of the contaminant. The ever increasing number of datasets and diversity of experimental conditions make the handling and analysis of biodistribution data difficult. This work sought to facilitate the statistical analysis of a large number of datasets and the comparison of results from diverse experimental conditions. Functional modules were developed using the open-source programming language R to facilitate specific operations: descriptive statistics, visual comparison, curve fitting, and implementation of biokinetic models. In addition, the structure of the datasets was harmonized using the same table format. Analysis outputs can be written in text files and updated data can be written in the consistent table format. Hence, a data repository is built progressively, which is essential for the optimal use of animal data. Graphical representations can be automatically generated and saved as image files. The resulting computational tool was applied using data derived from wound contamination experiments conducted under different conditions.In facilitating biodistribution data handling and statistical analyses, this computational tool ensures faster analyses and a better reproducibility compared with the use of multiple office software applications. Furthermore, re-analysis of archival data and comparison of data from different sources is made much easier. Hence this tool will help to understand better the influence of contamination characteristics on actinide biokinetics. Our approach can aid the optimization of treatment protocols and therefore contribute to the improvement of the medical response after internal contamination with actinides.","Lamart, Stephanie; Griffiths, Nina M.; Tchitchek, Nicolas; Angulo, Jaime F.; Van der Meeren, Anne","van der meeren, anne/Y-6246-2019; ANGULO, Jaime F./B-3024-2009","Lamart, Stephanie/0000-0003-3924-3512; ANGULO MORA, Jaime Francisco/0000-0003-1447-2263; Tchitchek, Nicolas/0000-0003-3307-0446",Analysis methodology and development of a statistical tool for biodistribution data from internal contamination with actinides,37,1,10.1088/1361-6498/37/1/296 ,Article ,2017.0,"The aim of this work was to develop a computational tool that integrates several statistical analysis features for biodistribution data from internal contamination experiments. These data represent actinide levels in biological compartments as a function of time and are derived from activity measurements in tissues and excreta. These experiments aim at assessing the influence of different contamination conditions (e.g. intake route or radioelement) on the biological behavior of the contaminant. The ever increasing number of datasets and diversity of experimental conditions make the handling and analysis of biodistribution data difficult. This work sought to facilitate the statistical analysis of a large number of datasets and the comparison of results from diverse experimental conditions. Functional modules were developed using the open-source programming language R to facilitate specific operations: descriptive statistics, visual comparison, curve fitting, and implementation of biokinetic models. In addition, the structure of the datasets was harmonized using the same table format. Analysis outputs can be written in text files and updated data can be written in the consistent table format. Hence, a data repository is built progressively, which is essential for the optimal use of animal data. Graphical representations can be automatically generated and saved as image files. The resulting computational tool was applied using data derived from wound contamination experiments conducted under different conditions.In facilitating biodistribution data handling and statistical analyses, this computational tool ensures faster analyses and a better reproducibility compared with the use of multiple office software applications. Furthermore, re-analysis of archival data and comparison of data from different sources is made much easier. Hence this tool will help to understand better the influence of contamination characteristics on actinide biokinetics. Our approach can aid the optimization of treatment protocols and therefore contribute to the improvement of the medical response after internal contamination with actinides.",0952-4746,1361-6498,,296-308, , ,,out_of_scope,
4035,"Title:A new method for building single feedforward neural network models for multivariate static regression problems: a combined weight initialization and constructive algorithm

 The performance of models based on a Feedforward Neural Network depends strongly on the initial estimate of weights and the number of units in the hidden layers. This work presents a new method for the initialization of weights and definition of the number of hidden units in the identification of Multiple Input Single Output models associated with regression problems. The initialization strategy consists of a complete linearization of the network with only one neuron unit around an equilibrium point and the determination of the initial weights through the maximum approximation of the linearized model to the Optimal Linear Regressor whose solution can be obtained analytically. The constructive algorithm performs a gradual increase in the number of hidden units in such a way that at each training only weights associated with new hidden units are randomly initialized, while weights obtained from previous training are used as initial guess for the subsequent ones. The proposed method was compared to the classical random initialization method and to the Extreme Learning Machine (a typical gradient-free learning algorithm), both of which also involve a constructive approach to define the final network. The methods were applied to 11 real datasets widely used as benchmarks for regression problems. The proposed method performed better than the other approaches in 8-9 case studies and was able to ensure a monotonic decrease in the loss function with an increasing number of hidden units.","de Sa, Ghabriel A. Gomes; Fontes, Cristiano Hora; Embirucu, Marcelo",,"Anton Gomes de Sa, Ghabriel/0009-0007-4330-4265",A new method for building single feedforward neural network models for multivariate static regression problems: a combined weight initialization and constructive algorithm,,,10.1007/s12065-022-00813-z ,Article; Early Access ,,"The performance of models based on a Feedforward Neural Network depends strongly on the initial estimate of weights and the number of units in the hidden layers. This work presents a new method for the initialization of weights and definition of the number of hidden units in the identification of Multiple Input Single Output models associated with regression problems. The initialization strategy consists of a complete linearization of the network with only one neuron unit around an equilibrium point and the determination of the initial weights through the maximum approximation of the linearized model to the Optimal Linear Regressor whose solution can be obtained analytically. The constructive algorithm performs a gradual increase in the number of hidden units in such a way that at each training only weights associated with new hidden units are randomly initialized, while weights obtained from previous training are used as initial guess for the subsequent ones. The proposed method was compared to the classical random initialization method and to the Extreme Learning Machine (a typical gradient-free learning algorithm), both of which also involve a constructive approach to define the final network. The methods were applied to 11 real datasets widely used as benchmarks for regression problems. The proposed method performed better than the other approaches in 8-9 case studies and was able to ensure a monotonic decrease in the loss function with an increasing number of hidden units.",1864-5909,1864-5917,,, , ,,out_of_scope,
4036,"Title:Cyberknife Radiosurgery for Prostate Cancer after Abdominoperineal Resection (CYRANO): The Combined Computer Tomography and Electromagnetic Navigation Guided Transperineal Fiducial Markers Implantation Technique

 In this technical development report, we present the strategic placement of fiducial markers within the prostate under the guidance of computed tomography (CT) and electromagnetic navigation (EMN) for the delivery of ultra-hypofractionated cyberknife (CK) therapy in a patient with localized prostate cancer (PCa) who had previously undergone chemo-radiotherapy for rectal cancer and subsequent abdominoperineal resection due to local recurrence. The patient was positioned in a prone position with a pillow under the pelvis to facilitate access, and an electromagnetic fiducial marker was placed on the patient's skin to establish a stable position. CT scans were performed to plan the procedure, mark virtual points, and simulate the needle trajectory using the navigation system. Local anesthesia was administered, and a 21G needle was used to place the fiducial markers according to the navigation system information. A confirmatory CT scan was obtained to ensure proper positioning. The implantation procedure was safe, without any acute side effects such as pain, hematuria, dysuria, or hematospermia. Our report highlights the ability to use EMN systems to virtually navigate within a pre-acquired imaging dataset in the interventional room, allowing for non-conventional approaches and potentially revolutionizing fiducial marker positioning, offering new perspectives for PCa treatment in selected cases.","Vavassori, Andrea; Mauri, Giovanni; Mazzola, Giovanni Carlo; Mastroleo, Federico; Bonomo, Guido; Durante, Stefano; Zerini, Dario; Marvaso, Giulia; Corrao, Giulia; Ferrari, Elettra Dorotea; Rondi, Elena; Vigorito, Sabrina; Cattani, Federica; Orsi, Franco; Jereczek-Fossa, Barbara Alicja",,"Mastroleo, Federico/0000-0001-6580-6767; Marvaso, Giulia/0000-0002-5339-8038; Mazzola, Giovanni Carlo/0000-0002-0865-0134; Corrao, Giulia/0000-0002-5757-6073; Orsi, Franco/0000-0002-7330-0499",Cyberknife Radiosurgery for Prostate Cancer after Abdominoperineal Resection (CYRANO): The Combined Computer Tomography and Electromagnetic Navigation Guided Transperineal Fiducial Markers Implantation Technique,30,9,10.3390/curroncol30090576 ,Article ,2023.0,"In this technical development report, we present the strategic placement of fiducial markers within the prostate under the guidance of computed tomography (CT) and electromagnetic navigation (EMN) for the delivery of ultra-hypofractionated cyberknife (CK) therapy in a patient with localized prostate cancer (PCa) who had previously undergone chemo-radiotherapy for rectal cancer and subsequent abdominoperineal resection due to local recurrence. The patient was positioned in a prone position with a pillow under the pelvis to facilitate access, and an electromagnetic fiducial marker was placed on the patient's skin to establish a stable position. CT scans were performed to plan the procedure, mark virtual points, and simulate the needle trajectory using the navigation system. Local anesthesia was administered, and a 21G needle was used to place the fiducial markers according to the navigation system information. A confirmatory CT scan was obtained to ensure proper positioning. The implantation procedure was safe, without any acute side effects such as pain, hematuria, dysuria, or hematospermia. Our report highlights the ability to use EMN systems to virtually navigate within a pre-acquired imaging dataset in the interventional room, allowing for non-conventional approaches and potentially revolutionizing fiducial marker positioning, offering new perspectives for PCa treatment in selected cases.",1198-0052,1718-7729,,7926-7935, , ,,out_of_scope,
4037,"Title:New insights into the evolutionary features of viral overlapping genes by discriminant analysis

 Overlapping genes originate by a mechanism of overprinting, in which nucleotide substitutions in a pre-existing frame induce the expression of a de novo protein from an alternative frame. In this study, I assembled a dataset of 319 viral overlapping genes, which included 82 overlaps whose expression is experimentally known and the respective 237 homologs. Principal component analysis revealed that overlapping genes have a common pattern of nucleotide and amino acid composition. Discriminant analysis separated overlapping from non-overlapping genes with an accuracy of 97%. When applied to overlapping genes with known genealogy, it separated ancestral from de novo frames with an accuracy close to 100%. This high discriminant power was crucial to computationally design variants of de novo viral proteins known to possess selective anticancer toxicity (apoptin) or protection against neurodegeneration (X protein), as well as to detect two new potential overlapping genes in the genome of the new coronavirus SARS-CoV-2.","Pavesi, Angelo",,,New insights into the evolutionary features of viral overlapping genes by discriminant analysis,546,,10.1016/j.virol.2020.03.007 ,Article ,2020.0,"Overlapping genes originate by a mechanism of overprinting, in which nucleotide substitutions in a pre-existing frame induce the expression of a de novo protein from an alternative frame. In this study, I assembled a dataset of 319 viral overlapping genes, which included 82 overlaps whose expression is experimentally known and the respective 237 homologs. Principal component analysis revealed that overlapping genes have a common pattern of nucleotide and amino acid composition. Discriminant analysis separated overlapping from non-overlapping genes with an accuracy of 97%. When applied to overlapping genes with known genealogy, it separated ancestral from de novo frames with an accuracy close to 100%. This high discriminant power was crucial to computationally design variants of de novo viral proteins known to possess selective anticancer toxicity (apoptin) or protection against neurodegeneration (X protein), as well as to detect two new potential overlapping genes in the genome of the new coronavirus SARS-CoV-2.",0042-6822,1089-862X,,51-66, , ,,out_of_scope,
4038,"Title:Acrylamide concentrations in potato crisps in Europe from 2002 to 2011

 A dataset of manufacturers' measurements of acrylamide levels in 40,455 samples of fresh sliced potato crisps from 20 European countries for years 2002 to 2011 was compiled. This dataset is by far the largest ever compiled relating to acrylamide levels in potato crisps. Analysis of variance was applied to the data and showed a clear, significant downward trend for mean levels of acrylamide, from 763 +/- 91.1 ng g(-1) (parts per billion) in 2002 to 358 +/- 2.5 ng g(-1) in 2011; this was a decrease of 53% +/- 13.5%. The yearly 95th quantile values were also subject to a clear downward trend. The effect of seasonality arising from the influence of potato storage on acrylamide levels was evident, with acrylamide in the first 6 months of the year being significantly higher than in the second 6 months. The proportion of samples containing acrylamide at a level above the indicative value of 1000ngg(-1) for potato crisps introduced by the European Commission in 2011 fell from 23.8% in 2002 to 3.2% in 2011. Nevertheless, even in 2011, a small proportion of samples still contained high levels of acrylamide, with 0.2% exceeding 2000ngg(-1).","Powers, Stephen J.; Mottram, Donald S.; Curtis, Andrew; Halford, Nigel G.","Halford, Nigel G./B-3872-2009","Halford, Nigel G./0000-0001-6488-2530",Acrylamide concentrations in potato crisps in Europe from 2002 to 2011,30,9,10.1080/19440049.2013.805439 ,Article ,2013.0,"A dataset of manufacturers' measurements of acrylamide levels in 40,455 samples of fresh sliced potato crisps from 20 European countries for years 2002 to 2011 was compiled. This dataset is by far the largest ever compiled relating to acrylamide levels in potato crisps. Analysis of variance was applied to the data and showed a clear, significant downward trend for mean levels of acrylamide, from 763 +/- 91.1 ng g(-1) (parts per billion) in 2002 to 358 +/- 2.5 ng g(-1) in 2011; this was a decrease of 53% +/- 13.5%. The yearly 95th quantile values were also subject to a clear downward trend. The effect of seasonality arising from the influence of potato storage on acrylamide levels was evident, with acrylamide in the first 6 months of the year being significantly higher than in the second 6 months. The proportion of samples containing acrylamide at a level above the indicative value of 1000ngg(-1) for potato crisps introduced by the European Commission in 2011 fell from 23.8% in 2002 to 3.2% in 2011. Nevertheless, even in 2011, a small proportion of samples still contained high levels of acrylamide, with 0.2% exceeding 2000ngg(-1).",1944-0049,,,1493-1500, , ,,out_of_scope,
4039,"Title:CottonLeafNet: cotton plant leaf disease detection using deep neural networks

 India is a cover crop region whereby agricultural production sustains a substantial proportion of the populace and upon which the whole Indian economy is heavily reliant. As per research, it provides subsistence for around 70% of rural households. In terms of agricultural output and exports, India ranks second and ninth, respectively. However, it accomplishes the first position globally in terms of cotton exports thereby adequately contributing to the economy of the country. However, it has been documented that various crops especially cotton plants are severely harmed by various pests, extreme climatic variations, nutrient inadequacy and toxicity, and so on. Cotton plant diseases cause a wide range of illnesses ranging from bacterial to nutritional deficiency giving a hard time for the human eye to recognize. However, most of the researchers have considered only a few types of cotton leaf diseases and excluded many. Keeping these constraints in consideration, this research seeks to aid the detection of these diseases by employing deep learning paradigms. The research begins with acquiring a near-balanced dataset with 22 leaf disease types including bacterial, fungal, viral, nutrient deficiency, etc. followed by data augmentation to boost the performance of the models. Many algorithms were tested, however, CNN happens to be very efficient and productive. The proposed model when evaluated on the test set achieves an accuracy of 99.39% with a negligible error rate, thus outperforming all the existing approaches by consuming less computational time. The outcome portrays that the proposed approach has the efficiency to be implemented in real-time detection systems to aid the precise detection of cotton leaf diseases to help the farmers in taking appropriate actions.","Singh, Paramjeet; Singh, Parvinder; Farooq, Umar; Khurana, Surinder Singh; Verma, Jitendra Kumar; Kumar, Munish","Singh, Parvinder/AAM-5012-2021; Verma, Jitendra Kumar/AAQ-5538-2021","Singh, Parvinder/0000-0001-7258-7769; Farooq, Umar/0000-0002-3786-2574",CottonLeafNet: cotton plant leaf disease detection using deep neural networks,,,10.1007/s11042-023-14954-5 ,Article; Early Access ,,"India is a cover crop region whereby agricultural production sustains a substantial proportion of the populace and upon which the whole Indian economy is heavily reliant. As per research, it provides subsistence for around 70% of rural households. In terms of agricultural output and exports, India ranks second and ninth, respectively. However, it accomplishes the first position globally in terms of cotton exports thereby adequately contributing to the economy of the country. However, it has been documented that various crops especially cotton plants are severely harmed by various pests, extreme climatic variations, nutrient inadequacy and toxicity, and so on. Cotton plant diseases cause a wide range of illnesses ranging from bacterial to nutritional deficiency giving a hard time for the human eye to recognize. However, most of the researchers have considered only a few types of cotton leaf diseases and excluded many. Keeping these constraints in consideration, this research seeks to aid the detection of these diseases by employing deep learning paradigms. The research begins with acquiring a near-balanced dataset with 22 leaf disease types including bacterial, fungal, viral, nutrient deficiency, etc. followed by data augmentation to boost the performance of the models. Many algorithms were tested, however, CNN happens to be very efficient and productive. The proposed model when evaluated on the test set achieves an accuracy of 99.39% with a negligible error rate, thus outperforming all the existing approaches by consuming less computational time. The outcome portrays that the proposed approach has the efficiency to be implemented in real-time detection systems to aid the precise detection of cotton leaf diseases to help the farmers in taking appropriate actions.",1380-7501,1573-7721,,, , ,,out_of_scope,
4040,"Title:Metadata Stewardship in Nanosafety Research: Community-Driven Organisation of Metadata Schemas to Support FAIR Nanoscience Data

 The emergence of nanoinformatics as a key component of nanotechnology and nanosafety assessment for the prediction of engineered nanomaterials (NMs) properties, interactions, and hazards, and for grouping and read-across to reduce reliance on animal testing, has put the spotlight firmly on the need for access to high-quality, curated datasets. To date, the focus has been around what constitutes data quality and completeness, on the development of minimum reporting standards, and on the FAIR (findable, accessible, interoperable, and reusable) data principles. However, moving from the theoretical realm to practical implementation requires human intervention, which will be facilitated by the definition of clear roles and responsibilities across the complete data lifecycle and a deeper appreciation of what metadata is, and how to capture and index it. Here, we demonstrate, using specific worked case studies, how to organise the nano-community efforts to define metadata schemas, by organising the data management cycle as a joint effort of all players (data creators, analysts, curators, managers, and customers) supervised by the newly defined role of data shepherd. We propose that once researchers understand their tasks and responsibilities, they will naturally apply the available tools. Two case studies are presented (modelling of particle agglomeration for dose metrics, and consensus for NM dissolution), along with a survey of the currently implemented metadata schema in existing nanosafety databases. We conclude by offering recommendations on the steps forward and the needed workflows for metadata capture to ensure FAIR nanosafety data.","Papadiamantis, Anastasios G.; Klaessig, Frederick C.; Exner, Thomas E.; Hofer, Sabine; Hofstaetter, Norbert; Himly, Martin; Williams, Marc A.; Doganis, Philip; Hoover, Mark D.; Afantitis, Antreas; Melagraki, Georgia; Nolan, Tracy S.; Rumble, John; Maier, Dieter; Lynch, Iseult","nolan, tracy/IAO-2763-2023; Afantitis, Antreas/A-9637-2010; Lynch, Iseult/I-3915-2014; Hoover, Mark D./I-4201-2012; Himly, Martin/D-1568-2015","Afantitis, Antreas/0000-0002-0977-8180; Lynch, Iseult/0000-0003-4250-4584; Hoover, Mark D./0000-0002-8726-8127; Hofer, Sabine/0000-0003-4986-3539; Klaessig, Frederick/0000-0002-6062-8700; Himly, Martin/0000-0001-5416-085X; Hofstatter, Norbert/0000-0003-0207-0654; Papadiamantis, Anastasios/0000-0002-1297-3104; Nolan, Tracy/0000-0002-7023-7586",Metadata Stewardship in Nanosafety Research: Community-Driven Organisation of Metadata Schemas to Support FAIR Nanoscience Data,10,10,10.3390/nano10102033 ,Article ,2020.0,"The emergence of nanoinformatics as a key component of nanotechnology and nanosafety assessment for the prediction of engineered nanomaterials (NMs) properties, interactions, and hazards, and for grouping and read-across to reduce reliance on animal testing, has put the spotlight firmly on the need for access to high-quality, curated datasets. To date, the focus has been around what constitutes data quality and completeness, on the development of minimum reporting standards, and on the FAIR (findable, accessible, interoperable, and reusable) data principles. However, moving from the theoretical realm to practical implementation requires human intervention, which will be facilitated by the definition of clear roles and responsibilities across the complete data lifecycle and a deeper appreciation of what metadata is, and how to capture and index it. Here, we demonstrate, using specific worked case studies, how to organise the nano-community efforts to define metadata schemas, by organising the data management cycle as a joint effort of all players (data creators, analysts, curators, managers, and customers) supervised by the newly defined role of data shepherd. We propose that once researchers understand their tasks and responsibilities, they will naturally apply the available tools. Two case studies are presented (modelling of particle agglomeration for dose metrics, and consensus for NM dissolution), along with a survey of the currently implemented metadata schema in existing nanosafety databases. We conclude by offering recommendations on the steps forward and the needed workflows for metadata capture to ensure FAIR nanosafety data.",,2079-4991,,, , ,,out_of_scope,
4041,"Title:Supervised machine learning-based classification scheme to segment the brainstem on MRI in multicenter brain tumor treatment context

 To constrain the risk of severe toxicity in radiotherapy and radiosurgery, precise volume delineation of organs at risk is required. This task is still manually performed, which is time-consuming and prone to observer variability. To address these issues, and as alternative to atlas-based segmentation methods, machine learning techniques, such as support vector machines (SVM), have been recently presented to segment subcortical structures on magnetic resonance images (MRI).SVM is proposed to segment the brainstem on MRI in multicenter brain cancer context. A dataset composed by 14 adult brain MRI scans is used to evaluate its performance. In addition to spatial and probabilistic information, five different image intensity values (IIVs) configurations are evaluated as features to train the SVM classifier. Segmentation accuracy is evaluated by computing the Dice similarity coefficient (DSC), absolute volumes difference (AVD) and percentage volume difference between automatic and manual contours.Mean DSC for all proposed IIVs configurations ranged from 0.89 to 0.90. Mean AVD values were below , where the value for best performing IIVs configuration was , representing an absolute mean difference of with respect to the manual segmented volumes.Results suggest consistent volume estimation and high spatial similarity with respect to expert delineations. The proposed approach outperformed presented methods to segment the brainstem, not only in volume similarity metrics, but also in segmentation time. Preliminary results showed that the approach might be promising for adoption in clinical use.","Dolz, Jose; Laprie, Anne; Ken, Soleakhena; Leroy, Henri-Arthur; Reyns, Nicolas; Massoptier, Laurent; Vermandel, Maximilien","Dolz, Jose/Y-5756-2019; Ken, Soleakhena/AAC-1260-2021; Laprie, Anne/O-4948-2014","Dolz, Jose/0000-0002-2436-7750; Ken, Soleakhena/0000-0001-7904-5882; Laprie, Anne/0000-0002-0103-7935",Supervised machine learning-based classification scheme to segment the brainstem on MRI in multicenter brain tumor treatment context,11,1,10.1007/s11548-015-1266-2 ,Article ,2016.0,"To constrain the risk of severe toxicity in radiotherapy and radiosurgery, precise volume delineation of organs at risk is required. This task is still manually performed, which is time-consuming and prone to observer variability. To address these issues, and as alternative to atlas-based segmentation methods, machine learning techniques, such as support vector machines (SVM), have been recently presented to segment subcortical structures on magnetic resonance images (MRI).SVM is proposed to segment the brainstem on MRI in multicenter brain cancer context. A dataset composed by 14 adult brain MRI scans is used to evaluate its performance. In addition to spatial and probabilistic information, five different image intensity values (IIVs) configurations are evaluated as features to train the SVM classifier. Segmentation accuracy is evaluated by computing the Dice similarity coefficient (DSC), absolute volumes difference (AVD) and percentage volume difference between automatic and manual contours.Mean DSC for all proposed IIVs configurations ranged from 0.89 to 0.90. Mean AVD values were below , where the value for best performing IIVs configuration was , representing an absolute mean difference of with respect to the manual segmented volumes.Results suggest consistent volume estimation and high spatial similarity with respect to expert delineations. The proposed approach outperformed presented methods to segment the brainstem, not only in volume similarity metrics, but also in segmentation time. Preliminary results showed that the approach might be promising for adoption in clinical use.",1861-6410,1861-6429,,43-51, , ,,out_of_scope,
4042,"Title:Atmospheric Concentrations and Health Implications of PAHs, PCBs and PCDD/Fs in the Vicinity of a Heavily Industrialized Site in Greece

 Background: Thriassion Plain is considered the most industrialized area in Greece and thus a place where emissions of pollutants are expected to be elevated, leading to the degradation of air quality. Methods: Simultaneous determination of polycyclic aromatic hydrocarbons (PAHs), polychlorinated dibenzo-p-dioxins/dibenzofurans (PCDD/Fs), and polychlorinated biphenyls (PCBs) was performed in PM10 samples. SPSS statistical package was employed for statistical analysis and source apportionment purposes. Cancer risk was estimated from total persistent organic pollutants' (POPs) dataset according to the available literature. Results: POPs concentrations in particulate matter were measured in similar levels compared to other studies in Greece and worldwide, with mean concentrations of sigma PAHs, sigma PCDD/Fs, dioxin like PCBs, and indicator PCBs being 7.07 ng m(-3), 479 fg m(-3), 1634 fg m(-3), and 18.1 pg m(-3), respectively. Seasonal variations were observed only for PAHS with higher concentrations during cold period. MDRs, D/F ratios, and principal component analysis (PCA) highlighted combustions as the main source of POPs' emissions. Estimation of particles' carcinogenic and mutagenic potential indicates the increased toxicity of PM10 during cold periods, and cancer risk assessment concludes that 3 to 4 people out of 100,000 may suffer from cancer due to POPs' inhalation. Conclusions: Increased cancer risk for citizens leads to the necessity of chronic POPs' monitoring in Thriassion Plain, and such strategies have to be a priority for Greek environmental authorities.","Koukoulakis, Konstantinos G.; Kanellopoulos, Panagiotis George; Chrysochou, Eirini; Costopoulou, Danae; Vassiliadou, Irene; Leondiadis, Leondios; Bakeas, Evangelos",,"Bakeas, Vagelis/0000-0003-2585-0645; Chrysochou, Eirini/0009-0007-2655-4449; Koukoulakis, Konstantinos/0000-0002-4294-3221","Atmospheric Concentrations and Health Implications of PAHs, PCBs and PCDD/Fs in the Vicinity of a Heavily Industrialized Site in Greece",10,24,10.3390/app10249023 ,Article ,2020.0,"Background: Thriassion Plain is considered the most industrialized area in Greece and thus a place where emissions of pollutants are expected to be elevated, leading to the degradation of air quality. Methods: Simultaneous determination of polycyclic aromatic hydrocarbons (PAHs), polychlorinated dibenzo-p-dioxins/dibenzofurans (PCDD/Fs), and polychlorinated biphenyls (PCBs) was performed in PM10 samples. SPSS statistical package was employed for statistical analysis and source apportionment purposes. Cancer risk was estimated from total persistent organic pollutants' (POPs) dataset according to the available literature. Results: POPs concentrations in particulate matter were measured in similar levels compared to other studies in Greece and worldwide, with mean concentrations of sigma PAHs, sigma PCDD/Fs, dioxin like PCBs, and indicator PCBs being 7.07 ng m(-3), 479 fg m(-3), 1634 fg m(-3), and 18.1 pg m(-3), respectively. Seasonal variations were observed only for PAHS with higher concentrations during cold period. MDRs, D/F ratios, and principal component analysis (PCA) highlighted combustions as the main source of POPs' emissions. Estimation of particles' carcinogenic and mutagenic potential indicates the increased toxicity of PM10 during cold periods, and cancer risk assessment concludes that 3 to 4 people out of 100,000 may suffer from cancer due to POPs' inhalation. Conclusions: Increased cancer risk for citizens leads to the necessity of chronic POPs' monitoring in Thriassion Plain, and such strategies have to be a priority for Greek environmental authorities.",,2076-3417,,, , ,,out_of_scope,
4043,"Title:Transforming approach for assessing the performance and applicability of rice arsenic contamination forecasting models based on regression and probability methods

 Probability models are preferred over regression models recently in contamination evaluation but lacking proper performance comparison between two model types. Linear regression, logistic regression, XGBoost-based regression, and probability models were built considering soil arsenic and certain soil physicochemical properties of 287 samples to predict arsenic in rice grains. The outputs of all models were binarily classified uniformly for comparison. The complex algorithm-based models-XGBoost-based regression (R-2 =0.046 +/- 0.036) and probability models (cross-entropy = 0.697 +/- 0.020)-did not surpass the simple linear regression (R-2 =0.046 +/- 0.031) and logistic regression models (cross-entropy = 0.694 +/- 0.021). Accuracy, sensitivity, specificity, precision, and Fl score showed that the probability models exhibit no advantage on regression models, although the indicators above did not serve as proper scoring rules for the probability model. When discretizing the contaminant concentration in grains for probabilistic modeling, the limit concentration was considered as the splitting point but not the structure of the datasets, which would reduce the inherent advantage of the probability model. When predicting the contamination of crops, the probability model cannot eliminate the regression model, and simple but robust algorithm-based models are preferred when the quality and quantity of the dataset are undesirable.","Zhao, Chen; Yang, Jun; Shi, Huading; Chen, Tongbin","赵, 琛/JQI-5972-2023",,Transforming approach for assessing the performance and applicability of rice arsenic contamination forecasting models based on regression and probability methods,424,,10.1016/j.jhazmat.2021.127375 ,Article ,2022.0,"Probability models are preferred over regression models recently in contamination evaluation but lacking proper performance comparison between two model types. Linear regression, logistic regression, XGBoost-based regression, and probability models were built considering soil arsenic and certain soil physicochemical properties of 287 samples to predict arsenic in rice grains. The outputs of all models were binarily classified uniformly for comparison. The complex algorithm-based models-XGBoost-based regression (R-2 =0.046 +/- 0.036) and probability models (cross-entropy = 0.697 +/- 0.020)-did not surpass the simple linear regression (R-2 =0.046 +/- 0.031) and logistic regression models (cross-entropy = 0.694 +/- 0.021). Accuracy, sensitivity, specificity, precision, and Fl score showed that the probability models exhibit no advantage on regression models, although the indicators above did not serve as proper scoring rules for the probability model. When discretizing the contaminant concentration in grains for probabilistic modeling, the limit concentration was considered as the splitting point but not the structure of the datasets, which would reduce the inherent advantage of the probability model. When predicting the contamination of crops, the probability model cannot eliminate the regression model, and simple but robust algorithm-based models are preferred when the quality and quantity of the dataset are undesirable.",0304-3894,1873-3336,,, , ,,out_of_scope,
4044,"Title:Methods, models, mechanisms and metadata: Introducing the Nanotoxicology collection at F1000Research.

 Nanotoxicology is a relatively new field of research concerning the study and application of nanomaterials to evaluate the potential for harmful effects in parallel with the development of applications. Nanotoxicology as a field spans materials synthesis and characterisation, assessment of fate and behaviour, exposure science, toxicology / ecotoxicology, molecular biology and toxicogenomics, epidemiology, safe and sustainable by design approaches, and chemoinformatics and nanoinformatics, thus requiring scientists to work collaboratively, often outside their core expertise area. This interdisciplinarity can lead to challenges in terms of interpretation and reporting, and calls for a platform for sharing of best-practice in nanotoxicology research. The F1000Research Nanotoxicology collection, introduced via this editorial, will provide a place to share accumulated best practice, via original research reports including no-effects studies, protocols and methods papers, software reports and living systematic reviews, which can be updated as new knowledge emerges or as the domain of applicability of the method, model or software is expanded. This editorial introduces the Nanotoxicology Collection in F1000Research. The aim of the collection is to provide an open access platform for nanotoxicology researchers, to support an improved culture of data sharing and documentation of evolving protocols, biological and computational models, software tools and datasets, that can be applied and built upon to develop predictive models and move towards in silico nanotoxicology and nanoinformatics. Submissions will be assessed for fit to the collection and subjected to the F1000Research open peer review process.","Lynch, Iseult; Nymark, Penny; Doganis, Philip; Gulumian, Mary; Yoon, Tae-Hyun; Martinez, Diego S T; Afantitis, Antreas","Lynch, Iseult/I-3915-2014","Lynch, Iseult/0000-0003-4250-4584; Nymark, Penny/0000-0002-3435-7775","Methods, models, mechanisms and metadata: Introducing the Nanotoxicology collection at F1000Research.",10,,10.12688/f1000research.75113.1 ,"Editorial; Research Support, Non-U.S. Gov't ",2021.0,"Nanotoxicology is a relatively new field of research concerning the study and application of nanomaterials to evaluate the potential for harmful effects in parallel with the development of applications. Nanotoxicology as a field spans materials synthesis and characterisation, assessment of fate and behaviour, exposure science, toxicology / ecotoxicology, molecular biology and toxicogenomics, epidemiology, safe and sustainable by design approaches, and chemoinformatics and nanoinformatics, thus requiring scientists to work collaboratively, often outside their core expertise area. This interdisciplinarity can lead to challenges in terms of interpretation and reporting, and calls for a platform for sharing of best-practice in nanotoxicology research. The F1000Research Nanotoxicology collection, introduced via this editorial, will provide a place to share accumulated best practice, via original research reports including no-effects studies, protocols and methods papers, software reports and living systematic reviews, which can be updated as new knowledge emerges or as the domain of applicability of the method, model or software is expanded. This editorial introduces the Nanotoxicology Collection in F1000Research. The aim of the collection is to provide an open access platform for nanotoxicology researchers, to support an improved culture of data sharing and documentation of evolving protocols, biological and computational models, software tools and datasets, that can be applied and built upon to develop predictive models and move towards in silico nanotoxicology and nanoinformatics. Submissions will be assessed for fit to the collection and subjected to the F1000Research open peer review process.",,2046-1402,,1196-1196, , ,,out_of_scope,
4045,"Title:Towards the Importance of the Type of Deep Neural Network and Employment of Pre-trained Word Vectors for Toxicity Detection: An Experimental Study

 As a natural consequence of offering many advantages to their users, social media platforms have become a part of their daily lives. Recent studies emphasize the necessity of an automated way of detecting offensive posts in social media since these 'toxic' posts have become pervasive. To this end, a novel toxic post detection approach based on Deep Neural Networks was proposed within this study. Given that several word embedding methods exist, we shed light on which word embedding method produces better results when employed with the five most common types of deep neural networks, namely, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), GRU (Gated Recurrent Unit), Bidirectional Long ShortTerm Memory (BiLSTM), and a combination of CNN and BiLSTM. To this end, the word vectors for the given comments were obtained through four different methods, namely, (i) Word2vec, (ii) fastT ext, (iii) GloVe, and (iv) the Embedding layer of deep neural networks. Eventually, a total of twenty benchmark models were proposed and both trained and evaluated on a gold standard dataset which consists of 16K tweets. According to the experimental result, the best F1 - score, 84.844%, was obtained on the proposed CNN model without employing pre-trained word vectors which outperformed the state-of-the-art works and implies the effective embedding ability of CNNs. Other key findings obtained through the conducted experiments are that the models, that constructed word embeddings through the Embedding layers, obtained higher F1 - scores and converged much faster than the models that utilized pre-trained word vectors.","Kabakus, Abdullah Talha","Kabakus, Abdullah Talha/J-8361-2019","Kabakus, Abdullah Talha/0000-0003-2181-4292",Towards the Importance of the Type of Deep Neural Network and Employment of Pre-trained Word Vectors for Toxicity Detection: An Experimental Study,20,8,10.13052/jwe1540-9589.2082 ,Article ,2021.0,"As a natural consequence of offering many advantages to their users, social media platforms have become a part of their daily lives. Recent studies emphasize the necessity of an automated way of detecting offensive posts in social media since these 'toxic' posts have become pervasive. To this end, a novel toxic post detection approach based on Deep Neural Networks was proposed within this study. Given that several word embedding methods exist, we shed light on which word embedding method produces better results when employed with the five most common types of deep neural networks, namely, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), GRU (Gated Recurrent Unit), Bidirectional Long ShortTerm Memory (BiLSTM), and a combination of CNN and BiLSTM. To this end, the word vectors for the given comments were obtained through four different methods, namely, (i) Word2vec, (ii) fastT ext, (iii) GloVe, and (iv) the Embedding layer of deep neural networks. Eventually, a total of twenty benchmark models were proposed and both trained and evaluated on a gold standard dataset which consists of 16K tweets. According to the experimental result, the best F1 - score, 84.844%, was obtained on the proposed CNN model without employing pre-trained word vectors which outperformed the state-of-the-art works and implies the effective embedding ability of CNNs. Other key findings obtained through the conducted experiments are that the models, that constructed word embeddings through the Embedding layers, obtained higher F1 - scores and converged much faster than the models that utilized pre-trained word vectors.",1540-9589,1544-5976,,2243-2268, , ,,detection#evaluation,
4046,"Title:Feature Selection for Graph Kernels

 Graph classification is important for different scientific applications; it can be exploited in various problems related to bioinformatics and cheminformatics. Given their graphs, there is increasing need for classifying small molecules to predict their properties such as activity, toxicity or mutagenicity. Using subtrees as feature set for graph classification in kernel methods has been shown to perform well in classifying small molecules. It is also well-known that feature selection can improve the performance of classifiers. However, most of the graph kernels are not selective in choosing which subtrees to include in the set of features. Instead, they use all subtrees of a certain property as their feature set. We argue that not all the latter features are needed for effective classification. In this paper, we investigate the effect of selecting subset of the subtrees as features for graph kernels, i.e., we try to identify and keep useful features; all the remaining subtrees are eliminated. A masking procedure, which boils down to feature selection, is proposed for classifying graphs. We conducted experiments on several molecule classification datasets; the results demonstrate the applicability and effectiveness of the proposed feature selection process.","Tan, Mehmet; Polat, Faruk; Alhajj, Reda","Polat, Faruk/ABA-3585-2020; Tan, Mehmet/I-2328-2019","Polat, Faruk/0000-0003-0509-9153; Tan, Mehmet/0000-0002-1741-0570",Feature Selection for Graph Kernels,,, ,Proceedings Paper ,2010.0,"Graph classification is important for different scientific applications; it can be exploited in various problems related to bioinformatics and cheminformatics. Given their graphs, there is increasing need for classifying small molecules to predict their properties such as activity, toxicity or mutagenicity. Using subtrees as feature set for graph classification in kernel methods has been shown to perform well in classifying small molecules. It is also well-known that feature selection can improve the performance of classifiers. However, most of the graph kernels are not selective in choosing which subtrees to include in the set of features. Instead, they use all subtrees of a certain property as their feature set. We argue that not all the latter features are needed for effective classification. In this paper, we investigate the effect of selecting subset of the subtrees as features for graph kernels, i.e., we try to identify and keep useful features; all the remaining subtrees are eliminated. A masking procedure, which boils down to feature selection, is proposed for classifying graphs. We conducted experiments on several molecule classification datasets; the results demonstrate the applicability and effectiveness of the proposed feature selection process.",2156-1125,2156-1133,978-1-4244-8307-5,632-637, , IEEE International Conference on Bioinformatics and Biomedicine (BIBM)IEEE International Conference on Bioinformatics and Biomedicine (BIBM),,out_of_scope,
4047,"Title:TOXIFY: a deep learning approach to classify animal venom proteins

 In the era of Next-Generation Sequencing and shotgun proteomics, the sequences of animal toxigenic proteins are being generated at rates exceeding the pace of traditional means for empirical toxicity verification. To facilitate the automation of toxin identification from protein sequences, we trained Recurrent Neural Networks with Gated Recurrent Units on publicly available datasets. The resulting models are available via the novel software package TOXIFY, allowing users to infer the probability of a given protein sequence being a venom protein. TOXIFY is more than 20X faster and uses over an order of magnitude less memory than previously published methods. Additionally, TOXIFY is more accurate, precise, and sensitive at classifying venom proteins.","Cole, T. Jeffrey; Brewer, Michael S.",,"Brewer, Michael/0000-0002-1535-6929",TOXIFY: a deep learning approach to classify animal venom proteins,7,,10.7717/peerj.7200 ,Article ,2019.0,"In the era of Next-Generation Sequencing and shotgun proteomics, the sequences of animal toxigenic proteins are being generated at rates exceeding the pace of traditional means for empirical toxicity verification. To facilitate the automation of toxin identification from protein sequences, we trained Recurrent Neural Networks with Gated Recurrent Units on publicly available datasets. The resulting models are available via the novel software package TOXIFY, allowing users to infer the probability of a given protein sequence being a venom protein. TOXIFY is more than 20X faster and uses over an order of magnitude less memory than previously published methods. Additionally, TOXIFY is more accurate, precise, and sensitive at classifying venom proteins.",2167-8359,,,, , ,,out_of_scope,
4048,"Title:Consistency of QSAR models: Correct split of training and test sets, ranking of models and performance parameters

 Recent implementations of QSAR modelling software provide the user with numerous models and a wealth of information. In this work, we provide some guidance on how one should interpret the results of QSAR modelling, compare and assess the resulting models, and select the best and most consistent ones. Two QSAR datasets are applied as case studies for the comparison of model performance parameters and model selection methods. We demonstrate the capabilities of sum of ranking differences (SRD) in model selection and ranking, and identify the best performance indicators and models. While the exchange of the original training and (external) test sets does not affect the ranking of performance parameters, it provides improved models in certain cases (despite the lower number of molecules in the training set). Performance parameters for external validation are substantially separated from the other merits in SRD analyses, highlighting their value in data fusion.","Racz, A.; Bajusz, D.; Heberger, K.","Heberger, Karoly/A-4195-2011; Bajusz, Dávid/G-4199-2015","Heberger, Karoly/0000-0003-0965-939X; Bajusz, Dávid/0000-0003-4277-9481","Consistency of QSAR models: Correct split of training and test sets, ranking of models and performance parameters",26,7-9,10.1080/1062936X.2015.1084647 ,Article ,2015.0,"Recent implementations of QSAR modelling software provide the user with numerous models and a wealth of information. In this work, we provide some guidance on how one should interpret the results of QSAR modelling, compare and assess the resulting models, and select the best and most consistent ones. Two QSAR datasets are applied as case studies for the comparison of model performance parameters and model selection methods. We demonstrate the capabilities of sum of ranking differences (SRD) in model selection and ranking, and identify the best performance indicators and models. While the exchange of the original training and (external) test sets does not affect the ranking of performance parameters, it provides improved models in certain cases (despite the lower number of molecules in the training set). Performance parameters for external validation are substantially separated from the other merits in SRD analyses, highlighting their value in data fusion.",1062-936X,1029-046X,,683-700, , ,,out_of_scope,
4049,"Title:Detecting Genetic Interactions for Quantitative Traits With U-Statistics

 The genetic etiology of complex human diseases has been commonly viewed as a process that involves multiple genetic variants, environmental factors, as well as their interactions. Statistical approaches, such as the multifactor dimensionality reduction (MDR) and generalized MDR (GMDR), have recently been proposed to test the joint association of multiple genetic variants with either dichotomous or continuous traits. In this study, we propose a novel Forward U-Test to evaluate the combined effect of multiple loci on quantitative traits with consideration of gene-gene/gene-environment interactions. In this new approach, a U-Statistic-based forward algorithm is first used to select potential disease-susceptibility loci and then a weighted U-statistic is used to test the joint association of the selected loci with the disease. Through a simulation study, we found the Forward U-Test outperformed GMDR in terms of greater power. Aside from that, our approach is less computationally intensive, making it feasible for high-dimensional gene-gene/gene-environment research. We illustrate our method with a real data application to nicotine dependence (ND), using three independent datasets from the Study of Addiction: Genetics and Environment. Our gene-gene interaction analysis of 155 SNPs in 67 candidate genes identified two SNPs, rs16969968 within gene CHRNA5 and rs1122530 within gene NTRK2, jointly associated with the level of ND (P-value = 5.31e-7). The association, which involves essential interaction, is replicated in two independent datasets with P-values of 1.08e-5 and 0.02, respectively. Our finding suggests that joint action may exist between the two gene products. Genet. Epidemiol. 35: 457-468, 2011. (C) 2011 Wiley-Liss, Inc.","Li, Ming; Ye, Chengyin; Fu, Wenjiang; Elston, Robert C.; Lu, Qing",,,Detecting Genetic Interactions for Quantitative Traits With U-Statistics,35,6,10.1002/gepi.20594 ,Article ,2011.0,"The genetic etiology of complex human diseases has been commonly viewed as a process that involves multiple genetic variants, environmental factors, as well as their interactions. Statistical approaches, such as the multifactor dimensionality reduction (MDR) and generalized MDR (GMDR), have recently been proposed to test the joint association of multiple genetic variants with either dichotomous or continuous traits. In this study, we propose a novel Forward U-Test to evaluate the combined effect of multiple loci on quantitative traits with consideration of gene-gene/gene-environment interactions. In this new approach, a U-Statistic-based forward algorithm is first used to select potential disease-susceptibility loci and then a weighted U-statistic is used to test the joint association of the selected loci with the disease. Through a simulation study, we found the Forward U-Test outperformed GMDR in terms of greater power. Aside from that, our approach is less computationally intensive, making it feasible for high-dimensional gene-gene/gene-environment research. We illustrate our method with a real data application to nicotine dependence (ND), using three independent datasets from the Study of Addiction: Genetics and Environment. Our gene-gene interaction analysis of 155 SNPs in 67 candidate genes identified two SNPs, rs16969968 within gene CHRNA5 and rs1122530 within gene NTRK2, jointly associated with the level of ND (P-value = 5.31e-7). The association, which involves essential interaction, is replicated in two independent datasets with P-values of 1.08e-5 and 0.02, respectively. Our finding suggests that joint action may exist between the two gene products. Genet. Epidemiol. 35: 457-468, 2011. (C) 2011 Wiley-Liss, Inc.",0741-0395,,,457-468, , ,,out_of_scope,
4050,"Title:Rapid detection of mussels contaminated by heavy metals using near-infrared reflectance spectroscopy and a constrained difference extreme learning machine

 The consumption of mussels contaminated with heavy metals can cause toxicity in humans. To realize quick, accurate, and non-destructive detection of heavy metals in mussels, a new method based on near-infrared reflection spectroscopy was developed in this study. Spectral data from 900 nm to 1700 nm of non-contaminated mussels and mussels contaminated with Cd, Zn, Pb, and Cu were collected using a near-infrared spectrometer. After pre-processing spectral data with multiplicative scatter correction, wavelength selection algorithms based on consistency measures of neighborhood rough sets were used to extract wavelengths for distinguishing non-contaminated and contaminated mussels. A constrained difference extreme learning machine was established as a classification model to detect contaminated mussels. In the proposed model, the weight and bias of the hidden layers are calculated by the difference vectors of samples between classes instead of being randomly selected. The results indicate that the proposed model performs significantly well in differentiating between non-contaminated and contaminated mussels. The average classification accuracy of 50 randomly generated test datasets reaches 97.53%, 95.67%, 99.00%, and 98.80% for the detection of Zn, Pb, Cd, and Cu contamination, respectively. This study demonstrates that near-infrared spectroscopy coupled with a constrained difference extreme learning can be used to rapidly and accurately detect mussels contaminated with heavy metals. This is of great significance for the evaluation of the quality and safety of mussels. (c) 2021 Elsevier B.V. All rights reserved.","Liu, Yao; Xu, Lele; Zeng, Shaogeng; Qiao, Fu; Jiang, Wei; Xu, Zhen","Xu, Le/HDN-9623-2022",,Rapid detection of mussels contaminated by heavy metals using near-infrared reflectance spectroscopy and a constrained difference extreme learning machine,269,,10.1016/j.saa.2021.120776 ,Article ,2022.0,"The consumption of mussels contaminated with heavy metals can cause toxicity in humans. To realize quick, accurate, and non-destructive detection of heavy metals in mussels, a new method based on near-infrared reflection spectroscopy was developed in this study. Spectral data from 900 nm to 1700 nm of non-contaminated mussels and mussels contaminated with Cd, Zn, Pb, and Cu were collected using a near-infrared spectrometer. After pre-processing spectral data with multiplicative scatter correction, wavelength selection algorithms based on consistency measures of neighborhood rough sets were used to extract wavelengths for distinguishing non-contaminated and contaminated mussels. A constrained difference extreme learning machine was established as a classification model to detect contaminated mussels. In the proposed model, the weight and bias of the hidden layers are calculated by the difference vectors of samples between classes instead of being randomly selected. The results indicate that the proposed model performs significantly well in differentiating between non-contaminated and contaminated mussels. The average classification accuracy of 50 randomly generated test datasets reaches 97.53%, 95.67%, 99.00%, and 98.80% for the detection of Zn, Pb, Cd, and Cu contamination, respectively. This study demonstrates that near-infrared spectroscopy coupled with a constrained difference extreme learning can be used to rapidly and accurately detect mussels contaminated with heavy metals. This is of great significance for the evaluation of the quality and safety of mussels. (c) 2021 Elsevier B.V. All rights reserved.",1386-1425,1873-3557,,, , ,,out_of_scope,
4051,"Title:The Pathogen-annotated Tracking Resource Network (PATRN) system: A web-based resource to aid food safety, regulatory science, and investigations of foodborne pathogens and disease

 Investigation of foodborne diseases requires the capture and analysis of time-sensitive information on microbial pathogens that is derived from multiple analytical methods and sources. The web-based Pathogen-annotated Tracking Resource Network (PATRN) system (www.patrn.net) was developed to address the data aggregation, analysis, and communication needs important to the global food safety community for the investigation of foodborne disease. PATRN incorporates a standard vocabulary for describing isolate metadata and provides a representational schema for a prototypic data exchange standard using a novel data loading wizard for aggregation of assay and attribution information. PATRN currently houses expert-curated, high-quality foundational datasets consisting of published experimental results from conventional assays and next generation analysis platforms for isolates of Escherichia coli, Listeria monocytogenes, and Salmonella, Shigella, Vibrio and Cronobacter species. A suite of computational tools for data mining, clustering, and graphical representation is available. Within PATRN, the public curated data repository is complemented by a secure private workspace for user-driven analyses, and for sharing data among collaborators. To demonstrate the data curation, loading wizard features, and analytical capabilities of PATRN, three use-case scenarios are presented. Use-case scenario one is a comparison of the distribution and prevalence of plasmid-encoded virulence factor genes among 249 Cronobacter strains with similar attributes to that of nine Cronobacter isolates from recent cases obtained between March and October, 2010-2011. To highlight PATRN's data management and trend finding tools, analysis of datasets, stored in PATRN as part of an ongoing surveillance project to identify the predominant molecular serogroups among Cronobacter sakazakii isolates observed in the USA is shown. Use-case scenario two demonstrates the secure workspace available for private users to upload and analyze sensitive data, and for collating cross-platform datasets to identify and validate congruent datapoints. SNP datasets from WGS assemblies and pan-genome microarrays are analyzed in a combinatorial fashion to determine relatedness of 33 Salmonella enterica strains to six strains collected as part of an outbreak investigation. Use-case scenario three utilizes published surveillance results that describe the incidence and sources of O157:H7 E. coli isolates associated with a produce pre-harvest surveillance study that occurred during 2002-2006. In summary, PATRN is a web-based integrated platform containing tools for the management, analysis and visualization of data about foodborne pathogens. Published by Elsevier Ltd.","Gopinath, G.; Hari, K.; Jain, R.; Mammel, M. K.; Kothary, M. H.; Franco, A. A.; Grim, C. J.; Jarvis, K. G.; Sathyamoorthy, V.; Hu, L.; Datta, A. R.; Patel, I. R.; Jackson, S. A.; Gangiredla, J.; Kotewicz, M. L.; LeClerc, J. E.; Wekell, M.; McCardell, B. A.; Solomotis, M. D.; Tall, B. D.",,"Jackson, Scott/0000-0003-4891-8323; Tall, Ben/0000-0003-0399-3629","The Pathogen-annotated Tracking Resource Network (PATRN) system: A web-based resource to aid food safety, regulatory science, and investigations of foodborne pathogens and disease",34,2,10.1016/j.fm.2013.01.001 ,Article ,2013.0,"Investigation of foodborne diseases requires the capture and analysis of time-sensitive information on microbial pathogens that is derived from multiple analytical methods and sources. The web-based Pathogen-annotated Tracking Resource Network (PATRN) system (www.patrn.net) was developed to address the data aggregation, analysis, and communication needs important to the global food safety community for the investigation of foodborne disease. PATRN incorporates a standard vocabulary for describing isolate metadata and provides a representational schema for a prototypic data exchange standard using a novel data loading wizard for aggregation of assay and attribution information. PATRN currently houses expert-curated, high-quality foundational datasets consisting of published experimental results from conventional assays and next generation analysis platforms for isolates of Escherichia coli, Listeria monocytogenes, and Salmonella, Shigella, Vibrio and Cronobacter species. A suite of computational tools for data mining, clustering, and graphical representation is available. Within PATRN, the public curated data repository is complemented by a secure private workspace for user-driven analyses, and for sharing data among collaborators. To demonstrate the data curation, loading wizard features, and analytical capabilities of PATRN, three use-case scenarios are presented. Use-case scenario one is a comparison of the distribution and prevalence of plasmid-encoded virulence factor genes among 249 Cronobacter strains with similar attributes to that of nine Cronobacter isolates from recent cases obtained between March and October, 2010-2011. To highlight PATRN's data management and trend finding tools, analysis of datasets, stored in PATRN as part of an ongoing surveillance project to identify the predominant molecular serogroups among Cronobacter sakazakii isolates observed in the USA is shown. Use-case scenario two demonstrates the secure workspace available for private users to upload and analyze sensitive data, and for collating cross-platform datasets to identify and validate congruent datapoints. SNP datasets from WGS assemblies and pan-genome microarrays are analyzed in a combinatorial fashion to determine relatedness of 33 Salmonella enterica strains to six strains collected as part of an outbreak investigation. Use-case scenario three utilizes published surveillance results that describe the incidence and sources of O157:H7 E. coli isolates associated with a produce pre-harvest surveillance study that occurred during 2002-2006. In summary, PATRN is a web-based integrated platform containing tools for the management, analysis and visualization of data about foodborne pathogens. Published by Elsevier Ltd.",0740-0020,1095-9998,,303-318, , ,,out_of_scope,
4052,"Title:Advances in the management of radiation-induced cystitis in patients with pelvic malignancies

 ObjectiveRadiotherapy plays a vital role as a treatment for malignant pelvic tumors, in which the bladder represents a significant organ at risk involved during tumor radiotherapy. Exposing the bladder wall to high doses of ionizing radiation is unavoidable and will lead to radiation cystitis (RC) because of its central position in the pelvic cavity. Radiation cystitis will result in several complications (e.g. frequent micturition, urgent urination, and nocturia) that can significantly reduce the patient's quality of life and in very severe cases become life-threatening.MethodsExisting studies on the pathophysiology, prevention, and management of radiation-induced cystitis from January 1990 to December 2021 were reviewed. PubMed was used as the main search engine. Besides the reviewed studies, citations to those studies were also included.Results and discussionsIn this review, the symptoms of radiation cystitis and the mainstream grading scales employed in clinical situations are presented. Next, preclinical and clinical research on preventing and treating radiation cystitis are summarized, and an overview of currently available prevention and treatment strategies as guidelines for clinicians is provided. Treatment options involve symptomatic treatment, vascular interventional therapy, surgery, hyperbaric oxygen therapy (HBOT), bladder irrigation, and electrocoagulation. Prevention includes filling up the bladder to remove it from the radiation field and delivering radiation based on helical tomotherapy and CT-guided 3D intracavitary brachytherapy techniques.","Wang, Yimin; Zhu, Yan; Xu, Xiaoting",,"Luo, Yiming/0000-0003-3096-4583; Lin, Yiming/0000-0001-6249-9909",Advances in the management of radiation-induced cystitis in patients with pelvic malignancies,,,10.1080/09553002.2023.2181996 ,Review; Early Access ,,"ObjectiveRadiotherapy plays a vital role as a treatment for malignant pelvic tumors, in which the bladder represents a significant organ at risk involved during tumor radiotherapy. Exposing the bladder wall to high doses of ionizing radiation is unavoidable and will lead to radiation cystitis (RC) because of its central position in the pelvic cavity. Radiation cystitis will result in several complications (e.g. frequent micturition, urgent urination, and nocturia) that can significantly reduce the patient's quality of life and in very severe cases become life-threatening.MethodsExisting studies on the pathophysiology, prevention, and management of radiation-induced cystitis from January 1990 to December 2021 were reviewed. PubMed was used as the main search engine. Besides the reviewed studies, citations to those studies were also included.Results and discussionsIn this review, the symptoms of radiation cystitis and the mainstream grading scales employed in clinical situations are presented. Next, preclinical and clinical research on preventing and treating radiation cystitis are summarized, and an overview of currently available prevention and treatment strategies as guidelines for clinicians is provided. Treatment options involve symptomatic treatment, vascular interventional therapy, surgery, hyperbaric oxygen therapy (HBOT), bladder irrigation, and electrocoagulation. Prevention includes filling up the bladder to remove it from the radiation field and delivering radiation based on helical tomotherapy and CT-guided 3D intracavitary brachytherapy techniques.",0955-3002,1362-3095,,, , ,,out_of_scope,
4053,"Title:Willingness to engage in a pro-environmental behavior: An analysis of e-waste recycling based on a national survey of U.S. households

 Using concepts from environmental psychology and economics, we investigate U.S. households' willingness to engage in a form of pro-environmental behavior: recycling electronic waste (e-waste) at drop-off locations. We rely on rich dataset from a 2006 national survey of U.S. households (N = 2136). Our internal variables include a modified version of the New Ecological Paradigm scale, a moral norm scale based on Schwartz's norm-activation model, and indicators of social pressure for recycling. External variables consist of detailed socio-demographic characteristics. Our logit model shows that external variables do not help characterizing people with e-waste recycling experience, except that they tend to have larger families or to be over 60 years old. However, knowing that e-waste contains potentially toxic materials, recycling conventional materials at work or at school, and especially having strong moral norms helps explain e-waste recycling behavior. Using a generalized ordered logit model, we then show that the most important variables for explaining household willingness to recycle e-waste are internal variables, followed by recycling convenience, knowledge of the potential toxicity of e-waste, prior e-waste recycling experience, as well as gender and marital status; education, age, and ethnicity play only a minor role, while knowledge of e-waste laws, availability of curbside recycling for domestic waste, and income are not statistically significant. Our results suggest that e-waste recycling can be stimulated by promoting moral norms, educating the public about the benefits of recycling e-waste, and making e-waste recycling more convenient but other measures will likely be necessary to tackle the e-waste problem. (C) 2011 Elsevier B.V. All rights reserved.","Saphores, Jean-Daniel M.; Ogunseitan, Oladele A.; Shapiro, Andrew A.","Saphores, Jean-Daniel/JCZ-2810-2023; Ogunseitan, oladele/AAF-8528-2020; Saphores, Jean Daniel/Q-5445-2019","Saphores, Jean-Daniel/0000-0001-9514-0994; Ogunseitan, oladele/0000-0003-1317-6219; Saphores, Jean Daniel/0000-0001-9514-0994; Shapiro, Andrew/0000-0002-2650-8107",Willingness to engage in a pro-environmental behavior: An analysis of e-waste recycling based on a national survey of U.S. households,60,,10.1016/j.resconrec.2011.12.003 ,Article ,2012.0,"Using concepts from environmental psychology and economics, we investigate U.S. households' willingness to engage in a form of pro-environmental behavior: recycling electronic waste (e-waste) at drop-off locations. We rely on rich dataset from a 2006 national survey of U.S. households (N = 2136). Our internal variables include a modified version of the New Ecological Paradigm scale, a moral norm scale based on Schwartz's norm-activation model, and indicators of social pressure for recycling. External variables consist of detailed socio-demographic characteristics. Our logit model shows that external variables do not help characterizing people with e-waste recycling experience, except that they tend to have larger families or to be over 60 years old. However, knowing that e-waste contains potentially toxic materials, recycling conventional materials at work or at school, and especially having strong moral norms helps explain e-waste recycling behavior. Using a generalized ordered logit model, we then show that the most important variables for explaining household willingness to recycle e-waste are internal variables, followed by recycling convenience, knowledge of the potential toxicity of e-waste, prior e-waste recycling experience, as well as gender and marital status; education, age, and ethnicity play only a minor role, while knowledge of e-waste laws, availability of curbside recycling for domestic waste, and income are not statistically significant. Our results suggest that e-waste recycling can be stimulated by promoting moral norms, educating the public about the benefits of recycling e-waste, and making e-waste recycling more convenient but other measures will likely be necessary to tackle the e-waste problem. (C) 2011 Elsevier B.V. All rights reserved.",0921-3449,,,49-63, , ,,out_of_scope,
4054,"Title:Light Sheet-based Fluorescence Microscopy of Living or Fixed and Stained Tribolium castaneum Embryos

 The red flour beetle Tribolium castaneum has become an important insect model organism in developmental genetics and evolutionary developmental biology. The observation of Tribolium embryos with light sheet-based fluorescence microscopy has multiple advantages over conventional widefield and confocal fluorescence microscopy. Due to the unique properties of a light sheet-based microscope, three dimensional images of living specimens can be recorded with high signal-to-noise ratios and significantly reduced photo-bleaching as well as photo-toxicity along multiple directions over periods that last several days. With more than four years of methodological development and a continuous increase of data, the time seems appropriate to establish standard operating procedures for the usage of light sheet technology in the Tribolium community as well as in the insect community at large. This protocol describes three mounting techniques suitable for different purposes, presents two novel custom-made transgenic Tribolium lines appropriate for long-term live imaging, suggests five fluorescent dyes to label intracellular structures of fixed embryos and provides information on data post-processing for the timely evaluation of the recorded data. Representative results concentrate on long-term live imaging, optical sectioning and the observation of the same embryo along multiple directions. The respective datasets are provided as a downloadable resource. Finally, the protocol discusses quality controls for live imaging assays, current limitations and the applicability of the outlined procedures to other insect species.This protocol is primarily intended for developmental biologists who seek imaging solutions that outperform standard laboratory equipment. It promotes the continuous attempt to close the gap between the technically orientated laboratories/communities, which develop and refine microscopy methodologically, and the life science laboratories/communities, which require 'plug-and-play' solutions to technical challenges. Furthermore, it supports an axiomatic approach that moves the biological questions into the center of attention.","Strobl, Frederic; Klees, Selina; Stelzer, Ernst H. K.","Stelzer, Ernst H K/A-7648-2011","Stelzer, Ernst H K/0000-0003-1545-0736; Strobl, Frederic/0000-0002-5350-0194",Light Sheet-based Fluorescence Microscopy of Living or Fixed and Stained Tribolium castaneum Embryos,,122,10.3791/55629 ,Article ,2017.0,"The red flour beetle Tribolium castaneum has become an important insect model organism in developmental genetics and evolutionary developmental biology. The observation of Tribolium embryos with light sheet-based fluorescence microscopy has multiple advantages over conventional widefield and confocal fluorescence microscopy. Due to the unique properties of a light sheet-based microscope, three dimensional images of living specimens can be recorded with high signal-to-noise ratios and significantly reduced photo-bleaching as well as photo-toxicity along multiple directions over periods that last several days. With more than four years of methodological development and a continuous increase of data, the time seems appropriate to establish standard operating procedures for the usage of light sheet technology in the Tribolium community as well as in the insect community at large. This protocol describes three mounting techniques suitable for different purposes, presents two novel custom-made transgenic Tribolium lines appropriate for long-term live imaging, suggests five fluorescent dyes to label intracellular structures of fixed embryos and provides information on data post-processing for the timely evaluation of the recorded data. Representative results concentrate on long-term live imaging, optical sectioning and the observation of the same embryo along multiple directions. The respective datasets are provided as a downloadable resource. Finally, the protocol discusses quality controls for live imaging assays, current limitations and the applicability of the outlined procedures to other insect species.This protocol is primarily intended for developmental biologists who seek imaging solutions that outperform standard laboratory equipment. It promotes the continuous attempt to close the gap between the technically orientated laboratories/communities, which develop and refine microscopy methodologically, and the life science laboratories/communities, which require 'plug-and-play' solutions to technical challenges. Furthermore, it supports an axiomatic approach that moves the biological questions into the center of attention.",1940-087X,,,, , ,,out_of_scope,
4055,"Title:Modelling exposure in flour processing sectors in The Netherlands: A baseline measurement in the context of an intervention program

 Introduction: Recent studies have shown that even low exposure levels to flour dust and related allergens can cause severe respiratory symptoms. In The Netherlands the Dutch government and responsible branch organizations [from bakeries (traditional & industrial), flour mills and bakery ingredient producers] signed a covenant to reduce exposure to Hour dust and decrease the prevalence of work-related occupational airway disease. This paper describes a sector wide survey to measure exposure to flour dust, wheat allergens and fungal a-amylase. The results are being used to underpin various elements of the covenant.Methods: A dataset containing 910 personal measurements was compiled from four field studies containing information on exposure and potential determinants. The dataset represents a baseline estimate of exposure for four major flour processing sectors in The Netherlands. Exposure models for all sectors and agents were generated, based on job, tasks and company size, taking into account worker and company as random effect components. Use of control measures and, where possible, their effect were evaluated.Results: Flour dust and enzyme exposures vary strongly between sectors. The job performed and specific tasks were identified as important determinants of exposure. The number of identified control measures during walk-through surveys, and their effectiveness in reduction of dust exposure was generally limited. The exposure models explained significant exposure variability between companies and workers but performed poorly in explaining day to day differences in exposure.Discussion: The dataset serves as a baseline estimate and will be compared with a post intervention survey in the near future. The information obtained on control measures can be used to optimize the intervention scenarios that will be implemented in the different sectors by external occupational hygienists. The predictive exposure models will provide a relevant measure of average personal exposure that will be used in the sector wide health surveillance system.","Meijster, Tim; Tielemans, Erik; de Pater, Nettie; Heederik, Dick",,"Heederik, Dick/0000-0002-4550-1437",Modelling exposure in flour processing sectors in The Netherlands: A baseline measurement in the context of an intervention program,51,3,10.1093/annhyg/mem008 ,Article ,2007.0,"Introduction: Recent studies have shown that even low exposure levels to flour dust and related allergens can cause severe respiratory symptoms. In The Netherlands the Dutch government and responsible branch organizations [from bakeries (traditional & industrial), flour mills and bakery ingredient producers] signed a covenant to reduce exposure to Hour dust and decrease the prevalence of work-related occupational airway disease. This paper describes a sector wide survey to measure exposure to flour dust, wheat allergens and fungal a-amylase. The results are being used to underpin various elements of the covenant.Methods: A dataset containing 910 personal measurements was compiled from four field studies containing information on exposure and potential determinants. The dataset represents a baseline estimate of exposure for four major flour processing sectors in The Netherlands. Exposure models for all sectors and agents were generated, based on job, tasks and company size, taking into account worker and company as random effect components. Use of control measures and, where possible, their effect were evaluated.Results: Flour dust and enzyme exposures vary strongly between sectors. The job performed and specific tasks were identified as important determinants of exposure. The number of identified control measures during walk-through surveys, and their effectiveness in reduction of dust exposure was generally limited. The exposure models explained significant exposure variability between companies and workers but performed poorly in explaining day to day differences in exposure.Discussion: The dataset serves as a baseline estimate and will be compared with a post intervention survey in the near future. The information obtained on control measures can be used to optimize the intervention scenarios that will be implemented in the different sectors by external occupational hygienists. The predictive exposure models will provide a relevant measure of average personal exposure that will be used in the sector wide health surveillance system.",0003-4878,1475-3162,,293-304, , ,,out_of_scope,
4056,"Title:Predicting personalised and progressive adaptive dose escalation to gross tumour volume using knowledge-based planning models for inoperable advanced-stage non-small cell lung cancer patients treated with volumetric modulated arc therapy

 Objectives. Increased radiation doses could improve local control and overall survival of lung cancer patients, however, this could be challenging without exceeding organs at risk (OAR) dose constraints, especially for patients with advanced-stage disease. Increasing OAR doses could reduce the therapeutic ratio and quality of life. It is therefore important to investigate methods to increase the dose to target volume without exceeding OAR dose constraints. Methods. Gross tumour volume (GTV) was contoured on synthetic computerised tomography (sCT) datasets produced using the Velocity adaptive radiotherapy software for eleven patients. The fractions where GTV volume decreased compared to that prior to radiotherapy (reference plan) were considered for personalised progressive dose escalation. The dose to the adapted GTV (GTV(Adaptive)) was increased until OAR doses were affected (as compared to the original clinical plan). Planning target volume (PTV) coverage was maintained for all plans. Doses were also escalated to the reference plan (GTV(Clinical)) using the same method. Adapted, dose-escalated, plans were combined to estimate accumulated dose, D-99 (dose to 99%) of GTV(Adapted,) PTV D-99 and OAR doses and compared with those in the original clinical plans. Knowledge-based planning (KBP) model was developed to predict D-99 of the adapted GTV with OAR doses and PTV coverage kept similar to the original clinical plans; prediction accuracy and model verification were performed using further data sets. Results. Compared to the original clinical plan, the dose to GTV was significantly increased without exceeding OAR doses. Adaptive dose-escalation increased the average D(99 )to GTV(Adaptive) by 15.1Gy and 8.7Gy compared to the clinical plans. The KBP models were verified and demonstrated prediction accuracy of 0.4% and 0.7% respectively. Conclusion. Progressive adaptive dose escalation can significantly increase the dose to GTV without increasing OAR doses or compromising the dose to microscopic disease. This may increase overall survival without increasing toxicities.","Tambe, Nilesh S.; Pires, Isabel M.; Moore, Craig; Wieczorek, Andrew; Upadhyay, Sunil; Beavis, Andrew W.",,"beavis, andrew/0000-0002-2519-0205; Monteiro dos Santos Pires, Isabel/0000-0002-0417-2710; Moore, Craig/0000-0001-7409-8387",Predicting personalised and progressive adaptive dose escalation to gross tumour volume using knowledge-based planning models for inoperable advanced-stage non-small cell lung cancer patients treated with volumetric modulated arc therapy,8,3,10.1088/2057-1976/ac56eb ,Article ,2022.0,"Objectives. Increased radiation doses could improve local control and overall survival of lung cancer patients, however, this could be challenging without exceeding organs at risk (OAR) dose constraints, especially for patients with advanced-stage disease. Increasing OAR doses could reduce the therapeutic ratio and quality of life. It is therefore important to investigate methods to increase the dose to target volume without exceeding OAR dose constraints. Methods. Gross tumour volume (GTV) was contoured on synthetic computerised tomography (sCT) datasets produced using the Velocity adaptive radiotherapy software for eleven patients. The fractions where GTV volume decreased compared to that prior to radiotherapy (reference plan) were considered for personalised progressive dose escalation. The dose to the adapted GTV (GTV(Adaptive)) was increased until OAR doses were affected (as compared to the original clinical plan). Planning target volume (PTV) coverage was maintained for all plans. Doses were also escalated to the reference plan (GTV(Clinical)) using the same method. Adapted, dose-escalated, plans were combined to estimate accumulated dose, D-99 (dose to 99%) of GTV(Adapted,) PTV D-99 and OAR doses and compared with those in the original clinical plans. Knowledge-based planning (KBP) model was developed to predict D-99 of the adapted GTV with OAR doses and PTV coverage kept similar to the original clinical plans; prediction accuracy and model verification were performed using further data sets. Results. Compared to the original clinical plan, the dose to GTV was significantly increased without exceeding OAR doses. Adaptive dose-escalation increased the average D(99 )to GTV(Adaptive) by 15.1Gy and 8.7Gy compared to the clinical plans. The KBP models were verified and demonstrated prediction accuracy of 0.4% and 0.7% respectively. Conclusion. Progressive adaptive dose escalation can significantly increase the dose to GTV without increasing OAR doses or compromising the dose to microscopic disease. This may increase overall survival without increasing toxicities.",2057-1976,,,, , ,,out_of_scope,
4057,"Title:Printed Machine Learning Classifiers

 A large number of application domains have requirements on cost, conformity, and non-toxicity that silicon-based computing systems cannot meet, but that may be met by printed electronics. For several of these domains, a typical computational task to be performed is classification. In this work, we explore the hardware cost of inference engines for popular classification algorithms (Multi-Layer Perceptrons, Support Vector Machines (SVMs), Logistic Regression, Random Forests and Binary Decision Trees) in EGT and CNT-TFT printed technologies and determine that Decision Trees and SVMs provide a good balance between accuracy and cost. We evaluate conventional Decision Tree and SVM architectures in these technologies and conclude that their area and power overhead must be reduced. We explore, through SPICE and gate-level hardware simulations and multiple working prototypes, several classifier architectures that exploit the unique cost and implementation tradeoffs in printed technologies - a) Bespoke printed classifers that are customized to a model generated for a given application using specific training datasets, b) Lookup-based printed classifiers where key hardware computations are replaced by lookup tables, and c) Analog printed classifiers where some classifier components are replaced by their analog equivalents. Our evaluations show that bespoke implementation of EGT printed Decision Trees has 48.9x lower area (average) and 75.6x lower power (average) than their conventional equivalents; corresponding benefits for bespoke SVMs are 12.8x and 12.7x respectively. Lookup-based Decision Trees outperform their non-lookup bespoke equivalents by 38% and 70%; lookup-based SVMs are better by 8% and 0.6%. Analog printed Decision Trees provide 437 x area and 27x power benefits over digital bespoke counterparts; analog SVMs yield 490x area and 12x power improvements. Our results and prototypes demonstrate feasibility of fabricating and deploying battery and self-powered printed classifiers in the application domains of interest.","Mubarik, Muhammad Husnain; Weller, Dennis D.; Bleier, Nathaniel; Tomei, Matthew; Aghassi-Hagmann, Jasmin; Tahoori, Mehdi B.; Kumar, Rakesh","Kumar, Rakesh/ABD-1065-2020","Kumar, Rakesh/0000-0001-7664-0803; Bleier, Nathaniel/0000-0001-7791-2065; Aghassi-Hagmann, Jasmin/0000-0003-0348-041X",Printed Machine Learning Classifiers,,,10.1109/MICRO50266.2020.00019 ,Proceedings Paper ,2020.0,"A large number of application domains have requirements on cost, conformity, and non-toxicity that silicon-based computing systems cannot meet, but that may be met by printed electronics. For several of these domains, a typical computational task to be performed is classification. In this work, we explore the hardware cost of inference engines for popular classification algorithms (Multi-Layer Perceptrons, Support Vector Machines (SVMs), Logistic Regression, Random Forests and Binary Decision Trees) in EGT and CNT-TFT printed technologies and determine that Decision Trees and SVMs provide a good balance between accuracy and cost. We evaluate conventional Decision Tree and SVM architectures in these technologies and conclude that their area and power overhead must be reduced. We explore, through SPICE and gate-level hardware simulations and multiple working prototypes, several classifier architectures that exploit the unique cost and implementation tradeoffs in printed technologies - a) Bespoke printed classifers that are customized to a model generated for a given application using specific training datasets, b) Lookup-based printed classifiers where key hardware computations are replaced by lookup tables, and c) Analog printed classifiers where some classifier components are replaced by their analog equivalents. Our evaluations show that bespoke implementation of EGT printed Decision Trees has 48.9x lower area (average) and 75.6x lower power (average) than their conventional equivalents; corresponding benefits for bespoke SVMs are 12.8x and 12.7x respectively. Lookup-based Decision Trees outperform their non-lookup bespoke equivalents by 38% and 70%; lookup-based SVMs are better by 8% and 0.6%. Analog printed Decision Trees provide 437 x area and 27x power benefits over digital bespoke counterparts; analog SVMs yield 490x area and 12x power improvements. Our results and prototypes demonstrate feasibility of fabricating and deploying battery and self-powered printed classifiers in the application domains of interest.",,,978-1-7281-7383-2,73-87, , 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO),,out_of_scope,
4058,"Title:Multifunctional Ag-In-Zn-S/Cs3Cu2Cl5-Based Memristors with Coexistence of Non-Volatile Memory and Volatile Threshold Switching Behaviors for Neuroinspired Computing

 Lead-free all-inorganic Cs3Cu2Cl5 perovskites, a member of the metal-metal halide material family, have attracted pronounced attention owing to their low toxicity, facile fabrication strategies, considerable ambient stability, and intriguing photoelectric properties. However, the application of environmentally friendly copper-based Cs3Cu2Cl5 in memristors has been rarely reported to the authors' knowledge. Herein, multifunctional memristors with the coexistence of non-volatile memory (MS) and volatile threshold switching (TS) behaviors are introduced based on an innovative Ag-In-Zn-S/Cs3Cu2Cl5 heterostructure. The inserted Ag-In-Zn-S quantum dots layer may provide an effective method for guiding the formation of the dominant metallic Ag filaments, resulting in considerably stable and controllable multiple switching behaviors. Additionally, the heterostructure memristor is capable of imitating some essential biological synaptic functions, including long-term potentiation (LTP), long-term depression (LTD), and the short-term memory (STM) to long-term memory (LTM) transition. Furthermore, the famous conditioning Pavlov's dog experiment corresponding to associative learning is electronically simulated by the studied device. Moreover, utilizing the devices' LTP and LTD properties, relatively high recognition accuracies for small and large digits datasets are achieved through a three-layer artificial neural network, revealing the feasibility of implementing neuromorphic computation using heterostructure memristors.","He, Nan; Ye, Fan; Liu, Jun; Sun, Tianlong; Wang, Xinpeng; Hou, Wenjie; Shao, Weijing; Wan, Xiang; Tong, Yi; Xu, Feng; Sheng, Yang",,"He, Nan/0000-0002-8885-2907; Wan, Xiang/0000-0001-6085-0603",Multifunctional Ag-In-Zn-S/Cs3Cu2Cl5-Based Memristors with Coexistence of Non-Volatile Memory and Volatile Threshold Switching Behaviors for Neuroinspired Computing,9,3,10.1002/aelm.202201038 ,Article ,2023.0,"Lead-free all-inorganic Cs3Cu2Cl5 perovskites, a member of the metal-metal halide material family, have attracted pronounced attention owing to their low toxicity, facile fabrication strategies, considerable ambient stability, and intriguing photoelectric properties. However, the application of environmentally friendly copper-based Cs3Cu2Cl5 in memristors has been rarely reported to the authors' knowledge. Herein, multifunctional memristors with the coexistence of non-volatile memory (MS) and volatile threshold switching (TS) behaviors are introduced based on an innovative Ag-In-Zn-S/Cs3Cu2Cl5 heterostructure. The inserted Ag-In-Zn-S quantum dots layer may provide an effective method for guiding the formation of the dominant metallic Ag filaments, resulting in considerably stable and controllable multiple switching behaviors. Additionally, the heterostructure memristor is capable of imitating some essential biological synaptic functions, including long-term potentiation (LTP), long-term depression (LTD), and the short-term memory (STM) to long-term memory (LTM) transition. Furthermore, the famous conditioning Pavlov's dog experiment corresponding to associative learning is electronically simulated by the studied device. Moreover, utilizing the devices' LTP and LTD properties, relatively high recognition accuracies for small and large digits datasets are achieved through a three-layer artificial neural network, revealing the feasibility of implementing neuromorphic computation using heterostructure memristors.",2199-160X,,,, , ,,out_of_scope,
4059,"Title:Development and validation of a deep learning-based automatic auscultatory blood pressure measurement method

 Manual auscultatory is the gold standard for clinical non-invasive blood pressure (BP) measurement, but its usage is decreasing as it requires substantial professional skills and training, and its environmental concerns related to mercury toxicity. As an alternative, automatic oscillometric technique has been used as one of the most common methods for BP measurement, however, it only estimates BPs based on empirical equations. To overcome these problems, this study aimed to develop a deep learning-based automatic auscultatory BP measurement method, and clinically validate its performance. A deep learning-based method that utilized time-frequency characteristics and temporal dependence of segmented Korotkoff sound (KorS) signals and employed convolutional neural network (CNN) and long short-term memory (LSTM) network was developed and trained using KorS and cuff pressure signals recorded from 314 subjects. The BPs determined by the manual auscultatory method was used as the reference for each measurement. The measurement error and BP category classification performance of our proposed method were then validated on a separate dataset of 114 subjects. Its performance in comparison with the oscillometric method was also comprehensively analyzed. The deep learning method achieved measurement errors of 0.2 +/- 4.6 mmHg and 0.1 +/- 3.2 mmHg for systolic BP and diastolic BP, respectively, and achieved high sensitivity, specificity and accuracy (all > 90 %) in classifying hypertensive subjects, which were better than those of the traditional oscillometric method. This validation study demonstrated that deep learning-based automatic auscultatory BP measurement can be developed to achieve high measurement accuracy and high BP category classification performance.","Pan, Fan; He, Peiyu; Wang, He; Xu, Yuhang; Pu, Xiaobo; Zhao, Qijun; Chen, Fei; Zheng, Dingchang","Pan, Fan/T-3449-2019; Chen, Fei/AAK-6755-2020; Wang, He/ABD-8303-2021; pu, xiaobo/GYV-1065-2022","Pan, Fan/0000-0001-9119-7387; Chen, Fei/0000-0002-6988-492X; Wang, He/0000-0002-2281-5679; pu, xiaobo/0000-0003-1992-0977; Xu, Yuhang/0000-0002-9897-4334; Zheng, Dingchang/0000-0001-8077-4548",Development and validation of a deep learning-based automatic auscultatory blood pressure measurement method,68,,10.1016/j.bspc.2021.102742 ,Article ,2021.0,"Manual auscultatory is the gold standard for clinical non-invasive blood pressure (BP) measurement, but its usage is decreasing as it requires substantial professional skills and training, and its environmental concerns related to mercury toxicity. As an alternative, automatic oscillometric technique has been used as one of the most common methods for BP measurement, however, it only estimates BPs based on empirical equations. To overcome these problems, this study aimed to develop a deep learning-based automatic auscultatory BP measurement method, and clinically validate its performance. A deep learning-based method that utilized time-frequency characteristics and temporal dependence of segmented Korotkoff sound (KorS) signals and employed convolutional neural network (CNN) and long short-term memory (LSTM) network was developed and trained using KorS and cuff pressure signals recorded from 314 subjects. The BPs determined by the manual auscultatory method was used as the reference for each measurement. The measurement error and BP category classification performance of our proposed method were then validated on a separate dataset of 114 subjects. Its performance in comparison with the oscillometric method was also comprehensively analyzed. The deep learning method achieved measurement errors of 0.2 +/- 4.6 mmHg and 0.1 +/- 3.2 mmHg for systolic BP and diastolic BP, respectively, and achieved high sensitivity, specificity and accuracy (all > 90 %) in classifying hypertensive subjects, which were better than those of the traditional oscillometric method. This validation study demonstrated that deep learning-based automatic auscultatory BP measurement can be developed to achieve high measurement accuracy and high BP category classification performance.",1746-8094,1746-8108,,, , ,,out_of_scope,
4060,"Title:The Relevance of Goodness-of-fit, Robustness and Prediction Validation Categories of OECD-QSAR Principles with Respect to Sample Size and Model Type

 We investigated the relevance of the validation principles on the Quantitative Structure Activity Relationship models issued by Organization for Economic and Co-operation and Development. We checked the goodness-of-fit, robustness and predictivity categories in linear and nonlinear models using benchmark datasets. Most of our conclusions are drawn using the sample size dependence of the different validation parameters. We found that the goodness-of-fit parameters misleadingly overestimate the models on small samples. In the case of neural network and support vector models, the feasibility of the goodness-of-fit parameters often might be questioned. We propose to use the simplest y-scrambling method to estimate chance correlation. We found that the leave-one-out and leave-many-out cross-validation parameters can be rescaled to each other in all models and the computationally feasible method should be chosen depending on the model type. We assessed the interdependence of the validation parameters by calculating their rank correlations. Goodness of fit and robustness correlate quite well over a sample size for linear models and one of the approaches might be redundant. In the rank correlation between internal and external validation parameters, we found that the assignment of good and bad modellable data to the training or the test causes negative correlations.","Kiraly, Peter; Kiss, Ramona; Kovacs, Daniel; Ballaj, Amine; Toth, Gergely","Kovács, Dániel/AAH-2865-2021; Toth, Gergely/G-5382-2011","Toth, Gergely/0000-0002-5146-5700; Kovacs, Daniel/0000-0001-9584-0878; , Peter/0009-0001-0631-4858","The Relevance of Goodness-of-fit, Robustness and Prediction Validation Categories of OECD-QSAR Principles with Respect to Sample Size and Model Type",41,11,10.1002/minf.202200072 ,Article ,2022.0,"We investigated the relevance of the validation principles on the Quantitative Structure Activity Relationship models issued by Organization for Economic and Co-operation and Development. We checked the goodness-of-fit, robustness and predictivity categories in linear and nonlinear models using benchmark datasets. Most of our conclusions are drawn using the sample size dependence of the different validation parameters. We found that the goodness-of-fit parameters misleadingly overestimate the models on small samples. In the case of neural network and support vector models, the feasibility of the goodness-of-fit parameters often might be questioned. We propose to use the simplest y-scrambling method to estimate chance correlation. We found that the leave-one-out and leave-many-out cross-validation parameters can be rescaled to each other in all models and the computationally feasible method should be chosen depending on the model type. We assessed the interdependence of the validation parameters by calculating their rank correlations. Goodness of fit and robustness correlate quite well over a sample size for linear models and one of the approaches might be redundant. In the rank correlation between internal and external validation parameters, we found that the assignment of good and bad modellable data to the training or the test causes negative correlations.",1868-1743,1868-1751,,, , ,,out_of_scope,
4061,"Title:Abusive Bangla comments detection on Facebook using transformer-based deep learning models

 In the era of social networking platforms, user-generated content is flooding every second on online social media platforms like Facebook. So observing and identifying many contents, including threats and sexual harassment, are more accessible than traditional media. Online content with extreme toxicity can lead to online harassment, profanity, personal attacks, and bullying acts. As Bangla is the seventh most spoken language worldwide, the utilization of Bangla language in Facebook has raised current times. The use of abusive comments on Facebook with Bangla also has increased alarmingly, but the research regarding this is very low. In this research work, we concentrate on identifying abusive comments of Bangla language in social media (Facebook) that can filter out at the primitive stage of social media's affixing. To classify abusive comments swiftly and precisely, we apply transformer-based deep neural network models. We employ pre-training language architectures, BERT (Bidirectional Encoder Representations from Transformers) and ELECTRA (Efficiency Learning an Encoder that Classifies Token Replacements Accurately). We have conducted this work with a novel dataset comprises 44,001 comments from multitudinous Facebook posts. In this classification process, we have exhibited an average accuracy, precision, recall, and f1-score to evaluate our proposed models. The outcomes have brought a percipience of our applied BERT and ELECTRA architecture that performs notably with 85.00% and 84.92% test accuracy, respectively.","Aurpa, Tanjim Taharat; Sadik, Rifat; Ahmed, Md Shoaib","Ahmed, Md Shoaib/ABD-3756-2021; Aurpa, Tanjim Taharat/GMW-4407-2022; SADIK, RIFAT/HNP-2874-2023","Ahmed, Md Shoaib/0000-0002-6938-7309; Aurpa, Tanjim Taharat/0000-0003-1471-1316; SADIK, RIFAT/0000-0002-0068-1817",Abusive Bangla comments detection on Facebook using transformer-based deep learning models,12,1,10.1007/s13278-021-00852-x ,Article ,2022.0,"In the era of social networking platforms, user-generated content is flooding every second on online social media platforms like Facebook. So observing and identifying many contents, including threats and sexual harassment, are more accessible than traditional media. Online content with extreme toxicity can lead to online harassment, profanity, personal attacks, and bullying acts. As Bangla is the seventh most spoken language worldwide, the utilization of Bangla language in Facebook has raised current times. The use of abusive comments on Facebook with Bangla also has increased alarmingly, but the research regarding this is very low. In this research work, we concentrate on identifying abusive comments of Bangla language in social media (Facebook) that can filter out at the primitive stage of social media's affixing. To classify abusive comments swiftly and precisely, we apply transformer-based deep neural network models. We employ pre-training language architectures, BERT (Bidirectional Encoder Representations from Transformers) and ELECTRA (Efficiency Learning an Encoder that Classifies Token Replacements Accurately). We have conducted this work with a novel dataset comprises 44,001 comments from multitudinous Facebook posts. In this classification process, we have exhibited an average accuracy, precision, recall, and f1-score to evaluate our proposed models. The outcomes have brought a percipience of our applied BERT and ELECTRA architecture that performs notably with 85.00% and 84.92% test accuracy, respectively.",1869-5450,1869-5469,,, , ,,Gen_dataset#detection#out_but_toxicity,
4062,"Title:On augmenting topological graph representations for attributed graphs

 Graph representations based on embedding methods allow for easier analysis of the network structure and can be used for a variety of tasks, such as link prediction and node classification. These methods have been shown to be effective in a variety of settings and have become an important tool in the field of graph learning. These methods are easy to implement, and their predictions yield interpretable results. However, most graph embedding methods rely solely on graph structural information and do not consider node/edge attributes, limiting their applicability. In this paper, we propose graph-theoretic designs to incorporate node and edge attributes within the topology, enabling graph-embedding methods to seamlessly work on attributed graphs. To find ideal representation for a given attributed graph, we propose augmenting special subgraph structures within original network. We discuss the potential challenges of the proposed approach and prove some of its theoretical limitations. We test the efficacy of our approach by comparing state-of-the-art graph classification models on 15 standard bioinformatics datasets. We observe an encouraging improvement of up to 5% in classification accuracy on the augmented graphs compared to the results on the original graphs. (c) 2023 Elsevier B.V. All rights reserved.","Said, Anwar; Shabbir, Mudassir; Hassan, Saeed-Ul; Hassan, Zohair Raza; Ahmed, Ammar; Koutsoukos, Xenofon","Hassan, Saeed-Ul/G-1889-2016","Hassan, Saeed-Ul/0000-0002-6509-9190",On augmenting topological graph representations for attributed graphs,136,,10.1016/j.asoc.2023.110104 ,Article ,2023.0,"Graph representations based on embedding methods allow for easier analysis of the network structure and can be used for a variety of tasks, such as link prediction and node classification. These methods have been shown to be effective in a variety of settings and have become an important tool in the field of graph learning. These methods are easy to implement, and their predictions yield interpretable results. However, most graph embedding methods rely solely on graph structural information and do not consider node/edge attributes, limiting their applicability. In this paper, we propose graph-theoretic designs to incorporate node and edge attributes within the topology, enabling graph-embedding methods to seamlessly work on attributed graphs. To find ideal representation for a given attributed graph, we propose augmenting special subgraph structures within original network. We discuss the potential challenges of the proposed approach and prove some of its theoretical limitations. We test the efficacy of our approach by comparing state-of-the-art graph classification models on 15 standard bioinformatics datasets. We observe an encouraging improvement of up to 5% in classification accuracy on the augmented graphs compared to the results on the original graphs. (c) 2023 Elsevier B.V. All rights reserved.",1568-4946,1872-9681,,, , ,,out_of_scope,
4063,"Title:CoMFA, HQSAR and molecular docking studies of butitaxel analogues with β-tubulin

 Results from biochemical analyses for a series of 20 butitaxel analogues, paclitaxel and docetaxel were used to build two- and three-dimensional quantitative structure-activity relationship ( QSAR) models in order to investigate the properties associated with microtubule assembly and stabilization. A comparative molecular field analysis (CoMFA) model was built using steric and electrostatic fields. The CoMFA model yielded an r(2) of 0.943 and a cross-validated r(2) ( i.e. q(2)) of 0.376. Hologram quantitative structure-activity relationship (HQSAR) modeling of these same data generated an r(2) of 0.919 and a q(2) of 0.471. Contour maps used to visualize the steric and electrostatic contributions associated with activity or lack thereof were, as expected, localized to the varied position of the taxane system. Each analogue was docked successfully into a model of beta-tubulin derived from previously determined cryoelectron microscopy analyses of the tubulin alpha/beta heterodimer. All analogues superimposed well with paclitaxel bound to the protein, as well as with each other. De. ning the variable region of each structure as the ligand and docking it separately into the paclitaxel site revealed a modest correlation ( r(2) = 0.53) between activity and docking energy of all the compounds in the dataset. When only the butitaxel derivatives were considered, the correlation increased to 0.61. The mathematical models derived here provide information for the future development of taxanes.","Cunningham, SL; Cunningham, AR; Day, BW",,"Day, Billy/0000-0001-6208-9950","CoMFA, HQSAR and molecular docking studies of butitaxel analogues with β-tubulin",11,1,10.1007/s00894-004-0220-y ,Article ,2005.0,"Results from biochemical analyses for a series of 20 butitaxel analogues, paclitaxel and docetaxel were used to build two- and three-dimensional quantitative structure-activity relationship ( QSAR) models in order to investigate the properties associated with microtubule assembly and stabilization. A comparative molecular field analysis (CoMFA) model was built using steric and electrostatic fields. The CoMFA model yielded an r(2) of 0.943 and a cross-validated r(2) ( i.e. q(2)) of 0.376. Hologram quantitative structure-activity relationship (HQSAR) modeling of these same data generated an r(2) of 0.919 and a q(2) of 0.471. Contour maps used to visualize the steric and electrostatic contributions associated with activity or lack thereof were, as expected, localized to the varied position of the taxane system. Each analogue was docked successfully into a model of beta-tubulin derived from previously determined cryoelectron microscopy analyses of the tubulin alpha/beta heterodimer. All analogues superimposed well with paclitaxel bound to the protein, as well as with each other. De. ning the variable region of each structure as the ligand and docking it separately into the paclitaxel site revealed a modest correlation ( r(2) = 0.53) between activity and docking energy of all the compounds in the dataset. When only the butitaxel derivatives were considered, the correlation increased to 0.61. The mathematical models derived here provide information for the future development of taxanes.",1610-2940,0948-5023,,48-54, , ,,out_of_scope,
4064,"Title:Association between ozone and emergency department visits: an ecological study

 The objective of this study was to examine the association between the levels of ozone concentration and emergency department (ED) visits for respiratory and cardiovascular conditions in Maryland in the United States by considering temporal and spatial characteristics, including socioeconomic status (SES), as a covariate. This study used multiple large datasets derived from government agencies for data of ozone, weather, census, and ED visits to represent Maryland in the summer of 2002. Block kriging was used to estimate the daily ozone and weather factors by ZIP code-day level. Results from a negative binomial regression showed that a 10-ppb increment of the 8-hr ozone level as a three-day average was associated with increased respiratory ED visits by 2.4%, after adjusting for weather factors, SES, and day of the week. For cardiovascular ED visits, an increment of 10 ppb of the 8-hr ozone level as a five-day average increased by 3.5%.","Choi, Mona; Curriero, Frank C.; Johantgen, Meg; Mills, Mary Etta C.; Sattler, Barbara; Lipscomb, Jane","Choi, Mona/AGJ-1918-2022","Choi, Mona/0000-0003-4694-0359",Association between ozone and emergency department visits: an ecological study,21,3,10.1080/09603123.2010.533366 ,Article ,2011.0,"The objective of this study was to examine the association between the levels of ozone concentration and emergency department (ED) visits for respiratory and cardiovascular conditions in Maryland in the United States by considering temporal and spatial characteristics, including socioeconomic status (SES), as a covariate. This study used multiple large datasets derived from government agencies for data of ozone, weather, census, and ED visits to represent Maryland in the summer of 2002. Block kriging was used to estimate the daily ozone and weather factors by ZIP code-day level. Results from a negative binomial regression showed that a 10-ppb increment of the 8-hr ozone level as a three-day average was associated with increased respiratory ED visits by 2.4%, after adjusting for weather factors, SES, and day of the week. For cardiovascular ED visits, an increment of 10 ppb of the 8-hr ozone level as a five-day average increased by 3.5%.",0960-3123,1369-1619,,201-221, , ,,out_of_scope,
4065,"Title:Pathway Analysis of Smoking Quantity in Multiple GWAS Identifies Cholinergic and Sensory Pathways

 Cigarette smoking is a common addiction that increases the risk for many diseases, including lung cancer and chronic obstructive pulmonary disease. Genome-wide association studies (GWAS) have successfully identified and validated several susceptibility loci for nicotine consumption and dependence. However, the trait variance explained by these genes is only a small fraction of the estimated genetic risk. Pathway analysis complements single marker methods by including biological knowledge into the evaluation of GWAS, under the assumption that causal variants lie in functionally related genes, enabling the evaluation of a broad range of signals. Our approach to the identification of pathways enriched for multiple genes associated with smoking quantity includes the analysis of two studies and the replication of common findings in a third dataset. This study identified pathways for the cholinergic receptors, which included SNPs known to be genome-wide significant; as well as novel pathways, such as genes involved in the sensory perception of smell, that do not contain any single SNP that achieves that stringent threshold.","Harari, Oscar; Wang, Jen-Chyong; Bucholz, Kathleen; Edenberg, Howard J.; Heath, Andrew; Martin, Nicholas G.; Pergadia, Michele L.; Montgomery, Grant; Schrage, Andrew; Bierut, Laura J.; Madden, Pamela F.; Goate, Alison M.","Bucholz, Kathleen/IXD-3612-2023; Bierut, Laura Jean/W-6806-2019; Martin, Nicholas/R-9235-2019","Bucholz, Kathleen/0000-0003-3794-0736; Bierut, Laura Jean/0000-0002-9952-4810; Martin, Nicholas/0000-0003-4069-8020; Goate, Alison/0000-0002-0576-2472; Edenberg, Howard/0000-0003-0344-9690",Pathway Analysis of Smoking Quantity in Multiple GWAS Identifies Cholinergic and Sensory Pathways,7,12,10.1371/journal.pone.0050913 ,Article ,2012.0,"Cigarette smoking is a common addiction that increases the risk for many diseases, including lung cancer and chronic obstructive pulmonary disease. Genome-wide association studies (GWAS) have successfully identified and validated several susceptibility loci for nicotine consumption and dependence. However, the trait variance explained by these genes is only a small fraction of the estimated genetic risk. Pathway analysis complements single marker methods by including biological knowledge into the evaluation of GWAS, under the assumption that causal variants lie in functionally related genes, enabling the evaluation of a broad range of signals. Our approach to the identification of pathways enriched for multiple genes associated with smoking quantity includes the analysis of two studies and the replication of common findings in a third dataset. This study identified pathways for the cholinergic receptors, which included SNPs known to be genome-wide significant; as well as novel pathways, such as genes involved in the sensory perception of smell, that do not contain any single SNP that achieves that stringent threshold.",1932-6203,,,, , ,,out_of_scope,
4066,"Title:Estimation of Risk to the Eco-Environment and Human Health of Using Heavy Metals in the Uttarakhand Himalaya, India

 In the modern era, due to the rapid increase in urbanization and industrialization in the vicinity of the Himalayas, heavy metals contamination in soil has become a key priority for researchers working globally; however, evaluation of the human and ecological risks mainly in hilly areas remains limited. In this study, we analyzed indices like the contamination factor (CF), degree of contamination (DC), enrichment factor (EF), geochemical index (I-geo), pollution ecological risk index (PERI), and pollution load index (PLI), along with cancer risk (CR) and hazard indices (HI), to ascertain the eco-environmental and human risks of using heavy metals in datasets collected from 168 sampling locations in Uttarakhand, India. The evaluation calculated of I-geo, EF, and CF suggests that represented soil samples were moderately contaminated and highly augmented with Rb, while PERI (75.56) advocates a low ecological risk. Further, PLI and DC (PLI: 1.26; DC: 36.66) show a possible health risk for the native population in the vicinity of the studied catchment. The hazard index (HI) is estimated greater than 1 (HI > 1) for Cr and Mn, representing a possible risk for cancer. However, adults are free from cancer risk, and other studied elements have been reported as noncarcinogenic. This assessment gives important information to policymakers, environmentalists, and foresters for taking mitigation measures in advance to mitigate the potential future risk of soil pollution on humans, ecology, and the environment.","Kumar, Amit; Cabral-Pinto, Marina; Kumar, Munesh; Dinis, Pedro A.","Kumar, Amit/ABC-8065-2020; Kumar, Munesh/AAB-3364-2022; Pinto, Marina Cabral/AAA-6633-2022; Dinis, Pedro/D-9867-2016; Kumar, Amit/M-3541-2015","Kumar, Amit/0000-0003-1956-0174; Pinto, Marina Cabral/0000-0002-6908-1596; Dinis, Pedro/0000-0001-7558-7369; Kumar, Amit/0000-0002-6073-0860; Kumar, Munesh/0000-0002-0807-6726","Estimation of Risk to the Eco-Environment and Human Health of Using Heavy Metals in the Uttarakhand Himalaya, India",10,20,10.3390/app10207078 ,Article ,2020.0,"In the modern era, due to the rapid increase in urbanization and industrialization in the vicinity of the Himalayas, heavy metals contamination in soil has become a key priority for researchers working globally; however, evaluation of the human and ecological risks mainly in hilly areas remains limited. In this study, we analyzed indices like the contamination factor (CF), degree of contamination (DC), enrichment factor (EF), geochemical index (I-geo), pollution ecological risk index (PERI), and pollution load index (PLI), along with cancer risk (CR) and hazard indices (HI), to ascertain the eco-environmental and human risks of using heavy metals in datasets collected from 168 sampling locations in Uttarakhand, India. The evaluation calculated of I-geo, EF, and CF suggests that represented soil samples were moderately contaminated and highly augmented with Rb, while PERI (75.56) advocates a low ecological risk. Further, PLI and DC (PLI: 1.26; DC: 36.66) show a possible health risk for the native population in the vicinity of the studied catchment. The hazard index (HI) is estimated greater than 1 (HI > 1) for Cr and Mn, representing a possible risk for cancer. However, adults are free from cancer risk, and other studied elements have been reported as noncarcinogenic. This assessment gives important information to policymakers, environmentalists, and foresters for taking mitigation measures in advance to mitigate the potential future risk of soil pollution on humans, ecology, and the environment.",,2076-3417,,, , ,,out_of_scope,
4067,"Title:Semi-correlations combined with the index of ideality of correlation: a tool to build up model of mutagenic potential

 Mutagenicity is the ability of a substance to induce mutations. This hazardous ability of a substance is decisive from point of view of ecotoxicology. The number of substances, which are used for practical needs, grows every year. Consequently, methods for at least preliminary estimation of mutagenic potential of new substances are necessary. Semi-correlations are a special case of traditional correlations. These correlations can be named as correlations along two parallel lines. This kind of correlation has been tested as a tool to predict selected endpoints, which are represented by only two values: inactive/active (0/1). Here this approach is used to build up predictive models for mutagenicity of large dataset (n=3979). The so-called index of ideality of correlation (IIC) has been tested as a statistical criterion to estimate the semi-correlation. Three random splits of experimental data into the training, invisible-training, calibration, and validation sets were analyzed. Two models were built up for each split: the first model based on optimization without the IIC and the second model based on optimization where IIC is involved in the Monte Carlo optimization. The statistical characteristics of the best model (calculated with taking into account the IIC) n=969; sensitivity=0.8050; specificity=0.9069; accuracy=0.8648; Matthews's correlation coefficient=0.7196 (using IIC). Thus, the use of IIC improves the statistical quality of the binary classification models of mutagenic potentials (Ames test) of organic compounds.","Toropova, Alla P.; Toropov, Andrey A.; Veselinovic, Aleksandar M.; Veselinovic, Jovana B.; Leszczynska, Danuta; Leszczynski, Jerzy","Toropova, Alla P./F-4891-2019; Toropov, Andrey A./I-1189-2014","Toropova, Alla P./0000-0002-4194-9963; Toropov, Andrey A./0000-0001-6864-6340",Semi-correlations combined with the index of ideality of correlation: a tool to build up model of mutagenic potential,452,1-2,10.1007/s11010-018-3419-4 ,Article ,2019.0,"Mutagenicity is the ability of a substance to induce mutations. This hazardous ability of a substance is decisive from point of view of ecotoxicology. The number of substances, which are used for practical needs, grows every year. Consequently, methods for at least preliminary estimation of mutagenic potential of new substances are necessary. Semi-correlations are a special case of traditional correlations. These correlations can be named as correlations along two parallel lines. This kind of correlation has been tested as a tool to predict selected endpoints, which are represented by only two values: inactive/active (0/1). Here this approach is used to build up predictive models for mutagenicity of large dataset (n=3979). The so-called index of ideality of correlation (IIC) has been tested as a statistical criterion to estimate the semi-correlation. Three random splits of experimental data into the training, invisible-training, calibration, and validation sets were analyzed. Two models were built up for each split: the first model based on optimization without the IIC and the second model based on optimization where IIC is involved in the Monte Carlo optimization. The statistical characteristics of the best model (calculated with taking into account the IIC) n=969; sensitivity=0.8050; specificity=0.9069; accuracy=0.8648; Matthews's correlation coefficient=0.7196 (using IIC). Thus, the use of IIC improves the statistical quality of the binary classification models of mutagenic potentials (Ames test) of organic compounds.",0300-8177,1573-4919,,133-140, , ,,out_of_scope,
4068,"Title:Data mining tools for Salmonella characterization: application to gel-based fingerprinting analysis

 Background: Pulsed field gel electrophoresis (PFGE) is currently the most widely and routinely used method by the Centers for Disease Control and Prevention (CDC) and state health labs in the United States for Salmonella surveillance and outbreak tracking. Major drawbacks of commercially available PFGE analysis programs have been their difficulty in dealing with large datasets and the limited availability of analysis tools. There exists a need to develop new analytical tools for PFGE data mining in order to make full use of valuable data in large surveillance databases.Results: In this study, a software package was developed consisting of five types of bioinformatics approaches exploring and implementing for the analysis and visualization of PFGE fingerprinting. The approaches include PFGE band standardization, Salmonella serotype prediction, hierarchical cluster analysis, distance matrix analysis and two-way hierarchical cluster analysis. PFGE band standardization makes it possible for cross-group large dataset analysis. The Salmonella serotype prediction approach allows users to predict serotypes of Salmonella isolates based on their PFGE patterns. The hierarchical cluster analysis approach could be used to clarify subtypes and phylogenetic relationships among groups of PFGE patterns. The distance matrix and two-way hierarchical cluster analysis tools allow users to directly visualize the similarities/dissimilarities of any two individual patterns and the inter-and intra-serotype relationships of two or more serotypes, and provide a summary of the overall relationships between user-selected serotypes as well as the distinguishable band markers of these serotypes. The functionalities of these tools were illustrated on PFGE fingerprinting data from PulseNet of CDC.Conclusions: The bioinformatics approaches included in the software package developed in this study were integrated with the PFGE database to enhance the data mining of PFGE fingerprints. Fast and accurate prediction makes it possible to elucidate Salmonella serotype information before conventional serological methods are pursued. The development of bioinformatics tools to distinguish the PFGE markers and serotype specific patterns will enhance PFGE data retrieval, interpretation and serotype identification and will likely accelerate source tracking to identify the Salmonella isolates implicated in foodborne diseases.","Zou, Wen; Tang, Hailin; Zhao, Weizhong; Meehan, Joe; Foley, Steven L.; Lin, Wei-Jiun; Chen, Hung-Chia; Fang, Hong; Nayak, Rajesh; Chen, James J.","Wang, Xin/HZL-4695-2023; Wang, Xinhua/ISR-8520-2023","Zou, Wen/0000-0002-3735-1133; Foley, Steven/0000-0003-3146-4548; Meehan, Joe/0000-0001-9602-3394",Data mining tools for Salmonella characterization: application to gel-based fingerprinting analysis,14,,10.1186/1471-2105-14-S14-S15 ,Article; Proceedings Paper ,2013.0,"Background: Pulsed field gel electrophoresis (PFGE) is currently the most widely and routinely used method by the Centers for Disease Control and Prevention (CDC) and state health labs in the United States for Salmonella surveillance and outbreak tracking. Major drawbacks of commercially available PFGE analysis programs have been their difficulty in dealing with large datasets and the limited availability of analysis tools. There exists a need to develop new analytical tools for PFGE data mining in order to make full use of valuable data in large surveillance databases.Results: In this study, a software package was developed consisting of five types of bioinformatics approaches exploring and implementing for the analysis and visualization of PFGE fingerprinting. The approaches include PFGE band standardization, Salmonella serotype prediction, hierarchical cluster analysis, distance matrix analysis and two-way hierarchical cluster analysis. PFGE band standardization makes it possible for cross-group large dataset analysis. The Salmonella serotype prediction approach allows users to predict serotypes of Salmonella isolates based on their PFGE patterns. The hierarchical cluster analysis approach could be used to clarify subtypes and phylogenetic relationships among groups of PFGE patterns. The distance matrix and two-way hierarchical cluster analysis tools allow users to directly visualize the similarities/dissimilarities of any two individual patterns and the inter-and intra-serotype relationships of two or more serotypes, and provide a summary of the overall relationships between user-selected serotypes as well as the distinguishable band markers of these serotypes. The functionalities of these tools were illustrated on PFGE fingerprinting data from PulseNet of CDC.Conclusions: The bioinformatics approaches included in the software package developed in this study were integrated with the PFGE database to enhance the data mining of PFGE fingerprints. Fast and accurate prediction makes it possible to elucidate Salmonella serotype information before conventional serological methods are pursued. The development of bioinformatics tools to distinguish the PFGE markers and serotype specific patterns will enhance PFGE data retrieval, interpretation and serotype identification and will likely accelerate source tracking to identify the Salmonella isolates implicated in foodborne diseases.",1471-2105,,,, , 10th Annual Conference of the MidSouth-Computational-Biology-and-Bioinformatics-Society (MCBIOS) on Discovery in a Sea of Data10th Annual Conference of the MidSouth-Computational-Biology-and-Bioinformatics-Society (MCBIOS) on Discovery in a Sea of Data,,out_of_scope,
4069,"Title:A comparison between detectors of high frequency oscillations

 Objective: High frequency oscillations (HFOs) are a biomarker of epileptogenicity. Visual marking of HFOs is highly time-consuming and inevitably subjective, making automatic detection necessary. We compare four existing detectors on the same dataset.Methods: HFOs and baselines were identified by experienced reviewers in intracerebral EEGs from 20 patients. A new feature of our detector to deal with channels where baseline cannot be found is presented. The original and an optimal configuration are implemented. Receiver operator curves, false discovery rate, and channel ranking are used to evaluate performance.Results: All detectors improve performance with the optimal configuration. Our detector had higher sensitivity, lower false positives than the others, and similar false detections. The main difference in performance was in very active channels.Conclusions: Each detector was developed for different recordings and with different aims. Our detector performed better in this dataset, but was developed on data similar to the test data. Moreover, optimizing on a particular data type improves performance in any detector.Significance: Automatic HFO detection is crucial to propel their clinical use as biomarkers of epileptogenic tissue. Comparing detectors on a single dataset is important to analyze their performance and to emphasize the issues involved in validation. (C) 2011 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.","Zelmann, R.; Mari, F.; Jacobs, J.; Zijlmans, M.; Dubeau, F.; Gotman, J.","Mari, Francesco/AAB-8462-2019","Mari, Francesco/0000-0001-6914-5812; Zelmann, Rina/0000-0002-2142-7324; Zijlmans, Maeike/0000-0003-1258-5678",A comparison between detectors of high frequency oscillations,123,1,10.1016/j.clinph.2011.06.006 ,Article ,2012.0,"Objective: High frequency oscillations (HFOs) are a biomarker of epileptogenicity. Visual marking of HFOs is highly time-consuming and inevitably subjective, making automatic detection necessary. We compare four existing detectors on the same dataset.Methods: HFOs and baselines were identified by experienced reviewers in intracerebral EEGs from 20 patients. A new feature of our detector to deal with channels where baseline cannot be found is presented. The original and an optimal configuration are implemented. Receiver operator curves, false discovery rate, and channel ranking are used to evaluate performance.Results: All detectors improve performance with the optimal configuration. Our detector had higher sensitivity, lower false positives than the others, and similar false detections. The main difference in performance was in very active channels.Conclusions: Each detector was developed for different recordings and with different aims. Our detector performed better in this dataset, but was developed on data similar to the test data. Moreover, optimizing on a particular data type improves performance in any detector.Significance: Automatic HFO detection is crucial to propel their clinical use as biomarkers of epileptogenic tissue. Comparing detectors on a single dataset is important to analyze their performance and to emphasize the issues involved in validation. (C) 2011 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.",1388-2457,1872-8952,,106-116, , ,,out_of_scope,
4070,"Title:Arsenic concentration in tobacco leaves:: A study on three commercially important tobacco (Nicotiana tabacum L.) types

 In recent years, arsenic (As) has received increased attention as humans may be exposed to it through occupational and environmental exposure. Tobacco (Nicotiana tabacum L.) like other crops can uptake this element from the soil, which may lead to human exposure. Here, we report on a survey on arsenic in cured or processed tobacco leaves obtained from Africa, Asia, Europe, South and North America. A total of 1,431 leaf samples of flue-cured, burley, and Oriental tobaccos were obtained from various sampling locations during 2002 to 2004. Arsenic concentration in the samples averaged 0.4 +/- 0.6 mu g g(-1) as determined by inductively coupled plasma-mass spectrometry. Recorded values from most samples showed that concentrations of arsenic were usually found at the lower end of the distribution. Significant differences were found among tobacco types, sampling locations, and crop years. Arsenic concentrations were rather low in the majority of regions investigated, which is compatible with data from the literature. However, sample size was small and sampling geographically restricted. Our results would need to be validated with a larger dataset.","Lugon-Moulin, Nicolas; Martin, Florian; Krauss, Marc R.; Ramey, Patrice B.; Rossi, Luca",,,Arsenic concentration in tobacco leaves:: A study on three commercially important tobacco (Nicotiana tabacum L.) types,192,1-4,10.1007/s11270-008-9658-3 ,Article ,2008.0,"In recent years, arsenic (As) has received increased attention as humans may be exposed to it through occupational and environmental exposure. Tobacco (Nicotiana tabacum L.) like other crops can uptake this element from the soil, which may lead to human exposure. Here, we report on a survey on arsenic in cured or processed tobacco leaves obtained from Africa, Asia, Europe, South and North America. A total of 1,431 leaf samples of flue-cured, burley, and Oriental tobaccos were obtained from various sampling locations during 2002 to 2004. Arsenic concentration in the samples averaged 0.4 +/- 0.6 mu g g(-1) as determined by inductively coupled plasma-mass spectrometry. Recorded values from most samples showed that concentrations of arsenic were usually found at the lower end of the distribution. Significant differences were found among tobacco types, sampling locations, and crop years. Arsenic concentrations were rather low in the majority of regions investigated, which is compatible with data from the literature. However, sample size was small and sampling geographically restricted. Our results would need to be validated with a larger dataset.",0049-6979,1573-2932,,315-319, , ,,out_of_scope,
4071,"Title:Extraction, Labeling, Clustering, and Semantic Mapping of Segments From Clinical Notes

 This work is motivated by the scarcity of tools for accurate, unsupervised information extraction from unstructured clinical notes in computationally underrepresented languages, such as Czech. We introduce a stepping stone to a broad array of downstream tasks such as summarisation or integration of individual patient records, extraction of structured information for national cancer registry reporting or building of semi-structured semantic patient representations that can be used for computing patient embeddings. More specifically, we present a method for unsupervised extraction of semantically-labeled textual segments from clinical notes and test it out on a dataset of Czech breast cancer patients, provided by Masaryk Memorial Cancer Institute (the largest Czech hospital specialising exclusively in oncology). Our goal was to extract, classify (i.e. label) and cluster segments of the free-text notes that correspond to specific clinical features (e.g., family background, comorbidities or toxicities). Finally, we propose a tool for computer-assisted semantic mapping of segment types to pre-defined ontologies and validate it on a downstream task of category-specific patient similarity. The presented results demonstrate the practical relevance of the proposed approach for building more sophisticated extraction and analytical pipelines deployed on Czech clinical notes.","Zelina, Petr; Halamkova, Jana; Novacek, Vit","Zelina, Petr/JHS-8291-2023","Zelina, Petr/0009-0004-1247-522X; Novacek, Vit/0000-0003-4687-6043","Extraction, Labeling, Clustering, and Semantic Mapping of Segments From Clinical Notes",22,4,10.1109/TNB.2023.3275195 ,Article ,2023.0,"This work is motivated by the scarcity of tools for accurate, unsupervised information extraction from unstructured clinical notes in computationally underrepresented languages, such as Czech. We introduce a stepping stone to a broad array of downstream tasks such as summarisation or integration of individual patient records, extraction of structured information for national cancer registry reporting or building of semi-structured semantic patient representations that can be used for computing patient embeddings. More specifically, we present a method for unsupervised extraction of semantically-labeled textual segments from clinical notes and test it out on a dataset of Czech breast cancer patients, provided by Masaryk Memorial Cancer Institute (the largest Czech hospital specialising exclusively in oncology). Our goal was to extract, classify (i.e. label) and cluster segments of the free-text notes that correspond to specific clinical features (e.g., family background, comorbidities or toxicities). Finally, we propose a tool for computer-assisted semantic mapping of segment types to pre-defined ontologies and validate it on a downstream task of category-specific patient similarity. The presented results demonstrate the practical relevance of the proposed approach for building more sophisticated extraction and analytical pipelines deployed on Czech clinical notes.",1536-1241,1558-2639,,781-788, , ,,out_of_scope,
4072,"Title:Expert system classifier for adaptive radiation therapy in prostate cancer

 A classifier-based expert system was developed to compare delivered and planned radiation therapy in prostate cancer patients. Its aim is to automatically identify patients that can benefit from an adaptive treatment strategy. The study predominantly addresses dosimetric uncertainties and critical issues caused by motion of hollow organs. 1200 MVCT images of 38 prostate adenocarcinoma cases were analyzed. An automatic daily re-contouring of structures (i.e. rectum, bladder and femoral heads), rigid/deformable registration and dose warping was carried out to simulate dose and volume variations during therapy. Support vector machine, K-means clustering algorithms and similarity index analysis were used to create an unsupervised predictive tool to detect incorrect setup and/or morphological changes as a consequence of inadequate patient preparation due to stochastic physiological changes, supporting clinical decision-making. After training on a dataset that was considered sufficiently dosimetrically stable, the system identified two equally sized macro clusters with distinctly different volumetric and dosimetric baseline properties and defined thresholds for these two clusters. Application to the test cohort resulted in 25% of the patients located outside the two macro clusters thresholds and which were therefore suspected to be dosimetrically unstable. In these patients, over the treatment course, mean volumetric changes of 30 and 40% for rectum and bladder were detected which possibly represents values justifying adjustment of patient preparation, frequent re-planning or a plan-of-the-day strategy. Based on our research, by combining daily IGRT images with rigid/deformable registration and dose warping, it is possible to apply a machine learning approach to the clinical setting obtaining useful information for a decision regarding an individualized adaptive strategy. Especially for treatments influenced by the movement of hollow organs, this could reduce inadequate treatments and possibly reduce toxicity, thereby increasing overall RT efficacy.","Guidi, Gabriele; Maffei, Nicola; Vecchi, Claudio; Gottardi, Giovanni; Ciarmatori, Alberto; Mistretta, Grazia Maria; Mazzeo, Ercole; Giacobazzi, Patrizia; Lohr, Frank; Costi, Tiziana","Guidi, Gabriele/F-1380-2015; Mazzeo, Ercole/AAH-2182-2020; Lohr, Frank/AAC-2528-2022","Guidi, Gabriele/0000-0001-9535-9152; Lohr, Frank/0000-0003-1014-5556; Maffei, Nicola/0000-0002-7962-8612",Expert system classifier for adaptive radiation therapy in prostate cancer,40,2,10.1007/s13246-017-0535-5 ,Article ,2017.0,"A classifier-based expert system was developed to compare delivered and planned radiation therapy in prostate cancer patients. Its aim is to automatically identify patients that can benefit from an adaptive treatment strategy. The study predominantly addresses dosimetric uncertainties and critical issues caused by motion of hollow organs. 1200 MVCT images of 38 prostate adenocarcinoma cases were analyzed. An automatic daily re-contouring of structures (i.e. rectum, bladder and femoral heads), rigid/deformable registration and dose warping was carried out to simulate dose and volume variations during therapy. Support vector machine, K-means clustering algorithms and similarity index analysis were used to create an unsupervised predictive tool to detect incorrect setup and/or morphological changes as a consequence of inadequate patient preparation due to stochastic physiological changes, supporting clinical decision-making. After training on a dataset that was considered sufficiently dosimetrically stable, the system identified two equally sized macro clusters with distinctly different volumetric and dosimetric baseline properties and defined thresholds for these two clusters. Application to the test cohort resulted in 25% of the patients located outside the two macro clusters thresholds and which were therefore suspected to be dosimetrically unstable. In these patients, over the treatment course, mean volumetric changes of 30 and 40% for rectum and bladder were detected which possibly represents values justifying adjustment of patient preparation, frequent re-planning or a plan-of-the-day strategy. Based on our research, by combining daily IGRT images with rigid/deformable registration and dose warping, it is possible to apply a machine learning approach to the clinical setting obtaining useful information for a decision regarding an individualized adaptive strategy. Especially for treatments influenced by the movement of hollow organs, this could reduce inadequate treatments and possibly reduce toxicity, thereby increasing overall RT efficacy.",0158-9938,1879-5447,,337-348, , ,,out_of_scope,
4073,"Title:Software Tools for the Evaluation of Clinical Signs and Symptoms in the Medical Management of Acute Radiation Syndrome-A Five-year Experience

 A suite of software tools has been developed for dose estimation (BAT, WinFRAT) and prediction of acute health effects (WinFRAT, H-Module) using clinical symptoms and/or changes in blood cell counts. We constructed a database of 191 ARS cases using the METREPOL (n = 167) and the SEARCH-database (n = 24). The cases ranged from unexposed (RC0), to mild (RC1), moderate (RC2), severe (RC3), and lethal ARS (RC4). From 2015-2019, radiobiology students and participants of two NATO meetings predicted clinical outcomes (RC, H-ARS, and hospitalization) based on clinical symptoms. We evaluated the prediction outcomes using the same input datasets with a total of 32 teams and 94 participants. We found that: (1) unexposed (RC0) and mildly exposed individuals (RC1) could not be discriminated; (2) the severity of RC2 and RC3 were systematically overestimated, but almost all lethal cases (RC4) were correctly predicted; (3) introducing a prior education component for non-physicians significantly increased the correct predictions of RC, ARS, and hospitalization by around 10% (p<0.005) with a threefold reduction in variance and a halving of the evaluation time per case; (4) correct outcome prediction was independent of the software tools used; and (5) comparing the dose estimates generated by the teams with H-ARS severity reflected known limitations of dose alone as a surrogate for H-ARS severity. We found inexperienced personnel can use software tools to make accurate diagnostic and treatment recommendations with up to 98% accuracy. Educational training improved the quality of decision making and enabled participants lacking a medical background to perform comparably to experts.","Port, Matthias; Haupt, Julian; Ostheim, Patrick; Majewski, Matthaus; Combs, Stephanie E.; Atkinson, Mike; Abend, Michael","Port, Matthias/D-5230-2011","Port, Matthias/0000-0002-8496-5883",Software Tools for the Evaluation of Clinical Signs and Symptoms in the Medical Management of Acute Radiation Syndrome-A Five-year Experience,120,4,10.1097/HP.0000000000001353 ,Article ,2021.0,"A suite of software tools has been developed for dose estimation (BAT, WinFRAT) and prediction of acute health effects (WinFRAT, H-Module) using clinical symptoms and/or changes in blood cell counts. We constructed a database of 191 ARS cases using the METREPOL (n = 167) and the SEARCH-database (n = 24). The cases ranged from unexposed (RC0), to mild (RC1), moderate (RC2), severe (RC3), and lethal ARS (RC4). From 2015-2019, radiobiology students and participants of two NATO meetings predicted clinical outcomes (RC, H-ARS, and hospitalization) based on clinical symptoms. We evaluated the prediction outcomes using the same input datasets with a total of 32 teams and 94 participants. We found that: (1) unexposed (RC0) and mildly exposed individuals (RC1) could not be discriminated; (2) the severity of RC2 and RC3 were systematically overestimated, but almost all lethal cases (RC4) were correctly predicted; (3) introducing a prior education component for non-physicians significantly increased the correct predictions of RC, ARS, and hospitalization by around 10% (p<0.005) with a threefold reduction in variance and a halving of the evaluation time per case; (4) correct outcome prediction was independent of the software tools used; and (5) comparing the dose estimates generated by the teams with H-ARS severity reflected known limitations of dose alone as a surrogate for H-ARS severity. We found inexperienced personnel can use software tools to make accurate diagnostic and treatment recommendations with up to 98% accuracy. Educational training improved the quality of decision making and enabled participants lacking a medical background to perform comparably to experts.",0017-9078,1538-5159,,400-409, , ,,out_of_scope,
4074,"Title:Automated detection of pneumoconiosis with multilevel deep features learned from chest X-Ray radiographs

 Early detection of pneumoconiosis in X-Rays has been a challenging task that leads to high inter- and intra-reader variability. Motivated by the success of deep learning in general and medical image classification, this paper proposes an approach to automatically detect pneumoconiosis using a deep feature based binary classifier. The features are extracted from X-rays using deep transfer learning, comprising both low and high-level feature sets. For this, a CNN model pre-trained with a transfer learning from a CheXNet model was initially used to extract deep features from the X-Ray images, then the deep features were mapped to higher-dimensional feature spaces for classification using Support Vector Machine (SVM) and CNN based feature aggregation methods. In order to cross validate the proposed method, the training and testing images were randomly split into three folds before each experiment. Nine evaluation metrics were employed to compare the performance of the proposed method and state-of-the-art methods from the literature that used the same datasets. The experimental results show that the proposed framework outperformed others, achieving an accuracy of 92.68% in the automated detection of pneumoconiosis.","Devnath, Liton; Luo, Suhuai; Summons, Peter; Wang, Dadong","; Wang, Dadong/A-5173-2009","Luo, Suhuai/0000-0002-6185-6035; Wang, Dadong/0000-0003-0409-2259",Automated detection of pneumoconiosis with multilevel deep features learned from chest X-Ray radiographs,129,,10.1016/j.compbiomed.2020.104125 ,Article ,2021.0,"Early detection of pneumoconiosis in X-Rays has been a challenging task that leads to high inter- and intra-reader variability. Motivated by the success of deep learning in general and medical image classification, this paper proposes an approach to automatically detect pneumoconiosis using a deep feature based binary classifier. The features are extracted from X-rays using deep transfer learning, comprising both low and high-level feature sets. For this, a CNN model pre-trained with a transfer learning from a CheXNet model was initially used to extract deep features from the X-Ray images, then the deep features were mapped to higher-dimensional feature spaces for classification using Support Vector Machine (SVM) and CNN based feature aggregation methods. In order to cross validate the proposed method, the training and testing images were randomly split into three folds before each experiment. Nine evaluation metrics were employed to compare the performance of the proposed method and state-of-the-art methods from the literature that used the same datasets. The experimental results show that the proposed framework outperformed others, achieving an accuracy of 92.68% in the automated detection of pneumoconiosis.",0010-4825,1879-0534,,, , ,,out_of_scope,
4075,"Title:Uncorrelated linear discriminant analysis (ULDA): A powerful tool for exploration of metabolomics data

 The theory together with an algorithm for uncorrelated linear discriminant analysis (ULDA) is introduced and applied to explore metabolomics data. ULDA is a supervised method for feature extraction (FE), discriminant analysis (DA) and biomarker screening based on the Fisher criterion function. While principal component analysis (PCA) searches for directions of maximum variance in the data, ULDA seeks linearly combined variables called uncorrelated discriminant vectors (UDVs). The UDVs maximize the separation among different classes in terms of the Fisher criterion. The performance of ULDA is evaluated and compared with PCA, partial least squares discriminant analysis (PLS-DA) and target projection discriminant analysis (TP-DA) for two datasets, one simulated and one real from a metabolomic study. ULDA showed better discriminatory ability than PCA, PLS-DA and TP-DA. The shortcomings of PCA, PLS-DA and TP-DA are attributed to interference from linear correlations in data. PLS-DA and TP-DA performed successfully for the simulated data, but PLS-DA was slightly inferior to ULDA for the real data. ULDA successfully extracted optimal features for discriminant analysis and revealed potential biomarkers. Furthermore, by means of cross-validation, the classification model obtained by ULDA showed better predictive ability than PCA, PLS-DA and TP-DA. In conclusion, ULDA is a powerful tool for revealing discriminatory information in metabolomics data. (C) 2008 Elsevier B.V. All rights reserved.","Yuan, Dalin; Liang, Yizeng; Yi, Lunzhao; Xu, Qjngsong; Kvalheim, Olav M.","Xu, Qing-Song/B-1405-2010; yi, lunzhao/AAS-3256-2021; Xu, Qingsong/G-6562-2012",,Uncorrelated linear discriminant analysis (ULDA): A powerful tool for exploration of metabolomics data,93,1,10.1016/j.chemolab.2008.04.005 ,Article ,2008.0,"The theory together with an algorithm for uncorrelated linear discriminant analysis (ULDA) is introduced and applied to explore metabolomics data. ULDA is a supervised method for feature extraction (FE), discriminant analysis (DA) and biomarker screening based on the Fisher criterion function. While principal component analysis (PCA) searches for directions of maximum variance in the data, ULDA seeks linearly combined variables called uncorrelated discriminant vectors (UDVs). The UDVs maximize the separation among different classes in terms of the Fisher criterion. The performance of ULDA is evaluated and compared with PCA, partial least squares discriminant analysis (PLS-DA) and target projection discriminant analysis (TP-DA) for two datasets, one simulated and one real from a metabolomic study. ULDA showed better discriminatory ability than PCA, PLS-DA and TP-DA. The shortcomings of PCA, PLS-DA and TP-DA are attributed to interference from linear correlations in data. PLS-DA and TP-DA performed successfully for the simulated data, but PLS-DA was slightly inferior to ULDA for the real data. ULDA successfully extracted optimal features for discriminant analysis and revealed potential biomarkers. Furthermore, by means of cross-validation, the classification model obtained by ULDA showed better predictive ability than PCA, PLS-DA and TP-DA. In conclusion, ULDA is a powerful tool for revealing discriminatory information in metabolomics data. (C) 2008 Elsevier B.V. All rights reserved.",0169-7439,1873-3239,,70-79, , ,,out_of_scope,
4076,"Title:Cyanotoxin mixture models: Relating environmental variables and toxin co-occurrence to human exposure risk

 Toxic cyanobacterial blooms, often containing multiple toxins, are a serious public health issue. However, there are no known models that predict a cyanotoxin mixture (anatoxin-a, microcystin, saxitoxin). This paper presents two cyanotoxin mixture models (MIX) and compares them to two microcystin (MC) models from data collected in 2016-2017 from three recurring cyanobacterial bloom locations in Kabetogama Lake, Voyageurs National Park (Minnesota, USA). Models include those using near-real-time environmental variables (readily available) and those using additional comprehensive variables (based on laboratory analyses). Comprehensive models (R2 = 0.87 MC; R2 = 0.86 MIX) explained more variability than the environmental models (R2 = 0.58 MC; R2 = 0.57 MIX). Although neither MIX model was a better fit than the MC models, the MIX models produced no false negatives in the calibration dataset, indicating that all observations above regulatory guidelines were simulated by the MIX models. This is the first known use of Virtual Beach software for a cyanotoxin mixture model, and the methods used in this paper may be applicable to other lakes or beaches.","Christensen, Victoria G.; Stelzer, Erin A.; Eikenberry, Barbara C.; Olds, Hayley T.; LeDuc, Jaime F.; Maki, Ryan P.; Saley, Alisha M.; Norland, Jack; Khan, Eakalak",,"Norland, Jack/0000-0002-3314-5498; Khan, Eakalak/0000-0002-6729-2170",Cyanotoxin mixture models: Relating environmental variables and toxin co-occurrence to human exposure risk,415,,10.1016/j.jhazmat.2021.125560 ,Article ,2021.0,"Toxic cyanobacterial blooms, often containing multiple toxins, are a serious public health issue. However, there are no known models that predict a cyanotoxin mixture (anatoxin-a, microcystin, saxitoxin). This paper presents two cyanotoxin mixture models (MIX) and compares them to two microcystin (MC) models from data collected in 2016-2017 from three recurring cyanobacterial bloom locations in Kabetogama Lake, Voyageurs National Park (Minnesota, USA). Models include those using near-real-time environmental variables (readily available) and those using additional comprehensive variables (based on laboratory analyses). Comprehensive models (R2 = 0.87 MC; R2 = 0.86 MIX) explained more variability than the environmental models (R2 = 0.58 MC; R2 = 0.57 MIX). Although neither MIX model was a better fit than the MC models, the MIX models produced no false negatives in the calibration dataset, indicating that all observations above regulatory guidelines were simulated by the MIX models. This is the first known use of Virtual Beach software for a cyanotoxin mixture model, and the methods used in this paper may be applicable to other lakes or beaches.",0304-3894,1873-3336,,, , ,,out_of_scope,
4077,"Title:A non-invasive approach for calcium deficiency detection in pears using machine learning

 A pear is a sweet fruit that is rich in dietary fiber, antioxidants, and plant compounds. The nutritional disorder in pears is either due to deficiency of nutrients or toxicity of nutrients. The techniques to identify the nutrients deficiencies include tissue testing, soil analysis, plant analysis, and visual deficiency symptoms. The effects of alfalfa greening, black end, and cork spot are minimised by correcting the calcium nutrition in the pear tree. In this paper, a two-class decision jungle model is proposed for the recognition of calcium deficiency in pears based on a non-invasive approach. The calcium deficiency in pears makes a bumpy fruit surface and leaves yellow color on the affected area than the rest of the skin results in the greyish corky lesion. The nutrient deficiency that results in serious disorders in pears not only influences the plant but also impacts the fruit quality. The introduction of artificial intelligence in the agriculture industry has helped farmers to produce healthier fruits. The artificial intelligence provides a real-time data for the classifier that results in increasing agricultural efficiencies, better crop yields and reduce fruit production costs by facilitating the routine and most complex tasks. The two-class decision jungle model achieves an accuracy of 98% with a database of 1000 samples. The other approaches, such as Boosted decision tree, Bayes point machine, Logistic regression, Neural Network, and SVM, have an accuracy of 92.20%, 84.3%, 72.5%, 82.4%, and 72.5%, respectively for the equivalent datasets. The highest accuracy is achieved with the proposed two class decision jungle that has non-linear decision boundaries and the performance is resilient in the presence of features that consist of noise. The number of calcium-deficient and healthy pears is 500 each. The geometrical features are extracted for the development of an artificial intelligence-based model for the classification of two classes like calcium deficient and healthy pear. The extracted features are split into training, validation, and testing. For training, validation, and testing, 80%, 10% and 10% samples are used respectively. The precision level is observed to be 0.974 and test accuracy is achieved as 98.7% and the overall accuracy 98% which are better than the existing 88.2% accuracy for pears using Support Vector Machine.","Yogesh; Dubey, Ashwani Kumar; Rocha, Alvaro","Dubey, Ashwani Kumar/ABI-1337-2020","Dubey, Ashwani Kumar/0000-0003-0778-9262; , Dr Yogesh/0000-0002-0746-0558; Rocha, Alvaro/0000-0002-0750-8187",A non-invasive approach for calcium deficiency detection in pears using machine learning,,,10.1007/s00521-023-08444-w ,Article; Early Access ,,"A pear is a sweet fruit that is rich in dietary fiber, antioxidants, and plant compounds. The nutritional disorder in pears is either due to deficiency of nutrients or toxicity of nutrients. The techniques to identify the nutrients deficiencies include tissue testing, soil analysis, plant analysis, and visual deficiency symptoms. The effects of alfalfa greening, black end, and cork spot are minimised by correcting the calcium nutrition in the pear tree. In this paper, a two-class decision jungle model is proposed for the recognition of calcium deficiency in pears based on a non-invasive approach. The calcium deficiency in pears makes a bumpy fruit surface and leaves yellow color on the affected area than the rest of the skin results in the greyish corky lesion. The nutrient deficiency that results in serious disorders in pears not only influences the plant but also impacts the fruit quality. The introduction of artificial intelligence in the agriculture industry has helped farmers to produce healthier fruits. The artificial intelligence provides a real-time data for the classifier that results in increasing agricultural efficiencies, better crop yields and reduce fruit production costs by facilitating the routine and most complex tasks. The two-class decision jungle model achieves an accuracy of 98% with a database of 1000 samples. The other approaches, such as Boosted decision tree, Bayes point machine, Logistic regression, Neural Network, and SVM, have an accuracy of 92.20%, 84.3%, 72.5%, 82.4%, and 72.5%, respectively for the equivalent datasets. The highest accuracy is achieved with the proposed two class decision jungle that has non-linear decision boundaries and the performance is resilient in the presence of features that consist of noise. The number of calcium-deficient and healthy pears is 500 each. The geometrical features are extracted for the development of an artificial intelligence-based model for the classification of two classes like calcium deficient and healthy pear. The extracted features are split into training, validation, and testing. For training, validation, and testing, 80%, 10% and 10% samples are used respectively. The precision level is observed to be 0.974 and test accuracy is achieved as 98.7% and the overall accuracy 98% which are better than the existing 88.2% accuracy for pears using Support Vector Machine.",0941-0643,1433-3058,,, , ,,out_of_scope,
4078,"Title:NanoMiner - Integrative Human Transcriptomics Data Resource for Nanoparticle Research

 The potential impact of nanoparticles on the environment and on human health has attracted considerable interest worldwide. The amount of transcriptomics data, in which tissues and cell lines are exposed to nanoparticles, increases year by year. In addition to the importance of the original findings, this data can have value in broader context when combined with other previously acquired and published results. In order to facilitate the efficient usage of the data, we have developed the NanoMiner web resource (http://nanominer.cs.tut.fi/), which contains 404 human transcriptome samples exposed to various types of nanoparticles. All the samples in NanoMiner have been annotated, preprocessed and normalized using standard methods that ensure the quality of the data analyses and enable the users to utilize the database systematically across the different experimental setups and platforms. With NanoMiner it is possible to 1) search and plot the expression profiles of one or several genes of interest, 2) cluster the samples within the datasets, 3) find differentially expressed genes in various nanoparticle studies, 4) detect the nanoparticles causing differential expression of selected genes, 5) analyze enriched Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways and Gene Ontology (GO) terms for the detected genes and 6) search the expression values and differential expressions of the genes belonging to a specific KEGG pathway or Gene Ontology. In sum, NanoMiner database is a valuable collection of microarray data which can be also used as a data repository for future analyses.","Kong, Lingjia; Tuomela, Soile; Hahne, Lauri; Ahlfors, Helena; Yli-Harja, Olli; Fadeel, Bengt; Lahesmaa, Riitta; Autio, Reija","Autio, Reija/D-2037-2014","Ahlfors, Helena/0000-0002-8183-0895; Autio, Reija/0000-0002-6519-2715; Kong, Lingjia/0000-0003-1016-030X; Yli-Harja, Olli/0000-0001-8581-4414",NanoMiner - Integrative Human Transcriptomics Data Resource for Nanoparticle Research,8,7,10.1371/journal.pone.0068414 ,Article ,2013.0,"The potential impact of nanoparticles on the environment and on human health has attracted considerable interest worldwide. The amount of transcriptomics data, in which tissues and cell lines are exposed to nanoparticles, increases year by year. In addition to the importance of the original findings, this data can have value in broader context when combined with other previously acquired and published results. In order to facilitate the efficient usage of the data, we have developed the NanoMiner web resource (http://nanominer.cs.tut.fi/), which contains 404 human transcriptome samples exposed to various types of nanoparticles. All the samples in NanoMiner have been annotated, preprocessed and normalized using standard methods that ensure the quality of the data analyses and enable the users to utilize the database systematically across the different experimental setups and platforms. With NanoMiner it is possible to 1) search and plot the expression profiles of one or several genes of interest, 2) cluster the samples within the datasets, 3) find differentially expressed genes in various nanoparticle studies, 4) detect the nanoparticles causing differential expression of selected genes, 5) analyze enriched Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways and Gene Ontology (GO) terms for the detected genes and 6) search the expression values and differential expressions of the genes belonging to a specific KEGG pathway or Gene Ontology. In sum, NanoMiner database is a valuable collection of microarray data which can be also used as a data repository for future analyses.",1932-6203,,,, , ,,out_of_scope,
4079,"Title:Multimodal Spatiotemporal Deep Learning Framework to Predict Response of Breast Cancer to Neoadjuvant Systemic Therapy

 Current approaches to breast cancer therapy include neoadjuvant systemic therapy (NST). The efficacy of NST is measured by pathologic complete response (pCR). A patient who attains pCR has significantly enhanced disease-free survival progress. The accurate prediction of pCR in response to a given treatment regimen could increase the likelihood of achieving pCR and prevent toxicities caused by treatments that are not effective. Th early prediction of response to NST can increase the likelihood of survival and help with decisions regarding breast-conserving surgery. An automated NST prediction framework that is able to precisely predict which patient undergoing NST will achieve a pathological complete response (pCR) at an early stage of treatment is needed. Here, we propose an end-to-end efficient multimodal spatiotemporal deep learning framework (deep-NST) framework to predict the outcome of NST prior or at an early stage of treatment. The deep-NST model incorporates imaging data captured at different timestamps of NST regimens, a tumor's molecular data, and a patient's demographic data. The efficacy of the proposed work is validated on the publicly available ISPY-1 dataset, in terms of accuracy, area under the curve (AUC), and computational complexity. In addition, seven ablation experiments were carried out to evaluate the impact of each design module in the proposed work. The experimental results show that the proposed framework performs significantly better than other recent methods.","Verma, Monu; Abdelrahman, Leila; Collado-Mesa, Fernando; Abdel-Mottaleb, Mohamed",,"Verma, Monu/0000-0003-4962-882X",Multimodal Spatiotemporal Deep Learning Framework to Predict Response of Breast Cancer to Neoadjuvant Systemic Therapy,13,13,10.3390/diagnostics13132251 ,Article ,2023.0,"Current approaches to breast cancer therapy include neoadjuvant systemic therapy (NST). The efficacy of NST is measured by pathologic complete response (pCR). A patient who attains pCR has significantly enhanced disease-free survival progress. The accurate prediction of pCR in response to a given treatment regimen could increase the likelihood of achieving pCR and prevent toxicities caused by treatments that are not effective. Th early prediction of response to NST can increase the likelihood of survival and help with decisions regarding breast-conserving surgery. An automated NST prediction framework that is able to precisely predict which patient undergoing NST will achieve a pathological complete response (pCR) at an early stage of treatment is needed. Here, we propose an end-to-end efficient multimodal spatiotemporal deep learning framework (deep-NST) framework to predict the outcome of NST prior or at an early stage of treatment. The deep-NST model incorporates imaging data captured at different timestamps of NST regimens, a tumor's molecular data, and a patient's demographic data. The efficacy of the proposed work is validated on the publicly available ISPY-1 dataset, in terms of accuracy, area under the curve (AUC), and computational complexity. In addition, seven ablation experiments were carried out to evaluate the impact of each design module in the proposed work. The experimental results show that the proposed framework performs significantly better than other recent methods.",,2075-4418,,, , ,,out_of_scope,
4080,"Title:Early prediction of radiotherapy-induced parotid shrinkage and toxicity based on CT radiomics and fuzzy classification

 Motivation: Patients under radiotherapy for head-and-neck cancer often suffer of long-term xerostomia, and/or consistent shrinkage of parotid glands. In order to avoid these drawbacks, adaptive therapy can be planned for patients at risk, if the prediction is obtained timely, before or during the early phase of treatment. Artificial intelligence can address the problem, by learning from examples and building classification models. In particular, fuzzy logic has shown its suitability for medical applications, in order to manage uncertain data, and to build transparent rule-based classifiers.In previous works, clinical, dosimetric and image-based features were considered separately, to find different possible predictors of parotid shrinkage. On the other hand, a few works reported possible image-based predictors of xerostomia, while the combination of different types of features has been little addressed.Objective: This paper proposes the application of a novel machine learning approach, based on both statistics and fuzzy logic, aimed at the classification of patients at risk of i) parotid gland shrinkage and ii) 12-months xerostomia. Both problems are addressed with the aim of individuating predictors and models to classify respective outcomes.Methods: Knowledge is extracted from a real dataset of radiotherapy patients, by means of a recently developed method named Likelihood-Fuzzy Analysis, based on the representation of statistical information by fuzzy rule-based models. This method enables to manage heterogeneous variables and missing data, and to obtain interpretable fuzzy models presenting good generalization power (thus high performance), and to measure classification confidence.Numerous features are extracted to characterize patients, coming from different sources, i.e. clinical features, dosimetric parameters, and radiomics-based measures obtained by texture analysis of Computed Tomography images. A learning approach based on the composition of simple models in a more complicated one allows to consider the features separately, in order to identify predictors and models to use when only some data source is available, and obtaining more accurate results when more information can be combined.Results: Regarding parotid shrinkage, a number of good predictors is detected, some already known and confirmed here, and some others found here, in particular among radiomics-based features. A number of models are also designed, some using single features and others involving models composition to improve classification accuracy. In particular, the best model to be used at the initial treatment stage, and another one applicable at the half treatment stage are identified.Regarding 12-months toxicity, some possible predictors are detected, in particular among radiomics-based features. Moreover, the relation between final parotid shrinkage rate and 12-months xerostomia is evaluated.The method is compared to the naive Bayes classifier, which reveals similar results in terms of classification accuracy and best predictors.The interpretable fuzzy rule-based models are explicitly presented, and the dependence between predictors and outcome is explained, thus furnishing in some cases helpful insights about the considered problems.Conclusion: Thanks to the performance and interpretability of the fuzzy classification method employed, predictors of both parotid shrinkage and xerostomia are detected, and their influence on each outcome is revealed. Moreover, models for predicting parotid shrinkage at initial and half radiotherapy stages are found. (C) 2017 Elsevier B.V. All rights reserved.","Pota, Marco; Scalco, Elisa; Sanguineti, Giuseppe; Farneti, Alessia; Cattaneo, Giovanni Mauro; Rizzo, Giovanna; Esposito, Massimo","Esposito, Massimo/AAX-3348-2020; Scalco, Elisa/J-3619-2018; Pota, Marco/AAX-9053-2020","Scalco, Elisa/0000-0003-2721-5792; ESPOSITO, MASSIMO/0000-0002-7196-7994; RIZZO, GIOVANNA/0000-0002-6341-1304",Early prediction of radiotherapy-induced parotid shrinkage and toxicity based on CT radiomics and fuzzy classification,81,,10.1016/j.artmed.2017.03.004 ,Article; Proceedings Paper ,2017.0,"Motivation: Patients under radiotherapy for head-and-neck cancer often suffer of long-term xerostomia, and/or consistent shrinkage of parotid glands. In order to avoid these drawbacks, adaptive therapy can be planned for patients at risk, if the prediction is obtained timely, before or during the early phase of treatment. Artificial intelligence can address the problem, by learning from examples and building classification models. In particular, fuzzy logic has shown its suitability for medical applications, in order to manage uncertain data, and to build transparent rule-based classifiers.In previous works, clinical, dosimetric and image-based features were considered separately, to find different possible predictors of parotid shrinkage. On the other hand, a few works reported possible image-based predictors of xerostomia, while the combination of different types of features has been little addressed.Objective: This paper proposes the application of a novel machine learning approach, based on both statistics and fuzzy logic, aimed at the classification of patients at risk of i) parotid gland shrinkage and ii) 12-months xerostomia. Both problems are addressed with the aim of individuating predictors and models to classify respective outcomes.Methods: Knowledge is extracted from a real dataset of radiotherapy patients, by means of a recently developed method named Likelihood-Fuzzy Analysis, based on the representation of statistical information by fuzzy rule-based models. This method enables to manage heterogeneous variables and missing data, and to obtain interpretable fuzzy models presenting good generalization power (thus high performance), and to measure classification confidence.Numerous features are extracted to characterize patients, coming from different sources, i.e. clinical features, dosimetric parameters, and radiomics-based measures obtained by texture analysis of Computed Tomography images. A learning approach based on the composition of simple models in a more complicated one allows to consider the features separately, in order to identify predictors and models to use when only some data source is available, and obtaining more accurate results when more information can be combined.Results: Regarding parotid shrinkage, a number of good predictors is detected, some already known and confirmed here, and some others found here, in particular among radiomics-based features. A number of models are also designed, some using single features and others involving models composition to improve classification accuracy. In particular, the best model to be used at the initial treatment stage, and another one applicable at the half treatment stage are identified.Regarding 12-months toxicity, some possible predictors are detected, in particular among radiomics-based features. Moreover, the relation between final parotid shrinkage rate and 12-months xerostomia is evaluated.The method is compared to the naive Bayes classifier, which reveals similar results in terms of classification accuracy and best predictors.The interpretable fuzzy rule-based models are explicitly presented, and the dependence between predictors and outcome is explained, thus furnishing in some cases helpful insights about the considered problems.Conclusion: Thanks to the performance and interpretability of the fuzzy classification method employed, predictors of both parotid shrinkage and xerostomia are detected, and their influence on each outcome is revealed. Moreover, models for predicting parotid shrinkage at initial and half radiotherapy stages are found. (C) 2017 Elsevier B.V. All rights reserved.",0933-3657,1873-2860,,41-53, , 15th Conference on Artificial Intelligence in Medicine (AIME)15th Conference on Artificial Intelligence in Medicine (AIME),,out_of_scope,
4081,"181    Title:Deep Learning-Based Automated Cardiac Su...
Name: Abstract, dtype: object","Guthier, C. V.; McKenzie, E.; Zeleznik, R.; Bitterman, D. S.; Bredfeldt, J. S.; Aerts, H.; Atkins, K. M.; Mak, R. H.","Aerts, Hugo/ABF-2821-2020","Aerts, Hugo/0000-0002-2122-2003",Deep Learning-Based Automated Cardiac Sub-Structure Contouring with Dosimetric and Clinical Outcomes Validation,114,3, ,Meeting Abstract ,2022.0,"AbstractCardiac structure contouring is a time consuming and tedious manual activity used for radiotherapeutic dose toxicity planning. We developed an automatic cardiac structure segmentation pipeline for use in low-dose non-contrast planning CT based on deep learning algorithms for small datasets. Fifty CT scans were retrospectively selected and the whole heart, ventricles and atria were contoured. A two stage deep learning pipeline was trained on 41 non contrast planning CTs, tuned with 3 CT scans and validated on 6 CT scans. In the first stage, An InceptionResNetV2 network was used to identify the slices that contained cardiac structures. The second stage consisted of three deep learning models trained on the images containing cardiac structures to segment the structures. The three deep learning models predicted the segmentations/contours on axial, coronal and sagittal images and are combined to create the final prediction. The final accuracy of the pipeline was quantified on 6 volumes by calculating the Dice similarity coefficient (DC), 95% Hausdorff distance (95% HD) and volume ratios between predicted and ground truth volumes. Median DC and 95% HD of 0.96, 0.88, 0.92, 0.80 and 0.82, and 1.86, 2.98, 2.02, 6.16 and 6.46 were achieved for the whole heart, right and left ventricle, and right and left atria respectively. The median differences in volume were -4, -1, + 5, -16 and -20% for the whole heart, right and left ventricle, and right and left atria respectively. The automatic contouring pipeline achieves good results for whole heart and ventricles. Robust automatic contouring with deep learning methods seems viable for local centers with small datasets.",0360-3016,1879-355X,,S46-S47, , Annual Meeting of the American-Society-for-Radiation-Oncology (ASTRO)Annual Meeting of the American-Society-for-Radiation-Oncology (ASTRO),,out_of_scope,
4082,"Title:Greenhouse investigation on the phytoremediation potential of pioneer tree Pinus halepensis Mill. in abandoned mine site

 Tailings and mine dumps are often pollutant sources that pose serious environmental threats to surrounding areas. The use of pioneer vascular plants to extract or stabilize metals is considered among the more effective mine tailing reclamation techniques. The study aimed at evaluating the phytoremediation potential of Pinus halepensis in abandoned mine-tailing (SW-Sardinia, Italy). Plant ability to tolerate high Zn, Pb, and Cd concentration and their accumulation in roots and aerial parts were assessed at greenhouse conditions. Experiments were performed on 45 seedlings planted in different substrates (mine-tailings, mine-tailings compost-amended, and reference) and on 15 seedlings grown spontaneously in the contaminated mine site investigated with their own substrates. The phytostabilization potential of plant was evaluated through biological accumulation and translocation indexes together with plant survival and biometric parameters. The outcomes showed the adaptability of P. halepensis to grow and survive in contaminated substrates. Compost addition did not improve plant survival and growth, however, it enhanced total carbon and nitrogen contents of soil, restricted metal bioavailability, and accumulation in plant aerial parts. These findings highlight that P. halepensis may be considered for phytostabilization given the great potential to limit Zn, Pb, and Cd toxicity in plant tissues by applying compost amendment in metal contaminated mine sites.","Kharazian, Pegah; Cappai, Giovanna; Boi, Maria Enrica; Porceddu, Marco; Piredda, Martina; De Giudici, Giovanni; Bacchetta, Gianluigi",,,Greenhouse investigation on the phytoremediation potential of pioneer tree Pinus halepensis Mill. in abandoned mine site,,,10.1080/15226514.2023.2267128 ,Article; Early Access ,,"Tailings and mine dumps are often pollutant sources that pose serious environmental threats to surrounding areas. The use of pioneer vascular plants to extract or stabilize metals is considered among the more effective mine tailing reclamation techniques. The study aimed at evaluating the phytoremediation potential of Pinus halepensis in abandoned mine-tailing (SW-Sardinia, Italy). Plant ability to tolerate high Zn, Pb, and Cd concentration and their accumulation in roots and aerial parts were assessed at greenhouse conditions. Experiments were performed on 45 seedlings planted in different substrates (mine-tailings, mine-tailings compost-amended, and reference) and on 15 seedlings grown spontaneously in the contaminated mine site investigated with their own substrates. The phytostabilization potential of plant was evaluated through biological accumulation and translocation indexes together with plant survival and biometric parameters. The outcomes showed the adaptability of P. halepensis to grow and survive in contaminated substrates. Compost addition did not improve plant survival and growth, however, it enhanced total carbon and nitrogen contents of soil, restricted metal bioavailability, and accumulation in plant aerial parts. These findings highlight that P. halepensis may be considered for phytostabilization given the great potential to limit Zn, Pb, and Cd toxicity in plant tissues by applying compost amendment in metal contaminated mine sites.",1522-6514,1549-7879,,, , ,,out_of_scope,
4083,"Title:Occurrence of fumonisins in Catalonia (Spain) and an exposure assessment of specific population groups

 Fumonisin B-1 (FB1) and B-2 (FB2) are mycotoxins produced by Fusarium verticillioides and F. proliferatum and common contaminants of cereal crops. The objectives of this study were to (1) study the occurrence of fumonisins in Catalonia (north-eastern region of Spain) and (2) assess the exposure of the Catalonian population to these mycotoxins. Contamination data was provided by a wide survey where 928 individual samples were pooled to analyse 370 composite samples. Fumonisins were extracted and purified using immunoaffinity columns and determined by HPLC with fluorescence detection. The raw consumption data came from a nutritional study specifically designed to assess the dietary intake of the main foodstuffs related to fumonisin contamination for all population age groups. In addition, two specific groups were selected with respect to maize consumption: immigrants and celiac sufferers. Contamination and consumption data were combined by simulation using an essentially parametric-parametric (P-P) method. The P-P method draws sampling values from distribution functions fitted to consumption and contamination datasets. Moreover, to quantify the accuracy and reliability of the statistical estimates, we built related confidence intervals using a Pseudo-Parametric bootstrap method. The results of this study show that fumonisins are commonly found in some commodities on the Catalonian market, such as beer, corn snacks and ethnic foods; however, the values were well below the permitted maximum EU levels. The most exposed group were infants followed by immigrants but, in all cases, they were below the TDI of 2 mu g/kg bw/day.","Cano-Sancho, G.; Ramos, A. J.; Marin, S.; Sanchis, V.","Ramos, Antonio J./B-3934-2011; Marin, Sonia/G-1013-2012; Marín, Sonia/B-8295-2011; sanchis, vicente/B-3752-2011","Ramos, Antonio J./0000-0002-2830-8299; Marin, Sonia/0000-0002-0714-6155; Marín, Sonia/0000-0002-0714-6155; sanchis, vicente/0000-0001-9889-8098; Cano-Sancho, German/0000-0003-4111-4007",Occurrence of fumonisins in Catalonia (Spain) and an exposure assessment of specific population groups,29,5,10.1080/19440049.2011.644813 ,Article ,2012.0,"Fumonisin B-1 (FB1) and B-2 (FB2) are mycotoxins produced by Fusarium verticillioides and F. proliferatum and common contaminants of cereal crops. The objectives of this study were to (1) study the occurrence of fumonisins in Catalonia (north-eastern region of Spain) and (2) assess the exposure of the Catalonian population to these mycotoxins. Contamination data was provided by a wide survey where 928 individual samples were pooled to analyse 370 composite samples. Fumonisins were extracted and purified using immunoaffinity columns and determined by HPLC with fluorescence detection. The raw consumption data came from a nutritional study specifically designed to assess the dietary intake of the main foodstuffs related to fumonisin contamination for all population age groups. In addition, two specific groups were selected with respect to maize consumption: immigrants and celiac sufferers. Contamination and consumption data were combined by simulation using an essentially parametric-parametric (P-P) method. The P-P method draws sampling values from distribution functions fitted to consumption and contamination datasets. Moreover, to quantify the accuracy and reliability of the statistical estimates, we built related confidence intervals using a Pseudo-Parametric bootstrap method. The results of this study show that fumonisins are commonly found in some commodities on the Catalonian market, such as beer, corn snacks and ethnic foods; however, the values were well below the permitted maximum EU levels. The most exposed group were infants followed by immigrants but, in all cases, they were below the TDI of 2 mu g/kg bw/day.",1944-0049,1944-0057,,799-808, , ,,out_of_scope,
4084,"Title:Radiomic and radiogenomic modeling for radiotherapy: strategies, pitfalls, and challenges

 The power of predictive modeling for radiotherapy outcomes has historically been limited by an inability to adequately capture patient-specific variabilities; however, next-generation platforms together with imaging technologies and powerful bioinformatic tools have facilitated strategies and provided optimism. Integrating clinical, biological, imaging, and treatment-specific data for more accurate prediction of tumor control probabilities or risk of radiation-induced side effects are high-dimensional problems whose solutions could have wide-spread benefits to a diverse patient population-we discuss technical approaches toward this objective. Increasing interest in the above is specifically reflected by the emergence of two nascent fields, which are distinct but complementary: radiogenomics, which broadly seeks to integrate biological risk factors together with treatment and diagnostic information to generate individualized patient risk profiles, and radiomics, which further leverages large-scale imaging correlates and extracted features for the same purpose. We review classical analytical and data-driven approaches for outcomes prediction that serve as antecedents to both radiomic and radiogenomic strategies. Discussion then focuses on uses of conventional and deep machine learning in radiomics. We further consider promising strategies for the harmonization of high-dimensional, heterogeneous multiomics datasets (panomics) and techniques for nonparametric validation of best-fit models. Strategies to overcome common pitfalls that are unique to data-intensive radiomics are also discussed. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.","Coates, James T. T.; Pirovano, Giacomo; El Naqa, Issam",,"Pirovano, Giacomo/0000-0001-8862-3613; Coates, James/0000-0002-4908-0975","Radiomic and radiogenomic modeling for radiotherapy: strategies, pitfalls, and challenges",8,3,10.1117/1.JMI.8.3.031902 ,Review ,2021.0,"The power of predictive modeling for radiotherapy outcomes has historically been limited by an inability to adequately capture patient-specific variabilities; however, next-generation platforms together with imaging technologies and powerful bioinformatic tools have facilitated strategies and provided optimism. Integrating clinical, biological, imaging, and treatment-specific data for more accurate prediction of tumor control probabilities or risk of radiation-induced side effects are high-dimensional problems whose solutions could have wide-spread benefits to a diverse patient population-we discuss technical approaches toward this objective. Increasing interest in the above is specifically reflected by the emergence of two nascent fields, which are distinct but complementary: radiogenomics, which broadly seeks to integrate biological risk factors together with treatment and diagnostic information to generate individualized patient risk profiles, and radiomics, which further leverages large-scale imaging correlates and extracted features for the same purpose. We review classical analytical and data-driven approaches for outcomes prediction that serve as antecedents to both radiomic and radiogenomic strategies. Discussion then focuses on uses of conventional and deep machine learning in radiomics. We further consider promising strategies for the harmonization of high-dimensional, heterogeneous multiomics datasets (panomics) and techniques for nonparametric validation of best-fit models. Strategies to overcome common pitfalls that are unique to data-intensive radiomics are also discussed. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.",2329-4302,2329-4310,,, , ,,out_of_scope,
4085,"Title:Combined molecular docking and QSAR study of fused heterocyclic herbicide inhibitors of D1 protein in photosystem II of plants

 Cinnoline, pyridine, pyrimidine, and triazine herbicides were found be inhibitors of the D1 protein in photosystem II (D1 PSII) electron transport of plants. The photosystem II inhibitory activity of these herbicides, expressed by experimental values, was modeled by a docking and quantitative structure-activity relationships study. A conformer ensemble for each of the herbicide structure was generated using the MMFF94s force field. These conformers were further employed in a docking approach, which provided new information about the rational active conformations and various interaction patterns of the herbicide derivatives with D1 PSII. The most active conformers from the docking study were used to calculate structural descriptors, which were further related to the inhibitory experimental values by multiple linear regression (MLR). The dataset was divided into training and test sets according to the partition around medoids approach, taking 27% of the compounds from the entire series for the test set. Variable selection was performed using the genetic algorithm, and several criteria were checked for model performance. WHIM and GETAWAY geometrical descriptors (position of substituents and moieties in the molecular space) were found to contribute to the herbicidal activity. The derived MLR model is statistically significant, shows very good stability and was used to predict the herbicidal activity of new derivatives having cinnoline, indeno[1.2-c]cinnoline-ll-one, triazolo[1,5-a] pyridine, imidazo[1,2-a]pyridine, triazine and triazolo[1,5-a] pyrimidine scaffolds whose experimental inhibitory activity against D1 PSII had not been determined up to now.","Funar-Timofei, Simona; Borota, Ana; Crisan, Luminita","Crisan, Luminita Elena/P-1208-2014; FUNAR-TIMOFEI, SIMONA/C-3369-2011; Borota, Ana/AFL-9809-2022","Crisan, Luminita Elena/0000-0001-7148-5701; FUNAR-TIMOFEI, SIMONA/0000-0002-6786-6584; Borota, Ana/0000-0003-1138-8357",Combined molecular docking and QSAR study of fused heterocyclic herbicide inhibitors of D1 protein in photosystem II of plants,21,2,10.1007/s11030-017-9735-x ,Article ,2017.0,"Cinnoline, pyridine, pyrimidine, and triazine herbicides were found be inhibitors of the D1 protein in photosystem II (D1 PSII) electron transport of plants. The photosystem II inhibitory activity of these herbicides, expressed by experimental values, was modeled by a docking and quantitative structure-activity relationships study. A conformer ensemble for each of the herbicide structure was generated using the MMFF94s force field. These conformers were further employed in a docking approach, which provided new information about the rational active conformations and various interaction patterns of the herbicide derivatives with D1 PSII. The most active conformers from the docking study were used to calculate structural descriptors, which were further related to the inhibitory experimental values by multiple linear regression (MLR). The dataset was divided into training and test sets according to the partition around medoids approach, taking 27% of the compounds from the entire series for the test set. Variable selection was performed using the genetic algorithm, and several criteria were checked for model performance. WHIM and GETAWAY geometrical descriptors (position of substituents and moieties in the molecular space) were found to contribute to the herbicidal activity. The derived MLR model is statistically significant, shows very good stability and was used to predict the herbicidal activity of new derivatives having cinnoline, indeno[1.2-c]cinnoline-ll-one, triazolo[1,5-a] pyridine, imidazo[1,2-a]pyridine, triazine and triazolo[1,5-a] pyrimidine scaffolds whose experimental inhibitory activity against D1 PSII had not been determined up to now.",1381-1991,1573-501X,,437-454, , ,,out_of_scope,
4086,"Title:Development of a QSAR model to predict comedogenic potential of some cosmetic ingredients

 Comedogenicity is a common adverse reaction to cosmetic ingredients that cause blackheads or pimples by blocking the pores, especially for acne-prone skin. Before animal testing was banned by European Commission in 2013, comedogenic potential of cosmetics were tested on rabbits. However, full replacement of animal tests by alternatives has not been possible yet. Therefore, there is a need for applying new approach methodologies. In this study, we aimed to develop a QSAR model to predict comedogenic potential of cosmetic ingredients by using different machine learning algorithms and types of molecular descriptors. The dataset consists of 121 cosmetic ingredients including such as fatty acids, fatty alcohols and their de-rivatives and pigments tested on rabbit ears was obtained from the literature. 4837 molecular descriptors were calculated via various software. Different machine learning classification algorithms were used in the modelling studies with WEKA software. The model performance was evaluated by using 10-fold cross validation. All models were compared by the means of classification accuracy, area under the ROC curve, area under the precision-recall curve, MCC, F score, kappa statistic, sensitivity, specificity and the best model was chosen accordingly. The QSAR modelling results for two models are promising for comedogenicity prediction. The random forest models by the means of Mold2 and alvaDesc descriptors gave the successful results with 85.87% and 84.87% accuracy for the cross-validated models and 75.86% and 79.31% accuracy for the test sets. In conclusion, this study is the first step in terms of comedogenicity prediction. In the near future, advances in in silico modelling studies will provide us non-animal based alternative models by regarding animal rights and ethical issues for the safety evaluation of cosmetics.","Akturk, Sebla Oztan; Tugcu, Gulcin; Sipahi, Hande",,"Tugcu, Gulcin/0000-0002-9750-6563",Development of a QSAR model to predict comedogenic potential of some cosmetic ingredients,21,,10.1016/j.comtox.2021.100207 ,Article ,2022.0,"Comedogenicity is a common adverse reaction to cosmetic ingredients that cause blackheads or pimples by blocking the pores, especially for acne-prone skin. Before animal testing was banned by European Commission in 2013, comedogenic potential of cosmetics were tested on rabbits. However, full replacement of animal tests by alternatives has not been possible yet. Therefore, there is a need for applying new approach methodologies. In this study, we aimed to develop a QSAR model to predict comedogenic potential of cosmetic ingredients by using different machine learning algorithms and types of molecular descriptors. The dataset consists of 121 cosmetic ingredients including such as fatty acids, fatty alcohols and their de-rivatives and pigments tested on rabbit ears was obtained from the literature. 4837 molecular descriptors were calculated via various software. Different machine learning classification algorithms were used in the modelling studies with WEKA software. The model performance was evaluated by using 10-fold cross validation. All models were compared by the means of classification accuracy, area under the ROC curve, area under the precision-recall curve, MCC, F score, kappa statistic, sensitivity, specificity and the best model was chosen accordingly. The QSAR modelling results for two models are promising for comedogenicity prediction. The random forest models by the means of Mold2 and alvaDesc descriptors gave the successful results with 85.87% and 84.87% accuracy for the cross-validated models and 75.86% and 79.31% accuracy for the test sets. In conclusion, this study is the first step in terms of comedogenicity prediction. In the near future, advances in in silico modelling studies will provide us non-animal based alternative models by regarding animal rights and ethical issues for the safety evaluation of cosmetics.",2468-1113,,,, , ,,out_of_scope,
4087,"Title:An IoT-Based Data-Driven Real-Time Monitoring System for Control of Heavy Metals to Ensure Optimal Lettuce Growth in Hydroponic Set-Ups

 Heavy metal concentrations that must be maintained in aquaponic environments for plant growth have been a source of concern for many decades, as they cannot be completely eliminated in a commercial set-up. Our goal was to create a low-cost real-time smart sensing and actuation system for controlling heavy metal concentrations in aquaponic solutions. Our solution entails sensing the nutrient concentrations in the hydroponic solution, specifically calcium, sulfate, and phosphate, and sending them to a Machine Learning (ML) model hosted on an Android application. The ML algorithm used in this case was a Linear Support Vector Machine (Linear-SVM) trained on top three nutrient predictors chosen after applying a pipeline of Feature Selection methods namely a pairwise correlation matrix, ExtraTreesClassifier and Xgboost classifier on a dataset recorded from three aquaponic farms from South-East Texas. The ML algorithm was then hosted on a cloud platform which would then output the maximum tolerable levels of iron, copper and zinc in real time using the concentration of phosphorus, calcium and sulfur as inputs and would be controlled using an array of dispensing and detecting equipments in a closed loop system.","Dhal, Sambandh Bhusan; Mahanta, Shikhadri; Gumero, Jonathan; O'Sullivan, Nick; Soetan, Morayo; Louis, Julia; Gadepally, Krishna Chaitanya; Mahanta, Snehadri; Lusher, John; Kalafatis, Stavros","Dhal, Sambandh/HLG-3042-2023","Dhal, Sambandh/0000-0002-9115-4042; Mahanta, Shikhadri/0000-0001-9363-4245",An IoT-Based Data-Driven Real-Time Monitoring System for Control of Heavy Metals to Ensure Optimal Lettuce Growth in Hydroponic Set-Ups,23,1,10.3390/s23010451 ,Article ,2023.0,"Heavy metal concentrations that must be maintained in aquaponic environments for plant growth have been a source of concern for many decades, as they cannot be completely eliminated in a commercial set-up. Our goal was to create a low-cost real-time smart sensing and actuation system for controlling heavy metal concentrations in aquaponic solutions. Our solution entails sensing the nutrient concentrations in the hydroponic solution, specifically calcium, sulfate, and phosphate, and sending them to a Machine Learning (ML) model hosted on an Android application. The ML algorithm used in this case was a Linear Support Vector Machine (Linear-SVM) trained on top three nutrient predictors chosen after applying a pipeline of Feature Selection methods namely a pairwise correlation matrix, ExtraTreesClassifier and Xgboost classifier on a dataset recorded from three aquaponic farms from South-East Texas. The ML algorithm was then hosted on a cloud platform which would then output the maximum tolerable levels of iron, copper and zinc in real time using the concentration of phosphorus, calcium and sulfur as inputs and would be controlled using an array of dispensing and detecting equipments in a closed loop system.",,1424-8220,,, , ,,out_of_scope,
4088,"Title:An analecta of visualizations for foodborne illness trends and seasonality

 Disease surveillance systems worldwide face increasing pressure to maintain and distribute data in usable formats supplemented with effective visualizations to enable actionable policy and programming responses. Annual reports and interactive portals provide access to surveillance data and visualizations depicting temporal trends and seasonal patterns of diseases. Analyses and visuals are typically limited to reporting the annual time series and the month with the highest number of cases per year. Yet, detecting potential disease outbreaks and supporting public health interventions requires detailed spatiotemporal comparisons to characterize spatiotemporal patterns of illness across diseases and locations. The Centers for Disease Control and Prevention's (CDC) FoodNet Fast provides population-based foodborne-disease surveillance records and visualizations for select counties across the US. We offer suggestions on how current FoodNet Fast data organization and visual analytics can be improved to facilitate data interpretation, decision-making, and communication of features related to trend and seasonality. The resulting compilation, or analecta, of 436 visualizations of records and codes are openly available online.","Simpson, Ryan B.; Zhou, Bingjie; Alarcon Falconi, Tania M.; Naumova, Elena N.","Naumova, Elena/AAP-3395-2020","Naumova, Elena/0000-0002-9562-4734; Alarcon Falconi, Tania/0000-0002-8229-1491; Simpson, Ryan Benner/0000-0002-1375-5387",An analecta of visualizations for foodborne illness trends and seasonality,7,1,10.1038/s41597-020-00677-x ,Article; Data Paper ,2020.0,"Disease surveillance systems worldwide face increasing pressure to maintain and distribute data in usable formats supplemented with effective visualizations to enable actionable policy and programming responses. Annual reports and interactive portals provide access to surveillance data and visualizations depicting temporal trends and seasonal patterns of diseases. Analyses and visuals are typically limited to reporting the annual time series and the month with the highest number of cases per year. Yet, detecting potential disease outbreaks and supporting public health interventions requires detailed spatiotemporal comparisons to characterize spatiotemporal patterns of illness across diseases and locations. The Centers for Disease Control and Prevention's (CDC) FoodNet Fast provides population-based foodborne-disease surveillance records and visualizations for select counties across the US. We offer suggestions on how current FoodNet Fast data organization and visual analytics can be improved to facilitate data interpretation, decision-making, and communication of features related to trend and seasonality. The resulting compilation, or analecta, of 436 visualizations of records and codes are openly available online.",,2052-4463,,, , ,,out_of_scope,
4089,"Title:An Integrated Gaussian Graphical Model to evaluate the impact of exposures on metabolic networks

 Examining the effects of exogenous exposures on complex metabolic processes poses the unique challenge of identifying interactions among a large number of metabolites. Recent progress in the quantification of the metabolome through mass spectrometry (MS) and nuclear magnetic resonance (NMR) has given rise to high-dimensional biomedical data of specific metabolites that can be leveraged to study their effects in humans. These metabolic interactions can be evaluated using probabilistic graphical models (PGMs), which define conditional dependence and independence between components within and between heterogeneous biomedical datasets. This method allows for the detection and recovery of valuable but latent information that cannot be easily detected by other currently existing methods. Here, we develop a PGM method, referred to as an Integrated Gaussian Graphical Model (IGGM), to incorporate exposure concentrations of seven trace elements arsenic (As), lead (Pb), mercury (Hg), cadmium (Cd), zinc (Zn), selenium (Se) and copper (Cu into metabolic networks. We first conducted a simulation study demonstrating that the integration of trace elements into metabolomics data can improve the accuracy of detecting latent interactions of metabolites impacted by exposure in the network. We tested parameters such as sample size and the number of neighboring metabolites of a chosen trace element for their impact on the accuracy of detecting metabolite interactions. We then applied this method to measurements of cord blood plasma metabolites and placental trace elements collected from newborns in the New Hampshire Birth Cohort Study (NHBCS). We found that our approach can identify latent interactions among metabolites that are related to trace element concentrations. Application to similarly structured data may contribute to our understanding of the complex interplay between exposure-related metabolic interactions that are important for human health.","Lee, Jai Woo; Moen, Erika L.; Punshon, Tracy; Hoen, Anne G.; Stewart, Delisha; Li, Hongzhe; Karagas, Margaret R.; Gui, Jiang","Hoen, Anne G/E-7493-2011","Lee, Jai Woo/0000-0002-4385-2831; Moen, Erika/0000-0002-9800-8742",An Integrated Gaussian Graphical Model to evaluate the impact of exposures on metabolic networks,114,,10.1016/j.compbiomed.2019.103417 ,Article ,2019.0,"Examining the effects of exogenous exposures on complex metabolic processes poses the unique challenge of identifying interactions among a large number of metabolites. Recent progress in the quantification of the metabolome through mass spectrometry (MS) and nuclear magnetic resonance (NMR) has given rise to high-dimensional biomedical data of specific metabolites that can be leveraged to study their effects in humans. These metabolic interactions can be evaluated using probabilistic graphical models (PGMs), which define conditional dependence and independence between components within and between heterogeneous biomedical datasets. This method allows for the detection and recovery of valuable but latent information that cannot be easily detected by other currently existing methods. Here, we develop a PGM method, referred to as an Integrated Gaussian Graphical Model (IGGM), to incorporate exposure concentrations of seven trace elements arsenic (As), lead (Pb), mercury (Hg), cadmium (Cd), zinc (Zn), selenium (Se) and copper (Cu into metabolic networks. We first conducted a simulation study demonstrating that the integration of trace elements into metabolomics data can improve the accuracy of detecting latent interactions of metabolites impacted by exposure in the network. We tested parameters such as sample size and the number of neighboring metabolites of a chosen trace element for their impact on the accuracy of detecting metabolite interactions. We then applied this method to measurements of cord blood plasma metabolites and placental trace elements collected from newborns in the New Hampshire Birth Cohort Study (NHBCS). We found that our approach can identify latent interactions among metabolites that are related to trace element concentrations. Application to similarly structured data may contribute to our understanding of the complex interplay between exposure-related metabolic interactions that are important for human health.",0010-4825,1879-0534,,, , ,,out_of_scope,
4090,"Title:Computational prediction of the bioactivity potential of proteomes based on expert knowledge

 Advances in the field of genome sequencing have enabled a comprehensive analysis and annotation of the dynamics of the protein inventory of cells. This has been proven particularly rewarding for microbial cells, for which the majority of proteins are already accessible to analysis through automatic metagenome annotation. The large-scale in silico screening of proteomes and metaproteomes is key to uncover bioactivities of translational, clinical and biotechnological interest, and to help assign functions to certain proteins, such as those predicted as hypothetical. This work introduces a new method for the prediction of the bioactivity potential of proteomes/ metaproteomes, supporting the discovery of functionally relevant proteins based on prior knowledge. This methodology complements functional annotation enrichment methods by allowing the assignment of functions to proteins annotated as hypothetical/putative/uncharacterised, as well as and enabling the detection of specific bioactivities and the recovery of proteins from defined taxa.This work shows how the new method can be applied to screen proteome and metaproteome sets to obtain predictions of clinical or biotechnological interest based on reference datasets. Notably, with this methodology, the large information files obtained after DNA sequencing or protein identification experiments can be associated for translational purposes that, in cases such as antibiotic-resistance pathogens or foodborne diseases, may represent changes in how these important and global health burdens are approached in the clinical practice.Finally, the Sequence-based Expert-driven pRoteome bioactivity Prediction EnvironmENT, a public Web service implemented in Scala functional programming style, is introduced as means to ensure broad access to the method as well as to discuss main implementation issues, such as modularity, extensibility and interoperability.","Blanco-Miguez, Aitor; Blanco, Guillermo; Gutierrez-Jacome, Alberto; Fdez-Riverola, Florentino; Sanchez, Borja; Lourenco, Analia","Blanco-Míguez, Aitor/AAN-2149-2020; Lourenço, Anália/G-8879-2013; Fdez-Riverola, Florentino/G-1411-2011; Lourenço, Anália/Y-9447-2019; González, Guillermo Blanco/Z-5276-2019","Blanco-Míguez, Aitor/0000-0001-7386-5572; Lourenço, Anália/0000-0001-8401-5362; Fdez-Riverola, Florentino/0000-0002-3943-8013; Lourenço, Anália/0000-0001-8401-5362; González, Guillermo Blanco/0000-0003-1449-3697; , IIS Galicia Sur/0000-0003-3812-7413",Computational prediction of the bioactivity potential of proteomes based on expert knowledge,91,,10.1016/j.jbi.2019.103121 ,Article ,2019.0,"Advances in the field of genome sequencing have enabled a comprehensive analysis and annotation of the dynamics of the protein inventory of cells. This has been proven particularly rewarding for microbial cells, for which the majority of proteins are already accessible to analysis through automatic metagenome annotation. The large-scale in silico screening of proteomes and metaproteomes is key to uncover bioactivities of translational, clinical and biotechnological interest, and to help assign functions to certain proteins, such as those predicted as hypothetical. This work introduces a new method for the prediction of the bioactivity potential of proteomes/ metaproteomes, supporting the discovery of functionally relevant proteins based on prior knowledge. This methodology complements functional annotation enrichment methods by allowing the assignment of functions to proteins annotated as hypothetical/putative/uncharacterised, as well as and enabling the detection of specific bioactivities and the recovery of proteins from defined taxa.This work shows how the new method can be applied to screen proteome and metaproteome sets to obtain predictions of clinical or biotechnological interest based on reference datasets. Notably, with this methodology, the large information files obtained after DNA sequencing or protein identification experiments can be associated for translational purposes that, in cases such as antibiotic-resistance pathogens or foodborne diseases, may represent changes in how these important and global health burdens are approached in the clinical practice.Finally, the Sequence-based Expert-driven pRoteome bioactivity Prediction EnvironmENT, a public Web service implemented in Scala functional programming style, is introduced as means to ensure broad access to the method as well as to discuss main implementation issues, such as modularity, extensibility and interoperability.",1532-0464,1532-0480,,, , ,,out_of_scope,
4091,"Title:An artificial intelligence model to identify snakes from across the world: Opportunities and challenges for global health and herpetology

 BackgroundSnakebite envenoming is a neglected tropical disease that kills an estimated 81,000 to 138,000 people and disables another 400,000 globally every year. The World Health Organization aims to halve this burden by 2030. To achieve this ambitious goal, we need to close the data gap in snake ecology and snakebite epidemiology and give healthcare providers up-to-date knowledge and access to better diagnostic tools. An essential first step is to improve the capacity to identify biting snakes taxonomically. The existence of AI-based identification tools for other animals offers an innovative opportunity to apply machine learning to snake identification and snakebite envenoming, a life-threatening situation.MethodologyWe developed an AI model based on Vision Transformer, a recent neural network architecture, and a comprehensive snake photo dataset of 386,006 training photos covering 198 venomous and 574 non-venomous snake species from 188 countries. We gathered photos from online biodiversity platforms (iNaturalist and HerpMapper) and a photo-sharing site (Flickr).Principal findingsThe model macro-averaged F1 score, which reflects the species-wise performance as averaging performance for each species, is 92.2%. The accuracy on a species and genus level is 96.0% and 99.0%, respectively. The average accuracy per country is 94.2%. The model accurately classifies selected venomous and non-venomous lookalike species from Southeast Asia and sub-Saharan Africa.ConclusionsTo our knowledge, this model's taxonomic and geographic coverage and performance are unprecedented. This model could provide high-speed and low-cost snake identification to support snakebite victims and healthcare providers in low-resource settings, as well as zoologists, conservationists, and nature lovers from across the world.","Bolon, Isabelle; Picek, Lukas; Durso, Andrew M.; Alcoba, Gabriel; Chappuis, Francois; de Castaneda, Rafael Ruiz","Picek, Lukáš/HLX-8615-2023; Durso, Andrew/D-1657-2012","Picek, Lukáš/0000-0002-6041-9722; Durso, Andrew/0000-0002-3008-7763; Bolon, Isabelle/0000-0001-5940-2731",An artificial intelligence model to identify snakes from across the world: Opportunities and challenges for global health and herpetology,16,8,10.1371/journal.pntd.0010647 ,Article ,2022.0,"BackgroundSnakebite envenoming is a neglected tropical disease that kills an estimated 81,000 to 138,000 people and disables another 400,000 globally every year. The World Health Organization aims to halve this burden by 2030. To achieve this ambitious goal, we need to close the data gap in snake ecology and snakebite epidemiology and give healthcare providers up-to-date knowledge and access to better diagnostic tools. An essential first step is to improve the capacity to identify biting snakes taxonomically. The existence of AI-based identification tools for other animals offers an innovative opportunity to apply machine learning to snake identification and snakebite envenoming, a life-threatening situation.MethodologyWe developed an AI model based on Vision Transformer, a recent neural network architecture, and a comprehensive snake photo dataset of 386,006 training photos covering 198 venomous and 574 non-venomous snake species from 188 countries. We gathered photos from online biodiversity platforms (iNaturalist and HerpMapper) and a photo-sharing site (Flickr).Principal findingsThe model macro-averaged F1 score, which reflects the species-wise performance as averaging performance for each species, is 92.2%. The accuracy on a species and genus level is 96.0% and 99.0%, respectively. The average accuracy per country is 94.2%. The model accurately classifies selected venomous and non-venomous lookalike species from Southeast Asia and sub-Saharan Africa.ConclusionsTo our knowledge, this model's taxonomic and geographic coverage and performance are unprecedented. This model could provide high-speed and low-cost snake identification to support snakebite victims and healthcare providers in low-resource settings, as well as zoologists, conservationists, and nature lovers from across the world.",1935-2735,,,, , ,,out_of_scope,
4092,"Title:Intensity-based hierarchical Bayes method improves testing for differentially expressed genes in microarray experiments

 Background: The small sample sizes often used for microarray experiments result in poor estimates of variance if each gene is considered independently. Yet accurately estimating variability of gene expression measurements in microarray experiments is essential for correctly identifying differentially expressed genes. Several recently developed methods for testing differential expression of genes utilize hierarchical Bayesian models to pool information from multiple genes. We have developed a statistical testing procedure that further improves upon current methods by incorporating the well-documented relationship between the absolute gene expression level and the variance of gene expression measurements into the general empirical Bayes framework.Results: We present a novel Bayesian moderated-T, which we show to perform favorably in simulations, with two real, dual-channel microarray experiments and in two controlled single-channel experiments. In simulations, the new method achieved greater power while correctly estimating the true proportion of false positives, and in the analysis of two publicly-available spike-in experiments, the new method performed favorably compared to all tested alternatives. We also applied our method to two experimental datasets and discuss the additional biological insights as revealed by our method in contrast to the others. The R-source code for implementing our algorithm is freely available at http://eh3.uc.edu/ibmt.Conclusion: We use a Bayesian hierarchical normal model to define a novel Intensity-Based Moderated T-statistic (IBMT). The method is completely data-dependent using empirical Bayes philosophy to estimate hyperparameters, and thus does not require specification of any free parameters. IBMT has the strength of balancing two important factors in the analysis of microarray data: the degree of independence of variances relative to the degree of identity (i.e. t-tests vs. equal variance assumption), and the relationship between variance and signal intensity. When this variance-intensity relationship is weak or does not exist, IBMT reduces to a previously described moderated t-statistic. Furthermore, our method may be directly applied to any array platform and experimental design. Together, these properties show IBMT to be a valuable option in the analysis of virtually any microarray experiment.","Sartor, Maureen A.; Tomlinson, Craig R.; Wesselkamper, Scott C.; Sivaganesan, Siva; Leikauf, George D.; Medvedovic, Mario","Tomlinson, Craig R./F-1319-2017; Sartor, Maureen/L-2902-2019","Tomlinson, Craig/0000-0003-0923-1449; Leikauf, George/0000-0002-4514-7060",Intensity-based hierarchical Bayes method improves testing for differentially expressed genes in microarray experiments,7,,10.1186/1471-2105-7-538 ,Article ,2006.0,"Background: The small sample sizes often used for microarray experiments result in poor estimates of variance if each gene is considered independently. Yet accurately estimating variability of gene expression measurements in microarray experiments is essential for correctly identifying differentially expressed genes. Several recently developed methods for testing differential expression of genes utilize hierarchical Bayesian models to pool information from multiple genes. We have developed a statistical testing procedure that further improves upon current methods by incorporating the well-documented relationship between the absolute gene expression level and the variance of gene expression measurements into the general empirical Bayes framework.Results: We present a novel Bayesian moderated-T, which we show to perform favorably in simulations, with two real, dual-channel microarray experiments and in two controlled single-channel experiments. In simulations, the new method achieved greater power while correctly estimating the true proportion of false positives, and in the analysis of two publicly-available spike-in experiments, the new method performed favorably compared to all tested alternatives. We also applied our method to two experimental datasets and discuss the additional biological insights as revealed by our method in contrast to the others. The R-source code for implementing our algorithm is freely available at http://eh3.uc.edu/ibmt.Conclusion: We use a Bayesian hierarchical normal model to define a novel Intensity-Based Moderated T-statistic (IBMT). The method is completely data-dependent using empirical Bayes philosophy to estimate hyperparameters, and thus does not require specification of any free parameters. IBMT has the strength of balancing two important factors in the analysis of microarray data: the degree of independence of variances relative to the degree of identity (i.e. t-tests vs. equal variance assumption), and the relationship between variance and signal intensity. When this variance-intensity relationship is weak or does not exist, IBMT reduces to a previously described moderated t-statistic. Furthermore, our method may be directly applied to any array platform and experimental design. Together, these properties show IBMT to be a valuable option in the analysis of virtually any microarray experiment.",1471-2105,,,, , ,,out_of_scope,
4093,"Title:Reward modeling for mitigating toxicity in transformer-based language models

 Transformer-based language models can generate fluent text and be efficiently adapted across various natural language generation tasks. However, language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment. Various detoxification methods have been proposed to mitigate language model toxicity; however, these methods struggle to detoxify language models when conditioned on prompts that contain specific social identities related to gender, race, or religion. In this study, we propose Reinforce-Detoxify, a reinforcement learning-based method for mitigating toxicity in language models. We address the challenge of safety in language models and propose a new reward model that can detect toxic content and mitigate unintended bias towards social identities in toxicity prediction. The experiments demonstrate that the Reinforce-Detoxify method for language model detoxification outperforms existing detoxification approaches in automatic evaluation metrics, indicating that our approach in language model detoxification is less prone to unintended bias toward social identities in generated content.","Faal, Farshid; Schmitt, Ketra; Yu, Jia Yuan","Schmitt, Ketra/GWQ-5329-2022","Faal, Farshid/0000-0002-2555-3221",Reward modeling for mitigating toxicity in transformer-based language models,53,7,10.1007/s10489-022-03944-z ,Article ,2023.0,"Transformer-based language models can generate fluent text and be efficiently adapted across various natural language generation tasks. However, language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment. Various detoxification methods have been proposed to mitigate language model toxicity; however, these methods struggle to detoxify language models when conditioned on prompts that contain specific social identities related to gender, race, or religion. In this study, we propose Reinforce-Detoxify, a reinforcement learning-based method for mitigating toxicity in language models. We address the challenge of safety in language models and propose a new reward model that can detect toxic content and mitigate unintended bias towards social identities in toxicity prediction. The experiments demonstrate that the Reinforce-Detoxify method for language model detoxification outperforms existing detoxification approaches in automatic evaluation metrics, indicating that our approach in language model detoxification is less prone to unintended bias toward social identities in generated content.",0924-669X,1573-7497,,8421-8435, , ,,Use_dataset#detox#methodology,
4094,"Title:Text Detoxification using Large Pre-trained Neural Models

 We present two novel unsupervised methods for eliminating toxicity in text. Our first method combines two recent ideas: (1) guidance of the generation process with small style-conditional language models and (2) use of paraphrasing models to perform style transfer. We use a well-performing paraphraser guided by style-trained language models to keep the text content and remove toxicity. Our second method uses BERT to replace toxic words with their non-offensive synonyms. We make the method more flexible by enabling BERT to replace mask tokens with a variable number of words. Finally, we present the first large-scale comparative study of style transfer models on the task of toxicity removal. We compare our models with a number of methods for style transfer. The models are evaluated in a reference-free way using a combination of unsupervised style transfer metrics. Both methods we suggest yield new SOTA results.","Dale, David; Voronov, Anton; Dementieva, Daryna; Logacheva, Varvara; Kozlova, Olga; Semenov, Nikita; Panchenko, Alexander","Voronov, Anton/JED-4209-2023","Dementieva, Daryna/0000-0003-0929-4140",Text Detoxification using Large Pre-trained Neural Models,,, ,Proceedings Paper ,2021.0,"We present two novel unsupervised methods for eliminating toxicity in text. Our first method combines two recent ideas: (1) guidance of the generation process with small style-conditional language models and (2) use of paraphrasing models to perform style transfer. We use a well-performing paraphraser guided by style-trained language models to keep the text content and remove toxicity. Our second method uses BERT to replace toxic words with their non-offensive synonyms. We make the method more flexible by enabling BERT to replace mask tokens with a variable number of words. Finally, we present the first large-scale comparative study of style transfer models on the task of toxicity removal. We compare our models with a number of methods for style transfer. The models are evaluated in a reference-free way using a combination of unsupervised style transfer metrics. Both methods we suggest yield new SOTA results.",,,978-1-955917-09-4,7979-7996, , Conference on Empirical Methods in Natural Language Processing (EMNLP)Conference on Empirical Methods in Natural Language Processing (EMNLP),,detox#methodology,
4095,"Title:Leashing the Inner Demons: Self-Detoxification for Language Models

 Language models (LMs) can reproduce (or amplify) toxic language seen during training, which poses a risk to their practical application. In this paper, we conduct extensive experiments to study this phenomenon. We analyze the impact of prompts, decoding strategies and training corpora on the output toxicity. Based on our findings, we propose a simple yet effective method for language models to detoxify themselves without an additional large corpus or external discriminator. Compared to a supervised baseline, our proposed method shows better toxicity reduction with good generation quality in the generated content under multiple settings. Warning: some examples shown in the paper may contain uncensored offensive content.","Xu, Canwen; He, Zexue; He, Zhankui; McAuley, Julian",,,Leashing the Inner Demons: Self-Detoxification for Language Models,,, ,Proceedings Paper ,2022.0,"Language models (LMs) can reproduce (or amplify) toxic language seen during training, which poses a risk to their practical application. In this paper, we conduct extensive experiments to study this phenomenon. We analyze the impact of prompts, decoding strategies and training corpora on the output toxicity. Based on our findings, we propose a simple yet effective method for language models to detoxify themselves without an additional large corpus or external discriminator. Compared to a supervised baseline, our proposed method shows better toxicity reduction with good generation quality in the generated content under multiple settings. Warning: some examples shown in the paper may contain uncensored offensive content.",2159-5399,2374-3468,978-1-57735-876-3,11530-11537, , 36th AAAI Conference on Artificial Intelligence / 34th Conference on Innovative Applications of Artificial Intelligence / 12th Symposium on Educational Advances in Artificial Intelligence36th AAAI Conference on Artificial Intelligence / 34th Conference on Innovative Applications of Artificial Intelligence / 12th Symposium on Educational Advances in Artificial Intelligence,,detox#methodology,
4096,"Title:PaLM: Scaling Language Modeling with Pathways

 Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540 billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.","Chowdhery, Aakanksha; Narang, Sharan; Devlin, Jacob; Bosma, Maarten; Mishra, Gaurav; Roberts, Adam; Barham, Paul; Chung, Hyung Won; Sutton, Charles; Gehrmann, Sebastian; Schuh, Parker; Shi, Kensen; Tsvyashchenko, Sasha; Maynez, Joshua; Rao, Abhishek; Barnes, Parker; Tay, Yi; Shazeer, Noam; Prabhakaran, Vinodkumar; Reif, Emily; Du, Nan; Hutchinson, Ben; Pope, Reiner; Bradbury, James; Austin, Jacob; Isard, Michael; Gur-Ari, Guy; Yin, Pengcheng; Duke, Toju; Levskaya, Anselm; Ghemawat, Sanjay; Dev, Sunipa; Michalewski, Henryk; Garcia, Xavier; Misra, Vedant; Robinson, Kevin; Fedus, Liam; Zhou, Denny; Ippolito, Daphne; Luan, David; Lim, Hyeontaek; Zoph, Barret; Spiridonov, Alexander; Sepassi, Ryan; Dohan, David; Agrawal, Shivani; Omernick, Mark; Dai, Andrew M.; Pillai, Thanumalayan Sankaranarayana; Pellat, Marie; Lewkowycz, Aitor; Moreira, Erica; Child, Rewon; Polozov, Oleksandr; Lee, Katherine; Zhou, Zongwei; Wang, Xuezhi; Saeta, Brennan; Diaz, Mark; Firat, Orhan; Catasta, Michele; Wei, Jason; Meier-Hellstern, Kathy; Eck, Douglas; Dean, Jeff; Petrov, Slav; Fiedel, Noah",,,PaLM: Scaling Language Modeling with Pathways,24,, ,Article ,2023.0,"Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540 billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.",1532-4435,,,, , ,,evaluation,
4097,"Title:Perturbation Sensitivity Analysis to Detect Unintended Model Biases

 Data-driven statistical Natural Language Processing (NLP) techniques leverage large amounts of language data to build models that can understand language. However, most language data reflect the public discourse at the time the data was produced, and hence NLP models are susceptible to learning incidental associations around named referents at a particular point in time, in addition to general linguistic meaning. An NLP system designed to model notions such as sentiment and toxicity should ideally produce scores that are independent of the identity of such entities mentioned in text and their social associations. For example, in a general purpose sentiment analysis system, a phrase such as I hate Katy Perry should be interpreted as having the same sentiment as I hate Taylor Swift. Based on this idea, we propose a generic evaluation framework, Perturbation Sensitivity Analysis, which detects unintended model biases related to named entities, and requires no new annotations or corpora. We demonstrate the utility of this analysis by employing it on two different NLP models - a sentiment model and a toxicity model - applied on online comments in English language from four different genres.","Prabhakaran, Vinodkumar; Hutchinson, Ben; Mitchell, Margaret",,,Perturbation Sensitivity Analysis to Detect Unintended Model Biases,,, ,Proceedings Paper ,2019.0,"Data-driven statistical Natural Language Processing (NLP) techniques leverage large amounts of language data to build models that can understand language. However, most language data reflect the public discourse at the time the data was produced, and hence NLP models are susceptible to learning incidental associations around named referents at a particular point in time, in addition to general linguistic meaning. An NLP system designed to model notions such as sentiment and toxicity should ideally produce scores that are independent of the identity of such entities mentioned in text and their social associations. For example, in a general purpose sentiment analysis system, a phrase such as I hate Katy Perry should be interpreted as having the same sentiment as I hate Taylor Swift. Based on this idea, we propose a generic evaluation framework, Perturbation Sensitivity Analysis, which detects unintended model biases related to named entities, and requires no new annotations or corpora. We demonstrate the utility of this analysis by employing it on two different NLP models - a sentiment model and a toxicity model - applied on online comments in English language from four different genres.",,,978-1-950737-90-1,5740-5745, , Conference on Empirical Methods in Natural Language Processing / 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Conference on Empirical Methods in Natural Language Processing / 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),,evaluation#methodology,
4098,"Title:Probing Toxic Content in Large Pre-Trained Language Models

 Large pre-trained language models (PTLMs) have been shown to carry biases towards different social groups which leads to the reproduction of stereotypical and toxic content by major NLP systems. We propose a method based on logistic regression classifiers to probe English, French, and Arabic PTLMs and quantify the potentially harmful content that they convey with respect to a set of templates. The templates are prompted by a name of a social group followed by a cause-effect relation. We use PTLMs to predict masked tokens at the end of a sentence in order to examine how likely they enable toxicity towards specific communities. We shed the light on how such negative content can be triggered within unrelated and benign contexts based on evidence from a large-scale study, then we explain how to take advantage of our methodology to assess and mitigate the toxicity transmitted by PTLMs.","Ousidhoum, Nedjma; Zhao, Xinran; Fang, Tianqing; Song, Yangqiu; Yeung, Dit-Yan","Fang, Tianqing/JJF-2802-2023","Fang, Tianqing/0000-0002-0186-8253",Probing Toxic Content in Large Pre-Trained Language Models,,, ,Proceedings Paper ,2021.0,"Large pre-trained language models (PTLMs) have been shown to carry biases towards different social groups which leads to the reproduction of stereotypical and toxic content by major NLP systems. We propose a method based on logistic regression classifiers to probe English, French, and Arabic PTLMs and quantify the potentially harmful content that they convey with respect to a set of templates. The templates are prompted by a name of a social group followed by a cause-effect relation. We use PTLMs to predict masked tokens at the end of a sentence in order to examine how likely they enable toxicity towards specific communities. We shed the light on how such negative content can be triggered within unrelated and benign contexts based on evidence from a large-scale study, then we explain how to take advantage of our methodology to assess and mitigate the toxicity transmitted by PTLMs.",,,978-1-954085-52-7,4262-4274, , Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP)Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP),,detox#evaluation,
4099,"Title:Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP

 This paper contains prompts and model outputs that are offensive in nature.When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As largemodels require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated-word lists, nor does it require any training data or changes to the model's parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.(1)","Schick, Timo; Udupa, Sahana; Schuetze, Hinrich",,,Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP,9,,10.1162/tacl_a_00434 ,Article ,2021.0,"This paper contains prompts and model outputs that are offensive in nature.When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As largemodels require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated-word lists, nor does it require any training data or changes to the model's parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.(1)",,2307-387X,,1408-1424, , ,,detox#evaluation#methodology,
4100,"Title:Avoiding Unintended Bias in Toxicity Classification with Neural Networks

 The growing popularity of online platforms that allow users to communicate with each other, exchange opinions about various events and leave comments, has contributed to the development of natural language processing algorithms. Tens of millions of messages per day published by users of a certain social network must be analyzed in real time for moderation to prevent the spread of various illegal or offensive information, threats and other types of toxic comments. Of course, such a large amount of information can be processed quite quickly only automatically. That is why it is necessary to find a way to teach a computer to understand a text written by a man. It is a non-trivial task, even if the word understand here means only to detect or classify. The rapid development of machine learning technologies has led to the widespread adoption of new algorithms. Many tasks that for years were considered almost impossible to solve using computer now can be successfully solved with deep learning technologies. In this article, the author presents modern approaches to solving the problem of toxic comments detection using deep learning technologies and neural networks. The author introduces two state-of-the-art neural network architectures and also demonstrates how to use a contextual language representation model to detect toxicity. Furthermore, in this article will be presented the results of the developed algorithms, as well as the results of their ensemble, tested on a large training set, gathered and marked up by Google and Jigsaw.","Morzhov, Sergey",,,Avoiding Unintended Bias in Toxicity Classification with Neural Networks,,,10.23919/fruct48808.2020.9087368 ,Proceedings Paper ,2020.0,"The growing popularity of online platforms that allow users to communicate with each other, exchange opinions about various events and leave comments, has contributed to the development of natural language processing algorithms. Tens of millions of messages per day published by users of a certain social network must be analyzed in real time for moderation to prevent the spread of various illegal or offensive information, threats and other types of toxic comments. Of course, such a large amount of information can be processed quite quickly only automatically. That is why it is necessary to find a way to teach a computer to understand a text written by a man. It is a non-trivial task, even if the word understand here means only to detect or classify. The rapid development of machine learning technologies has led to the widespread adoption of new algorithms. Many tasks that for years were considered almost impossible to solve using computer now can be successfully solved with deep learning technologies. In this article, the author presents modern approaches to solving the problem of toxic comments detection using deep learning technologies and neural networks. The author introduces two state-of-the-art neural network architectures and also demonstrates how to use a contextual language representation model to detect toxicity. Furthermore, in this article will be presented the results of the developed algorithms, as well as the results of their ensemble, tested on a large training set, gathered and marked up by Google and Jigsaw.",2305-7254,2343-0737,978-952-69244-2-7,314-320, , 26th Conference of Open Innovations Association FRUCT26th Conference of Open Innovations Association FRUCT,,detection#methodology,
4101,"Title:Predicting Molecule Toxicity via Descriptor-Based Graph Self-Supervised Learning

 Predicting molecular properties with Graph Neural Networks (GNNs) has recently drawn a lot of attention, with compound toxicity prediction being one of the biggest challenges. In cases where there is insufficient labeled molecule data, an effective approach is to pre-train GNNs on large-scale unlabeled molecular data and then fine-tune them for downstream tasks. Among pre-training strategies, node-level pre-training involves masking and predicting atom properties, while motif-based methods capture rich information in subgraphs. These approaches have shown effectiveness across various downstream tasks. However, current pre-training frameworks face two main challenges: (1) node-level auxiliary tasks do not preserve useful domain knowledge, and (2) the fusion of motif-based methods and node-level tasks is computationally extensive. To address these challenges, we propose Descriptor-based Graph Self-supervised Learning (DGSSL), a method that utilizes domain knowledge to enhance graph representation learning. We extract domain knowledge from a descriptor language known as fragmentary code of substructure superposition (FCSS), where molecules are described using substructures that can serve as centers for weak bonds. Specifically, DGSLL identifies descriptor centers in molecules and encodes motif-like information as special atomic numbers in the pre-training tasks. This enables node-level self-supervised pre-training frameworks for GNNs to also capture rich information in local subgraphs. Experimental results demonstrate that our method achieves state-of-the-art performance on three toxicity-related benchmarks and show their significance in an ablation experiment.","Li, Xinze; Makarov, Ilya; Kiselev, Dmitrii",,"Kiselev, Dmitrii/0000-0001-6190-7587",Predicting Molecule Toxicity via Descriptor-Based Graph Self-Supervised Learning,11,,10.1109/ACCESS.2023.3308203 ,Article ,2023.0,"Predicting molecular properties with Graph Neural Networks (GNNs) has recently drawn a lot of attention, with compound toxicity prediction being one of the biggest challenges. In cases where there is insufficient labeled molecule data, an effective approach is to pre-train GNNs on large-scale unlabeled molecular data and then fine-tune them for downstream tasks. Among pre-training strategies, node-level pre-training involves masking and predicting atom properties, while motif-based methods capture rich information in subgraphs. These approaches have shown effectiveness across various downstream tasks. However, current pre-training frameworks face two main challenges: (1) node-level auxiliary tasks do not preserve useful domain knowledge, and (2) the fusion of motif-based methods and node-level tasks is computationally extensive. To address these challenges, we propose Descriptor-based Graph Self-supervised Learning (DGSSL), a method that utilizes domain knowledge to enhance graph representation learning. We extract domain knowledge from a descriptor language known as fragmentary code of substructure superposition (FCSS), where molecules are described using substructures that can serve as centers for weak bonds. Specifically, DGSLL identifies descriptor centers in molecules and encodes motif-like information as special atomic numbers in the pre-training tasks. This enables node-level self-supervised pre-training frameworks for GNNs to also capture rich information in local subgraphs. Experimental results demonstrate that our method achieves state-of-the-art performance on three toxicity-related benchmarks and show their significance in an ablation experiment.",2169-3536,,,91842-91849, , ,,out_of_scope,
4102,"Title:Automated Identification of Patients With Immune-Related Adverse Events From Clinical Notes Using Word Embedding and Machine Learning

 PURPOSE Although immune checkpoint inhibitors (ICIs) have substantially improved survival in patients with advanced malignancies, they are associated with a unique spectrum of side effects termed immune-related adverse events (irAEs). To ensure treatment safety, research efforts are needed to comprehensively detect and understand irAEs. Retrospective analysis of data from electronic health records can provide knowledge to characterize these toxicities. However, such information is not captured in a structured format within the electronic health record and requires manual chart review.MATERIALS AND METHODS In this work, we propose a natural language processing pipeline that can automatically annotate clinical notes and determine whether there is evidence that a patient developed an irAE. Seven hundred eighty-one cases were manually reviewed by clinicians and annotated for irAEs at the patient level. A dictionary of irAEs keywords was used to perform text reduction on clinical notes belonging to each patient; only sentences with relevant expressions were kept. Word embeddings were then used to generate vector representations over the reduced text, which served as input for the machine learning classifiers. The output of the models was presence or absence of any irAEs. Additional models were built to classify skin-related toxicities, endocrine toxicities, and colitis. D RESULTS The model for any irAE achieved an average F1-score = 0.75 and area under the receiver operating characteristic curve = 0.85. This outperformed a basic keyword filtering approach. Although the classifier of any irAEs achieved good accuracy, individual irAE classification still has room for improvement.CONCLUSION We demonstrate that patient-level annotations combined with a machine learning approach using keywords filtering and word embeddings can achieve promising accuracy in classifying irAEs in clinical notes. This model may facilitate annotation and analysis of large irAEs data sets. (C) 2021 by American Society of Clinical Oncology","Gupta, Samir; Belouali, Anas; Shah, Neil J.; Atkins, Michael B.; Madhavan, Subha","Belouali, Anas/AAX-6308-2021; Belouali, Anas/IYJ-5849-2023","Belouali, Anas/0000-0002-2780-2500; Madhavan, Subha/0000-0001-7617-3547; Atkins, Michael/0000-0003-3901-9924; Gupta, Samir/0000-0003-2656-3912",Automated Identification of Patients With Immune-Related Adverse Events From Clinical Notes Using Word Embedding and Machine Learning,5,,10.1200/CCI.20.00109 ,Article ,2021.0,"PURPOSE Although immune checkpoint inhibitors (ICIs) have substantially improved survival in patients with advanced malignancies, they are associated with a unique spectrum of side effects termed immune-related adverse events (irAEs). To ensure treatment safety, research efforts are needed to comprehensively detect and understand irAEs. Retrospective analysis of data from electronic health records can provide knowledge to characterize these toxicities. However, such information is not captured in a structured format within the electronic health record and requires manual chart review.MATERIALS AND METHODS In this work, we propose a natural language processing pipeline that can automatically annotate clinical notes and determine whether there is evidence that a patient developed an irAE. Seven hundred eighty-one cases were manually reviewed by clinicians and annotated for irAEs at the patient level. A dictionary of irAEs keywords was used to perform text reduction on clinical notes belonging to each patient; only sentences with relevant expressions were kept. Word embeddings were then used to generate vector representations over the reduced text, which served as input for the machine learning classifiers. The output of the models was presence or absence of any irAEs. Additional models were built to classify skin-related toxicities, endocrine toxicities, and colitis. D RESULTS The model for any irAE achieved an average F1-score = 0.75 and area under the receiver operating characteristic curve = 0.85. This outperformed a basic keyword filtering approach. Although the classifier of any irAEs achieved good accuracy, individual irAE classification still has room for improvement.CONCLUSION We demonstrate that patient-level annotations combined with a machine learning approach using keywords filtering and word embeddings can achieve promising accuracy in classifying irAEs in clinical notes. This model may facilitate annotation and analysis of large irAEs data sets. (C) 2021 by American Society of Clinical Oncology",2473-4276,,,541-549, , ,,out_of_scope,
4103,"Title:Modern Approaches to Detecting and Classifying Toxic Comments Using Neural Networks

 The rising popularity of online platforms on which users communicate with each other, share opinions about various events, and leave comments has spurred on the development of natural language processing algorithms. Content moderation requires analyzing tens of millions of messages published by users of a given social network daily in real time, in order to prevent the spread of various illegal or offensive information, threats, and other types of toxic comments. Of course, such a large amount of data can be processed quickly enough only automatically. That leads to the problem of teaching computers to understand human written speech, which is nontrivial even if understand here means nothing more than classify. The rapid evolution of machine learning technologies has led to ubiquitous implementation of new algorithms. With the use of deep learning technologies, we are now able to quite successfully solve many problems that had for years been considered almost impossible. This article considers algorithms constructed using deep learning technologies and neural networks that solve the problem of detecting and classifying toxic comments. In addition, the article presents the results of testing both the developed algorithms and an ensemble of all considered algorithms on a large training set collected and tagged by Google and Jigsaw.","Morzhov, S. V.",,"Morzhov, Sergey/0000-0001-6652-3574",Modern Approaches to Detecting and Classifying Toxic Comments Using Neural Networks,55,7,10.3103/S0146411621070117 ,Article ,2021.0,"The rising popularity of online platforms on which users communicate with each other, share opinions about various events, and leave comments has spurred on the development of natural language processing algorithms. Content moderation requires analyzing tens of millions of messages published by users of a given social network daily in real time, in order to prevent the spread of various illegal or offensive information, threats, and other types of toxic comments. Of course, such a large amount of data can be processed quickly enough only automatically. That leads to the problem of teaching computers to understand human written speech, which is nontrivial even if understand here means nothing more than classify. The rapid evolution of machine learning technologies has led to ubiquitous implementation of new algorithms. With the use of deep learning technologies, we are now able to quite successfully solve many problems that had for years been considered almost impossible. This article considers algorithms constructed using deep learning technologies and neural networks that solve the problem of detecting and classifying toxic comments. In addition, the article presents the results of testing both the developed algorithms and an ensemble of all considered algorithms on a large training set collected and tagged by Google and Jigsaw.",0146-4116,1558-108X,,607-616, , ,,detection#methodology,
4104,"Title:Reducing Offensive Replies in Open Domain Dialogue Systems

 In recent years, a series of open-domain dialogue systems using large-scale language models have been proposed. These dialogue systems are attracting business attention because these do significantly natural and diverse dialogues with humans. However, it has been noted that these dialogue systems reflect gender, race, and other biases inherent in the data and may generate offensive replies or replies that agree with offensive utterances. This study examined a dialogue system that outputs appropriate replies to offensive utterances. Specifically, our system incorporates multiple dialogue models, each of which is specialized to suppress offensive replies in a specific category, then selects the most non-offensive reply from the outputs of the models. We evaluated the utility of our system when suppressing offensive replies of DialoGPT. We confirmed ours reduces the offensive replies to less than 1%, whereas one of the state-of-the-art suppressing methods reduces to 9.8%.","Uchida, Naokazu; Homma, Takeshi; Iwayama, Makoto; Sogawa, Yasuhiro",,"Homma, Takeshi/0000-0003-3864-3848",Reducing Offensive Replies in Open Domain Dialogue Systems,,,10.21437/Interspeech.2022-200 ,Proceedings Paper ,2022.0,"In recent years, a series of open-domain dialogue systems using large-scale language models have been proposed. These dialogue systems are attracting business attention because these do significantly natural and diverse dialogues with humans. However, it has been noted that these dialogue systems reflect gender, race, and other biases inherent in the data and may generate offensive replies or replies that agree with offensive utterances. This study examined a dialogue system that outputs appropriate replies to offensive utterances. Specifically, our system incorporates multiple dialogue models, each of which is specialized to suppress offensive replies in a specific category, then selects the most non-offensive reply from the outputs of the models. We evaluated the utility of our system when suppressing offensive replies of DialoGPT. We confirmed ours reduces the offensive replies to less than 1%, whereas one of the state-of-the-art suppressing methods reduces to 9.8%.",2308-457X,,*****************,1076-1080, , Interspeech ConferenceInterspeech Conference,,detox#methodology,
4105,"Title:The Structure of Toxic Conversations on Twitter

 Social media platforms promise to enable rich and vibrant conversations online; however, their potential is often hindered by antisocial behaviors. In this paper, we study the relationship between structure and toxicity in conversations on Twitter. We collect 1.18M conversations (58.5M tweets, 4.4M users) prompted by tweets that are posted by or mention major news outlets over one year and candidates who ran in the 2018 US midterm elections over four months. We analyze the conversations at the individual, dyad, and group level. At the individual level, we find that toxicity is spread across many low to moderately toxic users. At the dyad level, we observe that toxic replies are more likely to come from users who do not have any social connection nor share many common friends with the poster. At the group level, we find that toxic conversations tend to have larger, wider, and deeper reply trees, but sparser follow graphs. To test the predictive power of the conversational structure, we consider two prediction tasks. In the first prediction task, we demonstrate that the structural features can be used to predict whether the conversation will become toxic as early as the first ten replies. In the second prediction task, we show that the structural characteristics of the conversation are also predictive of whether the next reply posted by a specific user will be toxic or not. We observe that the structural and linguistic characteristics of the conversations are complementary in both prediction tasks. Our findings inform the design of healthier social media platforms and demonstrate that models based on the structural characteristics of conversations can be used to detect early signs of toxicity and potentially steer conversations in a less toxic direction.","Saveski, Martin; Roy, Brandon; Roy, Deb",,,The Structure of Toxic Conversations on Twitter,,,10.1145/3442381.3449861 ,Proceedings Paper ,2021.0,"Social media platforms promise to enable rich and vibrant conversations online; however, their potential is often hindered by antisocial behaviors. In this paper, we study the relationship between structure and toxicity in conversations on Twitter. We collect 1.18M conversations (58.5M tweets, 4.4M users) prompted by tweets that are posted by or mention major news outlets over one year and candidates who ran in the 2018 US midterm elections over four months. We analyze the conversations at the individual, dyad, and group level. At the individual level, we find that toxicity is spread across many low to moderately toxic users. At the dyad level, we observe that toxic replies are more likely to come from users who do not have any social connection nor share many common friends with the poster. At the group level, we find that toxic conversations tend to have larger, wider, and deeper reply trees, but sparser follow graphs. To test the predictive power of the conversational structure, we consider two prediction tasks. In the first prediction task, we demonstrate that the structural features can be used to predict whether the conversation will become toxic as early as the first ten replies. In the second prediction task, we show that the structural characteristics of the conversation are also predictive of whether the next reply posted by a specific user will be toxic or not. We observe that the structural and linguistic characteristics of the conversations are complementary in both prediction tasks. Our findings inform the design of healthier social media platforms and demonstrate that models based on the structural characteristics of conversations can be used to detect early signs of toxicity and potentially steer conversations in a less toxic direction.",,,978-1-4503-8312-7,1086-1097, , 30th World Wide Web Conference (WWW)30th World Wide Web Conference (WWW),,evaluation,
4106,"Title:Dynamics of online hate and misinformation

 Online debates are often characterised by extreme polarisation and heated discussions among users. The presence of hate speech online is becoming increasingly problematic, making necessary the development of appropriate countermeasures. In this work, we perform hate speech detection on a corpus of more than one million comments on YouTube videos through a machine learning model, trained and fine-tuned on a large set of hand-annotated data. Our analysis shows that there is no evidence of the presence of pure haters, meant as active users posting exclusively hateful comments. Moreover, coherently with the echo chamber hypothesis, we find that users skewed towards one of the two categories of video channels (questionable, reliable) are more prone to use inappropriate, violent, or hateful language within their opponents' community. Interestingly, users loyal to reliable sources use on average a more toxic language than their counterpart. Finally, we find that the overall toxicity of the discussion increases with its length, measured both in terms of the number of comments and time. Our results show that, coherently with Godwin's law, online debates tend to degenerate towards increasingly toxic exchanges of views.","Cinelli, Matteo; Pelicon, Andraz; Mozetic, Igor; Quattrociocchi, Walter; Novak, Petra Kralj; Zollo, Fabiana","Zollo, Fabiana/Z-1506-2019; Cinelli, Matteo/AFO-0408-2022; Quattrociocchi, Walter/IAQ-5197-2023","Zollo, Fabiana/0000-0002-0833-5388; Cinelli, Matteo/0000-0003-3899-4592; Quattrociocchi, Walter/0000-0002-4374-9324; Mozetic, Igor/0000-0002-5466-0608; Pelicon, Andraz/0000-0002-2060-6670",Dynamics of online hate and misinformation,11,1,10.1038/s41598-021-01487-w ,Article ,2021.0,"Online debates are often characterised by extreme polarisation and heated discussions among users. The presence of hate speech online is becoming increasingly problematic, making necessary the development of appropriate countermeasures. In this work, we perform hate speech detection on a corpus of more than one million comments on YouTube videos through a machine learning model, trained and fine-tuned on a large set of hand-annotated data. Our analysis shows that there is no evidence of the presence of pure haters, meant as active users posting exclusively hateful comments. Moreover, coherently with the echo chamber hypothesis, we find that users skewed towards one of the two categories of video channels (questionable, reliable) are more prone to use inappropriate, violent, or hateful language within their opponents' community. Interestingly, users loyal to reliable sources use on average a more toxic language than their counterpart. Finally, we find that the overall toxicity of the discussion increases with its length, measured both in terms of the number of comments and time. Our results show that, coherently with Godwin's law, online debates tend to degenerate towards increasingly toxic exchanges of views.",2045-2322,,,, , ,,detection#evaluation#methodology,
4107,"Title:Does the first response matter for future contributions? A study of first contributions

 Open Source Software (OSS) projects rely on a continuous stream of new contributors for their livelihood. Recent studies reported that new contributors experience many barriers in their first contribution, with the social barrier being critical. Although a number of studies investigated the social barriers to new contributors, we hypothesize that negative first responses may cause an unpleasant feeling, and subsequently lead to the discontinuity of any future contribution. We execute protocols of a registered report to analyze 2,765,917 first contributions as Pull Requests (PRs) with 642,841 first responses. We characterize most first response as being positive, but less responsive, and exhibiting sentiments of fear, joy and love. Results also indicate that negative first responses have the literal intention to arouse emotions of being either constructive (50.71%) or criticizing (37.68%) in nature. Running different machine learning models, we find that predicting future interactions is low (F1 score of 0.6171), but relatively better than baselines. Furthermore, an analysis of these models show that interactions are positively correlated with a future contribution, with other dimensions (i.e., project, contributor, contribution) having a large effect.","Assavakamhaenghan, Noppadol; Wattanakriengkrai, Supatsara; Shimada, Naomichi; Kula, Raula Gaikovina; Ishio, Takashi; Matsumoto, Kenichi","Kula, Raula/AAD-6079-2019","Kula, Raula/0000-0003-2324-0608; Ishio, Takashi/0000-0003-4106-699X",Does the first response matter for future contributions? A study of first contributions,28,3,10.1007/s10664-023-10299-7 ,Article ,2023.0,"Open Source Software (OSS) projects rely on a continuous stream of new contributors for their livelihood. Recent studies reported that new contributors experience many barriers in their first contribution, with the social barrier being critical. Although a number of studies investigated the social barriers to new contributors, we hypothesize that negative first responses may cause an unpleasant feeling, and subsequently lead to the discontinuity of any future contribution. We execute protocols of a registered report to analyze 2,765,917 first contributions as Pull Requests (PRs) with 642,841 first responses. We characterize most first response as being positive, but less responsive, and exhibiting sentiments of fear, joy and love. Results also indicate that negative first responses have the literal intention to arouse emotions of being either constructive (50.71%) or criticizing (37.68%) in nature. Running different machine learning models, we find that predicting future interactions is low (F1 score of 0.6171), but relatively better than baselines. Furthermore, an analysis of these models show that interactions are positively correlated with a future contribution, with other dimensions (i.e., project, contributor, contribution) having a large effect.",1382-3256,1573-7616,,, , ,,out_of_scope,
4108,"Title:An ontology-driven semantic mashup of gene and biological pathway information: Application to the domain of nicotine dependence

 Objectives: This paper illustrates how Semantic Web technologies (especially RDF, OWL, and SPARQL) can support information integration and make it easy to create semantic mashups (semantically integrated resources). In the context Of understanding the genetic basis of nicotine dependence, we integrate gene and pathway information and show how three complex biological queries can be answered by the integrated knowledge base.Methods: We use an ontology-driven approach to integrate two gene resources (Entrez Gene and Homolo-Gene) and three pathway resources (KEGG, Reactome and BioCyc), for five organisms, including humans. We created the Entrez Knowledge Model (EKoM), an information model in OWL for the gene resources, and integrated it with the extant BioPAX ontology designed for pathway resources. The integrated schema is populated with data from the pathway resources, Publicly available in BioPAX-compatible format, and gene resources for which a Population procedure was created. The SPARQL query language is used to formulate queries over the integrated knowledge base to answer the three biological queries. Results: Simple SPARQL queries could easily identify hub genes, i.e., those genes whose gene products participate in many pathways or interact with many other gene products. The identification of the genes expressed in the brain turned out to be more difficult, due to the lack of a common identification scheme for Proteins.Conclusion: Semantic Web technologies provide a valid framework for information integration in the life sciences. Ontology-driven integration represents a flexible, Sustainable and extensible solution to the integration of large volumes of information. Additional resources, which enable the creation of mappings between information sources, are required to compensate for heterogeneity across namespaces. Resource pagehttp://knoesis.wright.edu/research/lifesci/integration/structured-data/JBI-2008/ (C) 2008 Elsevier Inc. All rights reserved.","Sahoo, Satya S.; Bodenreider, Olivier; Rutter, Joni L.; Skinner, Karen J.; Sheth, Amit P.","Sheth, Amit/ABC-4600-2020; Bodenreider, Olivier/C-8382-2009; Sahoo, Satya/R-4832-2019","Sheth, Amit/0000-0002-0021-5293; Sahoo, Satya/0000-0001-9190-4256; Rutter, Joni/0000-0002-6502-2361",An ontology-driven semantic mashup of gene and biological pathway information: Application to the domain of nicotine dependence,41,5,10.1016/j.jbi.2008.02.006 ,Article ,2008.0,"Objectives: This paper illustrates how Semantic Web technologies (especially RDF, OWL, and SPARQL) can support information integration and make it easy to create semantic mashups (semantically integrated resources). In the context Of understanding the genetic basis of nicotine dependence, we integrate gene and pathway information and show how three complex biological queries can be answered by the integrated knowledge base.Methods: We use an ontology-driven approach to integrate two gene resources (Entrez Gene and Homolo-Gene) and three pathway resources (KEGG, Reactome and BioCyc), for five organisms, including humans. We created the Entrez Knowledge Model (EKoM), an information model in OWL for the gene resources, and integrated it with the extant BioPAX ontology designed for pathway resources. The integrated schema is populated with data from the pathway resources, Publicly available in BioPAX-compatible format, and gene resources for which a Population procedure was created. The SPARQL query language is used to formulate queries over the integrated knowledge base to answer the three biological queries. Results: Simple SPARQL queries could easily identify hub genes, i.e., those genes whose gene products participate in many pathways or interact with many other gene products. The identification of the genes expressed in the brain turned out to be more difficult, due to the lack of a common identification scheme for Proteins.Conclusion: Semantic Web technologies provide a valid framework for information integration in the life sciences. Ontology-driven integration represents a flexible, Sustainable and extensible solution to the integration of large volumes of information. Additional resources, which enable the creation of mappings between information sources, are required to compensate for heterogeneity across namespaces. Resource pagehttp://knoesis.wright.edu/research/lifesci/integration/structured-data/JBI-2008/ (C) 2008 Elsevier Inc. All rights reserved.",1532-0464,1532-0480,,752-765, , ,,out_of_scope,
4109,"Title:Using an apex predator for large-scale monitoring of trace element contamination: Associations with environmental, anthropogenic and dietary proxies

 Understanding the levels and drivers of contamination in top predators is important for their conservation and eventual use as sentinels in environmental monitoring. Therefore, metals and trace elements were analyzed in feathers of Bonelli's eagles (Aquila fasciata) from southern Portugal in 2007-2013, where they are believed to be exposed to a wide range of contamination sources such as agricultural land uses, urban areas, active and abandoned mines and a coal-fired power plant. We focused on concentrations of aluminum (Al), arsenic (As), copper (Cu), chromium (Cr), mercury (Hg), lead (Pb), selenium (Se) and zinc (Zn), as these contaminants arc potentially associated with those sources and are known to pose a risk for terrestrial vertebrates. Stable isotope values of nitrogen (delta N-15:N- 15/N-14), carbon (delta C-13: C-13/C-12) and sulphur (delta S-34:S- 34/S-32) were used as dietary proxies to control for potential effects of prey composition on the contamination pattern. The spatial distribution of potential contamination sources was quantified using geographic information systems. Concentrations of Hg in the southern part of the study area were above a reported toxicity threshold for raptors, particularly in territories closer to a coal-fired power plant at Sines, showing that contamination persisted after a previous assessment conducted in the 1990s. Hg and Se levels were positively correlated with delta N-15, which indicates biomagnification. Concentrations of As, Cr, Cu, Pb and Zn were generally low and unrelated to mining- or industrial activities, indicating low environmental background concentrations. Al was found at higher concentrations in the southernmost areas of Portugal, but this pattern might be related to external soil contamination on feathers. Overall, this study indicates that. among all elements studied, Hg seems to be the most important contaminant for Bonelli's eagles in southern Portugal, likely due to the power plant emissions and biomagnitication of Hg in terrestrial food webs. (C) 2019 Elsevier B.V. All rights reserved.","Badry, Alexander; Palma, Luis; Beja, Pedro; Ciesielski, Tomasz M.; Dias, Andreia; Lierhagen, Syverin; Jenssen, Bjorn Munro; Sturaro, Nicolas; Eulaers, Igor; Jaspers, Veerle L. B.","Jaspers, Veerle/E-1379-2011; Jenssen, Bjorn M/J-4830-2012; Eulaers, Igor/AAJ-5912-2020; Palma, Luís M A/L-7826-2013; Jenssen, Bjorn Munro/O-3217-2019; Beja, Pedro/A-7851-2008; Ciesielski, Tomasz/J-9039-2012","Jaspers, Veerle/0000-0002-2385-4493; Jenssen, Bjorn M/0000-0002-7042-2191; Eulaers, Igor/0000-0002-7130-9932; Palma, Luís M A/0000-0003-2899-9269; Jenssen, Bjorn Munro/0000-0002-7042-2191; Beja, Pedro/0000-0001-8164-0760; Ciesielski, Tomasz Maciej/0000-0001-7509-1662; Badry, Alexander/0000-0002-7056-398X","Using an apex predator for large-scale monitoring of trace element contamination: Associations with environmental, anthropogenic and dietary proxies",676,,10.1016/j.scitotenv.2019.04.217 ,Article ,2019.0,"Understanding the levels and drivers of contamination in top predators is important for their conservation and eventual use as sentinels in environmental monitoring. Therefore, metals and trace elements were analyzed in feathers of Bonelli's eagles (Aquila fasciata) from southern Portugal in 2007-2013, where they are believed to be exposed to a wide range of contamination sources such as agricultural land uses, urban areas, active and abandoned mines and a coal-fired power plant. We focused on concentrations of aluminum (Al), arsenic (As), copper (Cu), chromium (Cr), mercury (Hg), lead (Pb), selenium (Se) and zinc (Zn), as these contaminants arc potentially associated with those sources and are known to pose a risk for terrestrial vertebrates. Stable isotope values of nitrogen (delta N-15:N- 15/N-14), carbon (delta C-13: C-13/C-12) and sulphur (delta S-34:S- 34/S-32) were used as dietary proxies to control for potential effects of prey composition on the contamination pattern. The spatial distribution of potential contamination sources was quantified using geographic information systems. Concentrations of Hg in the southern part of the study area were above a reported toxicity threshold for raptors, particularly in territories closer to a coal-fired power plant at Sines, showing that contamination persisted after a previous assessment conducted in the 1990s. Hg and Se levels were positively correlated with delta N-15, which indicates biomagnification. Concentrations of As, Cr, Cu, Pb and Zn were generally low and unrelated to mining- or industrial activities, indicating low environmental background concentrations. Al was found at higher concentrations in the southernmost areas of Portugal, but this pattern might be related to external soil contamination on feathers. Overall, this study indicates that. among all elements studied, Hg seems to be the most important contaminant for Bonelli's eagles in southern Portugal, likely due to the power plant emissions and biomagnitication of Hg in terrestrial food webs. (C) 2019 Elsevier B.V. All rights reserved.",0048-9697,1879-1026,,746-755, , ,,out_of_scope,
4110,"Title:Regionalized phosphorus fate factors for freshwater eutrophication in Bahia, Brazil: an analysis of spatial and temporal variability

 Purpose Fate factors, for freshwater eutrophication, represent the route of a limiting-nutrient, phosphorus or nitrogen, and their degradation in the environment. Their value may vary according to the location and emission season; that is, they are site and temporal dependent. In this study, phosphorus fate factors for the freshwater eutrophication impact category were estimated in a native scale of state hydrographic units (SHU), considering its variability and applied in a case study for one hydrographic basin in the state of Bahia, Brazil. Methods The fate model considered the phosphorus removal processes of advection, retention, and agricultural and domestic water use, based on national databases (Geonetwork, HidroWeb, SAR, and SNIS). Heat maps and correlation networks allowed the assessment of fate factors' spatiotemporal variability. The new generated fate factors were qualitatively and quantitatively assessed, then further applied in a case study of buffalo milk production at Leste SHU to determine the regionalization effects on the freshwater eutrophication potential impact. Results and discussion This study reconfirmed the spatial and temporal variability of the fate factors. The fate factor values found, in this study, for Pardo SHU are similar to those estimated with the non-regionalized data used by the adopted model, being within the range of 0 to 20 days. However, the fate factors for De Contas and, mainly, for Leste were underestimated, reaching a value up to five times higher, indicating that the model's proposed changes impacted the final result. The temporal differentiation was mainly determined by periods of higher and lower water availability. Advection processes inversely determined the fate factors, and the phosphorus removal by retention processes became more prominent when the water availability was lower. On the other hand, the role of phosphorus removal through water use was minimum. Water availability was the largest contributor to the sensitivity analysis, followed by the total freshwater volume. Conclusion The fate modeling adopted in this study, with the use of data from national databases and native resolution, gave a more precise and detailed analysis perspective of the phosphorus fate in Brazilian SHUs, setting up site- and temporal-specific fate factors. Besides, this study provides a further understanding of the fate factors establishment by analyzing their relationship with the respective input parameters and highlighting one of the used model's weaknesses: the estimation of phosphorus removals instead of phosphorus load underestimates the true freshwater eutrophication potential.","de Andrade, Maira Caetano; Ugaya, Cassia Maria Lie; de Almeida Neto, Jose Adolfo; Rodrigues, Luciano Brito",,"Caetano de Andrade, Maira/0000-0002-8524-8368","Regionalized phosphorus fate factors for freshwater eutrophication in Bahia, Brazil: an analysis of spatial and temporal variability",26,5,10.1007/s11367-021-01912-2 ,Article ,2021.0,"Purpose Fate factors, for freshwater eutrophication, represent the route of a limiting-nutrient, phosphorus or nitrogen, and their degradation in the environment. Their value may vary according to the location and emission season; that is, they are site and temporal dependent. In this study, phosphorus fate factors for the freshwater eutrophication impact category were estimated in a native scale of state hydrographic units (SHU), considering its variability and applied in a case study for one hydrographic basin in the state of Bahia, Brazil. Methods The fate model considered the phosphorus removal processes of advection, retention, and agricultural and domestic water use, based on national databases (Geonetwork, HidroWeb, SAR, and SNIS). Heat maps and correlation networks allowed the assessment of fate factors' spatiotemporal variability. The new generated fate factors were qualitatively and quantitatively assessed, then further applied in a case study of buffalo milk production at Leste SHU to determine the regionalization effects on the freshwater eutrophication potential impact. Results and discussion This study reconfirmed the spatial and temporal variability of the fate factors. The fate factor values found, in this study, for Pardo SHU are similar to those estimated with the non-regionalized data used by the adopted model, being within the range of 0 to 20 days. However, the fate factors for De Contas and, mainly, for Leste were underestimated, reaching a value up to five times higher, indicating that the model's proposed changes impacted the final result. The temporal differentiation was mainly determined by periods of higher and lower water availability. Advection processes inversely determined the fate factors, and the phosphorus removal by retention processes became more prominent when the water availability was lower. On the other hand, the role of phosphorus removal through water use was minimum. Water availability was the largest contributor to the sensitivity analysis, followed by the total freshwater volume. Conclusion The fate modeling adopted in this study, with the use of data from national databases and native resolution, gave a more precise and detailed analysis perspective of the phosphorus fate in Brazilian SHUs, setting up site- and temporal-specific fate factors. Besides, this study provides a further understanding of the fate factors establishment by analyzing their relationship with the respective input parameters and highlighting one of the used model's weaknesses: the estimation of phosphorus removals instead of phosphorus load underestimates the true freshwater eutrophication potential.",0948-3349,1614-7502,,879-898, , ,,out_of_scope,
4111,"Title:Application of life cycle assessment to the LCA case studies single superphosphate production

 Goal, Scope and Background. There is a competition between wet and thermal routes for phosphate fertilizers manufacture. In the Brazilian case, the thermal route is represented by thermophosphate. This fertilizer is considered the most adequate one for Brazilian agricultural conditions; its main restriction is the intensive consumption of energy necessary for its production. The wet route uses sulfuric acid to directly produce the single superphosphate (SSP) or the intermediate phosphoric acid, which will be used to result in triple superphosphate (TSP) and ammonium phosphate production. The main restriction of the wet route is the large amount of phosphogypsum generated in phosphoric acid production. Envisaged is an environmental comparison of both routes using LCA methodology. This paper presents the LCA for SSP production. The goal of the study is to establish the Environmental Profile of this fertilizer. Eight impact categories were selected for the study. The system boundaries was defined for a 'cradle to gate' approach, including extraction of natural resources, intermediate products, and production.The SSP System. The SSP system (single superphosphate) comprises the stages of mining and concentration of the phosphate rock, elemental sulfur extraction, production of sulfuric acid, and manufacture of single superphosphate.SSP LCI. The LCI was performed considering the production of 1.0 ton of SSP (single superphosphate) as a Functional Unit. The data collected were developed for different producing companies, all of them located in the same regional area. Allocation criteria of energy and mass were applied to the production of sulfuric acid and manufacture of single superphosphate. The transportation step included either the transport of the mined phosphated rock to the concentration plant or the transport of the phosphate concentrate to the SSP unit.Conclusion, Recommendation and Perspective. The accomplishment of an LCA to SSP production identified the GWP and EP as its meaningful environmental impacts. In reference to global warming, the transportation step was the greatest contributor agent, while the losses of PO4- from the SSP manufacturing were the main cause of ER The most important contribution in terms of water consumption was observed in the concentration step. Finally, the self sufficiency of the sulfuric acid production in energetic terms must be highlighted.The knowledge of the environmental profile of fertilizers is necessary to support LCA studies of agricultural products, a relevant raw material source for many industrial sectors. The method used here may be important for modelling other LCA fertilizer studies. As most of the agricultural raw materials are transferred among different countries, comparisons of the environmental profiles of fertilizers in developed and developing countries are needed.","Silva, GA; Kulay, LA","Kulay, Luiz/A-7422-2013; Silva, Gil Anderi/L-1499-2014","Kulay, Luiz/0000-0003-1107-1800;",Application of life cycle assessment to the LCA case studies single superphosphate production,8,4,10.1007/BF02978473 ,Article ,2003.0,"Goal, Scope and Background. There is a competition between wet and thermal routes for phosphate fertilizers manufacture. In the Brazilian case, the thermal route is represented by thermophosphate. This fertilizer is considered the most adequate one for Brazilian agricultural conditions; its main restriction is the intensive consumption of energy necessary for its production. The wet route uses sulfuric acid to directly produce the single superphosphate (SSP) or the intermediate phosphoric acid, which will be used to result in triple superphosphate (TSP) and ammonium phosphate production. The main restriction of the wet route is the large amount of phosphogypsum generated in phosphoric acid production. Envisaged is an environmental comparison of both routes using LCA methodology. This paper presents the LCA for SSP production. The goal of the study is to establish the Environmental Profile of this fertilizer. Eight impact categories were selected for the study. The system boundaries was defined for a 'cradle to gate' approach, including extraction of natural resources, intermediate products, and production.The SSP System. The SSP system (single superphosphate) comprises the stages of mining and concentration of the phosphate rock, elemental sulfur extraction, production of sulfuric acid, and manufacture of single superphosphate.SSP LCI. The LCI was performed considering the production of 1.0 ton of SSP (single superphosphate) as a Functional Unit. The data collected were developed for different producing companies, all of them located in the same regional area. Allocation criteria of energy and mass were applied to the production of sulfuric acid and manufacture of single superphosphate. The transportation step included either the transport of the mined phosphated rock to the concentration plant or the transport of the phosphate concentrate to the SSP unit.Conclusion, Recommendation and Perspective. The accomplishment of an LCA to SSP production identified the GWP and EP as its meaningful environmental impacts. In reference to global warming, the transportation step was the greatest contributor agent, while the losses of PO4- from the SSP manufacturing were the main cause of ER The most important contribution in terms of water consumption was observed in the concentration step. Finally, the self sufficiency of the sulfuric acid production in energetic terms must be highlighted.The knowledge of the environmental profile of fertilizers is necessary to support LCA studies of agricultural products, a relevant raw material source for many industrial sectors. The method used here may be important for modelling other LCA fertilizer studies. As most of the agricultural raw materials are transferred among different countries, comparisons of the environmental profiles of fertilizers in developed and developing countries are needed.",0948-3349,1614-7502,,209-214, , ,,out_of_scope,
4112,"Title:Seasonal variability of a conditional stability constant and the characterization of sedimentary humic substances from typical agricultural and urban areas

 Brazil is the largest producer of sugarcane in the world. This extensive production of sugarcane has changed the use and form of Brazilian soil, causing changes in the structural characteristics of humic substances (HS). In this context, the main objective of this study was to evaluate the effect of seasonality on a conditional stability constant (Kc) of the complexes HS-Cu (II) and HS-Cr (III) from the HS of urban and agricultural regions, with an emphasis on sugarcane culture.The study was conducted in the northwestern region of the state of So Paulo, which is the leading producer of sugar and ethanol in the country and is the region with the lowest percentage of riparian vegetation (3 %). Sediments were sampled during the rainy and dry seasons at four locations: (1) a typical agricultural area, (2) an urban area, (3) a sugarcane cultivation area, (4) and an area that receives the entire pollutant load from the hydrographic basin. The HS were extracted and characterized using conventional techniques. The Kc of the HS with copper (Cu) and chromium (Cr) ions was determined by fluorescence suppression employing the Stern-Volmer model.Kc values were higher in the rainy seasons for HS-Cu (II) and HS-Cr (III). The highest value of Kc for the HS with Cu (1.23) and Cr (5.2 x 10(-1)) ions was found during the rainy season in the area receiving the pollutant load from the basin and in the typical area of sugarcane cultivation, respectively. All of the FTIR spectra showed characteristic bands of HS, and the values of the E-4/E-6 ratio confirmed the presence of more aromatic groups. An elemental analysis and molecular fluorescence spectra in the emission mode confirmed that the HS from the agricultural area and sugarcane culture area mostly exhibited characteristics of humic acids and that the HS from the urban area and the area receiving the pollutant load from the basin had a mixture of humic and fulvic acids.We can conclude that HS-metal complexes from the area that received the entire load of pollutants from the watershed and the typical area of sugarcane culture showed the highest stability among the study areas. The Kc values found in the basin were lower than those previously obtained by several studies that were performed in other locations. The HS obtained in rainy season had more aromatic groups in the HS structure, and the HS from the sugarcane area presented more characteristics of humic acids.","Pantano, Glaucia; Tadini, Amanda Maria; Bisinoti, Marcia Cristina; Moreira, Altair Benedito","Moreira, Altair/D-1029-2012; Pantano, Glaucia/P-6797-2015; Tadini, Amanda Maria/J-5299-2015; Bisinoti, Márcia/B-9765-2012","Pantano, Glaucia/0000-0001-5868-4300; Tadini, Amanda Maria/0000-0003-2571-4125; Bisinoti, Márcia/0000-0002-4631-2400; Moreira, Altair/0000-0001-7903-2360",Seasonal variability of a conditional stability constant and the characterization of sedimentary humic substances from typical agricultural and urban areas,14,2,10.1007/s11368-013-0710-6 ,Article ,2014.0,"Brazil is the largest producer of sugarcane in the world. This extensive production of sugarcane has changed the use and form of Brazilian soil, causing changes in the structural characteristics of humic substances (HS). In this context, the main objective of this study was to evaluate the effect of seasonality on a conditional stability constant (Kc) of the complexes HS-Cu (II) and HS-Cr (III) from the HS of urban and agricultural regions, with an emphasis on sugarcane culture.The study was conducted in the northwestern region of the state of So Paulo, which is the leading producer of sugar and ethanol in the country and is the region with the lowest percentage of riparian vegetation (3 %). Sediments were sampled during the rainy and dry seasons at four locations: (1) a typical agricultural area, (2) an urban area, (3) a sugarcane cultivation area, (4) and an area that receives the entire pollutant load from the hydrographic basin. The HS were extracted and characterized using conventional techniques. The Kc of the HS with copper (Cu) and chromium (Cr) ions was determined by fluorescence suppression employing the Stern-Volmer model.Kc values were higher in the rainy seasons for HS-Cu (II) and HS-Cr (III). The highest value of Kc for the HS with Cu (1.23) and Cr (5.2 x 10(-1)) ions was found during the rainy season in the area receiving the pollutant load from the basin and in the typical area of sugarcane cultivation, respectively. All of the FTIR spectra showed characteristic bands of HS, and the values of the E-4/E-6 ratio confirmed the presence of more aromatic groups. An elemental analysis and molecular fluorescence spectra in the emission mode confirmed that the HS from the agricultural area and sugarcane culture area mostly exhibited characteristics of humic acids and that the HS from the urban area and the area receiving the pollutant load from the basin had a mixture of humic and fulvic acids.We can conclude that HS-metal complexes from the area that received the entire load of pollutants from the watershed and the typical area of sugarcane culture showed the highest stability among the study areas. The Kc values found in the basin were lower than those previously obtained by several studies that were performed in other locations. The HS obtained in rainy season had more aromatic groups in the HS structure, and the HS from the sugarcane area presented more characteristics of humic acids.",1439-0108,1614-7480,,385-393, , ,,out_of_scope,
4113,"Title:Base-Metal-Electroded Piezoelectric Transformers - Towards Pb-Free Components -

 Piezoelectric transformers (PTs) have widely been used in the backlight inverter for lap-top computers. Now, the development of the PTs trends from step-up to step-down adapters. Accordingly, the required output impedance became from high to low, leading to the design change from a long plate to a high capacitance multilayer disk type. On the other hand, though lead oxide based piezoelectrics such as lead zirconate titanate (Pb(Zr,Ti)O-3 or PZT) still remain the most popular material for actuator, sensor and transducer applications, the toxicity of lead in PZT has been pointed out and the restriction of PZT usage may be taken effect in the future. Pb-free piezoelectrics have been extensively studied in these days. This paper reports two-fold technological approaches, (1) high-power density multilayer PT designing principle, and (2) high power characterization of the present Pb-fee piezoelectrics, aiming at realization of non-lead piezoelectric transformers.","Uchino, K.; Ural, S. O.; Tuncdemir, S.; Gurdal, E. A.; Park, H. -Y.; Nahm, S.",,,Base-Metal-Electroded Piezoelectric Transformers - Towards Pb-Free Components -,,, ,Proceedings Paper ,2010.0,"Piezoelectric transformers (PTs) have widely been used in the backlight inverter for lap-top computers. Now, the development of the PTs trends from step-up to step-down adapters. Accordingly, the required output impedance became from high to low, leading to the design change from a long plate to a high capacitance multilayer disk type. On the other hand, though lead oxide based piezoelectrics such as lead zirconate titanate (Pb(Zr,Ti)O-3 or PZT) still remain the most popular material for actuator, sensor and transducer applications, the toxicity of lead in PZT has been pointed out and the restriction of PZT usage may be taken effect in the future. Pb-free piezoelectrics have been extensively studied in these days. This paper reports two-fold technological approaches, (1) high-power density multilayer PT designing principle, and (2) high power characterization of the present Pb-fee piezoelectrics, aiming at realization of non-lead piezoelectric transformers.",,,978-3-933339-12-6,130-+, , 12th International Conference on New Actuators/6th International Exhibition on Smart Actuators and Drive Systems12th International Conference on New Actuators/6th International Exhibition on Smart Actuators and Drive Systems,,out_of_scope,
4114,"Title:Comparison between Machine Learning and Deep Learning Approaches for the Detection of Toxic Comments on Social Networks

 The way we communicate has been revolutionised by the widespread use of social networks. Any kind of online message can reach anyone in the world almost instantly. The speed with which information spreads is undoubtedly the strength of social networks, but at the same time, any user of these platforms can see how toxic messages spread in parallel with likes, comments and ratings about any person or entity. In such cases, the victim feels even more helpless and defenceless as a result of the rapid spread. For this reason, we have implemented an automatic detector of toxic messages on social media. This allows us to stop toxicity in its tracks and protect victims. In particular, the aim of the survey is to demonstrate how traditional Machine Learning methods of Natural Language Processing (NLP) work on equal terms with Deep Learning methods represented by a Transformer architecture and characterised by a higher computational cost. In particular, the paper describes the results obtained by testing different supervised Machine Learning classifiers (Logistic Regression, Random Forest and Support Vector Machine) combined with two topic-modelling techniques of NLP, (Latent Semantic Analysis and Latent Dirichlet Allocation). A pre-trained Transformer named BERTweet was also tested. All models performed well in this task, so much so that values close to or above 90% were achieved in terms of the F1 score evaluation metric. The best result achieved by Transformer BERTweet, 91.40%, was therefore not impressive in this context, as the performance gains are too small compared to the computational overhead.","Bonetti, Andrea; Martinez-Sober, Marcelino; Torres, Julio C.; Vega, Jose M.; Pellerin, Sebastien; Vila-Frances, Joan",,"Vila Frances, Joan/0000-0001-8293-8235",Comparison between Machine Learning and Deep Learning Approaches for the Detection of Toxic Comments on Social Networks,13,10,10.3390/app13106038 ,Article ,2023.0,"The way we communicate has been revolutionised by the widespread use of social networks. Any kind of online message can reach anyone in the world almost instantly. The speed with which information spreads is undoubtedly the strength of social networks, but at the same time, any user of these platforms can see how toxic messages spread in parallel with likes, comments and ratings about any person or entity. In such cases, the victim feels even more helpless and defenceless as a result of the rapid spread. For this reason, we have implemented an automatic detector of toxic messages on social media. This allows us to stop toxicity in its tracks and protect victims. In particular, the aim of the survey is to demonstrate how traditional Machine Learning methods of Natural Language Processing (NLP) work on equal terms with Deep Learning methods represented by a Transformer architecture and characterised by a higher computational cost. In particular, the paper describes the results obtained by testing different supervised Machine Learning classifiers (Logistic Regression, Random Forest and Support Vector Machine) combined with two topic-modelling techniques of NLP, (Latent Semantic Analysis and Latent Dirichlet Allocation). A pre-trained Transformer named BERTweet was also tested. All models performed well in this task, so much so that values close to or above 90% were achieved in terms of the F1 score evaluation metric. The best result achieved by Transformer BERTweet, 91.40%, was therefore not impressive in this context, as the performance gains are too small compared to the computational overhead.",,2076-3417,,, , ,,detection#evaluation,
4115,"Title:Disentangling Representations of Text by Masking Transformers

 Representations from large pretrained models such as BERT encode a range of features into monolithic vectors, affording strong predictive accuracy across a range of downstream tasks. In this paper we explore whether it is possible to learn disentangled representations by identifying existing subnetworks within pretrained models that encode distinct, complementary aspects. Concretely, we learn binary masks over transformer weights or hidden units to uncover subsets of features that correlate with a specific factor of variation; this eliminates the need to train a disentangled model from scratch for a particular task. We evaluate this method with respect to its ability to disentangle representations of sentiment from genre in movie reviews, toxicity from dialect in Tweets, and syntax from semantics. By combining masking with magnitude pruning we find that we can identify sparse subnetworks within BERT that strongly encode particular aspects (e.g., semantics) while only weakly encoding others (e.g., syntax). Moreover, despite only learning masks, disentanglement-via-masking performs as well as - and often better than - previously proposed methods based on variational autoencoders and adversarial training.","Zhang, Xiongyi; van de Meent, Jan-Willem; Wallace, Byron C.",,,Disentangling Representations of Text by Masking Transformers,,, ,Proceedings Paper ,2021.0,"Representations from large pretrained models such as BERT encode a range of features into monolithic vectors, affording strong predictive accuracy across a range of downstream tasks. In this paper we explore whether it is possible to learn disentangled representations by identifying existing subnetworks within pretrained models that encode distinct, complementary aspects. Concretely, we learn binary masks over transformer weights or hidden units to uncover subsets of features that correlate with a specific factor of variation; this eliminates the need to train a disentangled model from scratch for a particular task. We evaluate this method with respect to its ability to disentangle representations of sentiment from genre in movie reviews, toxicity from dialect in Tweets, and syntax from semantics. By combining masking with magnitude pruning we find that we can identify sparse subnetworks within BERT that strongly encode particular aspects (e.g., semantics) while only weakly encoding others (e.g., syntax). Moreover, despite only learning masks, disentanglement-via-masking performs as well as - and often better than - previously proposed methods based on variational autoencoders and adversarial training.",,,978-1-955917-09-4,778-791, , Conference on Empirical Methods in Natural Language Processing (EMNLP)Conference on Empirical Methods in Natural Language Processing (EMNLP),,out_of_scope,
4116,"Title:Liquid metal coil

 Metal coils are typically used as motors, inductors, transformers, and loop antennas, which are essential and ubiquitous elements in electronics. With the improvement of living standards and the demand for compliant technologies, flexible electronics are thriving as new frontiers in diverse areas. Along with that, various soft circuits and electronic components are urgently required to replace those traditional rigid ones, in order to tackle existing challenges. Among those materials to realize device flexibility, room temperature liquid metals are playing ever important roles instead of conventional metal components due to their outstanding fluidity, large conductivity, and non-toxicity. In this review, we summarized and classified the transformable properties of liquid metal coils (LMCs) as four fundamental passive electronic components: resistor, capacitor, inductor, and memristor. The fabrication methods of LMCs are illustrated. Then we concluded LMCs' contributions to soft actuation, flexible sensing, antenna, and so on, which would be conducive to the fields such as wearable and implantable devices, soft robotics, and medical instruments. Finally, the current challenges in LMC's practical applications and outlook have been discussed.","Ye, Jiao; Xing, Ze-Rong; Gao, Jian-Ye; Liu, Jing","zhao, yujie/JLL-1283-2023; cao, yutong/JJF-4531-2023; qi, li/JFE-7167-2023; wang, qi/ITT-9652-2023; li, zhang/JHV-1750-2023; Liu, Jing/IQX-0664-2023; li, bai/JNE-1502-2023; wu, p/JDW-5015-2023","Gao, Jianye/0000-0003-4024-4758; Xing, Zerong/0000-0001-9832-5986",Liquid metal coil,32,,10.1016/j.mtcomm.2022.104120 ,Article ,2022.0,"Metal coils are typically used as motors, inductors, transformers, and loop antennas, which are essential and ubiquitous elements in electronics. With the improvement of living standards and the demand for compliant technologies, flexible electronics are thriving as new frontiers in diverse areas. Along with that, various soft circuits and electronic components are urgently required to replace those traditional rigid ones, in order to tackle existing challenges. Among those materials to realize device flexibility, room temperature liquid metals are playing ever important roles instead of conventional metal components due to their outstanding fluidity, large conductivity, and non-toxicity. In this review, we summarized and classified the transformable properties of liquid metal coils (LMCs) as four fundamental passive electronic components: resistor, capacitor, inductor, and memristor. The fabrication methods of LMCs are illustrated. Then we concluded LMCs' contributions to soft actuation, flexible sensing, antenna, and so on, which would be conducive to the fields such as wearable and implantable devices, soft robotics, and medical instruments. Finally, the current challenges in LMC's practical applications and outlook have been discussed.",,2352-4928,,, , ,,out_of_scope,
4117,"Title:Automatic Segmentation of Target Structures for Total Marrow and Lymphoid Irradiation in Bone Marrow Transplantation.

 The use of total marrow and lymphoid irradiation (TMLI) as part of conditioning regimens for bone marrow transplantation is trending due to its advantages in disease control and low toxicity. Accurate contouring of target structures such as bone and lymph nodes plays an important role in irradiation planning. However, this process is often time-consuming and prone to inter-observer variation. Recently, deep learning methods such as convolutional neural networks (CNNs) and vision transformers have achieved tremendous success in medical image segmentation, therefore enabling fast semiautomatic radiotherapy planning. In this paper, we propose a dual-encoder U-shaped model named DE-Net, to automatically segment the target structures for TMLI. To enhance the learned features, the encoder of DE-Net is composed of parallel CNNs and vision transformers, which can model both local and global contexts. The multi-level features from the two branches are progressively fused by intermediate modules, therefore effectively preserving low-level details. Our experiments demonstrate that the proposed method achieves state-of-the-art results and a significant improvement in lymph node segmentation compared with existing methods.","Shi, Jun; Wang, Zhaohui; Kan, Hongyu; Zhao, Minfan; Xue, Xudong; Yan, Bing; An, Hong; Shen, Jianjun; Bartlett, Joseph; Lu, Wenqi; Duan, Jinming",,"Shi, Jun/0000-0002-9888-6238",Automatic Segmentation of Target Structures for Total Marrow and Lymphoid Irradiation in Bone Marrow Transplantation.,2022,,10.1109/EMBC48229.2022.9871824 ,"Journal Article; Research Support, Non-U.S. Gov't ",2022.0,"The use of total marrow and lymphoid irradiation (TMLI) as part of conditioning regimens for bone marrow transplantation is trending due to its advantages in disease control and low toxicity. Accurate contouring of target structures such as bone and lymph nodes plays an important role in irradiation planning. However, this process is often time-consuming and prone to inter-observer variation. Recently, deep learning methods such as convolutional neural networks (CNNs) and vision transformers have achieved tremendous success in medical image segmentation, therefore enabling fast semiautomatic radiotherapy planning. In this paper, we propose a dual-encoder U-shaped model named DE-Net, to automatically segment the target structures for TMLI. To enhance the learned features, the encoder of DE-Net is composed of parallel CNNs and vision transformers, which can model both local and global contexts. The multi-level features from the two branches are progressively fused by intermediate modules, therefore effectively preserving low-level details. Our experiments demonstrate that the proposed method achieves state-of-the-art results and a significant improvement in lymph node segmentation compared with existing methods.",,2694-0604,,5025-5029, , ,,out_of_scope,
4118,"Title:Natural Language Processing to Automatically Extract the Presence and Severity of Esophagitis in Notes of Patients Undergoing Radiotherapy.

 PURPOSE: Radiotherapy (RT) toxicities can impair survival and quality of life, yet remain understudied. Real-world evidence holds potential to improve our understanding of toxicities, but toxicity information is often only in clinical notes. We developed natural language processing (NLP) models to identify the presence and severity of esophagitis from notes of patients treated with thoracic RT.METHODS: Our corpus consisted of a gold-labeled data set of 1,524 clinical notes from 124 patients with lung cancer treated with RT, manually annotated for Common Terminology Criteria for Adverse Events (CTCAE) v5.0 esophagitis grade, and a silver-labeled data set of 2,420 notes from 1,832 patients from whom toxicity grades had been collected as structured data during clinical care. We fine-tuned statistical and pretrained Bidirectional Encoder Representations from Transformers-based models for three esophagitis classification tasks: task 1, no esophagitis versus grade 1-3; task 2, grade ≤1 versus >1; and task 3, no esophagitis versus grade 1 versus grade 2-3. Transferability was tested on 345 notes from patients with esophageal cancer undergoing RT.RESULTS: Fine-tuning of PubMedBERT yielded the best performance. The best macro-F1 was 0.92, 0.82, and 0.74 for tasks 1, 2, and 3, respectively. Selecting the most informative note sections during fine-tuning improved macro-F1 by ≥2% for all tasks. Silver-labeled data improved the macro-F1 by ≥3% across all tasks. For the esophageal cancer notes, the best macro-F1 was 0.73, 0.74, and 0.65 for tasks 1, 2, and 3, respectively, without additional fine-tuning.CONCLUSION: To our knowledge, this is the first effort to automatically extract esophagitis toxicity severity according to CTCAE guidelines from clinical notes. This provides proof of concept for NLP-based automated detailed toxicity monitoring in expanded domains.","Chen, Shan; Guevara, Marco; Ramirez, Nicolas; Murray, Arpi; Warner, Jeremy L; Aerts, Hugo J W L; Miller, Timothy A; Savova, Guergana K; Mak, Raymond H; Bitterman, Danielle S","; Aerts, Hugo/ABF-2821-2020","Bitterman, Danielle/0000-0003-0345-2232; Chen, Shan/0000-0001-7999-7410; Warner, Jeremy/0000-0002-2851-7242; Aerts, Hugo/0000-0002-2122-2003; Mak, Raymond/0000-0002-8754-0565",Natural Language Processing to Automatically Extract the Presence and Severity of Esophagitis in Notes of Patients Undergoing Radiotherapy.,7,,10.1200/CCI.23.00048 ,"Journal Article; Research Support, Non-U.S. Gov't ",2023.0,"PURPOSE: Radiotherapy (RT) toxicities can impair survival and quality of life, yet remain understudied. Real-world evidence holds potential to improve our understanding of toxicities, but toxicity information is often only in clinical notes. We developed natural language processing (NLP) models to identify the presence and severity of esophagitis from notes of patients treated with thoracic RT.METHODS: Our corpus consisted of a gold-labeled data set of 1,524 clinical notes from 124 patients with lung cancer treated with RT, manually annotated for Common Terminology Criteria for Adverse Events (CTCAE) v5.0 esophagitis grade, and a silver-labeled data set of 2,420 notes from 1,832 patients from whom toxicity grades had been collected as structured data during clinical care. We fine-tuned statistical and pretrained Bidirectional Encoder Representations from Transformers-based models for three esophagitis classification tasks: task 1, no esophagitis versus grade 1-3; task 2, grade ≤1 versus >1; and task 3, no esophagitis versus grade 1 versus grade 2-3. Transferability was tested on 345 notes from patients with esophageal cancer undergoing RT.RESULTS: Fine-tuning of PubMedBERT yielded the best performance. The best macro-F1 was 0.92, 0.82, and 0.74 for tasks 1, 2, and 3, respectively. Selecting the most informative note sections during fine-tuning improved macro-F1 by ≥2% for all tasks. Silver-labeled data improved the macro-F1 by ≥3% across all tasks. For the esophageal cancer notes, the best macro-F1 was 0.73, 0.74, and 0.65 for tasks 1, 2, and 3, respectively, without additional fine-tuning.CONCLUSION: To our knowledge, this is the first effort to automatically extract esophagitis toxicity severity according to CTCAE guidelines from clinical notes. This provides proof of concept for NLP-based automated detailed toxicity monitoring in expanded domains.",,2473-4276,,e2300048-e2300048, , ,,out_of_scope,
4119,"Title:A Toxic Style Transfer Method Based on the Delete-Retrieve-Generate Framework Exploiting Toxic Lexicon Semantic Similarity

 Whether consciously or inadvertently, our messages can include toxic language which contributes to the polarization of social networks. Intelligent techniques can help us detect these expressions and even change them into kinder expressions by applying style transfer techniques. This work aims to advance detoxification style transfer techniques using deep learning and semantic similarity technologies. The article explores the advantages of a toxicity-deletion method that uses linguistic resources in a detoxification system. For this purpose, we propose a method that removes toxic words from the source sentence using a similarity function with a toxic vocabulary. We present two models that leverage it, namely, LexiconGST and MultiLexiconGST, which are based on the Delete -Retrieve-Generate framework. Experimental results show that our models perform well in the detoxification task compared to other state-of-the-art methods. Finally, this research confirms that linguistic resources can guide deep learning techniques and improve their performance.","Iglesias, Martin; Araque, Oscar; Iglesias, Carlos A.","IGLESIAS FERNANDEZ, CARLOS ANGEL/I-2181-2015","IGLESIAS FERNANDEZ, CARLOS ANGEL/0000-0002-1755-2712; Iglesias Goyanes, Martin/0009-0003-6614-9828; Araque, Oscar/0000-0003-3224-0001",A Toxic Style Transfer Method Based on the Delete-Retrieve-Generate Framework Exploiting Toxic Lexicon Semantic Similarity,13,15,10.3390/app13158590 ,Article ,2023.0,"Whether consciously or inadvertently, our messages can include toxic language which contributes to the polarization of social networks. Intelligent techniques can help us detect these expressions and even change them into kinder expressions by applying style transfer techniques. This work aims to advance detoxification style transfer techniques using deep learning and semantic similarity technologies. The article explores the advantages of a toxicity-deletion method that uses linguistic resources in a detoxification system. For this purpose, we propose a method that removes toxic words from the source sentence using a similarity function with a toxic vocabulary. We present two models that leverage it, namely, LexiconGST and MultiLexiconGST, which are based on the Delete -Retrieve-Generate framework. Experimental results show that our models perform well in the detoxification task compared to other state-of-the-art methods. Finally, this research confirms that linguistic resources can guide deep learning techniques and improve their performance.",,2076-3417,,, , ,,detox#methodology,
4120,"Title:Stat3 shRNA delivery with folate receptor-modified multi-functionalized graphene oxide particles for combined infrared radiation and gene therapy in hepatocellular carcinoma

 As a vital oncogene, a variety of inhibitors targeting Stat3 and its various upstream signaling pathways has been explored. Since small molecules, peptidomimetics and other peptide inhibitors usually lead to side effects and difficult administration, gene therapeutics that have characteristics of low toxicity and high targeting, make them an attractive alternative for targeting Stat3. A major challenge to this approach is the lack of safe delivery systems for in-vivo applications. Among the various siRNA delivery systems, nanoparticles emerge as a new tool for gene delivery with high biocompatibility, low cost, and minimal toxicity. In this study, we developed a graphene oxide (GO)-based nanocarrier, GO-polyethyleneimine (PEI)-polyethylene glycol (PEG)-folic acid (FA), as a tool targeting for Stat3-specific shRNA to mouse hepatoma cells in vitro and in vivo. Infrared photothermal therapy was combined in vivo since GO has the characteristic of infrared absorbability. Our results suggest a significant tumor growth inhibition after treatment with GO-PEI-PEG-FA-sh-Stat3 combined with infrared photothermal therapy. Thus, GO-PEI-PEG-FA appears to be a novel nano-transformer that could be used in the clinics in future.","Chen, Xuyang; Zhang, Ling; Wang, Xiaoqin; Xu, Libo; Sun, Jicheng; Liu, Yiran; Liu, Xiaorui; Kalvakolanu, Dhan, V; Guo, Baofeng","liu, yiran/JDW-2246-2023; Chen, Xuyang/JEO-6530-2023",,Stat3 shRNA delivery with folate receptor-modified multi-functionalized graphene oxide particles for combined infrared radiation and gene therapy in hepatocellular carcinoma,34,6,10.1097/CAD.0000000000001461 ,Article ,2023.0,"As a vital oncogene, a variety of inhibitors targeting Stat3 and its various upstream signaling pathways has been explored. Since small molecules, peptidomimetics and other peptide inhibitors usually lead to side effects and difficult administration, gene therapeutics that have characteristics of low toxicity and high targeting, make them an attractive alternative for targeting Stat3. A major challenge to this approach is the lack of safe delivery systems for in-vivo applications. Among the various siRNA delivery systems, nanoparticles emerge as a new tool for gene delivery with high biocompatibility, low cost, and minimal toxicity. In this study, we developed a graphene oxide (GO)-based nanocarrier, GO-polyethyleneimine (PEI)-polyethylene glycol (PEG)-folic acid (FA), as a tool targeting for Stat3-specific shRNA to mouse hepatoma cells in vitro and in vivo. Infrared photothermal therapy was combined in vivo since GO has the characteristic of infrared absorbability. Our results suggest a significant tumor growth inhibition after treatment with GO-PEI-PEG-FA-sh-Stat3 combined with infrared photothermal therapy. Thus, GO-PEI-PEG-FA appears to be a novel nano-transformer that could be used in the clinics in future.",0959-4973,1473-5741,,715-724, , ,,out_of_scope,
4121,"Title:Monitoring beam charge during FLASH irradiations

 In recent years, FLASH irradiation has attracted significant interest in radiation research. Studies have shown that irradiation at ultra-high dose rates (FLASH) reduces the severity of toxicities in normal tissues compared to irradiation at conventional dose rates (CONV), as currently used in clinical practice. Most pre-clinical work is currently carried out using charged particle beams and the beam charge monitor described here is relevant to such beams. Any biological effect comparisons between FLASH and CONV irradiations rely on measurement of tissue dose. While well-established approaches can be used to monitor, in real time, the dose delivered during CONV irradiations, monitoring FLASH doses is not so straightforward. Recently the use of non-intercepting beam current transformers (BCTs) has been proposed for FLASH work. Such BCTs have been used for decades in numerous accelerator installations to monitor temporal and intensity beam profiles. In order to serve as monitoring dosimeters, the BCT output current must be integrated, using electronic circuitry or using software integration following signal digitisation. While sensitive enough for FLASH irradiation, where few intense pulses deliver the requisite dose, the inherent insensitivity of BCTs and the need for a wide detection bandwidth makes them less suitable for use during CONV reference irradiations. The purpose of this article is to remind the FLASH community of a different mode of BCT operation: direct monitoring of charge, rather than current, achieved by loading the BCT capacitively rather than resistively. The resulting resonant operation achieves very high sensitivities, enabling straightforward monitoring of output during both CONV and FLASH regimes. Historically, such inductive charge monitors have been used for single pulse work; however, a straightforward circuit modification allows selective resonance damping when repetitive pulsing is used, as during FLASH and CONV irradiations. Practical means of achieving this are presented, as are construction and signal processing details. Finally, results are presented showing the beneficial behaviour of the BCT versus an (Advanced Markus) ionisation chamber for measurements over a dose rate range, from <0.1 Gys(-1) to >3 kGys(-1).","Vojnovic, Borivoj; Tullis, Iain D. C.; Newman, Robert G.; Petersson, Kristoffer",,,Monitoring beam charge during FLASH irradiations,11,,10.3389/fphy.2023.1185237 ,Article ,2023.0,"In recent years, FLASH irradiation has attracted significant interest in radiation research. Studies have shown that irradiation at ultra-high dose rates (FLASH) reduces the severity of toxicities in normal tissues compared to irradiation at conventional dose rates (CONV), as currently used in clinical practice. Most pre-clinical work is currently carried out using charged particle beams and the beam charge monitor described here is relevant to such beams. Any biological effect comparisons between FLASH and CONV irradiations rely on measurement of tissue dose. While well-established approaches can be used to monitor, in real time, the dose delivered during CONV irradiations, monitoring FLASH doses is not so straightforward. Recently the use of non-intercepting beam current transformers (BCTs) has been proposed for FLASH work. Such BCTs have been used for decades in numerous accelerator installations to monitor temporal and intensity beam profiles. In order to serve as monitoring dosimeters, the BCT output current must be integrated, using electronic circuitry or using software integration following signal digitisation. While sensitive enough for FLASH irradiation, where few intense pulses deliver the requisite dose, the inherent insensitivity of BCTs and the need for a wide detection bandwidth makes them less suitable for use during CONV reference irradiations. The purpose of this article is to remind the FLASH community of a different mode of BCT operation: direct monitoring of charge, rather than current, achieved by loading the BCT capacitively rather than resistively. The resulting resonant operation achieves very high sensitivities, enabling straightforward monitoring of output during both CONV and FLASH regimes. Historically, such inductive charge monitors have been used for single pulse work; however, a straightforward circuit modification allows selective resonance damping when repetitive pulsing is used, as during FLASH and CONV irradiations. Practical means of achieving this are presented, as are construction and signal processing details. Finally, results are presented showing the beneficial behaviour of the BCT versus an (Advanced Markus) ionisation chamber for measurements over a dose rate range, from <0.1 Gys(-1) to >3 kGys(-1).",2296-424X,,,, , ,,out_of_scope,
4122,"Series([], Name: Abstract, dtype: object)","KENNEDY, MCS; ROUTLEDGE, R",,,INVESTIGATION OF A MINOR ASBESTOS HAZARD,24,3, ,Article ,1967.0,"Series([], Name: Abstract, dtype: object)",0007-1072,,,232-+, , ,,out_of_scope,
4123,"Title:Developing a Novel Environmental Friendly Polyester-imide Impregnating Resin

 In this article, a novel environmental friendly polyester-imide impregnating resin was developed by combining polyester-imide, novel active cross-linking monomer and effective initiator-inhibitor system. The new resin has excellent processing abilities, suitable for usual dipping, VPI, and dip-rolling machines. The comprehensive performance of this new resin was investigated systematically, including curing reaction, volatile material content, bond strength, volume shrinkage rate, heat resistance, storage stability, application performance of impregnating mica tape, acute toxicity, and skin irritation. The results indicate that the new resin has many excellent characteristics, such as fast curing at low-temperature, very low volatile material content, low volume shrinkage rate, excellent bond strength and heat resistance above Class H temperature, excellent storage stability without cold storage, and good electrical insulation properties with mica tape as main wall insulation. The new resin can be used for both low and medium voltage rotating machines and transformers. It is an excellent substitution to common unsaturated polyester impregnating resins by complying with the global environmental policy, and has a significant effect on upgrading insulating impregnating resin products and environmental improvement of insulation impregnating in the areas of motors and electrical equipment industry.","Xia, Yu; Zhou, Cheng; Wang, We; Wen, Xueping; He, Shaobo; Chen, William",,,Developing a Novel Environmental Friendly Polyester-imide Impregnating Resin,,, ,Proceedings Paper ,2015.0,"In this article, a novel environmental friendly polyester-imide impregnating resin was developed by combining polyester-imide, novel active cross-linking monomer and effective initiator-inhibitor system. The new resin has excellent processing abilities, suitable for usual dipping, VPI, and dip-rolling machines. The comprehensive performance of this new resin was investigated systematically, including curing reaction, volatile material content, bond strength, volume shrinkage rate, heat resistance, storage stability, application performance of impregnating mica tape, acute toxicity, and skin irritation. The results indicate that the new resin has many excellent characteristics, such as fast curing at low-temperature, very low volatile material content, low volume shrinkage rate, excellent bond strength and heat resistance above Class H temperature, excellent storage stability without cold storage, and good electrical insulation properties with mica tape as main wall insulation. The new resin can be used for both low and medium voltage rotating machines and transformers. It is an excellent substitution to common unsaturated polyester impregnating resins by complying with the global environmental policy, and has a significant effect on upgrading insulating impregnating resin products and environmental improvement of insulation impregnating in the areas of motors and electrical equipment industry.",,,978-1-4799-7354-5,551-554, , 33rd IEEE Electrical Insulation Conference (EIC)33rd IEEE Electrical Insulation Conference (EIC),,out_of_scope,
4124,"Title:Transcriptomic evidence for versatile metabolic activities of mercury cycling microorganisms in brackish microbial mats

 Methylmercury, biomagnifying through food chains, is highly toxic for aquatic life. Its production and degradation are largely driven by microbial transformations; however, diversity and metabolic activity of mercury transformers, resulting in methylmercury concentrations in environments, remain poorly understood. Microbial mats are thick biofilms where oxic and anoxic metabolisms cooccur, providing opportunities to investigate the complexity of the microbial mercury transformations over contrasted redox conditions. Here, we conducted a genome-resolved metagenomic and metatranscriptomic analysis to identify putative activity of mercury reducers, methylators and demethylators in microbial mats strongly contaminated by mercury. Our transcriptomic results revealed the major role of rare microorganisms in mercury cycling. Mercury methylators, mainly related to Desulfobacterota, expressed a large panel of metabolic activities in sulfur, iron, nitrogen, and halogen compound transformations, extending known activities of mercury methylators under suboxic to anoxic conditions. Methylmercury detoxification processes were dissociated in the microbial mats with methylmercury cleavage being carried out by sulfide-oxidizing Thiotrichaceae and Rhodobacteraceae populations, whereas mercury reducers included members of the Verrucomicrobia, Bacteroidetes, Gammaproteobacteria, and different populations of Rhodobacteraceae. However most of the mercury reduction was potentially carried out anaerobically by sulfur- and iron-reducing Desulfuromonadaceae, revising our understanding of mercury transformers ecophysiology.","Vigneron, Adrien; Cruaud, Perrine; Aube, Johanne; Guyoneaud, Remy; Goni-Urriza, Marisol","Goni Urriza, Marisol/F-1843-2013","Goni Urriza, Marisol/0000-0001-7694-6511; Aube, Johanne/0000-0001-9677-2950; Vigneron, Adrien/0000-0003-3552-8369; Cruaud, Perrine/0000-0001-8628-3600",Transcriptomic evidence for versatile metabolic activities of mercury cycling microorganisms in brackish microbial mats,7,1,10.1038/s41522-021-00255-y ,Article ,2021.0,"Methylmercury, biomagnifying through food chains, is highly toxic for aquatic life. Its production and degradation are largely driven by microbial transformations; however, diversity and metabolic activity of mercury transformers, resulting in methylmercury concentrations in environments, remain poorly understood. Microbial mats are thick biofilms where oxic and anoxic metabolisms cooccur, providing opportunities to investigate the complexity of the microbial mercury transformations over contrasted redox conditions. Here, we conducted a genome-resolved metagenomic and metatranscriptomic analysis to identify putative activity of mercury reducers, methylators and demethylators in microbial mats strongly contaminated by mercury. Our transcriptomic results revealed the major role of rare microorganisms in mercury cycling. Mercury methylators, mainly related to Desulfobacterota, expressed a large panel of metabolic activities in sulfur, iron, nitrogen, and halogen compound transformations, extending known activities of mercury methylators under suboxic to anoxic conditions. Methylmercury detoxification processes were dissociated in the microbial mats with methylmercury cleavage being carried out by sulfide-oxidizing Thiotrichaceae and Rhodobacteraceae populations, whereas mercury reducers included members of the Verrucomicrobia, Bacteroidetes, Gammaproteobacteria, and different populations of Rhodobacteraceae. However most of the mercury reduction was potentially carried out anaerobically by sulfur- and iron-reducing Desulfuromonadaceae, revising our understanding of mercury transformers ecophysiology.",,2055-5008,,, , ,,out_of_scope,
4125,"Title:A graph neural network approach for molecule carcinogenicity prediction

 Motivation: Molecular carcinogenicity is a preventable cause of cancer, but systematically identifying carcinogenic compounds, which involves performing experiments on animal models, is expensive, time consuming and low throughput. As a result, carcinogenicity information is limited and building data-driven models with good prediction accuracy remains a major challenge.Results: In this work, we propose CONCERTO, a deep learning model that uses a graph transformer in conjunction with a molecular fingerprint representation for carcinogenicity prediction from molecular structure. Special efforts have been made to overcome the data size constraint, such as multi-round pre-training on related but lower quality mutagenicity data, and transfer learning from a large self-supervised model. Extensive experiments demonstrate that our model performs well and can generalize to external validation sets. CONCERTO could be useful for guiding future carcinogenicity experiments and provide insight into the molecular basis of carcinogenicity.","Fradkin, Philip; Young, Adamo; Atanackovic, Lazar; Frey, Brendan; Lee, Leo J.; Wang, Bo","Wang, Bo/HDO-6738-2022","Wang, Bo/0000-0002-9620-3413",A graph neural network approach for molecule carcinogenicity prediction,38,SUPPL 1,10.1093/bioinformatics/btac266 ,Article; Proceedings Paper ,2022.0,"Motivation: Molecular carcinogenicity is a preventable cause of cancer, but systematically identifying carcinogenic compounds, which involves performing experiments on animal models, is expensive, time consuming and low throughput. As a result, carcinogenicity information is limited and building data-driven models with good prediction accuracy remains a major challenge.Results: In this work, we propose CONCERTO, a deep learning model that uses a graph transformer in conjunction with a molecular fingerprint representation for carcinogenicity prediction from molecular structure. Special efforts have been made to overcome the data size constraint, such as multi-round pre-training on related but lower quality mutagenicity data, and transfer learning from a large self-supervised model. Extensive experiments demonstrate that our model performs well and can generalize to external validation sets. CONCERTO could be useful for guiding future carcinogenicity experiments and provide insight into the molecular basis of carcinogenicity.",1367-4803,1460-2059,,84-91, , 30th Annual Conference on Intelligent Systems for Molecular Biology (ISMB)30th Annual Conference on Intelligent Systems for Molecular Biology (ISMB),,out_of_scope,
4126,"Title:Piezoelectric Actuators 2010-Piezoelectric Devices in the Sustainable Society

 Our 21(st) century will face to a sustainable society, which requires (a) usage of non-toxic materials, (b) disposal technology for existing hazardous materials, (c) new energy source creation, and (d) energy-efficient device development. Electric components such as motors and transformers are mostly based on electromagnetic transduction at present. With reducing their size, these electromagnetic components reduce their efficiency drastically due to the Joule heat in their thin coil wire (i.e., the resistance in the coil becomes significant). Thus, piezoelectric actuators and transducers with much less losses are highly sought after in the 21 century. In the past 30 years, most researchers have put efforts on improving the piezoelectric performance from the real-part property's viewpoint: that is, improved displacement, force, responsivity etc. However, from the viewpoint of efficiency and reliability such as heat generation or performance degradation under high voltage/power drive, the key is the imaginary-part; that is, loss and hysteresis mechanisms.Piezoelectric devices seem to be all-around contributors and a key component to the above mentioned four R&D areas in the sustainable society. Some of the efforts include: (a) Since the most widely used piezoelectric lead zirconate titante (PZT) ceramics will be regulated in less than 10 years in European and Japanese communities due to their toxicity (Pb(2+) ion), lead-free piezoelectric ceramics based on (K,Na)(Ta,Nb)O(3) and (Bi,Na,Ba)TiO(3) have been developed with performance equivalent to the PZTs. (b) Since hazardous organic substances such as dioxin can be easily dissolved by the irradiation of ultrasonic energy in water, a new technology for safe disposal of dioxin using high-power piezoelectric transducers has been developed. (c) We demonstrated an energy recovery system on a hybrid car from its engine's mechanical vibration to the fuel cell for electric charging. A self-powered remote light switching system has also been developed using piezoelectric bimorphs. (d) Micro ultrasonic motors based on piezoelectrics demonstrated 1/20 reduction in the volume and weight and a 20 time increase in efficiency of the conventional electromagnetic motors with equivalent output power. We also demonstrated compact and highly-efficient high-voltage supplies with piezoelectric transformers, which have been widely commercialized for laptop backlight inverter applications. The key to improving efficiency is the development of low loss piezoelectrics.This paper introduces leading piezoelectric materials, devices, and drive/control methods, relating with the above sustainability technologies, aiming at further research expansion in this area.","Uchino, Kenji",,,Piezoelectric Actuators 2010-Piezoelectric Devices in the Sustainable Society,,, ,Proceedings Paper ,2010.0,"Our 21(st) century will face to a sustainable society, which requires (a) usage of non-toxic materials, (b) disposal technology for existing hazardous materials, (c) new energy source creation, and (d) energy-efficient device development. Electric components such as motors and transformers are mostly based on electromagnetic transduction at present. With reducing their size, these electromagnetic components reduce their efficiency drastically due to the Joule heat in their thin coil wire (i.e., the resistance in the coil becomes significant). Thus, piezoelectric actuators and transducers with much less losses are highly sought after in the 21 century. In the past 30 years, most researchers have put efforts on improving the piezoelectric performance from the real-part property's viewpoint: that is, improved displacement, force, responsivity etc. However, from the viewpoint of efficiency and reliability such as heat generation or performance degradation under high voltage/power drive, the key is the imaginary-part; that is, loss and hysteresis mechanisms.Piezoelectric devices seem to be all-around contributors and a key component to the above mentioned four R&D areas in the sustainable society. Some of the efforts include: (a) Since the most widely used piezoelectric lead zirconate titante (PZT) ceramics will be regulated in less than 10 years in European and Japanese communities due to their toxicity (Pb(2+) ion), lead-free piezoelectric ceramics based on (K,Na)(Ta,Nb)O(3) and (Bi,Na,Ba)TiO(3) have been developed with performance equivalent to the PZTs. (b) Since hazardous organic substances such as dioxin can be easily dissolved by the irradiation of ultrasonic energy in water, a new technology for safe disposal of dioxin using high-power piezoelectric transducers has been developed. (c) We demonstrated an energy recovery system on a hybrid car from its engine's mechanical vibration to the fuel cell for electric charging. A self-powered remote light switching system has also been developed using piezoelectric bimorphs. (d) Micro ultrasonic motors based on piezoelectrics demonstrated 1/20 reduction in the volume and weight and a 20 time increase in efficiency of the conventional electromagnetic motors with equivalent output power. We also demonstrated compact and highly-efficient high-voltage supplies with piezoelectric transformers, which have been widely commercialized for laptop backlight inverter applications. The key to improving efficiency is the development of low loss piezoelectrics.This paper introduces leading piezoelectric materials, devices, and drive/control methods, relating with the above sustainability technologies, aiming at further research expansion in this area.",,,978-3-933339-12-6,110-118, , 12th International Conference on New Actuators/6th International Exhibition on Smart Actuators and Drive Systems12th International Conference on New Actuators/6th International Exhibition on Smart Actuators and Drive Systems,,out_of_scope,
4127,"Title:Biosorption of Cadmium (II) Ion from Aqueous Solution Using Living Cell and Non-Living Cell Microalga Scenedesmus Dimorphus

 The ability of microalga Scenedesmusdimorphus, living cells and non-living cells has been tested for bioremoval of a heavy metal, Cadmium (Cd+2) in aqueous solution. Bioremoval capacity of living and non-living cells microalga Scenedesmusdimorphus was studied include the effects of pH solution, initial concentration of Cd+2 and contact time. For non-living cells microalga, the maximum adsorption was obtained at pH 6 with 2.465 mgCd/g of removal capacity. The highest extent of Cd+2 removal occurred at initial concentration 20 mgCd/L, and optimal contact time achieved when it exposed for 3 hours. For living cells microalga, the maximum adsorption was obtained at pH 7 with 2.765 mgCd/g of removal capacity. The highest extent of Cd+2 removal was also occurred at initial concentration 20 mgCd/L, and optimal contact time achieved when it exposed for 10 hours. Further the biosorbent was characterized by Fourier Transformer Infrared Spectroscopy (FT-IR) studies helped to identify the various functional groups contributing in the sorption process. From FTIR spectra analysis, hydroxyl was the major functional group contributed in biosorption process. The electron microscopy examination by Scanning Electron Microscopy (SEM) showed that there was a significant change in cell's surface structure after the uptake of Cd ions. There were tangled formations formed and change in pores size and shape. It was concluded that S. dimorphus biomass can be used potentially as biosorbent for the removal Cd in aqueous solution.","Chaidir, Zulkarnain; Jesica, Shinta; Zein, Rahmiana; Munaf, Edison",,"Zein, Rahmiana/0000-0002-4281-2993; chaidir, zulkarnain/0000-0003-2585-1947",Biosorption of Cadmium (II) Ion from Aqueous Solution Using Living Cell and Non-Living Cell Microalga Scenedesmus Dimorphus,6,2, ,Article ,2015.0,"The ability of microalga Scenedesmusdimorphus, living cells and non-living cells has been tested for bioremoval of a heavy metal, Cadmium (Cd+2) in aqueous solution. Bioremoval capacity of living and non-living cells microalga Scenedesmusdimorphus was studied include the effects of pH solution, initial concentration of Cd+2 and contact time. For non-living cells microalga, the maximum adsorption was obtained at pH 6 with 2.465 mgCd/g of removal capacity. The highest extent of Cd+2 removal occurred at initial concentration 20 mgCd/L, and optimal contact time achieved when it exposed for 3 hours. For living cells microalga, the maximum adsorption was obtained at pH 7 with 2.765 mgCd/g of removal capacity. The highest extent of Cd+2 removal was also occurred at initial concentration 20 mgCd/L, and optimal contact time achieved when it exposed for 10 hours. Further the biosorbent was characterized by Fourier Transformer Infrared Spectroscopy (FT-IR) studies helped to identify the various functional groups contributing in the sorption process. From FTIR spectra analysis, hydroxyl was the major functional group contributed in biosorption process. The electron microscopy examination by Scanning Electron Microscopy (SEM) showed that there was a significant change in cell's surface structure after the uptake of Cd ions. There were tangled formations formed and change in pores size and shape. It was concluded that S. dimorphus biomass can be used potentially as biosorbent for the removal Cd in aqueous solution.",0975-8585,,,1972-1980, , ,,out_of_scope,
4128,"Title:Polychlorinated biphenyls in indoor dust from urban dwellings of Lahore, Pakistan: Congener profile, toxicity equivalency, and human health implications

 This study is the pioneer assessment of the PCBs in indoor dust particles (from air conditioners) of an urbanized megacity from South Asian. The n-ary sumation (35) PCB concentration ranged from 0.27 to 152.9 ng/g (mean: 24.84 +/- 22.10 ng/g). The tri- and tetra-PCBs were dominant homologues, contributing 57.36% of the total PCB concentrations. The mean levels of Sigma(8)-dioxin-like (DL), Sigma(6)-indicator PCBs and WHO2005-TEQ for DL-PCBs were 2.22 +/- 2.55 ng/g, 9.49 +/- 8.04 ng/g and 4.77 +/- 4.89 pg/g, respectively. The multiple linear regression indicated a significant correlation of dusting frequency (p = 1.06 x 10-04) and age of the house (p = 1.02 x 10-06) with PCB concentrations in indoor environment. The spatial variation of PCB profile revealed relatively higher concentrations from sites near to illegal waste burning spots, electrical locomotive workshops, and grid stations. Human health risk assessment of PCBs for adults and toddlers through all three exposure routes (ie, inhalation, ingestion, and dermal contact) demonstrated that toddlers were vulnerable to high cancer risk (4.32 x 10(-04)), while adults were susceptible from low to moderate levels of risk (3.16 x 10(-05)). Therefore, comprehensive investigations for PCBs in the indoor settings, focusing particularly on the sensitive populations with relationship to the electronic devices, transformers, and illegal waste burning sites, are recommended.","Aslam, Iqra; Baqar, Mujtaba; Qadir, Abdul; Mumtaz, Mehvish; Li, Jun; Zhang, Gan","Baqar, Mujtaba/JDC-9352-2023; li, jun/C-4943-2012; Zhang, Gan/C-3528-2012","Baqar, Mujtaba/0000-0003-1457-1659; li, jun/0000-0002-3637-1642; Zhang, Gan/0000-0002-9010-8140","Polychlorinated biphenyls in indoor dust from urban dwellings of Lahore, Pakistan: Congener profile, toxicity equivalency, and human health implications",31,5,10.1111/ina.12788 ,Article ,2021.0,"This study is the pioneer assessment of the PCBs in indoor dust particles (from air conditioners) of an urbanized megacity from South Asian. The n-ary sumation (35) PCB concentration ranged from 0.27 to 152.9 ng/g (mean: 24.84 +/- 22.10 ng/g). The tri- and tetra-PCBs were dominant homologues, contributing 57.36% of the total PCB concentrations. The mean levels of Sigma(8)-dioxin-like (DL), Sigma(6)-indicator PCBs and WHO2005-TEQ for DL-PCBs were 2.22 +/- 2.55 ng/g, 9.49 +/- 8.04 ng/g and 4.77 +/- 4.89 pg/g, respectively. The multiple linear regression indicated a significant correlation of dusting frequency (p = 1.06 x 10-04) and age of the house (p = 1.02 x 10-06) with PCB concentrations in indoor environment. The spatial variation of PCB profile revealed relatively higher concentrations from sites near to illegal waste burning spots, electrical locomotive workshops, and grid stations. Human health risk assessment of PCBs for adults and toddlers through all three exposure routes (ie, inhalation, ingestion, and dermal contact) demonstrated that toddlers were vulnerable to high cancer risk (4.32 x 10(-04)), while adults were susceptible from low to moderate levels of risk (3.16 x 10(-05)). Therefore, comprehensive investigations for PCBs in the indoor settings, focusing particularly on the sensitive populations with relationship to the electronic devices, transformers, and illegal waste burning sites, are recommended.",0905-6947,1600-0668,,1417-1426, , ,,out_of_scope,
4129,"Title:High-performance laminated luminescent solar concentrators based on colloidal carbon quantum dots

 Luminescent solar concentrators (LSCs) are light-weight, semitransparent and large-area sunlight collectors for solar-to-electricity conversion. To date, carbon quantum dots (C-QDs) have attracted a lot of attention due to their size/shape/composition tunable optical properties, high quantum yield, excellent photostability, lower toxicity and simple synthetic methods using earth-abundant and low-cost precursors. However, due to the overlap between their absorption and emission spectra, it is still challenging to fabricate high-efficiency LSCs based on C-dots. In this work, we used C-QDs to fabricate semi-transparent large-area laminated LSCs (10 x 10 cm(2)). C-QDs have the absorption spectrum ranging from 300 to 550 nm with a Stokes shift of 0.6 eV. By optimizing the concentration of C-QDs, the laminated LSC exhibits a highest eta(opt) of 1.6%, which is 1.6 times higher than that of a single-layer LSC (100 mW cm(-2)). In addition, the laminated LSC exhibits a power conversion efficiency of 0.7% under natural sunlight illumination (62 mW cm(-2)) with excellent photostability. These findings suggest that laminated structured LSCs could be used for efficient solar energy harvesting compared to single layer or tandem structured LSCs based on colloidal C-QDs.","Zhao, Haiguang; Liu, Guiju; Han, Guangting",,,High-performance laminated luminescent solar concentrators based on colloidal carbon quantum dots,1,12,10.1039/c9na00527g ,Article ,2019.0,"Luminescent solar concentrators (LSCs) are light-weight, semitransparent and large-area sunlight collectors for solar-to-electricity conversion. To date, carbon quantum dots (C-QDs) have attracted a lot of attention due to their size/shape/composition tunable optical properties, high quantum yield, excellent photostability, lower toxicity and simple synthetic methods using earth-abundant and low-cost precursors. However, due to the overlap between their absorption and emission spectra, it is still challenging to fabricate high-efficiency LSCs based on C-dots. In this work, we used C-QDs to fabricate semi-transparent large-area laminated LSCs (10 x 10 cm(2)). C-QDs have the absorption spectrum ranging from 300 to 550 nm with a Stokes shift of 0.6 eV. By optimizing the concentration of C-QDs, the laminated LSC exhibits a highest eta(opt) of 1.6%, which is 1.6 times higher than that of a single-layer LSC (100 mW cm(-2)). In addition, the laminated LSC exhibits a power conversion efficiency of 0.7% under natural sunlight illumination (62 mW cm(-2)) with excellent photostability. These findings suggest that laminated structured LSCs could be used for efficient solar energy harvesting compared to single layer or tandem structured LSCs based on colloidal C-QDs.",2516-0230,,,4888-4894, , ,,out_of_scope,
4130,"Title:Transformation of tetrabromobisphenol A by Rhodococcus jostii RHAl: Effects of heavy metals

 Tetrabromobisphenol A (TBBPA) is one of the most widely used brominated flame retardants in the world but it is also a pollutant of global concern. In the present study, we studied the transformation of C-14- labeled TBBPA by a polychlorinated-biphenyl-degrading bacterium, Rhodococcus jostii RHAl (RHA1), under oxic conditions. During the 5-day incubation, TBBPA was biotransformed rapidly first to its monomethyl ether MeO-TBBPA and then to its more hydrophobic but less toxic dimethyl ether diMeO-TBBPA. The biotransformation followed pseudo-first-order decay kinetics, with a half-life of TBBPA of 0.32 days and only 0.6% of the initially added amount being mineralized. Considering the frequent co-occurrence of TBBPA with heavy metals in the natural environment, we also investigated the effects of three heavy metals (Cd, Cu, and Fe) on the transformation of TBBPA by strain RHA1. While TBBPA transformation was not significantly altered by Cd, it was accelerated by Cu and Fe, presumably due to the effects of these two essential metals on O-methyltransferase activity. Overall, the present study showed that RHAl is an effective transformer of TBBPA and that certain essential metals, including Cu and Fe, promote the transformation. (C) 2018 Elsevier Ltd. All rights reserved.","Xu, Shen; Wang, Yong-Feng; Yang, Liu-Yan; Ji, Rong; Miao, Ai-Jun","liu, yang/HHY-8583-2022; yang, liu/GVU-8760-2022; yang, liu/HTN-9175-2023; Wang, Yongfeng/R-9274-2016; Liu, Yang/HNJ-6693-2023; LIU, YANG/HWQ-4615-2023; liu, yang/HIU-0559-2022; liu, yang/HQY-7531-2023; Ji, Rong/E-5473-2011","Wang, Yongfeng/0000-0003-2528-7354; Ji, Rong/0000-0002-1724-5253",Transformation of tetrabromobisphenol A by Rhodococcus jostii RHAl: Effects of heavy metals,196,,10.1016/j.chemosphere.2017.12.173 ,Article ,2018.0,"Tetrabromobisphenol A (TBBPA) is one of the most widely used brominated flame retardants in the world but it is also a pollutant of global concern. In the present study, we studied the transformation of C-14- labeled TBBPA by a polychlorinated-biphenyl-degrading bacterium, Rhodococcus jostii RHAl (RHA1), under oxic conditions. During the 5-day incubation, TBBPA was biotransformed rapidly first to its monomethyl ether MeO-TBBPA and then to its more hydrophobic but less toxic dimethyl ether diMeO-TBBPA. The biotransformation followed pseudo-first-order decay kinetics, with a half-life of TBBPA of 0.32 days and only 0.6% of the initially added amount being mineralized. Considering the frequent co-occurrence of TBBPA with heavy metals in the natural environment, we also investigated the effects of three heavy metals (Cd, Cu, and Fe) on the transformation of TBBPA by strain RHA1. While TBBPA transformation was not significantly altered by Cd, it was accelerated by Cu and Fe, presumably due to the effects of these two essential metals on O-methyltransferase activity. Overall, the present study showed that RHAl is an effective transformer of TBBPA and that certain essential metals, including Cu and Fe, promote the transformation. (C) 2018 Elsevier Ltd. All rights reserved.",0045-6535,1879-1298,,206-213, , ,,out_of_scope,
4131,"Title:A novel micro drill design based on Ros-Drillx24b8;

 This paper presents the development of a novel micro drill device for single living organisms. Currently, microinjection for mice and some other species is performed with the help of piezo-driven actuators with a very small amount of mercury column in the proximal end of the pipette in order to increase the success rate. However, the toxicity of mercury exhibits a risk factor both for the operator and the injected cells. Therefore, mercury-free devices have become a necessity. Here, a novel micro drill is developed based on the same principle of Ros-Drill(x24b8;) piercing approach; piercing via rotational movements. The new drill is driven by a brushless motor, and it incorporates the micropipette holder. Both the amplitude and the frequency of rotational oscillations can be adjusted in very wide ranges. The experiments reveal that the drill is suitable for different tasks such as microinjection and biopsy of different organisms. It presents good performance in terms of success rate, ease of usage, compactness and compatibility with different manipulation systems.","Nak, Handan; Ergenc, Ali Fuat","Nak, Handan/AAA-3113-2020; Ergenc, Ali Fuat Fuat/AFG-9674-2022; Ergenc, Ali Fuat/N-9333-2013","Nak, Handan/0000-0002-6642-3546; Ergenc, Ali Fuat Fuat/0000-0003-2782-5566; Ergenc, Ali Fuat/0000-0003-2782-5566",A novel micro drill design based on Ros-Drillx24b8;,21,4,10.1007/s10544-019-0432-7 ,Article ,2019.0,"This paper presents the development of a novel micro drill device for single living organisms. Currently, microinjection for mice and some other species is performed with the help of piezo-driven actuators with a very small amount of mercury column in the proximal end of the pipette in order to increase the success rate. However, the toxicity of mercury exhibits a risk factor both for the operator and the injected cells. Therefore, mercury-free devices have become a necessity. Here, a novel micro drill is developed based on the same principle of Ros-Drill(x24b8;) piercing approach; piercing via rotational movements. The new drill is driven by a brushless motor, and it incorporates the micropipette holder. Both the amplitude and the frequency of rotational oscillations can be adjusted in very wide ranges. The experiments reveal that the drill is suitable for different tasks such as microinjection and biopsy of different organisms. It presents good performance in terms of success rate, ease of usage, compactness and compatibility with different manipulation systems.",1387-2176,1572-8781,,, , ,,out_of_scope,
4132,"Title:Comparative Life Cycle Assessment of a Thai Island's diesel/PV/wind hybrid microgrid

 Hybrid microgrid systems are an emerging tool for rural electrification due in part to their purported environmental benefits. This study uses Life Cycle Assessment (LCA) to compare the environmental impacts of a diesel/PV/wind hybrid microgrid on the island of Koh Jig, Thailand with the electrification alternatives of grid extension and home diesel generators. The impact categories evaluated are: acidification potential (kg SO2 eq), global warming potential (kg CO2 eq), human toxicity potential (kg 1.4 DCB eq), and abiotic resource depletion potential (kg Sb eq). The results show that the microgrid system has the lowest global warming and abiotic resource depletion potentials of all three electrification scenarios. The use phase of the diesel generator and the extraction of copper are shown to significantly contribute to the microgrid's environmental impacts. The relative environmental impacts of the grid extension scenario are found to be proportional to the distance required for grid extension. Across all categories except acidification potential, the impacts from the home diesel generators are the largest. Sensitivity analyses show that maximizing the renewable energy fraction does not necessarily produce a more environmentally sustainable electrification scenario and that the diesel generator provides versatility to the system by allowing power production to be scaled significantly before more technology is needed to meet demand. While the environmental benefits of the microgrid increase as the installation community becomes more isolated, the choice of electrification scenario requires assigning relative importance to each impact category and considering social and economic factors. (C) 2015 Elsevier Ltd. All rights reserved.","Smith, Cameron; Burrows, John; Scheier, Eric; Young, Amberli; Smith, Jessica; Young, Tiffany; Gheewala, Shabbir H.","Gheewala, Shabbir/ADH-5003-2022; Gheewala, Shabbir H./AAG-5732-2020","Gheewala, Shabbir H./0000-0002-4300-1551",Comparative Life Cycle Assessment of a Thai Island's diesel/PV/wind hybrid microgrid,80,,10.1016/j.renene.2015.01.003 ,Article ,2015.0,"Hybrid microgrid systems are an emerging tool for rural electrification due in part to their purported environmental benefits. This study uses Life Cycle Assessment (LCA) to compare the environmental impacts of a diesel/PV/wind hybrid microgrid on the island of Koh Jig, Thailand with the electrification alternatives of grid extension and home diesel generators. The impact categories evaluated are: acidification potential (kg SO2 eq), global warming potential (kg CO2 eq), human toxicity potential (kg 1.4 DCB eq), and abiotic resource depletion potential (kg Sb eq). The results show that the microgrid system has the lowest global warming and abiotic resource depletion potentials of all three electrification scenarios. The use phase of the diesel generator and the extraction of copper are shown to significantly contribute to the microgrid's environmental impacts. The relative environmental impacts of the grid extension scenario are found to be proportional to the distance required for grid extension. Across all categories except acidification potential, the impacts from the home diesel generators are the largest. Sensitivity analyses show that maximizing the renewable energy fraction does not necessarily produce a more environmentally sustainable electrification scenario and that the diesel generator provides versatility to the system by allowing power production to be scaled significantly before more technology is needed to meet demand. While the environmental benefits of the microgrid increase as the installation community becomes more isolated, the choice of electrification scenario requires assigning relative importance to each impact category and considering social and economic factors. (C) 2015 Elsevier Ltd. All rights reserved.",0960-1481,,,85-100, , ,,out_of_scope,
4133,"Title:A transgenic female killing system for the genetic control of Drosophila suzukii

 The spotted wing Drosophila (Drosophila suzukii) is an invasive pest of soft-skinned fruit crops. It is rapidly transmitted in Europe and North America, causing widespread agricultural losses. Genetic control strategies such as the sterile insect technique (SIT) have been proposed as environment-friendly and species-restricted approaches for this pest. However, females are inefficient agents in SIT programs. Here we report a conditional female-killing (FK) strategy based on the tetracycline-off system. We assembled sixteen genetic constructs for testing in vitro and in vivo. Twenty-four independent transgenic strains of D. suzukii were generated and tested for female-specific lethality. The strongest FK effect in the absence of tetracycline was achieved by the construct containing D. suzukii nullo promoter for early gene expression, D. suzukii pro-apoptotic gene hid(Ala4) for lethality, and the transformer gene intron from the Mediterranean fruit fly Ceratitis capitata for female-specific splicing. One strain carrying this construct eliminated 100% of the female offspring during embryogenesis and produced only males. However, homozygous females from these FK strains were not viable on a tetracycline-supplemented diet, possibly due to the basal expression of hid(Ala4). Potential improvements to the gene constructs and the use of such FK strains in an SIT program are discussed.","Schetelig, Marc F.; Schwirz, Jonas; Yan, Ying",,"Schetelig, Prof. Dr. Marc F./0000-0002-9217-394X; Yan, Ying/0000-0002-1247-3302",A transgenic female killing system for the genetic control of Drosophila suzukii,11,1,10.1038/s41598-021-91938-1 ,Article ,2021.0,"The spotted wing Drosophila (Drosophila suzukii) is an invasive pest of soft-skinned fruit crops. It is rapidly transmitted in Europe and North America, causing widespread agricultural losses. Genetic control strategies such as the sterile insect technique (SIT) have been proposed as environment-friendly and species-restricted approaches for this pest. However, females are inefficient agents in SIT programs. Here we report a conditional female-killing (FK) strategy based on the tetracycline-off system. We assembled sixteen genetic constructs for testing in vitro and in vivo. Twenty-four independent transgenic strains of D. suzukii were generated and tested for female-specific lethality. The strongest FK effect in the absence of tetracycline was achieved by the construct containing D. suzukii nullo promoter for early gene expression, D. suzukii pro-apoptotic gene hid(Ala4) for lethality, and the transformer gene intron from the Mediterranean fruit fly Ceratitis capitata for female-specific splicing. One strain carrying this construct eliminated 100% of the female offspring during embryogenesis and produced only males. However, homozygous females from these FK strains were not viable on a tetracycline-supplemented diet, possibly due to the basal expression of hid(Ala4). Potential improvements to the gene constructs and the use of such FK strains in an SIT program are discussed.",2045-2322,,,, , ,,out_of_scope,
4134,"Title:A state-of-the-art review on the liquid properties regarding energy and environmental performance in liquid desiccant air-conditioning systems

 Liquid desiccant air-conditioning system (LDAS) becomes an attractive option for reducing the energy consumption of conventional air-conditioning systems. Despite lots of published papers on LDAS in various aspects, there is not yet a comprehensive and up-to-date review on the properties of liquid desiccants, while the selection of liquid desiccant plays essential role in the overall performance of LDAS. In this paper, a state-of-the-art review on the properties in regard of energy and environmental performance is delivered for present and potential liquid desiccants, including vapor-liquid equilibrium, specific heat capacity, safety concerns. The current situations and future concerns of liquid desiccant investigation can be obtained, while different kinds of liquid desiccant candidates can be compared and evaluated comprehensively. Existing liquid desiccant of halide salt faces severe drawback of corrosiveness in long-term use. Compared with existing liquid desiccants, the candidates of weak acid salt, ionic liquid and deep eutectic solvent behave low toxicity and friendly corrosiveness, whereas their weak moisture absorption ability, high cost or high viscosity is the bottleneck for further applications. Therefore, the mixture of them can be regarded as a promising candidate in LDAS applications, but the fundamental properties are urged to be measured. The work in this paper provides momentous reference and guidance for the exploration of new liquid desiccant as well as the evaluation of future prospect of LDAS.","Luo, Jielin; Yang, Hongxing",,"Luo, Jielin/0000-0002-1515-1325",A state-of-the-art review on the liquid properties regarding energy and environmental performance in liquid desiccant air-conditioning systems,325,,10.1016/j.apenergy.2022.119853 ,Review ,2022.0,"Liquid desiccant air-conditioning system (LDAS) becomes an attractive option for reducing the energy consumption of conventional air-conditioning systems. Despite lots of published papers on LDAS in various aspects, there is not yet a comprehensive and up-to-date review on the properties of liquid desiccants, while the selection of liquid desiccant plays essential role in the overall performance of LDAS. In this paper, a state-of-the-art review on the properties in regard of energy and environmental performance is delivered for present and potential liquid desiccants, including vapor-liquid equilibrium, specific heat capacity, safety concerns. The current situations and future concerns of liquid desiccant investigation can be obtained, while different kinds of liquid desiccant candidates can be compared and evaluated comprehensively. Existing liquid desiccant of halide salt faces severe drawback of corrosiveness in long-term use. Compared with existing liquid desiccants, the candidates of weak acid salt, ionic liquid and deep eutectic solvent behave low toxicity and friendly corrosiveness, whereas their weak moisture absorption ability, high cost or high viscosity is the bottleneck for further applications. Therefore, the mixture of them can be regarded as a promising candidate in LDAS applications, but the fundamental properties are urged to be measured. The work in this paper provides momentous reference and guidance for the exploration of new liquid desiccant as well as the evaluation of future prospect of LDAS.",0306-2619,1872-9118,,, , ,,out_of_scope,
4135,"Title:Accelerating SARS-CoV-2 Vaccine Development: Leveraging Novel Hybrid Deep Learning Models and Bioinformatics Analysis for Epitope Selection and Classification

 It is essential to use highly antigenic epitope areas, since the development of peptide vaccines heavily relies on the precise design of epitope regions that can elicit a strong immune response. Choosing epitope regions experimentally for the production of the SARS-CoV-2 vaccine can be time-consuming, costly, and labor-intensive. Scientists have created in silico prediction techniques based on machine learning to find these regions, to cut down the number of candidate epitopes that might be tested in experiments, and, as a result, to lessen the time-consuming process of their mapping. However, the tools and approaches involved continue to have low accuracy. In this work, we propose a hybrid deep learning model based on a convolutional neural network (CNN) and long short-term memory (LSTM) for the classification of peptides into epitopes or non-epitopes. Numerous transfer learning strategies were utilized, and the fine-tuned method gave the best result, with an AUC of 0.979, an f1 score of 0.902, and 95.1% accuracy, which was far better than the performance of the model trained from scratch. The experimental results obtained show that this model has superior performance when compared to other methods trained on IEDB datasets. Using bioinformatics tools such as ToxinPred, VaxiJen, and AllerTop2.0, the toxicities, antigenicities, and allergenicities, respectively, of the predicted epitopes were determined. In silico cloning and codon optimization were used to successfully express the vaccine in E. coli. This work will help scientists choose the best epitope for the development of the COVID-19 vaccine, reducing cost and labor and thereby accelerating vaccine production.","Ameen, Zubaida Said; Mostafa, Hala; Ozsahin, Dilber Uzun; Mubarak, Auwalu Saleh","Uzun Ozsahin, Dilber/GLT-9806-2022","Auwalu, Mubarak/0000-0001-6240-1684",Accelerating SARS-CoV-2 Vaccine Development: Leveraging Novel Hybrid Deep Learning Models and Bioinformatics Analysis for Epitope Selection and Classification,11,6,10.3390/pr11061829 ,Article ,2023.0,"It is essential to use highly antigenic epitope areas, since the development of peptide vaccines heavily relies on the precise design of epitope regions that can elicit a strong immune response. Choosing epitope regions experimentally for the production of the SARS-CoV-2 vaccine can be time-consuming, costly, and labor-intensive. Scientists have created in silico prediction techniques based on machine learning to find these regions, to cut down the number of candidate epitopes that might be tested in experiments, and, as a result, to lessen the time-consuming process of their mapping. However, the tools and approaches involved continue to have low accuracy. In this work, we propose a hybrid deep learning model based on a convolutional neural network (CNN) and long short-term memory (LSTM) for the classification of peptides into epitopes or non-epitopes. Numerous transfer learning strategies were utilized, and the fine-tuned method gave the best result, with an AUC of 0.979, an f1 score of 0.902, and 95.1% accuracy, which was far better than the performance of the model trained from scratch. The experimental results obtained show that this model has superior performance when compared to other methods trained on IEDB datasets. Using bioinformatics tools such as ToxinPred, VaxiJen, and AllerTop2.0, the toxicities, antigenicities, and allergenicities, respectively, of the predicted epitopes were determined. In silico cloning and codon optimization were used to successfully express the vaccine in E. coli. This work will help scientists choose the best epitope for the development of the COVID-19 vaccine, reducing cost and labor and thereby accelerating vaccine production.",,2227-9717,,, , ,,out_of_scope,
4136,"Title:An early female lethal system of the New World screwworm, Cochliomyia hominivorax, for biotechnology-enhanced SIT

 BackgroundThe New World Screwworm fly (NWS), Cochliomyia hominivorax, is an ectoparasite of warm-blooded animals and a major pest of livestock in parts of South America and the Caribbean where it remains endemic. In North and Central America it was eradicated using the Sterile Insect Technique (SIT). A control program is managed cooperatively between the governments of the United States and Panama to prevent the northward spread of NWS from infested countries in South America. This is accomplished by maintaining a permanent barrier through the release of millions of sterile male and female flies in the border between Panama and Colombia. Our research team demonstrated the utility of biotechnology-enhanced approaches for SIT by developing a male-only strain of the NWS. The strain carried a single component tetracycline repressible female lethal system where females died at late larval/pupal stages. The control program can be further improved by removing females during embryonic development as larval diet costs are significant.ResultsThe strains developed carry a two-component system consisting of the Lucilia sericata bottleneck gene promoter driving expression of the tTA gene and a tTA-regulated Lshid proapoptotic effector gene. Insertion of the sex-specifically spliced intron from the C. hominivorax transformer gene within the Lshid gene ensures that only females die when insects are reared in the absence of tetracycline. In several double homozygous two-component strains and in one All-in-one strain that had both components in a single construct, female lethality occurred at the embryonic and/or first instar larval stages when raised on diet without tetracycline. Laboratory evaluation for phenotypes that are relevant for mass rearing in a production facility revealed that most strains had fitness characteristics similar to the wild type J06 strain that is currently reared for release in the permanent barrier. Testing of an All in one strain under mass rearing conditions showed that the strain maintained the fitness characteristics observed in small-scale rearing.ConclusionsThe early female lethal strains described here could be selected by the NWS Control Program for testing at large scale in the production facility to enhance the efficiency of the NWS eradication program.","Concha, Carolina; Yan, Ying; Arp, Alex; Quilarque, Evelin; Sagel, Agustin; de Leon, Adalberto Perez; Owen McMillan, W.; Skoda, Steven; Scott, Maxwell J.","Scott, Maxwell J/J-1935-2015","Scott, Maxwell J/0000-0001-6536-4735; Arp, Alex/0000-0003-3005-8580; Yan, Ying/0000-0002-1247-3302","An early female lethal system of the New World screwworm, Cochliomyia hominivorax, for biotechnology-enhanced SIT",21,,10.1186/s12863-020-00948-x ,Article ,2020.0,"BackgroundThe New World Screwworm fly (NWS), Cochliomyia hominivorax, is an ectoparasite of warm-blooded animals and a major pest of livestock in parts of South America and the Caribbean where it remains endemic. In North and Central America it was eradicated using the Sterile Insect Technique (SIT). A control program is managed cooperatively between the governments of the United States and Panama to prevent the northward spread of NWS from infested countries in South America. This is accomplished by maintaining a permanent barrier through the release of millions of sterile male and female flies in the border between Panama and Colombia. Our research team demonstrated the utility of biotechnology-enhanced approaches for SIT by developing a male-only strain of the NWS. The strain carried a single component tetracycline repressible female lethal system where females died at late larval/pupal stages. The control program can be further improved by removing females during embryonic development as larval diet costs are significant.ResultsThe strains developed carry a two-component system consisting of the Lucilia sericata bottleneck gene promoter driving expression of the tTA gene and a tTA-regulated Lshid proapoptotic effector gene. Insertion of the sex-specifically spliced intron from the C. hominivorax transformer gene within the Lshid gene ensures that only females die when insects are reared in the absence of tetracycline. In several double homozygous two-component strains and in one All-in-one strain that had both components in a single construct, female lethality occurred at the embryonic and/or first instar larval stages when raised on diet without tetracycline. Laboratory evaluation for phenotypes that are relevant for mass rearing in a production facility revealed that most strains had fitness characteristics similar to the wild type J06 strain that is currently reared for release in the permanent barrier. Testing of an All in one strain under mass rearing conditions showed that the strain maintained the fitness characteristics observed in small-scale rearing.ConclusionsThe early female lethal strains described here could be selected by the NWS Control Program for testing at large scale in the production facility to enhance the efficiency of the NWS eradication program.",1471-2156,,,, , ,,out_of_scope,
4137,"Title:KINETICS OF MAIZE LEAF ELONGATION .1. INCREASED YIELD THRESHOLD LIMITS SHORT-TERM, STEADY-STATE ELONGATION RATES AFTER EXPOSURE TO SALINITY

 The short-term responses of leaf elongation to salinity are investigated in this study. The kinetics of maize (Zea mays L.) leaf elongation were measured with Linear Variable Differential Transformers (LVDTs). After exposure to salinity (0 to 120 mol m-3 NaCl), leaf elongation rates (LER) declined rapidly. Within 4 h, LER had recovered and reached a new steady-state for all salinity treatments. These rates were reduced by 10, 20, and 60% of control rates by 40, 80 and 120 mol m-3 NaCl, respectively. Osmotic adjustment in the growing zone of leaves was correlated with the recovery of LER after plant exposure to salinity. However, after 4 h of exposure, the osmolality of the cell sap continued to increase without effect on steady-state LER. Estimates of the apparent turgor in the growing zone indicated that turgor was no longer limiting LER of salt-stressed plants after 4 h. An in vivo technique was developed to apply a unidirectional force to intact growing leaves of maize to mimic increases in elongation force. Relative elongation rate (RER) were increased by adding weights to the LVDT core to increase elongation force. Plots of RER as a function of elongation force gave estimates of two growth coefficients: the yield threshold and the yielding coefficient, mL/(m + L), where m is the cell wall extensibility and L is the hydraulic conductivity. RER as a function of elongation force was determined immediately, 0.5, 4, and 21 h after plants were salinized. Estimates of the growth coefficients indicated that the apparent yield threshold decreased immediately after salinization. However, when LER reached steady-state, the yield threshold of salt-stressed plants had increased above control values and was the only limiting growth coefficient. There were no significant effects of salinity on the yielding coefficients, cell wall extensibility or hydraulic conductivity. One of the advantages of this in vivo technique over other methods is that yield threshold, yielding coefficient, and cell wall extensibility can be determined without the confounding effects of wounding or osmotic stress. This technique may prove widely applicable to the study of other growth regulating factors.","CRAMER, GR; BOWMAN, DC","Cramer, Grant R/E-1815-2011",,"KINETICS OF MAIZE LEAF ELONGATION .1. INCREASED YIELD THRESHOLD LIMITS SHORT-TERM, STEADY-STATE ELONGATION RATES AFTER EXPOSURE TO SALINITY",42,244,10.1093/jxb/42.11.1417 ,Article ,1991.0,"The short-term responses of leaf elongation to salinity are investigated in this study. The kinetics of maize (Zea mays L.) leaf elongation were measured with Linear Variable Differential Transformers (LVDTs). After exposure to salinity (0 to 120 mol m-3 NaCl), leaf elongation rates (LER) declined rapidly. Within 4 h, LER had recovered and reached a new steady-state for all salinity treatments. These rates were reduced by 10, 20, and 60% of control rates by 40, 80 and 120 mol m-3 NaCl, respectively. Osmotic adjustment in the growing zone of leaves was correlated with the recovery of LER after plant exposure to salinity. However, after 4 h of exposure, the osmolality of the cell sap continued to increase without effect on steady-state LER. Estimates of the apparent turgor in the growing zone indicated that turgor was no longer limiting LER of salt-stressed plants after 4 h. An in vivo technique was developed to apply a unidirectional force to intact growing leaves of maize to mimic increases in elongation force. Relative elongation rate (RER) were increased by adding weights to the LVDT core to increase elongation force. Plots of RER as a function of elongation force gave estimates of two growth coefficients: the yield threshold and the yielding coefficient, mL/(m + L), where m is the cell wall extensibility and L is the hydraulic conductivity. RER as a function of elongation force was determined immediately, 0.5, 4, and 21 h after plants were salinized. Estimates of the growth coefficients indicated that the apparent yield threshold decreased immediately after salinization. However, when LER reached steady-state, the yield threshold of salt-stressed plants had increased above control values and was the only limiting growth coefficient. There were no significant effects of salinity on the yielding coefficients, cell wall extensibility or hydraulic conductivity. One of the advantages of this in vivo technique over other methods is that yield threshold, yielding coefficient, and cell wall extensibility can be determined without the confounding effects of wounding or osmotic stress. This technique may prove widely applicable to the study of other growth regulating factors.",0022-0957,,,1417-1426, , ,,out_of_scope,
4138,"Series([], Name: Abstract, dtype: object)","MASLOWSKI, R; ROSE, V",,,HIGH-RISE BUILDING DECONTAMINATION AFTER A FURAN INCIDENT,1,1,10.1109/TPWRD.1986.4307914 ,Article ,1986.0,"Series([], Name: Abstract, dtype: object)",0885-8977,,,239-244, , ,,out_of_scope,
4139,"Title:Comparison of Deep Learning Models and Various Text Pre-Processing Techniques for the Toxic Comments Classification

 The emergence of anti-social behaviour in online environments presents a serious issue in today's society. Automatic detection and identification of such behaviour are becoming increasingly important. Modern machine learning and natural language processing methods can provide effective tools to detect different types of anti-social behaviour from the pieces of text. In this work, we present a comparison of various deep learning models used to identify the toxic comments in the Internet discussions. Our main goal was to explore the effect of the data preparation on the model performance. As we worked with the assumption that the use of traditional pre-processing methods may lead to the loss of characteristic traits, specific for toxic content, we compared several popular deep learning and transformer language models. We aimed to analyze the influence of different pre-processing techniques and text representations including standard TF-IDF, pre-trained word embeddings and also explored currently popular transformer models. Experiments were performed on the dataset from the Kaggle Toxic Comment Classification competition, and the best performing model was compared with the similar approaches using standard metrics used in data analysis.","Maslej-Kresnakova, Viera; Sarnovsky, Martin; Butka, Peter; Machova, Kristina","Maslej Krešňáková, Viera/ABH-9510-2020; Sarnovsky, Martin/Z-4954-2019; Machova, Kristina/R-9468-2019; Butka, Peter/Z-5863-2019","Maslej Krešňáková, Viera/0000-0002-0451-2279; Sarnovsky, Martin/0000-0003-3019-8364; Machova, Kristina/0000-0002-7741-4039; Butka, Peter/0000-0002-1585-0986",Comparison of Deep Learning Models and Various Text Pre-Processing Techniques for the Toxic Comments Classification,10,23,10.3390/app10238631 ,Article ,2020.0,"The emergence of anti-social behaviour in online environments presents a serious issue in today's society. Automatic detection and identification of such behaviour are becoming increasingly important. Modern machine learning and natural language processing methods can provide effective tools to detect different types of anti-social behaviour from the pieces of text. In this work, we present a comparison of various deep learning models used to identify the toxic comments in the Internet discussions. Our main goal was to explore the effect of the data preparation on the model performance. As we worked with the assumption that the use of traditional pre-processing methods may lead to the loss of characteristic traits, specific for toxic content, we compared several popular deep learning and transformer language models. We aimed to analyze the influence of different pre-processing techniques and text representations including standard TF-IDF, pre-trained word embeddings and also explored currently popular transformer models. Experiments were performed on the dataset from the Kaggle Toxic Comment Classification competition, and the best performing model was compared with the similar approaches using standard metrics used in data analysis.",,2076-3417,,, , ,,Use_dataset#evaluation,
4140,"Title:Design of power electronic transformer based on cascaded H-bridge multilevel converter

 One key component of the future automation in electrical network is the replacement of conventional distribution transformers by an all-solid-state (power-electronic) alternative. In this paper, the optimum design of a Power Electronic Transformer (PET) based on state of the art cascaded H-bridge multilevel converter is investigated. In the design process, a new and simple control method for balancing the cascaded H-bridge DC buses has been introduced. The proposed PET is extremely modular and can be extended for different voltage and power levels. It performs typical functions and has advantages such as power factor correction, elimination of voltage sag and swell, and reduction of voltage flicker in load side. Also in comparison to conventional transformers, it has lower weight, lower volume and eliminates necessity for toxic dielectric coolants.","Iman-Eini, H.; Farhangi, Sh.; Schanen, J-L.; Aime, J.","IMANEINI, Hossein/X-6587-2018; Farhangi, Shahrokh/Y-4984-2018; SCHANEN, Jean-Luc/AAG-9013-2021","IMANEINI, Hossein/0000-0003-1118-2877; SCHANEN, Jean-Luc/0000-0002-1080-2010",Design of power electronic transformer based on cascaded H-bridge multilevel converter,,,10.1109/ISIE.2007.4374713 ,Proceedings Paper ,2007.0,"One key component of the future automation in electrical network is the replacement of conventional distribution transformers by an all-solid-state (power-electronic) alternative. In this paper, the optimum design of a Power Electronic Transformer (PET) based on state of the art cascaded H-bridge multilevel converter is investigated. In the design process, a new and simple control method for balancing the cascaded H-bridge DC buses has been introduced. The proposed PET is extremely modular and can be extended for different voltage and power levels. It performs typical functions and has advantages such as power factor correction, elimination of voltage sag and swell, and reduction of voltage flicker in load side. Also in comparison to conventional transformers, it has lower weight, lower volume and eliminates necessity for toxic dielectric coolants.",,,978-1-4244-0754-5,877-+, , IEEE International Symposium on Industrial ElectronicsIEEE International Symposium on Industrial Electronics,,out_of_scope,
4141,"Title:Analysis and design of power electronic transformer for medium voltage levels

 One key component of the future automation is replacement of conventional distribution transformers by an all-solid-state (power-electronic) alternative. In this paper, the optimum design of a Power Electronic Transformer (PET) will be investigated. In the design process, the PFC and DC-DC converters have been integrated to achieve higher efficiency. The proposed PET performs typical functions and has advantages such as power factor correction, voltage regulation, voltage sag and swell elimination, voltage flicker reduction and protection capability in fault situations. In addition, it has other benefits such as light weight, low volume and no toxic dielectric coolants.","Iman-Eini, H.; Farhangi, S.","Farhangi, Shahrokh/Y-4984-2018; IMANEINI, Hossein/X-6587-2018","IMANEINI, Hossein/0000-0003-1118-2877",Analysis and design of power electronic transformer for medium voltage levels,,, ,Proceedings Paper ,2006.0,"One key component of the future automation is replacement of conventional distribution transformers by an all-solid-state (power-electronic) alternative. In this paper, the optimum design of a Power Electronic Transformer (PET) will be investigated. In the design process, the PFC and DC-DC converters have been integrated to achieve higher efficiency. The proposed PET performs typical functions and has advantages such as power factor correction, voltage regulation, voltage sag and swell elimination, voltage flicker reduction and protection capability in fault situations. In addition, it has other benefits such as light weight, low volume and no toxic dielectric coolants.",0275-9306,,978-0-7803-9716-3,2903-+, , 37th IEEE Power Electronics Specialist Conference (PESC 2006)37th IEEE Power Electronics Specialist Conference (PESC 2006),,out_of_scope,
4142,"Title:Can pre-trained Transformers be used in detecting complex sensitive sentences? - A Monsanto case study

 Each and every organisation releases information in a variety of forms ranging from annual reports to legal proceedings. Such documents may contain sensitive information and releasing them openly may lead to the leakage of confidential information. Detection of sentences that contain sensitive information in documents can help organisations prevent the leakage of valuable confidential information. This is especially challenging when such sentences contain a substantial amount of information or are paraphrased versions of known sensitive content. Current approaches to sensitive information detection in such complex settings are based on keyword-based approaches or standard machine learning models. In this paper, we wish to explore whether pre-trained transformer models are well suited to detect complex sensitive information. Pre-trained transformers are typically trained on an enormous amount of text and therefore readily learn grammar, structure and other linguistic features, making them particularly attractive for this task. Through our experiments on the Monsanto trial data set, we observe that the fine-tuned Bidirectional Encoder Representations from Transformers (BERT) transformer model performs better than traditional models. We experimented with four different categories of documents in the Monsanto dataset and observed that BERT achieves better F2 scores by 24.13% to 65.79% for GHOST, 30.14% to 54.88% for TOXIC, 39.22% for CHEMI, 53.57% for REGUL compared to existing sensitive information detection models.","Timmer, Roelien C.; Liebowitz, David; Nepal, Surya; Kanhere, Salil S.","kanhere, salil/ABA-2025-2021; Nepal, Surya/B-7523-2011","kanhere, salil/0000-0002-1835-3475; Nepal, Surya/0000-0002-3289-6599",Can pre-trained Transformers be used in detecting complex sensitive sentences? - A Monsanto case study,,,10.1109/TPSISA52974.2021.00010 ,Proceedings Paper ,2021.0,"Each and every organisation releases information in a variety of forms ranging from annual reports to legal proceedings. Such documents may contain sensitive information and releasing them openly may lead to the leakage of confidential information. Detection of sentences that contain sensitive information in documents can help organisations prevent the leakage of valuable confidential information. This is especially challenging when such sentences contain a substantial amount of information or are paraphrased versions of known sensitive content. Current approaches to sensitive information detection in such complex settings are based on keyword-based approaches or standard machine learning models. In this paper, we wish to explore whether pre-trained transformer models are well suited to detect complex sensitive information. Pre-trained transformers are typically trained on an enormous amount of text and therefore readily learn grammar, structure and other linguistic features, making them particularly attractive for this task. Through our experiments on the Monsanto trial data set, we observe that the fine-tuned Bidirectional Encoder Representations from Transformers (BERT) transformer model performs better than traditional models. We experimented with four different categories of documents in the Monsanto dataset and observed that BERT achieves better F2 scores by 24.13% to 65.79% for GHOST, 30.14% to 54.88% for TOXIC, 39.22% for CHEMI, 53.57% for REGUL compared to existing sensitive information detection models.",,,978-1-6654-1623-8,90-97, ," 3rd EEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)3rd EEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)",,out_of_scope,
4143,"Title:Application of SRF Algorithm and SVPDM Concept in Power Electronic Transformer

 Increasing power demand, carbon emission from fossil fuel based generation, depletion of resources, unreliability of power system, poor power quality, low energy efficiency, high transmission losses are the driving factors to move towards smart grid. Smart grid is the integration of electrical grid with information and communication technology and comprises of several micro grid. The micro grids are integrated with main utility grid at point of common coupling using transformers. Such transformer should be of small size for indoor substations. The transformers should have features like bidirectional power flow, real and reactive power flow control and power quality control. Power electronic transformers (PET) are best suited for this application. This paper deals with matrix converter based power electronic transformer which has three phase matrix converter, STATCOM, bilateral converter, dc link capacitor, and voltage source inverter. The main problems of matrix converter based transformers are low input power factor and harmonics. Input power factor and input current harmonic problems are rectified by adding a STATCOM at the input side of matrix converter. Novel space vector based pulse density modulation is designed to obtain harmonic free output voltage in output side of PET. Additionally, the proposed PET performs typical functions and has advantages such as voltage regulation, voltage sag and swell elimination and voltage flicker mitigation. In addition, it has other benefits such as bidirectional power flow, light weight, low volume and no toxic dielectric coolants. Performance of the proposed power electronic transformer is validated by simulation studies.","Prakash, T. Ruban Deva; Kumar, R. Shiju","Deva Prakash, T Ruban/IUN-4770-2023",,Application of SRF Algorithm and SVPDM Concept in Power Electronic Transformer,326,,10.1007/978-81-322-2119-7_121 ,Proceedings Paper ,2015.0,"Increasing power demand, carbon emission from fossil fuel based generation, depletion of resources, unreliability of power system, poor power quality, low energy efficiency, high transmission losses are the driving factors to move towards smart grid. Smart grid is the integration of electrical grid with information and communication technology and comprises of several micro grid. The micro grids are integrated with main utility grid at point of common coupling using transformers. Such transformer should be of small size for indoor substations. The transformers should have features like bidirectional power flow, real and reactive power flow control and power quality control. Power electronic transformers (PET) are best suited for this application. This paper deals with matrix converter based power electronic transformer which has three phase matrix converter, STATCOM, bilateral converter, dc link capacitor, and voltage source inverter. The main problems of matrix converter based transformers are low input power factor and harmonics. Input power factor and input current harmonic problems are rectified by adding a STATCOM at the input side of matrix converter. Novel space vector based pulse density modulation is designed to obtain harmonic free output voltage in output side of PET. Additionally, the proposed PET performs typical functions and has advantages such as voltage regulation, voltage sag and swell elimination and voltage flicker mitigation. In addition, it has other benefits such as bidirectional power flow, light weight, low volume and no toxic dielectric coolants. Performance of the proposed power electronic transformer is validated by simulation studies.",1876-1100,1876-1119,978-81-322-2119-7; 978-81-322-2118-0,1245-1260, , International Conference on Power Electronics and Renewable Energy Systems (ICPERES)International Conference on Power Electronics and Renewable Energy Systems (ICPERES),,out_of_scope,
4144,"Title:A Power Electronic Based Transformer for Feeding Sensitive Loads

 In this paper a modular power electronic transformer (PET) for feeding sensitive loads is presented. The proposed PET can be directly connected to the medium voltage levels and provide a low-voltage and highly-stable interface with the consumer applications. At the input side, cascaded H-bridge rectifier serves as an active-front-end (AFE) rectifier to ensure sinusoidal input current, while converting AC input voltage to distinct DC buses. The isolated DC/DC converters are connected to the individual DC buses and reduce the AC voltage level through series-input and parallel-output configuration of the H-bridge cells. The proposed PET can compensate both the active and reactive powers, and remove the power quality disturbances such as sag, swell, under voltage, over voltage and voltage flicker. In comparison to the conventional transformers, it has low weight, compact volume, extended functionality, and eliminates the necessity for toxic dielectric coolants. The proposed topology and the principle of operation are explained and the validity of the design is verified using the simulation and experimental results.","Iman-Eini, H.; Schanen, J. L.; Farhangi, Sh.; Barbaroux, J.; Keradec, J. P.","Farhangi, Shahrokh/Y-4984-2018; IMANEINI, Hossein/X-6587-2018; SCHANEN, Jean-Luc/AAG-9013-2021","IMANEINI, Hossein/0000-0003-1118-2877; SCHANEN, Jean-Luc/0000-0002-1080-2010",A Power Electronic Based Transformer for Feeding Sensitive Loads,,,10.1109/PESC.2008.4592324 ,Proceedings Paper ,2008.0,"In this paper a modular power electronic transformer (PET) for feeding sensitive loads is presented. The proposed PET can be directly connected to the medium voltage levels and provide a low-voltage and highly-stable interface with the consumer applications. At the input side, cascaded H-bridge rectifier serves as an active-front-end (AFE) rectifier to ensure sinusoidal input current, while converting AC input voltage to distinct DC buses. The isolated DC/DC converters are connected to the individual DC buses and reduce the AC voltage level through series-input and parallel-output configuration of the H-bridge cells. The proposed PET can compensate both the active and reactive powers, and remove the power quality disturbances such as sag, swell, under voltage, over voltage and voltage flicker. In comparison to the conventional transformers, it has low weight, compact volume, extended functionality, and eliminates the necessity for toxic dielectric coolants. The proposed topology and the principle of operation are explained and the validity of the design is verified using the simulation and experimental results.",0275-9306,,978-1-4244-1667-7,2549-+, , 39th IEEE Power Electronics Specialists Conference (PESC 08)39th IEEE Power Electronics Specialists Conference (PESC 08),,out_of_scope,
4145,"Title:COMPLIANCE WITH EPA PCB REGULATIONS - OPTIONS ANALYSIS

 The EPA has written many Final Rules regulating PCB's since the passage of the Toxic Substances Control Act by Congress in 1976. The media and state and local environmental influences have continued to highlight PCB problems. These factors, plus the aging industrial plants that contain PCB's, pose a complex problem for owners of PCB-containing equipment. The EPA rules have become more restrictive and will continue to reflect the EPA's concern with any release of PCB's into the environment. Plant owners who must contend with increasingly complex market conditions must develop good PCB risk management practices. This paper explores the EPA PCB regulations, highlighting the more significant requirements. The most viable options for managing PCB equipment are reviewed, and a method of cost analysis of two of the most popular options is presented.","KUMP, RK",,,COMPLIANCE WITH EPA PCB REGULATIONS - OPTIONS ANALYSIS,27,6,10.1109/28.108469 ,Article ,1991.0,"The EPA has written many Final Rules regulating PCB's since the passage of the Toxic Substances Control Act by Congress in 1976. The media and state and local environmental influences have continued to highlight PCB problems. These factors, plus the aging industrial plants that contain PCB's, pose a complex problem for owners of PCB-containing equipment. The EPA rules have become more restrictive and will continue to reflect the EPA's concern with any release of PCB's into the environment. Plant owners who must contend with increasingly complex market conditions must develop good PCB risk management practices. This paper explores the EPA PCB regulations, highlighting the more significant requirements. The most viable options for managing PCB equipment are reviewed, and a method of cost analysis of two of the most popular options is presented.",0093-9994,,,1162-1168, , ,,out_of_scope,
4146,"Title:SSNCSE_NLP@LT-EDI-ACL2022: Homophobia/Transphobia Detection in Multiple Languages using SVM Classifiers and BERT-based Transformers

 Over the years, there has been a slow but steady change in the attitude of society towards different kinds of sexuality. However, on social media platforms, where people have the license to be anonymous, toxic comments targeted at homosexuals, transgenders and the LGBTQ+ community are not uncommon. Detection of homophobic comments on social media can be useful in making the internet a safer place for everyone. For this task, we used a combination of word embeddings and SVM Classifiers as well as some BERT-based transformers. We achieved a weighted F1-score of 0.93 on the English dataset, 0.75 on the Tamil dataset and 0.87 on the Tamil-English Code-Mixed dataset.","Swaminathan, Krithika; Sampath, Hrishik; Gayathri, G. L.; Bharathi, B.","B., Bharathi/GXV-8824-2022","B., Bharathi/0000-0001-7279-5357",SSNCSE_NLP@LT-EDI-ACL2022: Homophobia/Transphobia Detection in Multiple Languages using SVM Classifiers and BERT-based Transformers,,, ,Proceedings Paper ,2022.0,"Over the years, there has been a slow but steady change in the attitude of society towards different kinds of sexuality. However, on social media platforms, where people have the license to be anonymous, toxic comments targeted at homosexuals, transgenders and the LGBTQ+ community are not uncommon. Detection of homophobic comments on social media can be useful in making the internet a safer place for everyone. For this task, we used a combination of word embeddings and SVM Classifiers as well as some BERT-based transformers. We achieved a weighted F1-score of 0.93 on the English dataset, 0.75 on the Tamil dataset and 0.87 on the Tamil-English Code-Mixed dataset.",,,978-1-955917-43-8,239-244, ," 2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)",,detection#methodology,
4147,"Title:DC Power Flow control in DC Networks through DC/DC Zero Sequence Blocking Transformer

 World is moving to adopt the renewable energy sources to overcome the power issues with zero toxic emission. The key problem is to inject huge power to the grid, generating from renewable energy sources with traditional electrical equipment and grid infrastructure. Currently, work on DC networks is achieving great attention in distributed power generation system, which arise the problem related to the significance of DC power flow control in DC networks. Interline power flow controller (IPFC) are used to control of power flow in the multi-lines and parallel transmission lines. In this paper, a new topology for Interline DC Power Flow Controller (IDCPFC) based on the Zero Sequence Blocking Transformer (ZSBT) has been proposed and analyzed. In the proposed model, the buck converter works as a variable transformer and its current is regulated through the duty cycle of converter. In Comparison with pervious topologies the control algorithm is simple. To validate the topology, simulation results of proposed topology are investigated in this paper. Large-scale network has the characteristics of complex system, and its survivability is different from simple network. The current network survivability studies usually only aim for a specific network level or type, and seldom investigate survivability from a system perspective. In this paper, the concept of large-scale network survivability is defined from the perspective of complex system, the survivability association is analyzed based upon the correlation characteristics of complex system, and the structural model of large-scale network survivability association is established and its properties are analyzed. On the basis of survivability association properties, the survivability association function is defined based upon set pair analysis theory, which is utilized to characterize the survivability association degree among subsystems in large-scale network. Finally, the effectiveness of the model proposed in this paper is validated through case study.","Khan, Muhammad Qasim; Khan, Muhammad Mansoor; Jiang Huawei; Zhao Yi","Khan, Muhammad Qasim/GYJ-4924-2022; KHAN, MUHAMMAD KHURRAM/E-4836-2014; Jiang, Huawei/H-6675-2017","KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; Khan, Muhammad Qasim/0000-0002-3553-0859",DC Power Flow control in DC Networks through DC/DC Zero Sequence Blocking Transformer,,, ,Proceedings Paper ,2017.0,"World is moving to adopt the renewable energy sources to overcome the power issues with zero toxic emission. The key problem is to inject huge power to the grid, generating from renewable energy sources with traditional electrical equipment and grid infrastructure. Currently, work on DC networks is achieving great attention in distributed power generation system, which arise the problem related to the significance of DC power flow control in DC networks. Interline power flow controller (IPFC) are used to control of power flow in the multi-lines and parallel transmission lines. In this paper, a new topology for Interline DC Power Flow Controller (IDCPFC) based on the Zero Sequence Blocking Transformer (ZSBT) has been proposed and analyzed. In the proposed model, the buck converter works as a variable transformer and its current is regulated through the duty cycle of converter. In Comparison with pervious topologies the control algorithm is simple. To validate the topology, simulation results of proposed topology are investigated in this paper. Large-scale network has the characteristics of complex system, and its survivability is different from simple network. The current network survivability studies usually only aim for a specific network level or type, and seldom investigate survivability from a system perspective. In this paper, the concept of large-scale network survivability is defined from the perspective of complex system, the survivability association is analyzed based upon the correlation characteristics of complex system, and the structural model of large-scale network survivability association is established and its properties are analyzed. On the basis of survivability association properties, the survivability association function is defined based upon set pair analysis theory, which is utilized to characterize the survivability association degree among subsystems in large-scale network. Finally, the effectiveness of the model proposed in this paper is validated through case study.",,,978-1-4673-8979-2,1149-1153, ," 2nd IEEE Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)2nd IEEE Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)",,out_of_scope,
4148,"Title:A high voltage resonant inverter for dielectric discharge barrier cell plasma applications

 Among the applications of dielectric barrier discharge cells (DBDCs), the generation of cold plasmas for the degradation of toxic organic compounds has received a great deal of attention in recent years. Normally, a DBDC can be energized by means of a high voltage power supply operating at line frequency. In this paper, the analysis, design and construction of a power resonant series-inverter is presented; this inverter is aimed to operate at high-voltages/high-frequencies, and its suitability to excite a DBDC is investigated. The topological analysis of the inverter is carried out using the fundamental approximation technique, where the DBDC has been modelled as a capacitor whose terminals' voltage is provided by a pulse transformer. Both, the DBDC and the pulse transformer are represented in an RLC equivalent circuit. The resonant inverter is designed to operate in a region where the transfer function is load dependent. The series resonant inverter performance has been experimentally tested in a DBDC application, showing its effectiveness in the generation of the electron discharge by means of a charge/voltage figure of merit.","Godoy-Cabrera, O; Benítez-Read, JS; López-Callejas, R; Pacheco-Sotelo, J","Pacheco-Sotelo, Joel/AAC-6056-2020",,A high voltage resonant inverter for dielectric discharge barrier cell plasma applications,87,3,10.1080/002072100132255 ,Article ,2000.0,"Among the applications of dielectric barrier discharge cells (DBDCs), the generation of cold plasmas for the degradation of toxic organic compounds has received a great deal of attention in recent years. Normally, a DBDC can be energized by means of a high voltage power supply operating at line frequency. In this paper, the analysis, design and construction of a power resonant series-inverter is presented; this inverter is aimed to operate at high-voltages/high-frequencies, and its suitability to excite a DBDC is investigated. The topological analysis of the inverter is carried out using the fundamental approximation technique, where the DBDC has been modelled as a capacitor whose terminals' voltage is provided by a pulse transformer. Both, the DBDC and the pulse transformer are represented in an RLC equivalent circuit. The resonant inverter is designed to operate in a region where the transfer function is load dependent. The series resonant inverter performance has been experimentally tested in a DBDC application, showing its effectiveness in the generation of the electron discharge by means of a charge/voltage figure of merit.",0020-7217,,,361-376, , ,,out_of_scope,
4149,"Title:A Study of Multilingual Toxic Text Detection Approaches under Imbalanced Sample Distribution

 Multilingual characteristics, lack of annotated data, and imbalanced sample distribution are the three main challenges for toxic comment analysis in a multilingual setting. This paper proposes a multilingual toxic text classifier which adopts a novel fusion strategy that combines different loss functions and multiple pre-training models. Specifically, the proposed learning pipeline starts with a series of pre-processing steps, including translation, word segmentation, purification, text digitization, and vectorization, to convert word tokens to a vectorized form suitable for the downstream tasks. Two models, multilingual bidirectional encoder representation from transformers (MBERT) and XLM-RoBERTa (XLM-R), are employed for pre-training through Masking Language Modeling (MLM) and Translation Language Modeling (TLM), which incorporate semantic and contextual information into the models. We train six base models and fuse them to obtain three fusion models using the F1 scores as the weights. The models are evaluated on the Jigsaw Multilingual Toxic Comment dataset. Experimental results show that the best fusion model outperforms the two state-of-the-art models, MBERT and XLM-R, in F1 score by 5.05% and 0.76%, respectively, verifying the effectiveness and robustness of the proposed fusion strategy.","Song, Guizhe; Huang, Degen; Xiao, Zhifeng","Wang, Shan/JPX-1098-2023; wang, wenxin/JOZ-3291-2023","SONG, GUIZHE/0000-0002-2588-7010",A Study of Multilingual Toxic Text Detection Approaches under Imbalanced Sample Distribution,12,5,10.3390/info12050205 ,Article ,2021.0,"Multilingual characteristics, lack of annotated data, and imbalanced sample distribution are the three main challenges for toxic comment analysis in a multilingual setting. This paper proposes a multilingual toxic text classifier which adopts a novel fusion strategy that combines different loss functions and multiple pre-training models. Specifically, the proposed learning pipeline starts with a series of pre-processing steps, including translation, word segmentation, purification, text digitization, and vectorization, to convert word tokens to a vectorized form suitable for the downstream tasks. Two models, multilingual bidirectional encoder representation from transformers (MBERT) and XLM-RoBERTa (XLM-R), are employed for pre-training through Masking Language Modeling (MLM) and Translation Language Modeling (TLM), which incorporate semantic and contextual information into the models. We train six base models and fuse them to obtain three fusion models using the F1 scores as the weights. The models are evaluated on the Jigsaw Multilingual Toxic Comment dataset. Experimental results show that the best fusion model outperforms the two state-of-the-art models, MBERT and XLM-R, in F1 score by 5.05% and 0.76%, respectively, verifying the effectiveness and robustness of the proposed fusion strategy.",,2078-2489,,, , ,,detection#methodology,
4150,"Title:A national TSCA operating permit application of ISV

 Geosafe Corporation of Richland, WA has recently completed the testing and evaluation process to allow for a modification to its National Toxic Substance Control Act (TSCA) Operating Permit for the In Situ Vitrification (ISV) technology. Testing was performed at a site located in Spokane WA, which was contaminated with PCBs and PAHs from activities associated with the maintenance and disposal of used transformers. This paper presents the process through which Geosafe was granted the original National TSCA Operating Permit and its subsequent modification including: 1) project planning, 2) site preparation activities, 3) treatment of the contaminated soil and debris, 4) extensive sampling and analysis, and 5) evaluation of the data and granting of the permit.","Campbell, BE; Timmerman, CL",,,A national TSCA operating permit application of ISV,,, ,Proceedings Paper ,1998.0,"Geosafe Corporation of Richland, WA has recently completed the testing and evaluation process to allow for a modification to its National Toxic Substance Control Act (TSCA) Operating Permit for the In Situ Vitrification (ISV) technology. Testing was performed at a site located in Spokane WA, which was contaminated with PCBs and PAHs from activities associated with the maintenance and disposal of used transformers. This paper presents the process through which Geosafe was granted the original National TSCA Operating Permit and its subsequent modification including: 1) project planning, 2) site preparation activities, 3) treatment of the contaminated soil and debris, 4) extensive sampling and analysis, and 5) evaluation of the data and granting of the permit.",,,1-57477-061-6,231-236, , 1st International Conference on Remediation of Chlorinated and Recalcitrant Compounds1st International Conference on Remediation of Chlorinated and Recalcitrant Compounds,,out_of_scope,
4151,"Title:Automatic Misogyny Detection in Social Media Platforms using Attention-based Bidirectional-LSTM

 The important growth of social media and online gaming sites in recent years have increased the challenge of online moderation to keep the internet safe and without toxic content. Today, machine learning techniques play an important role in detecting inappropriate content and help moderate online interaction. Text classification using Natural Language Processing (NLP) methods has been extensively studied using deep learning models and transformers which have shown impressive results. Despite this, specific classification tasks on limited datasets still need to be improved. In this paper, we propose an approach based on an Attention-Based Bidirectional LSTM model and a combination of custom features to enhance automatic misogyny identification (AMI) on social media. We present a multi-lingual study of the phenomena by carrying out different classification experiments. Our study focuses on selecting most important features to improve the model for misogyny detection. The proposed model outperforms many state-of-the-art approaches across multiple datasets.","Rahali, Abir; Akhloufi, Moulay A.; Therien-Daniel, Anne-Marie; Brassard-Gourdeau, Eloi",,"RAHALI, ABIR/0000-0001-9742-9441",Automatic Misogyny Detection in Social Media Platforms using Attention-based Bidirectional-LSTM,,,10.1109/SMC52423.2021.9659158 ,Proceedings Paper ,2021.0,"The important growth of social media and online gaming sites in recent years have increased the challenge of online moderation to keep the internet safe and without toxic content. Today, machine learning techniques play an important role in detecting inappropriate content and help moderate online interaction. Text classification using Natural Language Processing (NLP) methods has been extensively studied using deep learning models and transformers which have shown impressive results. Despite this, specific classification tasks on limited datasets still need to be improved. In this paper, we propose an approach based on an Attention-Based Bidirectional LSTM model and a combination of custom features to enhance automatic misogyny identification (AMI) on social media. We present a multi-lingual study of the phenomena by carrying out different classification experiments. Our study focuses on selecting most important features to improve the model for misogyny detection. The proposed model outperforms many state-of-the-art approaches across multiple datasets.",1062-922X,,978-1-6654-4207-7,2706-2711, ," IEEE International Conference on Systems, Man, and Cybernetics (SMC)IEEE International Conference on Systems, Man, and Cybernetics (SMC)",,detection#methodology,
4152,"Title:Energy efficiency comparison of dimmable electromagnetic and electronic ballast systems

 Compared with electromagnetic ballasts, electronic ballasts have much shorter lifetime and are not recyclable. This prompts new concerns about their environmental impacts due to the accumulation of toxic and non-biodegradable waste components and materials. In this paper, the combined use of a central dimming system with low-loss electromagnetic ballasts is compared with electronic ballasts. Experimental results have confirmed that the use of a central dimming system for large electromagnetic ballast driven lighting systems can be as energy efficient as electronic ballasts. Considering the long lifetime of electromagnetic ballasts and recyclability of their magnetic chokes, this project shows that such combined technology can provide an improved environmental-friendly and energy-saving solution for large-scale electric lighting systems.","Hui, SYR; Yan, W; Chung, H; Tam, PW; Ho, G","Hui, Ron/E-1485-2011","Chung, Henry/0000-0003-4890-8256",Energy efficiency comparison of dimmable electromagnetic and electronic ballast systems,,, ,Proceedings Paper ,2005.0,"Compared with electromagnetic ballasts, electronic ballasts have much shorter lifetime and are not recyclable. This prompts new concerns about their environmental impacts due to the accumulation of toxic and non-biodegradable waste components and materials. In this paper, the combined use of a central dimming system with low-loss electromagnetic ballasts is compared with electronic ballasts. Experimental results have confirmed that the use of a central dimming system for large electromagnetic ballast driven lighting systems can be as energy efficient as electronic ballasts. Considering the long lifetime of electromagnetic ballasts and recyclability of their magnetic chokes, this project shows that such combined technology can provide an improved environmental-friendly and energy-saving solution for large-scale electric lighting systems.",0197-2618,,0-7803-9208-6,2775-2781, , 40th Annual Meeting of the IEEE-Industry-Applications-Society40th Annual Meeting of the IEEE-Industry-Applications-Society,,out_of_scope,
4153,"Title:Automatic Mushroom Species Classification Model for Foodborne Disease Prevention Based on Vision Transformer

 Mushrooms are the fleshy, spore-bearing structure of certain fungi, produced by a group of mycelia and buried in a substratum. Mushrooms are classified as edible, medicinal, and poisonous. However, many poisoning incidents occur yearly by consuming wild mushrooms. Thousands of poisoning incidents are reported each year globally, and 80% of these are from unidentified species of mushrooms. Mushroom poisoning is one of the most serious food safety issues worldwide. Motivated by this problem, this study uses an open-source mushroom dataset and employs several data augmentation approaches to decrease the probability of model overfitting. We propose a novel deep learning pipeline (ViT-Mushroom) for mushroom classification using the Vision Transformer large network (ViT-L/32). We compared the performance of our method against that of a convolutional neural network (CNN). We visualized the high-dimensional outputs of the ViT-L/32 model to achieve the interpretability of ViT-L/32 using the t-distributed stochastic neighbor embedding (t-SNE) method. The results show that ViT-L/32 is the best on the testing dataset, with an accuracy score of 95.97%. These results surpass previous approaches in reducing intraclass variability and generating well-separated feature embeddings. The proposed method is a promising deep learning model capable of automatically classifying mushroom species, helping wild mushroom consumers avoid eating toxic mushrooms, safeguarding food safety, and preventing public health incidents of food poisoning. The results will offer valuable resources for food scientists, nutritionists, and the public health sector regarding the safety and quality of mushrooms.","Wang, Boyuan",,"WANG, BOYUAN/0000-0003-2439-7615",Automatic Mushroom Species Classification Model for Foodborne Disease Prevention Based on Vision Transformer,2022,,10.1155/2022/1173102 ,Article ,2022.0,"Mushrooms are the fleshy, spore-bearing structure of certain fungi, produced by a group of mycelia and buried in a substratum. Mushrooms are classified as edible, medicinal, and poisonous. However, many poisoning incidents occur yearly by consuming wild mushrooms. Thousands of poisoning incidents are reported each year globally, and 80% of these are from unidentified species of mushrooms. Mushroom poisoning is one of the most serious food safety issues worldwide. Motivated by this problem, this study uses an open-source mushroom dataset and employs several data augmentation approaches to decrease the probability of model overfitting. We propose a novel deep learning pipeline (ViT-Mushroom) for mushroom classification using the Vision Transformer large network (ViT-L/32). We compared the performance of our method against that of a convolutional neural network (CNN). We visualized the high-dimensional outputs of the ViT-L/32 model to achieve the interpretability of ViT-L/32 using the t-distributed stochastic neighbor embedding (t-SNE) method. The results show that ViT-L/32 is the best on the testing dataset, with an accuracy score of 95.97%. These results surpass previous approaches in reducing intraclass variability and generating well-separated feature embeddings. The proposed method is a promising deep learning model capable of automatically classifying mushroom species, helping wild mushroom consumers avoid eating toxic mushrooms, safeguarding food safety, and preventing public health incidents of food poisoning. The results will offer valuable resources for food scientists, nutritionists, and the public health sector regarding the safety and quality of mushrooms.",0146-9428,1745-4557,,, , ,,out_of_scope,
4154,"Title:Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts

 Dialogue models trained on human conversations inadvertently learn to generate toxic responses. In addition to producing explicitly offensive utterances, these models can also implicitly insult a group or individual by aligning themselves with an offensive statement. To better understand the dynamics of contextually offensive language, we investigate the stance of dialogue model responses in offensive Reddit conversations. Specifically, we create TOXICHAT, a crowd-annotated dataset of 2,000 Reddit threads and model responses labeled with offensive language and stance. Our analysis reveals that 42% of human responses agree with toxic comments, whereas only 13% agree with safe comments. This undesirable behavior is learned by neural dialogue models, such as DialoGPT, which we show are two times more likely to agree with offensive comments. To enable automatic detection of offensive language, we fine-tuned transformer-based classifiers on TOXICHAT that achieve 0.71 F-1 for offensive labels and 0.53 Macro-F-1 for stance labels. Finally, we quantify the effectiveness of controllable text generation (CTG) methods to mitigate the tendency of neural dialogue models to agree with offensive comments. Compared to the baseline, our best CTG model achieves a 19% reduction in agreement with offensive comments and produces 29% fewer offensive replies. Our work highlights the need for further efforts to characterize and analyze inappropriate behavior in dialogue models, in order to help make them safer.(1)","Baheti, Ashutosh; Sap, Maarten; Ritter, Alan; Riedl, Mark",,"Sap, Maarten/0000-0002-0701-4654",Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts,,, ,Proceedings Paper ,2021.0,"Dialogue models trained on human conversations inadvertently learn to generate toxic responses. In addition to producing explicitly offensive utterances, these models can also implicitly insult a group or individual by aligning themselves with an offensive statement. To better understand the dynamics of contextually offensive language, we investigate the stance of dialogue model responses in offensive Reddit conversations. Specifically, we create TOXICHAT, a crowd-annotated dataset of 2,000 Reddit threads and model responses labeled with offensive language and stance. Our analysis reveals that 42% of human responses agree with toxic comments, whereas only 13% agree with safe comments. This undesirable behavior is learned by neural dialogue models, such as DialoGPT, which we show are two times more likely to agree with offensive comments. To enable automatic detection of offensive language, we fine-tuned transformer-based classifiers on TOXICHAT that achieve 0.71 F-1 for offensive labels and 0.53 Macro-F-1 for stance labels. Finally, we quantify the effectiveness of controllable text generation (CTG) methods to mitigate the tendency of neural dialogue models to agree with offensive comments. Compared to the baseline, our best CTG model achieves a 19% reduction in agreement with offensive comments and produces 29% fewer offensive replies. Our work highlights the need for further efforts to characterize and analyze inappropriate behavior in dialogue models, in order to help make them safer.(1)",,,978-1-955917-09-4,4846-4862, , Conference on Empirical Methods in Natural Language Processing (EMNLP)Conference on Empirical Methods in Natural Language Processing (EMNLP),,Gen_dataset#detox,
4155,"Title:Identification of efflux proteins based on contextual representations with deep bidirectional transformer encoders

 Efflux proteins are the transport proteins expressed in the plasma membrane, which are involved in the movement of unwanted toxic substances through specific efflux pumps. Several studies based on computational approaches have been proposed to predict transport proteins and thereby to understand the mechanism of the movement of ions across cell membranes. However, few methods were developed to identify efflux proteins. This paper presents an approach based on the contextualized word embeddings from Bidirectional Encoder Representations from Transformers (BERT) with the Support Vector Machine (SVM) classifier. BERT is the most effective pre-trained language model that performs exceptionally well on several Natural Language Processing (NLP) tasks. Therefore, the contextualized representations from BERT were implemented to incorporate multiple interpretations of identical amino acids in the sequence. A dataset of efflux proteins with annotations was first established. The feature vectors were extracted by transferring protein data through the hidden layers of the pretrained model. Our proposed method was trained on complete training datasets to identify efflux proteins and achieved the accuracies of 94.15% and 87.13% in the independent tests on membrane and transport datasets, respectively. This study opens a research avenue for the implementation of contextualized word embeddings in Bioinformatics and Computational Biology.","Taju, Semmy Wellem; Shah, Syed Muazzam Ali; Ou, Yu-Yen","Ou, Yu-Yen/AAA-1716-2022; Taju, Semmy Wellem/GNP-3877-2022","Shah, Syed Muazzam Ali/0000-0003-0129-2474",Identification of efflux proteins based on contextual representations with deep bidirectional transformer encoders,633,,10.1016/j.ab.2021.114416 ,Article ,2021.0,"Efflux proteins are the transport proteins expressed in the plasma membrane, which are involved in the movement of unwanted toxic substances through specific efflux pumps. Several studies based on computational approaches have been proposed to predict transport proteins and thereby to understand the mechanism of the movement of ions across cell membranes. However, few methods were developed to identify efflux proteins. This paper presents an approach based on the contextualized word embeddings from Bidirectional Encoder Representations from Transformers (BERT) with the Support Vector Machine (SVM) classifier. BERT is the most effective pre-trained language model that performs exceptionally well on several Natural Language Processing (NLP) tasks. Therefore, the contextualized representations from BERT were implemented to incorporate multiple interpretations of identical amino acids in the sequence. A dataset of efflux proteins with annotations was first established. The feature vectors were extracted by transferring protein data through the hidden layers of the pretrained model. Our proposed method was trained on complete training datasets to identify efflux proteins and achieved the accuracies of 94.15% and 87.13% in the independent tests on membrane and transport datasets, respectively. This study opens a research avenue for the implementation of contextualized word embeddings in Bioinformatics and Computational Biology.",0003-2697,1096-0309,,, , ,,out_of_scope,
4156,"Title:PCBs, PBDEs and dioxin-related compounds in floor dust from an informal end-of-life vehicle recycling site in northern Vietnam: contamination levels and implications for human exposure

 Floor dusts from Vietnamese end-of-life vehicle (ELV)-processing households were investigated to elucidate the contamination levels and exposure risk of polychlorinated biphenyls (PCBs), polybrominated diphenyl ethers (PBDEs) and dioxin-related compounds (DRCs). The concentrations were in order of PBDEs (260-11,000, median 280 ng/g overall) > PCBs (19-2200, median 140 ng/g) > dioxin-like PCBs (8.8-450, median 22 ng/g) >> polybrominated dibenzo-p-dioxin/dibenzofurans (PBDD/Fs, 2000-28,000, median 8500 pg/g) > polychlorinated dibenzo-p-dioxin/dibenzofurans (PCDD/Fs, 440-4100, median 1800 pg/g) > MoBPCDD/Fs (1.9-1200, median 250 pg/g). Concentrations of PCBs and DRCs were higher than those reported for Vietnamese urban houses, indicating ELV processing as a significant source of these contaminants. Higher concentrations of PCBs relative to PBDEs suggest the abundance of old electrical capacitors/transformers in ELVs. The PBDD/F and PCDD/F profiles were indicative of DecaBDE-containing materials and combustion sources, respectively. PBDFs, PCDFs and DL-PCBs were the most important dioxin-like toxic equivalent (TEQ) contributors. The estimated PCB and TEQ intake doses from dust ingestion approached or exceeded the reference doses for children living in some ELV-processing households, indicating potential health risk. More comprehensive risk assessment of the exposure to PCBs and DRCs is required for residents of informal ELV recycling sites.","Takahashi, Shin; Nguyen Minh Tue; Takayanagi, Chika; Le Huu Tuyen; Suzuki, Go; Matsukami, Hidenori; Pham Hung Viet; Kunisue, Tatsuya; Tanabe, Shinsuke","Matsukami, Hidenori/AAT-5330-2021; Suzuki, Go/AAW-1595-2021; Kunisue, Tatsuya/G-4171-2014; Pham, Viet H./C-8027-2017; Hung, Viet Pham/AAB-5775-2022","Suzuki, Go/0000-0002-4001-5632; Kunisue, Tatsuya/0000-0002-8167-1564; Matsukami, Hidenori/0000-0002-2751-4103","PCBs, PBDEs and dioxin-related compounds in floor dust from an informal end-of-life vehicle recycling site in northern Vietnam: contamination levels and implications for human exposure",19,4,10.1007/s10163-016-0571-3 ,Article ,2017.0,"Floor dusts from Vietnamese end-of-life vehicle (ELV)-processing households were investigated to elucidate the contamination levels and exposure risk of polychlorinated biphenyls (PCBs), polybrominated diphenyl ethers (PBDEs) and dioxin-related compounds (DRCs). The concentrations were in order of PBDEs (260-11,000, median 280 ng/g overall) > PCBs (19-2200, median 140 ng/g) > dioxin-like PCBs (8.8-450, median 22 ng/g) >> polybrominated dibenzo-p-dioxin/dibenzofurans (PBDD/Fs, 2000-28,000, median 8500 pg/g) > polychlorinated dibenzo-p-dioxin/dibenzofurans (PCDD/Fs, 440-4100, median 1800 pg/g) > MoBPCDD/Fs (1.9-1200, median 250 pg/g). Concentrations of PCBs and DRCs were higher than those reported for Vietnamese urban houses, indicating ELV processing as a significant source of these contaminants. Higher concentrations of PCBs relative to PBDEs suggest the abundance of old electrical capacitors/transformers in ELVs. The PBDD/F and PCDD/F profiles were indicative of DecaBDE-containing materials and combustion sources, respectively. PBDFs, PCDFs and DL-PCBs were the most important dioxin-like toxic equivalent (TEQ) contributors. The estimated PCB and TEQ intake doses from dust ingestion approached or exceeded the reference doses for children living in some ELV-processing households, indicating potential health risk. More comprehensive risk assessment of the exposure to PCBs and DRCs is required for residents of informal ELV recycling sites.",1438-4957,1611-8227,,1333-1341, , ,,out_of_scope,
4157,"Title:GraphBERT: Bridging Graph and Text for Malicious Behavior Detection on Social Media

 The development of social media (e.g., Twitter) allows users to make speeches with low cost and broad influence. Thus, social media has become a perfect place for users' malicious behaviors like committing hate crimes, spreading toxic information, abetting crimes, etc. Malicious behaviors are covert and widespread, with potential relevance regarding topic, person, place, and so on. Therefore, it is necessary to develop novel techniques to detect and disrupt malicious behavior on social media effectively. Previous research has shown promising results in extracting semantic text (speech) representation using natural language processing methods. Yet the latent relation between speeches and the connection between users behind speeches is rarely explored. In light of this, we propose a holistic model named Graph adaption BERT (GraphBERT) to detect malicious behaviors on Twitter with both semantic and relational information. Specifically, we first present a novel and a largescale corpus of tweet data to benefit both graph-based and language-based malicious behavior detection research. Then, we design a novel model GraphBERT to learn comprehensive tweet and user representation with the integration of both semantic information encoded by transformers (i.e., BERT) and relational information encoded by graph neural network. GraphBERT further leverages a weight adaption BERT module implemented between transformer layers to refine tweet embedding using relational information for malicious tweet classification. Finally, the adapted tweet embedding is used with the initial tweet representation to generate user embedding for malicious user detection. The extensive experiments on the collected Twitter data show that our model outperforms the state-of-the-art baseline methods for both tasks (i.e., malicious tweet classification and malicious user detection).","Wu, Jiele; Zhang, Chunhui; Liu, Zheyuan; Zhang, Erchi; Wilson, Steven; Zhang, Chuxu",,,GraphBERT: Bridging Graph and Text for Malicious Behavior Detection on Social Media,,,10.1109/ICDM54844.2022.00065 ,Proceedings Paper ,2022.0,"The development of social media (e.g., Twitter) allows users to make speeches with low cost and broad influence. Thus, social media has become a perfect place for users' malicious behaviors like committing hate crimes, spreading toxic information, abetting crimes, etc. Malicious behaviors are covert and widespread, with potential relevance regarding topic, person, place, and so on. Therefore, it is necessary to develop novel techniques to detect and disrupt malicious behavior on social media effectively. Previous research has shown promising results in extracting semantic text (speech) representation using natural language processing methods. Yet the latent relation between speeches and the connection between users behind speeches is rarely explored. In light of this, we propose a holistic model named Graph adaption BERT (GraphBERT) to detect malicious behaviors on Twitter with both semantic and relational information. Specifically, we first present a novel and a largescale corpus of tweet data to benefit both graph-based and language-based malicious behavior detection research. Then, we design a novel model GraphBERT to learn comprehensive tweet and user representation with the integration of both semantic information encoded by transformers (i.e., BERT) and relational information encoded by graph neural network. GraphBERT further leverages a weight adaption BERT module implemented between transformer layers to refine tweet embedding using relational information for malicious tweet classification. Finally, the adapted tweet embedding is used with the initial tweet representation to generate user embedding for malicious user detection. The extensive experiments on the collected Twitter data show that our model outperforms the state-of-the-art baseline methods for both tasks (i.e., malicious tweet classification and malicious user detection).",1550-4786,,978-1-6654-5099-7,548-557, , 22nd IEEE International Conference on Data Mining (ICDM)22nd IEEE International Conference on Data Mining (ICDM),,Gen_dataset#detection#methodology,
4158,"Title:Detection of Homophobia & Transphobia in Malayalam and Tamil: Exploring Deep Learning Methods

 The increase in abusive content on online social media platforms is impacting the social life of online users. Use of offensive and hate speech has been making social media toxic. Homophobia and transphobia constitute offensive comments against LGBT + community. It becomes imperative to detect and handle these comments, to timely flag or issue awarning to users indulging in such behaviour. However, automated detection of such content is a challenging task, more so in Dravidian languages which are identified as low resource languages. Motivated by this, the paper attempts to explore applicability of different deep learning models for classification of the social media comments in Malayalam and Tamil languages as homophobic, transphobic and non-anti-LGBT + content. The popularly used deep learning models-Convolutional Neural Network (CNN), Long Short Term Memory (LSTM) using GloVe embedding and transformerbased learning models (Multilingual BERT and IndicBERT) are applied to the classification problem. Results obtained show that IndicBERT outperforms the other implemented models, with obtained weighted average F1-score of 0.86 and 0.77 for Malayalam and Tamil, respectively. Therefore, the present work confirms higher performance of IndicBERT on the given task on selected Dravidian languages.","Sharma, Deepawali; Gupta, Vedika; Singh, Vivek Kumar","Gupta, Vedika/JNR-1706-2023",,Detection of Homophobia & Transphobia in Malayalam and Tamil: Exploring Deep Learning Methods,1798,,10.1007/978-3-031-28183-9_15 ,Proceedings Paper ,2023.0,"The increase in abusive content on online social media platforms is impacting the social life of online users. Use of offensive and hate speech has been making social media toxic. Homophobia and transphobia constitute offensive comments against LGBT + community. It becomes imperative to detect and handle these comments, to timely flag or issue awarning to users indulging in such behaviour. However, automated detection of such content is a challenging task, more so in Dravidian languages which are identified as low resource languages. Motivated by this, the paper attempts to explore applicability of different deep learning models for classification of the social media comments in Malayalam and Tamil languages as homophobic, transphobic and non-anti-LGBT + content. The popularly used deep learning models-Convolutional Neural Network (CNN), Long Short Term Memory (LSTM) using GloVe embedding and transformerbased learning models (Multilingual BERT and IndicBERT) are applied to the classification problem. Results obtained show that IndicBERT outperforms the other implemented models, with obtained weighted average F1-score of 0.86 and 0.77 for Malayalam and Tamil, respectively. Therefore, the present work confirms higher performance of IndicBERT on the given task on selected Dravidian languages.",1865-0929,1865-0937,978-3-031-28182-2; 978-3-031-28183-9,217-226, , 2nd International Conference on Advanced Network Technologies and Intelligent Computing (ANTIC)2nd International Conference on Advanced Network Technologies and Intelligent Computing (ANTIC),,detection#evaluation#methodology#out_but_toxicity,
4159,"Title:Intelligent energy management system for renewable energy driven ship

 Utilisation of renewable energy sources (RES) is increasing day by day to reduce greenhouse emissions. The toxic emission from ship is the main concern in marine sector. Here, utilisation of renewable energy for propulsion and electrification of accessories in a ship are proposed. Microgrid with AC and DC bus is developed using solar panels, wind mills, fuel cell, diesel generator, and energy storage devices. Energy management system with two fuzzy logic controllers (FLCs) is used to select and manage energy in the microgrid. Selection of source is decided by FLC1 based on the availability of RES. Generation of control pulses for inter-linking converters is decided by FLC2 based on variation in solar irradiance and wind velocity. The microgrid with RES is simulated using MATLAB/SIMULINK. The results show that uncertainty in RES can be handled by FLCs to provide a continuous power supply for transportation of ship and its accessories.","Manickavasagam, Krishnan; Thotakanama, Naveen Kumar; Puttaraj, Vineetha","THOTAKANAMA, NAVEEN KUMAR/AAS-1677-2020; Thotakanama, Naveen Kumar/ABF-4472-2021; Krishnan, Manickavasagam/I-1872-2019; Krishnan, Manickavasagam/U-7322-2019","THOTAKANAMA, NAVEEN KUMAR/0000-0001-5931-7510; Thotakanama, Naveen Kumar/0000-0001-5931-7510; Krishnan, Manickavasagam/0000-0002-3707-8317; Krishnan, Manickavasagam/0000-0002-4943-0007; Puttaraj, Vineetha/0000-0002-4964-8161",Intelligent energy management system for renewable energy driven ship,9,1,10.1049/iet-est.2018.5022 ,Article ,2019.0,"Utilisation of renewable energy sources (RES) is increasing day by day to reduce greenhouse emissions. The toxic emission from ship is the main concern in marine sector. Here, utilisation of renewable energy for propulsion and electrification of accessories in a ship are proposed. Microgrid with AC and DC bus is developed using solar panels, wind mills, fuel cell, diesel generator, and energy storage devices. Energy management system with two fuzzy logic controllers (FLCs) is used to select and manage energy in the microgrid. Selection of source is decided by FLC1 based on the availability of RES. Generation of control pulses for inter-linking converters is decided by FLC2 based on variation in solar irradiance and wind velocity. The microgrid with RES is simulated using MATLAB/SIMULINK. The results show that uncertainty in RES can be handled by FLCs to provide a continuous power supply for transportation of ship and its accessories.",2042-9738,2042-9746,,24-34, , ,,out_of_scope,
4160,"Title:De-coloration of hazardous dye from water system using chemically modified Ficus carica adsorbent

 Batch adsorption studies were carried out using a novel chemically modified Ficus carica fiber adsorbent for the removal of toxic methylene blue dye from aqueous solution. The modification of F. carica fiber was carried out using acrylic acid in the presence of ceric ammonium nitrate as the initiator to change the surface morphology of the natural fibers for the improvement of interfacial adhesion between matrix and fibers. The adsorbent was characterized by scanning electron microscopy and Fourier transformer infrared spectrometer. The effect of process parameters such as pH, adsorbent dosage, concentration, reaction temperature, contact time, electrolyte and surfactants were studied. The adsorption equilibrium was represented with Langmuir, Freundlich, Tempkin, and Harkin's-Jura and Dubinin-Radushkevich isotherm models. The maximum adsorption capacity of methylene blue onto adsorbent was 75.87 mg g(-1). The pseudo-first order, pseudo-second order and intraparticle diffusion models were tested and it is revealed that adsorption of methylene blue onto adsorbent follows the intraparticle diffusion model. Thermodynamic parameters such as enthalpy change (Delta H), entropy change (Delta S) and free energy change (Delta G) were evaluated to predict the nature of adsorption. The calculated values of H. AS and Delta G for uptake of MB were 33.13 kJ mol(-1), 173.46 J mol(-1) K-1 and -19.43 kJ mol(-1), respectively. This indicated the endothermic and spontaneous nature of the adsorption process. The desorption experiment showed that 60.04% of dye was recovered from the aqueous system. (C) 2012 Elsevier B.V. All rights reserved.","Gupta, Vinod Kumar; Pathania, Deepak; Agarwal, Shilpi; Sharma, Shikha","Sharma, Shikha/HPC-0370-2023; Agarwal, Shilpi/AFN-6205-2022",,De-coloration of hazardous dye from water system using chemically modified Ficus carica adsorbent,174,,10.1016/j.molliq.2012.07.017 ,Article ,2012.0,"Batch adsorption studies were carried out using a novel chemically modified Ficus carica fiber adsorbent for the removal of toxic methylene blue dye from aqueous solution. The modification of F. carica fiber was carried out using acrylic acid in the presence of ceric ammonium nitrate as the initiator to change the surface morphology of the natural fibers for the improvement of interfacial adhesion between matrix and fibers. The adsorbent was characterized by scanning electron microscopy and Fourier transformer infrared spectrometer. The effect of process parameters such as pH, adsorbent dosage, concentration, reaction temperature, contact time, electrolyte and surfactants were studied. The adsorption equilibrium was represented with Langmuir, Freundlich, Tempkin, and Harkin's-Jura and Dubinin-Radushkevich isotherm models. The maximum adsorption capacity of methylene blue onto adsorbent was 75.87 mg g(-1). The pseudo-first order, pseudo-second order and intraparticle diffusion models were tested and it is revealed that adsorption of methylene blue onto adsorbent follows the intraparticle diffusion model. Thermodynamic parameters such as enthalpy change (Delta H), entropy change (Delta S) and free energy change (Delta G) were evaluated to predict the nature of adsorption. The calculated values of H. AS and Delta G for uptake of MB were 33.13 kJ mol(-1), 173.46 J mol(-1) K-1 and -19.43 kJ mol(-1), respectively. This indicated the endothermic and spontaneous nature of the adsorption process. The desorption experiment showed that 60.04% of dye was recovered from the aqueous system. (C) 2012 Elsevier B.V. All rights reserved.",0167-7322,1873-3166,,86-94, , ,,out_of_scope,
4161,"Title:NLP applied to occupational health: MEDDOPROF shared task at IberLEF 2021 on automatic recognition, classification and normalization of professions and occupations from medical texts

 Among the socio-demographic patient characteristics, occupations play an important role regarding not only occupational health, work-related accidents and exposure to toxic/pathogenic agents, but also their impact on general physical and mental health. This paper presents the Medical Documents Profession Recognition (MEDDOPROF) shared task (held within IberLEF/SEPLN 2021), focused on the recognition and normalization of occupations in medical documents in Spanish. MEDDOPROF proposes three challenges: NER (recognition of professions, employment statuses and activities in text), CLASS (classifying each occupation mention to its holder, i.e. patient or family member) and NORM (normalizing mentions to their identifier in ESCO or SNOMED CT). From the total of 40 registered teams, 15 submitted a total of 94 runs for the various sub-tracks. Best-performing systems were based on deep-learning technologies (incl. transformers) and achieved 0.818 F-score in occupation detection (NER), 0.793 in classifying occupations to their referent (CLASS) and 0.619 in normalization (NORM). Future initiatives should also address multilingual aspects and application to other domains like social services, human resources, legal or job market data analytics and policy makers.","Lima-Lopez, Salvador; Farre-Maduell, Eulalia; Miranda-Escalada, Antonio; Briva-Iglesias, Vicent; Krallinger, Martin",,"Farre-Maduell, Eulalia/0000-0002-9116-1592; Krallinger, Martin/0000-0002-2646-8782; Lima Lopez, Salvador/0000-0002-7384-1877","NLP applied to occupational health: MEDDOPROF shared task at IberLEF 2021 on automatic recognition, classification and normalization of professions and occupations from medical texts",,67,10.26342/2021-67-21 ,Article ,2021.0,"Among the socio-demographic patient characteristics, occupations play an important role regarding not only occupational health, work-related accidents and exposure to toxic/pathogenic agents, but also their impact on general physical and mental health. This paper presents the Medical Documents Profession Recognition (MEDDOPROF) shared task (held within IberLEF/SEPLN 2021), focused on the recognition and normalization of occupations in medical documents in Spanish. MEDDOPROF proposes three challenges: NER (recognition of professions, employment statuses and activities in text), CLASS (classifying each occupation mention to its holder, i.e. patient or family member) and NORM (normalizing mentions to their identifier in ESCO or SNOMED CT). From the total of 40 registered teams, 15 submitted a total of 94 runs for the various sub-tracks. Best-performing systems were based on deep-learning technologies (incl. transformers) and achieved 0.818 F-score in occupation detection (NER), 0.793 in classifying occupations to their referent (CLASS) and 0.619 in normalization (NORM). Future initiatives should also address multilingual aspects and application to other domains like social services, human resources, legal or job market data analytics and policy makers.",1135-5948,1989-7553,,243-256, , ,,out_of_scope,
4162,"Title:Multimedia emissions inventory of polychlorinated Biphenyls for the US great lakes states

 Polychlorinated biphenyls (PCBs) were banned in the United States in 1979, and since then a significant decline in their release to the environment has been observed. This decline has now reached a plateau. Several new regulatory programs have been put in place to further reduce PCB emissions/releases. However, our ability to measure the effectiveness of these regulatory/voluntary programs and to Support regional fate/transport and source/receptor modeling efforts depend on reliable emission information. In this study, we attempt to improve the emission inventory for PCBs by compiling and analyzing the multimedia total PCB emission /release data reported for the U.S Great Lakes states for each year from 1990 to 2000. Although Toxic Release Inventory (TRI), National Emissions Inventory (NEI), Great Lakes Regional Air Toxic Emissions Inventory (GLRATEI), and Integrated Atmospheric Deposition Network (IADN) data formed the basis of estimating air emissions, we used the TRI, National Response Center (NRC), and PCB transformer inventory data to estimate PCB releases to land. We used the Permit Compliance System and NRC data to obtain estimates of PCB discharges to water systems in the Great Lakes states. The Remedial Action Plans for each area of concern were the primary source for estimating PCB loads of dredged sediments. On the basis of the NEI, IADN, and GLRATEI data, the total air emissions within the decade were approximately 126 t. The regionwide discharges to water systems and releases to land in the form of landfills and accidental spills in 1990-2000 were estimated as approximately 170 and 3225 t, respectively. We estimated that approximately 1.3 million t of PCB-contaminated sediment were removed or targeted for removal in five lakes of the U.S. portion of the Great Lakes basin. We stress that these estimates were based on reported amounts and the unreported PCB releases/emissions could result in significantly higher estimates.","Erdal, Serap; Berman, Laurel; Hryhorczuk, Daniel O.","Hryhorczuk, Daniel/X-6409-2019","Hryhorczuk, Daniel/0000-0001-7625-6756",Multimedia emissions inventory of polychlorinated Biphenyls for the US great lakes states,58,8,10.3155/1047-3289.58.8.1022 ,Article ,2008.0,"Polychlorinated biphenyls (PCBs) were banned in the United States in 1979, and since then a significant decline in their release to the environment has been observed. This decline has now reached a plateau. Several new regulatory programs have been put in place to further reduce PCB emissions/releases. However, our ability to measure the effectiveness of these regulatory/voluntary programs and to Support regional fate/transport and source/receptor modeling efforts depend on reliable emission information. In this study, we attempt to improve the emission inventory for PCBs by compiling and analyzing the multimedia total PCB emission /release data reported for the U.S Great Lakes states for each year from 1990 to 2000. Although Toxic Release Inventory (TRI), National Emissions Inventory (NEI), Great Lakes Regional Air Toxic Emissions Inventory (GLRATEI), and Integrated Atmospheric Deposition Network (IADN) data formed the basis of estimating air emissions, we used the TRI, National Response Center (NRC), and PCB transformer inventory data to estimate PCB releases to land. We used the Permit Compliance System and NRC data to obtain estimates of PCB discharges to water systems in the Great Lakes states. The Remedial Action Plans for each area of concern were the primary source for estimating PCB loads of dredged sediments. On the basis of the NEI, IADN, and GLRATEI data, the total air emissions within the decade were approximately 126 t. The regionwide discharges to water systems and releases to land in the form of landfills and accidental spills in 1990-2000 were estimated as approximately 170 and 3225 t, respectively. We estimated that approximately 1.3 million t of PCB-contaminated sediment were removed or targeted for removal in five lakes of the U.S. portion of the Great Lakes basin. We stress that these estimates were based on reported amounts and the unreported PCB releases/emissions could result in significantly higher estimates.",1096-2247,2162-2906,,1022-1032, , ,,out_of_scope,
4163,"Title:Isocyanurate-based periodic mesoporous organosilica (PMO-ICS): a highly efficient and recoverable nanocatalyst for the one-pot synthesis of substituted imidazoles and benzimidazoles

 Isocyanurate bridging periodic mesoporous organosilica (PMO-ICS) was shown to be a highly active and efficient recyclable catalyst for the three-component synthesis of imidazole derivatives from benzoin, different aldehydes and ammonium acetate under mild reaction conditions in short reaction times and good to excellent yields in EtOH. Also, benzimidazole derivatives were efficiently prepared from o-phenylenediamine and different aldehydes in the presence of PMO-ICS. Moreover, the catalyst was also recovered and reused at least four times without a significant decrease in its activity. The PMO-ICS catalyst was characterized by Fourier transformer infrared (FTIR) spectroscopy, thermogravimetry analysis (TGA), powder X-ray diffraction (XRD) and nitrogen adsorption-desorption isotherm (NADI) techniques as well as field emission scanning electron microscopy (FESEM) and transmission electron microscopy (TEM). Compared to the classical methodologies, this method illustrated significant advantages including low loading of the catalyst, avoiding the use of toxic transition metals or reactive reagents for modification of the catalytic activity, short reaction times, high to excellent yields, easy separation and purification of the products, and reusability of the catalyst.","Dekamin, Mohammad G.; Arefi, Elham; Yaghoubi, Amene","Dekamin, Mohammad G./F-5165-2011","Dekamin, Mohammad G./0000-0002-7018-7363",Isocyanurate-based periodic mesoporous organosilica (PMO-ICS): a highly efficient and recoverable nanocatalyst for the one-pot synthesis of substituted imidazoles and benzimidazoles,6,90,10.1039/c6ra14550g ,Article ,2016.0,"Isocyanurate bridging periodic mesoporous organosilica (PMO-ICS) was shown to be a highly active and efficient recyclable catalyst for the three-component synthesis of imidazole derivatives from benzoin, different aldehydes and ammonium acetate under mild reaction conditions in short reaction times and good to excellent yields in EtOH. Also, benzimidazole derivatives were efficiently prepared from o-phenylenediamine and different aldehydes in the presence of PMO-ICS. Moreover, the catalyst was also recovered and reused at least four times without a significant decrease in its activity. The PMO-ICS catalyst was characterized by Fourier transformer infrared (FTIR) spectroscopy, thermogravimetry analysis (TGA), powder X-ray diffraction (XRD) and nitrogen adsorption-desorption isotherm (NADI) techniques as well as field emission scanning electron microscopy (FESEM) and transmission electron microscopy (TEM). Compared to the classical methodologies, this method illustrated significant advantages including low loading of the catalyst, avoiding the use of toxic transition metals or reactive reagents for modification of the catalytic activity, short reaction times, high to excellent yields, easy separation and purification of the products, and reusability of the catalyst.",,2046-2069,,86982-86988, , ,,out_of_scope,
4164,"Title:SAS-UNet: Modified encoder-decoder network for the segmentation of obscenity in images

 Obscene content on online platforms can be harmful to society in several ways. Firstly, it can negatively impact the mental health of individuals who view or are exposed to it, particularly children and vulnerable individuals. Secondly, it can lead to the spread of illegal content such as child pornography or revenge porn, which can cause significant harm to the victims involved. Lastly, it can create a toxic and unsafe online environment, where cyberbullying, harassment, and hate speech thrive, ultimately leading to social division and harm to the community. As a result, it is important to promote the responsible and respectful use of online platforms to prevent such harm. Therefore, it is important to segment such obscene regions present in images across social media platforms. To deal with the issue, we have proposed a modified encoder-decoder-based technique entitled sandglass-block encoder with attention skip and swin-based bottleneck (SAS-UNet) for the segmentation of obscenity in nude/obscene images. Our proposed method SASUNet incorporates the usage of a sandglass block in the encoder section of U-Net, a swin transformer in the bottleneck, and CBAM inclusion at the skip connection. The proposed model is trained and validated with the segmented obscene image (SOI) dataset. The collected obscene images were segmented precisely to build a binary mask of all the obscene images. The proposed SAS-UNet achieved a precision of 94.30%, 93.22% recall, 92.31% of mDC value, and 91.42% of mIOU value which outperformed the existing algorithms.","Samal, Sonali; Gadekellu, Thippa Reddy; Rajput, Pankaj; Zhang, Yu-Dong; Balabantaray, Bunil Kumar","Balabantaray, Bunil/M-9711-2013; Zhang, Yudong/I-7633-2013; Gadekallu, Thippa Reddy/T-4254-2019","Balabantaray, Bunil/0000-0002-2769-7122; Zhang, Yudong/0000-0002-4870-1493; Gadekallu, Thippa Reddy/0000-0003-0097-801X",SAS-UNet: Modified encoder-decoder network for the segmentation of obscenity in images,,,10.1109/CCGridW59191.2023.00022 ,Proceedings Paper ,2023.0,"Obscene content on online platforms can be harmful to society in several ways. Firstly, it can negatively impact the mental health of individuals who view or are exposed to it, particularly children and vulnerable individuals. Secondly, it can lead to the spread of illegal content such as child pornography or revenge porn, which can cause significant harm to the victims involved. Lastly, it can create a toxic and unsafe online environment, where cyberbullying, harassment, and hate speech thrive, ultimately leading to social division and harm to the community. As a result, it is important to promote the responsible and respectful use of online platforms to prevent such harm. Therefore, it is important to segment such obscene regions present in images across social media platforms. To deal with the issue, we have proposed a modified encoder-decoder-based technique entitled sandglass-block encoder with attention skip and swin-based bottleneck (SAS-UNet) for the segmentation of obscenity in nude/obscene images. Our proposed method SASUNet incorporates the usage of a sandglass block in the encoder section of U-Net, a swin transformer in the bottleneck, and CBAM inclusion at the skip connection. The proposed model is trained and validated with the segmented obscene image (SOI) dataset. The collected obscene images were segmented precisely to build a binary mask of all the obscene images. The proposed SAS-UNet achieved a precision of 94.30%, 93.22% recall, 92.31% of mDC value, and 91.42% of mIOU value which outperformed the existing algorithms.",,,979-8-3503-0208-0,45-51, ," 23rd IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGrid)23rd IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",,detection#out_but_toxicity,
4165,"Title:Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT

 Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: offensiveand not offensive. To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%.","Haq, Ijazul; Qiu, Weidong; Guo, Jie; Tang, Peng","Haq, Ijazul/HKV-9993-2023","Haq, Ijazul/0000-0002-5594-7504",Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT,9,,10.7717/peerj-cs.1617 ,Article ,2023.0,"Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: offensiveand not offensive. To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%.",,2376-5992,,, , ,,out_but_toxicity,
4166,"Title:A BERT-Based Transfer Learning Approach for Hate Speech Detection in Online Social Media

 Generated hateful and toxic content by a portion of users in social media is a rising phenomenon that motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. We not only need an efficient automatic hate speech detection model based on advanced machine learning and natural language processing, but also a sufficiently large amount of annotated data to train a model. The lack of a sufficient amount of labelled hate speech data, along with the existing biases, has been the main issue in this domain of research. To address these needs, in this study we introduce a novel transfer learning approach based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers). More specifically, we investigate the ability of BERT at capturing hateful context within social media content by using new fine-tuning methods based on transfer learning. To evaluate our proposed approach, we use two publicly available datasets that have been annotated for racism, sexism, hate, or offensive content on Twitter. The results show that our solution obtains considerable performance on these datasets in terms of precision and recall in comparison to existing approaches. Consequently, our model can capture some biases in data annotation and collection process and can potentially lead us to a more accurate model.","Mozafari, Marzieh; Farahbakhsh, Reza; Crespi, Noel","Crespi, Noel/ABE-7052-2020; mozafari, marzieh/ABE-5011-2020","Crespi, Noel/0000-0003-2962-192X; mozafari, marzieh/0000-0002-1384-7548",A BERT-Based Transfer Learning Approach for Hate Speech Detection in Online Social Media,881,,10.1007/978-3-030-36687-2_77 ,Proceedings Paper ,2020.0,"Generated hateful and toxic content by a portion of users in social media is a rising phenomenon that motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. We not only need an efficient automatic hate speech detection model based on advanced machine learning and natural language processing, but also a sufficiently large amount of annotated data to train a model. The lack of a sufficient amount of labelled hate speech data, along with the existing biases, has been the main issue in this domain of research. To address these needs, in this study we introduce a novel transfer learning approach based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers). More specifically, we investigate the ability of BERT at capturing hateful context within social media content by using new fine-tuning methods based on transfer learning. To evaluate our proposed approach, we use two publicly available datasets that have been annotated for racism, sexism, hate, or offensive content on Twitter. The results show that our solution obtains considerable performance on these datasets in terms of precision and recall in comparison to existing approaches. Consequently, our model can capture some biases in data annotation and collection process and can potentially lead us to a more accurate model.",1860-949X,1860-9503,978-3-030-36687-2; 978-3-030-36686-5,928-940, , 8th International Conference on Complex Networks and Their Applications (COMPLEX NETWORKS)8th International Conference on Complex Networks and Their Applications (COMPLEX NETWORKS),,Use_dataset#detection#evaluation,
4167,"Title:Large pre-trained language models contain human-like biases of what is right and wrong to do

 Large language models identify patterns in the relations between words and capture their relations in an embedding space. Schramowski and colleagues show that a direction in this space can be identified that separates 'right' and 'wrong' actions as judged by human survey participants.Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a 'moral direction' which can be computed, for example, by a PCA, in the embedding space. The computed 'moral direction' can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the 'moral direction' can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.","Schramowski, Patrick; Turan, Cigdem; Andersen, Nico; Rothkopf, Constantin A.; Kersting, Kristian",,"Schramowski, Patrick/0000-0003-1231-7120; Turan-Schwiewager, Cigdem/0000-0002-4836-6023; Rothkopf, Constantin/0000-0002-5636-0801",Large pre-trained language models contain human-like biases of what is right and wrong to do,4,3,10.1038/s42256-022-00458-8 ,Article ,2022.0,"Large language models identify patterns in the relations between words and capture their relations in an embedding space. Schramowski and colleagues show that a direction in this space can be identified that separates 'right' and 'wrong' actions as judged by human survey participants.Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a 'moral direction' which can be computed, for example, by a PCA, in the embedding space. The computed 'moral direction' can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the 'moral direction' can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.",,2522-5839,,258-+, , ,,detox#evaluation#methodology,
4168,"Title:Named entity recognition in the food field based on BERT and Adversarial training

 Aiming at extracting effective entity information from unstructured corpus in the food field, a named entity recognition (NER) method based on BERT (Bidirectional Encoder Representations from Transformers) and Adversarial training is proposed. The task of NER requires both the identification of entity boundaries and entity types. In order to improve the precision of identifying entity boundaries, we use the BERT word embedding method to enhance the feature extraction ability of input information. To optimize the NER task, adversarial training is introduced, which not only use the shared information obtained from task training of Chinese word segmentation (CWS) and NER, but also prevent the private information of CWS task from generating noise. The experiment is based on the corpus of two categories which are Chinese food safety cases and People's Daily news, respectively. Among them, the Chinese food safety cases data set is used to train the NER task, and People's Daily news data set is used to train the CWS task. We use adversarial training to improve the precision of the NER task for entity recognition (including person, location, organization, food and toxic substance). The Precision rate, Recall rate and F1 score are 95.46%, 89.50% and 92.38% respectively. Experimental results show that this method has a high precision rate for Chinese NER task where the boundary of a specific domain is indistinct.","Dong, Zhe; Shao, RuoQi; Chen, YuLiang; Chen, JiaWei",,,Named entity recognition in the food field based on BERT and Adversarial training,,,10.1109/CCDC52312.2021.9601522 ,Proceedings Paper ,2021.0,"Aiming at extracting effective entity information from unstructured corpus in the food field, a named entity recognition (NER) method based on BERT (Bidirectional Encoder Representations from Transformers) and Adversarial training is proposed. The task of NER requires both the identification of entity boundaries and entity types. In order to improve the precision of identifying entity boundaries, we use the BERT word embedding method to enhance the feature extraction ability of input information. To optimize the NER task, adversarial training is introduced, which not only use the shared information obtained from task training of Chinese word segmentation (CWS) and NER, but also prevent the private information of CWS task from generating noise. The experiment is based on the corpus of two categories which are Chinese food safety cases and People's Daily news, respectively. Among them, the Chinese food safety cases data set is used to train the NER task, and People's Daily news data set is used to train the CWS task. We use adversarial training to improve the precision of the NER task for entity recognition (including person, location, organization, food and toxic substance). The Precision rate, Recall rate and F1 score are 95.46%, 89.50% and 92.38% respectively. Experimental results show that this method has a high precision rate for Chinese NER task where the boundary of a specific domain is indistinct.",1948-9439,,978-1-6654-4089-9,2219-2226, , 33rd Chinese Control and Decision Conference (CCDC)33rd Chinese Control and Decision Conference (CCDC),,out_of_scope,
4169,"Title:CERT-RNN: Towards Certifying the Robustness of Recurrent Neural Networks

 Certifiable robustness, the functionality of verifying whether the given region surrounding a data point admits any adversarial example, provides guaranteed security for neural networks deployed in adversarial environments. A plethora of work has been proposed to certify the robustness of feed-forward networks, e.g., FCNs and CNNs. Yet, most existing methods cannot be directly applied to recurrent neural networks (RNNs), due to their sequential inputs and unique operations.In this paper, we present CERT-RNN, a general framework for certifying the robustness of RNNs. Specifically, through detailed analysis for the intrinsic property of the unique function in different ranges, we exhaustively discuss different cases for the exact formula of bounding planes, based on which we design several precise and efficient abstract transformers for the unique calculations in RNNs. CERT-RNN significantly outperforms the state-of-the-art methods (e.g., POPQORN [25]) in terms of (i) effectiveness - it provides much tighter robustness bounds, and (ii) efficiency - it scales to much more complex models. Through extensive evaluation, we validate CERT-RNN's superior performance across various network architectures (e.g., vanilla RNN and LSTM) and applications (e.g., image classification, sentiment analysis, toxic comment detection, and malicious URL detection). For instance, for the RNN-2-32 model on the MNIST sequence dataset, the robustness bound certified by CERT-RNN is on average 1.86 times larger than that by POPQORN. Besides certifying the robustness of given RNNs, CERT-RNN also enables a range of practical applications including evaluating the provable effectiveness for various defenses (i.e., the defense with a larger robustness region is considered to be more robust), improving the robustness of RNNs (i.e., incorporating CERT-RNN with verified robust training) and identifying sensitive words (i.e., the word with the smallest certified robustness bound is considered to be the most sensitive word in a sentence), which helps build more robust and interpretable deep learning systems. We will open-source CERTRNN for facilitating the DNN security research.","Du, Tianyu; Ji, Shouling; Shen, Lujia; Zhang, Yao; Li, Jinfeng; Shi, Jie; Fang, Chengfang; Yin, Jianwei; Beyah, Raheem; Wang, Ting","Du, Tianyu/JAZ-0604-2023; li, jinfeng/GVS-5425-2022; Li, Jin/GYQ-5363-2022",,CERT-RNN: Towards Certifying the Robustness of Recurrent Neural Networks,,,10.1145/3460120.3484538 ,Proceedings Paper ,2021.0,"Certifiable robustness, the functionality of verifying whether the given region surrounding a data point admits any adversarial example, provides guaranteed security for neural networks deployed in adversarial environments. A plethora of work has been proposed to certify the robustness of feed-forward networks, e.g., FCNs and CNNs. Yet, most existing methods cannot be directly applied to recurrent neural networks (RNNs), due to their sequential inputs and unique operations.In this paper, we present CERT-RNN, a general framework for certifying the robustness of RNNs. Specifically, through detailed analysis for the intrinsic property of the unique function in different ranges, we exhaustively discuss different cases for the exact formula of bounding planes, based on which we design several precise and efficient abstract transformers for the unique calculations in RNNs. CERT-RNN significantly outperforms the state-of-the-art methods (e.g., POPQORN [25]) in terms of (i) effectiveness - it provides much tighter robustness bounds, and (ii) efficiency - it scales to much more complex models. Through extensive evaluation, we validate CERT-RNN's superior performance across various network architectures (e.g., vanilla RNN and LSTM) and applications (e.g., image classification, sentiment analysis, toxic comment detection, and malicious URL detection). For instance, for the RNN-2-32 model on the MNIST sequence dataset, the robustness bound certified by CERT-RNN is on average 1.86 times larger than that by POPQORN. Besides certifying the robustness of given RNNs, CERT-RNN also enables a range of practical applications including evaluating the provable effectiveness for various defenses (i.e., the defense with a larger robustness region is considered to be more robust), improving the robustness of RNNs (i.e., incorporating CERT-RNN with verified robust training) and identifying sensitive words (i.e., the word with the smallest certified robustness bound is considered to be the most sensitive word in a sentence), which helps build more robust and interpretable deep learning systems. We will open-source CERTRNN for facilitating the DNN security research.",,,978-1-4503-8454-4,516-534, , ACM SIGSAC Conference on Computer and Communications Security (ACM CCS)ACM SIGSAC Conference on Computer and Communications Security (ACM CCS),,evaluation#methodology,
4170,"Title:Electrolysis - Inevitable Energy Transformer in a World of Sustainable Energy

 The standard of living of a country is now judged by the energy it consumes, since the energy is the basic input to sustain the economic growth by providing the basic amenities of life for the entire population of the country. Nuclear energy, solar energy, wind energy, geothermal energy and tidal energy are some of the sources from which energy can be obtained. However, transport of the energy is not possible using these new unconventional energy sources and more than that some of them are available intermittently. In this context many scientists and engineers believe that the hydrogen energy system will be the best in view of the advantages over its chief-rivals electricity and methanol.Hydrogen has all the favorable properties for transport, distribution and generation of heat and electricity. As for as the safety point of view, it is neither toxic nor radioactive and so does not cause any damage. Even though the hydrogen/oxidizer mixtures have a wide ignition range, tending to rapid dejlagration, because of lightness it will diffuse upwards quite fast or burn away quickly. The availability of hydrogen as an energy carrier in economically significant amounts will be in the near future and its cost will be comparable when the fossil resources become scarce. Energy from the later is likely to become costlier if the firm adherence of environmental regulations is closely followed. Hydrogen can be manufactured by a variety of processes and this review paper mainly focuses on hydrogen generation by water electrolysis.","Vasudevan, S.","VASUDEVAN, S./O-5124-2014","VASUDEVAN, S./0000-0003-4879-2847",Electrolysis - Inevitable Energy Transformer in a World of Sustainable Energy,,, ,Proceedings Paper ,2013.0,"The standard of living of a country is now judged by the energy it consumes, since the energy is the basic input to sustain the economic growth by providing the basic amenities of life for the entire population of the country. Nuclear energy, solar energy, wind energy, geothermal energy and tidal energy are some of the sources from which energy can be obtained. However, transport of the energy is not possible using these new unconventional energy sources and more than that some of them are available intermittently. In this context many scientists and engineers believe that the hydrogen energy system will be the best in view of the advantages over its chief-rivals electricity and methanol.Hydrogen has all the favorable properties for transport, distribution and generation of heat and electricity. As for as the safety point of view, it is neither toxic nor radioactive and so does not cause any damage. Even though the hydrogen/oxidizer mixtures have a wide ignition range, tending to rapid dejlagration, because of lightness it will diffuse upwards quite fast or burn away quickly. The availability of hydrogen as an energy carrier in economically significant amounts will be in the near future and its cost will be comparable when the fossil resources become scarce. Energy from the later is likely to become costlier if the firm adherence of environmental regulations is closely followed. Hydrogen can be manufactured by a variety of processes and this review paper mainly focuses on hydrogen generation by water electrolysis.",,,978-1-4673-6150-7; 978-1-4673-6149-1,, , International Conference on Energy Efficient Technologies for Sustainability (ICEETS)International Conference on Energy Efficient Technologies for Sustainability (ICEETS),,out_of_scope,
4171,"Title:Which Discriminator for Cooperative Text Generation?

 Language models generate texts by successively predicting probability distributions for next tokens given past ones. A growing field of interest tries to leverage external information in the decoding process so that the generated texts have desired properties, such as being more natural, non toxic, faithful, or having a specific writing style. A solution is to use a classifier at each generation step, resulting in a cooperative environment where the classifier guides the decoding of the language model distribution towards relevant texts for the task at hand. In this paper, we examine three families of (transformer-based) discriminators for this specific task of cooperative decoding: bidirectional, left-to-right and generative ones. We evaluate the pros and cons of these different types of discriminators for cooperative generation, exploring respective accuracy on classification tasks along with their impact on the resulting sample quality and computational performances. We also provide the code of a batched implementation of the powerful cooperative decoding strategy used for our experiments, the Monte Carlo Tree Search, working with each discriminator for Natural Language Generation.","Chaffin, Antoine; Scialom, Thomas; Lamprier, Sylvain; Staiano, Jacopo; Piwowarski, Benjamin; Kijak, Ewa; Claveau, Vincent","Claveau, Vincent/HTQ-1196-2023","Claveau, Vincent/0000-0002-3459-0550",Which Discriminator for Cooperative Text Generation?,,,10.1145/3477495.3531858 ,Proceedings Paper ,2022.0,"Language models generate texts by successively predicting probability distributions for next tokens given past ones. A growing field of interest tries to leverage external information in the decoding process so that the generated texts have desired properties, such as being more natural, non toxic, faithful, or having a specific writing style. A solution is to use a classifier at each generation step, resulting in a cooperative environment where the classifier guides the decoding of the language model distribution towards relevant texts for the task at hand. In this paper, we examine three families of (transformer-based) discriminators for this specific task of cooperative decoding: bidirectional, left-to-right and generative ones. We evaluate the pros and cons of these different types of discriminators for cooperative generation, exploring respective accuracy on classification tasks along with their impact on the resulting sample quality and computational performances. We also provide the code of a batched implementation of the powerful cooperative decoding strategy used for our experiments, the Monte Carlo Tree Search, working with each discriminator for Natural Language Generation.",,,978-1-4503-8732-3,2360-2365, , 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),,detox#evaluation#methodology,
4172,"Title:A fusion of BERT, machine learning and manual approach for fake news detection

 A large number of users around the globe have preferred to read news and the latest information from the Internet, especially social media, leaving behind the traditional approach of print media. On the one hand, the Internet is a constructive medium to spread the latest news and information briefly. On the other hand, malicious users are very active on the Internet and spread fake news, which becomes viral within a few minutes. The spread of fake news has become a serious threat as many users now rely on Internet news without verification. In this digital world, it is easy to spread any toxic information over the Internet, like hate speech, extremism, propaganda, and political agendas. It is a big challenge in today's digital world to mitigate the spread of fake news; hence, there is a need for an automatic computational tool that can assist in measuring the credibility of news. This study aims to deliver a solution where fake news from Twitter and website-based articles can be detected using the Natural Language Processing (NLP) technique, Bidirectional Encoder Representations from Transformers (BERT), other machine learning classification algorithms, and manual program-based approaches. A dataset with fake and real labels for the textual content is used. Different classification algorithms are evaluated to find a suitable algorithm for delivering a fake news detector. The evaluations are based on machine learning and a program-based approach. The textual content that the user provides, such as an article or tweet, can confirm the legitimacy of fake news. This website offers fake news detection for both website-based news articles and tweets from Twitter in English, Arabic, and Urdu.","Al Ghamdi, Mohammed A.; Bhatti, Muhammad Shahid; Saeed, Atif; Gillani, Zeeshan; Almotiri, Sultan H.","Al Ghamdi, Mohammed/GPS-4826-2022","Al Ghamdi, Mohammed/0000-0002-5993-5236","A fusion of BERT, machine learning and manual approach for fake news detection",,,10.1007/s11042-023-16669-z ,Article; Early Access ,,"A large number of users around the globe have preferred to read news and the latest information from the Internet, especially social media, leaving behind the traditional approach of print media. On the one hand, the Internet is a constructive medium to spread the latest news and information briefly. On the other hand, malicious users are very active on the Internet and spread fake news, which becomes viral within a few minutes. The spread of fake news has become a serious threat as many users now rely on Internet news without verification. In this digital world, it is easy to spread any toxic information over the Internet, like hate speech, extremism, propaganda, and political agendas. It is a big challenge in today's digital world to mitigate the spread of fake news; hence, there is a need for an automatic computational tool that can assist in measuring the credibility of news. This study aims to deliver a solution where fake news from Twitter and website-based articles can be detected using the Natural Language Processing (NLP) technique, Bidirectional Encoder Representations from Transformers (BERT), other machine learning classification algorithms, and manual program-based approaches. A dataset with fake and real labels for the textual content is used. Different classification algorithms are evaluated to find a suitable algorithm for delivering a fake news detector. The evaluations are based on machine learning and a program-based approach. The textual content that the user provides, such as an article or tweet, can confirm the legitimacy of fake news. This website offers fake news detection for both website-based news articles and tweets from Twitter in English, Arabic, and Urdu.",1380-7501,1573-7721,,, , ,,out_of_scope,
4173,"Title:Artificial neural networks for insights into adsorption capacity of industrial dyes using carbon-based materials

 Organic waste-derived carbon-based materials (CBMs) are commonly applied in sustainable wastewater treatment and waste management. CBMs can remove toxic, non-biodegradable and carcinogenic pollutants such as dyes which include indigo, triphenylmethyl, azo, anthraquinone and phthalocyanine derivatives. Nonetheless, their diverse composition, surface properties, presence of numerous surface functional groups and the altering adsorption experimental conditions to which they are applied against the elimination of organic dyes make it challenging to completely understand the removal mechanism. Herein, a dataset of 1514 data points was compiled from various published peer-reviewed journals along with additional adsorption experiments conducted in this study. Artificial neural networks (ANN) based machine learning (ML) model was compared with other ML and a deep learning model named Tab-Transformer and the findings proposed ANN showed superior prediction performance for adsorption capacity as a function of adsorbent synthesis conditions, adsorbent physical characteristics and adsorption experimental conditions. The hyperparameters of ANN model was optimized using Bayesian optimizer and the batch size, activation and units were proven to be more important than the number of hidden layers and learning rate. The ANN model exhibits a higher coefficient of determination (R2 = 0.98) and lower root mean square error (RMSE = 46.95 mg/g) values for test dataset. Feature importance using SHapley Additive exPlanations (SHAP) analysis suggested that the adsorption characteristics with 51.4% was the most important in the ANN prediction followed by the adsorption experimental condition (31.2%) and adsorbent synthesis condition (17.4%). Moreover, the impact of six most important features were individually analyzed. Finally, a detailed discussion on the environmental impact of the presented ANN model is also included.","Iftikhar, Sara; Zahra, Nallain; Rubab, Fazila; Sumra, Raazia Abrar; Khan, Muhammad Burhan; Abbas, Ather; Jaffari, Zeeshan Haider",,"Abbas, Ather/0000-0002-0031-745X",Artificial neural networks for insights into adsorption capacity of industrial dyes using carbon-based materials,326,,10.1016/j.seppur.2023.124891 ,Article ,2023.0,"Organic waste-derived carbon-based materials (CBMs) are commonly applied in sustainable wastewater treatment and waste management. CBMs can remove toxic, non-biodegradable and carcinogenic pollutants such as dyes which include indigo, triphenylmethyl, azo, anthraquinone and phthalocyanine derivatives. Nonetheless, their diverse composition, surface properties, presence of numerous surface functional groups and the altering adsorption experimental conditions to which they are applied against the elimination of organic dyes make it challenging to completely understand the removal mechanism. Herein, a dataset of 1514 data points was compiled from various published peer-reviewed journals along with additional adsorption experiments conducted in this study. Artificial neural networks (ANN) based machine learning (ML) model was compared with other ML and a deep learning model named Tab-Transformer and the findings proposed ANN showed superior prediction performance for adsorption capacity as a function of adsorbent synthesis conditions, adsorbent physical characteristics and adsorption experimental conditions. The hyperparameters of ANN model was optimized using Bayesian optimizer and the batch size, activation and units were proven to be more important than the number of hidden layers and learning rate. The ANN model exhibits a higher coefficient of determination (R2 = 0.98) and lower root mean square error (RMSE = 46.95 mg/g) values for test dataset. Feature importance using SHapley Additive exPlanations (SHAP) analysis suggested that the adsorption characteristics with 51.4% was the most important in the ANN prediction followed by the adsorption experimental condition (31.2%) and adsorbent synthesis condition (17.4%). Moreover, the impact of six most important features were individually analyzed. Finally, a detailed discussion on the environmental impact of the presented ANN model is also included.",1383-5866,1873-3794,,, , ,,out_of_scope,
4174,"Title:Economic Integration of Renewable and Conventional Power Sources-A Case Study

 In this study, we have presented an optimal microgrid design that ensures the uninterrupted energy supply to Mirpur University of Engineering and Technology (MUST), Azad Jammu and Kashmir AJK, Pakistan at the cheapest price by using reliable energy resources. The availability of energy resources, environmental viability, and economic feasibility are the key parameters of design. The available resources for the MUST site include the National grid, Solar photovoltaic (SPV), Battery bank, and Diesel generator. The data of electrical load, solar illumination, atmospheric temperature at the university, diesel fuel cost, SPV module lifetime, SPV degradation factor, SPV efficiency, SPV cost, battery cost, battery life, national grid energy price, load shedding and toxic emissions have been considered valuables in designing the hybrid micro-grid. The difference in net present cost (NPC) of the optimal design and the worst design is calculated by considering the above parameters. The proposed optimal microgrid design supplies energy to the load using SPV, Diesel generator, and battery bank with NPC of $250,546 and the renewable fraction of 99%. Whereas the worst design includes the Diesel generator and battery bank as energy supplying sources with the NPC of $2.14 M and a renewable fraction of 0%. Simulations performed using HOMER Pro software (HOMER Energy, HOMER Pro-3.11, Boulder, CO, USA) proved that after considering all the data and requirements mentioned above, out of 979 feasible designs, the proposed hybrid microgrid design is best suitable for MUST.","Awan, Muhammad Mateen Afzal; Javed, Muhammad Yaqoob; Asghar, Aamer Bilal; Ejsmont, Krzysztof; Zia-ur-Rehman","Ejsmont, Krzysztof/AAW-5055-2020; Asghar, Aamer Bilal/AHD-9118-2022; Javed, Muhammad Yaqoob/C-3487-2017","Ejsmont, Krzysztof/0000-0003-1516-0878; Asghar, Aamer Bilal/0000-0002-9708-257X; Javed, Muhammad Yaqoob/0000-0002-6449-1035; , Muhammad Mateen Afzal Awan/0000-0002-7354-5058",Economic Integration of Renewable and Conventional Power Sources-A Case Study,15,6,10.3390/en15062141 ,Article ,2022.0,"In this study, we have presented an optimal microgrid design that ensures the uninterrupted energy supply to Mirpur University of Engineering and Technology (MUST), Azad Jammu and Kashmir AJK, Pakistan at the cheapest price by using reliable energy resources. The availability of energy resources, environmental viability, and economic feasibility are the key parameters of design. The available resources for the MUST site include the National grid, Solar photovoltaic (SPV), Battery bank, and Diesel generator. The data of electrical load, solar illumination, atmospheric temperature at the university, diesel fuel cost, SPV module lifetime, SPV degradation factor, SPV efficiency, SPV cost, battery cost, battery life, national grid energy price, load shedding and toxic emissions have been considered valuables in designing the hybrid micro-grid. The difference in net present cost (NPC) of the optimal design and the worst design is calculated by considering the above parameters. The proposed optimal microgrid design supplies energy to the load using SPV, Diesel generator, and battery bank with NPC of $250,546 and the renewable fraction of 99%. Whereas the worst design includes the Diesel generator and battery bank as energy supplying sources with the NPC of $2.14 M and a renewable fraction of 0%. Simulations performed using HOMER Pro software (HOMER Energy, HOMER Pro-3.11, Boulder, CO, USA) proved that after considering all the data and requirements mentioned above, out of 979 feasible designs, the proposed hybrid microgrid design is best suitable for MUST.",,1996-1073,,, , ,,out_of_scope,
4175,"Title:A Diverse Community of Metal(loid) Oxide Respiring Bacteria Is Associated with Tube Worms in the Vicinity of the Juan de Fuca Ridge Black Smoker Field

 Epibiotic bacteria associated with tube worms living in the vicinity of deep sea hydrothermal vents of the Juan de Fuca Ridge in the Pacific Ocean were investigated for the ability to respire anaerobically on tellurite, tellurate, selenite, selenate, metavanadate and orthovanadate as terminal electron acceptors. Out of 107 isolates tested, 106 were capable of respiration on one or more of these oxides, indicating that metal(loid) oxide based respiration is not only much more prevalent in nature than is generally believed, but also is an important mode of energy generation in the habitat. Partial 16S rRNA gene sequencing revealed the bacterial community to be rich and highly diverse, containing many potentially new species. Furthermore, it appears that the worms not only possess a close symbiotic relationship with chemolithotrophic sulfide-oxidizing bacteria, but also with the metal(loid) oxide transformers. Possibly they protect the worms through reduction of the toxic compounds that would otherwise be harmful to the host.","Maltman, Chris; Walter, Graham; Yurkov, Vladimir",,"Maltman, Chris/0000-0001-6859-1263",A Diverse Community of Metal(loid) Oxide Respiring Bacteria Is Associated with Tube Worms in the Vicinity of the Juan de Fuca Ridge Black Smoker Field,11,2,10.1371/journal.pone.0149812 ,Article ,2016.0,"Epibiotic bacteria associated with tube worms living in the vicinity of deep sea hydrothermal vents of the Juan de Fuca Ridge in the Pacific Ocean were investigated for the ability to respire anaerobically on tellurite, tellurate, selenite, selenate, metavanadate and orthovanadate as terminal electron acceptors. Out of 107 isolates tested, 106 were capable of respiration on one or more of these oxides, indicating that metal(loid) oxide based respiration is not only much more prevalent in nature than is generally believed, but also is an important mode of energy generation in the habitat. Partial 16S rRNA gene sequencing revealed the bacterial community to be rich and highly diverse, containing many potentially new species. Furthermore, it appears that the worms not only possess a close symbiotic relationship with chemolithotrophic sulfide-oxidizing bacteria, but also with the metal(loid) oxide transformers. Possibly they protect the worms through reduction of the toxic compounds that would otherwise be harmful to the host.",1932-6203,,,, , ,,out_of_scope,
4176,"Title:Residential Community Load Management Based on Optimal Design of Standalone HRES With Model Predictive Control

 Microgrids being an important entity in the distribution system, and to get their full advantages by incorporating maximum distributed generation, standalone hybrid renewable energy systems (HRESs), being environmentally-safe and economically-efficient, are considered as the promising solution to electrify remote areas where the grid power is not available. In this work, a techno-economic investigation with an optimal design of HRES is presented to fulfill the domestic electricity need for a residential area of the Sherani district in the Province of Baluchistan, Pakistan. Nine case studies based on PV/wind/diesel/battery are analyzed based on net present cost (NPC), cost of energy (COE), and emission to decide the feasible solution. HOMER tool is utilized to accomplish modeling and simulation for economic analysis and optimal sizing. Simulation results demonstrated that HRES with PV-wind-battery is the most viable option for the specified area, and the optimal sizing of components are also obtained with $ 28,620 NPC and $ 0.311/kWh COE which shows 81.65 % reduction in cost and 100 % preserving in toxic emission while fulfilling 100 % energy demand with 67.3 % of excess energy. Furthermore, MATLAB/Simulink modeling for the optimally designed system is built for technical analysis while its effectiveness is proved by keeping dc and ac buses voltage constant, safe operating range of battery state of charge (SOC) with active power balance between HRES components, as well as efficient ac voltage quality, regardless of generation disturbances and load fluctuations. The output signal has total harmonic distortion (THD) of 0.30 % as compared to 5.44 % with the conventional control scheme. The novelty lies in the sequential application of both HOMER and MATLAB simulations of the proposed HRES model and validation of the proposition for the studied area; by using and implementing model predictive control (MPC) of a reconfigurable inverter.","Al-Ammar, Essam A.; Habib, Habib Ur Rahman; Kotb, Kotb M.; Wang, Shaorong; Ko, Wonsuk; Elmorshedy, Mahmoud F.; Waqar, Asad","Elmorshedy, Mahmoud F./AEX-1221-2022; HABIB, HABIB UR RAHMAN/ISS-7615-2023; Ko, Wonsuk/AAX-3800-2021; Kotb, Kotb M./X-4915-2018; HABIB, HABIB UR RAHMAN/ACL-1356-2022; Al-Ammar, Essam A./AFU-3208-2022","Elmorshedy, Mahmoud F./0000-0001-7900-4351; Kotb, Kotb M./0000-0002-9601-6167; HABIB, HABIB UR RAHMAN/0000-0003-3380-1851; Al-Ammar, Essam A./0000-0003-1386-3713; Wang, Shaorong/0000-0001-6239-2845; Waqar, Asad/0000-0001-6500-0990",Residential Community Load Management Based on Optimal Design of Standalone HRES With Model Predictive Control,8,,10.1109/ACCESS.2020.2965250 ,Article ,2020.0,"Microgrids being an important entity in the distribution system, and to get their full advantages by incorporating maximum distributed generation, standalone hybrid renewable energy systems (HRESs), being environmentally-safe and economically-efficient, are considered as the promising solution to electrify remote areas where the grid power is not available. In this work, a techno-economic investigation with an optimal design of HRES is presented to fulfill the domestic electricity need for a residential area of the Sherani district in the Province of Baluchistan, Pakistan. Nine case studies based on PV/wind/diesel/battery are analyzed based on net present cost (NPC), cost of energy (COE), and emission to decide the feasible solution. HOMER tool is utilized to accomplish modeling and simulation for economic analysis and optimal sizing. Simulation results demonstrated that HRES with PV-wind-battery is the most viable option for the specified area, and the optimal sizing of components are also obtained with $ 28,620 NPC and $ 0.311/kWh COE which shows 81.65 % reduction in cost and 100 % preserving in toxic emission while fulfilling 100 % energy demand with 67.3 % of excess energy. Furthermore, MATLAB/Simulink modeling for the optimally designed system is built for technical analysis while its effectiveness is proved by keeping dc and ac buses voltage constant, safe operating range of battery state of charge (SOC) with active power balance between HRES components, as well as efficient ac voltage quality, regardless of generation disturbances and load fluctuations. The output signal has total harmonic distortion (THD) of 0.30 % as compared to 5.44 % with the conventional control scheme. The novelty lies in the sequential application of both HOMER and MATLAB simulations of the proposed HRES model and validation of the proposition for the studied area; by using and implementing model predictive control (MPC) of a reconfigurable inverter.",2169-3536,,,12542-12572, , ,,out_of_scope,
4177,"Title:A transgenic embryonic sexing system for Anastrepha suspensa (Diptera: Tephritidae)

 The Sterile Insect Technique (SIT) is a highly successful biologically-based strategy to control pest insect populations that relies on the large-scale release of sterilized males to render females in the field nonreproductive. For medfly, a mutant-based sexing system is available as well as a transgenic system where a tetracycline-suppressible (Tet-off) toxic molecule is female-specifically produced. However, the former classical genetic system took many years to refine, and the latter system results in female death by a poorly understood mechanism, primarily in the pupal stage after rearing costs have been incurred. Here we describe a Tet-off transgenic embryonic sexing system (TESS) for Anastrepha suspensa that uses a driver construct having the promoter from the embryo-specific A. suspensa serendipity a gene, linked to the Tet-transactivator. This was used to drive the expression of a phospho-mutated variant of the proapoptotic cell death gene, Alhid, from Anastrepha ludens. The system uses a sex-specific intron splicing cassette linked to a cell death gene lethal effector. Progeny from TESS strains heterozygous for the transgene combination were 80-100% males, whereas four double homozygous TESS strains had 100% male-only progeny, with female death limited primarily to embryogenesis. In a large-scale test, more than 30,000 eggs from two strains resulted in 100% male-only progeny. The transgenic sexing approach described here is highly effective and cost-efficient by eliminating most, if not all, female insects early in embryogenesis using a well-characterized apoptotic mechanism. Published by Elsevier Ltd.","Schetelig, Marc F.; Handler, Alfred M.","Schetelig, Marc F./AAD-2332-2019","Schetelig, Marc F./0000-0002-9217-394X",A transgenic embryonic sexing system for Anastrepha suspensa (Diptera: Tephritidae),42,10,10.1016/j.ibmb.2012.07.007 ,Article ,2012.0,"The Sterile Insect Technique (SIT) is a highly successful biologically-based strategy to control pest insect populations that relies on the large-scale release of sterilized males to render females in the field nonreproductive. For medfly, a mutant-based sexing system is available as well as a transgenic system where a tetracycline-suppressible (Tet-off) toxic molecule is female-specifically produced. However, the former classical genetic system took many years to refine, and the latter system results in female death by a poorly understood mechanism, primarily in the pupal stage after rearing costs have been incurred. Here we describe a Tet-off transgenic embryonic sexing system (TESS) for Anastrepha suspensa that uses a driver construct having the promoter from the embryo-specific A. suspensa serendipity a gene, linked to the Tet-transactivator. This was used to drive the expression of a phospho-mutated variant of the proapoptotic cell death gene, Alhid, from Anastrepha ludens. The system uses a sex-specific intron splicing cassette linked to a cell death gene lethal effector. Progeny from TESS strains heterozygous for the transgene combination were 80-100% males, whereas four double homozygous TESS strains had 100% male-only progeny, with female death limited primarily to embryogenesis. In a large-scale test, more than 30,000 eggs from two strains resulted in 100% male-only progeny. The transgenic sexing approach described here is highly effective and cost-efficient by eliminating most, if not all, female insects early in embryogenesis using a well-characterized apoptotic mechanism. Published by Elsevier Ltd.",0965-1748,,,790-795, , ,,out_of_scope,
4178,"Title:Worldwide Residential Soil Guidance Values for Total Dioxins and Dioxin-Like Compounds

 Dioxins are well-known soil contaminants. Regulatory jurisdictions worldwide use regulatory guidance values (RGV) to help manage dioxin health risks. In the US, seven federal agencies, 41 states, and seven autonomous Native American jurisdictions have established values as have jurisdictions in at least 37 other nations. Dioxin soil guidance values are highly variable. The values for 2,3,7,8-tetrachlorbenzene-p-dioxin (or total dioxin expressed as TCDD) are well-dispersed over nearly 12 orders of magnitude from 4.91x10-9 to 2.5x103mg/kg. The value spans for other dioxins and dioxin-like dibenzofurans are similar. The degree to which soil dioxin guidance value ranges can be attributed to uncertainty in direct contact cancer and noncancer risk models was analyzed. Based on bounded set uncertainty analysis, approximately 61% of the 304 TCDD RGVs identified fall within US Environmental Protection Agency risk model uncertainty bounds. Approximately 84% fall within noncancer risk model uncertainty bounds and, because the bounds overlap, approximately 60% could have been generated by either model. However, these bounds are conservative because they are based on improbable combinations of model coefficients. When Monte Carlo simulation was used to generate 95% confidence intervals, only 39% of dioxin RGVs fell below the upper bound at a target risk of 1x10(-6). (c) 2018 American Society of Civil Engineers.","Jennings, Aaron A.",,,Worldwide Residential Soil Guidance Values for Total Dioxins and Dioxin-Like Compounds,144,7,10.1061/(ASCE)EE.1943-7870.0001383 ,Article ,2018.0,"Dioxins are well-known soil contaminants. Regulatory jurisdictions worldwide use regulatory guidance values (RGV) to help manage dioxin health risks. In the US, seven federal agencies, 41 states, and seven autonomous Native American jurisdictions have established values as have jurisdictions in at least 37 other nations. Dioxin soil guidance values are highly variable. The values for 2,3,7,8-tetrachlorbenzene-p-dioxin (or total dioxin expressed as TCDD) are well-dispersed over nearly 12 orders of magnitude from 4.91x10-9 to 2.5x103mg/kg. The value spans for other dioxins and dioxin-like dibenzofurans are similar. The degree to which soil dioxin guidance value ranges can be attributed to uncertainty in direct contact cancer and noncancer risk models was analyzed. Based on bounded set uncertainty analysis, approximately 61% of the 304 TCDD RGVs identified fall within US Environmental Protection Agency risk model uncertainty bounds. Approximately 84% fall within noncancer risk model uncertainty bounds and, because the bounds overlap, approximately 60% could have been generated by either model. However, these bounds are conservative because they are based on improbable combinations of model coefficients. When Monte Carlo simulation was used to generate 95% confidence intervals, only 39% of dioxin RGVs fell below the upper bound at a target risk of 1x10(-6). (c) 2018 American Society of Civil Engineers.",0733-9372,1943-7870,,, , ,,out_of_scope,
4179,"Title:PCB Levels in Humans in an Area of PCB Transformer Recycling

 PCB levels in environmental, food, and human samples were determined around a highly PCB-contaminated town (F town), a less contaminated town (P town), and a control town (DXG). There were significant differences in PCB concentrations in the intravenous blood of the mothers and their children living in F, P, and DXG sites. In F town, PCB concentrations in the blood of the mothers averaged 190 mu g/kg lipid, as compared to 97 mu g/kg lipid in the control site. PCB concentrations in the blood of boys and girls averaged 222 and 153 Kg/kg lipid, respectively, in F town. PCB concentrations in the umbilical cord blood averaged 566.8 and 168.2 mu g/kg lipid, respectively, in the more seriously (F town) and less seriously (P town) polluted sites. Concentrations in the fetal excreta of the newborns averaged 100.06 and 1.66 mu g/kg lipid, respectively, in these sites. PCBs were detected in surface water, underground water, soil, and vegetables, and have spread in a circumference of 30 km from the PCB source and have accumulated in the food chains from surface water to fish and duck eggs and from soil to chickens and pigs. The inhabitants have taken in PCBs through these foods since the 1970s. The results implicate the e-waste recycling operations as having caused elevated PCB levels in the environment and in humans. The elevated exposure levels may have health implications for the next generation.","Ling, Bo; Han, Guangeng; Xu, Ying",,,PCB Levels in Humans in an Area of PCB Transformer Recycling,1140,,10.1196/annals.1454.030 ,Article; Proceedings Paper ,2008.0,"PCB levels in environmental, food, and human samples were determined around a highly PCB-contaminated town (F town), a less contaminated town (P town), and a control town (DXG). There were significant differences in PCB concentrations in the intravenous blood of the mothers and their children living in F, P, and DXG sites. In F town, PCB concentrations in the blood of the mothers averaged 190 mu g/kg lipid, as compared to 97 mu g/kg lipid in the control site. PCB concentrations in the blood of boys and girls averaged 222 and 153 Kg/kg lipid, respectively, in F town. PCB concentrations in the umbilical cord blood averaged 566.8 and 168.2 mu g/kg lipid, respectively, in the more seriously (F town) and less seriously (P town) polluted sites. Concentrations in the fetal excreta of the newborns averaged 100.06 and 1.66 mu g/kg lipid, respectively, in these sites. PCBs were detected in surface water, underground water, soil, and vegetables, and have spread in a circumference of 30 km from the PCB source and have accumulated in the food chains from surface water to fish and duck eggs and from soil to chickens and pigs. The inhabitants have taken in PCBs through these foods since the 1970s. The results implicate the e-waste recycling operations as having caused elevated PCB levels in the environment and in humans. The elevated exposure levels may have health implications for the next generation.",0077-8923,,978-1-57331-740-5,135-142, , 12th International Conference of the Pacific-Basin-Consortium-for-Environment-and-Health-Sciences12th International Conference of the Pacific-Basin-Consortium-for-Environment-and-Health-Sciences,,out_of_scope,
4180,"Title:Transfer Learning and Prediction Consistency for Detecting Offensive Spans of Text

 Toxic span detection is the task of recognizing offensive spans in a text snippet. Although there has been prior work on classifying text snippets as offensive or not, the task of recognizing spans responsible for the toxicity of a text is not explored yet. In this work, we introduce a novel multi-task framework for toxic span detection in which the model seeks to simultaneously predict offensive words and opinion phrases to leverage their inter-dependencies and improve the performance. Moreover, we introduce a novel regularization mechanism to encourage the consistency of the model predictions across similar inputs for toxic span detection. Our extensive experiments demonstrate the effectiveness of the proposed model compared to strong baselines.","Ben Veyseh, Amir Pouran; Xu, Ning; Tran, Quan Hung; Manjunatha, Varun; Dernoncourt, Franck; Nguyen, Thien Huu",,,Transfer Learning and Prediction Consistency for Detecting Offensive Spans of Text,,, ,Proceedings Paper ,2022.0,"Toxic span detection is the task of recognizing offensive spans in a text snippet. Although there has been prior work on classifying text snippets as offensive or not, the task of recognizing spans responsible for the toxicity of a text is not explored yet. In this work, we introduce a novel multi-task framework for toxic span detection in which the model seeks to simultaneously predict offensive words and opinion phrases to leverage their inter-dependencies and improve the performance. Moreover, we introduce a novel regularization mechanism to encourage the consistency of the model predictions across similar inputs for toxic span detection. Our extensive experiments demonstrate the effectiveness of the proposed model compared to strong baselines.",,,978-1-955917-25-4,1630-1637, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,detection#evaluation#methodology,
4181,"Title:Leveraging fusion of sequence tagging models for toxic spans detection

 The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Negative and hateful comments are averting users from sharing their opinion freely on social media platforms. It often breaks people's confidence and causes extensive damage to their mental health. Hence, identifying these toxic contents and taking appropriate measures against them is crucial to preserve a safe environment on social media. Numerous state-of-the-art approaches classify the whole content as toxic or non-toxic, but they don't distinguish the precise toxic portion from the whole content. Detecting the toxic portions is essential as it substantially aids to moderate the toxic contents through excluding the abusive parts. This paper describes our proposed approach to detect the toxic portions from text contents efficiently and accurately. We explore an ensemble of sequence labeling models including the word embedding-based Spark NLP NER (named entity recognition) deep learning model, spaCy NER model with custom toxic tags, and ALBERT NER model to identify the toxic spans. The NER-based models usually intend to capture the contextual attributes of phrases and spans that are essential for named entity recognition. As the toxic span detection task also requires us to apprehend the phrasal context for detecting toxic span, the similarity between these two tasks inspires us to exploit these NER models. Finally, we determine the final toxic spans using a prevalence-based fusion of the predictions generated by these models. The fusion strategy enables us to consolidate the diversity of these models for perceiving the phrasal context in all aspects. Experimental results achieved on the SemEval2021 toxic spans detection dataset depict that our model meticulously captures the toxic fragment and achieves a competitive result among the other state-of-the-art methods. (c) 2022 Elsevier B.V. All rights reserved.","Naim, Jannatun; Hossain, Tashin; Tasneem, Fareen; Chy, Abu Nowshed; Aono, Masaki",,,Leveraging fusion of sequence tagging models for toxic spans detection,500,,10.1016/j.neucom.2022.05.049 ,Article ,2022.0,"The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Negative and hateful comments are averting users from sharing their opinion freely on social media platforms. It often breaks people's confidence and causes extensive damage to their mental health. Hence, identifying these toxic contents and taking appropriate measures against them is crucial to preserve a safe environment on social media. Numerous state-of-the-art approaches classify the whole content as toxic or non-toxic, but they don't distinguish the precise toxic portion from the whole content. Detecting the toxic portions is essential as it substantially aids to moderate the toxic contents through excluding the abusive parts. This paper describes our proposed approach to detect the toxic portions from text contents efficiently and accurately. We explore an ensemble of sequence labeling models including the word embedding-based Spark NLP NER (named entity recognition) deep learning model, spaCy NER model with custom toxic tags, and ALBERT NER model to identify the toxic spans. The NER-based models usually intend to capture the contextual attributes of phrases and spans that are essential for named entity recognition. As the toxic span detection task also requires us to apprehend the phrasal context for detecting toxic span, the similarity between these two tasks inspires us to exploit these NER models. Finally, we determine the final toxic spans using a prevalence-based fusion of the predictions generated by these models. The fusion strategy enables us to consolidate the diversity of these models for perceiving the phrasal context in all aspects. Experimental results achieved on the SemEval2021 toxic spans detection dataset depict that our model meticulously captures the toxic fragment and achieves a competitive result among the other state-of-the-art methods. (c) 2022 Elsevier B.V. All rights reserved.",0925-2312,1872-8286,,688-702, , ,,detection#evaluation#methodology,
4182,"Title:A New Classifier Applied to Biological Early Warning Systems for Toxicity Detection

 Biological early warning systems(BEWS) has been developed in recent years. BEWS detects toxicity by tracking the physiologic responses of the whole organisms. In the paper, we apply the classification technique to the biological early warning systems and propose a new BEWS which is meaningful to biological field Meanwhile, how to select the features in such classification application is also a contribution of this paper. By using the fractal dimension theory, we define the input features which represent the organism characteristics in non-toxic or toxic environment. The experiment results show that the proposed new bio-monitoring system is effective for environmental toxicity detection.","Li, Yingrong; Seo, Dong-Hun; Lee, Won Don",,,A New Classifier Applied to Biological Early Warning Systems for Toxicity Detection,,, ,Proceedings Paper ,2008.0,"Biological early warning systems(BEWS) has been developed in recent years. BEWS detects toxicity by tracking the physiologic responses of the whole organisms. In the paper, we apply the classification technique to the biological early warning systems and propose a new BEWS which is meaningful to biological field Meanwhile, how to select the features in such classification application is also a contribution of this paper. By using the fractal dimension theory, we define the input features which represent the organism characteristics in non-toxic or toxic environment. The experiment results show that the proposed new bio-monitoring system is effective for environmental toxicity detection.",,,978-1-4244-2623-2,367-372, , 1st International Conference on the Applications of Digital Information and Web Technologies1st International Conference on the Applications of Digital Information and Web Technologies,,out_of_scope,
4183,"Title:A New Classification Application of Biological Early Warning Systems for Toxicity Detection

 Biological early warning systems(BEWS) which detects toxicity by tracking the physiologic responses of the whole organisms has been developed in recent years. In the paper, we firstly apply the C4.5 decision tree Algorithm to the biological early warning systems and propose a new BEWS which can detect toxicity by classing the flea's behavior data. The new system is meaningful to both biological field and data mining. The new classification application includes decision tree algorithm and feature selection. The new BEWS system consists of training and test process. The experiment results show that the proposed new bio-monitoring system is available for environmental toxicity detection.","Li, Yingrong; Seo, Dong-Hun; Lee, Won Don",,,A New Classification Application of Biological Early Warning Systems for Toxicity Detection,,,10.1109/CSA.2008.78 ,Proceedings Paper ,2008.0,"Biological early warning systems(BEWS) which detects toxicity by tracking the physiologic responses of the whole organisms has been developed in recent years. In the paper, we firstly apply the C4.5 decision tree Algorithm to the biological early warning systems and propose a new BEWS which can detect toxicity by classing the flea's behavior data. The new system is meaningful to both biological field and data mining. The new classification application includes decision tree algorithm and feature selection. The new BEWS system consists of training and test process. The experiment results show that the proposed new bio-monitoring system is available for environmental toxicity detection.",,,978-0-7695-3428-2,239-242, , International Symposium on Computer Science and Its ApplicationsInternational Symposium on Computer Science and Its Applications,,out_of_scope,
4184,"Title:Fish Flesh Dielectric Performance for Toxicity Detection

 This paper investigates electrical response of fish flesh using a new design of slender steel indicator acted as probe in determining dielectric properties over a frequency range from 10Hz to 100Hz. At present, most of dielectric measurement technique uses electrode contact to under test sample, biological specimen but these techniques mostly are not suitable for living specimen. Therefore, in this research, a slender metal that resembles a pointer is designed and applied to analyse the electrical response of fish flesh dielectric properties for indicator of toxicity level in the fish body. Initial findings proven that proposed technique is feasible to be implemented.","Johar, Haffiz; Baki, Shah Rizam Mohd Shah; Putra, Siti Hazurah Indera; Tahir, Nooritawati Md","Tahir, Nooritawati Md/AAM-3454-2021",,Fish Flesh Dielectric Performance for Toxicity Detection,,, ,Proceedings Paper ,2013.0,"This paper investigates electrical response of fish flesh using a new design of slender steel indicator acted as probe in determining dielectric properties over a frequency range from 10Hz to 100Hz. At present, most of dielectric measurement technique uses electrode contact to under test sample, biological specimen but these techniques mostly are not suitable for living specimen. Therefore, in this research, a slender metal that resembles a pointer is designed and applied to analyse the electrical response of fish flesh dielectric properties for indicator of toxicity level in the fish body. Initial findings proven that proposed technique is feasible to be implemented.",,,978-1-4799-2208-6,214-218, ," IEEE Conference on Systems, Process and Control (ICSPC)IEEE Conference on Systems, Process and Control (ICSPC)",,out_of_scope,
4185,"Title:Handling Bias in Toxic Speech Detection: A Survey

 Detecting online toxicity has always been a challenge due to its inherent subjectivity. Factors such as the context, geography, socio-political climate, and background of the producers and consumers of the posts play a crucial role in determining if the content can be flagged as toxic. Adoption of automated toxicity detection models in production can thus lead to a sidelining of the various groups they aim to help in the first place. It has piqued researchers' interest in examining unintended biases and their mitigation. Due to the nascent and multi-faceted nature of the work, complete literature is chaotic in its terminologies, techniques, and findings. In this article, we put together a systematic study of the limitations and challenges of existing methods for mitigating bias in toxicity detection.We look closely at proposed methods for evaluating and mitigating bias in toxic speech detection. To examine the limitations of existing methods, we also conduct a case study to introduce the concept of bias shift due to knowledge-based bias mitigation. The survey concludes with an overview of the critical challenges, research gaps, and future directions. While reducing toxicity on online platforms continues to be an active area of research, a systematic study of various biases and their mitigation strategies will help the research community produce robust and fair models.(1)","Garg, Tanmay; Masud, Sarah; Suresh, Tharun; Chakraborty, Tanmoy",,"CHAKRABORTY, TANMOY/0000-0002-0210-0369",Handling Bias in Toxic Speech Detection: A Survey,55,13S,10.1145/3580494 ,Article ,2023.0,"Detecting online toxicity has always been a challenge due to its inherent subjectivity. Factors such as the context, geography, socio-political climate, and background of the producers and consumers of the posts play a crucial role in determining if the content can be flagged as toxic. Adoption of automated toxicity detection models in production can thus lead to a sidelining of the various groups they aim to help in the first place. It has piqued researchers' interest in examining unintended biases and their mitigation. Due to the nascent and multi-faceted nature of the work, complete literature is chaotic in its terminologies, techniques, and findings. In this article, we put together a systematic study of the limitations and challenges of existing methods for mitigating bias in toxicity detection.We look closely at proposed methods for evaluating and mitigating bias in toxic speech detection. To examine the limitations of existing methods, we also conduct a case study to introduce the concept of bias shift due to knowledge-based bias mitigation. The survey concludes with an overview of the critical challenges, research gaps, and future directions. While reducing toxicity on online platforms continues to be an active area of research, a systematic study of various biases and their mitigation strategies will help the research community produce robust and fair models.(1)",0360-0300,1557-7341,,, , ,,survey,
4186,"Title:Bad Vibrations: Sensing Toxicity From In-Game Audio Features

 Toxicity in online gaming is a problem that causes harm to players, developers, and gaming communities. Toxic behaviors persist in online multiplayer games for a number of reasons, and continue to go unchecked due in large part to a lack of reliable methods to accurately detect toxicity online, in real-time, and at scale. In this article, we present a modeling approach that uses features derived from in-game verbal communication and game metadata to predict if Overwatch games are toxic. With logistic regression models, we achieve accuracy scores of 86.3% for binary (high vs. low toxicity) predictions. We discuss which features were most salient, potential application of our predictive model, and implications for toxicity detection in games. Our approach is a low-cost, low-effort, and noninvasive contribution to holistic efforts in combating toxicity in games.","Reid, Elizabeth; Mandryk, Regan L.; Beres, Nicole A.; Klarkowski, Madison; Frommel, Julian","Mandryk, Regan/HZK-7531-2023","Beres, Nicole/0000-0001-9137-7994; Mandryk, Regan/0000-0003-0772-6616; Frommel, Julian/0000-0001-8783-7783",Bad Vibrations: Sensing Toxicity From In-Game Audio Features,14,4,10.1109/TG.2022.3176849 ,Article ,2022.0,"Toxicity in online gaming is a problem that causes harm to players, developers, and gaming communities. Toxic behaviors persist in online multiplayer games for a number of reasons, and continue to go unchecked due in large part to a lack of reliable methods to accurately detect toxicity online, in real-time, and at scale. In this article, we present a modeling approach that uses features derived from in-game verbal communication and game metadata to predict if Overwatch games are toxic. With logistic regression models, we achieve accuracy scores of 86.3% for binary (high vs. low toxicity) predictions. We discuss which features were most salient, potential application of our predictive model, and implications for toxicity detection in games. Our approach is a low-cost, low-effort, and noninvasive contribution to holistic efforts in combating toxicity in games.",2475-1502,2475-1510,,558-568, , ,,out_but_toxicity,
4187,"Title:Toxicity Detection in Multiplayer Online Games

 Social interactions in multi player online games are an essential feature for a growing number of players world-wide. However, this interaction between the players might lead to the emergence of undesired and unintended behavior, particularly if the game is designed to be highly competitive. Communication channels might be abused to harass and verbally assault other players, which negates the very purpose of entertainment games by creating a toxic player-community. By using a novel natural language processing framework, we detect profanity in chat-logs of a popular Multiplayer Online Battle Arena (MOBA) game and develop a method to classify toxic remarks. We show how toxicity is non-trivially linked to game success.","Martens, Marcus; Shen, Siqi; Iosup, Alexandru; Kuipers, Fernando","Iosup, Alexandru/G-4069-2012; Kuipers, Fernando/B-3176-2010","Iosup, Alexandru/0000-0001-8030-9398; Kuipers, Fernando/0000-0002-6686-8350",Toxicity Detection in Multiplayer Online Games,,, ,Proceedings Paper ,2015.0,"Social interactions in multi player online games are an essential feature for a growing number of players world-wide. However, this interaction between the players might lead to the emergence of undesired and unintended behavior, particularly if the game is designed to be highly competitive. Communication channels might be abused to harass and verbally assault other players, which negates the very purpose of entertainment games by creating a toxic player-community. By using a novel natural language processing framework, we detect profanity in chat-logs of a popular Multiplayer Online Battle Arena (MOBA) game and develop a method to classify toxic remarks. We show how toxicity is non-trivially linked to game success.",2156-8146,,978-1-5090-0068-5,, , International Workshop on Network and Systems Support for GamesInternational Workshop on Network and Systems Support for Games,,Use_dataset#detection,
4188,"Title:'Who built this crap?' Developing a Software Engineering Domain Specific Toxicity Detector

 Since toxicity during developers' interactions in open source software (OSS) projects show negative impacts on developers' relation, a toxicity detector for the Software Engineering (SE) domain is needed. However, prior studies found that contemporary toxicity detection tools performed poorly with the SE texts. To address this challenge, I have developed ToxiCR, a SE-specific toxicity detector that is evaluated with manually labeled 19,571 code review comments. I evaluate ToxiCR with different combinations of ten supervised learning models, five text vectorizers, and eight preprocessing techniques (two of them are SE domain-specific). After applying all possible combinations, I have found that ToxiCR significantly outperformed existing toxicity classifiers with accuracy of 95.8% and an F1 score of 88.9%.","Sarker, Jaydeb",,,'Who built this crap?' Developing a Software Engineering Domain Specific Toxicity Detector,,,10.1145/3551349.3559508 ,Proceedings Paper ,2022.0,"Since toxicity during developers' interactions in open source software (OSS) projects show negative impacts on developers' relation, a toxicity detector for the Software Engineering (SE) domain is needed. However, prior studies found that contemporary toxicity detection tools performed poorly with the SE texts. To address this challenge, I have developed ToxiCR, a SE-specific toxicity detector that is evaluated with manually labeled 19,571 code review comments. I evaluate ToxiCR with different combinations of ten supervised learning models, five text vectorizers, and eight preprocessing techniques (two of them are SE domain-specific). After applying all possible combinations, I have found that ToxiCR significantly outperformed existing toxicity classifiers with accuracy of 95.8% and an F1 score of 88.9%.",1527-1366,,978-1-4503-9475-8,, , 37th IEEE/ACM International Conference on Automated Software Engineering (ASE)37th IEEE/ACM International Conference on Automated Software Engineering (ASE),,Gen_dataset#detection,
4189,"Title:Comment toxicity detection via a multichannel convolutional bidirectional gated recurrent unit

 Recently, toxicity identification has become the most serious problem in online communities and social networking sites. Therefore, an automatic toxic identification system needs to be developed for preventing and limiting users from these online environments. In this paper, we present a multichannel convolutional bidirectional gated recurrent unit (MCBiGRU) for detecting toxic comments in a multilabel environment. The proposed model generates word vectors using pre-trained word embeddings. Moreover, this hybrid model extracts local features with many filters and different kernel sizes to model input words with long term dependency. We then integrate multiple channels with a fully connected layer, normalization layer, and an output layer with a sigmoid activation function for predicting multilabel categories. The experimental results indicate that the proposed MCBiGRU model outperforms in terms of multilabel metrics.(c) 2021 Elsevier B.V. All rights reserved.","Kumar, J. Ashok; Abirami, S.; Trueman, Tina Esther; Cambria, Erik","J, Ashok Kumar/AAV-3326-2020; Alsaif, Amal/IUO-9428-2023; Trueman, Tina/ABE-2606-2021; S, Abirami/AHH-8969-2022; Li, Yang/HPC-4054-2023; Cambria, Erik/C-2103-2013","J, Ashok Kumar/0000-0001-7611-1565; Alsaif, Amal/0000-0002-8204-0326; Trueman, Tina/0000-0003-3616-0914; S, Abirami/0000-0002-2028-5344; Cambria, Erik/0000-0002-3030-1280",Comment toxicity detection via a multichannel convolutional bidirectional gated recurrent unit,441,,10.1016/j.neucom.2021.02.023 ,Article ,2021.0,"Recently, toxicity identification has become the most serious problem in online communities and social networking sites. Therefore, an automatic toxic identification system needs to be developed for preventing and limiting users from these online environments. In this paper, we present a multichannel convolutional bidirectional gated recurrent unit (MCBiGRU) for detecting toxic comments in a multilabel environment. The proposed model generates word vectors using pre-trained word embeddings. Moreover, this hybrid model extracts local features with many filters and different kernel sizes to model input words with long term dependency. We then integrate multiple channels with a fully connected layer, normalization layer, and an output layer with a sigmoid activation function for predicting multilabel categories. The experimental results indicate that the proposed MCBiGRU model outperforms in terms of multilabel metrics.(c) 2021 Elsevier B.V. All rights reserved.",0925-2312,1872-8286,,272-278, , ,,detection#methodology,
4190,"Title:MULTIFUNCTIONAL SH-SY5Y-BASED BIOMIMETIC SENSOR FOR INTEGRATED DETECTION OF OLFACTION, GUSTATION AND TOXICITY

 The detection of olfaction, gustation and toxicity has played an important role in industries and research. The key factor to realize this function is to detect different substances with the same sensitive element. In this paper, the human neuroblastoma SH-SY5Y cells endogenously expressed the human bitter receptor, T2R16. Meanwhile, an olfactory receptor, ODR-10, was transfected on the plasma membrane of the cells at the same time. T2R16 could specifically respond to bitter compounds, which can be monitored by cell-impedance sensor. The ODR-10 receptor can also specifically respond to diacetyl, which was cultured on the microelectrode arrays to establish a novel biomimetic sensor for odor detection. The results represent a dose-dependent responses in a certain concentration range. Moreover, the cell-impedance biosensor enabled a quick toxicity detection of salicin. In conclusion, the biomimetic sensors based on extracellular recording in vitro show great potential for use in both basic research and practical applications.","Gao, Keqiang; Gao, Fan; Du, Liping; He, Chuanjiang; Wan, Hao; Wang, Ping",,,"MULTIFUNCTIONAL SH-SY5Y-BASED BIOMIMETIC SENSOR FOR INTEGRATED DETECTION OF OLFACTION, GUSTATION AND TOXICITY",,, ,Proceedings Paper ,2019.0,"The detection of olfaction, gustation and toxicity has played an important role in industries and research. The key factor to realize this function is to detect different substances with the same sensitive element. In this paper, the human neuroblastoma SH-SY5Y cells endogenously expressed the human bitter receptor, T2R16. Meanwhile, an olfactory receptor, ODR-10, was transfected on the plasma membrane of the cells at the same time. T2R16 could specifically respond to bitter compounds, which can be monitored by cell-impedance sensor. The ODR-10 receptor can also specifically respond to diacetyl, which was cultured on the microelectrode arrays to establish a novel biomimetic sensor for odor detection. The results represent a dose-dependent responses in a certain concentration range. Moreover, the cell-impedance biosensor enabled a quick toxicity detection of salicin. In conclusion, the biomimetic sensors based on extracellular recording in vitro show great potential for use in both basic research and practical applications.",,,978-1-5386-8327-9,18-20, , 18th International Symposium on Olfaction and Electronic Nose (ISOEN)18th International Symposium on Olfaction and Electronic Nose (ISOEN),,out_of_scope,
4191,"Series([], Name: Abstract, dtype: object)","BERNI, AJ; DICK, DE; LUTTGES, MW",,,DETECTION OF DIGITALIS TOXICITY BY COMPUTERIZED ELECTROCARDIOGRAM MONITORING,BM22,1,10.1109/TBME.1975.324536 ,Article ,1975.0,"Series([], Name: Abstract, dtype: object)",0018-9294,,,29-34, , ,,out_of_scope,
4192,"Title:Robust Conversational Agents against Imperceptible Toxicity Triggers

 Recent research in Natural Language Processing (NLP) has advanced the development of various toxicity detection models with the intention of identifying and mitigating toxic language from existing systems. Despite the abundance of research in this area, less attention has been given to adversarial attacks that force the system to generate toxic language and the defense against them. Existing work to generate such attacks is either based on human-generated attacks which is costly and not scalable or, in case of automatic attacks, the attack vector does not conform to human-like language, which can be detected using a language model loss. In this work, we propose attacks against conversational agents that are imperceptible, i.e., they fit the conversation in terms of coherency, relevancy, and fluency, while they are effective and scalable, i.e., they can automatically trigger the system into generating toxic language. We then propose a defense mechanism against such attacks which not only mitigates the attack but also attempts to maintain the conversational flow. Through automatic and human evaluations, we show that our defense is effective at avoiding toxic language generation even against imperceptible toxicity triggers while the generated language fits the conversation in terms of coherency and relevancy. Lastly, we establish the generalizability of such a defense mechanism on language generation models beyond conversational agents.","Mehrabi, Ninareh; Beirami, Ahmad; Morstatter, Fred; Galstyan, Aram","Galstyan, Aram/G-3660-2011",,Robust Conversational Agents against Imperceptible Toxicity Triggers,,, ,Proceedings Paper ,2022.0,"Recent research in Natural Language Processing (NLP) has advanced the development of various toxicity detection models with the intention of identifying and mitigating toxic language from existing systems. Despite the abundance of research in this area, less attention has been given to adversarial attacks that force the system to generate toxic language and the defense against them. Existing work to generate such attacks is either based on human-generated attacks which is costly and not scalable or, in case of automatic attacks, the attack vector does not conform to human-like language, which can be detected using a language model loss. In this work, we propose attacks against conversational agents that are imperceptible, i.e., they fit the conversation in terms of coherency, relevancy, and fluency, while they are effective and scalable, i.e., they can automatically trigger the system into generating toxic language. We then propose a defense mechanism against such attacks which not only mitigates the attack but also attempts to maintain the conversational flow. Through automatic and human evaluations, we show that our defense is effective at avoiding toxic language generation even against imperceptible toxicity triggers while the generated language fits the conversation in terms of coherency and relevancy. Lastly, we establish the generalizability of such a defense mechanism on language generation models beyond conversational agents.",,,978-1-955917-71-1,2831-2847, , Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language TechnologiesConference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies,,detox#methodology,
4193,"Title:On Transferability of Bias Mitigation Effects in Language Model Fine-Tuning

 Fine-tuned language models have been shown to exhibit biases against protected groups in a host of modeling tasks such as text classification and coreference resolution. Previous works focus on detecting these biases, reducing bias in data representations, and using auxiliary training objectives to mitigate bias during fine-tuning. Although these techniques achieve bias reduction for the task and domain at hand, the effects of bias mitigation may not directly transfer to new tasks, requiring additional data collection and customized annotation of sensitive attributes, and re-evaluation of appropriate fairness metrics. We explore the feasibility and benefits of upstream bias mitigation (UBM) for reducing bias on downstream tasks, by first applying bias mitigation to an upstream model through fine-tuning and subsequently using it for downstream fine-tuning. We find, in extensive experiments across hate speech detection, toxicity detection, occupation prediction, and coreference resolution tasks over various bias factors, that the effects of UBM are indeed transferable to new downstream tasks or domains via fine-tuning, creating less biased downstream models than directly fine-tuning on the downstream task or transferring from a vanilla upstream model. Though challenges remain, we show that UBM promises more efficient and accessible bias mitigation in LM fine-tuning.(12)","Jin, Xisen; Barbieri, Francesco; Kennedy, Brendan; Davani, Aida Mostafazadeh; Neves, Leonardo; Ren, Xiang",,"Kennedy, Brendan/0000-0001-7252-7475",On Transferability of Bias Mitigation Effects in Language Model Fine-Tuning,,, ,Proceedings Paper ,2021.0,"Fine-tuned language models have been shown to exhibit biases against protected groups in a host of modeling tasks such as text classification and coreference resolution. Previous works focus on detecting these biases, reducing bias in data representations, and using auxiliary training objectives to mitigate bias during fine-tuning. Although these techniques achieve bias reduction for the task and domain at hand, the effects of bias mitigation may not directly transfer to new tasks, requiring additional data collection and customized annotation of sensitive attributes, and re-evaluation of appropriate fairness metrics. We explore the feasibility and benefits of upstream bias mitigation (UBM) for reducing bias on downstream tasks, by first applying bias mitigation to an upstream model through fine-tuning and subsequently using it for downstream fine-tuning. We find, in extensive experiments across hate speech detection, toxicity detection, occupation prediction, and coreference resolution tasks over various bias factors, that the effects of UBM are indeed transferable to new downstream tasks or domains via fine-tuning, creating less biased downstream models than directly fine-tuning on the downstream task or transferring from a vanilla upstream model. Though challenges remain, we show that UBM promises more efficient and accessible bias mitigation in LM fine-tuning.(12)",,,978-1-954085-46-6,3770-3783, , Conference of the North-American-Chapter of the Association-for-Computational-Linguistics - Human Language Technologies (NAACL-HLT)Conference of the North-American-Chapter of the Association-for-Computational-Linguistics - Human Language Technologies (NAACL-HLT),,detection#evaluation#methodology,
4194,"Title:Dityrosine in food: A review of its occurrence, health effects, detection methods, and mitigation strategies

 Protein and amino acid oxidation in food products produce many new compounds, of which the reactive and toxic compound dityrosine, derived from oxidized tyrosine, is the most widely studied. The high reactivity of dityrosine enables this compound to induce oxidative stress and disrupt thyroid hormone function, contributing to the pathological processes of several diseases, such as obesity, diabetes, cognitive dysfunction, aging, and age-related diseases. From the perspective of food safety and human health, protein-oxidation products in food are the main concern of consumers, health management departments, and the food industry. This review highlights the latest research on the formation pathways, toxicity, detection methods, occurrence in food, and mitigation strategies for dityrosine. Furthermore, the control of dityrosine in family cooking and food-processing industry has been discussed. Food-derived dityrosine primarily originates from high-protein foods, such as meat and dairy products. Considering its toxicity, combining rapid high sensitivity dityrosine detection techniques with feasible control methods could be an effective strategy to ensure food safety and maintain human health. However, the current dityrosine detection and mitigation strategies exhibit some inherent characteristics and limitations. Therefore, developing technologies for rapid and effective dityrosine detection and control at the industrial level is necessary.","Li, Bowen; Yang, Yuhui; Ding, Yinyi; Ge, Yueting; Xu, Yuncong; Xie, Yanli; Shi, Yonghui; Le, Guowei","Li, Bowen/CAG-0851-2022; yuhui, yang/AAZ-8126-2021; SHI, YAN/HNI-1042-2023; SHI, YH/HLG-1159-2023; Xu, Yuncong/JEO-7264-2023","Li, Bowen/0000-0002-4199-7164; yuhui, yang/0000-0002-4949-3745; Xu, Yuncong/0009-0005-1799-0404","Dityrosine in food: A review of its occurrence, health effects, detection methods, and mitigation strategies",22,1,10.1111/1541-4337.13071 ,Review ,2023.0,"Protein and amino acid oxidation in food products produce many new compounds, of which the reactive and toxic compound dityrosine, derived from oxidized tyrosine, is the most widely studied. The high reactivity of dityrosine enables this compound to induce oxidative stress and disrupt thyroid hormone function, contributing to the pathological processes of several diseases, such as obesity, diabetes, cognitive dysfunction, aging, and age-related diseases. From the perspective of food safety and human health, protein-oxidation products in food are the main concern of consumers, health management departments, and the food industry. This review highlights the latest research on the formation pathways, toxicity, detection methods, occurrence in food, and mitigation strategies for dityrosine. Furthermore, the control of dityrosine in family cooking and food-processing industry has been discussed. Food-derived dityrosine primarily originates from high-protein foods, such as meat and dairy products. Considering its toxicity, combining rapid high sensitivity dityrosine detection techniques with feasible control methods could be an effective strategy to ensure food safety and maintain human health. However, the current dityrosine detection and mitigation strategies exhibit some inherent characteristics and limitations. Therefore, developing technologies for rapid and effective dityrosine detection and control at the industrial level is necessary.",1541-4337,,,355-379, , ,,out_of_scope,
4195,"Title:Domain Adaptation Multi-task Deep Neural Network for Mitigating Unintended Bias in Toxic Language Detection

 As online communities have grown, so has the ability to exchange ideas, which includes an increase in the spread of toxic language, including racism, sexual harassment, and other negative behaviors that are not tolerated in polite society. Hence, toxic language detection within online conversations has become an essential application of natural language processing. In recent years, machine learning approaches for toxic language detection have primarily focused on many researchers in academics and industries. However, in many of these machine learning models, non-toxic comments containing specific identity terms, such as gay, Black, Muslim, and Jewish, were given unreasonably high toxicity scores. In this research, we propose a new approach based on the domain adaptation language model and multi-task deep neural network to identify and mitigate this form of unintended model bias in online conversations. We use six toxic language detection and identification tasks to train the model to detect toxic contents and mitigate unintended bias in model prediction. We evaluate our model and compare it with other state-of-the-art deep learning models using specific performance metrics to measure the model bias. In detailed experiments, we show our approach can identify the toxic language in conversations with considerably more robustness to model bias towards commonly-attacked identity groups presented in online conversations in social media.","Faal, Farshid; Yu, Jia Yuan; Schmitt, Ketra","Schmitt, Ketra/GWQ-5329-2022; Faal, Farshid/AFL-8240-2022","Faal, Farshid/0000-0002-2555-3221",Domain Adaptation Multi-task Deep Neural Network for Mitigating Unintended Bias in Toxic Language Detection,,,10.5220/0010266109320940 ,Proceedings Paper ,2021.0,"As online communities have grown, so has the ability to exchange ideas, which includes an increase in the spread of toxic language, including racism, sexual harassment, and other negative behaviors that are not tolerated in polite society. Hence, toxic language detection within online conversations has become an essential application of natural language processing. In recent years, machine learning approaches for toxic language detection have primarily focused on many researchers in academics and industries. However, in many of these machine learning models, non-toxic comments containing specific identity terms, such as gay, Black, Muslim, and Jewish, were given unreasonably high toxicity scores. In this research, we propose a new approach based on the domain adaptation language model and multi-task deep neural network to identify and mitigate this form of unintended model bias in online conversations. We use six toxic language detection and identification tasks to train the model to detect toxic contents and mitigate unintended bias in model prediction. We evaluate our model and compare it with other state-of-the-art deep learning models using specific performance metrics to measure the model bias. In detailed experiments, we show our approach can identify the toxic language in conversations with considerably more robustness to model bias towards commonly-attacked identity groups presented in online conversations in social media.",,,978-989-758-484-8,932-940, , 13th International Conference on Agents and Artificial Intelligence (ICAART)13th International Conference on Agents and Artificial Intelligence (ICAART),,detection#evaluation#methodology,
4196,"Title:Preemptive Toxic Language Detection in Wikipedia Comments Using Thread-Level Context

 We address the task of automatically detecting toxic content in user generated texts. We focus on exploring the potential for preemptive moderation, i.e., predicting whether a particular conversation thread will, in the future, incite a toxic comment. Moreover, we perform preliminary investigation of whether a model that jointly considers all comments in a conversation thread outperforms a model that considers only individual comments. Using an existing dataset of conversations among Wikipedia contributors as a starting point, we compile a new large-scale dataset for this task consisting of labeled comments and comments from their conversation threads.","Karan, Mladen; Snajder, Jan",,,Preemptive Toxic Language Detection in Wikipedia Comments Using Thread-Level Context,,, ,Proceedings Paper ,2019.0,"We address the task of automatically detecting toxic content in user generated texts. We focus on exploring the potential for preemptive moderation, i.e., predicting whether a particular conversation thread will, in the future, incite a toxic comment. Moreover, we perform preliminary investigation of whether a model that jointly considers all comments in a conversation thread outperforms a model that considers only individual comments. Using an existing dataset of conversations among Wikipedia contributors as a starting point, we compile a new large-scale dataset for this task consisting of labeled comments and comments from their conversation threads.",,,978-1-950737-43-7,129-134, , 3rd Workshop on Abusive Language Online3rd Workshop on Abusive Language Online,,Use_dataset#detection#evaluation#methodology,
4197,"Title:Towards Equal Gender Representation in the Annotations of Toxic Language Detection

 Classifiers tend to propagate biases present in the data on which they are trained. Hence, it is important to understand how the demographic identities of the annotators of comments affect the fairness of the resulting model. In this paper, we focus on the differences in the ways men and women annotate comments for toxicity, investigating how these differences result in models that amplify the opinions of male annotators. We find that the BERT model associates toxic comments containing offensive words with male annotators, causing the model to predict 67.7% of toxic comments as having been annotated by men. We show that this disparity between gender predictions can be mitigated by removing offensive words and highly toxic comments from the training data. We then apply the learned associations between gender and language to toxic language classifiers, finding that models trained exclusively on female-annotated data perform 1.8% better than those trained solely on male-annotated data, and that training models on data after removing all offensive words reduces bias in the model by 55.5% while increasing the sensitivity by 0.4%.","Excell, Elizabeth; Al Moubayed, Noura",,,Towards Equal Gender Representation in the Annotations of Toxic Language Detection,,, ,Proceedings Paper ,2021.0,"Classifiers tend to propagate biases present in the data on which they are trained. Hence, it is important to understand how the demographic identities of the annotators of comments affect the fairness of the resulting model. In this paper, we focus on the differences in the ways men and women annotate comments for toxicity, investigating how these differences result in models that amplify the opinions of male annotators. We find that the BERT model associates toxic comments containing offensive words with male annotators, causing the model to predict 67.7% of toxic comments as having been annotated by men. We show that this disparity between gender predictions can be mitigated by removing offensive words and highly toxic comments from the training data. We then apply the learned associations between gender and language to toxic language classifiers, finding that models trained exclusively on female-annotated data perform 1.8% better than those trained solely on male-annotated data, and that training models on data after removing all offensive words reduces bias in the model by 55.5% while increasing the sensitivity by 0.4%.",,,978-1-954085-61-9,55-65, , 3rd Workshop on Gender Bias in Natural Language Processing (GeBNLP)3rd Workshop on Gender Bias in Natural Language Processing (GeBNLP),,detection#methodology,
4198,"Title:Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection

 This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.","Felipe Magnossao de Paula, Angel; Rosso, Paolo; Spina, Damiano","de Paula, Angel Felipe Magnossão/ABD-0457-2022; Spina, Damiano/C-9976-2016","de Paula, Angel Felipe Magnossão/0000-0001-8575-5012; Spina, Damiano/0000-0001-9913-433X","Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection",,,10.1109/IJCNN54540.2023.10191347 ,Proceedings Paper ,2023.0,"This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.",2161-4393,,978-1-6654-8867-9,, , International Joint Conference on Neural Networks (IJCNN)International Joint Conference on Neural Networks (IJCNN),,detection#evaluation#methodology,
4199,"Title:Toxic Speech and Speech Emotions: Investigations of Audio-based Modeling and Intercorrelations

 Content moderation (CM) systems have become essential following the monumental increase in multimodal and online social platforms; and while increasingly published work focuses on text-based solutions, there is still limited work on audio-based methods. In this study we aim to explore relationships between speech emotions and toxic speech, as part of a CM scenario. We first investigate an appropriate framework for combining speech emotion recognition (SER) and audio-based CM models. We then investigate which emotional aspects (i.e., attribute, sentiment, or attitude) could contribute the most in facilitating audio-based CM recognition platforms. Our experimental results indicate that conventional shared feature encoder approaches may fail to capture additional discriminative features for boosting audio-based CM tasks while utilizing SER learning. We further investigate performance trade-offs of late-fusion frameworks for combining SER and CM information. We argue that these observations could be attributed to an emotionally-biased distribution in the CM scenario, concluding that SER could in deed play a role in content moderation frameworks, given added application-specific emotional information.","Lin, Wei-Cheng; Emmanouilidou, Dimitra",,,Toxic Speech and Speech Emotions: Investigations of Audio-based Modeling and Intercorrelations,,, ,Proceedings Paper ,2022.0,"Content moderation (CM) systems have become essential following the monumental increase in multimodal and online social platforms; and while increasingly published work focuses on text-based solutions, there is still limited work on audio-based methods. In this study we aim to explore relationships between speech emotions and toxic speech, as part of a CM scenario. We first investigate an appropriate framework for combining speech emotion recognition (SER) and audio-based CM models. We then investigate which emotional aspects (i.e., attribute, sentiment, or attitude) could contribute the most in facilitating audio-based CM recognition platforms. Our experimental results indicate that conventional shared feature encoder approaches may fail to capture additional discriminative features for boosting audio-based CM tasks while utilizing SER learning. We further investigate performance trade-offs of late-fusion frameworks for combining SER and CM information. We argue that these observations could be attributed to an emotionally-biased distribution in the CM scenario, concluding that SER could in deed play a role in content moderation frameworks, given added application-specific emotional information.",2076-1465,,978-90-827970-9-1,115-119, , 30th European Signal Processing Conference (EUSIPCO)30th European Signal Processing Conference (EUSIPCO),,detection#out_but_toxicity,
4200,"Title:Anti-Islamic Arabic Text Categorization using Text Mining and Sentiment Analysis Techniques

 The aim of this research is to detect and classify websites based on their content if it encourages spreading hate speech toward Islam and Muslims, or Islamophobia using sentiment analysis and web text mining techniques. In this research, a large dataset corpus has been collected, to identify and classify anti-Islamic online contents. Our target is to automatically detect the content of those websites that are hostile to Islam and transmitting extremist ideas against it. The main purpose is to reduce the spread of those webpages that give the wrong idea about Islam. The proper dataset is collected from different sources, and the two datasets for the Arabic language (balanced and unbalanced) have been produced. The framework of the proposed approach has been described. The approach used in this framework is based on supervised Machine Learning (ML) approach using Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB) models as classifiers, and Term Frequency-Inverse Document Frequency (TF-IDF) as feature extraction. Different experiments including word level and trigram level on the two datasets have been conducted, and compared the obtained results. The experimental results shows that the supervised ML approach using word level is the finest approach for both datasets that produce high accuracy with 97% applied on the balanced Arabic dataset using SVM algorithm with TF-IDF as feature extraction. Finally, an interactive webapplication prototype has been developed and built in order to detect and classify toxic language such as anti-Islamic online textcontents.","Alraddadi, Rawan Abdullah; Ghembaza, Moulay Ibrahim El-Khalil",,,Anti-Islamic Arabic Text Categorization using Text Mining and Sentiment Analysis Techniques,12,8, ,Article ,2021.0,"The aim of this research is to detect and classify websites based on their content if it encourages spreading hate speech toward Islam and Muslims, or Islamophobia using sentiment analysis and web text mining techniques. In this research, a large dataset corpus has been collected, to identify and classify anti-Islamic online contents. Our target is to automatically detect the content of those websites that are hostile to Islam and transmitting extremist ideas against it. The main purpose is to reduce the spread of those webpages that give the wrong idea about Islam. The proper dataset is collected from different sources, and the two datasets for the Arabic language (balanced and unbalanced) have been produced. The framework of the proposed approach has been described. The approach used in this framework is based on supervised Machine Learning (ML) approach using Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB) models as classifiers, and Term Frequency-Inverse Document Frequency (TF-IDF) as feature extraction. Different experiments including word level and trigram level on the two datasets have been conducted, and compared the obtained results. The experimental results shows that the supervised ML approach using word level is the finest approach for both datasets that produce high accuracy with 97% applied on the balanced Arabic dataset using SVM algorithm with TF-IDF as feature extraction. Finally, an interactive webapplication prototype has been developed and built in order to detect and classify toxic language such as anti-Islamic online textcontents.",2158-107X,2156-5570,,776-785, , ,,detection#out_but_toxicity,
4201,"Title:A Hybrid Model for Monolingual and Multilingual Toxic Comment Detection

 Social media provides a public and convenient platform for people to communicate. However, it is also open to hateful behavior and toxic comments. Social networks, like Facebook, Twitter, and many others, have been working on developing effective toxic comment detection methods to provide better service. Monolingual language model focuses on a single-language and provides high accuracy in detection. Multilingual language model provides better generalization performance. In order to improve the effectiveness of detecting toxic comments in multiple languages, we propose a hybrid model, which fuses monolingual model and multilingual model. We use labeled data to fine-tune the monolingual pre-trained model. We use masked language modeling to semi-supervise the fine-tuning of multilingual pre-trained model on unlabeled data and then use labeled data to fine-tune the model. Through this way, we can fully utilize the large amount of unlabeled data; reduce dependence on labeled comment data; and improve the effectiveness of detection. We also design several comparative experiments. The results demonstrate the effectiveness and advantage of our proposed model, especially compared to the XLM-RoBERTa multilingual fine-tuning model.","Song, Guizhe; Huang, Degen; Zhang, Yanping","Zhang, Yanping/HMP-5348-2023",,A Hybrid Model for Monolingual and Multilingual Toxic Comment Detection,28,5,10.17559/TV-20210325125414 ,Article ,2021.0,"Social media provides a public and convenient platform for people to communicate. However, it is also open to hateful behavior and toxic comments. Social networks, like Facebook, Twitter, and many others, have been working on developing effective toxic comment detection methods to provide better service. Monolingual language model focuses on a single-language and provides high accuracy in detection. Multilingual language model provides better generalization performance. In order to improve the effectiveness of detecting toxic comments in multiple languages, we propose a hybrid model, which fuses monolingual model and multilingual model. We use labeled data to fine-tune the monolingual pre-trained model. We use masked language modeling to semi-supervise the fine-tuning of multilingual pre-trained model on unlabeled data and then use labeled data to fine-tune the model. Through this way, we can fully utilize the large amount of unlabeled data; reduce dependence on labeled comment data; and improve the effectiveness of detection. We also design several comparative experiments. The results demonstrate the effectiveness and advantage of our proposed model, especially compared to the XLM-RoBERTa multilingual fine-tuning model.",1330-3651,1848-6339,,1667-1673, , ,,detection#methodology,
4202,"Title:Detection of Racist Language in French Tweets

 Toxic online content has become a major issue in recent years due to the exponential increase in the use of the internet. In France, there has been a significant increase in hate speech against migrant and Muslim communities following events such as Great Britain's exit from the EU, the Charlie Hebdo attacks, and the Bataclan attacks. Therefore, the automated detection of offensive language and racism is in high demand, and it is a serious challenge. Unfortunately, there are fewer datasets annotated for racist speech than for general hate speech available, especially for French. This paper attempts to breach this gap by (1) proposing and evaluating a new dataset intended for automated racist speech detection in French; (2) performing a case study with multiple supervised models and text representations for the task of racist language detection in French; and (3) performing cross-lingual experiments.","Vanetik, Natalia; Mimoun, Elisheva","Vanetik, Natalia/GZN-2048-2022","Vanetik, Natalia/0000-0002-4939-1415",Detection of Racist Language in French Tweets,13,7,10.3390/info13070318 ,Article ,2022.0,"Toxic online content has become a major issue in recent years due to the exponential increase in the use of the internet. In France, there has been a significant increase in hate speech against migrant and Muslim communities following events such as Great Britain's exit from the EU, the Charlie Hebdo attacks, and the Bataclan attacks. Therefore, the automated detection of offensive language and racism is in high demand, and it is a serious challenge. Unfortunately, there are fewer datasets annotated for racist speech than for general hate speech available, especially for French. This paper attempts to breach this gap by (1) proposing and evaluating a new dataset intended for automated racist speech detection in French; (2) performing a case study with multiple supervised models and text representations for the task of racist language detection in French; and (3) performing cross-lingual experiments.",,2078-2489,,, , ,,detection#out_but_toxicity,
4203,"Title:Roman Urdu toxic comment classification

 With the increasing popularity of user-generated content on social media, the number of toxic texts is also on the rise. Such texts cause adverse effects on users and society at large, therefore, the identification of toxic comments is a growing need of the day. While toxic comment classification has been studied for resource-rich languages like English, no work has been done for Roman Urdu despite being a widely used language on social media in South Asia. This paper addresses the challenge of Roman Urdu toxic comment detection by developing a first-ever large labeled corpus of toxic and non-toxic comments. The developed corpus, called RUT (Roman Urdu Toxic), contains over 72 thousand comments collected from popular social media platforms and has been labeled manually with a strong inter-annotator agreement. With this dataset, we train several classification models to detect Roman Urdu toxic comments, including classical machine learning models with the bag-of-words representation and some recent deep models based on word embeddings. Despite the success of the latter in classifying toxic comments in English, the absence of pre-trained word embeddings for Roman Urdu prompted to generate different word embeddings using Glove, Word2Vec and FastText techniques, and compare them with task-specific word embeddings learned inside the classification task. Finally, we propose an ensemble approach, reaching our best F1-score of 86.35%, setting the first-ever benchmark for toxic comment classification in Roman Urdu.","Saeed, Hafiz Hassaan; Ashraf, Muhammad Haseeb; Kamiran, Faisal; Karim, Asim; Calders, Toon","Calders, Toon/S-6315-2018","Calders, Toon/0000-0002-4943-6978; Saeed, Hafiz Hassaan/0000-0001-5026-0765; Ashraf, Muhammad Haseeb/0000-0002-6345-454X",Roman Urdu toxic comment classification,55,4,10.1007/s10579-021-09530-y ,Article ,2021.0,"With the increasing popularity of user-generated content on social media, the number of toxic texts is also on the rise. Such texts cause adverse effects on users and society at large, therefore, the identification of toxic comments is a growing need of the day. While toxic comment classification has been studied for resource-rich languages like English, no work has been done for Roman Urdu despite being a widely used language on social media in South Asia. This paper addresses the challenge of Roman Urdu toxic comment detection by developing a first-ever large labeled corpus of toxic and non-toxic comments. The developed corpus, called RUT (Roman Urdu Toxic), contains over 72 thousand comments collected from popular social media platforms and has been labeled manually with a strong inter-annotator agreement. With this dataset, we train several classification models to detect Roman Urdu toxic comments, including classical machine learning models with the bag-of-words representation and some recent deep models based on word embeddings. Despite the success of the latter in classifying toxic comments in English, the absence of pre-trained word embeddings for Roman Urdu prompted to generate different word embeddings using Glove, Word2Vec and FastText techniques, and compare them with task-specific word embeddings learned inside the classification task. Finally, we propose an ensemble approach, reaching our best F1-score of 86.35%, setting the first-ever benchmark for toxic comment classification in Roman Urdu.",1574-020X,1574-0218,,971-996, , ,,detection#out_but_toxicity,
4204,"Title:WeChat Toxic Article Detection: A Data-Driven Machine Learning Approach

 Recently, toxic information detection has attracted tremendous amounts of research interest because of the popularity of social networks and the widespread of toxic information which may have dire consequences to the public. Existing work extensively studies toxic article detection in open social networks from information diffusion perspective. However, in closed social networks as exemplified byWeChat Moments (WM), the diffusion process is uneasily visible. To tackle the toxic article detection problem in closed social networks, in this paper we empirically study the articles spread in WM which is based on the largest Chinese social platform WeChat. In particular, we systematically analyze users' behavior and text information of normal and toxic articles and identify a striking difference between them. Furthermore, we design a new model named MAT-LSTM which can well capture the impact of different kinds of text information. To improve the performance of automatic toxic article detection, we propose XMATL framework which is enhanced from MAT-LSTM and can utilize text information and users' behavior characteristics in a holistic manner. We conduct extensive experiments using two real-world datasets and demonstrate that our proposed model can effectively detect toxic articles in WM and achieve outstanding performance gain over the classic methods.","Weng, Yunpeng; Wu, Muhong; Chen, Xu; Wu, Qiong; He, Lingnan; Chen, Liang",,,WeChat Toxic Article Detection: A Data-Driven Machine Learning Approach,,, ,Proceedings Paper ,2018.0,"Recently, toxic information detection has attracted tremendous amounts of research interest because of the popularity of social networks and the widespread of toxic information which may have dire consequences to the public. Existing work extensively studies toxic article detection in open social networks from information diffusion perspective. However, in closed social networks as exemplified byWeChat Moments (WM), the diffusion process is uneasily visible. To tackle the toxic article detection problem in closed social networks, in this paper we empirically study the articles spread in WM which is based on the largest Chinese social platform WeChat. In particular, we systematically analyze users' behavior and text information of normal and toxic articles and identify a striking difference between them. Furthermore, we design a new model named MAT-LSTM which can well capture the impact of different kinds of text information. To improve the performance of automatic toxic article detection, we propose XMATL framework which is enhanced from MAT-LSTM and can utilize text information and users' behavior characteristics in a holistic manner. We conduct extensive experiments using two real-world datasets and demonstrate that our proposed model can effectively detect toxic articles in WM and achieve outstanding performance gain over the classic methods.",2309-9402,,978-9-8814-7685-2,916-921, , 10th Asia-Pacific-Signal-and-Information-Processing-Association Annual Summit and Conference (APSIPA ASC)10th Asia-Pacific-Signal-and-Information-Processing-Association Annual Summit and Conference (APSIPA ASC),,detection#methodology,
4205,"Title:Investigating the Effect of Machine-Translation on Automated Classification of Toxic Comments

 This paper discusses the research findings on the performance of automated toxic comment classification following machine translation. We tested Google Perspective API first on comments from non-English Wikipedia talk pages in five languages, and then on their English translation (generated with Google's Cloud Translate API). In addition to giving baselines on the current performance of Perspective in five languages, this allows for comparison on how machine-translation alters the classification. We show that the level of disagreement between pre- and post-translation classification is heavily dependent on the language used. The comments come from a Kaggle dataset and we filter them to ensure monolingual comments with simple punctuation. Results show above 84% of the French, Italian and Spanish comments received the same class pre- and post-translation, while Portuguese and Russian performed the worst of the five languages tested, with F-scores below 0.6.","Roy, James; Suresh, Siddhi; Elsayed, Mohamed; Rocca, Ronie; Dong, Ziqian; Gu, Huanying; Artan, N. Sertac",,,Investigating the Effect of Machine-Translation on Automated Classification of Toxic Comments,,,10.1109/MASS56207.2022.00120 ,Proceedings Paper ,2022.0,"This paper discusses the research findings on the performance of automated toxic comment classification following machine translation. We tested Google Perspective API first on comments from non-English Wikipedia talk pages in five languages, and then on their English translation (generated with Google's Cloud Translate API). In addition to giving baselines on the current performance of Perspective in five languages, this allows for comparison on how machine-translation alters the classification. We show that the level of disagreement between pre- and post-translation classification is heavily dependent on the language used. The comments come from a Kaggle dataset and we filter them to ensure monolingual comments with simple punctuation. Results show above 84% of the French, Italian and Spanish comments received the same class pre- and post-translation, while Portuguese and Russian performed the worst of the five languages tested, with F-scores below 0.6.",,,978-1-6654-7180-0,764-769, , 19th IEEE International Conference on Mobile Ad Hoc and Smart Systems (MASS)19th IEEE International Conference on Mobile Ad Hoc and Smart Systems (MASS),,detection#evaluation#methodology,
4206,"Title:Deep learning for religious and continent-based toxic content detection and classification

 With time, numerous online communication platforms have emerged that allow people to express themselves, increasing the dissemination of toxic languages, such as racism, sexual harassment, and other negative behaviors that are not accepted in polite society. As a result, toxic language identification in online communication has emerged as a critical application of natural language processing. Numerous academic and industrial researchers have recently researched toxic language identification using machine learning algorithms. However, Nontoxic comments, including particular identification descriptors, such as Muslim, Jewish, White, and Black, were assigned unrealistically high toxicity ratings in several machine learning models. This research analyzes and compares modern deep learning algorithms for multilabel toxic comments classification. We explore two scenarios: the first is a multilabel classification of Religious toxic comments, and the second is a multilabel classification of race or toxic ethnicity comments with various word embeddings (GloVe, Word2vec, and FastText) without word embeddings using an ordinary embedding layer. Experiments show that the CNN model produced the best results for classifying multilabel toxic comments in both scenarios. We compared the outcomes of these modern deep learning model performances in terms of multilabel evaluation metrics.","Abbasi, Ahmed; Javed, Abdul Rehman; Iqbal, Farkhund; Kryvinska, Natalia; Jalil, Zunera","Kryvinska, Natalia/J-9160-2014; Javed, Abdul Rehman/AAR-7021-2020","Kryvinska, Natalia/0000-0003-3678-9229; Javed, Abdul Rehman/0000-0002-0570-1813",Deep learning for religious and continent-based toxic content detection and classification,12,1,10.1038/s41598-022-22523-3 ,Article ,2022.0,"With time, numerous online communication platforms have emerged that allow people to express themselves, increasing the dissemination of toxic languages, such as racism, sexual harassment, and other negative behaviors that are not accepted in polite society. As a result, toxic language identification in online communication has emerged as a critical application of natural language processing. Numerous academic and industrial researchers have recently researched toxic language identification using machine learning algorithms. However, Nontoxic comments, including particular identification descriptors, such as Muslim, Jewish, White, and Black, were assigned unrealistically high toxicity ratings in several machine learning models. This research analyzes and compares modern deep learning algorithms for multilabel toxic comments classification. We explore two scenarios: the first is a multilabel classification of Religious toxic comments, and the second is a multilabel classification of race or toxic ethnicity comments with various word embeddings (GloVe, Word2vec, and FastText) without word embeddings using an ordinary embedding layer. Experiments show that the CNN model produced the best results for classifying multilabel toxic comments in both scenarios. We compared the outcomes of these modern deep learning model performances in terms of multilabel evaluation metrics.",2045-2322,,,, , ,,detection#evaluation#methodology,
4207,"Title:Share of Toxic Comments among Different Topics: The Case of Russian Social Networks

 With the widespread use of online social networks, it is becoming more and more difficult to monitor and analyse all the user-generated content. Toxic speech in online conversations should be treated as a matter with serious social gravity, since it may result in both negative impacts on mental health and violent actions in the physical world. Within this study, we identified the share of toxic comments among different topics in Russian-language comments from social network Pikabu. Firstly, for toxic comments classification, we manually labelled the training dataset and fine-tuned several language models. To provide further toxic comments studies with strong classification baselines, we made our pre-trained publicly available to the research community. Secondly, we proposed an approach for topics labelling based on six major objective and observable dimensions for objective wellbeing measurement used by intergovernmental and government organisations. Lastly, we conducted an analysis of Pikabu data. We found that the largest share of toxic comments was under posts about politics, while security and socioeconomic topics ranked second and third, and the rest of the topics showed roughly the same values.","Smetanin, Sergey; Komarov, Mikhail","Komarov, Mikhail/O-1838-2013","Smetanin, Sergey/0000-0001-6373-3410; Komarov, Mikhail/0000-0001-7075-0016",Share of Toxic Comments among Different Topics: The Case of Russian Social Networks,,,10.1109/CBI52690.2021.10056 ,Proceedings Paper ,2021.0,"With the widespread use of online social networks, it is becoming more and more difficult to monitor and analyse all the user-generated content. Toxic speech in online conversations should be treated as a matter with serious social gravity, since it may result in both negative impacts on mental health and violent actions in the physical world. Within this study, we identified the share of toxic comments among different topics in Russian-language comments from social network Pikabu. Firstly, for toxic comments classification, we manually labelled the training dataset and fine-tuned several language models. To provide further toxic comments studies with strong classification baselines, we made our pre-trained publicly available to the research community. Secondly, we proposed an approach for topics labelling based on six major objective and observable dimensions for objective wellbeing measurement used by intergovernmental and government organisations. Lastly, we conducted an analysis of Pikabu data. We found that the largest share of toxic comments was under posts about politics, while security and socioeconomic topics ranked second and third, and the rest of the topics showed roughly the same values.",2378-1963,,978-1-6654-2069-3,65-70, , IEEE 23rd Conference on Business Informatics (CBI)IEEE 23rd Conference on Business Informatics (CBI),,out_but_toxicity,
4208,"Title:A literature survey on multimodal and multilingual automatic hate speech identification

 Social media is a more common and powerful platform for communication to share views about any topic or article, which consequently leads to unstructured toxic, and hateful conversations. Curbing hate speeches has emerged as a critical challenge globally. In this regard, Social media platforms are using modern statistical tools of AI technologies to process and eliminate toxic data to minimize hate crimes globally. Demanding the dire need, machine and deep learning-based techniques are getting more attention in analyzing these kinds of data. This survey presents a comprehensive analysis of hate speech definitions along with the motivation for detection and standard textual analysis methods that play a crucial role in identifying hate speech. State-of-the-art hate speech identification methods are also discussed, highlighting handcrafted feature-based and deep learning-based algorithms by considering multimodal and multilingual inputs and stating the pros and cons of each. Survey also presents popular benchmark datasets of hate speech/offensive language detection specifying their challenges, the methods for achieving top classification scores, and dataset characteristics such as the number of samples, modalities, language(s), number of classes, etc. Additionally, performance metrics are described, and classification scores of popular hate speech methods are mentioned. The conclusion and future research directions are presented at the end of the survey. Compared with earlier surveys, this paper gives a better presentation of multimodal and multilingual hate speech detection through well-organized comparisons, challenges, and the latest evaluation techniques, along with their best performances.","Chhabra, Anusha; Vishwakarma, Dinesh Kumar","VISHWAKARMA, DINESH KUMAR/L-3815-2018","VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047",A literature survey on multimodal and multilingual automatic hate speech identification,29,3,10.1007/s00530-023-01051-8 ,Article ,2023.0,"Social media is a more common and powerful platform for communication to share views about any topic or article, which consequently leads to unstructured toxic, and hateful conversations. Curbing hate speeches has emerged as a critical challenge globally. In this regard, Social media platforms are using modern statistical tools of AI technologies to process and eliminate toxic data to minimize hate crimes globally. Demanding the dire need, machine and deep learning-based techniques are getting more attention in analyzing these kinds of data. This survey presents a comprehensive analysis of hate speech definitions along with the motivation for detection and standard textual analysis methods that play a crucial role in identifying hate speech. State-of-the-art hate speech identification methods are also discussed, highlighting handcrafted feature-based and deep learning-based algorithms by considering multimodal and multilingual inputs and stating the pros and cons of each. Survey also presents popular benchmark datasets of hate speech/offensive language detection specifying their challenges, the methods for achieving top classification scores, and dataset characteristics such as the number of samples, modalities, language(s), number of classes, etc. Additionally, performance metrics are described, and classification scores of popular hate speech methods are mentioned. The conclusion and future research directions are presented at the end of the survey. Compared with earlier surveys, this paper gives a better presentation of multimodal and multilingual hate speech detection through well-organized comparisons, challenges, and the latest evaluation techniques, along with their best performances.",0942-4962,1432-1882,,1203-1230, , ,,survey,
4209,"Title:L-HSAB: A Levantine Twitter Dataset for Hate Speech and Abusive Language

 Hate speech and abusive language have become a common phenomenon on Arabic social media. Automatic hate speech and abusive detection systems can facilitate the prohibition of toxic textual contents. The complexity, informality and ambiguity of the Arabic dialects hindered the provision of the needed resources for Arabic abusive/hate speech detection research. In this paper, we introduce the first publicly-available Levantine Hate Speech and Abusive (L-HSAB) Twitter dataset with the objective to be a benchmark dataset for automatic detection of online Levantine toxic contents. We, further, provide a detailed review of the data collection steps and how we design the annotation guidelines such that a reliable dataset annotation is guaranteed. This has been later emphasized through the comprehensive evaluation of the annotations as the annotation agreement metrics of Cohen's Kappa (k) and Krippendorff's alpha (alpha) indicated the consistency of the annotations.","Mulki, Hala; Haddad, Hatem; Ali, Chedi Bechikh; Alshabani, Halima","haddad, hatem/ABD-1530-2021; Mulki, Hala/JLM-7752-2023","haddad, hatem/0000-0003-3599-7229;",L-HSAB: A Levantine Twitter Dataset for Hate Speech and Abusive Language,,, ,Proceedings Paper ,2019.0,"Hate speech and abusive language have become a common phenomenon on Arabic social media. Automatic hate speech and abusive detection systems can facilitate the prohibition of toxic textual contents. The complexity, informality and ambiguity of the Arabic dialects hindered the provision of the needed resources for Arabic abusive/hate speech detection research. In this paper, we introduce the first publicly-available Levantine Hate Speech and Abusive (L-HSAB) Twitter dataset with the objective to be a benchmark dataset for automatic detection of online Levantine toxic contents. We, further, provide a detailed review of the data collection steps and how we design the annotation guidelines such that a reliable dataset annotation is guaranteed. This has been later emphasized through the comprehensive evaluation of the annotations as the annotation agreement metrics of Cohen's Kappa (k) and Krippendorff's alpha (alpha) indicated the consistency of the annotations.",,,978-1-950737-43-7,111-118, , 3rd Workshop on Abusive Language Online3rd Workshop on Abusive Language Online,,out_but_toxicity,
4210,"Title:Computational Offloading for CNN-based Toxic Comment Detection on a Smartwatch

 Smartwatches are an important enabler of the Social Internet of Things (SIoT). However, a successful transition to SIoT will require negotiating challenges specific to social networks. One current challenge for social networks is the detection and removal of toxic comments like insults, threats, or sexually explicit language. Many proposed techniques for detecting toxic comments use deep neural networks. Like Siri, a smartwatch can use a remote service to detect toxic comments, or alternatively run the neural network on the edge to detect such comments. This paper presents the results of an experiment comparing the tradeoffs in memory consumption, CPU load and response time between running a toxic text detection CNN on a Samsung S3 smartwatch, or running the CNN remotely using computational offloading. Sentences were processed either periodically or by using a Poisson distribution with periods of between 0.25 and 4 minutes. The results were that there was little difference in battery depletion between running the CNN locally on the watch or remotely running the CNN. However, using WIFI for offloading resulted in much better (< 1 second) response time than running the CNN on the watch (1-2 seconds). This suggests that computational offloading is a preferred solution in this instance.","Zualkernan, Imran A.; Towheed, Mohammed","Zualkernan, Imran/B-6994-2018","Zualkernan, Imran/0000-0002-1048-5633",Computational Offloading for CNN-based Toxic Comment Detection on a Smartwatch,,,10.1109/fmec49853.2020.9144770 ,Proceedings Paper ,2020.0,"Smartwatches are an important enabler of the Social Internet of Things (SIoT). However, a successful transition to SIoT will require negotiating challenges specific to social networks. One current challenge for social networks is the detection and removal of toxic comments like insults, threats, or sexually explicit language. Many proposed techniques for detecting toxic comments use deep neural networks. Like Siri, a smartwatch can use a remote service to detect toxic comments, or alternatively run the neural network on the edge to detect such comments. This paper presents the results of an experiment comparing the tradeoffs in memory consumption, CPU load and response time between running a toxic text detection CNN on a Samsung S3 smartwatch, or running the CNN remotely using computational offloading. Sentences were processed either periodically or by using a Poisson distribution with periods of between 0.25 and 4 minutes. The results were that there was little difference in battery depletion between running the CNN locally on the watch or remotely running the CNN. However, using WIFI for offloading resulted in much better (< 1 second) response time than running the CNN on the watch (1-2 seconds). This suggests that computational offloading is a preferred solution in this instance.",,,978-1-7281-7216-3,284-288, , 5th International Conference on Fog and Mobile Edge Computing (FMEC)5th International Conference on Fog and Mobile Edge Computing (FMEC),,out_but_toxicity,
4211,"Title:Automatic Generation of Adversarial Readable Chinese Texts

 Natural language processing (NLP) models are known vulnerable to adversarial examples, similar to image processing models. Studying adversarial texts is an essential step to improve the robustness of NLP models. However, existing studies mainly focus on generating adversarial texts for English, with no prior knowledge that whether those attacks could be applied to Chinese. After analyzing the differences between Chinese and English, we propose a novel adversarial Chinese text generation solution Argot, by utilizing the method for adversarial English examples and several novel methods developed on Chinese characteristics. Argot could effectively and efficiently generate adversarial Chinese texts with good readability in both white-box and black-box settings. Argot could also automatically generate targeted Chinese adversarial texts, achieving a high success rate and ensuring the readability of the generated texts. Furthermore, we apply Argot to the spam detection task in both local detection models and a public toxic content detection system from a well-known security company. Argot achieves a relatively high bypass success rate with fluent readability, which proves that the real-world toxic content detection system is vulnerable to adversarial example attacks. We also evaluate some available defense strategies, and the results indicate that Argot can still achieve high attack success rates.","Liu, Mingxuan; Zhang, Zihan; Zhang, Yiming; Zhang, Chao; Li, Zhou; Li, Qi; Duan, Haixin; Sun, Donghong","zhang, zihan/JHU-2592-2023; Liu, Mingxuan/GQB-0395-2022","Li, Zhou/0000-0002-9401-1012; Duan, Haixin/0000-0003-0083-733X",Automatic Generation of Adversarial Readable Chinese Texts,20,2,10.1109/TDSC.2022.3164289 ,Article ,2023.0,"Natural language processing (NLP) models are known vulnerable to adversarial examples, similar to image processing models. Studying adversarial texts is an essential step to improve the robustness of NLP models. However, existing studies mainly focus on generating adversarial texts for English, with no prior knowledge that whether those attacks could be applied to Chinese. After analyzing the differences between Chinese and English, we propose a novel adversarial Chinese text generation solution Argot, by utilizing the method for adversarial English examples and several novel methods developed on Chinese characteristics. Argot could effectively and efficiently generate adversarial Chinese texts with good readability in both white-box and black-box settings. Argot could also automatically generate targeted Chinese adversarial texts, achieving a high success rate and ensuring the readability of the generated texts. Furthermore, we apply Argot to the spam detection task in both local detection models and a public toxic content detection system from a well-known security company. Argot achieves a relatively high bypass success rate with fluent readability, which proves that the real-world toxic content detection system is vulnerable to adversarial example attacks. We also evaluate some available defense strategies, and the results indicate that Argot can still achieve high attack success rates.",1545-5971,1941-0018,,1756-1770, , ,,out_but_toxicity,
4212,"Title:MaLang: A Decentralized Deep Learning Approach for Detecting Abusive Textual Content

 Cyberbullying is a growing and significant problem in today's workplace. Existing automated cyberbullying detection solutions rely on machine learning and deep learning techniques. It is proven that the deep learning-based approaches produce better accuracy for text-based classification than other existing approaches. A novel decentralized deep learning approach called MaLang is developed to detect abusive textual content. MaLang is deployed at two levels in a network: (1) the System Level and (2) the Cloud Level, to tackle the usage of toxic or abusive content on any messaging application within a company's networks. The system-level module consists of a simple deep learning model called CASE that reads the user's messaging data and classifies them into abusive and non-abusive categories, without sending any raw or readable data to the cloud. Identified abusive messages are sent to the cloud module with a unique identifier to keep user profiles hidden. The cloud module, called KIPP, utilizes deep learning to determine the probability of a message containing different categories of toxic content, such as: 'Toxic', 'Insult', 'Threat', or 'Hate Speech'. MaLang achieves a 98.2% classification accuracy that outperforms other current cyberbullying detection systems.","Kompally, Pranav; Sethuraman, Sibi Chakkaravarthy; Walczak, Steven; Johnson, Samuel; Cruz, Meenalosini Vimal","Cruz, Meenalosini Vimal/AAX-3872-2021","Cruz, Meenalosini Vimal/0000-0003-3164-4848",MaLang: A Decentralized Deep Learning Approach for Detecting Abusive Textual Content,11,18,10.3390/app11188701 ,Article ,2021.0,"Cyberbullying is a growing and significant problem in today's workplace. Existing automated cyberbullying detection solutions rely on machine learning and deep learning techniques. It is proven that the deep learning-based approaches produce better accuracy for text-based classification than other existing approaches. A novel decentralized deep learning approach called MaLang is developed to detect abusive textual content. MaLang is deployed at two levels in a network: (1) the System Level and (2) the Cloud Level, to tackle the usage of toxic or abusive content on any messaging application within a company's networks. The system-level module consists of a simple deep learning model called CASE that reads the user's messaging data and classifies them into abusive and non-abusive categories, without sending any raw or readable data to the cloud. Identified abusive messages are sent to the cloud module with a unique identifier to keep user profiles hidden. The cloud module, called KIPP, utilizes deep learning to determine the probability of a message containing different categories of toxic content, such as: 'Toxic', 'Insult', 'Threat', or 'Hate Speech'. MaLang achieves a 98.2% classification accuracy that outperforms other current cyberbullying detection systems.",,2076-3417,,, , ,,out_but_toxicity,
4213,"Title:Aanisha@TamilNLP-ACL2022:Abusive Detection in Tamil

 In social media, there are instances where people present their opinions in strong language, resorting to abusive/toxic comments.There are instances of communal hatred, hate-speech, toxicity and bullying. And, in this age of social media, it's very important to find means to keep check on these toxic comments, as to preserve the mental peace of people in social media. While there are tools, models to detect and potentially filter these kind of content, developing these kinds of models for the low resource language space is an issue of research.In this paper, the task of abusive comment identification in Tamil language, is seen upon as a multiclass classification problem.There are different pre-processing as well as modelling approaches discussed in this paper.The different approaches are compared on the basis of weighted average accuracy.","Bhattacharyya, Aanisha",,,Aanisha@TamilNLP-ACL2022:Abusive Detection in Tamil,,, ,Proceedings Paper ,2022.0,"In social media, there are instances where people present their opinions in strong language, resorting to abusive/toxic comments.There are instances of communal hatred, hate-speech, toxicity and bullying. And, in this age of social media, it's very important to find means to keep check on these toxic comments, as to preserve the mental peace of people in social media. While there are tools, models to detect and potentially filter these kind of content, developing these kinds of models for the low resource language space is an issue of research.In this paper, the task of abusive comment identification in Tamil language, is seen upon as a multiclass classification problem.There are different pre-processing as well as modelling approaches discussed in this paper.The different approaches are compared on the basis of weighted average accuracy.",,,978-1-955917-34-6,214-220, , 2nd Workshop on Speech and Language Technologies for Dravidian Languages (DravidianLangTech) / 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)2nd Workshop on Speech and Language Technologies for Dravidian Languages (DravidianLangTech) / 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,detection#out_but_toxicity,
4214,"Title:Model Agnostic Approach for NLP Backdoor Detection

 Poisoning training datasets by inserting backdoors into Natural Language Processing (NLP) models can result in model misclassifications with potential adverse impacts such as evasion of toxic content detection systems, fake news publication. A majority of the NLP backdoor defenses focus on model specific defenses. The current work proposes a model agnostic approach for NLP backdoor detection. To this end two metrics are developed to successfully distinguish between clean and poisoned text data samples.","Surendrababu, Hema Karnam",,,Model Agnostic Approach for NLP Backdoor Detection,,,10.1109/COLCACI59285.2023.10226144 ,Proceedings Paper ,2023.0,"Poisoning training datasets by inserting backdoors into Natural Language Processing (NLP) models can result in model misclassifications with potential adverse impacts such as evasion of toxic content detection systems, fake news publication. A majority of the NLP backdoor defenses focus on model specific defenses. The current work proposes a model agnostic approach for NLP backdoor detection. To this end two metrics are developed to successfully distinguish between clean and poisoned text data samples.",2769-3651,,979-8-3503-1659-9,, , IEEE Colombian Conference on Applications of Computational Intelligence (ColCACI)IEEE Colombian Conference on Applications of Computational Intelligence (ColCACI),,detection#evaluation#methodology,
4215,"Title:Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection

 Hate speech in social media is a growing phenomenon, and detecting such toxic content has recently gained significant traction in the research community. Existing studies have explored fine-tuning language models (LMs) to perform hate speech detection, and these solutions have yielded significant performance. However, most of these studies are limited to detecting hate speech only in English, neglecting the bulk of hateful content that is generated in other languages, particularly in low-resource languages. Developing a classifier that captures hate speech and nuances in a low-resource language with limited data is extremely challenging. To fill the research gap, we propose HateMAML, a model-agnostic meta-learning-based framework that effectively performs hate speech detection in low-resource languages. HateMAML utilizes a self-supervision strategy to overcome the limitation of data scarcity and produces better LM initialization for fast adaptation to an unseen target language (i.e., cross-lingual transfer) or other hate speech datasets (i.e., domain generalization). Extensive experiments are conducted on five datasets across eight different low-resource languages. The results show that HateMAML outperforms the state-of-the-art baselines by more than 3% in the cross-domain multilingual transfer setting. We also conduct ablation studies to analyze the characteristics of HateMAML.","Awal, Md Rabiul; Lee, Roy Ka-Wei; Tanwar, Eshaan; Garg, Tanmay; Chakraborty, Tanmoy",,"Lee, Roy Ka-Wei/0000-0002-1986-7750; CHAKRABORTY, TANMOY/0000-0002-0210-0369",Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection,,,10.1109/TCSS.2023.3252401 ,Article; Early Access ,,"Hate speech in social media is a growing phenomenon, and detecting such toxic content has recently gained significant traction in the research community. Existing studies have explored fine-tuning language models (LMs) to perform hate speech detection, and these solutions have yielded significant performance. However, most of these studies are limited to detecting hate speech only in English, neglecting the bulk of hateful content that is generated in other languages, particularly in low-resource languages. Developing a classifier that captures hate speech and nuances in a low-resource language with limited data is extremely challenging. To fill the research gap, we propose HateMAML, a model-agnostic meta-learning-based framework that effectively performs hate speech detection in low-resource languages. HateMAML utilizes a self-supervision strategy to overcome the limitation of data scarcity and produces better LM initialization for fast adaptation to an unseen target language (i.e., cross-lingual transfer) or other hate speech datasets (i.e., domain generalization). Extensive experiments are conducted on five datasets across eight different low-resource languages. The results show that HateMAML outperforms the state-of-the-art baselines by more than 3% in the cross-domain multilingual transfer setting. We also conduct ablation studies to analyze the characteristics of HateMAML.",2329-924X,,,, , ,,detection#evaluation#methodology,
4216,"Title:Tackling Faceless Killers: Toxic Comment Detection to Maintain a Healthy Internet Environment

 According to BBC News, online hate speech increased by 20% during the COVID-19 pandemic. Hate speech from anonymous users can result in psychological harm, including depression and trauma, and can even lead to suicide. Malicious online comments are increasingly becoming a social and cultural problem. It is therefore critical to detect such comments at the national level and detect malicious users at the corporate level. To achieve a healthy and safe Internet environment, studies should focus on institutional and technical topics. The detection of toxic comments can create a safe online environment. In this study, to detect malicious comments, we used approximately 9,400 examples of hate speech from a Korean corpus of entertainment news comments. We developed toxic comment classification models using supervised learning algorithms, including decision trees, random forest, a support vector machine, and K-nearest neighbors. The proposed model uses random forests to classify toxic words, achieving an F1-score of 0.94. We analyzed the trained model using the permutation feature importance, which is an explanatorymachine learning method. Our experimental results confirmed that the toxic comment classifier properly classified hate words used in Korea. Using this research methodology, the proposed method can create a healthy Internet environment by detecting malicious comments written in Korean.","Park, Semi; Lee, Kyungho",,,Tackling Faceless Killers: Toxic Comment Detection to Maintain a Healthy Internet Environment,76,1,10.32604/cmc.2023.035313 ,Article ,2023.0,"According to BBC News, online hate speech increased by 20% during the COVID-19 pandemic. Hate speech from anonymous users can result in psychological harm, including depression and trauma, and can even lead to suicide. Malicious online comments are increasingly becoming a social and cultural problem. It is therefore critical to detect such comments at the national level and detect malicious users at the corporate level. To achieve a healthy and safe Internet environment, studies should focus on institutional and technical topics. The detection of toxic comments can create a safe online environment. In this study, to detect malicious comments, we used approximately 9,400 examples of hate speech from a Korean corpus of entertainment news comments. We developed toxic comment classification models using supervised learning algorithms, including decision trees, random forest, a support vector machine, and K-nearest neighbors. The proposed model uses random forests to classify toxic words, achieving an F1-score of 0.94. We analyzed the trained model using the permutation feature importance, which is an explanatorymachine learning method. Our experimental results confirmed that the toxic comment classifier properly classified hate words used in Korea. Using this research methodology, the proposed method can create a healthy Internet environment by detecting malicious comments written in Korean.",1546-2218,1546-2226,,813-826, , ,,out_but_toxicity,
4217,"Title:Overview of The Shared Task on Homophobia and Transphobia Detection in Social Media Comments

 Homophobia and Transphobia Detection is the task of identifying homophobia, transphobia, and non-anti-LGBT+ content from the given corpus. Homophobia and transphobia are both toxic languages directed at LGBTQ+ individuals that are described as hate speech. This paper summarizes our findings on the Homophobia and Transphobia Detection in social media comments shared task held at LT-EDI 2022 - ACL 2022(1). This shared task focused on three sub-tasks for Tamil, English, and Tamil-English (code-mixed) languages. It received 10 systems for Tamil, 13 systems for English, and 11 systems for Tamil-English. The best systems for Tamil, English, and Tamil-English scored 0.570, 0.870, and 0.610, respectively, on average macro F1-score.","Chakravarthi, Bharathi Raja; Priyadharshini, Ruba; Thenmozhi, Durairaj; McCrae, John Phillip; Buitelaar, Paul; Ponnusamy, Rahul; Kumaresan, Prasanna Kumar","Chakravarthi, Bharathi Raja/ABD-4145-2020","Chakravarthi, Bharathi Raja/0000-0002-4575-7934; Ponnusamy, Rahul/0000-0001-8023-7742; Kumaresan, Prasanna Kumar/0000-0003-2244-246X",Overview of The Shared Task on Homophobia and Transphobia Detection in Social Media Comments,,, ,Proceedings Paper ,2022.0,"Homophobia and Transphobia Detection is the task of identifying homophobia, transphobia, and non-anti-LGBT+ content from the given corpus. Homophobia and transphobia are both toxic languages directed at LGBTQ+ individuals that are described as hate speech. This paper summarizes our findings on the Homophobia and Transphobia Detection in social media comments shared task held at LT-EDI 2022 - ACL 2022(1). This shared task focused on three sub-tasks for Tamil, English, and Tamil-English (code-mixed) languages. It received 10 systems for Tamil, 13 systems for English, and 11 systems for Tamil-English. The best systems for Tamil, English, and Tamil-English scored 0.570, 0.870, and 0.610, respectively, on average macro F1-score.",,,978-1-955917-43-8,369-377, ," 2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)",,survey,
4218,"Title:Hidden Backdoors in Human-Centric Language Models

 Natural language processing (NLP) systems have been proven to be vulnerable to backdoor attacks, whereby hidden features (backdoors) are trained into a language model and may only be activated by specific inputs (called triggers), to trick the model into producing unexpected behaviors. In this paper, we create covert and natural triggers for textual backdoor attacks, hidden backdoors, where triggers can fool both modern language models and human inspection. We deploy our hidden backdoors through two state-of-the-art trigger embedding methods. The first approach via homograph replacement, embeds the trigger into deep neural networks through the visual spoofing of lookalike character replacement. The second approach uses subtle differences between text generated by language models and real natural text to produce trigger sentences with correct grammar and highfluency. We demonstrate that the proposed hidden backdoors can be effective across three downstream security-critical NLP tasks, representative of modern human-centric NLP systems, including toxic comment detection, neural machine translation (NMT), and question answering (QA). Our two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at least 97% with an injection rate of only 3% in toxic comment detection, 95.1% ASR in NMT with less than 0.5% injected data, and finally 91.12% ASR against QA updated with only 27 poisoning data samples on a model previously trained with 92,024 samples (0.029%). We are able to demonstrate the adversary's high success rate of attacks, while maintaining functionality for regular users, with triggers inconspicuous by the human administrators.","Li, Shaofeng; Liu, Hui; Dong, Tian; Zhao, Benjamin Zi Hao; Xue, Minhui; Zhu, Haojin; Lu, Jialiang","Li, Shaofeng/HHS-0894-2022; dong, tian/JDW-6309-2023",,Hidden Backdoors in Human-Centric Language Models,,,10.1145/3460120.3484576 ,Proceedings Paper ,2021.0,"Natural language processing (NLP) systems have been proven to be vulnerable to backdoor attacks, whereby hidden features (backdoors) are trained into a language model and may only be activated by specific inputs (called triggers), to trick the model into producing unexpected behaviors. In this paper, we create covert and natural triggers for textual backdoor attacks, hidden backdoors, where triggers can fool both modern language models and human inspection. We deploy our hidden backdoors through two state-of-the-art trigger embedding methods. The first approach via homograph replacement, embeds the trigger into deep neural networks through the visual spoofing of lookalike character replacement. The second approach uses subtle differences between text generated by language models and real natural text to produce trigger sentences with correct grammar and highfluency. We demonstrate that the proposed hidden backdoors can be effective across three downstream security-critical NLP tasks, representative of modern human-centric NLP systems, including toxic comment detection, neural machine translation (NMT), and question answering (QA). Our two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at least 97% with an injection rate of only 3% in toxic comment detection, 95.1% ASR in NMT with less than 0.5% injected data, and finally 91.12% ASR against QA updated with only 27 poisoning data samples on a model previously trained with 92,024 samples (0.029%). We are able to demonstrate the adversary's high success rate of attacks, while maintaining functionality for regular users, with triggers inconspicuous by the human administrators.",,,978-1-4503-8454-4,3123-3140, , ACM SIGSAC Conference on Computer and Communications Security (ACM CCS)ACM SIGSAC Conference on Computer and Communications Security (ACM CCS),,detection,
4219,"Title:A Bi-GRU with attention and CapsNet hybrid model for cyberbullying detection on social media

 As a constructive mode of information sharing, collaboration and communication, social media platforms offer users with limitless opportunities. The same hypermedia can be transposed into a synthetic and toxic milieu that provides an anonymous, destructive pedestal for online bullying and harassment. Automatic cyberbullying detection on social media using synthetic or real-world datasets is one of a proverbial natural language processing problem. Analyzing a given text requires capturing the existent semantics, syntactic and spatial relationships. Learning representative features automatically using deep learning models efficiently captures the contextual semantics and word order arrangement to build robust and superlative predictive models. This work puts forward a hybrid model, Bi-GRU-Attention-CapsNet (Bi-GAC), that benefits by learning sequential semantic representations and spatial location information using a Bi-GRU with self-attention followed by CapsNet for cyberbullying detection in the textual content of social media. The proposed Bi-GAC model is evaluated for performance using F1-score and ROC-AUC curve as metrics. The results show a superior performance to the existing techniques on the benchmark Formspring.me and MySpace datasets. In comparison to the conventional models, an improvement of nearly 9% and 3% in F-score is observed for MySpace and Formspring.me dataset respectively.","Kumar, Akshi; Sachdeva, Nitin",,"Kumar, Akshi/0000-0003-4263-7168",A Bi-GRU with attention and CapsNet hybrid model for cyberbullying detection on social media,25,4,10.1007/s11280-021-00920-4 ,Article ,2022.0,"As a constructive mode of information sharing, collaboration and communication, social media platforms offer users with limitless opportunities. The same hypermedia can be transposed into a synthetic and toxic milieu that provides an anonymous, destructive pedestal for online bullying and harassment. Automatic cyberbullying detection on social media using synthetic or real-world datasets is one of a proverbial natural language processing problem. Analyzing a given text requires capturing the existent semantics, syntactic and spatial relationships. Learning representative features automatically using deep learning models efficiently captures the contextual semantics and word order arrangement to build robust and superlative predictive models. This work puts forward a hybrid model, Bi-GRU-Attention-CapsNet (Bi-GAC), that benefits by learning sequential semantic representations and spatial location information using a Bi-GRU with self-attention followed by CapsNet for cyberbullying detection in the textual content of social media. The proposed Bi-GAC model is evaluated for performance using F1-score and ROC-AUC curve as metrics. The results show a superior performance to the existing techniques on the benchmark Formspring.me and MySpace datasets. In comparison to the conventional models, an improvement of nearly 9% and 3% in F-score is observed for MySpace and Formspring.me dataset respectively.",1386-145X,1573-1413,,1537-1550, , ,,detection#methodology,
4220,"Title:DETECTING HATE SPEECH IN TWEETS USING DIFFERENT DEEP NEURAL NETWORK ARCHITECTURES

 One of the major problems, apparent in online social media, is the toxic online content. This has continued unabated, as people from diverse cultural backgrounds access the Internet, concealing their identity under the cloud of anonymity. Deep neural networks have been employed to detect hate speech from online content. This paper describes three different Deep Neural Network (DNN) Architectures for detection of hate words in Twitter - Gated Recurrent Unit (GRU), useful in capturing sequence orders, Convolution Neural Network (CNN), good for feature extraction, and Universal Language Model Fine-tuning (ULMFiT) model, which is based on transfer learning technique. ULMFiT model uses the DNN Architecture called Average-SGD Weight-Dropped Long Short Term Memory (AWD-LSTM). AWD LSTM model was pre-trained using WikiText103 dataset. This method significantly outperformed the other Architectures.","Amrutha, B. R.; Bindu, K. R.",,"K R, Bindu/0000-0003-2793-2978",DETECTING HATE SPEECH IN TWEETS USING DIFFERENT DEEP NEURAL NETWORK ARCHITECTURES,,,10.1109/iccs45141.2019.9065763 ,Proceedings Paper ,2019.0,"One of the major problems, apparent in online social media, is the toxic online content. This has continued unabated, as people from diverse cultural backgrounds access the Internet, concealing their identity under the cloud of anonymity. Deep neural networks have been employed to detect hate speech from online content. This paper describes three different Deep Neural Network (DNN) Architectures for detection of hate words in Twitter - Gated Recurrent Unit (GRU), useful in capturing sequence orders, Convolution Neural Network (CNN), good for feature extraction, and Universal Language Model Fine-tuning (ULMFiT) model, which is based on transfer learning technique. ULMFiT model uses the DNN Architecture called Average-SGD Weight-Dropped Long Short Term Memory (AWD-LSTM). AWD LSTM model was pre-trained using WikiText103 dataset. This method significantly outperformed the other Architectures.",,,978-1-5386-8113-8,923-926, , International Conference on Intelligent Computing and Control Systems (ICCS)International Conference on Intelligent Computing and Control Systems (ICCS),,out_but_toxicity,
4221,"Title:Offensive Language and Hate Speech Detection Based on Transfer Learning

 Offensive language is a toxic content that invades the web. It is characterized by being more than a negative reaction towards a certain event or person, since it is sharp and rude. Hate speech may be implied within an offensive language if it targets a specific part of a society, a religion, a political part, a race, a background or a specific gender. The spread of such languages over the web may cause psychological effects, hate, and war and can destruct a whole community. Preventing such a virus from spreading may help to prevent many social and political disastrous effects. In this paper, we aim to detect offensive language in social media reviews. Although detecting offensive language is a task similar to sentiment analysis, the targets of each task differ, however a transfer learning between them is possible. The offensive language detection system will be based on the same characteristics as a sentiment analysis system. We enhance the classification by performing ensemble learning that addresses the outputs of many classifiers. In order to detect hate speech, we based experiments on named entities. All along experiments, we perform both supervised and unsupervised approaches, and we also vary the lexicons based on which we generate features. The herein used lexicons are either internal extracted manually or automatically from the training corpus by the authors of this paper or external collected and filtered by our system.","Touahri, Ibtissam; Mazroui, Azzeddine",,,Offensive Language and Hate Speech Detection Based on Transfer Learning,1418,,10.1007/978-3-030-90639-9_24 ,Proceedings Paper ,2022.0,"Offensive language is a toxic content that invades the web. It is characterized by being more than a negative reaction towards a certain event or person, since it is sharp and rude. Hate speech may be implied within an offensive language if it targets a specific part of a society, a religion, a political part, a race, a background or a specific gender. The spread of such languages over the web may cause psychological effects, hate, and war and can destruct a whole community. Preventing such a virus from spreading may help to prevent many social and political disastrous effects. In this paper, we aim to detect offensive language in social media reviews. Although detecting offensive language is a task similar to sentiment analysis, the targets of each task differ, however a transfer learning between them is possible. The offensive language detection system will be based on the same characteristics as a sentiment analysis system. We enhance the classification by performing ensemble learning that addresses the outputs of many classifiers. In order to detect hate speech, we based experiments on named entities. All along experiments, we perform both supervised and unsupervised approaches, and we also vary the lexicons based on which we generate features. The herein used lexicons are either internal extracted manually or automatically from the training corpus by the authors of this paper or external collected and filtered by our system.",2194-5357,2194-5365,978-3-030-90639-9; 978-3-030-90638-2,300-311, , 3rd International Conference on Advanced Intelligent Systems for Sustainable Development (AI2SD)3rd International Conference on Advanced Intelligent Systems for Sustainable Development (AI2SD),,detection#methodology,
4222,"Title:Use of Data Augmentation Techniques in Detection of Antisocial Behavior Using Deep Learning Methods

 The work presented in this paper focuses on the use of data augmentation techniques applied in the domain of the detection of antisocial behavior. Data augmentation is a frequently used approach to overcome issues related to the lack of data or problems related to imbalanced classes. Such techniques are used to generate artificial data samples used to improve the volume of the training set or to balance the target distribution. In the antisocial behavior detection domain, we frequently face both issues, the lack of quality labeled data as well as class imbalance. As the majority of the data in this domain is textual, we must consider augmentation methods suitable for NLP tasks. Easy data augmentation (EDA) represents a group of such methods utilizing simple text transformations to create the new, artificial samples. Our main motivation is to explore EDA techniques' usability on the selected tasks from the antisocial behavior detection domain. We focus on the class imbalance problem and apply EDA techniques to two problems: fake news and toxic comments classification. In both cases, we train the convolutional neural networks classifier and compare its performance on the original and EDA-extended datasets. EDA techniques prove to be very task-dependent, with certain limitations resulting from the data they are applied on. The model's performance on the extended toxic comments dataset did improve only marginally, gaining only 0.01 improvement in the F1 metric when applying only a subset of EDA methods. EDA techniques in this case were not suitable enough to handle texts written in more informal language. On the other hand, on the fake news dataset, the performance was improved more significantly, boosting the F1 score by 0.1. Improvement was most significant in the prediction of the minor class, where F1 improved from 0.67 to 0.86.","Maslej-Kresnakova, Viera; Sarnovsky, Martin; Jackova, Julia","Sarnovsky, Martin/Z-4954-2019; Maslej Krešňáková, Viera/ABH-9510-2020","Sarnovsky, Martin/0000-0003-3019-8364; Maslej Krešňáková, Viera/0000-0002-0451-2279",Use of Data Augmentation Techniques in Detection of Antisocial Behavior Using Deep Learning Methods,14,9,10.3390/fi14090260 ,Article ,2022.0,"The work presented in this paper focuses on the use of data augmentation techniques applied in the domain of the detection of antisocial behavior. Data augmentation is a frequently used approach to overcome issues related to the lack of data or problems related to imbalanced classes. Such techniques are used to generate artificial data samples used to improve the volume of the training set or to balance the target distribution. In the antisocial behavior detection domain, we frequently face both issues, the lack of quality labeled data as well as class imbalance. As the majority of the data in this domain is textual, we must consider augmentation methods suitable for NLP tasks. Easy data augmentation (EDA) represents a group of such methods utilizing simple text transformations to create the new, artificial samples. Our main motivation is to explore EDA techniques' usability on the selected tasks from the antisocial behavior detection domain. We focus on the class imbalance problem and apply EDA techniques to two problems: fake news and toxic comments classification. In both cases, we train the convolutional neural networks classifier and compare its performance on the original and EDA-extended datasets. EDA techniques prove to be very task-dependent, with certain limitations resulting from the data they are applied on. The model's performance on the extended toxic comments dataset did improve only marginally, gaining only 0.01 improvement in the F1 metric when applying only a subset of EDA methods. EDA techniques in this case were not suitable enough to handle texts written in more informal language. On the other hand, on the fake news dataset, the performance was improved more significantly, boosting the F1 score by 0.1. Improvement was most significant in the prediction of the minor class, where F1 improved from 0.67 to 0.86.",,1999-5903,,, , ,,detection#methodology,
4223,"Title:Is this Question Real? Dataset Collection on Perceived Intentions and Implicit Attack Detection

 The proliferation of social media and online communication platforms has made social interactions more accessible, leading to a significant expansion of research into language use with a particular focus on toxic behavior and hate speech. Few studies, however, have focused on the tacit information that may imply a negative intention and the perspective that impacts the interpretation of such intention. Conversation is a joint activity that relies on coordination between what one party expresses and how the other party construes what has been expressed. Thus, how a message is perceived becomes equally important regardless of whether the sent message includes any form of explicit attack or offense. This study focuses on identifying the implicit attacks and negative intentions in text-based conversation from the reader's point of view. We focus on questions in conversations and investigate the underlying perceived intention. We introduce our dataset that includes questions, intention polarity, and type of attacks. We conduct a meta-analysis on the data to demonstrate how a question may be used as a means of attack and how different perspectives can lead to multiple interpretations. We also report benchmark results of several models for detecting instances of tacit attacks in questions with the aim of avoiding latent or manifest conflict in conversations.","Mirzaei, Maryam Sadat; Meshgi, Kourosh; Sekine, Satoshi",,,Is this Question Real? Dataset Collection on Perceived Intentions and Implicit Attack Detection,,,10.1145/3485447.3512005 ,Proceedings Paper ,2022.0,"The proliferation of social media and online communication platforms has made social interactions more accessible, leading to a significant expansion of research into language use with a particular focus on toxic behavior and hate speech. Few studies, however, have focused on the tacit information that may imply a negative intention and the perspective that impacts the interpretation of such intention. Conversation is a joint activity that relies on coordination between what one party expresses and how the other party construes what has been expressed. Thus, how a message is perceived becomes equally important regardless of whether the sent message includes any form of explicit attack or offense. This study focuses on identifying the implicit attacks and negative intentions in text-based conversation from the reader's point of view. We focus on questions in conversations and investigate the underlying perceived intention. We introduce our dataset that includes questions, intention polarity, and type of attacks. We conduct a meta-analysis on the data to demonstrate how a question may be used as a means of attack and how different perspectives can lead to multiple interpretations. We also report benchmark results of several models for detecting instances of tacit attacks in questions with the aim of avoiding latent or manifest conflict in conversations.",,,978-1-4503-9096-5,2850-2859, , 31st ACM Web Conference (WWW)31st ACM Web Conference (WWW),,Gen_dataset,
4224,"Title:Deep Learning in the Detection of Disinformation about COVID-19 in Online Space

 This article focuses on the problem of detecting disinformation about COVID-19 in online discussions. As the Internet expands, so does the amount of content on it. In addition to content based on facts, a large amount of content is being manipulated, which negatively affects the whole society. This effect is currently compounded by the ongoing COVID-19 pandemic, which caused people to spend even more time online and to get more invested in this fake content. This work brings a brief overview of how toxic information looks like, how it is spread, and how to potentially prevent its dissemination by early recognition of disinformation using deep learning. We investigated the overall suitability of deep learning in solving problem of detection of disinformation in conversational content. We also provided a comparison of architecture based on convolutional and recurrent principles. We have trained three detection models based on three architectures using CNN (convolutional neural networks), LSTM (long short-term memory), and their combination. We have achieved the best results using LSTM (F1 = 0.8741, Accuracy = 0.8628). But the results of all three architectures were comparable, for example the CNN+LSTM architecture achieved F1 = 0.8672 and Accuracy = 0.852. The paper offers finding that introducing a convolutional component does not bring significant improvement. In comparison with our previous works, we noted that from all forms of antisocial posts, disinformation is the most difficult to recognize, since disinformation has no unique language, such as hate speech, toxic posts etc.","Machova, Kristina; Mach, Marian; Porezany, Michal",,"Machova, Kristina/0000-0002-7741-4039",Deep Learning in the Detection of Disinformation about COVID-19 in Online Space,22,23,10.3390/s22239319 ,Article ,2022.0,"This article focuses on the problem of detecting disinformation about COVID-19 in online discussions. As the Internet expands, so does the amount of content on it. In addition to content based on facts, a large amount of content is being manipulated, which negatively affects the whole society. This effect is currently compounded by the ongoing COVID-19 pandemic, which caused people to spend even more time online and to get more invested in this fake content. This work brings a brief overview of how toxic information looks like, how it is spread, and how to potentially prevent its dissemination by early recognition of disinformation using deep learning. We investigated the overall suitability of deep learning in solving problem of detection of disinformation in conversational content. We also provided a comparison of architecture based on convolutional and recurrent principles. We have trained three detection models based on three architectures using CNN (convolutional neural networks), LSTM (long short-term memory), and their combination. We have achieved the best results using LSTM (F1 = 0.8741, Accuracy = 0.8628). But the results of all three architectures were comparable, for example the CNN+LSTM architecture achieved F1 = 0.8672 and Accuracy = 0.852. The paper offers finding that introducing a convolutional component does not bring significant improvement. In comparison with our previous works, we noted that from all forms of antisocial posts, disinformation is the most difficult to recognize, since disinformation has no unique language, such as hate speech, toxic posts etc.",,1424-8220,,, , ,,out_of_scope,
4225,"Title:Applying Machine Learning Techniques for Religious Extremism Detection on Online User Contents

 In this research paper, we propose a corpus for the task of detecting religious extremism in social networks and open sources and compare various machine learning algorithms for the binary classification problem using a previously created corpus, thereby checking whether it is possible to detect extremist messages in the Kazakh language. To do this, the authors trained models using six classic machine-learning algorithms such as Support Vector Machine, Decision Tree, Random Forest, K Nearest Neighbors, Naive Bayes, and Logistic Regression. To increase the accuracy of detecting extremist texts, we used various characteristics such as Statistical Features, TF-IDF, POS, LIWC, and applied oversampling and undersampling techniques to handle imbalanced data. As a result, we achieved 98% accuracy in detecting religious extremism in Kazakh texts for the collected dataset. Testing the developed machine learning models in various databases that are often found in everyday life Jokes, News, Toxic content, Spam, Advertising has also shown high rates of extremism detection.","Mussiraliyeva, Shynar; Omarov, Batyrkhan; Yoo, Paul; Bolatbek, Milana","Mussiraliyeva, Shynar/ABA-9832-2021; Bolatbek, Milana/GZL-7318-2022; Omarov, Batyrkhan/V-7356-2019","Mussiraliyeva, Shynar/0000-0001-5794-3649; Omarov, Batyrkhan/0000-0002-8341-7113",Applying Machine Learning Techniques for Religious Extremism Detection on Online User Contents,70,1,10.32604/cmc.2022.019189 ,Article ,2022.0,"In this research paper, we propose a corpus for the task of detecting religious extremism in social networks and open sources and compare various machine learning algorithms for the binary classification problem using a previously created corpus, thereby checking whether it is possible to detect extremist messages in the Kazakh language. To do this, the authors trained models using six classic machine-learning algorithms such as Support Vector Machine, Decision Tree, Random Forest, K Nearest Neighbors, Naive Bayes, and Logistic Regression. To increase the accuracy of detecting extremist texts, we used various characteristics such as Statistical Features, TF-IDF, POS, LIWC, and applied oversampling and undersampling techniques to handle imbalanced data. As a result, we achieved 98% accuracy in detecting religious extremism in Kazakh texts for the collected dataset. Testing the developed machine learning models in various databases that are often found in everyday life Jokes, News, Toxic content, Spam, Advertising has also shown high rates of extremism detection.",1546-2218,1546-2226,,915-934, , ,,Gen_dataset#out_but_toxicity,
4226,"Title:A Literature Review of Textual Hate Speech Detection Methods and Datasets

 Online toxic discourses could result in conflicts between groups or harm to online communities. Hate speech is complex and multifaceted harmful or offensive content targeting individuals or groups. Existing literature reviews have generally focused on a particular category of hate speech, and to the best of our knowledge, no review has been dedicated to hate speech datasets. This paper systematically reviews textual hate speech detection systems and highlights their primary datasets, textual features, and machine learning models. The results of this literature review are integrated with content analysis, resulting in several themes for 138 relevant papers. This study shows several approaches that do not provide consistent results in various hate speech categories. The most dominant sets of methods combine more than one deep learning model. Moreover, the analysis of several hate speech datasets shows that many datasets are small in size and are not reliable for various tasks of hate speech detection. Therefore, this study provides the research community with insights and empirical evidence on the intrinsic properties of hate speech and helps communities identify topics for future work.","Alkomah, Fatimah; Ma, Xiaogang","Ma, Xiaogang (Marshall)/C-9286-2011","Ma, Xiaogang (Marshall)/0000-0002-9110-7369",A Literature Review of Textual Hate Speech Detection Methods and Datasets,13,6,10.3390/info13060273 ,Review ,2022.0,"Online toxic discourses could result in conflicts between groups or harm to online communities. Hate speech is complex and multifaceted harmful or offensive content targeting individuals or groups. Existing literature reviews have generally focused on a particular category of hate speech, and to the best of our knowledge, no review has been dedicated to hate speech datasets. This paper systematically reviews textual hate speech detection systems and highlights their primary datasets, textual features, and machine learning models. The results of this literature review are integrated with content analysis, resulting in several themes for 138 relevant papers. This study shows several approaches that do not provide consistent results in various hate speech categories. The most dominant sets of methods combine more than one deep learning model. Moreover, the analysis of several hate speech datasets shows that many datasets are small in size and are not reliable for various tasks of hate speech detection. Therefore, this study provides the research community with insights and empirical evidence on the intrinsic properties of hate speech and helps communities identify topics for future work.",,2078-2489,,, , ,,survey,
4227,"Title:Acoustic and Visual Approaches to Adversarial Text Generation for Google Perspective

 Google's Perspective API was introduced to help detect and classify toxic comments in online platforms. Adversarial machine learning attacks can decrease the effectiveness of Perspective in identifying toxic comments. We have shown in our previous study that by applying a semantic-based attack to a surrogate model trained with just 10,000 queries we could produce adversarial examples which evade Perspective 25% of the time. In this paper, we propose two new approaches to generate adversarial text to evade Google's Perspective, one based on acoustic similarity and the other based on visual similarity. We tested the success rate of obfuscation in Google Perspective using the adversarial texts generated through the proposed approaches and showed that Google Perspective misclassified the generated texts 33% and 72.5% of the time for the visual-based and acoustic based approaches, respectively. The study aims to broaden the understanding of adversarial text generation and to improve the robustness for online toxic comment detection for a safe online community.","Brown, Stephan; Milkov, Petar; Patel, Sameep; Looi, Yi Zen; Jain, Edwin; Dong, Ziqian; Gu, Huanying; Artan, N. Sertac",,"Artan, N. Sertac/0000-0002-2335-0279",Acoustic and Visual Approaches to Adversarial Text Generation for Google Perspective,,,10.1109/CSCI49370.2019.00069 ,Proceedings Paper ,2019.0,"Google's Perspective API was introduced to help detect and classify toxic comments in online platforms. Adversarial machine learning attacks can decrease the effectiveness of Perspective in identifying toxic comments. We have shown in our previous study that by applying a semantic-based attack to a surrogate model trained with just 10,000 queries we could produce adversarial examples which evade Perspective 25% of the time. In this paper, we propose two new approaches to generate adversarial text to evade Google's Perspective, one based on acoustic similarity and the other based on visual similarity. We tested the success rate of obfuscation in Google Perspective using the adversarial texts generated through the proposed approaches and showed that Google Perspective misclassified the generated texts 33% and 72.5% of the time for the visual-based and acoustic based approaches, respectively. The study aims to broaden the understanding of adversarial text generation and to improve the robustness for online toxic comment detection for a safe online community.",,,978-1-7281-5584-5,355-360, , 6th Annual Conference on Computational Science and Computational Intelligence (CSCI)6th Annual Conference on Computational Science and Computational Intelligence (CSCI),,detection#methodology,
4228,"Title:RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining

 Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese. In this work, we propose ROCBERT: a pretrained Chinese Bert that is robust to various forms of adversarial attacks like word perturbation, synonyms, typos, etc. It is pretrained with the contrastive learning objective which maximizes the label consistency under different synthesized adversarial examples. The model takes as input multimodal information including the semantic, phonetic and visual features. We show all these features are important to the model robustness since the attack can be performed in all the three forms. Across 5 Chinese NLU tasks, ROCBERT outperforms strong baselines under three blackbox adversarial algorithms without sacrificing the performance on clean testset. It also performs the best in the toxic content detection task under human-made attacks.","Su, Hui; Shi, Weiwei; Shen, Xiaoyu; Zhou, Xiao; Ji, Tuo; Fang, Jiarui; Zhou, Jie","fang, jiarui/GLR-0255-2022","fang, jiarui/0000-0002-6724-2763",RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining,,, ,Proceedings Paper ,2022.0,"Large-scale pretrained language models have achieved SOTA results on NLP tasks. However, they have been shown vulnerable to adversarial attacks especially for logographic languages like Chinese. In this work, we propose ROCBERT: a pretrained Chinese Bert that is robust to various forms of adversarial attacks like word perturbation, synonyms, typos, etc. It is pretrained with the contrastive learning objective which maximizes the label consistency under different synthesized adversarial examples. The model takes as input multimodal information including the semantic, phonetic and visual features. We show all these features are important to the model robustness since the attack can be performed in all the three forms. Across 5 Chinese NLU tasks, ROCBERT outperforms strong baselines under three blackbox adversarial algorithms without sacrificing the performance on clean testset. It also performs the best in the toxic content detection task under human-made attacks.",,,978-1-955917-21-6,921-931, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,out_but_toxicity,
4229,"Title:Detection of homophobia and transphobia in YouTube comments

 Users of online platforms have negative effects on their mental health as a direct result of the spread of abusive content across social media networks. Homophobia are terms that refer to the fear, hatred, discomfort, or suspicion of or toward those who identify as homosexual or bisexual. Transphobia is fear, hatred, discomfort toward those who are transgenders. Homophobia/transphobia speechs are a sort of offensive language that can be summed up as hate speech directed toward LGBTQ+ persons, and it has become an increasing concern in recent years. The homophobia and transphobia found online are a serious societal issue that can make online platforms toxic and unwelcoming to LGBTQ+ individuals and hinder the eradication of equality, diversity, and inclusion. We present a new dataset for online homophobia and transphobia detection that has been annotated by experts, which will enable homophobic and transphobic content to be automatically recognized. The dataset includes 15,141 annotated comments written in English, Tamil, and both Tamil and English. Additionally, we provide the outcomes of our benchmark system in a variety of machine learning models. For the purpose of developing benchmark systems, we conducted a number of experiments utilizing a variety of cutting-edge machine and deep learning models. Furthermore, we discuss our shared task conducted at LTEDI-ACL 2022 workshop to improve the research in homophobia and transphobia detection. It garnered 10 systems for the Tamil language, 13 systems for the English language, and 11 systems for the combination of Tamil and English languages. The best systems for Tamil, English, and Tamil-English each received an average macro F1 score of 0.570, 0.870, and 0.610, respectively.","Chakravarthi, Bharathi Raja",,,Detection of homophobia and transphobia in YouTube comments,,,10.1007/s41060-023-00400-0 ,Article; Early Access ,,"Users of online platforms have negative effects on their mental health as a direct result of the spread of abusive content across social media networks. Homophobia are terms that refer to the fear, hatred, discomfort, or suspicion of or toward those who identify as homosexual or bisexual. Transphobia is fear, hatred, discomfort toward those who are transgenders. Homophobia/transphobia speechs are a sort of offensive language that can be summed up as hate speech directed toward LGBTQ+ persons, and it has become an increasing concern in recent years. The homophobia and transphobia found online are a serious societal issue that can make online platforms toxic and unwelcoming to LGBTQ+ individuals and hinder the eradication of equality, diversity, and inclusion. We present a new dataset for online homophobia and transphobia detection that has been annotated by experts, which will enable homophobic and transphobic content to be automatically recognized. The dataset includes 15,141 annotated comments written in English, Tamil, and both Tamil and English. Additionally, we provide the outcomes of our benchmark system in a variety of machine learning models. For the purpose of developing benchmark systems, we conducted a number of experiments utilizing a variety of cutting-edge machine and deep learning models. Furthermore, we discuss our shared task conducted at LTEDI-ACL 2022 workshop to improve the research in homophobia and transphobia detection. It garnered 10 systems for the Tamil language, 13 systems for the English language, and 11 systems for the combination of Tamil and English languages. The best systems for Tamil, English, and Tamil-English each received an average macro F1 score of 0.570, 0.870, and 0.610, respectively.",2364-415X,2364-4168,,, , ,,Gen_dataset#detection,
4230,"Title:Detecting Interpersonal Conflict in Issues and Code Review: Cross Pollinating Open- and Closed-Source Approaches

 Interpersonal conflict in code review, such as toxic language or an unnecessary pushback, is associated with negative outcomes such as stress and turnover. Automatic detection is one approach to prevent and mitigate interpersonal conflict. Two recent automatic detection approaches were developed in different settings: a toxicity detector using text analytics for open source issue discussions and a pushback detector using logs-based metrics for corporate code reviews. This paper tests how the toxicity detector and the pushback detector can be generalized beyond their respective contexts and discussion types, and how the combination of the two can help improve interpersonal conflict detection. The results reveal connections between the two concepts.LAY ABSTRACTSoftware engineers often communicate with one another on platforms that support tasks like discussing bugs and inspecting each others' code. Such discussions sometimes contain interpersonal conflict, which can lead to stress and abandonment. In this paper, we investigate how to automatically detect interpersonal conflict, both by analyzing the text of the what the engineers are saying and by analyzing the properties of that text.","Qiu, Huilian Sophie; Vasilescu, Bogdan; Kastner, Christian; Egelman, Carolyn; Jaspan, Ciera; Murphy-Hill, Emerson","Qiu, Huilian Sophie/HCG-8422-2022","Qiu, Huilian Sophie/0000-0002-6089-7003; Egelman, Carolyn/0000-0003-3352-2203",Detecting Interpersonal Conflict in Issues and Code Review: Cross Pollinating Open- and Closed-Source Approaches,,,10.1145/3510458.3513019 ,Proceedings Paper ,2022.0,"Interpersonal conflict in code review, such as toxic language or an unnecessary pushback, is associated with negative outcomes such as stress and turnover. Automatic detection is one approach to prevent and mitigate interpersonal conflict. Two recent automatic detection approaches were developed in different settings: a toxicity detector using text analytics for open source issue discussions and a pushback detector using logs-based metrics for corporate code reviews. This paper tests how the toxicity detector and the pushback detector can be generalized beyond their respective contexts and discussion types, and how the combination of the two can help improve interpersonal conflict detection. The results reveal connections between the two concepts.LAY ABSTRACTSoftware engineers often communicate with one another on platforms that support tasks like discussing bugs and inspecting each others' code. Such discussions sometimes contain interpersonal conflict, which can lead to stress and abandonment. In this paper, we investigate how to automatically detect interpersonal conflict, both by analyzing the text of the what the engineers are saying and by analyzing the properties of that text.",,,978-1-6654-9594-3,41-55, , 44th IEEE/ACM International Conference on Software Engineering - Software Engineering in Society (ICSE-SEIS)44th IEEE/ACM International Conference on Software Engineering - Software Engineering in Society (ICSE-SEIS),,out_of_scope,
4231,"Title:Implementation of Adaboost for the Detection of the Toxic Response Behaviour of Zebrafish (Danio Rerio)

 The movement behaviour of zebrafish (Banjo rerio) schools was observed in response to treatment with copper at a 24 h half-lethal concentration. The behavioural characteristic parameters, which were continuously recorded into a SQL (Structured Query Language) Server database by a digital image processing system both before and after the treatment, had significant changes. Subsequently, the Adaboost algorithm was implemented to solve the data vector classification problem in normal and abnormal water. Furthermore, to evaluate the accuracy and timeliness of the classifiers, Adaboost was compared with a back-propagation neural network (BPNN) and support vector machine (SVM). The results clearly demonstrated that the prediction accuracy of the Gentle Adaboost and Real Adaboost algorithms were over 93%, which was better than the Modest Adaboost, the BPNN and the SVM. In addition, the time requirement was also acceptable. In conclusion, Adaboost is a useful computational method for the classification of water quality.","Du, Qiuju; Xu, Jianyu; Ge, Yinghui; Wang, Chunlin",,,Implementation of Adaboost for the Detection of the Toxic Response Behaviour of Zebrafish (Danio Rerio),,, ,Proceedings Paper ,2015.0,"The movement behaviour of zebrafish (Banjo rerio) schools was observed in response to treatment with copper at a 24 h half-lethal concentration. The behavioural characteristic parameters, which were continuously recorded into a SQL (Structured Query Language) Server database by a digital image processing system both before and after the treatment, had significant changes. Subsequently, the Adaboost algorithm was implemented to solve the data vector classification problem in normal and abnormal water. Furthermore, to evaluate the accuracy and timeliness of the classifiers, Adaboost was compared with a back-propagation neural network (BPNN) and support vector machine (SVM). The results clearly demonstrated that the prediction accuracy of the Gentle Adaboost and Real Adaboost algorithms were over 93%, which was better than the Modest Adaboost, the BPNN and the SVM. In addition, the time requirement was also acceptable. In conclusion, Adaboost is a useful computational method for the classification of water quality.",2162-7843,,978-1-5090-0480-5,466-471, , IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)IEEE International Symposium on Signal Processing and Information Technology (ISSPIT),,out_of_scope,
4232,"Title:Detecting ethnicity-targeted hate speech in Russian social media texts

 Ethnicity-targeted hate speech has been widely shown to influence on-the-ground inter-ethnic conflict and violence, especially in such multi-ethnic societies as Russia. Therefore, ethnicitytargeted hate speech detection in user texts is becoming an important task. However, it faces a number of unresolved problems: difficulties of reliable mark-up, informal and indirect ways of expressing negativity in user texts (such as irony, false generalization and attribution of unfavored actions to targeted groups), users' inclination to express opposite attitudes to different ethnic groups in the same text and, finally, lack of research on languages other than English. In this work we address several of these problems in the task of ethnicity-targeted hate speech detection in Russian-language social media texts. This approach allows us to differentiate between attitudes towards different ethnic groups mentioned in the same text - a task that has never been addressed before. We use a dataset of over 2,6M user messages mentioning ethnic groups to construct a representative sample of 12K instances (ethnic group, text) that are further thoroughly annotated via a special procedure. In contrast to many previous collections that usually comprise extreme cases of toxic speech, representativity of our sample secures a realistic and, therefore, much higher proportion of subtle negativity which additionally complicates its automatic detection. We then experiment with four types of machine learning models, from traditional classifiers such as SVM to deep learning approaches, notably the recently introduced BERT architecture, and interpret their predictions in terms of various linguistic phenomena. In addition to hate speech detection with a text-level two-class approach (hate, no hate), we also justify and implement a unique instance-based three-class approach (positive, neutral, negative attitude, the latter implying hate speech). Our best results are achieved by using fine-tuned and pre-trained RuBERT combined with linguistic features, with F1-hate=0.760, F1-macro=0.833 on the textlevel two-class problem comparable to previous studies, and F1-hate=0.813, F1-macro=0.824 on our unique instance-based three-class hate speech detection task. Finally, we perform error analysis, and it reveals that further improvement could be achieved by accounting for complex and creative language issues more accurately, i.e., by detecting irony and unconventional forms of obscene lexicon.","Pronoza, Ekaterina; Panicheva, Polina; Koltsova, Olessia; Rosso, Paolo","Koltsova, Olessia/C-1891-2016","Koltsova, Olessia/0000-0002-2669-3154",Detecting ethnicity-targeted hate speech in Russian social media texts,58,6,10.1016/j.ipm.2021.102674 ,Article ,2021.0,"Ethnicity-targeted hate speech has been widely shown to influence on-the-ground inter-ethnic conflict and violence, especially in such multi-ethnic societies as Russia. Therefore, ethnicitytargeted hate speech detection in user texts is becoming an important task. However, it faces a number of unresolved problems: difficulties of reliable mark-up, informal and indirect ways of expressing negativity in user texts (such as irony, false generalization and attribution of unfavored actions to targeted groups), users' inclination to express opposite attitudes to different ethnic groups in the same text and, finally, lack of research on languages other than English. In this work we address several of these problems in the task of ethnicity-targeted hate speech detection in Russian-language social media texts. This approach allows us to differentiate between attitudes towards different ethnic groups mentioned in the same text - a task that has never been addressed before. We use a dataset of over 2,6M user messages mentioning ethnic groups to construct a representative sample of 12K instances (ethnic group, text) that are further thoroughly annotated via a special procedure. In contrast to many previous collections that usually comprise extreme cases of toxic speech, representativity of our sample secures a realistic and, therefore, much higher proportion of subtle negativity which additionally complicates its automatic detection. We then experiment with four types of machine learning models, from traditional classifiers such as SVM to deep learning approaches, notably the recently introduced BERT architecture, and interpret their predictions in terms of various linguistic phenomena. In addition to hate speech detection with a text-level two-class approach (hate, no hate), we also justify and implement a unique instance-based three-class approach (positive, neutral, negative attitude, the latter implying hate speech). Our best results are achieved by using fine-tuned and pre-trained RuBERT combined with linguistic features, with F1-hate=0.760, F1-macro=0.833 on the textlevel two-class problem comparable to previous studies, and F1-hate=0.813, F1-macro=0.824 on our unique instance-based three-class hate speech detection task. Finally, we perform error analysis, and it reveals that further improvement could be achieved by accounting for complex and creative language issues more accurately, i.e., by detecting irony and unconventional forms of obscene lexicon.",0306-4573,1873-5371,,, , ,,out_but_toxicity,
4233,"Title:Suum Cuique: Studying Bias in Taboo Detection with a Community Perspective

 Prior research has discussed and illustrated the need to consider linguistic norms at the community level when studying taboo (hateful/offensive/toxic etc.) language. However, a methodology for doing so, that is firmly founded on community language norms is still largely absent. This can lead both to biases in taboo text classification and limitations in our understanding of the causes of bias. We propose a method to study bias in taboo classification and annotation where a community perspective is front and center. This is accomplished by using special classifiers tuned for each community's language. In essence, these classifiers represent community level language norms. We use these to study bias and find, for example, biases are largest against African Americans (7/10 datasets and all 3 classifiers examined). In contrast to previous papers we also study other communities and find, for example, strong biases against South Asians. In a small scale user study we illustrate our key idea which is that common utterances, i.e., those with high alignment scores with a community (community classifier confidence scores) are unlikely to be regarded taboo. Annotators who are community members contradict taboo classification decisions and annotations in a majority of instances. This paper is a significant step toward reducing false positive taboo decisions that over time harm minority communities.","Khalid, Osama; Rusert, Jonathan; Srinivasan, Padmini",,,Suum Cuique: Studying Bias in Taboo Detection with a Community Perspective,,, ,Proceedings Paper ,2022.0,"Prior research has discussed and illustrated the need to consider linguistic norms at the community level when studying taboo (hateful/offensive/toxic etc.) language. However, a methodology for doing so, that is firmly founded on community language norms is still largely absent. This can lead both to biases in taboo text classification and limitations in our understanding of the causes of bias. We propose a method to study bias in taboo classification and annotation where a community perspective is front and center. This is accomplished by using special classifiers tuned for each community's language. In essence, these classifiers represent community level language norms. We use these to study bias and find, for example, biases are largest against African Americans (7/10 datasets and all 3 classifiers examined). In contrast to previous papers we also study other communities and find, for example, strong biases against South Asians. In a small scale user study we illustrate our key idea which is that common utterances, i.e., those with high alignment scores with a community (community classifier confidence scores) are unlikely to be regarded taboo. Annotators who are community members contradict taboo classification decisions and annotations in a majority of instances. This paper is a significant step toward reducing false positive taboo decisions that over time harm minority communities.",,,978-1-955917-25-4,2883-2896, , 60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)60th Annual Meeting of the Association-for-Computational-Linguistics (ACL),,evaluation,
4234,"Title:Cyberbullying Classifiers are Sensitive to Model-Agnostic Perturbations

 A limited amount of studies investigate the role of model-agnostic adversarial behavior in toxic content classification. As toxicity classifiers predominantly rely on lexical cues, (deliberately) creative and evolving language-use can be detrimental to the utility of current corpora and state-of-the-art models when they are deployed for content moderation. The less training data is available, the more vulnerable models might become. This study is, to our knowledge, the first to investigate the effect of adversarial behavior and augmentation for cyberbullying detection. We demonstrate that model-agnostic lexical substitutions significantly hurt classifier performance. Moreover, when these perturbed samples are used for augmentation, we show models become robust against word-level perturbations at a slight trade-off in overall task performance. Augmentations proposed in prior work on toxicity prove to be less effective. Our results underline the need for such evaluations in online harm areas with small corpora. The perturbed data, models, and code are available for reproduction at https://github.com/cmry/augtox.","Emmery, Chris; Kadar, Akos; Chrupala, Grzegorz; Daelemans, Walter",,"Daelemans, Walter/0000-0002-9832-7890; Chrupala, Grzegorz/0000-0001-9498-6912; Emmery, Chris/0000-0002-2179-559X",Cyberbullying Classifiers are Sensitive to Model-Agnostic Perturbations,,, ,Proceedings Paper ,2022.0,"A limited amount of studies investigate the role of model-agnostic adversarial behavior in toxic content classification. As toxicity classifiers predominantly rely on lexical cues, (deliberately) creative and evolving language-use can be detrimental to the utility of current corpora and state-of-the-art models when they are deployed for content moderation. The less training data is available, the more vulnerable models might become. This study is, to our knowledge, the first to investigate the effect of adversarial behavior and augmentation for cyberbullying detection. We demonstrate that model-agnostic lexical substitutions significantly hurt classifier performance. Moreover, when these perturbed samples are used for augmentation, we show models become robust against word-level perturbations at a slight trade-off in overall task performance. Augmentations proposed in prior work on toxicity prove to be less effective. Our results underline the need for such evaluations in online harm areas with small corpora. The perturbed data, models, and code are available for reproduction at https://github.com/cmry/augtox.",,,979-10-95546-72-6,2976-2988, , 13th International Conference on Language Resources and Evaluation (LREC)13th International Conference on Language Resources and Evaluation (LREC),,detection#evaluation#methodology,
4235,"Title:Automated detection and quantification of Enchytraeus crypticus (Oligochaeta: Enchytraeidae) in tropical artificial soil using image analysis

 The effects of toxic substance in soil matrices are evaluated by assessing adult worm survival and reproduction. Throughout the test, hundreds of juvenile potworms can be found. The current method for Enchytraeus crypticus quantification in soil samples is a laborious and time-consuming procedure that involves manual counting. The present work proposes a method for quick and reliable counting of E. crypticus by using an automated image analysis algorithm applied to soil images. Comparisons between automated and manual methods conducted in double-blind trials involving a large, routine batch of tropical artificial soil samples revealed no statistically significant differences for a wide range of worm densities. The proposed method overcomes time-consuming counts in manual methods and is suited to be deployed routinely for soil toxicity studies involving large batches of samples.","Belini, Valdinei L.; Felipe, Mayara C.; Corbi, Juliano J.; Zaiat, Marcelo","Corbi, Juliano JJ/F-8060-2015; Zaiat, Marcelo/C-4752-2012","Zaiat, Marcelo/0000-0001-7336-9093; Felipe, Mayara Caroline/0000-0003-4728-5958; Corbi, Juliano/0000-0003-0249-9370",Automated detection and quantification of Enchytraeus crypticus (Oligochaeta: Enchytraeidae) in tropical artificial soil using image analysis,194,9,10.1007/s10661-022-10317-z ,Article ,2022.0,"The effects of toxic substance in soil matrices are evaluated by assessing adult worm survival and reproduction. Throughout the test, hundreds of juvenile potworms can be found. The current method for Enchytraeus crypticus quantification in soil samples is a laborious and time-consuming procedure that involves manual counting. The present work proposes a method for quick and reliable counting of E. crypticus by using an automated image analysis algorithm applied to soil images. Comparisons between automated and manual methods conducted in double-blind trials involving a large, routine batch of tropical artificial soil samples revealed no statistically significant differences for a wide range of worm densities. The proposed method overcomes time-consuming counts in manual methods and is suited to be deployed routinely for soil toxicity studies involving large batches of samples.",0167-6369,1573-2959,,, , ,,out_of_scope,
4236,"Title:Machine learning and semantic analysis of in-game chat for cyberbullying

 One major problem with cyberbullying research is the lack of data, since researchers are traditionally forced to rely on survey data where victims and perpetrators self-report their impressions. In this paper, an automatic data collection system is presented that continuously collects in-game chat data from one of the most popular online multiplayer games: World of Tanks. The data were collected and combined with other information about the players from available online data services. It presents a scoring scheme to enable identification of cyberbullying based on current research. Classification of the collected data was carried out using simple feature detection with SQL database queries and compared to classification from AI-based sentiment text analysis services that have recently become available and further against manually classified data using a custom-built classification client built for this paper. The simple SQL classification proved to be quite useful at identifying some features of toxic chat such as the use of bad language or racist sentiments, however the classification by the more sophisticated online sentiment analysis services proved to be disappointing. The results were then examined for insights into cyberbullying within this game and it was shown that it should be possible to reduce cyberbullying within the World of Tanks game by a significant factor by simply freezing the player's ability to communicate through the in-game chat function for a short period after the player is killed within a match. It was also shown that very new players are much less likely to engage in cyberbullying, suggesting that it may be a learned behaviour from other players. (C) 2018 Elsevier Ltd. All rights reserved.","Murnion, Shane; Buchanan, William J.; Smales, Adrian; Russell, Gordon","Buchanan, William/F-2240-2015; Russell, Gordon/AAA-9285-2019","Buchanan, William/0000-0003-0809-3523; Russell, Gordon/0000-0002-3589-3051",Machine learning and semantic analysis of in-game chat for cyberbullying,76,,10.1016/j.cose.2018.02.016 ,Article ,2018.0,"One major problem with cyberbullying research is the lack of data, since researchers are traditionally forced to rely on survey data where victims and perpetrators self-report their impressions. In this paper, an automatic data collection system is presented that continuously collects in-game chat data from one of the most popular online multiplayer games: World of Tanks. The data were collected and combined with other information about the players from available online data services. It presents a scoring scheme to enable identification of cyberbullying based on current research. Classification of the collected data was carried out using simple feature detection with SQL database queries and compared to classification from AI-based sentiment text analysis services that have recently become available and further against manually classified data using a custom-built classification client built for this paper. The simple SQL classification proved to be quite useful at identifying some features of toxic chat such as the use of bad language or racist sentiments, however the classification by the more sophisticated online sentiment analysis services proved to be disappointing. The results were then examined for insights into cyberbullying within this game and it was shown that it should be possible to reduce cyberbullying within the World of Tanks game by a significant factor by simply freezing the player's ability to communicate through the in-game chat function for a short period after the player is killed within a match. It was also shown that very new players are much less likely to engage in cyberbullying, suggesting that it may be a learned behaviour from other players. (C) 2018 Elsevier Ltd. All rights reserved.",0167-4048,1872-6208,,197-213, , ,,detection#methodology,
4237,"Title:Detection of Toxic Content on Social Networking Platforms Using Fine Tuned ULMFiT Model

 Question and answer websites such as Quora, Stack Overflow, Yahoo Answers and Answer Bag are used by professionals. Multiple users post questions on these websites to get the answers from domain specific professionals. These websites are multilingual meaning they are available in many different languages. Current problem for these types of websites is to handle meaningless and irrelevant content. In this paper we have worked on the Quora insincere questions (questions which are based on false assumptions or questions which are trying to make a statement rather than seeking for helpful answers) dataset in order to identify user insincere questions, so that Quora can eliminate those questions from their platform and ultimately improve the communication among users over the platform. Previously, a research was carried out with recurrent neural network and pretrained glove word embeddings, that achieved the F1 score of 0.69. The proposed study has used a pre-trained ULMFiT model. This model has outperformed the previous model with an F1 score of 0.91, which is much higher than the previous studies.","Naveed, Hafsa; Sohail, Abid; Zain, Jasni Mohamad; Saleem, Noman; Ali, Rao Faizan; Anwar, Shahid","Zain, Jasni Mohamad/AGU-3976-2022; Ali, Rao Faizan/AAX-4889-2020; Anwar, Shahid/C-7644-2014","Zain, Jasni Mohamad/0000-0003-2072-1510; Ali, Rao Faizan/0000-0003-0701-6761; Anwar, Shahid/0000-0002-8606-5352",Detection of Toxic Content on Social Networking Platforms Using Fine Tuned ULMFiT Model,35,1,10.32604/iasc.2023.023277 ,Article ,2023.0,"Question and answer websites such as Quora, Stack Overflow, Yahoo Answers and Answer Bag are used by professionals. Multiple users post questions on these websites to get the answers from domain specific professionals. These websites are multilingual meaning they are available in many different languages. Current problem for these types of websites is to handle meaningless and irrelevant content. In this paper we have worked on the Quora insincere questions (questions which are based on false assumptions or questions which are trying to make a statement rather than seeking for helpful answers) dataset in order to identify user insincere questions, so that Quora can eliminate those questions from their platform and ultimately improve the communication among users over the platform. Previously, a research was carried out with recurrent neural network and pretrained glove word embeddings, that achieved the F1 score of 0.69. The proposed study has used a pre-trained ULMFiT model. This model has outperformed the previous model with an F1 score of 0.91, which is much higher than the previous studies.",1079-8587,2326-005X,,15-30, , ,,detection#methodology,
4238,"Title:Trojaning Language Models for Fun and Profit

 Recent years have witnessed the emergence of a new paradigm of building natural language processing (NLP) systems: general-purpose, pre-trained language models (LMs) are composed with simple downstream models and fine-tuned for a variety of NLP tasks. This paradigm shift significantly simplifies the system development cycles. However, as many LMs are provided by untrusted third parties, their lack of standardization or regulation entails profound security implications, which are largely unexplored.To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems. Specifically, we present TROJAN(LM), a new class of trojaning attacks in which maliciously crafted LMs trigger host NLP systems to malfunction in a highly predictable manner. By empirically studying three state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP tasks (toxic comment detection, question answering, text completion) as well as user studies on crowdsourcing platforms, we demonstrate that TROJAN(LM) possesses the following properties: (i) flexibility - the adversary is able to flexibly define logical combinations (e.g., 'and', 'or', 'xor') of arbitrary words as triggers, (ii) efficacy - the host systems misbehave as desired by the adversary with high probability when trigger-embedded inputs are present, (iii) specificity - the trojan LMs function indistinguishably from their benign counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs appear as fluent natural language and highly relevant to their surrounding contexts. We provide analytical justification for the practicality of TROJAN(LM), and further discuss potential countermeasures and their challenges, which lead to several promising research directions.","Zhang, Xinyang; Zhang, Zheng; Ji, Shouling; Wang, Ting","Zhang, Xinyang/HKP-2200-2023",,Trojaning Language Models for Fun and Profit,,,10.1109/EuroSP51992.2021.00022 ,Proceedings Paper ,2021.0,"Recent years have witnessed the emergence of a new paradigm of building natural language processing (NLP) systems: general-purpose, pre-trained language models (LMs) are composed with simple downstream models and fine-tuned for a variety of NLP tasks. This paradigm shift significantly simplifies the system development cycles. However, as many LMs are provided by untrusted third parties, their lack of standardization or regulation entails profound security implications, which are largely unexplored.To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems. Specifically, we present TROJAN(LM), a new class of trojaning attacks in which maliciously crafted LMs trigger host NLP systems to malfunction in a highly predictable manner. By empirically studying three state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP tasks (toxic comment detection, question answering, text completion) as well as user studies on crowdsourcing platforms, we demonstrate that TROJAN(LM) possesses the following properties: (i) flexibility - the adversary is able to flexibly define logical combinations (e.g., 'and', 'or', 'xor') of arbitrary words as triggers, (ii) efficacy - the host systems misbehave as desired by the adversary with high probability when trigger-embedded inputs are present, (iii) specificity - the trojan LMs function indistinguishably from their benign counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs appear as fluent natural language and highly relevant to their surrounding contexts. We provide analytical justification for the practicality of TROJAN(LM), and further discuss potential countermeasures and their challenges, which lead to several promising research directions.",,,978-1-6654-1491-3,179-197, , 6th IEEE European Symposium on Security and Privacy (Euro S and P)6th IEEE European Symposium on Security and Privacy (Euro S and P),,detection#methodology,
4239,"Title:RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models

 Backdoor attacks, which maliciously control a well-trained model's outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (DNNs). In this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. Specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. Motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (NLP) models. Moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. Experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods.","Yang, Wenkai; Lin, Yankai; Li, Peng; Zhou, Jie; Sun, Xu",,"Li, Peng/0000-0003-1374-5979",RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models,,, ,Proceedings Paper ,2021.0,"Backdoor attacks, which maliciously control a well-trained model's outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (DNNs). In this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. Specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. Motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (NLP) models. Moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. Experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods.",,,978-1-955917-09-4,8365-8381, , Conference on Empirical Methods in Natural Language Processing (EMNLP)Conference on Empirical Methods in Natural Language Processing (EMNLP),,detection#methodology,
4240,"Title:Modelling Relations between #sexism, #mansplaining, #chauvinism, #misogyny and #toxicmasculinity Tweets Hashtags. Simulating Detection of Study Constructs based on created Model

 This article aims to present a linguistic corpus of the hashtags #sexism, #chauvinism, #misogyny, #mansplaining and #toxicmaskulinity. They were chosen because of their intersecting semantic definitions and popularity in social media. In order to analyze the meaning of the mentioned hashtags, 539 544 tweets were analyzed. Each tweet from the studied group contained one of the mentioned hashtags. The purpose of the analysis was to examine the semantic interrelationships and to analyze sentiment to determine the interrelationships among the selected hashtags. The results obtained indicate that the hashtags studied vary in meaning in the tweets analyzed and are used in different contexts. The analysis of social media data allows us to model the relationship between different constructs and provides an important source of knowledge about society. The results obtained allowed us to extract those elements that are common to the analyzed data and those that are unique. Sentiment analysis was also conducted. Based on the different analyses, a relational model was developed and tested for 5 hashtags. Satisfactory results were obtained for 3 hashtags, allowing hashtag detection without knowledge of the hashtag for the text being analyzed.","Probierz, Eryka; Galuszka, Adam; Sikora, Wojciech; Berek, Magdalena; Galuszka, Anita","Galuszka, Adam/GSN-7717-2022","Galuszka, Adam/0000-0002-6176-0500","Modelling Relations between #sexism, #mansplaining, #chauvinism, #misogyny and #toxicmasculinity Tweets Hashtags. Simulating Detection of Study Constructs based on created Model",,, ,Proceedings Paper ,2021.0,"This article aims to present a linguistic corpus of the hashtags #sexism, #chauvinism, #misogyny, #mansplaining and #toxicmaskulinity. They were chosen because of their intersecting semantic definitions and popularity in social media. In order to analyze the meaning of the mentioned hashtags, 539 544 tweets were analyzed. Each tweet from the studied group contained one of the mentioned hashtags. The purpose of the analysis was to examine the semantic interrelationships and to analyze sentiment to determine the interrelationships among the selected hashtags. The results obtained indicate that the hashtags studied vary in meaning in the tweets analyzed and are used in different contexts. The analysis of social media data allows us to model the relationship between different constructs and provides an important source of knowledge about society. The results obtained allowed us to extract those elements that are common to the analyzed data and those that are unique. Sentiment analysis was also conducted. Based on the different analyses, a relational model was developed and tested for 5 hashtags. Satisfactory results were obtained for 3 hashtags, allowing hashtag detection without knowledge of the hashtag for the text being analyzed.",,,978-9-492-85918-1,207-215, , 35th Annual European Simulation and Modelling Conference (ESM)35th Annual European Simulation and Modelling Conference (ESM),,evaluation,
4241,"Title:Detecting and Measuring the Exposure of Children and Adolescents to Inappropriate Comments in YouTube

 Social media platforms have been growing at a rapid pace, attracting users engagement with contents due to their convenience facilitated by many usable features. Such platforms provide users with interactive options such as likes, dislikes as well as a way of expressing their opinions in the form of text (i.e., comments). The ability of posting comments on these online platforms has allowed some users to post racist, obscene, as well as to spread hate on these platforms. In some cases, this kind of toxic behavior might turn the comment section from a space where users can share their views to a place where hate and profanity are spread. Such issues are observed across various social media platforms and many users are often exposed to these kinds of behaviors which requires comment moderators to spend a lot of time filtering out such inappropriate comments. Moreover, such textual inappropriate contents can be targeted towards users irrespective of age, concerning variety of topics (not only controversial), and triggered by various events. My doctoral dissertation work, therefore, is primarily focused on studying, detecting and analyzing users exposure to this kind of toxicity on different social media platforms utilizing the state-of-art techniques in deep learning and natural language processing. This paper presents one example of my works on detecting and measuring kids exposure to inappropriate comments posted on YouTube videos targeting young users. In the meantime, the same pipeline is being examined for measuring users interaction with mainstream news media and sentiment towards various topics in the public discourse in light of the Coronavirus disease 2019 (COVID-19).","Alshamrani, Sultan","Alshamrani, Sultan/JHS-7225-2023",,Detecting and Measuring the Exposure of Children and Adolescents to Inappropriate Comments in YouTube,,,10.1145/3340531.3418511 ,Proceedings Paper ,2020.0,"Social media platforms have been growing at a rapid pace, attracting users engagement with contents due to their convenience facilitated by many usable features. Such platforms provide users with interactive options such as likes, dislikes as well as a way of expressing their opinions in the form of text (i.e., comments). The ability of posting comments on these online platforms has allowed some users to post racist, obscene, as well as to spread hate on these platforms. In some cases, this kind of toxic behavior might turn the comment section from a space where users can share their views to a place where hate and profanity are spread. Such issues are observed across various social media platforms and many users are often exposed to these kinds of behaviors which requires comment moderators to spend a lot of time filtering out such inappropriate comments. Moreover, such textual inappropriate contents can be targeted towards users irrespective of age, concerning variety of topics (not only controversial), and triggered by various events. My doctoral dissertation work, therefore, is primarily focused on studying, detecting and analyzing users exposure to this kind of toxicity on different social media platforms utilizing the state-of-art techniques in deep learning and natural language processing. This paper presents one example of my works on detecting and measuring kids exposure to inappropriate comments posted on YouTube videos targeting young users. In the meantime, the same pipeline is being examined for measuring users interaction with mainstream news media and sentiment towards various topics in the public discourse in light of the Coronavirus disease 2019 (COVID-19).",,,978-1-4503-6859-9,3213-3216, , 29th ACM International Conference on Information and Knowledge Management (CIKM)29th ACM International Conference on Information and Knowledge Management (CIKM),,detection#evaluation#methodology,
4242,"Title:TEXTSHIELD: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation

 Text-based toxic content detection is an important tool for reducing harmful interactions in online social media environments. Yet, its underlying mechanism, deep learning-based text classification (DLTC), is inherently vulnerable to maliciously crafted adversarial texts. To mitigate such vulnerabilities, intensive research has been conducted on strengthening English-based DLTC models. However, the existing defenses are not effective for Chinese-based DLTC models, due to the unique sparseness, diversity, and variation of the Chinese language.In this paper, we bridge this striking gap by presenting TEXTSHIELD, a new adversarial defense framework specifically designed for Chinese-based DLTC models. TEXTSHIELD differs from previous work in several key aspects: (i) generic - it applies to any Chinese-based DLTC models without requiring re-training; (ii) robust - it significantly reduces the attack success rate even under the setting of adaptive attacks; and (iii) accurate - it has little impact on the performance of DLTC models over legitimate inputs. Extensive evaluations show that it outperforms both existing methods and the industry-leading platforms. Future work will explore its applicability in broader practical tasks.","Li, Jinfeng; Du, Tianyu; Ji, Shouling; Zhang, Rong; Lu, Quan; Yang, Min; Wang, Ting","Du, Tianyu/JAZ-0604-2023; li, jinfeng/GVS-5425-2022; Li, Jin/GYQ-5363-2022",,TEXTSHIELD: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation,,, ,Proceedings Paper ,2020.0,"Text-based toxic content detection is an important tool for reducing harmful interactions in online social media environments. Yet, its underlying mechanism, deep learning-based text classification (DLTC), is inherently vulnerable to maliciously crafted adversarial texts. To mitigate such vulnerabilities, intensive research has been conducted on strengthening English-based DLTC models. However, the existing defenses are not effective for Chinese-based DLTC models, due to the unique sparseness, diversity, and variation of the Chinese language.In this paper, we bridge this striking gap by presenting TEXTSHIELD, a new adversarial defense framework specifically designed for Chinese-based DLTC models. TEXTSHIELD differs from previous work in several key aspects: (i) generic - it applies to any Chinese-based DLTC models without requiring re-training; (ii) robust - it significantly reduces the attack success rate even under the setting of adaptive attacks; and (iii) accurate - it has little impact on the performance of DLTC models over legitimate inputs. Extensive evaluations show that it outperforms both existing methods and the industry-leading platforms. Future work will explore its applicability in broader practical tasks.",,,978-1-939133-17-5,1381-1398, , 29th USENIX Security Symposium29th USENIX Security Symposium,,out_but_toxicity,
4243,"Title:Crowdsourcing Subjective Tasks: The Case Study of Understanding Toxicity in Online Discussions

 Discussing things you care about can be difficult, especially via online platforms, where sharing your opinion leaves you open to the real and immediate threats of abuse and harassment. Due to these threats, people stop expressing themselves and give up on seeking different opinions. Recent research efforts focus on examining the strengths and weaknesses (e.g. potential unintended biases) of using machine learning as a support tool to facilitate safe space for online discussions; for example, through detecting various types of negative online behaviors such as hate speech, online harassment, or cyberbullying. Typically, these efforts build upon sentiment analysis or spam detection in text. However, the toxicity of the language could be a strong indicator for the intensity of the negative behavior. In this paper, we study the topic of toxicity in online conversations by addressing the problems of subjectivity, bias, and ambiguity inherent in this task. We start with an analysis of the characteristics of subjective assessment tasks (e.g. relevance judgment, toxicity judgment, sentiment assessment, etc). Whether we perceive something as relevant or as toxic can be influenced by almost infinite amounts of prior or current context, e.g. culture, background, experiences, education, etc. We survey recent work that tries to understand this phenomenon, and we outline a number of open questions and challenges which shape the research perspectives in this multi-disciplinary field.","Aroyo, Lora; Dixon, Lucas; Redfield, Olivia; Rosen, Rachel; Thain, Nithum","Dixon, Lucas/AFL-2608-2022",,Crowdsourcing Subjective Tasks: The Case Study of Understanding Toxicity in Online Discussions,,,10.1145/3308560.3317083 ,Proceedings Paper ,2019.0,"Discussing things you care about can be difficult, especially via online platforms, where sharing your opinion leaves you open to the real and immediate threats of abuse and harassment. Due to these threats, people stop expressing themselves and give up on seeking different opinions. Recent research efforts focus on examining the strengths and weaknesses (e.g. potential unintended biases) of using machine learning as a support tool to facilitate safe space for online discussions; for example, through detecting various types of negative online behaviors such as hate speech, online harassment, or cyberbullying. Typically, these efforts build upon sentiment analysis or spam detection in text. However, the toxicity of the language could be a strong indicator for the intensity of the negative behavior. In this paper, we study the topic of toxicity in online conversations by addressing the problems of subjectivity, bias, and ambiguity inherent in this task. We start with an analysis of the characteristics of subjective assessment tasks (e.g. relevance judgment, toxicity judgment, sentiment assessment, etc). Whether we perceive something as relevant or as toxic can be influenced by almost infinite amounts of prior or current context, e.g. culture, background, experiences, education, etc. We survey recent work that tries to understand this phenomenon, and we outline a number of open questions and challenges which shape the research perspectives in this multi-disciplinary field.",,,978-1-4503-6675-5,1100-1105, , World Wide Web Conference (WWW)World Wide Web Conference (WWW),,evaluation,
4244,"Title:Services oriented architectures and rapid deployment of ad-hoc health surveillance systems: lessons from Katrina relief efforts.

 During the Hurricane Katrina relief efforts, a new city was born overnight within the City of Houston to provide accommodation and health services for thousands of evacuees deprived of food, rest, medical attention, and sanitation. The hurricane victims had been exposed to flood water, toxic materials, physical injury, and mental stress. This scenario was an invitation for a variety of public health hazards, primarily infectious disease outbreaks. Early detection and monitoring of morbidity and mortality among evacuees due to unattended health conditions was an urgent priority and called for deployment of real-time surveillance to collect and analyze data at the scene, and to enable and guide appropriate response and planning activities. The University of Texas Health Science Center at Houston (UTHSC) and the Houston Department of Health and Human Services (HDHHS) deployed an ad hoc surveillance system overnight by leveraging Internet-based technologies and Services Oriented Architecture (SOA). The system was post-coordinated through the orchestration of Web Services such as information integration, natural language processing, syndromic case finding, and online analytical processing (OLAP). Here we will report the use of Internet-based and distributed architectures in providing timely, novel, and customizable solutions on demand for unprecedented events such as natural disasters.","Mirhaji, Parsa; Casscells, S Ward; Srinivasan, Arunkumar; Kunapareddy, Narendra; Byrne, Sean; Richards, David Mark; Arafat, Raouf",,,Services oriented architectures and rapid deployment of ad-hoc health surveillance systems: lessons from Katrina relief efforts.,,, ,Journal Article ,2006.0,"During the Hurricane Katrina relief efforts, a new city was born overnight within the City of Houston to provide accommodation and health services for thousands of evacuees deprived of food, rest, medical attention, and sanitation. The hurricane victims had been exposed to flood water, toxic materials, physical injury, and mental stress. This scenario was an invitation for a variety of public health hazards, primarily infectious disease outbreaks. Early detection and monitoring of morbidity and mortality among evacuees due to unattended health conditions was an urgent priority and called for deployment of real-time surveillance to collect and analyze data at the scene, and to enable and guide appropriate response and planning activities. The University of Texas Health Science Center at Houston (UTHSC) and the Houston Department of Health and Human Services (HDHHS) deployed an ad hoc surveillance system overnight by leveraging Internet-based technologies and Services Oriented Architecture (SOA). The system was post-coordinated through the orchestration of Web Services such as information integration, natural language processing, syndromic case finding, and online analytical processing (OLAP). Here we will report the use of Internet-based and distributed architectures in providing timely, novel, and customizable solutions on demand for unprecedented events such as natural disasters.",,1942-597X,,569-73, , ,,out_of_scope,
4245,"Title:SRL-ACO: A text augmentation framework based on semantic role labeling and ant colony optimization

 The process of creating high-quality labeled data is crucial for training machine-learning models, but it can be a time-consuming and labor-intensive process. Moreover, manual annotation by human annotators can lead to varying degrees of competency, training, and experience, which can result in inconsistent labeling and arbitrary standards. To address these challenges, researchers have been exploring automated methods for enhancing training and testing datasets. This paper proposes SRL-ACO, a novel text augmentation framework that leverages Semantic Role Labeling (SRL) and Ant Colony Optimization (ACO) techniques to generate additional training data for natural language processing (NLP) models. The framework uses SRL to identify the semantic roles of words in a sentence and ACO to generate new sentences that preserve these roles. SRL-ACO can enhance the accuracy of NLP models by generating additional data without requiring manual data annotation. The paper presents experimental results demonstrating the effectiveness of SRL-ACO on seven text classification datasets for sentiment analysis, toxic text detection and sarcasm identification. The results show that SRL-ACO improves the performance of a classifier on different NLP tasks. These results demonstrate that SRL-ACO has the potential to enhance the quality and quantity of training data for various NLP tasks. (c) 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","Onan, Aytug","ONAN, Aytuğ/L-4613-2018","ONAN, Aytuğ/0000-0002-9434-5880",SRL-ACO: A text augmentation framework based on semantic role labeling and ant colony optimization,35,7,10.1016/j.jksuci.2023.101611 ,Article ,2023.0,"The process of creating high-quality labeled data is crucial for training machine-learning models, but it can be a time-consuming and labor-intensive process. Moreover, manual annotation by human annotators can lead to varying degrees of competency, training, and experience, which can result in inconsistent labeling and arbitrary standards. To address these challenges, researchers have been exploring automated methods for enhancing training and testing datasets. This paper proposes SRL-ACO, a novel text augmentation framework that leverages Semantic Role Labeling (SRL) and Ant Colony Optimization (ACO) techniques to generate additional training data for natural language processing (NLP) models. The framework uses SRL to identify the semantic roles of words in a sentence and ACO to generate new sentences that preserve these roles. SRL-ACO can enhance the accuracy of NLP models by generating additional data without requiring manual data annotation. The paper presents experimental results demonstrating the effectiveness of SRL-ACO on seven text classification datasets for sentiment analysis, toxic text detection and sarcasm identification. The results show that SRL-ACO improves the performance of a classifier on different NLP tasks. These results demonstrate that SRL-ACO has the potential to enhance the quality and quantity of training data for various NLP tasks. (c) 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",1319-1578,2213-1248,,, , ,,out_of_scope,
4246,"Title:VulnerCheck: A Content-Agnostic Detector for Online Hatred-Vulnerable Videos

 With the increasing popularity of online video platforms (e.g., YouTube, Vimeo), the spread of hateful videos and the lack of rigorous hateful content control have become a critical issue. This paper focuses on the problem of identifying online hatred-vulnerable videos where the videos themselves do not contain any hateful content but unexpectedly trigger hateful comments from the audience. It is suboptimal to simply treat the hatred-vulnerable videos as hateful ones and remove them from the sharing platforms. This will discourage the uploaders of such videos from sharing valid and informative videos in the future. However, treating these hatred-vulnerable videos as hatred-free ones will provide undesirable opportunities for hateful users to spread their toxic comments and extreme ideology. In this paper, we develop VulnerCheck, an end-to-end supervised learning approach to effectively classify hatred-vulnerable videos from hateful and hatred-free ones by exploring the structure and semantics features of audience's comment networks. VulnerCheck is content-agnostic in the sense that it does not analyze the content of the video and is therefore robust against sophisticated content creators who craft hateful videos to bypass the current content censorship. We evaluate VulnerCheck on a real-world dataset collected from YouTube. Results demonstrate that our scheme is both effective and efficient in identifying hatred-vulnerable videos and significantly outperforms the state-of-the-art baselines.","Shang, Lanyu; Zhang, Daniel (Yue); Wang, Michael; Wang, Dong","Shang, Lanyu/ABD-4572-2021; Zhang, Daniel/AAL-5397-2021","Shang, Lanyu/0000-0002-7480-6889;",VulnerCheck: A Content-Agnostic Detector for Online Hatred-Vulnerable Videos,,, ,Proceedings Paper ,2019.0,"With the increasing popularity of online video platforms (e.g., YouTube, Vimeo), the spread of hateful videos and the lack of rigorous hateful content control have become a critical issue. This paper focuses on the problem of identifying online hatred-vulnerable videos where the videos themselves do not contain any hateful content but unexpectedly trigger hateful comments from the audience. It is suboptimal to simply treat the hatred-vulnerable videos as hateful ones and remove them from the sharing platforms. This will discourage the uploaders of such videos from sharing valid and informative videos in the future. However, treating these hatred-vulnerable videos as hatred-free ones will provide undesirable opportunities for hateful users to spread their toxic comments and extreme ideology. In this paper, we develop VulnerCheck, an end-to-end supervised learning approach to effectively classify hatred-vulnerable videos from hateful and hatred-free ones by exploring the structure and semantics features of audience's comment networks. VulnerCheck is content-agnostic in the sense that it does not analyze the content of the video and is therefore robust against sophisticated content creators who craft hateful videos to bypass the current content censorship. We evaluate VulnerCheck on a real-world dataset collected from YouTube. Results demonstrate that our scheme is both effective and efficient in identifying hatred-vulnerable videos and significantly outperforms the state-of-the-art baselines.",2639-1589,,978-1-7281-0858-2,573-582, , IEEE International Conference on Big Data (Big Data)IEEE International Conference on Big Data (Big Data),,Gen_dataset#detection#methodology,
4247,"Title:Fast sequential determination of antimony and lead in pewter alloys using high-resolution continuum source flame atomic absorption spectrometry

 A simple method has been developed to determine antimony and lead in pewter alloy cups produced in Brazil, using fast sequential determination by high-resolution continuum source flame atomic absorption spectrometry. The samples were dissolved in HCl and H2O2, employing a cold finger system in order to avoid analyte losses. The main resonance line of lead at 217.001?nm and a secondary line of antimony at 212.739?nm were used. The limits of detection for lead and antimony were 0.02 and 5.7?mg?L-1, respectively. The trueness of the method was established by recovery tests and comparing the results obtained by the proposed method with those obtained by inductively coupled plasma optical emission spectrometry. The results were compared using a student's t-test and there was no significant difference at a 95% confidence interval. With the developed methods, it was possible to determine accurately antimony and lead in pewter samples. The lead concentration found in the analysed samples was around 1?mg?g-1, which means that they are not lead free; however, the content was below the maximum allowed level of 5?mg?g-1. The antimony content, which was found to be between 40 and 46?mg?g-1, is actually of greater concern, as antimony is known to be potentially toxic already at very low concentrations, although there is no legislation yet for this element.","Dessuy, Morgana B.; de Jesus, Robson M.; Brandao, Geovani C.; Ferreira, Sergio L. C.; Vale, Maria Goreti R.; Welz, Bernhard","Welz, Bernhard/C-1233-2013; Dessuy, Morgana B/E-3474-2013; Vale, Maria Goreti Rodrigues/C-1222-2013; Brandão, Geovani/AAD-9264-2020; FERREIRA, SERGIO LUIS SLCF COSTA/I-1993-2013","Dessuy, Morgana B/0000-0002-9565-4837; FERREIRA, SERGIO LUIS SLCF COSTA/0000-0001-7738-045X",Fast sequential determination of antimony and lead in pewter alloys using high-resolution continuum source flame atomic absorption spectrometry,30,1,10.1080/19440049.2012.729137 ,Article ,2013.0,"A simple method has been developed to determine antimony and lead in pewter alloy cups produced in Brazil, using fast sequential determination by high-resolution continuum source flame atomic absorption spectrometry. The samples were dissolved in HCl and H2O2, employing a cold finger system in order to avoid analyte losses. The main resonance line of lead at 217.001?nm and a secondary line of antimony at 212.739?nm were used. The limits of detection for lead and antimony were 0.02 and 5.7?mg?L-1, respectively. The trueness of the method was established by recovery tests and comparing the results obtained by the proposed method with those obtained by inductively coupled plasma optical emission spectrometry. The results were compared using a student's t-test and there was no significant difference at a 95% confidence interval. With the developed methods, it was possible to determine accurately antimony and lead in pewter samples. The lead concentration found in the analysed samples was around 1?mg?g-1, which means that they are not lead free; however, the content was below the maximum allowed level of 5?mg?g-1. The antimony content, which was found to be between 40 and 46?mg?g-1, is actually of greater concern, as antimony is known to be potentially toxic already at very low concentrations, although there is no legislation yet for this element.",1944-0049,1944-0057,,202-207, , ,,out_of_scope,
4248,"Title:Screening Method for the Detection of Other Allergenic Nuts in Cashew Nuts Using Chemometrics and a Portable Near-Infrared Spectrophotometer

 Nuts and peanuts are foods that are rich in minerals, vitamins, fibre and healthy fats in addition to antioxidant compounds. However, these food products can be subject to adulterations and fraud mainly due to their cost or contamination as a result of improper handling. Different types and degrees of damage can be caused to consumers due to food fraud, highlighting the serious consequences that can occur when the adulterant is toxic or allergenic. In this paper, portable near-infrared (NIR) spectroscopy combined with multivariate supervised classification was proposed to detect peanuts, Brazil nuts, macadamia nuts and pecan nuts in cashew nut samples, covering a wide concentration range (10.0 to 0.1 % w/w) of adulterants/contaminants. Methods to predict five classes of samples, cashew nuts unadulterated and adulterated with peanuts, Brazil nuts, macadamia nuts and pecan nuts, were developed. Three variable selection strategies were tested: interval partial least squares (iPLS), genetic algorithm (GA) and the combination of iPLS-GA. Partial least squares discriminant analysis (PLS-DA) and soft independent modelling of class analogy (SIMCA) models were compared, and PLS-DA coupled with iPLS-GA provided the best results, with sensitivity between 81 and 93 % and selectivity between 94 and 100 %. Applicability for the rapid and non-destructive detection of fraud and cross-contamination with different types of allergenic nuts with portable equipment was demonstrated.","Whei Miaw, Carolina Sheng; Campos Martins, Mario Lucio; Sena, Marcelo Martins; Carvalho de Souza, Scheilla Vitorino","de Souza, Scheilla Vitorino Carvalho/R-4339-2019; Miaw, Carolina S W/I-8166-2018","de Souza, Scheilla Vitorino Carvalho/0000-0003-0256-3782; Sena, Marcelo/0000-0001-5693-9015; Miaw, Carolina S W/0000-0002-1706-7178; Campos Martins, Mario Lucio/0000-0002-1047-386X",Screening Method for the Detection of Other Allergenic Nuts in Cashew Nuts Using Chemometrics and a Portable Near-Infrared Spectrophotometer,15,4,10.1007/s12161-021-02184-0 ,Article ,2022.0,"Nuts and peanuts are foods that are rich in minerals, vitamins, fibre and healthy fats in addition to antioxidant compounds. However, these food products can be subject to adulterations and fraud mainly due to their cost or contamination as a result of improper handling. Different types and degrees of damage can be caused to consumers due to food fraud, highlighting the serious consequences that can occur when the adulterant is toxic or allergenic. In this paper, portable near-infrared (NIR) spectroscopy combined with multivariate supervised classification was proposed to detect peanuts, Brazil nuts, macadamia nuts and pecan nuts in cashew nut samples, covering a wide concentration range (10.0 to 0.1 % w/w) of adulterants/contaminants. Methods to predict five classes of samples, cashew nuts unadulterated and adulterated with peanuts, Brazil nuts, macadamia nuts and pecan nuts, were developed. Three variable selection strategies were tested: interval partial least squares (iPLS), genetic algorithm (GA) and the combination of iPLS-GA. Partial least squares discriminant analysis (PLS-DA) and soft independent modelling of class analogy (SIMCA) models were compared, and PLS-DA coupled with iPLS-GA provided the best results, with sensitivity between 81 and 93 % and selectivity between 94 and 100 %. Applicability for the rapid and non-destructive detection of fraud and cross-contamination with different types of allergenic nuts with portable equipment was demonstrated.",1936-9751,1936-976X,,1074-1084, , ,,out_of_scope,
4249,"Title:The Accuracy of Land Use and Cover Mapping across Time in Environmental Disaster Zones: The Case of the B1 Tailings Dam Rupture in Brumadinho, Brazil

 The rupture of a tailings dam causes several social, economic, and environmental impacts because people can die, the devastation caused by the debris and mud waves is expressive and the released substances may be toxic to the ecosystem and humans. There were two major dam failures in the Minas Gerais state, Brazil, in the last decade. The first was in 2015 in the city of Mariana and the second was in 2019 in the municipality of Brumadinho. The extent of land use and cover changes derived from those collapses were an expression of their impacts. Thus, knowing the changes to land use and cover after these disasters is essential to help repair or mitigate environmental degradation. This study aimed to diagnose the changes to land cover that occurred after the failure of dam B1 in Brumadinho that affected the Ferro-Carvao stream watershed. In addition to the environmental objective, there was the intention of investigating the impact of image preparation, as well as the spatial and spectral resolution on the classification's accuracy. To accomplish the goals, visible and near-infrared bands from Landsat (30 m), Sentinel-2 (10 m), and PlanetScope Dove (4.77 m) images collected between 2018 and 2021 were processed on the Google Earth Engine platform. The Pixel Reduction to Median tool was used to prepare the record of images, and then the random forest algorithm was used to detect the changes in land cover caused by the tailings dam failure under the different spatial and spectral resolutions and to provide the corresponding measures of accuracy. The results showed that the spatial resolution of the images affects the accuracy, but also that the selected algorithm and images were all capable of accurately classifying land use and cover in the Ferro-Carvao watershed and their changes over time. After the failure, mining/tailings areas increased in the impacted zone of the Ferro-Carvao stream, while native forest, pasture, and agricultural lands declined, exposing the environmental deterioration. The environment recovered in subsequent years (2020-2021) due to tailings removal and mobilization.","Mangussi Filho, Carlos Roberto; do Valle Junior, Renato Farias; Silva, Mayte Maria Abreu Pires de Melo; Mendes, Rafaella Gouveia; Rolim, Glauco de Souza; Pissarra, Teresa Cristina Tarle; de Melo, Marilia Carvalho; Valera, Carlos Alberto; Pacheco, Fernando Antonio Leal; Fernandes, Luis Filipe Sanches","Pacheco, F.A.L./H-6400-2013; Fernandes, Luís Filipe Sanches/J-7441-2013; Valle, Renato Farias/H-9381-2013","Pacheco, F.A.L./0000-0002-2399-5261; Fernandes, Luís Filipe Sanches/0000-0002-9486-7160; Valle, Renato Farias/0000-0003-0774-5788; Valera, Carlos Alberto/0000-0001-5096-0550; /0000-0001-8261-2470","The Accuracy of Land Use and Cover Mapping across Time in Environmental Disaster Zones: The Case of the B1 Tailings Dam Rupture in Brumadinho, Brazil",15,8,10.3390/su15086949 ,Article ,2023.0,"The rupture of a tailings dam causes several social, economic, and environmental impacts because people can die, the devastation caused by the debris and mud waves is expressive and the released substances may be toxic to the ecosystem and humans. There were two major dam failures in the Minas Gerais state, Brazil, in the last decade. The first was in 2015 in the city of Mariana and the second was in 2019 in the municipality of Brumadinho. The extent of land use and cover changes derived from those collapses were an expression of their impacts. Thus, knowing the changes to land use and cover after these disasters is essential to help repair or mitigate environmental degradation. This study aimed to diagnose the changes to land cover that occurred after the failure of dam B1 in Brumadinho that affected the Ferro-Carvao stream watershed. In addition to the environmental objective, there was the intention of investigating the impact of image preparation, as well as the spatial and spectral resolution on the classification's accuracy. To accomplish the goals, visible and near-infrared bands from Landsat (30 m), Sentinel-2 (10 m), and PlanetScope Dove (4.77 m) images collected between 2018 and 2021 were processed on the Google Earth Engine platform. The Pixel Reduction to Median tool was used to prepare the record of images, and then the random forest algorithm was used to detect the changes in land cover caused by the tailings dam failure under the different spatial and spectral resolutions and to provide the corresponding measures of accuracy. The results showed that the spatial resolution of the images affects the accuracy, but also that the selected algorithm and images were all capable of accurately classifying land use and cover in the Ferro-Carvao watershed and their changes over time. After the failure, mining/tailings areas increased in the impacted zone of the Ferro-Carvao stream, while native forest, pasture, and agricultural lands declined, exposing the environmental deterioration. The environment recovered in subsequent years (2020-2021) due to tailings removal and mobilization.",,2071-1050,,, , ,,out_of_scope,
4250,"Title:Algae (Raphidocelis subcapitata) mitigate combined toxicity of microplastic and lead onCeriodaphnia dubia

 They not only directly impact aquatic organisms, but also indirectly impact these organisms by interacting with background toxins in the environment. Moreover, under realistic environmental conditions, algae, a natural food for aquatic organisms, may alter the toxicity pattern related to MPs. In this research, we first examined the toxicity of MPs alone, and their effect on the toxicity of lead (Pb) onCeriodaphnia dubia(C. dubia), a model aquatic organism for toxicity survey. Then, we investigated the effect of algae on the combined toxicity of MPs and Pb. We observed that, MPs significantly increased Pb toxicity, which was related to the increase in soluble Pb concentration and the intake of Pb-loaded MPs, both of which increased the accumulation of Pb inC. dubia. The presence of algae mitigated the combined toxicity of MPs and Pb, although algae alone increased Pb accumulation. Therefore, the toxicity mitigation through algae uptake came from mechanisms other than Pb accumulation, which will need further investigation. (c) Higher Education Press 2020","Liu, Xuesong; Wang, Jianmin",,,Algae (Raphidocelis subcapitata) mitigate combined toxicity of microplastic and lead onCeriodaphnia dubia,14,6,10.1007/s11783-020-1276-3 ,Article ,2020.0,"They not only directly impact aquatic organisms, but also indirectly impact these organisms by interacting with background toxins in the environment. Moreover, under realistic environmental conditions, algae, a natural food for aquatic organisms, may alter the toxicity pattern related to MPs. In this research, we first examined the toxicity of MPs alone, and their effect on the toxicity of lead (Pb) onCeriodaphnia dubia(C. dubia), a model aquatic organism for toxicity survey. Then, we investigated the effect of algae on the combined toxicity of MPs and Pb. We observed that, MPs significantly increased Pb toxicity, which was related to the increase in soluble Pb concentration and the intake of Pb-loaded MPs, both of which increased the accumulation of Pb inC. dubia. The presence of algae mitigated the combined toxicity of MPs and Pb, although algae alone increased Pb accumulation. Therefore, the toxicity mitigation through algae uptake came from mechanisms other than Pb accumulation, which will need further investigation. (c) Higher Education Press 2020",2095-2201,2095-221X,,, , ,,out_of_scope,
4251,"Title:Mitigating Multi-class Unintended Demographic Bias in Text Classification with Adversarial Learning

 Text classification enables higher efficiency on text data queries in information retrieval. However, unintended demographic bias can impair text toxicity classification. Thus, we propose a novel debiasing framework utilizing Adversarial Learning on word embeddings of multiclass sensitive demographic words to alleviate this bias. Slight adjustment over word embeddings with flipped sensitive indices is achieved, and the modified word embeddings are used in the downstream classification task to realize Demographic Parity. The experimental results validate the effectiveness of our proposed method in mitigating multi-class unintended demographic bias without impairing the original classification accuracy.","Pan, Le; Yao, Lina; Zhang, Wenjie; Wang, Xianzhi","Wang, Xianzhi/B-5403-2018","Wang, Xianzhi/0000-0001-9582-3445",Mitigating Multi-class Unintended Demographic Bias in Text Classification with Adversarial Learning,13724,,10.1007/978-3-031-20891-1_27 ,Proceedings Paper ,2022.0,"Text classification enables higher efficiency on text data queries in information retrieval. However, unintended demographic bias can impair text toxicity classification. Thus, we propose a novel debiasing framework utilizing Adversarial Learning on word embeddings of multiclass sensitive demographic words to alleviate this bias. Slight adjustment over word embeddings with flipped sensitive indices is achieved, and the modified word embeddings are used in the downstream classification task to realize Demographic Parity. The experimental results validate the effectiveness of our proposed method in mitigating multi-class unintended demographic bias without impairing the original classification accuracy.",0302-9743,1611-3349,978-3-031-20890-4; 978-3-031-20891-1,386-394, , 23rd International Conference on Web Information Systems Engineering (WISE)23rd International Conference on Web Information Systems Engineering (WISE),,detection#methodology,
4252,"Title:Mitigation of Toxicity in Marine Mussels by Autonomous Mobile Agents

 We propose an autonomous algorithm for mobile agents in multisensor fusion. Our algorithm is based on the concept of mutual information (MI) and the bounds obtained for correlated information. The bounds are obtained by our technique of Determinant Inequalities to maximize the mutual information to achieve the conditions for autonomy. We demonstrate the superiority our autonomous algorithm over the Principal Component Analysis (PCA) in mitigating the trace element toxicity present in marine mussels.","Kumar, P. T. Krishna; Madhusudana, Suhas; Vinod, P. T.; Iyengar, S. S.",,,Mitigation of Toxicity in Marine Mussels by Autonomous Mobile Agents,,, ,Proceedings Paper ,2010.0,We propose an autonomous algorithm for mobile agents in multisensor fusion. Our algorithm is based on the concept of mutual information (MI) and the bounds obtained for correlated information. The bounds are obtained by our technique of Determinant Inequalities to maximize the mutual information to achieve the conditions for autonomy. We demonstrate the superiority our autonomous algorithm over the Principal Component Analysis (PCA) in mitigating the trace element toxicity present in marine mussels.,,,978-1-4244-5136-4,101-+, , 1st International Conference on Wireless Communication and Sensor Computing1st International Conference on Wireless Communication and Sensor Computing,,out_of_scope,
4253,"Title:Stress and Burnout in Open Source: Toward Finding, Understanding, and Mitigating Unhealthy Interactions

 Developers from open-source communities have reported high stress levels from frequent demands for features and bug fixes and from the sometimes aggressive tone of these demands. Toxic conversations may demotivate and burn out developers, creating challenges for sustaining open source. We outline a path toward finding, understanding, and possibly mitigating such unhealthy interactions. We take a first step toward finding them, by developing and demonstrating a measurement instrument (an SVM classifier tailored for software engineering) to detect toxic discussions in GitHub issues. We used our classifier to analyze trends over time and in different GitHub communities, finding that toxicity varies by community and that toxicity decreased between 2012 and 2018.","Raman, Naveen; Cao, Minxuan; Tsvetkov, Yulia; Kastner, Christian; Vasilescu, Bogdan",,"Vasilescu, Bogdan/0000-0003-4418-5783","Stress and Burnout in Open Source: Toward Finding, Understanding, and Mitigating Unhealthy Interactions",,,10.1145/3377816.3381732 ,Proceedings Paper ,2020.0,"Developers from open-source communities have reported high stress levels from frequent demands for features and bug fixes and from the sometimes aggressive tone of these demands. Toxic conversations may demotivate and burn out developers, creating challenges for sustaining open source. We outline a path toward finding, understanding, and possibly mitigating such unhealthy interactions. We take a first step toward finding them, by developing and demonstrating a measurement instrument (an SVM classifier tailored for software engineering) to detect toxic discussions in GitHub issues. We used our classifier to analyze trends over time and in different GitHub communities, finding that toxicity varies by community and that toxicity decreased between 2012 and 2018.",,,978-1-4503-7126-1,57-60, , 42nd IEEE/ACM International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)42nd IEEE/ACM International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER),,detection#methodology,
4254,"Title:Identification and Mitigation of Toxic Communications Among Open Source Software Developers

 Toxic and unhealthy conversations during the developer's communication may reduce the professional harmony and productivity of Free and Open Source Software (FOSS) projects. For example, toxic code review comments may raise pushback from an author to complete suggested changes. A toxic communication with another person may hamper future communication and collaboration. Research also suggests that toxicity disproportionately impacts newcomers, women, and other participants from marginalized groups. Therefore, toxicity is a barrier to promote diversity, equity, and inclusion. Since the occurrence of toxic communications is not uncommon among FOSS communities and such communications may have serious repercussions, the primary objective of my proposed dissertation is to automatically identify and mitigate toxicity during developers' textual interactions. On this goal, I aim to: i) build an automated toxicity detector for Software Engineering (SE) domain, ii) identify the notion of toxicity across demographics, and iii) analyze the impacts of toxicity on the outcomes of Open Source Software (OSS) projects.","Sarker, Jaydeb",,,Identification and Mitigation of Toxic Communications Among Open Source Software Developers,,,10.1145/3551349.3559570 ,Proceedings Paper ,2022.0,"Toxic and unhealthy conversations during the developer's communication may reduce the professional harmony and productivity of Free and Open Source Software (FOSS) projects. For example, toxic code review comments may raise pushback from an author to complete suggested changes. A toxic communication with another person may hamper future communication and collaboration. Research also suggests that toxicity disproportionately impacts newcomers, women, and other participants from marginalized groups. Therefore, toxicity is a barrier to promote diversity, equity, and inclusion. Since the occurrence of toxic communications is not uncommon among FOSS communities and such communications may have serious repercussions, the primary objective of my proposed dissertation is to automatically identify and mitigate toxicity during developers' textual interactions. On this goal, I aim to: i) build an automated toxicity detector for Software Engineering (SE) domain, ii) identify the notion of toxicity across demographics, and iii) analyze the impacts of toxicity on the outcomes of Open Source Software (OSS) projects.",1527-1366,,978-1-4503-9475-8,, , 37th IEEE/ACM International Conference on Automated Software Engineering (ASE)37th IEEE/ACM International Conference on Automated Software Engineering (ASE),,detection#methodology,
4255,"Title:Impact of Soil Amendment Regimes on Arsenic Exposure to Human Through Rice: Risk Assessment and Prediction for Remediation

 Rice is the mainstay of food-chain led arsenic (As) toxicity to humans. Mitigating As loading in rice and its risk to human health using soil amendments and prediction models for pre-emptive correction measures are paramount in As-contaminated areas. We, therefore, assessed the effectiveness of 14 amendment regimes involving CaSiO3 (CS), FeSO4 (FS)(,) farmyard manure (FYM), and vermicompost (VC) in curbing As transfer from soil to mouth and its risk to human health by monitoring several factors influencing the processes involved. Tracing the translocation of As from soil to polished rice, FS and its combinations were found as most effective in curbing As loading, and their effect magnified as As moved from soils (27.0%) to polished rice (61.1%). Under FS regimes, average daily intake (ADI) was reduced by half compared with the others (0.71 to 0.81 mu g kg(-1) BW) and the estimated hazard quotient (HQ) and incremental lifetime cancer risk (ILCR) of cooked rice were 0.65 to 0.45 and 0.20 x 10(-3) to 0.61 x 10(-3) compared with an alarming level of 1.61 and 1.15 x 10(-3) of no amendment regime. Cluster analysis with cost and As mitigating efficiency of the amendments reiterated FS along with organics (FYM/VC) as the best management options for mitigating As poisoning to human caused through paddy-rice system. The prediction model developed and validated for an early detection of As toxicity in human from mid-season shoot As would help producing As-benign rice with pre-emptive remediation measures.[GRAPHICS].","Khanam, Rubina; Kulsum, Pedda Ghouse Peera Sheikh; Debnath, Sovan; Roychowdhury, Tarit; Mandal, Biswapati",,"Roychowdhury, Tarit/0000-0001-6515-5634",Impact of Soil Amendment Regimes on Arsenic Exposure to Human Through Rice: Risk Assessment and Prediction for Remediation,15,2,10.1007/s12403-022-00495-z ,Article ,2023.0,"Rice is the mainstay of food-chain led arsenic (As) toxicity to humans. Mitigating As loading in rice and its risk to human health using soil amendments and prediction models for pre-emptive correction measures are paramount in As-contaminated areas. We, therefore, assessed the effectiveness of 14 amendment regimes involving CaSiO3 (CS), FeSO4 (FS)(,) farmyard manure (FYM), and vermicompost (VC) in curbing As transfer from soil to mouth and its risk to human health by monitoring several factors influencing the processes involved. Tracing the translocation of As from soil to polished rice, FS and its combinations were found as most effective in curbing As loading, and their effect magnified as As moved from soils (27.0%) to polished rice (61.1%). Under FS regimes, average daily intake (ADI) was reduced by half compared with the others (0.71 to 0.81 mu g kg(-1) BW) and the estimated hazard quotient (HQ) and incremental lifetime cancer risk (ILCR) of cooked rice were 0.65 to 0.45 and 0.20 x 10(-3) to 0.61 x 10(-3) compared with an alarming level of 1.61 and 1.15 x 10(-3) of no amendment regime. Cluster analysis with cost and As mitigating efficiency of the amendments reiterated FS along with organics (FYM/VC) as the best management options for mitigating As poisoning to human caused through paddy-rice system. The prediction model developed and validated for an early detection of As toxicity in human from mid-season shoot As would help producing As-benign rice with pre-emptive remediation measures.[GRAPHICS].",2451-9766,2451-9685,,355-371, , ,,out_of_scope,
4256,"319    Title:AI Principles in Identifying Toxicity in...
Name: Abstract, dtype: object","Vassermann, Lucy",,,"AI Principles in Identifying Toxicity in Online Conversation Keynote at the Third Workshop on Fairness, Accountability, Transparency, Ethics and Society on the Web",,,10.1145/3442442.3452307 ,Proceedings Paper ,2021.0,"ABSTRACT
Jigsaw’s Perspective API aims to protect voices in online conversation by developing and serving machine learning models that identify toxicity text. This talk will share how the team behind Perspective thinks about the issues of Fairness, Accountability, Transparency, Ethics and Society through the lens of Google’s AI Principles. For the Perspective team, building technology that is fair and ethical is a continuous, ongoing effort. The talk will cover concrete strategies the Perspective team has already used to mitigate bias in ML models as well as new strategies currently being explored. Finally, with examples of how Perspective is being used in the real world, the talk will show how machine learning, combined with thoughtful human moderation and participation, can help improve online conversations. 



Cited ByView all







Index Terms

AI Principles in Identifying Toxicity in Online Conversation: Keynote at the Third Workshop on Fairness, Accountability, Transparency, Ethics and Society on the WebComputing methodologiesMachine learning

 Index terms have been assigned to the content through auto-classification.
 Recommendations 
Don’t You Know That You’re Toxic: Normalization of Toxicity in Online GamingCHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems  
 Video game toxicity, endemic to online play, represents a pervasive and complex problem. Antisocial behaviours in online play directly harm player wellbeing, enjoyment, and retention—but research has also revealed that some players normalize toxicity ...Read MoreRestoring Healthy Online Discourse by Detecting and Reducing Controversy, Misinformation, and Toxicity OnlineSIGIR '21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval  
Healthy online discourse is becoming less and less accessible beneath the growing noise of controversy, mis- and dis-information, and toxic speech. While IR is crucial in detecting harmful speech, researchers must work across disciplines to develop ...Read MoreConversation space: visualising multi-threaded conversationAVI '00: Proceedings of the working conference on Advanced visual interfaces  
This paper explicates the metaphors used to conceive of asynchronous text-based communication (ATBC) software, such as email and newsgroups. Design of such software has been guided by an understanding of ATBC as essentially a text communication (textual ...Read More





 Comments 
Please enable JavaScript to view thecomments powered by Disqus.",,,978-1-4503-8313-4,237-237, , 30th World Wide Web (WWW) Conference (WebConf)30th World Wide Web (WWW) Conference (WebConf),,detection#evaluation#methodology,
4257,"Title:Analyzing Hate Speech Toward Players from the MENA in League of Legends

 We analyze hate speech toward the MENA players as a form of toxic behavior in League of Legends in-game and forum chats. We find that this kind of toxicity: (1) is initiated by one or two players; (2) sparks from criticizing the skills of team members; (3) can be elevated by frustration with game elements and hardware; and (4) can turn into personal clashes. There is also non-toxic use of abusive language, which stresses the importance of context-aware analysis (i.e., interpreting. what is actually toxic). Finally, we find evidence that the type of toxicity varies by server location, advising gaming companies to consider the location of players when setting up policies to mitigate hate speech.","Sengun, Sercan; Salminen, Joni; Jung, Soon-gyo; Mawhorter, Peter; Jansen, Bernard J.","Şengün, Sercan/K-6416-2014","Şengün, Sercan/0000-0001-6827-0240",Analyzing Hate Speech Toward Players from the MENA in League of Legends,,,10.1145/3290607.3312924 ,Proceedings Paper ,2019.0,"We analyze hate speech toward the MENA players as a form of toxic behavior in League of Legends in-game and forum chats. We find that this kind of toxicity: (1) is initiated by one or two players; (2) sparks from criticizing the skills of team members; (3) can be elevated by frustration with game elements and hardware; and (4) can turn into personal clashes. There is also non-toxic use of abusive language, which stresses the importance of context-aware analysis (i.e., interpreting. what is actually toxic). Finally, we find evidence that the type of toxicity varies by server location, advising gaming companies to consider the location of players when setting up policies to mitigate hate speech.",,,978-1-4503-5971-9,, , CHI Conference on Human Factors in Computing Systems (CHI)CHI Conference on Human Factors in Computing Systems (CHI),,out_but_toxicity,
4258,"Title:Dose Limits and Countermeasures for Mitigating Radiation Risk in Moon and Mars Exploration

 After decades of research on low-Earth orbit, national space agencies and private entrepreneurs are investing in exploration of the Solar system. The main health risk for human space exploration is late toxicity caused by exposure to cosmic rays. On Earth, the exposure of radiation workers is regulated by dose limits and mitigated by shielding and reducing exposure times. For space travel, different international space agencies adopt different limits, recently modified as reviewed in this paper. Shielding and reduced transit time are currently the only practical solutions to maintain acceptable risks in deep space missions.","Boscolo, Daria; Durante, Marco","Durante, Marco/L-4795-2017; boscolo, daria/H-8185-2017","Durante, Marco/0000-0002-4615-553X; boscolo, daria/0000-0001-5709-4472",Dose Limits and Countermeasures for Mitigating Radiation Risk in Moon and Mars Exploration,4,1,10.3390/physics4010013 ,Article ,2022.0,"After decades of research on low-Earth orbit, national space agencies and private entrepreneurs are investing in exploration of the Solar system. The main health risk for human space exploration is late toxicity caused by exposure to cosmic rays. On Earth, the exposure of radiation workers is regulated by dose limits and mitigated by shielding and reducing exposure times. For space travel, different international space agencies adopt different limits, recently modified as reviewed in this paper. Shielding and reduced transit time are currently the only practical solutions to maintain acceptable risks in deep space missions.",,2624-8174,,172-184, , ,,out_of_scope,
4259,"Title:Gold nanoparticles synthesized using melatonin suppress cadmium uptake and alleviate its toxicity in rice†

 Melatonin is a general organizer that promotes plant development and moderates defense responses to abiotic stresses; e.g., heat, cold, and heavy metals. Cadmium (Cd) is a heavy metal that can be uptaken by cereal crops. It causes toxicity in plants and poses serious health risks due to its accumulation in the human body through the food chain. This study demonstrates that melatonin in the form of gold nanoparticles (Mel-AuNPs) can alleviate Cd toxicity to a greater extent in hydroponically grown rice plants compared to melatonin applied alone. When rice was grown in a medium supplemented with 200 mu M Mel-AuNPs, the melatonin content significantly increased in the roots (18.0%) and leaves (20.3%), and the Cd level significantly decreased by 33.0% and 46.2%, respectively. Furthermore, the Mel-AuNP supplement restored chlorophyll biosynthesis and mitigated Cd-induced oxidative stresses, while the anti-oxidant enzyme activities were significantly increased. Further study showed that supplying Mel-AuNPs inhibited the Cd-induced gene expression of metal transporter-related genes (OsHMA2, OsHMA3, OsIRT1, OsIRT2, OsNramp1, OsNramp5, and OsLCT1) in rice roots. Overall, this study suggests that Mel-AuNP application could mitigate Cd toxicity in rice seedlings by enhancing melatonin absorption and suppressing Cd uptake.","Jiang, Meng; Dai, Shang; Wang, Binqiang; Xie, Zhenming; Li, Jiulong; Wang, Liangyan; Li, Shan; Tan, Yuanyuan; Tian, Bing; Shu, Qingyao; Huang, Jianzhong","Jiang, Meng/AAL-1872-2021; Li, Jiulong/AEN-0352-2022; Jiang, Meng/HKW-0554-2023; Dai, Shang/IUQ-5415-2023; Shu, Qing-Yao/C-4859-2008","Jiang, Meng/0000-0002-7498-7093; Jiang, Meng/0000-0002-7498-7093; Dai, Shang/0000-0002-9291-4488; Shu, Qing-Yao/0000-0002-9201-0593; li, jiu long/0000-0002-8816-7539; xie, zhenming/0000-0002-0150-9015",Gold nanoparticles synthesized using melatonin suppress cadmium uptake and alleviate its toxicity in rice†,8,4,10.1039/d0en01172j ,Article ,2021.0,"Melatonin is a general organizer that promotes plant development and moderates defense responses to abiotic stresses; e.g., heat, cold, and heavy metals. Cadmium (Cd) is a heavy metal that can be uptaken by cereal crops. It causes toxicity in plants and poses serious health risks due to its accumulation in the human body through the food chain. This study demonstrates that melatonin in the form of gold nanoparticles (Mel-AuNPs) can alleviate Cd toxicity to a greater extent in hydroponically grown rice plants compared to melatonin applied alone. When rice was grown in a medium supplemented with 200 mu M Mel-AuNPs, the melatonin content significantly increased in the roots (18.0%) and leaves (20.3%), and the Cd level significantly decreased by 33.0% and 46.2%, respectively. Furthermore, the Mel-AuNP supplement restored chlorophyll biosynthesis and mitigated Cd-induced oxidative stresses, while the anti-oxidant enzyme activities were significantly increased. Further study showed that supplying Mel-AuNPs inhibited the Cd-induced gene expression of metal transporter-related genes (OsHMA2, OsHMA3, OsIRT1, OsIRT2, OsNramp1, OsNramp5, and OsLCT1) in rice roots. Overall, this study suggests that Mel-AuNP application could mitigate Cd toxicity in rice seedlings by enhancing melatonin absorption and suppressing Cd uptake.",2051-8153,2051-8161,,1042-1056, , ,,out_of_scope,
4260,"Title:Risk Assessment Regarding Perceived Toxicity and Acceptance of Carbon Dioxide-Based Fuel by Laypeople for Its Use in Road Traffic and Aviation

 One approach to mitigate the emissions of carbon dioxide (CO2) is the development of CO2-based products, such as fuels for road traffic and aviation. Since the acceptance of sustainable product innovations such as CO2-based fuels depends on an individual's acceptance decision based on perceived risks and benefits, this study focuses on subjective risk perceptions of fuel toxicity. An online survey was conducted to assess risk evaluations of CO2-based fuels regarding various risk targets, exposure characteristics, negative outcomes for health and environment, and frequency of health impairments. CO2-based fuels were significantly more positively perceived than conventional fuels and were found to be perceived to pose less risks regarding types of exposure and properties leading to toxic effects. For both aviation and road traffic the acceptance of CO2-based fuels increased with decreasing fear of health and environmental consequences and the less frequently health effects were assessed. The findings allow to derive implications for risk assessment and communication strategies in the development and roll-out of CO2-based fuels.","Engelmann, Linda; Arning, Katrin; Linzenich, Anika; Ziefle, Martina",,,Risk Assessment Regarding Perceived Toxicity and Acceptance of Carbon Dioxide-Based Fuel by Laypeople for Its Use in Road Traffic and Aviation,8,,10.3389/fenrg.2020.579814 ,Article ,2020.0,"One approach to mitigate the emissions of carbon dioxide (CO2) is the development of CO2-based products, such as fuels for road traffic and aviation. Since the acceptance of sustainable product innovations such as CO2-based fuels depends on an individual's acceptance decision based on perceived risks and benefits, this study focuses on subjective risk perceptions of fuel toxicity. An online survey was conducted to assess risk evaluations of CO2-based fuels regarding various risk targets, exposure characteristics, negative outcomes for health and environment, and frequency of health impairments. CO2-based fuels were significantly more positively perceived than conventional fuels and were found to be perceived to pose less risks regarding types of exposure and properties leading to toxic effects. For both aviation and road traffic the acceptance of CO2-based fuels increased with decreasing fear of health and environmental consequences and the less frequently health effects were assessed. The findings allow to derive implications for risk assessment and communication strategies in the development and roll-out of CO2-based fuels.",2296-598X,,,, , ,,out_of_scope,
4261,"Title:A review on Cadmium Exposure in the Population and Intervention Strategies Against Cadmium Toxicity

 The rapid industrial development has led to serious cadmium (Cd) pollution. Cd is a toxic heavy metal placing severe health threat to human. Cd can enter the body through the atmosphere, water, soil and food, and has a long half-life (10-30 years), it largely accumulates in kidneys, liver, bone and other organs and causes irreversible damage to the target organs. Cd pollution has also further caused certain carcinogenic and non-carcinogenic health risk. This study summarizes the current situation of Cd pollution, the toxicity of specific target organs, carcinogenic risk and non-carcinogenic risk in the general population, as well as dietary supplements to prevent and mitigate Cd toxication, which aims to focus on the adverse effects of Cd to human from both individual and population perspectives, hoping that not only the health risk of Cd poisoning can be reduced, but also the accurate prevention and control of Cd poisoning can be achieved in the future.","Wang, Mei; Chen, Zhaofang; Song, Wei; Hong, Dezi; Huang, Lei; Li, Yunhui","HUANG, LING/HTR-1819-2023; huang, lei/GQP-8739-2022",,A review on Cadmium Exposure in the Population and Intervention Strategies Against Cadmium Toxicity,106,1,10.1007/s00128-020-03088-1 ,Review ,2021.0,"The rapid industrial development has led to serious cadmium (Cd) pollution. Cd is a toxic heavy metal placing severe health threat to human. Cd can enter the body through the atmosphere, water, soil and food, and has a long half-life (10-30 years), it largely accumulates in kidneys, liver, bone and other organs and causes irreversible damage to the target organs. Cd pollution has also further caused certain carcinogenic and non-carcinogenic health risk. This study summarizes the current situation of Cd pollution, the toxicity of specific target organs, carcinogenic risk and non-carcinogenic risk in the general population, as well as dietary supplements to prevent and mitigate Cd toxication, which aims to focus on the adverse effects of Cd to human from both individual and population perspectives, hoping that not only the health risk of Cd poisoning can be reduced, but also the accurate prevention and control of Cd poisoning can be achieved in the future.",0007-4861,1432-0800,,65-74, , ,,out_of_scope,
4262,"Title:Simulation of respirometry-based detection and mitigation of activated sludge toxicity

 This paper presents the results of an evaluation of a toxicity mitigation control strategy using the IWA simulation benchmark (Respirometry in control of the activated sludge process: benchmarking control strategies, IWA Scientific and Technical Report #11, IWA, London, England, 2002; The COST simulation benchmark: description and simulator manual, Office for Official Publications of the European Community, Luxembourg, 2001, 154pp). The aim of the proposed strategy is to minimise the impact of a toxic influent shock load on process performance. To do this, the strategy depends on a respiration rate measurement to detect toxic events and uses an equalisation tank to store toxic influent. A defined control algorithm specific for the benchmark plant was developed and controls the reintroduction of the stored influent back into the process stream once the influent is deemed non-toxic. Implemented into the benchmark-defined nitrifying configuration, the evaluation required several alterations to the simulation benchmark including three model changes, the addition of a soluble unbiodegradable toxic state variable and the development of two toxic influent files: The results of the simulations indicate that the impact of the toxicant can be significantly mitigated through the use of off-line storage and reintroduction of suspected influent. (C) 2003 Elsevier Science Ltd. All rights reserved.","Copp, JB; Spanjers, H",,,Simulation of respirometry-based detection and mitigation of activated sludge toxicity,12,3,10.1016/S0967-0661(03)00103-5 ,Article ,2004.0,"This paper presents the results of an evaluation of a toxicity mitigation control strategy using the IWA simulation benchmark (Respirometry in control of the activated sludge process: benchmarking control strategies, IWA Scientific and Technical Report #11, IWA, London, England, 2002; The COST simulation benchmark: description and simulator manual, Office for Official Publications of the European Community, Luxembourg, 2001, 154pp). The aim of the proposed strategy is to minimise the impact of a toxic influent shock load on process performance. To do this, the strategy depends on a respiration rate measurement to detect toxic events and uses an equalisation tank to store toxic influent. A defined control algorithm specific for the benchmark plant was developed and controls the reintroduction of the stored influent back into the process stream once the influent is deemed non-toxic. Implemented into the benchmark-defined nitrifying configuration, the evaluation required several alterations to the simulation benchmark including three model changes, the addition of a soluble unbiodegradable toxic state variable and the development of two toxic influent files: The results of the simulations indicate that the impact of the toxicant can be significantly mitigated through the use of off-line storage and reintroduction of suspected influent. (C) 2003 Elsevier Science Ltd. All rights reserved.",0967-0661,,,305-313, , ,,out_of_scope,
4263,"Title:Effects of dietary arginine supplementation on cytokine- and antioxidant-related gene expressions in common carp (Cyprinus carpio) fingerling during ammonia toxicity

 This study investigated the effects of dietary arginine supplementation on plasma ammonia and urea levels, and immune- and antioxidant-related gene expressions of common carp (Cyprinus carpio), exposed to ambient ammonia. Fish (10.5 +/- 0.74 g) were fed diets containing arginine (0: control diet, 0.25: 0.25Arg and 0.5%: 0.5Arg) for 14 days and then subjected to ammonia exposure for three hours. The results showed that arginine significantly decreased plasma ammonia level, whereas increased the plasma urea level. Arginine supplementation significantly up-regulated head kidney il1b, il10, tnfa and liver sod, cat, gpx and gst gene expressions, whereas significantly down-regulated hsp70 gene expression in liver. Ammonia exposure led to a significant increase in plasma ammonia and urea levels. There were elevations in head kidney il1b, and liver sod, cat, gpx, gst and hsp70 gene expression in fish after challenged with ammonia. The interaction effects of arginine supplementation and ammonia exposure on head kidney il10, and liver gst and hsp70 gene expressions were observed, as arginine prevented ammonia-induced down-regulation in il10 expression, mitigated ammonia-induced up-regulation in hsp70 expression and intensified up-regulation in gst expression. In conclusion, it is suggested that two-week supplementation of arginine (0.5% of diet) is useful to mitigate the adverse effects of ambient ammonia when in the farm, common carp is at risk of ammonia toxicity.","Yousefi, Morteza; Abtahi, Behrooz; Adineh, Hossein; Hoseinifar, Seyed Hossein; Taheri Mirghaed, Ali; Paolucci, Marina; Van Doan, Hien","Taheri Mirghaed, Ali Taheri/AAW-5451-2021; Abtahi, Behrooz/ABA-9485-2021; Yousefi, Morteza/B-9911-2019; Ghelichpour, Melika/AFS-3315-2022; Van Doan, Hien/N-9579-2019; Hoseinifar, Seyed Hossein/G-8526-2017","Yousefi, Morteza/0000-0001-5352-8106; Paolucci, Marina/0000-0002-1784-3843; Taheri Mirghaed, Ali/0000-0001-5568-1390; Hoseinifar, Seyed Hossein/0000-0002-0210-9013; Abtahi, Behrooz/0000-0002-4049-0505",Effects of dietary arginine supplementation on cytokine- and antioxidant-related gene expressions in common carp (Cyprinus carpio) fingerling during ammonia toxicity,52,6,10.1111/are.15127 ,Article ,2021.0,"This study investigated the effects of dietary arginine supplementation on plasma ammonia and urea levels, and immune- and antioxidant-related gene expressions of common carp (Cyprinus carpio), exposed to ambient ammonia. Fish (10.5 +/- 0.74 g) were fed diets containing arginine (0: control diet, 0.25: 0.25Arg and 0.5%: 0.5Arg) for 14 days and then subjected to ammonia exposure for three hours. The results showed that arginine significantly decreased plasma ammonia level, whereas increased the plasma urea level. Arginine supplementation significantly up-regulated head kidney il1b, il10, tnfa and liver sod, cat, gpx and gst gene expressions, whereas significantly down-regulated hsp70 gene expression in liver. Ammonia exposure led to a significant increase in plasma ammonia and urea levels. There were elevations in head kidney il1b, and liver sod, cat, gpx, gst and hsp70 gene expression in fish after challenged with ammonia. The interaction effects of arginine supplementation and ammonia exposure on head kidney il10, and liver gst and hsp70 gene expressions were observed, as arginine prevented ammonia-induced down-regulation in il10 expression, mitigated ammonia-induced up-regulation in hsp70 expression and intensified up-regulation in gst expression. In conclusion, it is suggested that two-week supplementation of arginine (0.5% of diet) is useful to mitigate the adverse effects of ambient ammonia when in the farm, common carp is at risk of ammonia toxicity.",1355-557X,1365-2109,,2751-2758, , ,,out_of_scope,
4264,"Title:Effective degradation of zearalenone by dye-decolorizing peroxidases from Pleurotus ostreatus and its metabolic pathway and toxicity analysis.

 The widespread detection of zearalenone (ZEN) in cereal crops and feeds poses a significant threat to both humans and animals. Consequently, the urgency for the international community to address this issue is evident in the demand for safe and effective measures to mitigate zearalenone contamination and explore detoxification methods. In this study, a dye-decolorizing peroxidase (PoDyP4) from Pleurotus ostreatus is characterized for its impressive ZEN degradation effectiveness. PoDyP4 was demonstrated that the ability to almost completely degrade ZEN at pH6.0 and 40°C for 2h, even at high concentrations of 1mM. The promotion of enzymatic degradation of ZEN was most pronounced in the presence of Mg2+, while Cu2+ and Fe2+ exhibited a notable inhibitory effect. The degradation mechanism elucidated the detoxification of ZEN by PoDyP4 through hydroxylation and polymerization reactions. The resulting metabolic products displayed significantly reduced toxicity and minimal impact on the viability and apoptosis of mouse spermatocytes GC-2 cells, in comparison to the original ZEN. Hydrophobic contacts and hydrogen bonds were found to be crucial for ZEN-PoDyP4 stability via molecular docking. This finding suggests that PoDyP4 may have a promising application in the field of food and feed for zearalenone detoxification.","Ding, Shuai; Lin, Chen; Xiao, Qiuyun; Feng, Fa; Wang, Junfeng; Zhang, Xing; Yang, Shengjing; Li, Lingling; Li, Fei",,,Effective degradation of zearalenone by dye-decolorizing peroxidases from Pleurotus ostreatus and its metabolic pathway and toxicity analysis.,908,,10.1016/j.scitotenv.2023.168500 ,Journal Article ,2024.0,"The widespread detection of zearalenone (ZEN) in cereal crops and feeds poses a significant threat to both humans and animals. Consequently, the urgency for the international community to address this issue is evident in the demand for safe and effective measures to mitigate zearalenone contamination and explore detoxification methods. In this study, a dye-decolorizing peroxidase (PoDyP4) from Pleurotus ostreatus is characterized for its impressive ZEN degradation effectiveness. PoDyP4 was demonstrated that the ability to almost completely degrade ZEN at pH6.0 and 40°C for 2h, even at high concentrations of 1mM. The promotion of enzymatic degradation of ZEN was most pronounced in the presence of Mg2+, while Cu2+ and Fe2+ exhibited a notable inhibitory effect. The degradation mechanism elucidated the detoxification of ZEN by PoDyP4 through hydroxylation and polymerization reactions. The resulting metabolic products displayed significantly reduced toxicity and minimal impact on the viability and apoptosis of mouse spermatocytes GC-2 cells, in comparison to the original ZEN. Hydrophobic contacts and hydrogen bonds were found to be crucial for ZEN-PoDyP4 stability via molecular docking. This finding suggests that PoDyP4 may have a promising application in the field of food and feed for zearalenone detoxification.",,1879-1026,,168500-168500, , ,,out_of_scope,
4265,"Title:The effect of oxygen on biochemical networks and the evolution of complex life

 The evolution of oxygenic photosynthesis and ensuing oxygenation of Earth's atmosphere represent a major transition in the history of life. Although many organisms retreated to anoxic environments, others evolved to use oxygen as a. high-potential redox couple white concomitantly mitigating its toxicity. To understand the changes in biochemistry and enzymology that accompanied adaptation to O-2, we integrated network analysis with information on enzyme evolution to infer how oxygen availability changed the architecture of metabolic networks. Our analysis revealed the existence of four discrete groups of networks of increasing complexity, with transitions between groups being contingent on the presence of key metabolites, including molecular oxygen, which was required for transition into the largest networks.","Raymond, J; Segrè, D","Segrè, Daniel/A-1993-2009","Segrè, Daniel/0000-0003-4859-1914",The effect of oxygen on biochemical networks and the evolution of complex life,311,5768,10.1126/science.1118439 ,Article ,2006.0,"The evolution of oxygenic photosynthesis and ensuing oxygenation of Earth's atmosphere represent a major transition in the history of life. Although many organisms retreated to anoxic environments, others evolved to use oxygen as a. high-potential redox couple white concomitantly mitigating its toxicity. To understand the changes in biochemistry and enzymology that accompanied adaptation to O-2, we integrated network analysis with information on enzyme evolution to infer how oxygen availability changed the architecture of metabolic networks. Our analysis revealed the existence of four discrete groups of networks of increasing complexity, with transitions between groups being contingent on the presence of key metabolites, including molecular oxygen, which was required for transition into the largest networks.",0036-8075,1095-9203,,1764-1767, , ,,out_of_scope,
4266,"Title:Pulsed Electric Fields (PEF) to Mitigate Emerging Mycotoxins in Juices and Smoothies

 Featured ApplicationPulsed electric fields (PEF) technology is explored here as an effective tool for inactivating emerging mycotoxins at low temperatures and over short time periods.The development of innovative food processing technologies has increased to answer the growing demand to supply of fresh-like products. The aim of the present study is to investigate the effect of pulsed electric fields (PEF) technology on reducing the emerging mycotoxins (enniatins (ENs) and beauvericin (BEA)) contents in juice and smoothie samples. The products of degradation obtained after PEF treatment were identified and their toxicological endpoint toxicities predicted by Pro Tox-II web. Mycotoxin reduction ranged from 43 to 70% in juices and smoothies, but in water the expected effect was lower. The acidified pH increased BEA reduction in water. The degradation products that were produced were the result of the loss of aminoacidic fragments of the original molecules, such as HyLv, Val, Ile, or Phe. Pro Tox-II server assigned a toxicity class I for enniatin B (ENB) degradation products with a predicted LD50 of 3 mg/Kgbw. The other degradation products were classified in toxicity class III and IV.","Pallares, Noelia; Barba, Francisco J.; Berrada, Houda; Tolosa, Josefa; Ferrer, Emilia","Berrada, Houda/B-7723-2015; Barba, Francisco J./L-6596-2014; FERRER, EMILIA/F-5709-2016","Berrada, Houda/0000-0001-7302-5282; Barba, Francisco J./0000-0002-5630-3989; FERRER, EMILIA/0000-0002-5198-2521; Pallares, Noelia/0000-0001-8018-3959",Pulsed Electric Fields (PEF) to Mitigate Emerging Mycotoxins in Juices and Smoothies,10,19,10.3390/app10196989 ,Article ,2020.0,"Featured ApplicationPulsed electric fields (PEF) technology is explored here as an effective tool for inactivating emerging mycotoxins at low temperatures and over short time periods.The development of innovative food processing technologies has increased to answer the growing demand to supply of fresh-like products. The aim of the present study is to investigate the effect of pulsed electric fields (PEF) technology on reducing the emerging mycotoxins (enniatins (ENs) and beauvericin (BEA)) contents in juice and smoothie samples. The products of degradation obtained after PEF treatment were identified and their toxicological endpoint toxicities predicted by Pro Tox-II web. Mycotoxin reduction ranged from 43 to 70% in juices and smoothies, but in water the expected effect was lower. The acidified pH increased BEA reduction in water. The degradation products that were produced were the result of the loss of aminoacidic fragments of the original molecules, such as HyLv, Val, Ile, or Phe. Pro Tox-II server assigned a toxicity class I for enniatin B (ENB) degradation products with a predicted LD50 of 3 mg/Kgbw. The other degradation products were classified in toxicity class III and IV.",,2076-3417,,, , ,,out_of_scope,
4267,"Title:Time-varying Spectral Index of Electrodermal Activity to Predict Central Nervous System Oxygen Toxicity Symptoms in Divers: Preliminary results

 The most effective method to mitigate decompression sickness in divers is hyperbaric oxygen (HBO2) pre-breathing. However, divers breathing HBO2 are at risk for developing central nervous system oxygen toxicity (CNS-OT), which can manifest as symptoms that might impair a diver's performance, or cause more serious symptoms like seizures. In this study, we have collected electrodermal activity (EDA) signals in fifteen subjects at elevated oxygen partial pressures (2.06 ATA, 35 FSW) in the foxtrot chamber pool at the Duke University Hyperbaric Center, while performing a cognitive stress test for up to 120 minutes. Specifically, we have computed the time-varying spectral analysis of EDA (TVSymp) as a tool for sympathetic tone assessment and evaluated its feasibility for the prediction of symptoms of CNS-OT in divers. The preliminary results show large increase in the amplitude TVSymp values derived from EDA recordings similar to 2 minutes prior to expert human adjudication of symptoms related to oxygen toxicity. An early detection based on TVSymp might allow the diver to take countermeasures against the dire consequences of CNS-OT which can lead to drowning.","Posada-Quintero, Hugo F.; Derrick, Bruce J.; Winstead-Derlega, Christopher; Gonzalez, Sara, I; Ellis, M. Claire; Freiberger, John J.; Chon, Ki H.","Posada-Quintero, Hugo F./E-2581-2016","Posada-Quintero, Hugo F./0000-0003-4514-4772; Freiberger, John/0000-0002-1871-9430",Time-varying Spectral Index of Electrodermal Activity to Predict Central Nervous System Oxygen Toxicity Symptoms in Divers: Preliminary results,,,10.1109/EMBC46164.2021.9629924 ,Proceedings Paper ,2021.0,"The most effective method to mitigate decompression sickness in divers is hyperbaric oxygen (HBO2) pre-breathing. However, divers breathing HBO2 are at risk for developing central nervous system oxygen toxicity (CNS-OT), which can manifest as symptoms that might impair a diver's performance, or cause more serious symptoms like seizures. In this study, we have collected electrodermal activity (EDA) signals in fifteen subjects at elevated oxygen partial pressures (2.06 ATA, 35 FSW) in the foxtrot chamber pool at the Duke University Hyperbaric Center, while performing a cognitive stress test for up to 120 minutes. Specifically, we have computed the time-varying spectral analysis of EDA (TVSymp) as a tool for sympathetic tone assessment and evaluated its feasibility for the prediction of symptoms of CNS-OT in divers. The preliminary results show large increase in the amplitude TVSymp values derived from EDA recordings similar to 2 minutes prior to expert human adjudication of symptoms related to oxygen toxicity. An early detection based on TVSymp might allow the diver to take countermeasures against the dire consequences of CNS-OT which can lead to drowning.",1557-170X,1558-4615,978-1-7281-1179-7,1242-1245, , 43rd Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society (IEEE EMBC)43rd Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society (IEEE EMBC),,out_of_scope,
4268,"Title:Binding of serum albumin to perfluorooctanoic acid reduced cytotoxicity

 With the ubiquitous applications of perfluorinated compounds such as perfluorooctanoic acid (PFOA) in industrial and commercial products, the toxicity of these engineered materials in environmental and public health is received grow-ing attention. As a typical organic pollutant, PFOA has been extensively found in wildlife and human bodies, and can preferentially bind to serum albumin in vivo. However, the importance of protein-PFOA interactions on the cytotoxic-ity of PFOA could not be stressed enough. In this study, we used both experimental and theoretical approaches, to in-vestigate the interactions of PFOA with bovine serum albumin (BSA, the most abundant protein in blood). It was found that PFOA could mainly interact with Sudlow site I of BSA to form BSA-PFOA complex, in which van der Waals forces and hydrogen bonds played dominant roles. Moreover, the strong binding of BSA could greatly alter the cellular uptake and distribution of PFOA in human endothelial cells, and result in the decreases of reactive oxygen species formation and cytotoxicity for these BSA-coated PFOA. Consistently, the addition of fetal bovine serum into cell culture medium also significantly mitigated PFOA-induced cytotoxicity, which was attributed to the extracellular complexation be-tween PFOA and serum proteins. Altogether, our study demonstrates that the binding of serum albumin to PFOA could reduce its toxicity by affecting the cellular responses.","Yang, Ya-Di; Tian, Rong; Lu, Naihao",,,Binding of serum albumin to perfluorooctanoic acid reduced cytotoxicity,876,,10.1016/j.scitotenv.2023.162738 ,Article ,2023.0,"With the ubiquitous applications of perfluorinated compounds such as perfluorooctanoic acid (PFOA) in industrial and commercial products, the toxicity of these engineered materials in environmental and public health is received grow-ing attention. As a typical organic pollutant, PFOA has been extensively found in wildlife and human bodies, and can preferentially bind to serum albumin in vivo. However, the importance of protein-PFOA interactions on the cytotoxic-ity of PFOA could not be stressed enough. In this study, we used both experimental and theoretical approaches, to in-vestigate the interactions of PFOA with bovine serum albumin (BSA, the most abundant protein in blood). It was found that PFOA could mainly interact with Sudlow site I of BSA to form BSA-PFOA complex, in which van der Waals forces and hydrogen bonds played dominant roles. Moreover, the strong binding of BSA could greatly alter the cellular uptake and distribution of PFOA in human endothelial cells, and result in the decreases of reactive oxygen species formation and cytotoxicity for these BSA-coated PFOA. Consistently, the addition of fetal bovine serum into cell culture medium also significantly mitigated PFOA-induced cytotoxicity, which was attributed to the extracellular complexation be-tween PFOA and serum proteins. Altogether, our study demonstrates that the binding of serum albumin to PFOA could reduce its toxicity by affecting the cellular responses.",0048-9697,1879-1026,,, , ,,out_of_scope,
4269,"Title:The 5 principles of Design for Safer Nanotechnology

 Nanoparticles have been incorporated in hundreds of different types of products, and the novel properties of nanomaterials offer great promise to provide new technological breakthroughs. However, nanotechnology is an emerging technology which has potential health and safety risks throughout its product life cycle. The health risk of a nanoparticle is a function of both its hazard to human health and its exposure potential. It is prudent for companies to try to mitigate the potential risks of nanoparticles during the design stage rather than downstream during manufacturing or customer use. The intent of this paper is to propose five design principles for product designers to use during the design stage for products that contain nanoparticles. By using these design principles, the health risk of the nanoparticle may be mitigated by potentially lowering the hazard and/or the exposure potential of the nanoparticle. These proposed design principles are largely untested and are offered as an initial framework that will require more testing, validation, and refinement. (C) 2009 Elsevier Ltd. All rights reserved.","Morose, Gregory",,,The 5 principles of Design for Safer Nanotechnology,18,3,10.1016/j.jclepro.2009.10.001 ,Article ,2010.0,"Nanoparticles have been incorporated in hundreds of different types of products, and the novel properties of nanomaterials offer great promise to provide new technological breakthroughs. However, nanotechnology is an emerging technology which has potential health and safety risks throughout its product life cycle. The health risk of a nanoparticle is a function of both its hazard to human health and its exposure potential. It is prudent for companies to try to mitigate the potential risks of nanoparticles during the design stage rather than downstream during manufacturing or customer use. The intent of this paper is to propose five design principles for product designers to use during the design stage for products that contain nanoparticles. By using these design principles, the health risk of the nanoparticle may be mitigated by potentially lowering the hazard and/or the exposure potential of the nanoparticle. These proposed design principles are largely untested and are offered as an initial framework that will require more testing, validation, and refinement. (C) 2009 Elsevier Ltd. All rights reserved.",0959-6526,1879-1786,,285-289, , ,,out_of_scope,
4270,"Title:Kynurenic acid mediates bacteria-algae consortium in resisting environmental cadmium toxicity

 Cadmium (Cd2+) is a toxic heavy metal in the environment, posing severe damage to animal health and drinking water safety. The bacteria-algae consortium remediates environmental Cd2+ pollution by secreting chelating reagents, but the molecular mechanisms remain elusive. Here, we showed that Cellulosimicrobium sp. SH8 iso-lated from a Cd2+-polluted lake could interact with Synechocystis sp. PCC6803, a model species of cyanobacteria, in strengthening Cd2+ toxicity resistance, while SH8 or PCC6803 alone barely immobilized Cd2+. In addition, the SH8-PCC6803 consortium, but not SH8 alone, could grow in a carbon-free medium, suggesting that autotrophic PCC6803 enabled the growth of heterotrophic SH8. Totally, 12 metabolites were significantly changed when SH8 was added to PCC6803 culture in the presence of Cd2+ (PCC6803/Cd2+). Among them, kynurenic acid was the only metabolite that precipitated Cd2+. Remarkably, adding kynurenic acid increased the growth of PCC6803/ Cd2+ by 14.1 times. Consistently, the expressions of kynA, kynB, and kynT genes, known to be essential for kynurenic acid synthesis, were considerably increased when SH8 was added to PCC6803/Cd2+. Collectively, kynurenic acid secreted by SH8 mitigates Cd2+ toxicity for algae, and algae provide organic carbon for the growth of SH8, unveiling a critical link that mediates beneficial bacteria-algae interaction to resist Cd2+.","Qi, Xiaoli; Fu, Keyi; Yue, Mingyuan; Shou, Na; Yuan, Xuefeng; Chen, Xi; He, Chunyu; Yang, Yunfeng; Shi, Zunji",,,Kynurenic acid mediates bacteria-algae consortium in resisting environmental cadmium toxicity,444,,10.1016/j.jhazmat.2022.130397 ,Article ,2023.0,"Cadmium (Cd2+) is a toxic heavy metal in the environment, posing severe damage to animal health and drinking water safety. The bacteria-algae consortium remediates environmental Cd2+ pollution by secreting chelating reagents, but the molecular mechanisms remain elusive. Here, we showed that Cellulosimicrobium sp. SH8 iso-lated from a Cd2+-polluted lake could interact with Synechocystis sp. PCC6803, a model species of cyanobacteria, in strengthening Cd2+ toxicity resistance, while SH8 or PCC6803 alone barely immobilized Cd2+. In addition, the SH8-PCC6803 consortium, but not SH8 alone, could grow in a carbon-free medium, suggesting that autotrophic PCC6803 enabled the growth of heterotrophic SH8. Totally, 12 metabolites were significantly changed when SH8 was added to PCC6803 culture in the presence of Cd2+ (PCC6803/Cd2+). Among them, kynurenic acid was the only metabolite that precipitated Cd2+. Remarkably, adding kynurenic acid increased the growth of PCC6803/ Cd2+ by 14.1 times. Consistently, the expressions of kynA, kynB, and kynT genes, known to be essential for kynurenic acid synthesis, were considerably increased when SH8 was added to PCC6803/Cd2+. Collectively, kynurenic acid secreted by SH8 mitigates Cd2+ toxicity for algae, and algae provide organic carbon for the growth of SH8, unveiling a critical link that mediates beneficial bacteria-algae interaction to resist Cd2+.",0304-3894,1873-3336,,, , ,,out_of_scope,
4271,"Title:Current scenario and challenges of plastic pollution in Bangladesh: a focus on farmlands and terrestrial ecosystems

 Plastic is considered one of the most indispensable commodities in our daily life. At the end of life, the huge ever-growing pile of plastic waste (PW) causes serious concerns for our environment, including agricultural farmlands, groundwater quality, marine and land ecosystems, food toxicity and human health hazards. Lack of proper infrastructure, financial backup, and technological advancement turn this hazardous waste plastic management into a serious threat to developing countries, especially for Bangladesh. A comprehensive review of PW generation and its consequences on environment in both global and Bangladesh contexts is presented. The dispersion routes of PW from different sources in different forms (microplastic, macroplastic, nanoplastic) and its adverse effect on agriculture, marine life and terrestrial ecosystems are illustrated in this work. The key challenges to mitigate PW pollution and tackle down the climate change issue is discussed in this work. Moreover, way forward toward the design and implementation of proper PW management strategies are highlighted in this study. (C) Higher Education Press 2023","Islam, Md. Raihanul; Ruponti, Sumaiya Akter; Rakib, Md. Abdur; Nguyen, Huy Quoc; Mourshed, Monjur","MOURSHED, MONJUR/HZM-0689-2023","MOURSHED, MONJUR/0000-0001-9145-7572",Current scenario and challenges of plastic pollution in Bangladesh: a focus on farmlands and terrestrial ecosystems,17,6,10.1007/s11783-023-1666-4 ,Review ,2023.0,"Plastic is considered one of the most indispensable commodities in our daily life. At the end of life, the huge ever-growing pile of plastic waste (PW) causes serious concerns for our environment, including agricultural farmlands, groundwater quality, marine and land ecosystems, food toxicity and human health hazards. Lack of proper infrastructure, financial backup, and technological advancement turn this hazardous waste plastic management into a serious threat to developing countries, especially for Bangladesh. A comprehensive review of PW generation and its consequences on environment in both global and Bangladesh contexts is presented. The dispersion routes of PW from different sources in different forms (microplastic, macroplastic, nanoplastic) and its adverse effect on agriculture, marine life and terrestrial ecosystems are illustrated in this work. The key challenges to mitigate PW pollution and tackle down the climate change issue is discussed in this work. Moreover, way forward toward the design and implementation of proper PW management strategies are highlighted in this study. (C) Higher Education Press 2023",2095-2201,2095-221X,,, , ,,out_of_scope,
4272,"Title:Salinity and SiO2 Impact on Growth and Biochemical Responses of Basil (Ocimum Basilicum L.) Seedlings

 Silicon has the ability in ameliorating the negative effect of salinity on plants by reducing ionic toxicity and maintaining plant water balance, reducing oxidative stress. The present paper examines the effects of saline stress (50mM and 100mM NaCl) applied singular and in combination with SiO2 on basil (Ocimum basilicum L.) seedlings. Significant changes occurred in terms of shoot length, varying from 7.27 mm (50 mM NaCl) to 8.39 mm (50mM NaCl+SiNPs), and in the case of radicles, from 3.22 mm (SiNP) to 3.98 mm (100 mM NaCl), suggesting that salt treatment reduces shoot elongation, and SiO2 application could mitigate the saline stress effect. The activity of antioxidant enzymes in O. basilicum seedlings exposed to treatments, singular or in combination, was generally lower compared to the control. SiO2 supplement may contribute to the increase of salt tolerance, as reflected by the improvement of SOD and POD activity, especially in the combined treatment of 100 mM NaCl+ SiO2.","Oprica, Lacramioara; Grigore, Marius-Nicusor; Bara, Julia; Vochita, Gabriela",,,Salinity and SiO2 Impact on Growth and Biochemical Responses of Basil (Ocimum Basilicum L.) Seedlings,,,10.1109/EHB52898.2021.9657645 ,Proceedings Paper ,2021.0,"Silicon has the ability in ameliorating the negative effect of salinity on plants by reducing ionic toxicity and maintaining plant water balance, reducing oxidative stress. The present paper examines the effects of saline stress (50mM and 100mM NaCl) applied singular and in combination with SiO2 on basil (Ocimum basilicum L.) seedlings. Significant changes occurred in terms of shoot length, varying from 7.27 mm (50 mM NaCl) to 8.39 mm (50mM NaCl+SiNPs), and in the case of radicles, from 3.22 mm (SiNP) to 3.98 mm (100 mM NaCl), suggesting that salt treatment reduces shoot elongation, and SiO2 application could mitigate the saline stress effect. The activity of antioxidant enzymes in O. basilicum seedlings exposed to treatments, singular or in combination, was generally lower compared to the control. SiO2 supplement may contribute to the increase of salt tolerance, as reflected by the improvement of SOD and POD activity, especially in the combined treatment of 100 mM NaCl+ SiO2.",2575-5137,2575-5145,978-1-6654-4000-4,, , 9th IEEE International Conference on e-Health and Bioengineering (EHB)9th IEEE International Conference on e-Health and Bioengineering (EHB),,out_of_scope,
4273,"Title:Effective antiviral coatings for deactivating SARS-CoV-2 virus on N95 respirator masks or filters

 The application of antiviral coatings to masks and respirators is a potential mitigating step toward reducing viral transmission during the SARS-CoV-2 (severe acute respiratory syndrome coronavirus 2) pandemic. The use of appropriate masks, social distancing, and vaccines is the immediate solution for limiting the viral spread and protecting people from this virus. N95 respirator masks are effective in filtering the virus particles, but they cannot kill or deactivate the virus. We report a possible approach to deactivating SARS-CoV-2 by applying an antimicrobial coating (Goldshield 75) to masks and respirators, rendering them suitable for repeated use. Masks coated with Goldshield 75 demonstrated continuous inactivation of the Alpha and Beta variants of the SARS-CoV-2 over a 3-day period and no loss of inactivation when stored at temperatures at 50 degrees C.Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons. org/licenses/by/4.0/).","Paranthaman, Mariappan Parans; Peroutka-Bigus, Nathan; Larsen, Kristina R.; Phadke, Kruttika S.; Summers, Tina; Theodore, Merlin; Hensley, Dale K.; Levine, Alan M.; Lee, Richard J.; Bellaire, Bryan H.","Paranthaman, Mariappan/AAO-9751-2021; Bellaire, Bryan/GNP-5200-2022; Paranthaman, Mariappan/N-3866-2015; Hensley, Dale/A-6282-2016","Bellaire, Bryan/0000-0002-4034-6482; Paranthaman, Mariappan/0000-0003-3009-8531; Larsen, Kristina/0000-0003-0764-1217; Hensley, Dale/0000-0001-8763-7765",Effective antiviral coatings for deactivating SARS-CoV-2 virus on N95 respirator masks or filters,14,,10.1016/j.mtadv.2022.100228 ,Article ,2022.0,"The application of antiviral coatings to masks and respirators is a potential mitigating step toward reducing viral transmission during the SARS-CoV-2 (severe acute respiratory syndrome coronavirus 2) pandemic. The use of appropriate masks, social distancing, and vaccines is the immediate solution for limiting the viral spread and protecting people from this virus. N95 respirator masks are effective in filtering the virus particles, but they cannot kill or deactivate the virus. We report a possible approach to deactivating SARS-CoV-2 by applying an antimicrobial coating (Goldshield 75) to masks and respirators, rendering them suitable for repeated use. Masks coated with Goldshield 75 demonstrated continuous inactivation of the Alpha and Beta variants of the SARS-CoV-2 over a 3-day period and no loss of inactivation when stored at temperatures at 50 degrees C.Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons. org/licenses/by/4.0/).",2590-0498,,,, , ,,out_of_scope,
4274,"Title:A Review on Heavy Metal Concentration in Potable Water Sources in Nigeria: Human Health Effects and Mitigating Measures

 Nigeria is one of the most populated black nation in the world with a population of about 170 million. Over the years, potable water source which is one of the basic essential requirements for healthy living has been challenging due to inadequate controlled anthropogenic activities and by lesser extent natural conditions. This paper reviews the various potable water sources, heavy metal concentration, and its associated health effects in Nigeria. The study found that surface water such as stream, river, lake; ground water including borehole and hand-dug well; rain water; and packaged water such as bottled and sachet are the major source of potable water. The dominant heavy metals found in potable water include iron, zinc, copper, chromium, lead, and manganese. The concentration of heavy metals like mercury, lead, cadmium, iron, cobalt, manganese, chromium, nickel, zinc, and copper often exceed the maximum permissible limit recommended by standard organization of Nigeria and World Health Organization. The concentration of heavy metals fluctuates in most states/geographical coverage depending on the type of potable water sources. To a large extent, industrialization causes heavy metals concentration to exceed the permissible limits. The high concentration reported in most locations could cause various disease conditions depending on the type of metal and level of exposure. This study also suggest possible treatment and mitigating measures to avoid such harmful effects.","Izah, Sylvester Chibueze; Chakrabarty, Neelima; Srivastav, Arun Lal","Izah, Sylvester Chibueze/D-4193-2017; Srivastav, Arun Lal/N-6785-2019; SRIVASTAV, ARUN LAL/E-3695-2019","Izah, Sylvester Chibueze/0000-0001-5526-006X; Srivastav, Arun Lal/0000-0003-0238-7395; SRIVASTAV, ARUN LAL/0000-0003-0238-7395",A Review on Heavy Metal Concentration in Potable Water Sources in Nigeria: Human Health Effects and Mitigating Measures,8,2,10.1007/s12403-016-0195-9 ,Review ,2016.0,"Nigeria is one of the most populated black nation in the world with a population of about 170 million. Over the years, potable water source which is one of the basic essential requirements for healthy living has been challenging due to inadequate controlled anthropogenic activities and by lesser extent natural conditions. This paper reviews the various potable water sources, heavy metal concentration, and its associated health effects in Nigeria. The study found that surface water such as stream, river, lake; ground water including borehole and hand-dug well; rain water; and packaged water such as bottled and sachet are the major source of potable water. The dominant heavy metals found in potable water include iron, zinc, copper, chromium, lead, and manganese. The concentration of heavy metals like mercury, lead, cadmium, iron, cobalt, manganese, chromium, nickel, zinc, and copper often exceed the maximum permissible limit recommended by standard organization of Nigeria and World Health Organization. The concentration of heavy metals fluctuates in most states/geographical coverage depending on the type of potable water sources. To a large extent, industrialization causes heavy metals concentration to exceed the permissible limits. The high concentration reported in most locations could cause various disease conditions depending on the type of metal and level of exposure. This study also suggest possible treatment and mitigating measures to avoid such harmful effects.",2451-9766,2451-9685,,285-304, , ,,out_of_scope,
4275,"Title:Sulfur nanoparticles improved plant growth and reduced mercury toxicity via mitigating the oxidative stress in Brassica napus L.

 Experiments were conducted to determine the effects of sulfur nanoparticles (SNPs) on alleviating mercury (Hg) toxicity and accumulation in Brassica napus L. in MS medium. The results demonstrated that 10 mg/L Hg severely inhibit brassica seedlings growth, whereas the addition of 300 mg/L SNPs alleviated Hg toxicity, and dry weight were improved by 42.4% (shoot) and 37.8% (root) compared to 10 mg/L Hg treatment alone. SNPs application decreased Hg accumulation in roots and shoots by 6-10 folds. Comparatively, the effect of corresponding bulk sulfur particles (BSPs) and sulfate as ionic compound for counteracting Hg toxicity and accumulation was less pronounced than SNPs treatment. Co-exposure of SNPs along with Hg also alleviated the Hg-induced oxidative stress as the MDA and H2O2 contents, antioxidant enzymes activities (SOD, POD, APX and GST) and glutathione (GSH) content in roots and shoots were decreased relative to Hg treatment alone. The macro (K, Ca, P, Mg) and micronutrients (Zn, Mn, Fe) concentrations in roots and shoots were elevated considerably by SNPs co-exposure compared to plants exposed to Hg only. Further, the expression of selected genes encoding the antioxidant enzymes and nutrient transporters also showed changes similar to the physiological and biochemical parameters. Our results showed that SNPs play a significant role in the decreasing Hg accumulation, counteracting the Hg toxicity, and enhancing plant biomass and nutrients accumulation in B. napus. These findings will be helpful in developing strategies to decrease heavy metals contamination in the food chain as well as for phytoremediation applications.","Yuan, Haiyan; Liu, Qingquan; Guo, Zhi; Fu, Jiahao; Sun, Yuming; Gu, Chunsun; Xing, Baoshan; Dhankher, Om Parkash","Dhankher, Om Parkash P/P-1880-2016","Dhankher, Om Parkash/0000-0003-0737-6783",Sulfur nanoparticles improved plant growth and reduced mercury toxicity via mitigating the oxidative stress in Brassica napus L.,318,,10.1016/j.jclepro.2021.128589 ,Article ,2021.0,"Experiments were conducted to determine the effects of sulfur nanoparticles (SNPs) on alleviating mercury (Hg) toxicity and accumulation in Brassica napus L. in MS medium. The results demonstrated that 10 mg/L Hg severely inhibit brassica seedlings growth, whereas the addition of 300 mg/L SNPs alleviated Hg toxicity, and dry weight were improved by 42.4% (shoot) and 37.8% (root) compared to 10 mg/L Hg treatment alone. SNPs application decreased Hg accumulation in roots and shoots by 6-10 folds. Comparatively, the effect of corresponding bulk sulfur particles (BSPs) and sulfate as ionic compound for counteracting Hg toxicity and accumulation was less pronounced than SNPs treatment. Co-exposure of SNPs along with Hg also alleviated the Hg-induced oxidative stress as the MDA and H2O2 contents, antioxidant enzymes activities (SOD, POD, APX and GST) and glutathione (GSH) content in roots and shoots were decreased relative to Hg treatment alone. The macro (K, Ca, P, Mg) and micronutrients (Zn, Mn, Fe) concentrations in roots and shoots were elevated considerably by SNPs co-exposure compared to plants exposed to Hg only. Further, the expression of selected genes encoding the antioxidant enzymes and nutrient transporters also showed changes similar to the physiological and biochemical parameters. Our results showed that SNPs play a significant role in the decreasing Hg accumulation, counteracting the Hg toxicity, and enhancing plant biomass and nutrients accumulation in B. napus. These findings will be helpful in developing strategies to decrease heavy metals contamination in the food chain as well as for phytoremediation applications.",0959-6526,1879-1786,,, , ,,out_of_scope,
4276,"Title:Hesperetin activated SIRT1 neutralizes cadmium effects on the early bovine embryo development

 Cadmium (Cd) is a major environmental contaminant that has been linked to oocyte quality reduction and early embryo mortality in various in vivo studies. In this study, we investigated the mechanism of Cd-induced mitochondrial toxicity in bovine in vitro matured oocytes, primary cultured bovine cumulus cells, and in vitro developed bovine embryos. Cd significantly reduced PPARGC1A (PGC-1a) and nuclear respiratory factors, which leads to mitochondrial damage and hence reduction in oocyte maturation and embryo development. NAD-dependent deacetylase sirtuin-1 (SIRT1) is the upstream marker of PGC-1a and nuclear respiratory factors, and its activation significantly mitigated Cd-induced mitochondrial damage. For SIRT1 activation, we used Hesperetin (Hsp), a citrus flavonoid and a potent activator of SIRT1. The molecular docking approach was used to investigate the binding of hesperetin to bovine SIRT1, which revealed that hesperetin creates polar and non-polar interactions with residues that are reported essential for the activation of SIRT1. Furthermore, the SIRT1 enzymatic activity was measured in primary cultured bovine granulosa cells after hesperetin treatment. To further confirm the SIRT1-dependent effects of hesperetin we used a specific inhibitor of SIRT1 (EX527), which significantly (p < 0.05) reduced the effects of hesperetin on embryo mitochondria. Next, we treated hesperetin and Cd to early bovine embryos and discovered a significant (p 0.05) increase in PGC-1, NRF1, and NFE2L2 protein expression as well as embryo development recovery. Thus, we came to the conclusion that hesperetin can activate PGC-1 and nuclear respiratory factors via SIRT1, which can greatly reduce Cd-induced mitochondrial toxicity and promote mitochondrial biogenesis in early bovine embryos.(c) 2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).","Idrees, Muhammad; Kumar, Vikas; Khan, Abdul Majid; Joo, Myeong-Don; Uddin, Zia; Lee, Keun-Woo; Kong, Il-Keun","KUMAR, VIKAS/AAJ-8717-2021; Khan, Abdul Aziz/JQV-4953-2023","KUMAR, VIKAS/0000-0003-4468-3459; Khan, Abdul Majid/0000-0003-3526-9272; Idrees, Muhammad/0000-0002-9715-0691",Hesperetin activated SIRT1 neutralizes cadmium effects on the early bovine embryo development,189,,10.1016/j.theriogenology.2022.06.008 ,Article ,2022.0,"Cadmium (Cd) is a major environmental contaminant that has been linked to oocyte quality reduction and early embryo mortality in various in vivo studies. In this study, we investigated the mechanism of Cd-induced mitochondrial toxicity in bovine in vitro matured oocytes, primary cultured bovine cumulus cells, and in vitro developed bovine embryos. Cd significantly reduced PPARGC1A (PGC-1a) and nuclear respiratory factors, which leads to mitochondrial damage and hence reduction in oocyte maturation and embryo development. NAD-dependent deacetylase sirtuin-1 (SIRT1) is the upstream marker of PGC-1a and nuclear respiratory factors, and its activation significantly mitigated Cd-induced mitochondrial damage. For SIRT1 activation, we used Hesperetin (Hsp), a citrus flavonoid and a potent activator of SIRT1. The molecular docking approach was used to investigate the binding of hesperetin to bovine SIRT1, which revealed that hesperetin creates polar and non-polar interactions with residues that are reported essential for the activation of SIRT1. Furthermore, the SIRT1 enzymatic activity was measured in primary cultured bovine granulosa cells after hesperetin treatment. To further confirm the SIRT1-dependent effects of hesperetin we used a specific inhibitor of SIRT1 (EX527), which significantly (p < 0.05) reduced the effects of hesperetin on embryo mitochondria. Next, we treated hesperetin and Cd to early bovine embryos and discovered a significant (p 0.05) increase in PGC-1, NRF1, and NFE2L2 protein expression as well as embryo development recovery. Thus, we came to the conclusion that hesperetin can activate PGC-1 and nuclear respiratory factors via SIRT1, which can greatly reduce Cd-induced mitochondrial toxicity and promote mitochondrial biogenesis in early bovine embryos.(c) 2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",0093-691X,1879-3231,,209-221, , ,,out_of_scope,
4277,"Title:Aging-Aware Training for Printed Neuromorphic Circuits

 Printed electronics allow for ultra-low-cost circuit fabrication with unique properties such as flexibility, non-toxicity, and stretchability. Because of these advanced properties, there is a growing interest in adapting printed electronics for emerging areas such as fast-moving consumer goods and wearable technologies. In such domains, analog signal processing in or near the sensor is favorable. Printed neuromorphic circuits have been recently proposed as a solution to perform such analog processing natively. Additionally, their learning-based design process allows high efficiency of their optimization and enables them to mitigate the high process variations associated with low-cost printed processes. In this work, we address the aging of the printed components. This effect can significantly degrade the accuracy of printed neuromorphic circuits over time. For this, we develop a stochastic aging-model to describe the behavior of aged printed resistors and modify the training objective by considering the expected loss over the lifetime of the device. This approach ensures to provide acceptable accuracy over the device lifetime. Our experiments show that an overall 35.8% improvement in terms of expected accuracy over the device lifetime can be achieved using the proposed learning approach.","Zhao, Haibin; Hefenbrock, Michael; Beigl, Michael; Tahoori, Mehdi B.",,"Zhao, Haibin/0000-0001-7018-1159",Aging-Aware Training for Printed Neuromorphic Circuits,,,10.1145/3508352.3549411 ,Proceedings Paper ,2022.0,"Printed electronics allow for ultra-low-cost circuit fabrication with unique properties such as flexibility, non-toxicity, and stretchability. Because of these advanced properties, there is a growing interest in adapting printed electronics for emerging areas such as fast-moving consumer goods and wearable technologies. In such domains, analog signal processing in or near the sensor is favorable. Printed neuromorphic circuits have been recently proposed as a solution to perform such analog processing natively. Additionally, their learning-based design process allows high efficiency of their optimization and enables them to mitigate the high process variations associated with low-cost printed processes. In this work, we address the aging of the printed components. This effect can significantly degrade the accuracy of printed neuromorphic circuits over time. For this, we develop a stochastic aging-model to describe the behavior of aged printed resistors and modify the training objective by considering the expected loss over the lifetime of the device. This approach ensures to provide acceptable accuracy over the device lifetime. Our experiments show that an overall 35.8% improvement in terms of expected accuracy over the device lifetime can be achieved using the proposed learning approach.",1933-7760,,978-1-4503-9217-4,, , IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD),,out_of_scope,
4278,"Title:Selenium alleviates biological toxicity of thiamethoxam (TMX): Bioaccumulation of TMX, organ damage, and antioxidant response of red swamp crayfish (Procambarus clarkii)

 Pesticides are important for agricultural development; however, animals involved in rice-fish farming absorb the pesticides used during the farming process. Thiamethoxam (TMX) is extensively used in agriculture and is gradually occupying the market for traditional pesticides. Therefore, this study aimed to investigate whether selenomethionine (SeMet) could affect the survival rate, bioaccumulation of TMX, serum biochemical parameters, lipid peroxidation, antioxidants in the hepatopancreas, and expression of stress genes after exposure of red swamp crayfish to 10 ppt TMX for 7 days. The results showed that the survival rate significantly increased and the bioaccumulation of TMX significantly decreased with SeMet administration (P < 0.05). Furthermore, severe histological damage to the hepatopancreas of red crayfish was observed after exposure to TMX; however, this damage was alleviated after SeMet administration. SeMet also significantly reduced the TMX-induced changes in serum biochemical parameters, malondialdehyde content, and antioxidant enzyme activity in crayfish hepatopancreas (P < 0.05). Notably, analysis of the expression of 10 stress response genes showed that 0.5 mg/kg SeMet might decrease cell damage in the hepatopancreas. Consequently, our findings suggest that higher levels of TMX in crayfish may cause hepatopancreatic cell toxicity, which can be harmful to human health; however, SeMet could mitigate these effects, providing an understanding of pesticide compounds and food safety.","Zhang, Yan-Mei; Xu, Wen-Bin; Lin, Chen-Yang; Li, Bang-Ze; Shu, Miao-An",,"Shu, Miao-An/0000-0002-6035-0251","Selenium alleviates biological toxicity of thiamethoxam (TMX): Bioaccumulation of TMX, organ damage, and antioxidant response of red swamp crayfish (Procambarus clarkii)",458,,10.1016/j.jhazmat.2023.131896 ,Article ,2023.0,"Pesticides are important for agricultural development; however, animals involved in rice-fish farming absorb the pesticides used during the farming process. Thiamethoxam (TMX) is extensively used in agriculture and is gradually occupying the market for traditional pesticides. Therefore, this study aimed to investigate whether selenomethionine (SeMet) could affect the survival rate, bioaccumulation of TMX, serum biochemical parameters, lipid peroxidation, antioxidants in the hepatopancreas, and expression of stress genes after exposure of red swamp crayfish to 10 ppt TMX for 7 days. The results showed that the survival rate significantly increased and the bioaccumulation of TMX significantly decreased with SeMet administration (P < 0.05). Furthermore, severe histological damage to the hepatopancreas of red crayfish was observed after exposure to TMX; however, this damage was alleviated after SeMet administration. SeMet also significantly reduced the TMX-induced changes in serum biochemical parameters, malondialdehyde content, and antioxidant enzyme activity in crayfish hepatopancreas (P < 0.05). Notably, analysis of the expression of 10 stress response genes showed that 0.5 mg/kg SeMet might decrease cell damage in the hepatopancreas. Consequently, our findings suggest that higher levels of TMX in crayfish may cause hepatopancreatic cell toxicity, which can be harmful to human health; however, SeMet could mitigate these effects, providing an understanding of pesticide compounds and food safety.",0304-3894,1873-3336,,, , ,,out_of_scope,
4279,"Title:Effect of beeswax waste biochar on growth, physiology and cadmium uptake in saffron

 Saffron (Crocus sativus L.) is a medicinal important plant with none information on cadmium (Cd) phytotoxicity. Therefore, this study for the first time elevated the effects of beeswax waste biochar (a novel organic amendment) on Cd uptake, biomass, antioxidant enzymes activities and some physiobiochemical characteristics in saffron exposed to Cd stress. The treatments were consisted four Cd concentrations (0, 3, 6 and 9 mg kg(-1) soil) together with four biochar levels (0%, 1.5%, 3.0% and 6% w/w). The results showed that Cd uptake in saffron corm and leaf tissues was significantly elevated by increase in Cd stress, but this parameter in flower and stigma (as edible part of saffron) was unchanged. Application of Cd caused decrease in plant biomass which was found to recover with the amendment of biochar. The translocation factor values were less than 1 in all the treatments, demonstrating saffron can be considered as a candidate plant for cadmium phytostabilization. Cadmium-induced oxidative stress stimulated malondialdehyde content, and activity of superoxide dismutase, ascorbate peroxidase, catalase and glutathione reductase enzymes, while biochar application alleviated the oxidative damages. Crocin component was significantly raised along with increase in Cd concentration. Meanwhile, biochar application declined crocin and increased picrocrocin contents. In conclusion, beeswax waste biochar can mitigate Cd toxicity in saffron by inducing soil alkalinization, immobilizing Cd in soil, reducing Cd partitioning in the aboveground tissues and regulating Cd induced oxidative damage, consequently contributing to lowering the potential risks of Cd pollution. (C) 2019 Elsevier Ltd. All rights reserved.","Moradi, Rooholla; Pourghasemian, Nasibeh; Naghizadeh, Mehdi","Naghizadeh/AAU-5169-2020; Moradi, Rooholla/AAV-7727-2021; Pourghasemian, Nasibeh/AAC-2942-2022","Naghizadeh/0000-0001-9815-7062; Moradi, Rooholla/0000-0001-8754-8025","Effect of beeswax waste biochar on growth, physiology and cadmium uptake in saffron",229,,10.1016/j.jclepro.2019.05.047 ,Article ,2019.0,"Saffron (Crocus sativus L.) is a medicinal important plant with none information on cadmium (Cd) phytotoxicity. Therefore, this study for the first time elevated the effects of beeswax waste biochar (a novel organic amendment) on Cd uptake, biomass, antioxidant enzymes activities and some physiobiochemical characteristics in saffron exposed to Cd stress. The treatments were consisted four Cd concentrations (0, 3, 6 and 9 mg kg(-1) soil) together with four biochar levels (0%, 1.5%, 3.0% and 6% w/w). The results showed that Cd uptake in saffron corm and leaf tissues was significantly elevated by increase in Cd stress, but this parameter in flower and stigma (as edible part of saffron) was unchanged. Application of Cd caused decrease in plant biomass which was found to recover with the amendment of biochar. The translocation factor values were less than 1 in all the treatments, demonstrating saffron can be considered as a candidate plant for cadmium phytostabilization. Cadmium-induced oxidative stress stimulated malondialdehyde content, and activity of superoxide dismutase, ascorbate peroxidase, catalase and glutathione reductase enzymes, while biochar application alleviated the oxidative damages. Crocin component was significantly raised along with increase in Cd concentration. Meanwhile, biochar application declined crocin and increased picrocrocin contents. In conclusion, beeswax waste biochar can mitigate Cd toxicity in saffron by inducing soil alkalinization, immobilizing Cd in soil, reducing Cd partitioning in the aboveground tissues and regulating Cd induced oxidative damage, consequently contributing to lowering the potential risks of Cd pollution. (C) 2019 Elsevier Ltd. All rights reserved.",0959-6526,1879-1786,,1251-1261, , ,,out_of_scope,
4280,"Title:Investigation on the antimicrobial properties of cerium-doped bioactive glasses

 Cerium-doped bioactive glasses (Ce-BGs) are implant materials that present high biocompatibility, modulate the levels of reactive oxygen species, and exert antimicrobial activity. The potential of BGs, 45S5, and K50S derived glasses doped with CeO2 (1.2, 3.6, and 5.3 mol%) to inhibit the growth of pathogen microbes was thoroughly investigated according to the ISO 22196:2011 method properly adapted. A significant reduction of the E. coli charge was detected in all glasses, including the BGs without cerium. The evolution of pH of the medium not inoculated following the immersion of the Ce-BGs was monitored. The presence of cerium did not affect markedly the pH trend, which increased rapidly for both compositions. The change of pH was strongly mitigated by the presence of 200 mM phosphate buffer pH 7.0 (PB) in the medium. In media buffered by PB, the growth of E. coli, Pseudomonas aeruginosa, Listeria monocytogenes, Staphylococcus aureus, and C. albicans was not affected by the presence of BGs doped or not with cerium, suggesting that the antibacterial activity of Ce-BGs is linked to the increase of environmental pH rather than to specific ion effects. However, Ce-BGs resulted promising biomaterials that associate low toxicity to normal cells to a considerable antimicrobial effect, albeit the latter is not directly associated with the presence of cerium.","Raimondi, Stefano; Zambon, Alfonso; Ranieri, Raffaella; Fraulini, Francesca; Amaretti, Alberto; Rossi, Maddalena; Lusvardi, Gigliola","Lusvardi, Gigliola/L-6941-2015; Zambon, Alfonso/AFC-3324-2022; ranieri, raffaella/HMO-6774-2023; Rossi, Maddalena/F-1351-2015","Lusvardi, Gigliola/0000-0002-0772-6037; Zambon, Alfonso/0000-0002-8074-2308; Fraulini, Francesca/0000-0003-1261-8644; Rossi, Maddalena/0000-0002-5342-3950; Ranieri, Raffaella/0000-0003-2532-0812",Investigation on the antimicrobial properties of cerium-doped bioactive glasses,,,10.1002/jbm.a.37289 ,Article; Early Access ,,"Cerium-doped bioactive glasses (Ce-BGs) are implant materials that present high biocompatibility, modulate the levels of reactive oxygen species, and exert antimicrobial activity. The potential of BGs, 45S5, and K50S derived glasses doped with CeO2 (1.2, 3.6, and 5.3 mol%) to inhibit the growth of pathogen microbes was thoroughly investigated according to the ISO 22196:2011 method properly adapted. A significant reduction of the E. coli charge was detected in all glasses, including the BGs without cerium. The evolution of pH of the medium not inoculated following the immersion of the Ce-BGs was monitored. The presence of cerium did not affect markedly the pH trend, which increased rapidly for both compositions. The change of pH was strongly mitigated by the presence of 200 mM phosphate buffer pH 7.0 (PB) in the medium. In media buffered by PB, the growth of E. coli, Pseudomonas aeruginosa, Listeria monocytogenes, Staphylococcus aureus, and C. albicans was not affected by the presence of BGs doped or not with cerium, suggesting that the antibacterial activity of Ce-BGs is linked to the increase of environmental pH rather than to specific ion effects. However, Ce-BGs resulted promising biomaterials that associate low toxicity to normal cells to a considerable antimicrobial effect, albeit the latter is not directly associated with the presence of cerium.",1549-3296,1552-4965,,, , ,,out_of_scope,
4281,"Title:Global disposal strategies for waste cathode ray tubes

 The collection and management of waste electrical and electronic appliances around the world, and the possible negative environmental consequences have been an issue of current debate. Cathode ray tubes (CRTs) used as display screen for computer monitors and televisions contains large quantities of lead, estimated at between 0.5 and 4 kg, depending on the size of the CRT and has been identified as the most polluting of all electronic waste components. Having failed the tests used in the toxicity characterization of solid wastes, CRTs have been declared 'hazardous' and subsequently banned from landfills and incinerators in most developed countries. Presently, large quantities of CRTs are generated globally with only few developed countries having effective take back and sound management program. Meanwhile, large quantities of CRT-containing devices are being moved across frontiers into developing countries in the name of 'reuse' and 'bridging the digital divide'. With near absence of recycling infrastructure for electronic wastes in most developing countries, waste CRTs are disposed of with MSW at open dumps and unsanitary landfills. This paper reviews the current practices in the management of CRTs around the world, with emphasis on the role of regulations, availability of recycling infrastructure, recycling/reuse routes, and export into developing countries. Inappropriate disposal of waste CRTs creates the opportunity for large-scale environmental contamination with heavy metals, especially lead. Appropriate disposal routes are required globally in the management of CRTs in order to mitigate environmental contamination and human exposure to toxins. (C) 2010 Elsevier B.V. All rights reserved.","Nnorom, I. C.; Osibanjo, O.; Ogwuegbu, M. O. C.","NNOROM, INNOCENT Chidi/E-4804-2016","NNOROM, INNOCENT Chidi/0000-0001-8801-8931",Global disposal strategies for waste cathode ray tubes,55,3,10.1016/j.resconrec.2010.10.007 ,Review ,2011.0,"The collection and management of waste electrical and electronic appliances around the world, and the possible negative environmental consequences have been an issue of current debate. Cathode ray tubes (CRTs) used as display screen for computer monitors and televisions contains large quantities of lead, estimated at between 0.5 and 4 kg, depending on the size of the CRT and has been identified as the most polluting of all electronic waste components. Having failed the tests used in the toxicity characterization of solid wastes, CRTs have been declared 'hazardous' and subsequently banned from landfills and incinerators in most developed countries. Presently, large quantities of CRTs are generated globally with only few developed countries having effective take back and sound management program. Meanwhile, large quantities of CRT-containing devices are being moved across frontiers into developing countries in the name of 'reuse' and 'bridging the digital divide'. With near absence of recycling infrastructure for electronic wastes in most developing countries, waste CRTs are disposed of with MSW at open dumps and unsanitary landfills. This paper reviews the current practices in the management of CRTs around the world, with emphasis on the role of regulations, availability of recycling infrastructure, recycling/reuse routes, and export into developing countries. Inappropriate disposal of waste CRTs creates the opportunity for large-scale environmental contamination with heavy metals, especially lead. Appropriate disposal routes are required globally in the management of CRTs in order to mitigate environmental contamination and human exposure to toxins. (C) 2010 Elsevier B.V. All rights reserved.",0921-3449,1879-0658,,275-290, , ,,out_of_scope,
4282,"Title:Rhizobacteria and plant symbiosis in heavy metal uptake and its implications for soil bioremediation

 Certain species of plants can benefit from synergistic effects with plant growth-promoting rhizobacteria (PGPR) that improve plant growth and metal accumulation, mitigating toxic effects on plants and increasing their tolerance to heavy metals. The application of PGPR as biofertilizers and atmospheric nitrogen fixators contributes considerably to the intensification of the phytoremediation process. In this paper, we have built a system consisting of rhizospheric Azotobacter microbial populations and Lepidium sativum plants, growing in solutions containing heavy metals in various concentrations. We examined the ability of the organisms to grow in symbiosis so as to stimulate the plant growth and enhance its tolerance to Cr(VI) and Cd(II), to ultimately provide a reliable phytoremediation system. The study was developed at the laboratory level and, at this stage, does not assess the inherent interactions under real conditions occurring in contaminated fields with autochthonous microflora and under different pedoclimatic conditions and environmental stresses. Azotobacter sp. bacteria could indeed stimulate the average germination efficiency of Lepidium sativum by almost 7%, average root length by 22%, average stem length by 34% and dry biomass by 53%. The growth of L. sativum has been affected to a greater extent in Cd(II) solutions due its higher toxicity compared to that of Cr(VI). The reduced tolerance index (TI, %) indicated that plant growth in symbiosis with PGPR was however affected by heavy metal toxicity, while the tolerance of the plant to heavy metals was enhanced in the bacteria-plant system.A methodology based on artificial neural networks (ANNs) and differential evolution (DE), specifically a neuro-evolutionary approach, was applied to model germination rates, dry biomass and root/stem length and proving the robustness of the experimental data. The errors associated with all four variables are small and the correlation coefficients higher than 0.98, which indicate that the selected models can efficiently predict the experimental data. (C) 2016 Published by Elsevier B. V.","Sobariu, Dana Luminita; Fertu, Daniela Ionela Tudorache; Diaconu, Mariana; Pavel, Lucian Vasile; Hlihor, Raluca-Maria; Dragoi, Elena Niculina; Curteanu, Silvia; Lenz, Markus; Corvinid, Philippe Francois-Xavier; Gavrilescu, Maria","Gavrilescu, Maria/F-9265-2014; Dragoi, Elena Niculina/D-6256-2011; Hlihor, Raluca Maria/I-5228-2016; Curteanu, Silvia/D-7347-2011; Hlihor, Raluca Maria/ABG-4706-2020; Lenz, Markus/AAN-7142-2020","Gavrilescu, Maria/0000-0002-0663-0316; Dragoi, Elena Niculina/0000-0001-5006-000X; Hlihor, Raluca Maria/0000-0003-2428-3669; Curteanu, Silvia/0000-0002-5281-1265; Hlihor, Raluca Maria/0000-0003-2428-3669; Lenz, Markus/0000-0001-6832-3218",Rhizobacteria and plant symbiosis in heavy metal uptake and its implications for soil bioremediation,39,,10.1016/j.nbt.2016.09.002 ,Article ,2017.0,"Certain species of plants can benefit from synergistic effects with plant growth-promoting rhizobacteria (PGPR) that improve plant growth and metal accumulation, mitigating toxic effects on plants and increasing their tolerance to heavy metals. The application of PGPR as biofertilizers and atmospheric nitrogen fixators contributes considerably to the intensification of the phytoremediation process. In this paper, we have built a system consisting of rhizospheric Azotobacter microbial populations and Lepidium sativum plants, growing in solutions containing heavy metals in various concentrations. We examined the ability of the organisms to grow in symbiosis so as to stimulate the plant growth and enhance its tolerance to Cr(VI) and Cd(II), to ultimately provide a reliable phytoremediation system. The study was developed at the laboratory level and, at this stage, does not assess the inherent interactions under real conditions occurring in contaminated fields with autochthonous microflora and under different pedoclimatic conditions and environmental stresses. Azotobacter sp. bacteria could indeed stimulate the average germination efficiency of Lepidium sativum by almost 7%, average root length by 22%, average stem length by 34% and dry biomass by 53%. The growth of L. sativum has been affected to a greater extent in Cd(II) solutions due its higher toxicity compared to that of Cr(VI). The reduced tolerance index (TI, %) indicated that plant growth in symbiosis with PGPR was however affected by heavy metal toxicity, while the tolerance of the plant to heavy metals was enhanced in the bacteria-plant system.A methodology based on artificial neural networks (ANNs) and differential evolution (DE), specifically a neuro-evolutionary approach, was applied to model germination rates, dry biomass and root/stem length and proving the robustness of the experimental data. The errors associated with all four variables are small and the correlation coefficients higher than 0.98, which indicate that the selected models can efficiently predict the experimental data. (C) 2016 Published by Elsevier B. V.",1871-6784,1876-4347,,125-134, , ,,out_of_scope,
4283,"Title:Cerium oxide NPs mitigate the amyloid formation of α-synuclein and associated cytotoxicity

 Aim: Among therapeutic proposals for amyloid-associated disorders, special attention has been given to the exploitation of nanoparticles (NPs) as promising agents against aggregation.Methods: In this paper, the inhibitory effect of cerium oxide (CeO2) NPs against alpha-synuclein (alpha-syn) amyloid formation was explored by different methods such as Thioflavin T (ThT) and 8-anilinonaphthalene- 1 -sulfonic acid (ANS) fluorescence spectroscopy, Congo red adsorption assay, circular dichroism (CD) spectroscopy, transmission electron microscopy (TEM), and bioinformatical approaches. Also, the cytotoxicity of alpha-syn amyloid either alone or with CeO2 NPs against neuron-like cells (SH-SY5Y) was examined using 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT), flow cytometry, and quantitative real-time polymerase chain reaction (Bax and Bcl-2 gene expression) assays.Results: ThT and ANS fluorescence assays indicated that CeO2 NPs inhibit the formation of aggregated species and hydrophobic patches of alpha-syn in amyloidogenic conditions, respectively. Congo red and CD assays demonstrated that CeO2 NPs reduce the formation of amyloid species and beta-sheets structures of alpha-syn molecules, respectively. TEM investigation also confirmed that CeO2 NPs limited the formation of well-defined fibrillary structures of alpha-syn molecules. Molecular docking and dynamic studies revealed that CeO2 NPs could bind with different affinities to alpha-syn monomer and amyloid species and fibrillar structure of alpha-syn is disaggregated in the presence of CeO2 NPs. Moreover, cellular assays depicted that CeO2 NPs mitigate the cell mortality, apoptosis, and the ratio of Bax/Bcl-2 gene expression associated with alpha-syn amyloids.Conclusion: It may be concluded that CeO2 NPs can be used as therapeutic agents to reduce the aggregation of proteins and mitigate the occurrence of neurodegenerative diseases.","Zand, Zahra; Khaki, Pegah Afarinesh; Salihi, Abbas; Sharifi, Majid; Nanakali, Nadir Mustafa Qadir; Alasady, Asaad A. B.; Aziz, Falah Mohammad; Shahpasand, Koorosh; Hasan, Anwarul; Falahati, Mojtaba","Salihi, Abbas/V-1354-2019; Falahati, Mojtaba/AAN-6507-2021; Sharifi, Majid/AAD-8050-2020; Hasan, Anwarul/AAX-7440-2020; Salihi, Abbas/GPT-0420-2022","Salihi, Abbas/0000-0002-1342-2849; Sharifi, Majid/0000-0002-1546-7864; Hasan, Anwarul/0000-0001-8380-2233;",Cerium oxide NPs mitigate the amyloid formation of α-synuclein and associated cytotoxicity,14,,10.2147/IJN.S220380 ,Article ,2019.0,"Aim: Among therapeutic proposals for amyloid-associated disorders, special attention has been given to the exploitation of nanoparticles (NPs) as promising agents against aggregation.Methods: In this paper, the inhibitory effect of cerium oxide (CeO2) NPs against alpha-synuclein (alpha-syn) amyloid formation was explored by different methods such as Thioflavin T (ThT) and 8-anilinonaphthalene- 1 -sulfonic acid (ANS) fluorescence spectroscopy, Congo red adsorption assay, circular dichroism (CD) spectroscopy, transmission electron microscopy (TEM), and bioinformatical approaches. Also, the cytotoxicity of alpha-syn amyloid either alone or with CeO2 NPs against neuron-like cells (SH-SY5Y) was examined using 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT), flow cytometry, and quantitative real-time polymerase chain reaction (Bax and Bcl-2 gene expression) assays.Results: ThT and ANS fluorescence assays indicated that CeO2 NPs inhibit the formation of aggregated species and hydrophobic patches of alpha-syn in amyloidogenic conditions, respectively. Congo red and CD assays demonstrated that CeO2 NPs reduce the formation of amyloid species and beta-sheets structures of alpha-syn molecules, respectively. TEM investigation also confirmed that CeO2 NPs limited the formation of well-defined fibrillary structures of alpha-syn molecules. Molecular docking and dynamic studies revealed that CeO2 NPs could bind with different affinities to alpha-syn monomer and amyloid species and fibrillar structure of alpha-syn is disaggregated in the presence of CeO2 NPs. Moreover, cellular assays depicted that CeO2 NPs mitigate the cell mortality, apoptosis, and the ratio of Bax/Bcl-2 gene expression associated with alpha-syn amyloids.Conclusion: It may be concluded that CeO2 NPs can be used as therapeutic agents to reduce the aggregation of proteins and mitigate the occurrence of neurodegenerative diseases.",1178-2013,,,6989-7000, , ,,out_of_scope,
4284,"Title:An overlooked source of nanosized lead particles in the atmosphere: Residential honeycomb briquette combustion

 Atmospheric lead (Pb) pollution has attracted long-term and widespread concerns due to its high toxicity. The definite source identification of atmospheric Pb is the key step to mitigate this pollution. Here, we first report an overlooked source of atmospheric nanosized Pb particles using transmission electron microscopy and bulk sample analyses, finding that residential honeycomb briquette combustion emits large numbers of nanosized Pbrich particles. We found that 33.7 +/- 19.9 % of primary particles by number from residential honeycomb briquette combustion contains the crystalline Pb particles. These Pb-rich particles range in size from 14 to 956 nm with a mean diameter of 117 nm. Compared with raw coal chunks, honeycomb briquette combustion could emit less carbonaceous particles, but largely increase nanosized Pb particle emissions. This result is attributed to two key factors: (1) higher Pb content in honeycomb briquette (63.6 mu g g- 1) than that in coal chunk (8.5 mu g g-1), and (2) higher Pb release rate for honeycomb briquette (62.3 %) caused by honeycomb structure than that for coal chunk (20.1 %). This study highlights that atmospheric and health implications of high emissions of toxic nanosized Pb from honeycomb briquette should be paid more attention in future research on ambient and indoor airs.","Zhang, Yinxiao; Kong, Shaofei; Yan, Qin; Zhu, Kongyang; Jiang, Xiaotong; Liu, Lei; Xu, Liang; Wang, Yuanyuan; Pang, Yuner; Teng, Xiaomi; Zhu, Jihao; Li, Weijun","Li, WeiJun/GRE-7310-2022; Xu, Liang/HGU-1836-2022; zhang, yue/JAC-3705-2023; wang, yu/IUQ-6654-2023; Wang, Yuan/HHC-1520-2022; WANG, YUANYUAN/IQR-4295-2023; Wang, Yuan/GRF-3621-2022; Wang, Yu/GZL-9655-2022; jiang, xiaotong/P-7926-2016; Zhang, Yinxiao/S-6745-2019; wangwangwang, yuanyaunyuan/HHN-6432-2022; Kong, Shaofei/I-7015-2012","Li, WeiJun/0000-0003-3341-9265; jiang, xiaotong/0000-0003-0954-5480;",An overlooked source of nanosized lead particles in the atmosphere: Residential honeycomb briquette combustion,436,,10.1016/j.jhazmat.2022.129289 ,Article ,2022.0,"Atmospheric lead (Pb) pollution has attracted long-term and widespread concerns due to its high toxicity. The definite source identification of atmospheric Pb is the key step to mitigate this pollution. Here, we first report an overlooked source of atmospheric nanosized Pb particles using transmission electron microscopy and bulk sample analyses, finding that residential honeycomb briquette combustion emits large numbers of nanosized Pbrich particles. We found that 33.7 +/- 19.9 % of primary particles by number from residential honeycomb briquette combustion contains the crystalline Pb particles. These Pb-rich particles range in size from 14 to 956 nm with a mean diameter of 117 nm. Compared with raw coal chunks, honeycomb briquette combustion could emit less carbonaceous particles, but largely increase nanosized Pb particle emissions. This result is attributed to two key factors: (1) higher Pb content in honeycomb briquette (63.6 mu g g- 1) than that in coal chunk (8.5 mu g g-1), and (2) higher Pb release rate for honeycomb briquette (62.3 %) caused by honeycomb structure than that for coal chunk (20.1 %). This study highlights that atmospheric and health implications of high emissions of toxic nanosized Pb from honeycomb briquette should be paid more attention in future research on ambient and indoor airs.",0304-3894,1873-3336,,, , ,,out_of_scope,
4285,"Title:Integrating remote sensing, geographic information system, and analytical hierarchy process for hazardous waste landfill site selection

 This paper describes a method for identifying places for safe disposal of hazardous waste materials in the Egyptian Suez Canal Corridor. Hazardous waste is defined as a material that poses a threat to public health and the environment because of its ignitability, reactivity, corrosively, or toxicity. Industrial zones of the Suez Canal corridor produce large amounts of hazardous waste. To mitigate the deleterious impact of hazardous waste, it should be disposed of in an environmentally safe process. This includes selecting a site that will not contaminate groundwater, create dust, and noise in residential neighborhoods and has the capacity to last at least 10years. The standards used in this paper were established at the Basel Hazardous Waste Convention in 1992. They include social, economic, environmental, geological, hydrological, and geomorphological variables. Geographic information systems (GIS) and remote sensing were used to prepare a geospatial database representing the Basal Convention criteria for the study site. The information required to build the geospatial database were collected through field surveys, interpretation of satellite images, and from previous published scientific research. The criteria were weighted based on their roles and importance. Based on the weighted criteria, an analytical hierarchy process (AHP) was used to select the most environmentally sound sites. Through the AHP, two suitable sites were identified as being suitable for hazardous waste disposal.","Abd-El Monsef, Hesham; Smith, Scot E.","Abd-El Monsef, Hesham/GLU-7701-2022","Abd-El Monsef, Hesham/0000-0003-0072-7093","Integrating remote sensing, geographic information system, and analytical hierarchy process for hazardous waste landfill site selection",12,5,10.1007/s12517-019-4266-7 ,Article ,2019.0,"This paper describes a method for identifying places for safe disposal of hazardous waste materials in the Egyptian Suez Canal Corridor. Hazardous waste is defined as a material that poses a threat to public health and the environment because of its ignitability, reactivity, corrosively, or toxicity. Industrial zones of the Suez Canal corridor produce large amounts of hazardous waste. To mitigate the deleterious impact of hazardous waste, it should be disposed of in an environmentally safe process. This includes selecting a site that will not contaminate groundwater, create dust, and noise in residential neighborhoods and has the capacity to last at least 10years. The standards used in this paper were established at the Basel Hazardous Waste Convention in 1992. They include social, economic, environmental, geological, hydrological, and geomorphological variables. Geographic information systems (GIS) and remote sensing were used to prepare a geospatial database representing the Basal Convention criteria for the study site. The information required to build the geospatial database were collected through field surveys, interpretation of satellite images, and from previous published scientific research. The criteria were weighted based on their roles and importance. Based on the weighted criteria, an analytical hierarchy process (AHP) was used to select the most environmentally sound sites. Through the AHP, two suitable sites were identified as being suitable for hazardous waste disposal.",1866-7511,1866-7538,,, , ,,out_of_scope,
4286,"Title:Dispersing Zwitterions into Comb Polymers for Nonviral Transfection: Experiments and Molecular Simulation

 Polymer-based gene delivery vehicles benefit from the presence of hydrophilic groups that mitigate the inherent toxicity of polycations and that provide tunable polymer-DNA binding strength and stable complexes (polyplexes). However, hydrophilic groups screen charge, and as such can reduce cell uptake and transfection efficiency. We report the effect of embedding zwitterionic sulfobetaine (SB) groups in cationic comb polymers, using a combination of experiments and molecular simulations. Ring-opening metathesis polymerization (ROMP) produced comb polymers with tetralysine (K4) and SB pendent groups. Dynamic light scattering, zeta potential measurements, and fluorescence-based experiments, together with coarse grained molecular dynamics simulations, described the effect of SB groups on the size, shape, surface charge, composition, and DNA binding strength of polyplexes formed using these comb polymers. Experiments and simulations showed that increasing SB composition in the comb polymers decreased polymer-DNA binding strength, while simulations indicated that the SB groups distributed throughout the polyplex. This allows polyplexes to maintain a positive surface charge and provide high levels of gene expression in live cells. Notably, comb polymers with nearly 50 mol % SB form polyplexes that exhibit positive surface charge similarly as polyplexes formed from purely cationic comb polymers, indicating the ability to introduce an appreciable amount of SB functionality without screening surface charge. This integrated simulation-experimental study demonstrates the effectiveness of incorporating zwitterions in polyplexes, while guiding the design of new and effective gene delivery vectors.","Ghobadi, Ahmadreza F.; Letteri, Rachel; Parelkar, Sangram S.; Zhao, Yue; Chan-Seng, Delphine; Emrick, Todd; Jayaraman, Arthi","Letteri, Rachel A/T-7525-2017; Chan-Seng, Delphine/A-1310-2012","Letteri, Rachel A/0000-0002-2919-203X; Chan-Seng, Delphine/0000-0003-3508-2491; Zhao, Yue/0000-0001-5100-9230",Dispersing Zwitterions into Comb Polymers for Nonviral Transfection: Experiments and Molecular Simulation,17,2,10.1021/acs.biomac.5b01462 ,Article ,2016.0,"Polymer-based gene delivery vehicles benefit from the presence of hydrophilic groups that mitigate the inherent toxicity of polycations and that provide tunable polymer-DNA binding strength and stable complexes (polyplexes). However, hydrophilic groups screen charge, and as such can reduce cell uptake and transfection efficiency. We report the effect of embedding zwitterionic sulfobetaine (SB) groups in cationic comb polymers, using a combination of experiments and molecular simulations. Ring-opening metathesis polymerization (ROMP) produced comb polymers with tetralysine (K4) and SB pendent groups. Dynamic light scattering, zeta potential measurements, and fluorescence-based experiments, together with coarse grained molecular dynamics simulations, described the effect of SB groups on the size, shape, surface charge, composition, and DNA binding strength of polyplexes formed using these comb polymers. Experiments and simulations showed that increasing SB composition in the comb polymers decreased polymer-DNA binding strength, while simulations indicated that the SB groups distributed throughout the polyplex. This allows polyplexes to maintain a positive surface charge and provide high levels of gene expression in live cells. Notably, comb polymers with nearly 50 mol % SB form polyplexes that exhibit positive surface charge similarly as polyplexes formed from purely cationic comb polymers, indicating the ability to introduce an appreciable amount of SB functionality without screening surface charge. This integrated simulation-experimental study demonstrates the effectiveness of incorporating zwitterions in polyplexes, while guiding the design of new and effective gene delivery vectors.",1525-7797,1526-4602,,546-557, , ,,out_of_scope,
4287,"Title:The Meaning and Measurement of Bias: Lessons from Natural Language Processing

 The recent interest in identifying and mitigating bias in computational systems has introduced a wide range of different-and occasionally incomparable-proposals for what constitutes bias in such systems. This tutorial introduces the language of measurement modeling from the quantitative social sciences as a framework for examining how social, organizational, and political values enter computational systems and unpacking the varied normative concerns operationalized in different techniques for measuring bias. We showthat this framework helps to clarify the way unobservable theoretical constructs-such as creditworthiness, risk to society, or tweet toxicity-are turned into measurable quantities and how this process may introduce fairness-related harms. In particular, we demonstrate howto systematically assess the construct validity and reliability of these measurements to detect and characterize specific types of harms, which arise from mismatches between constructs and their operationalizations. We then take a critical look at existing approaches to examining bias in NLP models, ranging from work on embedding spaces to machine translation and hate speech detection. We show that measurement modeling can help uncover the implicit constructs that suchwork aims to capture when measuring bias. In so doing, we illustrate the limits of current debiasing techniques, which have obscured the specific harms whose measurements they implicitly aim to reduce. By introducing the language of measurement modeling, we provide the FAT* community with a framework for making explicit and testing assumptions about unobservable theoretical constructs embedded in computational systems, thereby clarifying and uniting our understandings of fairness-related harms.","Jacobs, Abigail Z.; Blodgett, Su Lin; Barocas, Solon; Daume, Hal, III; Wallach, Hanna",,,The Meaning and Measurement of Bias: Lessons from Natural Language Processing,,,10.1145/3351095.3375671 ,Proceedings Paper ,2020.0,"The recent interest in identifying and mitigating bias in computational systems has introduced a wide range of different-and occasionally incomparable-proposals for what constitutes bias in such systems. This tutorial introduces the language of measurement modeling from the quantitative social sciences as a framework for examining how social, organizational, and political values enter computational systems and unpacking the varied normative concerns operationalized in different techniques for measuring bias. We showthat this framework helps to clarify the way unobservable theoretical constructs-such as creditworthiness, risk to society, or tweet toxicity-are turned into measurable quantities and how this process may introduce fairness-related harms. In particular, we demonstrate howto systematically assess the construct validity and reliability of these measurements to detect and characterize specific types of harms, which arise from mismatches between constructs and their operationalizations. We then take a critical look at existing approaches to examining bias in NLP models, ranging from work on embedding spaces to machine translation and hate speech detection. We show that measurement modeling can help uncover the implicit constructs that suchwork aims to capture when measuring bias. In so doing, we illustrate the limits of current debiasing techniques, which have obscured the specific harms whose measurements they implicitly aim to reduce. By introducing the language of measurement modeling, we provide the FAT* community with a framework for making explicit and testing assumptions about unobservable theoretical constructs embedded in computational systems, thereby clarifying and uniting our understandings of fairness-related harms.",,,978-1-4503-6936-7,706-706, ," ACM Conference on Fairness, Accountability, and Transparency (FAT)ACM Conference on Fairness, Accountability, and Transparency (FAT)",,survey,
4288,"Title:Mitigating Cadmium Accumulation in Spinach and Onions by the Application of Silicon Fertilizer to Soil

 Cadmium (Cd) is readily absorbed by plants and can accumulate to concentrations that exceed food standards. Testing strategies that can mitigate plant uptake of Cd are essential to help manage the risk to food quality. We measured whether applying silicon (Si) fertilizer to a soil contaminated with Cd from phosphate fertilizer could decrease Cd concentrations in spinach (Spinacia olearacea) and onion (Allium cepa). The application of Si (1000 and 2500 kg ha(-1)) increased spinach dry matter (DM) yield and Si concentrations but had no effect on plant Cd concentrations or uptake. Application of Si had no effect on DM yield or Si concentrations in onions, but there was a 45% decrease in Cd concentrations in the onion bulb. Application of Si had no effect on calcium nitrate-extractable Cd. The decrease in Cd concentrations in onions was likely related to Si restricting the movement of Cd from the root to the harvestable part of the plant. These findings indicate that Si may have some potential as a mitigation tool to decrease plant uptake of Cd. Further investigation is required to evaluate its effectiveness across different soil types and test the response of a wider range of crops under field conditions.","Gray, Colin William; Wise, Bridget Elizabeth",,"Gray, Colin/0000-0002-5397-8243",Mitigating Cadmium Accumulation in Spinach and Onions by the Application of Silicon Fertilizer to Soil,29,5,10.1080/15320383.2020.1747980 ,Article ,2020.0,"Cadmium (Cd) is readily absorbed by plants and can accumulate to concentrations that exceed food standards. Testing strategies that can mitigate plant uptake of Cd are essential to help manage the risk to food quality. We measured whether applying silicon (Si) fertilizer to a soil contaminated with Cd from phosphate fertilizer could decrease Cd concentrations in spinach (Spinacia olearacea) and onion (Allium cepa). The application of Si (1000 and 2500 kg ha(-1)) increased spinach dry matter (DM) yield and Si concentrations but had no effect on plant Cd concentrations or uptake. Application of Si had no effect on DM yield or Si concentrations in onions, but there was a 45% decrease in Cd concentrations in the onion bulb. Application of Si had no effect on calcium nitrate-extractable Cd. The decrease in Cd concentrations in onions was likely related to Si restricting the movement of Cd from the root to the harvestable part of the plant. These findings indicate that Si may have some potential as a mitigation tool to decrease plant uptake of Cd. Further investigation is required to evaluate its effectiveness across different soil types and test the response of a wider range of crops under field conditions.",1532-0383,1549-7887,,532-544, , ,,out_of_scope,
4289,"Title:Carvacrol mitigates vancomycin-induced nephrotoxicity via regulation of IkBa/p38MAPK and Keap1/Nrf2 signaling pathways: an experimental study with in silico evidence

 OBJECTIVE: Despite its evident re-nal toxicity, vancomycin is considered an effective glycopeptide antibiotic against life-threatening pos-itive bacterial contagions. The current study aimed to investigate the potential protective effects of car-vacrol as well as its underlying mechanism against vancomycin-induced nephrotoxicity. MATERIALS AND METHODS: The animals were randomly classified into four groups (8 rats per group). Group I, which served as a control group, received only vehicles. Group II received a single i.p. injection of 50 mg/kg of carvacrol for seven days. Group III received vancomycin (200 mg/kg, i.p.) as a singular daily dose for sev-en days. Carvacrol was administered to Group IV seven days prior to the daily vancomycin dose. RESULTS: The results revealed that carvacrol minimized vancomycin-induced renal injury as evidenced by lower serum cystatin C levels and kidney injury molecule-1 (KIM-1), in addition to a decline in renal damage caused by vancomycin as indicated in histopathological assessment. Furthermore, carvacrol significantly attenuat- ed oxidative stress parameters and inflammato-ry mediators. Moreover, it downregulated Keap1, mitogen-activated protein kinase (p38MAPK), and nuclear factor kappa B (NF-kappa B) genes and proteins, along with controlling the NF-kappa B inhib-itory protein (IkB alpha) and nuclear factor erythroid 2-related factor 2 (Nrf2) genes and proteins ob-served through streaming its genes. A molecular docking technique was also used to investigate the potential interactivity between carvacrol and proteins involved in regulating oxidative injury and inflammatory responses. CONCLUSIONS: The current study findings revealed that carvacrol administration before vancomycin could be a promising therapeutic approach for maceration of renal damage stimu-lated by vancomycin via controlling IkB alpha/MAPK and Keap1/Nrf2 signaling molecules.","Khalaf, M. M.; Hassan, S. M.; Sayed, A. M.; Abo-Youssef, A. M.","Sayed, Ahmed/AAV-8741-2020","Sayed, Ahmed/0000-0002-3349-2545",Carvacrol mitigates vancomycin-induced nephrotoxicity via regulation of IkBa/p38MAPK and Keap1/Nrf2 signaling pathways: an experimental study with in silico evidence,26,23, ,Article ,2022.0,"OBJECTIVE: Despite its evident re-nal toxicity, vancomycin is considered an effective glycopeptide antibiotic against life-threatening pos-itive bacterial contagions. The current study aimed to investigate the potential protective effects of car-vacrol as well as its underlying mechanism against vancomycin-induced nephrotoxicity. MATERIALS AND METHODS: The animals were randomly classified into four groups (8 rats per group). Group I, which served as a control group, received only vehicles. Group II received a single i.p. injection of 50 mg/kg of carvacrol for seven days. Group III received vancomycin (200 mg/kg, i.p.) as a singular daily dose for sev-en days. Carvacrol was administered to Group IV seven days prior to the daily vancomycin dose. RESULTS: The results revealed that carvacrol minimized vancomycin-induced renal injury as evidenced by lower serum cystatin C levels and kidney injury molecule-1 (KIM-1), in addition to a decline in renal damage caused by vancomycin as indicated in histopathological assessment. Furthermore, carvacrol significantly attenuat- ed oxidative stress parameters and inflammato-ry mediators. Moreover, it downregulated Keap1, mitogen-activated protein kinase (p38MAPK), and nuclear factor kappa B (NF-kappa B) genes and proteins, along with controlling the NF-kappa B inhib-itory protein (IkB alpha) and nuclear factor erythroid 2-related factor 2 (Nrf2) genes and proteins ob-served through streaming its genes. A molecular docking technique was also used to investigate the potential interactivity between carvacrol and proteins involved in regulating oxidative injury and inflammatory responses. CONCLUSIONS: The current study findings revealed that carvacrol administration before vancomycin could be a promising therapeutic approach for maceration of renal damage stimu-lated by vancomycin via controlling IkB alpha/MAPK and Keap1/Nrf2 signaling molecules.",1128-3602,,,8738-8755, , ,,out_of_scope,
4290,"Title:Life cycle assessment of food loss and waste in the food supply chain

 Addressing food loss and waste (FLW) globally is critical for both improving food security and mitigating environmental pollution. While there are numerous studies addressing FLW in terms of nutrition, food security, food safety, public health and the economy, there is only a small body of life cycle assessment (LCA) research aimed at understanding impacts from FLW. We conducted a literature review of LCA studies focused on FLW in the food supply chain (FSC) to ascertain the state of the science and identify the research gaps. We identified 22 original research articles that met our search criteria and spanned the four stages of LCA. Regarding the goal and scope, there were a dearth of studies focused on the top of the waste hierarchy (prevention). Further, we identified a research gap in studies that accounted for avoided production from food waste management in the overall LCA and distinguished between avoidable and unavoidable waste streams. LCA studies to date largely used a mass-basis as the functional unit and were limited in terms of spatial and temporal specificity. Within the life cycle inventory, most of the studies were conducted in Europe and only one study in the US. In addition, some of the studies lack data transparency. The life cycle impact assessment phase showed that most of the studies only assess global warming potential with fewer studies evaluating energy, water demand and human toxicity. Lastly, within life cycle interpretation more than half of the studies focus on at least one of the three types of uncertainties supporting more informed policy decision making.","Omolayo, Yetunde; Feingold, Beth J.; Neff, Roni A.; Romeiko, Xiaobo Xue",,"Feingold, Beth/0000-0001-6670-5845; Sorunmu, Yetunde/0000-0003-2074-6371; Neff, Roni/0000-0002-0010-2635",Life cycle assessment of food loss and waste in the food supply chain,164,,10.1016/j.resconrec.2020.105119 ,Review ,2021.0,"Addressing food loss and waste (FLW) globally is critical for both improving food security and mitigating environmental pollution. While there are numerous studies addressing FLW in terms of nutrition, food security, food safety, public health and the economy, there is only a small body of life cycle assessment (LCA) research aimed at understanding impacts from FLW. We conducted a literature review of LCA studies focused on FLW in the food supply chain (FSC) to ascertain the state of the science and identify the research gaps. We identified 22 original research articles that met our search criteria and spanned the four stages of LCA. Regarding the goal and scope, there were a dearth of studies focused on the top of the waste hierarchy (prevention). Further, we identified a research gap in studies that accounted for avoided production from food waste management in the overall LCA and distinguished between avoidable and unavoidable waste streams. LCA studies to date largely used a mass-basis as the functional unit and were limited in terms of spatial and temporal specificity. Within the life cycle inventory, most of the studies were conducted in Europe and only one study in the US. In addition, some of the studies lack data transparency. The life cycle impact assessment phase showed that most of the studies only assess global warming potential with fewer studies evaluating energy, water demand and human toxicity. Lastly, within life cycle interpretation more than half of the studies focus on at least one of the three types of uncertainties supporting more informed policy decision making.",0921-3449,1879-0658,,, , ,,out_of_scope,
4291,"Title:Polystyrene nanoplastic exposure induces excessive mitophagy by activating AMPK/ULK1 pathway in differentiated SH-SY5Y cells and dopaminergic neurons in vivo.

 BACKGROUND: Microplastics and nanoplastics (MNPs) are emerging environmental contaminants detected in human samples, and have raised concerns regarding their potential risks to human health, particularly neurotoxicity. This study aimed to investigate the deleterious effects of polystyrene nanoplastics (PS-NPs, 50nm) and understand their mechanisms in inducing Parkinson's disease (PD)-like neurodegeneration, along with exploring preventive strategies.METHODS: Following exposure to PS-NPs (0.5-500mug/mL), we assessed cytotoxicity, mitochondrial integrity, ATP levels, and mitochondrial respiration in dopaminergic-differentiated SH-SY5Y cells. Molecular docking and dynamic simulations explored PS-NPs' interactions with mitochondrial complexes. We further probed mitophagy's pivotal role in PS-NP-induced mitochondrial damage and examined melatonin's ameliorative potential in vitro. We validated melatonin's intervention (intraperitoneal, 10mg/kg/d) in C57BL/6J mice exposed to 250mg/kg/d of PS-NPs for 28days.RESULTS: In our in vitro experiments, we observed PS-NP accumulation in cells, including mitochondria, leading to cell toxicity and reduced viability. Notably, antioxidant treatment failed to fully rescue viability, suggesting reactive oxygen species (ROS)-independent cytotoxicity. PS-NPs caused significant mitochondrial damage, characterized by altered morphology, reduced mitochondrial membrane potential, and decreased ATP production. Subsequent investigations pointed to PS-NP-induced disruption of mitochondrial respiration, potentially through interference with complex I (CI), a concept supported by molecular docking studies highlighting the influence of PS-NPs on CI. Rescue experiments using an AMPK pathway inhibitor (compound C) and an autophagy inhibitor (3-methyladenine) revealed that excessive mitophagy was induced through AMPK/ULK1 pathway activation, worsening mitochondrial damage and subsequent cell death in differentiated SH-SY5Y cells. Notably, we identified melatonin as a potential protective agent, capable of alleviating PS-NP-induced mitochondrial dysfunction. Lastly, our in vivo experiments demonstrated that melatonin could mitigate dopaminergic neuron loss and motor impairments by restoring mitophagy regulation in mice.CONCLUSIONS: Our study demonstrated that PS-NPs disrupt mitochondrial function by affecting CI, leading to excessive mitophagy through the AMPK/ULK1 pathway, causing dopaminergic neuron death. Melatonin can counteract PS-NP-induced mitochondrial dysfunction and motor impairments by regulating mitochondrial autophagy. These findings offer novel insights into the MNP-induced PD-like neurodegenerative mechanisms, and highlight melatonin's protective potential in mitigating the MNP's environmental risk.","Huang, Yuji; Liang, Boxuan; Li, Zhiming; Zhong, Yizhou; Wang, Bo; Zhang, Bingli; Du, Jiaxin; Ye, Rongyi; Xian, Hongyi; Min, Weicui; Yan, Xiliang; Deng, Yanhong; Feng, Yu; Bai, Ruobing; Fan, Bingchi; Yang, Xingfen; Huang, Zhenlie",,,Polystyrene nanoplastic exposure induces excessive mitophagy by activating AMPK/ULK1 pathway in differentiated SH-SY5Y cells and dopaminergic neurons in vivo.,20,1,10.1186/s12989-023-00556-4 ,Journal Article ,2023.0,"BACKGROUND: Microplastics and nanoplastics (MNPs) are emerging environmental contaminants detected in human samples, and have raised concerns regarding their potential risks to human health, particularly neurotoxicity. This study aimed to investigate the deleterious effects of polystyrene nanoplastics (PS-NPs, 50nm) and understand their mechanisms in inducing Parkinson's disease (PD)-like neurodegeneration, along with exploring preventive strategies.METHODS: Following exposure to PS-NPs (0.5-500mug/mL), we assessed cytotoxicity, mitochondrial integrity, ATP levels, and mitochondrial respiration in dopaminergic-differentiated SH-SY5Y cells. Molecular docking and dynamic simulations explored PS-NPs' interactions with mitochondrial complexes. We further probed mitophagy's pivotal role in PS-NP-induced mitochondrial damage and examined melatonin's ameliorative potential in vitro. We validated melatonin's intervention (intraperitoneal, 10mg/kg/d) in C57BL/6J mice exposed to 250mg/kg/d of PS-NPs for 28days.RESULTS: In our in vitro experiments, we observed PS-NP accumulation in cells, including mitochondria, leading to cell toxicity and reduced viability. Notably, antioxidant treatment failed to fully rescue viability, suggesting reactive oxygen species (ROS)-independent cytotoxicity. PS-NPs caused significant mitochondrial damage, characterized by altered morphology, reduced mitochondrial membrane potential, and decreased ATP production. Subsequent investigations pointed to PS-NP-induced disruption of mitochondrial respiration, potentially through interference with complex I (CI), a concept supported by molecular docking studies highlighting the influence of PS-NPs on CI. Rescue experiments using an AMPK pathway inhibitor (compound C) and an autophagy inhibitor (3-methyladenine) revealed that excessive mitophagy was induced through AMPK/ULK1 pathway activation, worsening mitochondrial damage and subsequent cell death in differentiated SH-SY5Y cells. Notably, we identified melatonin as a potential protective agent, capable of alleviating PS-NP-induced mitochondrial dysfunction. Lastly, our in vivo experiments demonstrated that melatonin could mitigate dopaminergic neuron loss and motor impairments by restoring mitophagy regulation in mice.CONCLUSIONS: Our study demonstrated that PS-NPs disrupt mitochondrial function by affecting CI, leading to excessive mitophagy through the AMPK/ULK1 pathway, causing dopaminergic neuron death. Melatonin can counteract PS-NP-induced mitochondrial dysfunction and motor impairments by regulating mitochondrial autophagy. These findings offer novel insights into the MNP-induced PD-like neurodegenerative mechanisms, and highlight melatonin's protective potential in mitigating the MNP's environmental risk.",,1743-8977,,44-44, , ,,out_of_scope,
4292,"Title:Impact of TiO2 nanoparticles on lead uptake and bioaccumulation in rice (Oryza sativa L.)

 Titanium dioxide nanoparticles (TiO2 NPs) are among the most widely used metal oxide nanoparticles, and their release into the environment is inevitable. The impact of this NPs release on the fate and toxicity of coexisting heavy metals is largely unknown. In this work, a series of hydroponic experiments were conducted to investigate impact of four types of TiO2 NPs, including one anatase (NAnT), one pristine rutile (NRuT) and two rutiles with hydrophilic and hydrophobic surfaces (NLRuT, NBRuT), as well as the bulk particles (BT), on the bioaccumulation of lead (Pb) by rice (Oryza sativa) seedlings. The results indicate that TiO2 NPs exposure at the levels of 10 and 1000 mg/L had no significant adverse effects on the growth and development of rice seedlings. Due to its small crystallite size (252.2 angstrom), only one type of TiO2 NPs (NAnT) entered rice seedling roots through an apoplastic route. However, NAnT particles were not translocated from roots to shoots, likely due to the obstruction effects of casparian strip in the root tissues. Both nano and bulk TiO2 reduced the bioaccumulation of Pb in rice at high TiO2 exposure levels (1000 mg/L) but the extent of the reduction was TiO2-type dependent. NAnT, NRuT and NLRuT reduced the Pb concentration in rice roots by >80% and by 77-97% in shoots, likely due to the particles high sorption potential for Pb in the nutrient solution. NBRuT and BT reduced Pb levels by 45-61% in roots and 11-38% in shoots. Although NAnT was able to effectively reduce the bioaccumulation of Pb in rice tissues, this particle did accumulate in rice roots, which poses a potential risk to food safety. Accordingly, NAnT is not recommended for Pb pollution control. NRuT and NLRuT are more appropriate agents to reduce Pb contamination threats to rice plants, which in turn may mitigate health risk to humans through the food chain. (C) 2017 Elsevier B.V. All rights reserved.","Cai, Fei; Wu, Xinyi; Zhang, Haiyun; Shen, Xiaofang; Zhang, Meng; Chen, Weixiao; Gao, Qian; White, Jason C.; Tao, Shu; Wang, Xilong","wang, long/IZE-1764-2023; wang, xl/Y-8251-2019; wang, xilong/M-1848-2017; Zhang, Meng/AAA-4436-2020","wang, xilong/0000-0002-5668-9703; Zhang, Meng/0000-0001-6979-6455",Impact of TiO2 nanoparticles on lead uptake and bioaccumulation in rice (Oryza sativa L.),5,,10.1016/j.impact.2017.01.006 ,Article ,2017.0,"Titanium dioxide nanoparticles (TiO2 NPs) are among the most widely used metal oxide nanoparticles, and their release into the environment is inevitable. The impact of this NPs release on the fate and toxicity of coexisting heavy metals is largely unknown. In this work, a series of hydroponic experiments were conducted to investigate impact of four types of TiO2 NPs, including one anatase (NAnT), one pristine rutile (NRuT) and two rutiles with hydrophilic and hydrophobic surfaces (NLRuT, NBRuT), as well as the bulk particles (BT), on the bioaccumulation of lead (Pb) by rice (Oryza sativa) seedlings. The results indicate that TiO2 NPs exposure at the levels of 10 and 1000 mg/L had no significant adverse effects on the growth and development of rice seedlings. Due to its small crystallite size (252.2 angstrom), only one type of TiO2 NPs (NAnT) entered rice seedling roots through an apoplastic route. However, NAnT particles were not translocated from roots to shoots, likely due to the obstruction effects of casparian strip in the root tissues. Both nano and bulk TiO2 reduced the bioaccumulation of Pb in rice at high TiO2 exposure levels (1000 mg/L) but the extent of the reduction was TiO2-type dependent. NAnT, NRuT and NLRuT reduced the Pb concentration in rice roots by >80% and by 77-97% in shoots, likely due to the particles high sorption potential for Pb in the nutrient solution. NBRuT and BT reduced Pb levels by 45-61% in roots and 11-38% in shoots. Although NAnT was able to effectively reduce the bioaccumulation of Pb in rice tissues, this particle did accumulate in rice roots, which poses a potential risk to food safety. Accordingly, NAnT is not recommended for Pb pollution control. NRuT and NLRuT are more appropriate agents to reduce Pb contamination threats to rice plants, which in turn may mitigate health risk to humans through the food chain. (C) 2017 Elsevier B.V. All rights reserved.",2452-0748,,,101-108, , ,,out_of_scope,
4293,"Title:Effects of arsenite on physiological, biochemical and grain yield attributes of quinoa (Chenopodium quinoa Willd.): implications for phytoremediation and health risk assessment

 The objectives of this study were to investigate the effects of arsenic (As) on physiological and biochemical attributes of quinoa, and human health risks associated with the consumption of As contaminated grains of quinoa. Quinoa genotype, Puno was grown on soil contaminated with various levels of arsenite; 0, 10, 20, 30, and 40 mg As kg(-1) soil. Results revealed that plant growth, photosynthetic pigments, stomatal conductance, and grain yield of As treated plants were significantly less as compared to control plants. Plants exposed to elevated levels of 30 and 40 mg As kg(-1) of soil could not survive until maturity. Plant roots retained higher concentration of As than shoot indicating As phytostabilizing behavior of quinoa. Arsenic toxicity caused oxidative stress in quinoa plants, which elevated the H2O2 and TBARS contents and decreased membrane stability. This oxidative stress was partly mitigated by the induction of antioxidant enzymes (SOD, CAT, POD, APX). Perhaps, our results regarding As availability might be an overestimate of the typical natural conditions, As accumulation in quinoa grains posed both carcinogenic and non-carcinogenic health risks to humans. It was concluded that quinoa is sensitive to As and the consumption of quinoa grains from plants grown on As concentration >= 20 mg kg(-1) of soil was not safe for humans.Novelty statement: The tolerance potential of quinoa (Chenopodium quinoa Willd.) against the trivalent form of arsenic (arsenite), and the health risks due to the consumption of arsenic-contaminated grains has not been explored yet. This is the first study in which we have explored the effects of arsenite on physiological, biochemical and phytoremedial attributes of quinoa. Moreover, human health risks associated with the consumption of As contaminated grains of quinoa has have been investigated. The findings of the present study would be helpful for farmers who intend to grow quinoa on arsenic-contaminated soils.","Shabbir, Arslan; Abbas, Ghulam; Asad, Saeed Ahmad; Razzaq, Hina; Anwar-ul-Haq, Muhammad; Amjad, Muhammad","Amjad, Muhammad/AAH-2296-2019; ABBAS, GHULAM/AAB-2312-2022; Abbas, Ghulam/AEG-5753-2022; Anwar-ul-Haq, Muhammad/AAD-1748-2022; Asad, Saeed A/E-6236-2019","Amjad, Muhammad/0000-0001-7552-8908; ABBAS, GHULAM/0000-0003-1074-7530; Anwar-ul-Haq, Muhammad/0000-0002-6623-5756; Asad, Saeed A/0000-0002-9242-3806; Shabbir, Arslan/0000-0002-1299-3287","Effects of arsenite on physiological, biochemical and grain yield attributes of quinoa (Chenopodium quinoa Willd.): implications for phytoremediation and health risk assessment",23,9,10.1080/15226514.2020.1865266 ,Article ,2021.0,"The objectives of this study were to investigate the effects of arsenic (As) on physiological and biochemical attributes of quinoa, and human health risks associated with the consumption of As contaminated grains of quinoa. Quinoa genotype, Puno was grown on soil contaminated with various levels of arsenite; 0, 10, 20, 30, and 40 mg As kg(-1) soil. Results revealed that plant growth, photosynthetic pigments, stomatal conductance, and grain yield of As treated plants were significantly less as compared to control plants. Plants exposed to elevated levels of 30 and 40 mg As kg(-1) of soil could not survive until maturity. Plant roots retained higher concentration of As than shoot indicating As phytostabilizing behavior of quinoa. Arsenic toxicity caused oxidative stress in quinoa plants, which elevated the H2O2 and TBARS contents and decreased membrane stability. This oxidative stress was partly mitigated by the induction of antioxidant enzymes (SOD, CAT, POD, APX). Perhaps, our results regarding As availability might be an overestimate of the typical natural conditions, As accumulation in quinoa grains posed both carcinogenic and non-carcinogenic health risks to humans. It was concluded that quinoa is sensitive to As and the consumption of quinoa grains from plants grown on As concentration >= 20 mg kg(-1) of soil was not safe for humans.Novelty statement: The tolerance potential of quinoa (Chenopodium quinoa Willd.) against the trivalent form of arsenic (arsenite), and the health risks due to the consumption of arsenic-contaminated grains has not been explored yet. This is the first study in which we have explored the effects of arsenite on physiological, biochemical and phytoremedial attributes of quinoa. Moreover, human health risks associated with the consumption of As contaminated grains of quinoa has have been investigated. The findings of the present study would be helpful for farmers who intend to grow quinoa on arsenic-contaminated soils.",1522-6514,1549-7879,,890-898, , ,,out_of_scope,
4294,"Title:Biotransformation-mediated detoxification of roxarsone in the anammox process: Gene regulation mechanism

 Roxarsone is a common organoarsenic feed additive used in livestock and poultry breeding, while the ecotoxicity of organic arsenic remains a concern. Therefore, the effects of roxarsone on the anaerobic ammonium oxidation (anammox) process and responding mechanism were investigated in this study. The minimum nitrogen removal efficiency (NRE) of anammox process was 64.0% under roxarsone stress. Meanwhile, the reactive oxygen species (ROS) content increased by 1.5-2.3 times, and electron transport system activity (ETSA) decreased by 22.9 +/- 5.0%. The total antioxidant capacity (T-AOC) level first increased and then decreased, resulting in an imbalance between ROS production and antioxidant defense. The copy numbers of arsenic resistance genes significantly increased, indicating that roxarsone was transformed in the anammox system. Co-occurrence networks manifested that arsenic resistance genes were significantly positively correlated with dominant genera. The detoxification mediated by biotransformation mitigated the toxicity of roxarsone and the side effects of oxidative stress. This work provides insights into the response and mechanism of anammox consortia to roxarsone and promotes the efficient treatment of wastewater containing organic arsenic by the anammox process.","Wang, Xin; Wu, Qian; Wang, Zhou-Zheng; Ma, Wen-Jie; Qiu, Jun; Fan, Nian-Si; Jin, Ren-Cun",,"Fan, Nian-Si/0000-0001-8640-8223",Biotransformation-mediated detoxification of roxarsone in the anammox process: Gene regulation mechanism,467,,10.1016/j.cej.2023.143449 ,Article ,2023.0,"Roxarsone is a common organoarsenic feed additive used in livestock and poultry breeding, while the ecotoxicity of organic arsenic remains a concern. Therefore, the effects of roxarsone on the anaerobic ammonium oxidation (anammox) process and responding mechanism were investigated in this study. The minimum nitrogen removal efficiency (NRE) of anammox process was 64.0% under roxarsone stress. Meanwhile, the reactive oxygen species (ROS) content increased by 1.5-2.3 times, and electron transport system activity (ETSA) decreased by 22.9 +/- 5.0%. The total antioxidant capacity (T-AOC) level first increased and then decreased, resulting in an imbalance between ROS production and antioxidant defense. The copy numbers of arsenic resistance genes significantly increased, indicating that roxarsone was transformed in the anammox system. Co-occurrence networks manifested that arsenic resistance genes were significantly positively correlated with dominant genera. The detoxification mediated by biotransformation mitigated the toxicity of roxarsone and the side effects of oxidative stress. This work provides insights into the response and mechanism of anammox consortia to roxarsone and promotes the efficient treatment of wastewater containing organic arsenic by the anammox process.",1385-8947,1873-3212,,, , ,,out_of_scope,
4295,"Title:A bispecific CAR-T cell therapy targeting BCMA and CD38 in relapsed or refractory multiple myeloma

 Background BCMA-specific chimeric antigen receptor-T cells (CAR-Ts) have exhibited remarkable efficacy in refractory or relapsed multiple myeloma (RRMM); however, primary resistance and relapse exist with single-target immunotherapy. Bispecific CARs are proposed to mitigate these limitations. Methods We constructed a humanized bispecific BM38 CAR targeting BCMA and CD38 and tested the antimyeloma activity of BM38 CAR-Ts in vitro and in vivo. Twenty-three patients with RRMM received infusions of BM38 CAR-Ts in a phase I trial. Results BM38 CAR-Ts showed stronger in vitro cytotoxicity to heterogeneous MM cells than did T cells expressing an individual BCMA or CD38 CAR. BM38 CAR-Ts also exhibited potent antimyeloma activity in xenograft mouse models. In the phase I trial, cytokine release syndrome occurred in 20 patients (87%) and was mostly grade 1-2 (65%). Neurotoxicity was not observed. Hematologic toxicities were common, including neutropenia in 96% of the patients, leukopenia in 87%, anemia in 43% and thrombocytopenia in 61%. At a median follow-up of 9.0 months (range 0.5 to 18.5), 20 patients (87%) attained a clinical response and minimal residual disease-negativity (<= 10(-4) nucleated cells), with 12 (52%) achieving a stringent complete response. Extramedullary plasmacytoma was eliminated completely in 56% and partially in 33% and of 9 patients. The median progression-free survival was 17.2 months. Two relapsed patients maintained BCMA and CD38 expression on MM cells. Notably, BM38 CAR-Ts cells were detectable in 77.8% of evaluable patients at 9 months and 62.2% at 12 months. Conclusion Bispecific BM38 CAR-Ts were feasible, safe and significantly effective in patient with RRMM. Trial registration: Chictr.org.cn ChiCTR1800018143.","Mei, Heng; Li, Chenggong; Jiang, Huiwen; Zhao, Xinying; Huang, Zhiping; Jin, Dan; Guo, Tao; Kou, Haiming; Liu, Lin; Tang, Lu; Yin, Ping; Wang, Zhihui; Ai, Lisha; Ke, Sha; Xia, Yimeng; Deng, Jun; Chen, Lei; Cai, Li; Sun, Chunyan; Xia, Linghui; Hua, Gaoquan; Hu, Yu","wang, zhihui/HSF-6639-2023; Mei, Heng/JHS-3233-2023","Mei, Heng/0000-0001-7941-2443",A bispecific CAR-T cell therapy targeting BCMA and CD38 in relapsed or refractory multiple myeloma,14,1,10.1186/s13045-021-01170-7 ,Article ,2021.0,"Background BCMA-specific chimeric antigen receptor-T cells (CAR-Ts) have exhibited remarkable efficacy in refractory or relapsed multiple myeloma (RRMM); however, primary resistance and relapse exist with single-target immunotherapy. Bispecific CARs are proposed to mitigate these limitations. Methods We constructed a humanized bispecific BM38 CAR targeting BCMA and CD38 and tested the antimyeloma activity of BM38 CAR-Ts in vitro and in vivo. Twenty-three patients with RRMM received infusions of BM38 CAR-Ts in a phase I trial. Results BM38 CAR-Ts showed stronger in vitro cytotoxicity to heterogeneous MM cells than did T cells expressing an individual BCMA or CD38 CAR. BM38 CAR-Ts also exhibited potent antimyeloma activity in xenograft mouse models. In the phase I trial, cytokine release syndrome occurred in 20 patients (87%) and was mostly grade 1-2 (65%). Neurotoxicity was not observed. Hematologic toxicities were common, including neutropenia in 96% of the patients, leukopenia in 87%, anemia in 43% and thrombocytopenia in 61%. At a median follow-up of 9.0 months (range 0.5 to 18.5), 20 patients (87%) attained a clinical response and minimal residual disease-negativity (<= 10(-4) nucleated cells), with 12 (52%) achieving a stringent complete response. Extramedullary plasmacytoma was eliminated completely in 56% and partially in 33% and of 9 patients. The median progression-free survival was 17.2 months. Two relapsed patients maintained BCMA and CD38 expression on MM cells. Notably, BM38 CAR-Ts cells were detectable in 77.8% of evaluable patients at 9 months and 62.2% at 12 months. Conclusion Bispecific BM38 CAR-Ts were feasible, safe and significantly effective in patient with RRMM. Trial registration: Chictr.org.cn ChiCTR1800018143.",,1756-8722,,, , ,,out_of_scope,
4296,"Title:Role of protected area in reducing marine and plastic litter: A case study from India's first Marine Protected Area and comparison with Non-Protected Areas

 This research is the first to assess marine litter and plastic pollution in India's first marine protected area (MPA), the Gulf of Kachchh Marine Protected Area (GOKMPA). We compare it to two non-protected areas, that is, Okha Beach and Beyt Dwarka, known for their high industrial and tourist activity, respectively. Standing-stock surveys were used to collect primary litter data, while questionnaire surveys were used to learn about people's perception and attitude towards the plastic pollution problem in the study area. We found that plastic was the most common component of the litter at all the sites and that it was primarily of terrestrial origin. Compared to non-protected sites, GOKMPA had the lowest litter density but the highest proportion of plastic litter. Single-use plastic bottles were the most counted items at all the sites, regardless of the conservation status of the sites. The majority of people (locals, visitors, and fishers) around these sites expressed concern about waste but were hesitant to take responsibility and discourage or prevent littering. We noted that designating coastal territories as protected areas helps in reducing plastic pollution while also conserving habitat and biodiversity. However, this could change rapidly due to either mishandling of litter within MPAs or neighboring non-PAs, and also because plastics pose an actual toxicity risk when present even at minimal concentrations in the environment. We recommend combining preventive, mitigating, and curative measures in areas where risk hotspots for plastic litter are identified, and such sites must be constantly monitored. Long-term solutions could include transitioning from a linear to a circular economy, which would involve goals for reducing plastic waste and instituting more sustainable production and consumption patterns.","Baroth, Anju; Mamgain, Sonalika; Sivakumar, Kuppusamy; Hatkar, Prachi Sachchidanand; Pathan, Sameeha","Hatkar, Prachi/GWQ-7964-2022","Hatkar, Prachi/0000-0002-1009-726X; Kuppusamy, Sivakumar/0000-0002-6938-7480; BAROTH, ANJU/0000-0003-2402-5774",Role of protected area in reducing marine and plastic litter: A case study from India's first Marine Protected Area and comparison with Non-Protected Areas,26,6,10.1111/jiec.13248 ,Article ,2022.0,"This research is the first to assess marine litter and plastic pollution in India's first marine protected area (MPA), the Gulf of Kachchh Marine Protected Area (GOKMPA). We compare it to two non-protected areas, that is, Okha Beach and Beyt Dwarka, known for their high industrial and tourist activity, respectively. Standing-stock surveys were used to collect primary litter data, while questionnaire surveys were used to learn about people's perception and attitude towards the plastic pollution problem in the study area. We found that plastic was the most common component of the litter at all the sites and that it was primarily of terrestrial origin. Compared to non-protected sites, GOKMPA had the lowest litter density but the highest proportion of plastic litter. Single-use plastic bottles were the most counted items at all the sites, regardless of the conservation status of the sites. The majority of people (locals, visitors, and fishers) around these sites expressed concern about waste but were hesitant to take responsibility and discourage or prevent littering. We noted that designating coastal territories as protected areas helps in reducing plastic pollution while also conserving habitat and biodiversity. However, this could change rapidly due to either mishandling of litter within MPAs or neighboring non-PAs, and also because plastics pose an actual toxicity risk when present even at minimal concentrations in the environment. We recommend combining preventive, mitigating, and curative measures in areas where risk hotspots for plastic litter are identified, and such sites must be constantly monitored. Long-term solutions could include transitioning from a linear to a circular economy, which would involve goals for reducing plastic waste and instituting more sustainable production and consumption patterns.",1088-1980,1530-9290,,2080-2091, , ,,out_of_scope,
4297,"Title:Endothelial NO and O2•- production rates differentially regulate oxidative, nitroxidative, and nitrosative stress in the microcirculation

 Endothelial dysfunction causes an imbalance in endothelial NO and O-2(center dot-) production rates and increased peroxynitrite formation. Peroxynitrite and its decomposition products cause multiple deleterious effects including tyrosine nitration of proteins, superoxide dismutase (SOD) inactivation, and tissue damage. Studies have shown that peroxynitrite formation during endothelial dysfunction is strongly dependent on the NO and O-2(center dot-) production rates. Previous experimental and modeling studies examining the role of NO and O-2(center dot-) production imbalance on peroxynitrite formation showed different results in biological and synthetic systems. However, there is a lack of quantitative information about the formation and biological relevance of peroxynitrite under oxidative, nitroxidative, and nitrosative stress conditions in the microcirculation. We developed a computational biotransport model to examine the role of endothelial NO and O-2(center dot-) production on the complex biochemical NO and O-2(center dot-) interactions in the microcirculation. We also modeled the effect of variability in SOD expression and activity during oxidative stress. The results showed that peroxynitrite concentration increased with increase in either O-2(center dot-) to NO or NO to O-2(center dot-) production rate ratio (Q(O2)(center dot-)/Q(NO) or Q(NO)/Q(O2)(center dot-) , respectively). The peroxynitrite concentrations were similar for both production rate ratios, indicating that peroxynitrite-related nitroxidative and nitrosative stresses may be similar in endothelial dysfunction or inducible NO synthase (iNOS)-induced NO production. The endothelial peroxynitrite concentration increased with increase in both Q(O2)(center dot-)/Q(NO) and Q(NO)/Q(O2)(center dot-) ratios at SOD concentrations of 0.1-100 mu M. The absence of SOD may not mitigate the extent of peroxynitrite-mediated toxicity, as we predicted an insignificant increase in peroxynitrite levels beyond Q(O2)(center dot-)/Q(NO) and Q(NO)/Q(O2)(center dot-) ratios of 1. The results support the experimental observations of biological systems and show that peroxynitrite formation increases with increase in either NO or O-2(center dot-) production, and excess NO production from iNOS or from NO donors during oxidative stress conditions does not reduce the extent of peroxynitrite mediated toxicity. (C) 2013 Elsevier Inc. All rights reserved.","Kar, Saptarshi; Kavdia, Mahendra","Kar, Saptarshi/H-5166-2014; Stefanadis, Christodoulos/ABH-2232-2020","Stefanadis, Christodoulos/0000-0001-5974-6454; Kar, Saptarshi/0000-0002-3788-372X","Endothelial NO and O2•- production rates differentially regulate oxidative, nitroxidative, and nitrosative stress in the microcirculation",63,,10.1016/j.freeradbiomed.2013.04.024 ,Article ,2013.0,"Endothelial dysfunction causes an imbalance in endothelial NO and O-2(center dot-) production rates and increased peroxynitrite formation. Peroxynitrite and its decomposition products cause multiple deleterious effects including tyrosine nitration of proteins, superoxide dismutase (SOD) inactivation, and tissue damage. Studies have shown that peroxynitrite formation during endothelial dysfunction is strongly dependent on the NO and O-2(center dot-) production rates. Previous experimental and modeling studies examining the role of NO and O-2(center dot-) production imbalance on peroxynitrite formation showed different results in biological and synthetic systems. However, there is a lack of quantitative information about the formation and biological relevance of peroxynitrite under oxidative, nitroxidative, and nitrosative stress conditions in the microcirculation. We developed a computational biotransport model to examine the role of endothelial NO and O-2(center dot-) production on the complex biochemical NO and O-2(center dot-) interactions in the microcirculation. We also modeled the effect of variability in SOD expression and activity during oxidative stress. The results showed that peroxynitrite concentration increased with increase in either O-2(center dot-) to NO or NO to O-2(center dot-) production rate ratio (Q(O2)(center dot-)/Q(NO) or Q(NO)/Q(O2)(center dot-) , respectively). The peroxynitrite concentrations were similar for both production rate ratios, indicating that peroxynitrite-related nitroxidative and nitrosative stresses may be similar in endothelial dysfunction or inducible NO synthase (iNOS)-induced NO production. The endothelial peroxynitrite concentration increased with increase in both Q(O2)(center dot-)/Q(NO) and Q(NO)/Q(O2)(center dot-) ratios at SOD concentrations of 0.1-100 mu M. The absence of SOD may not mitigate the extent of peroxynitrite-mediated toxicity, as we predicted an insignificant increase in peroxynitrite levels beyond Q(O2)(center dot-)/Q(NO) and Q(NO)/Q(O2)(center dot-) ratios of 1. The results support the experimental observations of biological systems and show that peroxynitrite formation increases with increase in either NO or O-2(center dot-) production, and excess NO production from iNOS or from NO donors during oxidative stress conditions does not reduce the extent of peroxynitrite mediated toxicity. (C) 2013 Elsevier Inc. All rights reserved.",0891-5849,1873-4596,,161-174, , ,,out_of_scope,
4298,"Title:The Devastation of Waste Plastic on the Environment and Remediation Processes: A Critical Review

 The devastating effect of plastic waste on the ecosystem due to the rapid increase in population has been a concern. Although stakeholders and governments invested in efforts to mitigate plastic waste, their exertions have limited to no effects as the demand for plastic increases annually. Emerging practical advancements in recycling plastic have been critical for achieving a sustainable circular economy. This study reviews the adverse effect of plastic waste on the environment and the inhabiting creature, the regulation for managing plastic waste, and their limitations. This scoping review also provides information on the current route for reducing plastic waste by defining its sources and their applications. After identifying the generation of plastic waste, the plastic polymers are categorized according to the hazard ranking of their monomers according to their environmental toxicity, damaging the inhabiting creature. The discharge pathways of plastic waste into the environment and aquatic systems leading to white pollution and climate change were also determined. Conversion of plastic waste through the remedial channel by manufacturing value-added products using techniques such as reusing, recycling, and energy recovery, reducing the disposal of plastic waste in landfills is outlined. The information on remedial processes provided in this study will help reduce plastic waste from the environment. In addition, correctly applying these suggestions may help reduce environmental pollution and the death of inhabiting creations. Further research is necessary to convert plastic waste as raw materials into high-value products to achieve a circular economy.","Khoaele, Katleho Keneuwe; Gbadeyan, Oluwatoyin Joseph; Chunilall, Viren; Sithole, Bruce","Gbadeyan, Oluwatoyin Joseph/Q-9327-2019","Gbadeyan, Oluwatoyin Joseph/0000-0002-7906-3965; Chunilall, Viren/0000-0002-6317-656X; Khoaele, Katleho Keneuwe/0000-0003-3281-9996",The Devastation of Waste Plastic on the Environment and Remediation Processes: A Critical Review,15,6,10.3390/su15065233 ,Review ,2023.0,"The devastating effect of plastic waste on the ecosystem due to the rapid increase in population has been a concern. Although stakeholders and governments invested in efforts to mitigate plastic waste, their exertions have limited to no effects as the demand for plastic increases annually. Emerging practical advancements in recycling plastic have been critical for achieving a sustainable circular economy. This study reviews the adverse effect of plastic waste on the environment and the inhabiting creature, the regulation for managing plastic waste, and their limitations. This scoping review also provides information on the current route for reducing plastic waste by defining its sources and their applications. After identifying the generation of plastic waste, the plastic polymers are categorized according to the hazard ranking of their monomers according to their environmental toxicity, damaging the inhabiting creature. The discharge pathways of plastic waste into the environment and aquatic systems leading to white pollution and climate change were also determined. Conversion of plastic waste through the remedial channel by manufacturing value-added products using techniques such as reusing, recycling, and energy recovery, reducing the disposal of plastic waste in landfills is outlined. The information on remedial processes provided in this study will help reduce plastic waste from the environment. In addition, correctly applying these suggestions may help reduce environmental pollution and the death of inhabiting creations. Further research is necessary to convert plastic waste as raw materials into high-value products to achieve a circular economy.",,2071-1050,,, , ,,out_of_scope,
4299,"Title:Carbon dioxide solubility in choline chloride-based deep eutectic solvents under diverse conditions

 ContextGlobal warming is a severe problem experiencing the climate crisis due to rising CO2 emissions. Deep eutectic solvents (DESs) have recently attracted a lot of attention as potential absorbents to mitigate carbon dioxide CO2 emissions because of their large CO2 capacities and stability under diverse conditions. Designing a potent DES requires knowledge of molecular-level understanding including structure, dynamics, and interfacial properties in DESs. In this study, we investigate the CO2 sorption and diffusion in different DESs at different temperatures and pressure using molecular dynamics (MD) simulations. Our results demonstrate that CO2 molecules preferentially concentrate at the CO2-DES interface, and the diffusion of CO2 in bulk DESs increases with increasing pressure and temperature. The solubility of CO2 in the three DESs increases as ChCL-ethylene glycol < ChCL-urea < ChCL-glycerol at high pressure (58.6 bar).MethodsThe initial configuration for MD simulations included DES and CO2 and produced the solvation box using PACKMOL software. The geometries are optimized in the Gaussian 09 software at the theoretical level of B3LYP/6-311 + G*. The partial atomic charges were fitted to an electrostatic surface potential using the CHELPG method. MD simulations were carried out by using the NAMD version 2.13 software. VMD software was used to take the snapshots. TRAVIS software is used to determine spatial distribution functions.","Biswas, Rima; Metya, Atanu Kumar; Abebe, Kindenew Mesenbet; Gedf, Sara Admasu; Melese, Birtukan Tsegaye",,,Carbon dioxide solubility in choline chloride-based deep eutectic solvents under diverse conditions,29,8,10.1007/s00894-023-05643-z ,Article ,2023.0,"ContextGlobal warming is a severe problem experiencing the climate crisis due to rising CO2 emissions. Deep eutectic solvents (DESs) have recently attracted a lot of attention as potential absorbents to mitigate carbon dioxide CO2 emissions because of their large CO2 capacities and stability under diverse conditions. Designing a potent DES requires knowledge of molecular-level understanding including structure, dynamics, and interfacial properties in DESs. In this study, we investigate the CO2 sorption and diffusion in different DESs at different temperatures and pressure using molecular dynamics (MD) simulations. Our results demonstrate that CO2 molecules preferentially concentrate at the CO2-DES interface, and the diffusion of CO2 in bulk DESs increases with increasing pressure and temperature. The solubility of CO2 in the three DESs increases as ChCL-ethylene glycol < ChCL-urea < ChCL-glycerol at high pressure (58.6 bar).MethodsThe initial configuration for MD simulations included DES and CO2 and produced the solvation box using PACKMOL software. The geometries are optimized in the Gaussian 09 software at the theoretical level of B3LYP/6-311 + G*. The partial atomic charges were fitted to an electrostatic surface potential using the CHELPG method. MD simulations were carried out by using the NAMD version 2.13 software. VMD software was used to take the snapshots. TRAVIS software is used to determine spatial distribution functions.",1610-2940,0948-5023,,, , ,,out_of_scope,
4300,"Title:Life cycle assessment of lead-acid batteries used in electric bicycles in China

 Electric bikes (e-bikes) have developed faster than any other mode of transport in China, which has stimulated the rapid growth of China's lead-acid battery (LAB) industry for more than a decade. This research undertook a life cycle assessment (LCA) for LABs used in e-bikes in China. Its purpose was to identify the key materials and processes that contribute most to impacts on the environment and public health within the life cycle of LABs, from materials extraction and processing, manufacture, transportation, use, and end-of-life. It also sought to find opportunities for improving the environmental profile of LABs. The results indicate that LABs use, as well as materials extraction and processing, have the largest environmental impacts within the life cycle of LABs. The former is responsible for 84% of the primary energy use and contributes the highest potentials to energy-related impacts, including global warming (86%) and acidification (69%). The latter, specifically the lead used in batteries, is the most important driver of impacts such as ozone depletion, photochemical smog, eutrophication, and carcinogenicity. Accordingly, battery reuse after refurbishment and recovery of materials in the end-of-life stage could significantly mitigate most of the overall life cycle impacts by reducing the consumption of virgin materials. However, currently, 95% of total lead emissions are released in the end-of-life stage due to improper management of the spent LABs recycling market in China, and these emissions causes 90% of total human toxicity potential. Battery manufacture only accounts for 3% of total lead emissions after the national cleanup action for heavy metal pollution. Moreover, sensitivity coefficients are employed to evaluate the reliability and uncertainty of the LCA results. Based on the findings, there are several substantial opportunities to further reduce the overall environmental impacts of LABs, such as prolonging the lifetime of LABs, reducing the consumption of metals in LABs, and improving the technology and management in the recovery of spent LABs. (C) 2015 Elsevier Ltd. All rights reserved.","Liu, Wei; Sang, Jing; Chen, Lujun; Tian, Jinping; Zhang, Huatang; Palma, Grecia Olvera",,"Liu, Wei/0000-0003-0714-4341; Tian, Jinping/0000-0002-8955-5154",Life cycle assessment of lead-acid batteries used in electric bicycles in China,108,,10.1016/j.jclepro.2015.07.026 ,Article ,2015.0,"Electric bikes (e-bikes) have developed faster than any other mode of transport in China, which has stimulated the rapid growth of China's lead-acid battery (LAB) industry for more than a decade. This research undertook a life cycle assessment (LCA) for LABs used in e-bikes in China. Its purpose was to identify the key materials and processes that contribute most to impacts on the environment and public health within the life cycle of LABs, from materials extraction and processing, manufacture, transportation, use, and end-of-life. It also sought to find opportunities for improving the environmental profile of LABs. The results indicate that LABs use, as well as materials extraction and processing, have the largest environmental impacts within the life cycle of LABs. The former is responsible for 84% of the primary energy use and contributes the highest potentials to energy-related impacts, including global warming (86%) and acidification (69%). The latter, specifically the lead used in batteries, is the most important driver of impacts such as ozone depletion, photochemical smog, eutrophication, and carcinogenicity. Accordingly, battery reuse after refurbishment and recovery of materials in the end-of-life stage could significantly mitigate most of the overall life cycle impacts by reducing the consumption of virgin materials. However, currently, 95% of total lead emissions are released in the end-of-life stage due to improper management of the spent LABs recycling market in China, and these emissions causes 90% of total human toxicity potential. Battery manufacture only accounts for 3% of total lead emissions after the national cleanup action for heavy metal pollution. Moreover, sensitivity coefficients are employed to evaluate the reliability and uncertainty of the LCA results. Based on the findings, there are several substantial opportunities to further reduce the overall environmental impacts of LABs, such as prolonging the lifetime of LABs, reducing the consumption of metals in LABs, and improving the technology and management in the recovery of spent LABs. (C) 2015 Elsevier Ltd. All rights reserved.",0959-6526,1879-1786,,1149-1156, , ,,out_of_scope,
4301,"Title:Task-based evaluation of fluorescent-guided cancer surgery as a means of identifying optimal imaging agent properties in the context of variability in tumor- and healthy-tissue physiology.

 Fluorescent molecular-guided surgery (FGS) is at a tipping point in terms of clinical approval and adoption in a number cancer applications, with ongoing phase 0 and phase 1 clinical trials being carried out in a wide range of cancers using a wide range of agents. The pharmacokinetics of each of these agents and the physiology of these cancers can differ vastly on a patient-to-patient basis, bringing to question: how can one fairly compare different methodologies (defined as the combination of imaging agent, system, and protocol) and how can existing methodologies be further optimized? To this point, little methodology comparison has been carried out, and the majority of FGS optimization has concerned system development-on the level of maximizing signal-to-noise, dynamic detection range, and sensitivity-independently from traditional agent development-in terms of fluorophore brightness, toxicity, solubility, and binding affinity and specificity. Here we propose an inclusion of tumor and healthy tissue physiology (blood flow, vascular permeability, specific and nonspecific binding sites, extracellular matrix, interstitial pressure, etc) variability into the optimization process and re-establish well-described task-based metrics for methodology optimization and comparing quality of one methodology to another. Two salient conclusions were identified: (1) contrast-to-background variability is a simple metric that correlates with difficult-to-carry-out task-based metrics for comparing methodologies, and (2) paired-agent imaging protocols offer unique advantages over single-imaging-agent studies for mitigating confounding tumor and background physiology variability.","Tichauer, Kenneth M; Wang, Cheng; Xu, Xiaochun; Samkoe, Kimberley S",,,Task-based evaluation of fluorescent-guided cancer surgery as a means of identifying optimal imaging agent properties in the context of variability in tumor- and healthy-tissue physiology.,11222,,10.1117/12.2546700 ,Journal Article ,2020.0,"Fluorescent molecular-guided surgery (FGS) is at a tipping point in terms of clinical approval and adoption in a number cancer applications, with ongoing phase 0 and phase 1 clinical trials being carried out in a wide range of cancers using a wide range of agents. The pharmacokinetics of each of these agents and the physiology of these cancers can differ vastly on a patient-to-patient basis, bringing to question: how can one fairly compare different methodologies (defined as the combination of imaging agent, system, and protocol) and how can existing methodologies be further optimized? To this point, little methodology comparison has been carried out, and the majority of FGS optimization has concerned system development-on the level of maximizing signal-to-noise, dynamic detection range, and sensitivity-independently from traditional agent development-in terms of fluorophore brightness, toxicity, solubility, and binding affinity and specificity. Here we propose an inclusion of tumor and healthy tissue physiology (blood flow, vascular permeability, specific and nonspecific binding sites, extracellular matrix, interstitial pressure, etc) variability into the optimization process and re-establish well-described task-based metrics for methodology optimization and comparing quality of one methodology to another. Two salient conclusions were identified: (1) contrast-to-background variability is a simple metric that correlates with difficult-to-carry-out task-based metrics for comparing methodologies, and (2) paired-agent imaging protocols offer unique advantages over single-imaging-agent studies for mitigating confounding tumor and background physiology variability.",0277-786X,,,, , ,,out_of_scope,
4302,"Title:Humor Reduces Online Incivility

 Online incivility is a persistent issue facing many news and social media platforms. To better understand it, we examined whether humorous content reduced online incivility and whether the (in)civility of another user might mitigate or amplify this effect in two experiments (Study 1, N = 122; Study 2, N = 208). Participants in both experiments read an online opinion article about an instance of negative stereotyping and provided a comment on a simulated online news forum. The first study manipulated article humor (humorous vs. not humorous). The second study manipulated humor and the (in)civility of a previous user's comment (civil vs. uncivil). In both studies, humor-reduced incivility. Anger mediated this effect. Source liking mediated the positive effect of humor on reducing anger. The (in)civility of a previous comment did not affect these results. Overall, the findings point to the value of humor and anger reduction in managing online incivility. Lay Summary Online incivility is a common occurrence in online public forums. This article investigated factors that may reduce incivility in two online experiments. The first experiment tested whether humor reduced anger and subsequently the incivility of participants' comments towards a negative stereotype-challenging op-ed article. The second experiment tested whether exposure to civil and uncivil previous user comments influenced the civility of participants' comments. Humor was found to reduce online incivility by reducing feelings of anger and increasing liking towards the author in both experiments. Exposure to another user's comment, whether civil or uncivil, did not appear to influence the civility of participants' comments, suggesting that article content is a more likely trigger for online incivility.","Elsayed, Yomna; Hollingshead, Andrea B.",,,Humor Reduces Online Incivility,27,3,10.1093/jcmc/zmac005 ,Article ,2022.0,"Online incivility is a persistent issue facing many news and social media platforms. To better understand it, we examined whether humorous content reduced online incivility and whether the (in)civility of another user might mitigate or amplify this effect in two experiments (Study 1, N = 122; Study 2, N = 208). Participants in both experiments read an online opinion article about an instance of negative stereotyping and provided a comment on a simulated online news forum. The first study manipulated article humor (humorous vs. not humorous). The second study manipulated humor and the (in)civility of a previous user's comment (civil vs. uncivil). In both studies, humor-reduced incivility. Anger mediated this effect. Source liking mediated the positive effect of humor on reducing anger. The (in)civility of a previous comment did not affect these results. Overall, the findings point to the value of humor and anger reduction in managing online incivility. Lay Summary Online incivility is a common occurrence in online public forums. This article investigated factors that may reduce incivility in two online experiments. The first experiment tested whether humor reduced anger and subsequently the incivility of participants' comments towards a negative stereotype-challenging op-ed article. The second experiment tested whether exposure to civil and uncivil previous user comments influenced the civility of participants' comments. Humor was found to reduce online incivility by reducing feelings of anger and increasing liking towards the author in both experiments. Exposure to another user's comment, whether civil or uncivil, did not appear to influence the civility of participants' comments, suggesting that article content is a more likely trigger for online incivility.",1083-6101,,,, , ,,out_but_toxicity,
4303,"Title:Synthesis of cosmetic grade TiO2-SiO2 core-shell powder from mechanically milled TiO2 nanopowder for commercial mass production

 TiO2 nanoparticles as an active sunscreen ingredient generate reactive oxygen species (ROS) upon UVA irradiation which is cytotoxic, genotoxic and potential to damage the DNA. The health concern and potential risks from TiO2 can be mitigated by shielding the particles through the suitable coating. Considering the advantages of SiO2, SiO2 coated TiO2 nanoparticles can be a potential material which can replace TiO2 for thickening, whitening, lubricating, and sunscreen ingredient in cosmetics. This article reports the synthesis of cosmetic grade TiO2-SiO2 core-shell nanopowder from mechanically milled TiO2 nanopowder for commercial mass production. From commercial TiO2 nanopowder was fabricated through size reduction by nanoset milling. Followed by the fabricated TiO(2 )nanopowder coated with SiO2 through sol-gel technique. A suitable optimum condition was explored for cosmetic grade TiO2-SiO2 core-shell nanopowder. Various physical properties and optical properties were analyzed. Synthesized of cosmetic grade TiO2-SiO2 core-shell nanopowder found to be at 100 nm size, with a homogeneous SiO2 coating having UVA protection factor 39 and sun protection factor (SPF) is 42. From the size, safety, and SPF perspective it can be an excellent cosmetic grade powder and from process simplicity perspective it can be commercially viable.","Swain, Basudev; Park, Jae Ryang; Park, Kyung-Soo; Lee, Chan Gi","Swain, Basudev/F-1230-2014; Swain, Basudev/AAN-5720-2021","Swain, Basudev/0000-0003-2771-8058;",Synthesis of cosmetic grade TiO2-SiO2 core-shell powder from mechanically milled TiO2 nanopowder for commercial mass production,95,,10.1016/j.msec.2018.10.005 ,Article ,2019.0,"TiO2 nanoparticles as an active sunscreen ingredient generate reactive oxygen species (ROS) upon UVA irradiation which is cytotoxic, genotoxic and potential to damage the DNA. The health concern and potential risks from TiO2 can be mitigated by shielding the particles through the suitable coating. Considering the advantages of SiO2, SiO2 coated TiO2 nanoparticles can be a potential material which can replace TiO2 for thickening, whitening, lubricating, and sunscreen ingredient in cosmetics. This article reports the synthesis of cosmetic grade TiO2-SiO2 core-shell nanopowder from mechanically milled TiO2 nanopowder for commercial mass production. From commercial TiO2 nanopowder was fabricated through size reduction by nanoset milling. Followed by the fabricated TiO(2 )nanopowder coated with SiO2 through sol-gel technique. A suitable optimum condition was explored for cosmetic grade TiO2-SiO2 core-shell nanopowder. Various physical properties and optical properties were analyzed. Synthesized of cosmetic grade TiO2-SiO2 core-shell nanopowder found to be at 100 nm size, with a homogeneous SiO2 coating having UVA protection factor 39 and sun protection factor (SPF) is 42. From the size, safety, and SPF perspective it can be an excellent cosmetic grade powder and from process simplicity perspective it can be commercially viable.",0928-4931,1873-0191,,95-103, , ,,out_of_scope,
4304,"Title:Physiologically based pharmacokinetic (PBPK) tool kit for environmental pollutants - metals

 The Agency for Toxic Substances and Disease Registry (ATSDR) is mandated by the US Congress to identify significant human exposure levels, develop methods to determine such exposures, and design strategies to mitigate them. Physiologically based pharmacokinetic (PBPK) models are increasingly being used to evaluate toxicity of environmental pollutants through multiple exposure pathways. As part of its translational research project, ATSDR is developing a human 'PBPK model tool kit' that consists of a series of published models re-coded in a common simulation language. The tool kit currently consists of models, at various stages of development, for priority environmental contaminants including solvents and persistent organic pollutants. Presented here are results of translational activities of re-coding models for cadmium, mercury, and arsenic. As part of this work, following re-coding each new model was evaluated for fidelity followed by sensitivity analysis. Good agreement was generally obtained for all three models when predictions of original and re-coded model simulations were compared. Also presented is an application of the cadmium toxicokinetic model to interpret biomonitoring data from the National Health and Nutrition Examination Survey (NHANES). The PBPK tool kit will enable ATSDR scientists to perform simulations of exposures from contaminated environmental media at sites of concern and to better interpret site-specific biomonitoring data.","Ruiz, P.; Fowler, B. A.; Osterloh, J. D.; Fisher, J.; Mumtaz, M.",,,Physiologically based pharmacokinetic (PBPK) tool kit for environmental pollutants - metals,21,7-8,10.1080/1062936X.2010.528942 ,Article ,2010.0,"The Agency for Toxic Substances and Disease Registry (ATSDR) is mandated by the US Congress to identify significant human exposure levels, develop methods to determine such exposures, and design strategies to mitigate them. Physiologically based pharmacokinetic (PBPK) models are increasingly being used to evaluate toxicity of environmental pollutants through multiple exposure pathways. As part of its translational research project, ATSDR is developing a human 'PBPK model tool kit' that consists of a series of published models re-coded in a common simulation language. The tool kit currently consists of models, at various stages of development, for priority environmental contaminants including solvents and persistent organic pollutants. Presented here are results of translational activities of re-coding models for cadmium, mercury, and arsenic. As part of this work, following re-coding each new model was evaluated for fidelity followed by sensitivity analysis. Good agreement was generally obtained for all three models when predictions of original and re-coded model simulations were compared. Also presented is an application of the cadmium toxicokinetic model to interpret biomonitoring data from the National Health and Nutrition Examination Survey (NHANES). The PBPK tool kit will enable ATSDR scientists to perform simulations of exposures from contaminated environmental media at sites of concern and to better interpret site-specific biomonitoring data.",1062-936X,1029-046X,,603-618, , ,,out_of_scope,
4305,"Title:A GIS-based Upscaling Estimation of Nutrient Runoff Losses from Rice Paddy Fields to a Regional Level

 Nutrient runoff losses from cropping fields can lead to nonpoint source pollution; however, the level of nutrient export is difficult to evaluate, particularly at the regional scale. This study aimed to establish a novel yet simple approach for estimating total nitrogen (TN) and total phosphorus (TP) runoff losses from regional paddy fields. In this approach, temporal changes of nutrient concentrations in floodwater were coupled with runoff-processing functions in rice (Oryza sativa L.) fields to calculate nutrient runoff losses for three site-specific field experiments. Validation experiments verified the accuracy of this method. The geographic information system technique was used to upscale and visualize the TN and TP runoff losses from field to regional scales. The results indicated that nutrient runoff losses had significant spatio-temporal variation characteristics during rice seasons, which were positively related to fertilizer rate and precipitation. The average runoff losses over five study seasons were 20.21 kg N ha(-1) for TN and 0.76 kg P ha(-1) for TP. Scenario analysis showed that TN and TP losses dropped by 7.64 and 3.0%, respectively, for each 10% reduction of fertilizer input. For alternate wetting and drying water management, the corresponding reduction ratio was 24.7 and 14.0% respectively. Our results suggest that, although both water and fertilizer management can mitigate nutrient runoff losses, the former is significantly more effective.","Sun, Xiaoxiao; Liang, Xinqiang; Zhang, Feng; Fu, Chaodong","Sun, Xiaoxiao/JQJ-6420-2023",,A GIS-based Upscaling Estimation of Nutrient Runoff Losses from Rice Paddy Fields to a Regional Level,45,6,10.2134/jeq2016.05.0181 ,Article ,2016.0,"Nutrient runoff losses from cropping fields can lead to nonpoint source pollution; however, the level of nutrient export is difficult to evaluate, particularly at the regional scale. This study aimed to establish a novel yet simple approach for estimating total nitrogen (TN) and total phosphorus (TP) runoff losses from regional paddy fields. In this approach, temporal changes of nutrient concentrations in floodwater were coupled with runoff-processing functions in rice (Oryza sativa L.) fields to calculate nutrient runoff losses for three site-specific field experiments. Validation experiments verified the accuracy of this method. The geographic information system technique was used to upscale and visualize the TN and TP runoff losses from field to regional scales. The results indicated that nutrient runoff losses had significant spatio-temporal variation characteristics during rice seasons, which were positively related to fertilizer rate and precipitation. The average runoff losses over five study seasons were 20.21 kg N ha(-1) for TN and 0.76 kg P ha(-1) for TP. Scenario analysis showed that TN and TP losses dropped by 7.64 and 3.0%, respectively, for each 10% reduction of fertilizer input. For alternate wetting and drying water management, the corresponding reduction ratio was 24.7 and 14.0% respectively. Our results suggest that, although both water and fertilizer management can mitigate nutrient runoff losses, the former is significantly more effective.",0047-2425,1537-2537,,1865-1873, , ,,out_of_scope,
4306,"Title:Carbon nanomaterials differentially impact bioaccumulation and oxidative response of phenanthrene and methyl derivatives in geophagous earthworms (Metaphire guillelmi): A multi-contaminant exposure study

 Carbon nanomaterials (CNMs) are increasingly released to the terrestrial system, but information on their environmental fate and risk is rather limited. Fullerenes (C-60) and two multi-walled carbon nanotubes (outer diameter < 8 nm: MW8; > 50 nm: MW50) were added to soil to evaluate their impact on bioaccumulation and oxidative response of phenanthrene, 3-methylphenanthrene and 3,6-dimethylphenanthrene by the geophagous earthworm Metaphire guillelmi under single-(F1), bi-(F2) and tri-contaminant (F3) systems. High-sorption CNMs exhibited lithe or suppression effect on phenanthrene and 3-methylphenanthrene bioaccumulation, whereas these treatments stimulated 3,6-dimethylphenanthrene bioaccumulation (6.1-25.9%), indicating a dissimilar role of CNMs on contaminant uptake as a function of analyte type. Compared to the single-contaminant system, the alleviated suppression effect of certain CNM treatments on bioaccumulation of both compounds in F2 system, as well as the sorption-and dose-dependent bioavailability of two methylphenanthrenes in F3 system revealed significant and dissimilar molecular interactions in multi-contaminant systems. CNMs mitigated the synergetic bioaccumulation of three compounds except for 3,6-dimethylphenanthrene under MW8 co-exposure. Oxidative stress did occur in all three systems but only high-level CNMs in F3 system triggered significant damage with considerable MDA (malondialdehyde) generated in earthworms. This study provides insight into CNM-contaminant exposure and risk under environmentally relevant scenarios and highlights the importance of considering these complexities when assessing overall risk.","Zhang, Haiyun; Chen, Weixiao; Zhang, Xinyu; Wu, Fan; White, Jason C.; Tao, Shu; Wang, Xilong","wang, long/IZE-1764-2023; wang, xilong/M-1848-2017; wang, xl/Y-8251-2019; peng, jy/JMB-2297-2023","wang, xilong/0000-0002-5668-9703; peng, jy/0000-0001-9665-1059",Carbon nanomaterials differentially impact bioaccumulation and oxidative response of phenanthrene and methyl derivatives in geophagous earthworms (Metaphire guillelmi): A multi-contaminant exposure study,6,5,10.1016/j.jece.2018.10.007 ,Article ,2018.0,"Carbon nanomaterials (CNMs) are increasingly released to the terrestrial system, but information on their environmental fate and risk is rather limited. Fullerenes (C-60) and two multi-walled carbon nanotubes (outer diameter < 8 nm: MW8; > 50 nm: MW50) were added to soil to evaluate their impact on bioaccumulation and oxidative response of phenanthrene, 3-methylphenanthrene and 3,6-dimethylphenanthrene by the geophagous earthworm Metaphire guillelmi under single-(F1), bi-(F2) and tri-contaminant (F3) systems. High-sorption CNMs exhibited lithe or suppression effect on phenanthrene and 3-methylphenanthrene bioaccumulation, whereas these treatments stimulated 3,6-dimethylphenanthrene bioaccumulation (6.1-25.9%), indicating a dissimilar role of CNMs on contaminant uptake as a function of analyte type. Compared to the single-contaminant system, the alleviated suppression effect of certain CNM treatments on bioaccumulation of both compounds in F2 system, as well as the sorption-and dose-dependent bioavailability of two methylphenanthrenes in F3 system revealed significant and dissimilar molecular interactions in multi-contaminant systems. CNMs mitigated the synergetic bioaccumulation of three compounds except for 3,6-dimethylphenanthrene under MW8 co-exposure. Oxidative stress did occur in all three systems but only high-level CNMs in F3 system triggered significant damage with considerable MDA (malondialdehyde) generated in earthworms. This study provides insight into CNM-contaminant exposure and risk under environmentally relevant scenarios and highlights the importance of considering these complexities when assessing overall risk.",,2213-3437,,6537-6544, , ,,out_of_scope,
4307,"Title:Virtual bronchoscopy-guided lung SAbR: dosimetric implications of using AAA versus Acuros XB to calculate dose in airways

 In previous works, we showed that incorporating individual airways as organs-at-risk (OARs) in the treatment of lung stereotactic ablative radiotherapy (SAbR) patients potentially mitigates post-SAbR radiation injury. However, the performance of common clinical dose calculation algorithms in airways has not been thoroughly studied. Airways are of particular concern because their small size and the density differences they create have the potential to hinder dose calculation accuracy. To address this gap in knowledge, here we investigate dosimetric accuracy in airways of two commonly used dose calculation algorithms, the anisotropic analytical algorithm (AAA) and Acuros-XB (AXB), recreating clinical treatment plans on a cohort of four SAbR patients. A virtual bronchoscopy software was used to delineate 856 airways on a high-resolution breath-hold CT (BHCT) image acquired for each patient. The planning target volumes (PTVs) and standard thoracic OARs were contoured on an average CT (AVG) image over the breathing cycle. Conformal and intensity-modulated radiation therapy plans were recreated on the BHCT image and on the AVG image, for a total of four plan types per patient. Dose calculations were performed using AAA and AXB, and the differences in maximum and mean dose in each structure were calculated. The median differences in maximum dose among all airways were <= 0.3Gy in magnitude for all four plan types. With airways grouped by dose-to-structure or diameter, median dose differences were still <= 0.5Gy in magnitude, with no clear dependence on airway size. These results, along with our previous airway radiosensitivity works, suggest that dose differences between AAA and AXB correspond to an airway collapse variation <= 0.7% in magnitude. This variation in airway injury risk can be considered as not clinically relevant, and the use of either AAA or AXB is therefore appropriate when including patient airways as individual OARs so as to reduce risk of radiation-induced lung toxicity.","Kinkopf, P.; Modiri, A.; Yu, Kun-Chang; Yan, Y.; Mohindra, P.; Timmerman, R.; Sawant, A.; Vicente, E.",,,Virtual bronchoscopy-guided lung SAbR: dosimetric implications of using AAA versus Acuros XB to calculate dose in airways,7,6,10.1088/2057-1976/ac240c ,Article ,2021.0,"In previous works, we showed that incorporating individual airways as organs-at-risk (OARs) in the treatment of lung stereotactic ablative radiotherapy (SAbR) patients potentially mitigates post-SAbR radiation injury. However, the performance of common clinical dose calculation algorithms in airways has not been thoroughly studied. Airways are of particular concern because their small size and the density differences they create have the potential to hinder dose calculation accuracy. To address this gap in knowledge, here we investigate dosimetric accuracy in airways of two commonly used dose calculation algorithms, the anisotropic analytical algorithm (AAA) and Acuros-XB (AXB), recreating clinical treatment plans on a cohort of four SAbR patients. A virtual bronchoscopy software was used to delineate 856 airways on a high-resolution breath-hold CT (BHCT) image acquired for each patient. The planning target volumes (PTVs) and standard thoracic OARs were contoured on an average CT (AVG) image over the breathing cycle. Conformal and intensity-modulated radiation therapy plans were recreated on the BHCT image and on the AVG image, for a total of four plan types per patient. Dose calculations were performed using AAA and AXB, and the differences in maximum and mean dose in each structure were calculated. The median differences in maximum dose among all airways were <= 0.3Gy in magnitude for all four plan types. With airways grouped by dose-to-structure or diameter, median dose differences were still <= 0.5Gy in magnitude, with no clear dependence on airway size. These results, along with our previous airway radiosensitivity works, suggest that dose differences between AAA and AXB correspond to an airway collapse variation <= 0.7% in magnitude. This variation in airway injury risk can be considered as not clinically relevant, and the use of either AAA or AXB is therefore appropriate when including patient airways as individual OARs so as to reduce risk of radiation-induced lung toxicity.",2057-1976,,,, , ,,out_of_scope,
4308,"Title:A nitroreductase DnrA catalyzes the biotransformation of several diphenyl ether herbicides in Bacillus sp. Za

 Diphenyl ether herbicides, typical globally used herbicides, threaten the agricultural environment and the sensitive crops. The microbial degradation pathways of diphenyl ether herbicides are well studied, but the nitroreduction of diphenyl ether herbicides by purified enzymes is still unclear. Here, the gene dnrA, encoding a nitroreductase DnrA responsible for the reduction of nitro to amino groups, was identified from the strain Bacillus sp. Za. DnrA had a broad substrate spectrum, and the Km values of DnrA for different diphenyl ether herbicides were 20.67 mu M (fomesafen), 23.64 mu M (bifenox), 26.19 mu M (fluoroglycofen), 28.24 mu M (acifluorfen), and 36.32 mu M (lactofen). DnrA also mitigated the growth inhibition effect on cucumber and sorghum through nitroreduction. Molecular docking revealed the mechanisms of the compounds fomesafen, bifenox, fluoroglycofen, lactofen, and acifluorfen with DnrA. Fomesafen showed higher affinities and lower binding energy values for DnrA, and residue Arg244 affected the affinity between diphenyl ether herbicides and DnrA. This research provides new genetic resources and insights into the microbial remediation of diphenyl ether herbicide-contaminated environments.","Tian, Yanning; Zhao, Guoqiang; Cheng, Minggen; Lu, Luyao; Zhang, Hao; Huang, Xing",,,A nitroreductase DnrA catalyzes the biotransformation of several diphenyl ether herbicides in Bacillus sp. Za,107,16,10.1007/s00253-023-12647-5 ,Article ,2023.0,"Diphenyl ether herbicides, typical globally used herbicides, threaten the agricultural environment and the sensitive crops. The microbial degradation pathways of diphenyl ether herbicides are well studied, but the nitroreduction of diphenyl ether herbicides by purified enzymes is still unclear. Here, the gene dnrA, encoding a nitroreductase DnrA responsible for the reduction of nitro to amino groups, was identified from the strain Bacillus sp. Za. DnrA had a broad substrate spectrum, and the Km values of DnrA for different diphenyl ether herbicides were 20.67 mu M (fomesafen), 23.64 mu M (bifenox), 26.19 mu M (fluoroglycofen), 28.24 mu M (acifluorfen), and 36.32 mu M (lactofen). DnrA also mitigated the growth inhibition effect on cucumber and sorghum through nitroreduction. Molecular docking revealed the mechanisms of the compounds fomesafen, bifenox, fluoroglycofen, lactofen, and acifluorfen with DnrA. Fomesafen showed higher affinities and lower binding energy values for DnrA, and residue Arg244 affected the affinity between diphenyl ether herbicides and DnrA. This research provides new genetic resources and insights into the microbial remediation of diphenyl ether herbicide-contaminated environments.",0175-7598,1432-0614,,5269-5279, , ,,out_of_scope,
4309,"Title:Prospective environmental risk screening of seven advanced materials based on production volumes and aquatic ecotoxicity

 The number and volume of advanced materials being manufactured is increasing. In order to mitigate future impacts from such materials, assessment methods that can provide early indications of potential environmental risk are required. This paper presents a further development and testing of an environmental risk screening method based on two proxy measures: aquatic ecotoxicity and global annual production volumes. In addition to considering current production volumes, this further developed method considers potential future production volumes, thereby enabling prospective environmental risk screening. The proxy measures are applied to seven advanced materials: graphene, graphene oxide, nanocellulose, nanodiamond, quantum dots, nano-sized molybdenum disulfide, and MXenes. Only MXenes show high aquatic ecotoxicity, though the number of test results is still very limited. While current production volumes are relatively modest for most materials, several of the materials (graphene, graphene oxide, nanocellulose, nano-sized molybdenum disulfide, and MXenes) have the potential to become high-volume materials in the future. For MXenes, with both high aquatic ecotoxicity and high potential future production volumes, more detailed environmental risk assessments should be considered. For the other materials with high potential future production volumes, the recommendation is to continuously monitor their aquatic ecotoxicity data. Based on the application of the proxy measures combined with future scenarios for production volumes, we recommend this environmental risk screening method be used in the early development of advanced materials to prioritize which advanced materials should be subject to more detailed environmental assessments.","Arvidsson, Rickard; Peters, Gregory; Hansen, Steffen Foss; Baun, Anders","Foss Hansen, Steffen/L-8182-2019; Arvidsson, Rickard/AAV-7598-2020; Baun, Anders/A-1330-2010","Foss Hansen, Steffen/0000-0003-4342-7779; Arvidsson, Rickard/0000-0002-9258-0641; Baun, Anders/0000-0003-1396-408X",Prospective environmental risk screening of seven advanced materials based on production volumes and aquatic ecotoxicity,25,,10.1016/j.impact.2022.100393 ,Article ,2022.0,"The number and volume of advanced materials being manufactured is increasing. In order to mitigate future impacts from such materials, assessment methods that can provide early indications of potential environmental risk are required. This paper presents a further development and testing of an environmental risk screening method based on two proxy measures: aquatic ecotoxicity and global annual production volumes. In addition to considering current production volumes, this further developed method considers potential future production volumes, thereby enabling prospective environmental risk screening. The proxy measures are applied to seven advanced materials: graphene, graphene oxide, nanocellulose, nanodiamond, quantum dots, nano-sized molybdenum disulfide, and MXenes. Only MXenes show high aquatic ecotoxicity, though the number of test results is still very limited. While current production volumes are relatively modest for most materials, several of the materials (graphene, graphene oxide, nanocellulose, nano-sized molybdenum disulfide, and MXenes) have the potential to become high-volume materials in the future. For MXenes, with both high aquatic ecotoxicity and high potential future production volumes, more detailed environmental risk assessments should be considered. For the other materials with high potential future production volumes, the recommendation is to continuously monitor their aquatic ecotoxicity data. Based on the application of the proxy measures combined with future scenarios for production volumes, we recommend this environmental risk screening method be used in the early development of advanced materials to prioritize which advanced materials should be subject to more detailed environmental assessments.",2452-0748,,,, , ,,out_of_scope,
4310,"Title:Toleration and Accumulation of Cotton to Heavy Metal-Potential Use for Phytoremediation

 Heavy metal contamination of agricultural soil has become a critical issue worldwide. A sustainable approach to mitigate heavy metal contamination is extremely important. Phytoremediation has been proved to be a well alternative for soil remediation as cost-effective, environment friendly, and esthetically pleasing. This review briefly elucidates heavy metal tolerance, uptake, and the corresponding mechanism in cotton, and discusses the risk of heavy metal residues and the socioeconomic benefits, to further assess cotton planting for phytoremediation of heavy metal-contaminated soils. Cotton plant has a relatively large biomass, a profuse toot system, and exhibits very excellent tolerance and enrichment capacity of heavy metals. Heavy metals residue in cotton was low. Especially, the content of heavy metal in the fiber, the main product of cotton, is obviously negligible. In brief, cotton as a fiber crop can be a promising candidate for phytoremediation of contaminated soils with heavy metals, which could minimize the risk of human food chain contamination and benefit in ecological and socioeconomic terms.","Li, Changfeng; Zheng, Cangsong; Zhou, Kehai; Han, Wenbing; Tian, Changjiu; Ye, Sihong; Zhao, Changbao; Zhou, Hao; Yan, Xiaoming; Ma, Xiongfeng","Zheng, Cangsong/HCI-1365-2022",,Toleration and Accumulation of Cotton to Heavy Metal-Potential Use for Phytoremediation,29,5,10.1080/15320383.2020.1747979 ,Article ,2020.0,"Heavy metal contamination of agricultural soil has become a critical issue worldwide. A sustainable approach to mitigate heavy metal contamination is extremely important. Phytoremediation has been proved to be a well alternative for soil remediation as cost-effective, environment friendly, and esthetically pleasing. This review briefly elucidates heavy metal tolerance, uptake, and the corresponding mechanism in cotton, and discusses the risk of heavy metal residues and the socioeconomic benefits, to further assess cotton planting for phytoremediation of heavy metal-contaminated soils. Cotton plant has a relatively large biomass, a profuse toot system, and exhibits very excellent tolerance and enrichment capacity of heavy metals. Heavy metals residue in cotton was low. Especially, the content of heavy metal in the fiber, the main product of cotton, is obviously negligible. In brief, cotton as a fiber crop can be a promising candidate for phytoremediation of contaminated soils with heavy metals, which could minimize the risk of human food chain contamination and benefit in ecological and socioeconomic terms.",1532-0383,1549-7887,,516-531, , ,,out_of_scope,
4311,"Title:Irrigating with arsenic contaminated groundwater in West Bengal and Bangladesh: A review of interventions for mitigating adverse health and crop outcomes

 There is a rich body of literature on arsenic (As) contamination of groundwater and its consequences for human health via drinking water. Less is known however, on the impacts that flow from the use of arsenic rich groundwater for irrigation or the effectiveness of arsenic remediation in agricultural systems. To partially fill this gap, we review 29 studies that examine the consequences of irrigating with arsenic contaminated groundwater and 28 studies which evaluate interventions aimed at reducing its negative impacts on human health and crops. These studies are geographically limited to West Bengal and Bangladesh (Bengal plains) as these regions constitute hubs of concerns for groundwater contamination. These studies show that there are six broad categories of interventions: deficit irrigation; soil fertilization; growing alternative field crops (other than paddy); switching to arsenic tolerant paddy cultivars; cooking methods to reduce arsenic content in rice and nutritional supplements. Importantly, these efforts target different stages of the agri-food system, some intervene in production processes and balance concerns for crop yields and human health while others focus on consumption practices and only mitigate health risks. Despite this diversity in focus, our results indicate that all treatments have positive effects, either in reducing As content in grains, its accumulation in soil and/or increase crop yields compared to control groups. However, the extent of these impacts varies as do their implications for long-term agricultural sustainability. From a policy perspective, these interventions offer promising alternatives to the extremes of restricted groundwater use on the one hand, and unregulated extraction on the other, but are yet to be integrated into mainstream extension services. (c) 2014 Elsevier B.V. All rights reserved.","Senanayake, Nan I.; Mukherji, Aditi",,"Senanayake, Nari/0000-0003-4464-3844; Mukherji, Aditi/0000-0002-8061-4349",Irrigating with arsenic contaminated groundwater in West Bengal and Bangladesh: A review of interventions for mitigating adverse health and crop outcomes,135,,10.1016/j.agwat.2013.12.015 ,Review ,2014.0,"There is a rich body of literature on arsenic (As) contamination of groundwater and its consequences for human health via drinking water. Less is known however, on the impacts that flow from the use of arsenic rich groundwater for irrigation or the effectiveness of arsenic remediation in agricultural systems. To partially fill this gap, we review 29 studies that examine the consequences of irrigating with arsenic contaminated groundwater and 28 studies which evaluate interventions aimed at reducing its negative impacts on human health and crops. These studies are geographically limited to West Bengal and Bangladesh (Bengal plains) as these regions constitute hubs of concerns for groundwater contamination. These studies show that there are six broad categories of interventions: deficit irrigation; soil fertilization; growing alternative field crops (other than paddy); switching to arsenic tolerant paddy cultivars; cooking methods to reduce arsenic content in rice and nutritional supplements. Importantly, these efforts target different stages of the agri-food system, some intervene in production processes and balance concerns for crop yields and human health while others focus on consumption practices and only mitigate health risks. Despite this diversity in focus, our results indicate that all treatments have positive effects, either in reducing As content in grains, its accumulation in soil and/or increase crop yields compared to control groups. However, the extent of these impacts varies as do their implications for long-term agricultural sustainability. From a policy perspective, these interventions offer promising alternatives to the extremes of restricted groundwater use on the one hand, and unregulated extraction on the other, but are yet to be integrated into mainstream extension services. (c) 2014 Elsevier B.V. All rights reserved.",0378-3774,1873-2283,,90-99, , ,,out_of_scope,
4312,"Title:Longitudinal Study on Seasonal Variation of Marine Biotoxins and Related Harmful Algae in Bivalve Mollusks Bred in Sardinia (Italy, W Mediterranean Sea) from 2015 to 2020 and Assessment of Potential Public Health Risks

 Annual and interannual dynamics of shellfish toxins and associated harmful algal species (HAS) were analyzed from 2015 to 2020 in Tortoli Lagoon (Sardinia, west Mediterranean Sea). Analysis of seasonal occurrence of different harmful algae, such as Dinophysis spp., Prorocentrum spp., Pseudo-nitzschia spp. and Alexandrium minutum, was performed. The species Dinophysis acuminata and Dinophysis sacculus were responsible for the accumulation of lipophilic toxins belonging to the okadaic acid group (OAs) and pectenotoxins2 (PTX2) in bivalve mollusks. The highest HAS detection was recorded in the winter months; in particular, Dinophysis spp. was mostly present in January-February. Out of 1090 analyzed mollusk samples, 39 were non-compliant, exceeding the legal limits (160 mu g OA eq/kg e.p.) reported in Regulation 853/2004 of the European Commission. A statistical analysis related to the presence of OA and PTX2 in mollusks with various environmental parameters (pH, water temperature, dissolved oxygen, algal density) was implemented, proving a clear winter seasonality. The present study highlights the necessity to better understand the different factors able to influence the production and accumulation of toxins in bivalve mollusks bred in an important Sardinian production area. The contribution of this research is important not only from an environmental and productive point of view but also from the view of implementing management in order to mitigate any harm to human health.","Mudadu, Alessandro G.; Bazzoni, Anna Maria; Congiu, Virgilio; Esposito, Giuseppe; Cesarani, Alberto; Melillo, Rita; Lorenzoni, Giuseppa; Cau, Simona; Soro, Barbara; Vodret, Bruna; Meloni, Domenico; Virgilio, Sebastiano","Cesarani, Alberto/T-3062-2018; Esposito, Giuseppe/HKE-1040-2023; Mudadu, Alessandro Graziano/AAE-7957-2021; Melillo, Rita/AAA-7235-2020","Cesarani, Alberto/0000-0003-4637-8669; Esposito, Giuseppe/0000-0001-6665-2712; Melillo, Rita/0000-0001-8783-1584; Cau, Simona/0000-0001-5141-2468; MELONI, Domenico/0000-0002-0423-4635; Bazzoni, Anna Maria/0000-0001-7236-3845; Mudadu, Alessandro Graziano/0000-0002-7078-4838; Soro, Barbara/0000-0002-8013-0918","Longitudinal Study on Seasonal Variation of Marine Biotoxins and Related Harmful Algae in Bivalve Mollusks Bred in Sardinia (Italy, W Mediterranean Sea) from 2015 to 2020 and Assessment of Potential Public Health Risks",9,5,10.3390/jmse9050510 ,Article ,2021.0,"Annual and interannual dynamics of shellfish toxins and associated harmful algal species (HAS) were analyzed from 2015 to 2020 in Tortoli Lagoon (Sardinia, west Mediterranean Sea). Analysis of seasonal occurrence of different harmful algae, such as Dinophysis spp., Prorocentrum spp., Pseudo-nitzschia spp. and Alexandrium minutum, was performed. The species Dinophysis acuminata and Dinophysis sacculus were responsible for the accumulation of lipophilic toxins belonging to the okadaic acid group (OAs) and pectenotoxins2 (PTX2) in bivalve mollusks. The highest HAS detection was recorded in the winter months; in particular, Dinophysis spp. was mostly present in January-February. Out of 1090 analyzed mollusk samples, 39 were non-compliant, exceeding the legal limits (160 mu g OA eq/kg e.p.) reported in Regulation 853/2004 of the European Commission. A statistical analysis related to the presence of OA and PTX2 in mollusks with various environmental parameters (pH, water temperature, dissolved oxygen, algal density) was implemented, proving a clear winter seasonality. The present study highlights the necessity to better understand the different factors able to influence the production and accumulation of toxins in bivalve mollusks bred in an important Sardinian production area. The contribution of this research is important not only from an environmental and productive point of view but also from the view of implementing management in order to mitigate any harm to human health.",,2077-1312,,, , ,,out_of_scope,
4313,"Title:On the Stability of Proteins Solvated in Imidazolium-Based Ionic Liquids Studied with Replica Exchange Molecular Dynamics

 The stability of two small proteins, one composed of three alpha-helices (alpha-peptide) and another composed of a beta-sheet (beta-peptide) solvated in five different ionic liquids (ILs), is analyzed using replica exchange molecular dynamics (REMD) simulations. ILs are composed of 1-butyl-3-methylimidazolium (BMIM) cations, paired with five different anions of varying hydrophilicity Gland size, namely, Cl-, NO3-, BF4-, PF6-, and NTf2-. REMD simulations greatly improve structure sampling and mitigate bias toward the initial folded peptide structure, thereby providing more adequate simulations to study protein stability. Cluster analysis, DSSP analysis and derivation of radius of gyration, interaction energies, and hydrogen bonding are used to quantify structural peptide changes in a large temperature range from 250 to 650 K. alpha-Peptides are least stable in ILs that contain small anions with localized negative charge, such as in BMIM-Cl and BMIM-NO3. Destabilization is caused by direct electrostatic interactions of anions with alpha-helices that are exposed to the solvent. This destabilization is characterized not by unfolded but instead by compact misfolded structures. Also, beta-peptides retain compact structures up to at least 400 K, below which unfolding hardly occurs. However, intrapeptide hydrogen bonds that constitute the beta-sheet are not exposed to the solvent. Therefore, beta-peptides are generally more stable than alpha-peptides in all considered ILs. Moreover, on contrary to alpha-peptides, beta-peptides are least stable in less polar ILs, such as BMIM-PF6 and BMIM-NTf2, because dissolving beta-sheets requires large structural changes of the peptide. Such transitions are energetically less opposed in ILs with weaker mutual ion coordination. A large interaction density within ILs, for example, in BMIM-Cl, is thus kinetically trapping beta-peptides in the original folded state. Additionally, in BMIM-BF4, interactions with beta-peptides are so weak, compared to an aqueous solvent, resulting in stronger interactions within the peptide, which extend beta-sheets, hence causing misfolding of a different kind. The results reveal how direct ion-peptide interactions and solvent reorganization energy in ILs are both crucial in determining protein stability. These insights could translate into guidelines for the design of new IL solvents with improved protein stability.","Lim, Geraldine S.; Klahn, Marco",,,On the Stability of Proteins Solvated in Imidazolium-Based Ionic Liquids Studied with Replica Exchange Molecular Dynamics,122,39,10.1021/acs.jpcb.8b06452 ,Article ,2018.0,"The stability of two small proteins, one composed of three alpha-helices (alpha-peptide) and another composed of a beta-sheet (beta-peptide) solvated in five different ionic liquids (ILs), is analyzed using replica exchange molecular dynamics (REMD) simulations. ILs are composed of 1-butyl-3-methylimidazolium (BMIM) cations, paired with five different anions of varying hydrophilicity Gland size, namely, Cl-, NO3-, BF4-, PF6-, and NTf2-. REMD simulations greatly improve structure sampling and mitigate bias toward the initial folded peptide structure, thereby providing more adequate simulations to study protein stability. Cluster analysis, DSSP analysis and derivation of radius of gyration, interaction energies, and hydrogen bonding are used to quantify structural peptide changes in a large temperature range from 250 to 650 K. alpha-Peptides are least stable in ILs that contain small anions with localized negative charge, such as in BMIM-Cl and BMIM-NO3. Destabilization is caused by direct electrostatic interactions of anions with alpha-helices that are exposed to the solvent. This destabilization is characterized not by unfolded but instead by compact misfolded structures. Also, beta-peptides retain compact structures up to at least 400 K, below which unfolding hardly occurs. However, intrapeptide hydrogen bonds that constitute the beta-sheet are not exposed to the solvent. Therefore, beta-peptides are generally more stable than alpha-peptides in all considered ILs. Moreover, on contrary to alpha-peptides, beta-peptides are least stable in less polar ILs, such as BMIM-PF6 and BMIM-NTf2, because dissolving beta-sheets requires large structural changes of the peptide. Such transitions are energetically less opposed in ILs with weaker mutual ion coordination. A large interaction density within ILs, for example, in BMIM-Cl, is thus kinetically trapping beta-peptides in the original folded state. Additionally, in BMIM-BF4, interactions with beta-peptides are so weak, compared to an aqueous solvent, resulting in stronger interactions within the peptide, which extend beta-sheets, hence causing misfolding of a different kind. The results reveal how direct ion-peptide interactions and solvent reorganization energy in ILs are both crucial in determining protein stability. These insights could translate into guidelines for the design of new IL solvents with improved protein stability.",1520-6106,1520-5207,,9274-9288, , ,,out_of_scope,
4314,"Title:Microbial redemption of evil days: a global appraisal to food security

 Without refute, a sustainable global food security can only be achieved when all folks have physical, social and economic access to safe, nutritious, and sufficient supply of food to meet their dietary needs and food preferences for healthy life. To this end, quest to achieve this dream has been on course since 1970s as evident by the establishment of a committee on food security in 1975 by the UN World Food Conference to oversee and make developmental difference in food security. Interestingly, 2019 Global Hunger Index revealed transition in global hunger from serious to moderate with 31% decline in global hunger since 2000, and hence depicting enhanced food security. Despite this achievement, many countries are still battling with hunger and under-nutrition. Moreover, if the ''zero hunger'' goal envisaged by World Food Program is to be actualized by 2030, then it is crucial to pool efforts toward the provision of suggestive approach(es) for mitigating global hunger and under-nutrition while averting the evils days of food scarcity, starvation, food borne illnesses, wastage, malnutrition and death. On this note, microorganisms have revolutionized from the era of only being known as food spoilers and disease-causing agents to useful resources with the capability to improve food supply, food safety and food production through bio-preservation, bio-based production, bio-fertilization among others. Therefore, the exploration of microbes in redeeming the evils associated with food insecurity cannot but be appraised. To this end, this review proposes optimization of different microbial processes as food security enhancing agents.","Bankefa, Olufemi Emmanuel; Oladeji, Seye Julius; Ayilara-Akande, Simbiat Olufunke; Lasisi, Modupe Mariam","OLADEJI, Seye Julius/ABA-3925-2020","OLADEJI, Seye Julius/0000-0002-1526-2850; BANKEFA, OLUFEMI EMMANUEL/0000-0002-4557-8119",Microbial redemption of evil days: a global appraisal to food security,58,6,10.1007/s13197-020-04725-7 ,Review ,2021.0,"Without refute, a sustainable global food security can only be achieved when all folks have physical, social and economic access to safe, nutritious, and sufficient supply of food to meet their dietary needs and food preferences for healthy life. To this end, quest to achieve this dream has been on course since 1970s as evident by the establishment of a committee on food security in 1975 by the UN World Food Conference to oversee and make developmental difference in food security. Interestingly, 2019 Global Hunger Index revealed transition in global hunger from serious to moderate with 31% decline in global hunger since 2000, and hence depicting enhanced food security. Despite this achievement, many countries are still battling with hunger and under-nutrition. Moreover, if the ''zero hunger'' goal envisaged by World Food Program is to be actualized by 2030, then it is crucial to pool efforts toward the provision of suggestive approach(es) for mitigating global hunger and under-nutrition while averting the evils days of food scarcity, starvation, food borne illnesses, wastage, malnutrition and death. On this note, microorganisms have revolutionized from the era of only being known as food spoilers and disease-causing agents to useful resources with the capability to improve food supply, food safety and food production through bio-preservation, bio-based production, bio-fertilization among others. Therefore, the exploration of microbes in redeeming the evils associated with food insecurity cannot but be appraised. To this end, this review proposes optimization of different microbial processes as food security enhancing agents.",0022-1155,0975-8402,,2041-2053, , ,,out_of_scope,
4315,"Title:Use 3-D tomography to reveal structural modification of bentonite-enriched clay by nonionic surfactants: Application of organo-clay composites to detoxify aflatoxin B1 in chickens

 Although nonionic surfactants are relatively eco-friendly compared with cationic and anionic surfactants, few studies have investigated their application in modified clay. Herein we prepared organo-clay composites (OCCs) by mixing bentonite-enriched clay (BEC) with nonionic surfactants (Brij 30 and Igepal CO-890) and determined if these modifications would enable chickens to detoxify aflatoxin B1 (AFB1). For the first time, in situ three-dimensional (3-D) microstructures of modified BEC was characterized in suspension using transmission X-ray microscopy. Although X-ray diffraction patterns indicated the expansion in the spacing between planes of atoms (basal spacing) of surfactant-modified BEC, 3-D images indicated shrinkage in its microscale porous framework with increasing surfactant additions from 1 to 30 wt%. Such declining trends in porous dimensions caused by the dehydration in interlayer galleries of clays positively correlated with sorption amounts of AFB1 on OCCs. After chickens had consumed amended feeds for 11 weeks, AFB1 concentrations in liver, kidney, and plasma were significantly lower than in the control treatment. Thus, we suggest using BEC with 1 wt% surfactant addition, an amendment to chicken feeds, to detoxify AFB1. Modifying BEC with nonionic surfactants show the promise in mitigating AFB1 accumulation in chickens, which should improve food safety and reduce environmental contamination.","Tzou, Yu-Min; Chan, Ya-Ting; Chen, Shuen-Ei; Wang, Chun-Chieh; Chiang, Po-Neng; Teah, Heng Yi; Hung, Jui-Ting; Wu, Jeng-Jzung; Liu, Yu-Ting","Teah, Heng Yi/AAB-4412-2020; Tzou, Yu-Min/C-6585-2008; Teah, Heng Yi/ABE-4614-2020; TEAH, HENG YI/Q-1619-2017; Chen, Shuen-Ei/AAE-3574-2019; Chen, Shuen-Ei/B-2341-2019","Tzou, Yu-Min/0000-0002-3680-7303; TEAH, HENG YI/0000-0003-2923-4938; Chiang, Po-Neng/0000-0003-4269-3186; Chen, Shuen-Ei/0000-0003-1737-2591",Use 3-D tomography to reveal structural modification of bentonite-enriched clay by nonionic surfactants: Application of organo-clay composites to detoxify aflatoxin B1 in chickens,375,,10.1016/j.jhazmat.2019.04.084 ,Article ,2019.0,"Although nonionic surfactants are relatively eco-friendly compared with cationic and anionic surfactants, few studies have investigated their application in modified clay. Herein we prepared organo-clay composites (OCCs) by mixing bentonite-enriched clay (BEC) with nonionic surfactants (Brij 30 and Igepal CO-890) and determined if these modifications would enable chickens to detoxify aflatoxin B1 (AFB1). For the first time, in situ three-dimensional (3-D) microstructures of modified BEC was characterized in suspension using transmission X-ray microscopy. Although X-ray diffraction patterns indicated the expansion in the spacing between planes of atoms (basal spacing) of surfactant-modified BEC, 3-D images indicated shrinkage in its microscale porous framework with increasing surfactant additions from 1 to 30 wt%. Such declining trends in porous dimensions caused by the dehydration in interlayer galleries of clays positively correlated with sorption amounts of AFB1 on OCCs. After chickens had consumed amended feeds for 11 weeks, AFB1 concentrations in liver, kidney, and plasma were significantly lower than in the control treatment. Thus, we suggest using BEC with 1 wt% surfactant addition, an amendment to chicken feeds, to detoxify AFB1. Modifying BEC with nonionic surfactants show the promise in mitigating AFB1 accumulation in chickens, which should improve food safety and reduce environmental contamination.",0304-3894,1873-3336,,312-319, , ,,out_of_scope,
4316,"Title:Application of zinc oxide nanoparticles to promote remediation of nickel by Sorghum bicolor: metal ecotoxic potency and plant response

 Nickel (Ni) is one of the most toxic metals in human health. Its bioaccumulation in gluten-free crops limits the progressing demand of safe foods for allergic people to gluten. Nanoparticles have shown promising results in enhancing the crop yield and reducing the risk of heavy metal uptake. However, their nanotoxicity has been raised environmental concerns. This study investigated the environmental behavior of Ni (II) with the co-presence of Zinc Oxide Nanoparticles (ZnO-NPs) in sorghum bicolor. The plants were exposed to different treatments of Ni, ZnO-NPs, or their coexistence. The uptake experiments were carried out within nine treatments consisting of 1 or 5 ppm Ni alone or in coexistence with 50 or 100 ppm ZnO-NPs. The physiological impacts on plants as potential fingerprints for nanotoxicity were recorded and assessed in a phenotypic spectrum. The total Ni or Zn contents were quantified using atomic absorption. NPs significantly altered the bioavailability of Ni. The results revealed that at 5 ppm Ni contamination, 50 and 100 ZnO-NPs significantly reduced the Ni uptake by similar to 43% and 47%, respectively. Further, the results showed at 50 ppm NPs, the phytotoxicity effects of both Ni and NPs may reduce, leading to higher plant dry biomass yield. Novelty statement Characterization of zinc oxide nanotoxicity threshold by developing a phenotypic spectrum. Also, the study revealed the phytoremediation potential of ZnO nanoparticle in mitigating the nickel uptake in a gluten-free crop (sorghum bicolor).","Doria-Manzur, Alonso; Sharifan, Hamidreza; Tejeda-Benitez, Lesly","Sharifan, Hamidreza/E-9990-2018","Sharifan, Hamidreza/0000-0002-6990-0635; Tejeda-Benitez, Lesly/0000-0003-3240-917X; Doria-Manzur, Alonso/0000-0002-4572-1122",Application of zinc oxide nanoparticles to promote remediation of nickel by Sorghum bicolor: metal ecotoxic potency and plant response,25,1,10.1080/15226514.2022.2060934 ,Article ,2023.0,"Nickel (Ni) is one of the most toxic metals in human health. Its bioaccumulation in gluten-free crops limits the progressing demand of safe foods for allergic people to gluten. Nanoparticles have shown promising results in enhancing the crop yield and reducing the risk of heavy metal uptake. However, their nanotoxicity has been raised environmental concerns. This study investigated the environmental behavior of Ni (II) with the co-presence of Zinc Oxide Nanoparticles (ZnO-NPs) in sorghum bicolor. The plants were exposed to different treatments of Ni, ZnO-NPs, or their coexistence. The uptake experiments were carried out within nine treatments consisting of 1 or 5 ppm Ni alone or in coexistence with 50 or 100 ppm ZnO-NPs. The physiological impacts on plants as potential fingerprints for nanotoxicity were recorded and assessed in a phenotypic spectrum. The total Ni or Zn contents were quantified using atomic absorption. NPs significantly altered the bioavailability of Ni. The results revealed that at 5 ppm Ni contamination, 50 and 100 ZnO-NPs significantly reduced the Ni uptake by similar to 43% and 47%, respectively. Further, the results showed at 50 ppm NPs, the phytotoxicity effects of both Ni and NPs may reduce, leading to higher plant dry biomass yield. Novelty statement Characterization of zinc oxide nanotoxicity threshold by developing a phenotypic spectrum. Also, the study revealed the phytoremediation potential of ZnO nanoparticle in mitigating the nickel uptake in a gluten-free crop (sorghum bicolor).",1522-6514,1549-7879,,98-105, , ,,out_of_scope,
4317,"Title:Mitigating the Adverse Effects of Polychlorinated Biphenyl Derivatives on Estrogenic Activity via Molecular Modification Techniques

 The aim of this paper is to explore the mechanism of the change in oestrogenic activity of PCBs molecules before and after modification by designing new PCBs derivatives in combination with molecular docking techniques through the constructed model of oestrogenic activity of PCBs molecules. We found that the weakened hydrophobic interaction between the hydrophobic amino acid residues and hydrophobic substituents at the binding site of PCB derivatives and human oestrogen receptor alpha (hER alpha) was the main reason for the weakened binding force and reduced anti-oestrogenic activity. It was consistent with the information that the hydrophobic field displayed by the 3D contour maps in the constructed oestrogen activity CoMSIA model was one of the main influencing force fields. The hydrophobic interaction between PCB derivatives and oestrogen-active receptors was negatively correlated with the average distance between hydrophobic substituents and hydrophobic amino acid residues at the hER alpha-binding site, and positively correlated with the number of hydrophobic amino acid residues. In other words, the smaller the average distance between the hydrophobic amino acid residues at the binding sites between the two and the more the number of them, and the stronger the oestrogen activity expression degree of PCBS derivative molecules. Therefore, hydrophobic interactions between PCB derivatives and the oestrogen receptor can be reduced by altering the microenvironmental conditions in humans. This reduces the ability of PCB derivatives to bind to the oestrogen receptor and can effectively modulate the risk of residual PCB derivatives to produce oestrogenic activity in humans.","He, Wei; Zhang, Wenhui; Chu, Zhenhua; Li, Yu",,"Li, Yu/0000-0003-1430-7989",Mitigating the Adverse Effects of Polychlorinated Biphenyl Derivatives on Estrogenic Activity via Molecular Modification Techniques,18,9,10.3390/ijerph18094999 ,Article ,2021.0,"The aim of this paper is to explore the mechanism of the change in oestrogenic activity of PCBs molecules before and after modification by designing new PCBs derivatives in combination with molecular docking techniques through the constructed model of oestrogenic activity of PCBs molecules. We found that the weakened hydrophobic interaction between the hydrophobic amino acid residues and hydrophobic substituents at the binding site of PCB derivatives and human oestrogen receptor alpha (hER alpha) was the main reason for the weakened binding force and reduced anti-oestrogenic activity. It was consistent with the information that the hydrophobic field displayed by the 3D contour maps in the constructed oestrogen activity CoMSIA model was one of the main influencing force fields. The hydrophobic interaction between PCB derivatives and oestrogen-active receptors was negatively correlated with the average distance between hydrophobic substituents and hydrophobic amino acid residues at the hER alpha-binding site, and positively correlated with the number of hydrophobic amino acid residues. In other words, the smaller the average distance between the hydrophobic amino acid residues at the binding sites between the two and the more the number of them, and the stronger the oestrogen activity expression degree of PCBS derivative molecules. Therefore, hydrophobic interactions between PCB derivatives and the oestrogen receptor can be reduced by altering the microenvironmental conditions in humans. This reduces the ability of PCB derivatives to bind to the oestrogen receptor and can effectively modulate the risk of residual PCB derivatives to produce oestrogenic activity in humans.",,1660-4601,,, , ,,out_of_scope,
4318,"Title:The Impact of Artificial Intelligence on Health Equity in Oncology: Scoping Review

 Background: The field of oncology is at the forefront of advances in artificial intelligence (AI) in health care, providing an opportunity to examine the early integration of these technologies in clinical research and patient care. Hope that AI will revolutionize health care delivery and improve clinical outcomes has been accompanied by concerns about the impact of these technologies on health equity.Objective: We aimed to conduct a scoping review of the literature to address the question, What are the current and potential impacts of AI technologies on health equity in oncology?Methods: Following PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines for scoping reviews, we systematically searched MEDLINE and Embase electronic databases from January 2000 to August 2021 for records engaging with key concepts of AI, health equity, and oncology. We included all English-language articles that engaged with the 3 key concepts. Articles were analyzed qualitatively for themes pertaining to the influence of AI on health equity in oncology.Results: Of the 14,011 records, 133 (0.95%) identified from our review were included. We identified 3 general themes in the literature: the use of AI to reduce health care disparities (58/133, 43.6%), concerns surrounding AI technologies and bias (16/133, 12.1%), and the use of AI to examine biological and social determinants of health (55/133, 41.4%). A total of 3% (4/133) of articles focused on many of these themes.Conclusions: Our scoping review revealed 3 main themes on the impact of AI on health equity in oncology, which relate to AI's ability to help address health disparities, its potential to mitigate or exacerbate bias, and its capability to help elucidate determinants of health. Gaps in the literature included a lack of discussion of ethical challenges with the application of AI technologies in low- and middle-income countries, lack of discussion of problems of bias in AI algorithms, and a lack of justification for the use of AI technologies over traditional statistical methods to address specific research questions in oncology. Our review highlights a need to address these gaps to ensure a more equitable integration of AI in cancer research and clinical practice. The limitations of our study include its exploratory nature, its focus on oncology as opposed to all health care sectors, and its analysis of solely English-language articles.","Istasy, Paul; Lee, Wen Shen; Iansavichene, Alla; Upshur, Ross; Gyawali, Bishal; Burkell, Jacquelyn; Sadikovic, Bekim; Lazo-Langner, Alejandro; Chin-Yee, Benjamin",,"Gyawali, Bishal/0000-0001-7444-8594; Iansavitchene, Alla/0000-0002-5651-1024; Istasy, Paul/0000-0003-2568-7542; Upshur, Ross/0000-0003-1128-0557; Burkell, Jacquelyn/0000-0003-2645-8127; Lee, Wen Shen/0000-0002-6811-2493",The Impact of Artificial Intelligence on Health Equity in Oncology: Scoping Review,24,11,10.2196/39748 ,Review ,2022.0,"Background: The field of oncology is at the forefront of advances in artificial intelligence (AI) in health care, providing an opportunity to examine the early integration of these technologies in clinical research and patient care. Hope that AI will revolutionize health care delivery and improve clinical outcomes has been accompanied by concerns about the impact of these technologies on health equity.Objective: We aimed to conduct a scoping review of the literature to address the question, What are the current and potential impacts of AI technologies on health equity in oncology?Methods: Following PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines for scoping reviews, we systematically searched MEDLINE and Embase electronic databases from January 2000 to August 2021 for records engaging with key concepts of AI, health equity, and oncology. We included all English-language articles that engaged with the 3 key concepts. Articles were analyzed qualitatively for themes pertaining to the influence of AI on health equity in oncology.Results: Of the 14,011 records, 133 (0.95%) identified from our review were included. We identified 3 general themes in the literature: the use of AI to reduce health care disparities (58/133, 43.6%), concerns surrounding AI technologies and bias (16/133, 12.1%), and the use of AI to examine biological and social determinants of health (55/133, 41.4%). A total of 3% (4/133) of articles focused on many of these themes.Conclusions: Our scoping review revealed 3 main themes on the impact of AI on health equity in oncology, which relate to AI's ability to help address health disparities, its potential to mitigate or exacerbate bias, and its capability to help elucidate determinants of health. Gaps in the literature included a lack of discussion of ethical challenges with the application of AI technologies in low- and middle-income countries, lack of discussion of problems of bias in AI algorithms, and a lack of justification for the use of AI technologies over traditional statistical methods to address specific research questions in oncology. Our review highlights a need to address these gaps to ensure a more equitable integration of AI in cancer research and clinical practice. The limitations of our study include its exploratory nature, its focus on oncology as opposed to all health care sectors, and its analysis of solely English-language articles.",1438-8871,,,, , ,,out_of_scope,
4319,"Title:Quantifying Gender Bias in Different Corpora

 Word embedding models have been shown to be effective in performing a wide variety of Natural Language Processing (NLP) tasks such as identifying audiences for web advertisements, parsing resumes to select promising job candidates, and translating documents from one language to another. However, it has been demonstrated that NLP systems learn gender bias from the corpora of documents on which they are trained. It is increasingly common for pre-trained models to be used as a starting point for building applications in a wide range of areas including critical decision making applications. It is also very easy to use a pre-trained model as the basis for a new application without careful consideration of the original nature of the training set. In this paper, we quantify the degree to which gender bias differs with the corpora used for training. We look especially at the impact of starting with a pre-trained model and fine-tuning with additional data. Specifically, we calculate a measure of direct gender bias on several pre-trained models including BERT's Wikipedia and Book corpus models as well as on several fine-tuned General Language Understanding Evaluation (GLUE) benchmarks. In addition, we evaluate the bias from several more extreme corpora including the Jigsaw identity toxic dataset that includes toxic speech biased against race, gender, religion, and disability and the RtGender dataset that includes speech specifically labelled by gender. Our results reveal that the direct gender bias of the Jigsaw toxic identity dataset is surprisingly close to that of the base pre-trained Google model, but the RtGender dataset has significantly higher direct gender bias than the base model. When the bias learned by an NLP system can vary significantly with the corpora used for training, it becomes important to consider and report these details, especially for use in critical decision-making applications.","Babaeianjelodar, Marzieh; Lorenz, Stephen; Gordon, Josh; Matthews, Jeanna; Freitag, Evan","Matthews, Jeanna/AAN-3766-2021; Matthews, Jeanna/AAQ-8226-2021","Matthews, Jeanna/0000-0001-5955-0996",Quantifying Gender Bias in Different Corpora,,,10.1145/3366424.3383559 ,Proceedings Paper ,2020.0,"Word embedding models have been shown to be effective in performing a wide variety of Natural Language Processing (NLP) tasks such as identifying audiences for web advertisements, parsing resumes to select promising job candidates, and translating documents from one language to another. However, it has been demonstrated that NLP systems learn gender bias from the corpora of documents on which they are trained. It is increasingly common for pre-trained models to be used as a starting point for building applications in a wide range of areas including critical decision making applications. It is also very easy to use a pre-trained model as the basis for a new application without careful consideration of the original nature of the training set. In this paper, we quantify the degree to which gender bias differs with the corpora used for training. We look especially at the impact of starting with a pre-trained model and fine-tuning with additional data. Specifically, we calculate a measure of direct gender bias on several pre-trained models including BERT's Wikipedia and Book corpus models as well as on several fine-tuned General Language Understanding Evaluation (GLUE) benchmarks. In addition, we evaluate the bias from several more extreme corpora including the Jigsaw identity toxic dataset that includes toxic speech biased against race, gender, religion, and disability and the RtGender dataset that includes speech specifically labelled by gender. Our results reveal that the direct gender bias of the Jigsaw toxic identity dataset is surprisingly close to that of the base pre-trained Google model, but the RtGender dataset has significantly higher direct gender bias than the base model. When the bias learned by an NLP system can vary significantly with the corpora used for training, it becomes important to consider and report these details, especially for use in critical decision-making applications.",,,978-1-4503-7024-0,752-759, , 29th World Wide Web Conference (WWW)29th World Wide Web Conference (WWW),,Use_dataset#evaluation,
4320,"371    Title:Cross-Domain Toxic Spans Detection\n\n A...
Name: Abstract, dtype: object","Schouten SF,Barbarestani B,Tufa W,Vossen P,Markov I",,,Cross-Domain Toxic Spans Detection,13913,,10.1007/978-3-031-35320-8_40 , Conference Paper,2023.0,"Abstract:Given the dynamic nature of toxic language use, automated methods for detecting toxic spans are likely to encounter distributional shift. To explore this phenomenon, we evaluate three approaches for detecting toxic spans under cross-domain conditions: lexicon-based, rationale extraction, and fine-tuned language models. Our findings indicate that a simple method using off-the-shelf lexicons performs best in the cross-domain setup. The cross-domain error analysis suggests that (1) rationale extraction methods are prone to false negatives, while (2) language models, despite performing best for the in-domain case, recall fewer explicitly toxic words than lexicons and are prone to certain types of false positives. Our code is publicly available at: this https URL.",,,,,Springer ,"Natural Language Processing and Information Systems - 28th International Conference on Applications of Natural Language to Information Systems, NLDB 2023, Derby, UK, June 21-23, 2023, Proceedings ",,detection#methodology,
4321,"372    Title:SINAI at SemEval-2021 Task 5: Combining ...
Name: Abstract, dtype: object","del Arco FM,López-Úbeda P,López LA,Valdivia MT",,,SINAI at SemEval-2021 Task 5: Combining Embeddings in a BiLSTM-CRF model for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.134 , Conference Paper,2021.0,Abstract:We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23% by F1-score on the Toxic Spans Detection task.,,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4322,"373    Title:IITK@Detox at SemEval-2021 Task 5: Semi-...
Name: Abstract, dtype: object","Bansal A,Kaushik A,Modi A",,,IITK@Detox at SemEval-2021 Task 5: Semi-Supervised Learning and Dice Loss for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.24 , Conference Paper,2021.0,"AbstractIn this work, we present our approach and findings for SemEval-2021 Task 5 - Toxic Spans Detection. The task’s main aim was to identify spans to which a given text’s toxicity could be attributed. The task is challenging mainly due to two constraints: the small training dataset and imbalanced class distribution. Our paper investigates two techniques, semi-supervised learning and learning with Self-Adjusting Dice Loss, for tackling these challenges. Our submitted system (ranked ninth on the leader board) consisted of an ensemble of various pre-trained Transformer Language Models trained using either of the above-proposed techniques.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4323,"374    Title:LISAC FSDM USMBA at SemEval-2021 Task 5:...
Name: Abstract, dtype: object","Benlahbib A,Alami A,Alami H",,,LISAC FSDM USMBA at SemEval-2021 Task 5: Tackling Toxic Spans Detection Challenge with Supervised SpanBERT-based Model and Unsupervised LIME-based Model,,,10.18653/V1/2021.SEMEVAL-1.116 , Conference Paper,2021.0,"AbstractToxic spans detection is an emerging challenge that aims to find toxic spans within a toxic text. In this paper, we describe our solutions to tackle toxic spans detection. The first solution, which follows a supervised approach, is based on SpanBERT model. This latter is intended to better embed and predict spans of text. The second solution, which adopts an unsupervised approach, combines linear support vector machine with the Local Interpretable Model-Agnostic Explanations (LIME). This last is used to interpret predictions of learning-based models. Our supervised model outperformed the unsupervised model and achieved the f-score of 67,84% (ranked 22/85) in Task 5 at SemEval-2021: Toxic Spans Detection.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4324,"375    Title:UAntwerp at SemEval-2021 Task 5: Spans a...
Name: Abstract, dtype: object","Burtenshaw B,Kestemont M",,,"UAntwerp at SemEval-2021 Task 5: Spans are Spans, stacking a binary word level approach to toxic span detection",,,10.18653/V1/2021.SEMEVAL-1.121 , Conference Paper,2021.0,"Abstract:Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4325,"376    Title:macech at SemEval-2021 Task 5: Toxic Spa...
Name: Abstract, dtype: object",Cech M,,,macech at SemEval-2021 Task 5: Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.137 , Conference Paper,2021.0,"Abstract:The increment of toxic comments on online space is causing tremendous effects on other vulnerable users. For this reason, considerable efforts are made to deal with this, and SemEval-2021 Task 5: Toxic Spans Detection is one of those. This task asks competitors to extract spans that have toxicity from the given texts, and we have done several analyses to understand its structure before doing experiments. We solve this task by two approaches, Named Entity Recognition with spaCy library and Question-Answering with RoBERTa combining with ToxicBERT, and the former gains the highest F1-score of 66.99%.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4326,"377    Title:YNU-HPCC at SemEval-2021 Task 5: Using a...
Name: Abstract, dtype: object","Chen R,Wang J,Zhang X",,,YNU-HPCC at SemEval-2021 Task 5: Using a Transformer-based Model with Auxiliary Information for Toxic Span Detection,,,10.18653/V1/2021.SEMEVAL-1.112 , Conference Paper,2021.0,"AbstractToxic span detection requires the detection of spans that make a text toxic instead of simply classifying the text. In this paper, a transformer-based model with auxiliary information is proposed for SemEval-2021 Task 5. The proposed model was implemented based on the BERT-CRF architecture. It consists of three parts: a transformer-based model that can obtain the token representation, an auxiliary information module that combines features from different layers, and an output layer used for the classification. Various BERT-based models, such as BERT, ALBERT, RoBERTa, and XLNET, were used to learn contextual representations. The predictions of these models were assembled to improve the sequence labeling tasks by using a voting strategy. Experimental results showed that the introduced auxiliary information can improve the performance of toxic spans detection. The proposed model ranked 5th of 91 in the competition. The code of this study is available at https://github.com/Chenrj233/semeval2021_task5",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4327,"378    Title:NLRG at SemEval-2021 Task 5: Toxic Spans...
Name: Abstract, dtype: object","Chhablani G,Sharma A,Pandey H,Bhartia Y,Suthaharan S",,,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,,,10.18653/V1/2021.SEMEVAL-1.27 , Conference Paper,2021.0,"Abstract:Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4328,"379    Title:SkoltechNLP at SemEval-2021 Task 5: Leve...
Name: Abstract, dtype: object","Dale D,Markov I,Logacheva V,Kozlova O,Semenov N,Panchenko A",,,SkoltechNLP at SemEval-2021 Task 5: Leveraging Sentence-level Pre-training for Toxic Span Detection,,,10.18653/V1/2021.SEMEVAL-1.126 , Conference Paper,2021.0,"Abstract:Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4329,"380    Title:Sefamerve ARGE at SemEval-2021 Task 5: T...
Name: Abstract, dtype: object","Delil S,Kuyumcu B,Aksakalli C",,,Sefamerve ARGE at SemEval-2021 Task 5: Toxic Spans Detection Using Segmentation Based 1-D Convolutional Neural Network Model,,,10.18653/V1/2021.SEMEVAL-1.123 , Conference Paper,2021.0,"AbstractThis paper describes our contribution to SemEval-2021 Task 5: Toxic Spans Detection. Our approach considers toxic spans detection as a segmentation problem. The system, Waw-unet, consists of a 1-D convolutional neural network adopted from U-Net architecture commonly applied for semantic segmentation. We customize existing architecture by adding a special network block considering for text segmentation, as an essential component of the model. We compared the model with two transformers-based systems RoBERTa and XLM-RoBERTa to see its performance against pre-trained language models. We obtained 0.6251 f1 score with Waw-unet while 0.6390 and 0.6601 with the compared models respectively.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4330,"381    Title:HamiltonDinggg at SemEval-2021 Task 5: I...
Name: Abstract, dtype: object","Ding H,Jurgens D",,,HamiltonDinggg at SemEval-2021 Task 5: Investigating Toxic Span Detection using RoBERTa Pre-training,,,10.18653/V1/2021.SEMEVAL-1.31 , Conference Paper,2021.0,"Abstract:Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4331,"382    Title:UIT-E10dot3 at SemEval-2021 Task 5: Toxi...
Name: Abstract, dtype: object","Hoang PG,Nguyen LT,Van Nguyen K",,,UIT-E10dot3 at SemEval-2021 Task 5: Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches,,,10.18653/V1/2021.SEMEVAL-1.125 , Conference Paper,2021.0,"Abstract:The increment of toxic comments on online space is causing tremendous effects on other vulnerable users. For this reason, considerable efforts are made to deal with this, and SemEval-2021 Task 5: Toxic Spans Detection is one of those. This task asks competitors to extract spans that have toxicity from the given texts, and we have done several analyses to understand its structure before doing experiments. We solve this task by two approaches, Named Entity Recognition with spaCy library and Question-Answering with RoBERTa combining with ToxicBERT, and the former gains the highest F1-score of 66.99%.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4332,"383    Title:CSECU-DSG at SemEval-2021 Task 5: Levera...
Name: Abstract, dtype: object","Hossain T,Naim J,Tasneem F,Tasnia R,Chy AN",,,CSECU-DSG at SemEval-2021 Task 5: Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.135 , Conference Paper,2021.0,"AbstractThe upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Detecting the toxic portions substantially aids to moderate or exclude the abusive parts for maintaining sound online platforms. This paper describes our participation in the SemEval 2021 toxic span detection task. The task requires detecting spans that convey toxic remarks from the given text. We explore an ensemble of sequence labeling models including the BiLSTM-CRF, spaCy NER model with custom toxic tags, and fine-tuned BERT model to identify the toxic spans. Finally, a majority voting ensemble method is used to determine the unified toxic spans. Experimental results depict the competitive performance of our model among the participants.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4333,"384    Title:hub at SemEval-2021 Task 5: Toxic Span D...
Name: Abstract, dtype: object","Huang B,Bai Y,Zhou X",,,hub at SemEval-2021 Task 5: Toxic Span Detection Based on Word-Level Classification,,,10.18653/V1/2021.SEMEVAL-1.122 , Conference Paper,2021.0,"Abstract:Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4334,"385    Title:Entity at SemEval-2021 Task 5: Weakly Su...
Name: Abstract, dtype: object","Jain V,Naghshnejad M",,,Entity at SemEval-2021 Task 5: Weakly Supervised Token Labelling for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.127 , Conference Paper,2021.0,"AbstractDetection of toxic spans - detecting toxicity of contents in the granularity of tokens - is crucial for effective moderation of online discussions. The baseline approach for this problem using the transformer model is to add a token classification head to the language model and fine-tune the layers with the token labeled dataset. One of the limitations of such a baseline approach is the scarcity of labeled data. To improve the results, We studied leveraging existing public datasets for a related but different task of entire comment/sentence classification. We propose two approaches: the first approach fine-tunes transformer models that are pre-trained on sentence classification samples. In the second approach, we perform weak supervision with soft attention to learn token level labels from sentence labels. Our experiments show improvements in the F1 score over the baseline approach. The implementation has been released publicly.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4335,"386    Title:UniParma at SemEval-2021 Task 5: Toxic S...
Name: Abstract, dtype: object","Karimi A,Rossi L,Prati A",,,UniParma at SemEval-2021 Task 5: Toxic Spans Detection Using CharacterBERT and Bag-of-Words Model,,,10.18653/V1/2021.SEMEVAL-1.25 , Conference Paper,2021.0,"AbstractWith the ever-increasing availability of digital information, toxic content is also on the rise. Therefore, the detection of this type of language is of paramount importance. We tackle this problem utilizing a combination of a state-of-the-art pre-trained language model (CharacterBERT) and a traditional bag-of-words technique. Since the content is full of toxic words that have not been written according to their dictionary spelling, attendance to individual characters is crucial. Therefore, we use CharacterBERT to extract features based on the word characters. It consists of a CharacterCNN module that learns character embeddings from the context. These are, then, fed into the well-known BERT architecture. The bag-of-words method, on the other hand, further improves upon that by making sure that some frequently used toxic words get labeled accordingly. With a ∼4 percent difference from the first team, our system ranked 36 th in the competition. The code is available for further research and reproduction of the results.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4336,"387    Title:BennettNLP at SemEval-2021 Task 5: Toxic...
Name: Abstract, dtype: object","Kataria H,Gupta A,Mishra V",,,BennettNLP at SemEval-2021 Task 5: Toxic Spans Detection using Stacked Embedding Powered Toxic Entity Recognizer,,,10.18653/V1/2021.SEMEVAL-1.128 , Conference Paper,2021.0,"Abstract:With the ever-increasing availability of digital information, toxic content is also on the rise. Therefore, the detection of this type of language is of paramount importance. We tackle this problem utilizing a combination of a state-of-the-art pre-trained language model (CharacterBERT) and a traditional bag-of-words technique. Since the content is full of toxic words that have not been written according to their dictionary spelling, attendance to individual characters is crucial. Therefore, we use CharacterBERT to extract features based on the word characters. It consists of a CharacterCNN module that learns character embeddings from the context. These are, then, fed into the well-known BERT architecture. The bag-of-words method, on the other hand, further improves upon that by making sure that some frequently used toxic words get labeled accordingly. With a 4 percent difference from the first team, our system ranked 36th in the competition. The code is available for further re-search and reproduction of the results.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4337,"388    Title:MIPT-NSU-UTMN at SemEval-2021 Task 5: En...
Name: Abstract, dtype: object","Kotyushev M,Glazkova A,Morozov D",,,MIPT-NSU-UTMN at SemEval-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.124 , Conference Paper,2021.0,"AbstractThis paper describes our system for SemEval-2021 Task 5 on Toxic Spans Detection. We developed ensemble models using BERT-based neural architectures and post-processing to combine tokens into spans. We evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned BERT models. Finally, our system obtained a F1-score of 67.55% on test data.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4338,"389    Title:UIT-ISE-NLP at SemEval-2021 Task 5: Toxi...
Name: Abstract, dtype: object","Luu ST,Nguyen NL",,,UIT-ISE-NLP at SemEval-2021 Task 5: Toxic Spans Detection with BiLSTM-CRF and ToxicBERT Comment Classification,,,10.18653/V1/2021.SEMEVAL-1.113 , Conference Paper,2021.0,Abstract:We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23% by F1-score on the Toxic Spans Detection task.,,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4339,"390    Title:HLE-UPC at SemEval-2021 Task 5: Multi-De...
Name: Abstract, dtype: object","Palliser-Sans R,Rial-Farràs A",,,HLE-UPC at SemEval-2021 Task 5: Multi-Depth DistilBERT for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.131 , Conference Paper,2021.0,"Abstract:This paper presents our submission to SemEval-2021 Task 5: Toxic Spans Detection. The purpose of this task is to detect the spans that make a text toxic, which is a complex labour for several reasons. Firstly, because of the intrinsic subjectivity of toxicity, and secondly, due to toxicity not always coming from single words like insults or offends, but sometimes from whole expressions formed by words that may not be toxic individually. Following this idea of focusing on both single words and multi-word expressions, we study the impact of using a multi-depth DistilBERT model, which uses embeddings from different layers to estimate the final per-token toxicity. Our quantitative results show that using information from multiple depths boosts the performance of the model. Finally, we also analyze our best model qualitatively.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4340,"391    Title:UPB at SemEval-2021 Task 5: Virtual Adve...
Name: Abstract, dtype: object","Paraschiv A,Cercel DC,Dascalu M",,,UPB at SemEval-2021 Task 5: Virtual Adversarial Training for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.26 , Conference Paper,2021.0,"Abstract:The real-world impact of polarization and toxicity in the online sphere marked the end of 2020 and the beginning of this year in a negative way. Semeval-2021, Task 5 - Toxic Spans Detection is based on a novel annotation of a subset of the Jigsaw Unintended Bias dataset and is the first language toxicity detection task dedicated to identifying the toxicity-level spans. For this task, participants had to automatically detect character spans in short comments that render the message as toxic. Our model considers applying Virtual Adversarial Training in a semi-supervised setting during the fine-tuning process of several Transformer-based models (i.e., BERT and RoBERTa), in combination with Conditional Random Fields. Our approach leads to performance improvements and more robust models, enabling us to achieve an F1-score of 65.73% in the official submission and an F1-score of 66.13% after further tuning during post-evaluation.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4341,"392    Title:SemEval-2021 Task 5: Toxic Spans Detecti...
Name: Abstract, dtype: object","Pavlopoulos J,Sorensen J,Laugier L,Androutsopoulos I",,,SemEval-2021 Task 5: Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.6 , Conference Paper,2021.0,"Abstract:Social network platforms are generally used to share positive, constructive, and insightful content. However, in recent times, people often get exposed to objectionable content like threat, identity attacks, hate speech, insults, obscene texts, offensive remarks or bullying. Existing work on toxic speech detection focuses on binary classification or on differentiating toxic speech among a small set of categories. This paper describes the system proposed by team Cisco for SemEval-2021 Task 5: Toxic Spans Detection, the first shared task focusing on detecting the spans in the text that attribute to its toxicity, in English language. We approach this problem primarily in two ways: a sequence tagging approach and a dependency parsing approach. In our sequence tagging approach we tag each token in a sentence under a particular tagging scheme. Our best performing architecture in this approach also proved to be our best performing architecture overall with an F1 score of 0.6922, thereby placing us 7th on the final evaluation phase leaderboard. We also explore a dependency parsing approach where we extract spans from the input sentence under the supervision of target span boundaries and rank our spans using a biaffine model. Finally, we also provide a detailed analysis of our results and model performance in our paper.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4342,"393    Title:UTNLP at SemEval-2021 Task 5: A Comparat...
Name: Abstract, dtype: object","Salemi A,Sabri N,Kebriaei E,Bahrak B,Shakery A",,,"UTNLP at SemEval-2021 Task 5: A Comparative Analysis of Toxic Span Detection using Attention-based, Named Entity Recognition, and Ensemble Models",,,10.18653/V1/2021.SEMEVAL-1.136 , Conference Paper,2021.0,"AbstractDetecting which parts of a sentence contribute to that sentence’s toxicity—rather than providing a sentence-level verdict of hatefulness— would increase the interpretability of models and allow human moderators to better understand the outputs of the system. This paper presents our team’s, UTNLP, methodology and results in the SemEval-2021 shared task 5 on toxic spans detection. We test multiple models and contextual embeddings and report the best setting out of all. The experiments start with keyword-based models and are followed by attention-based, named entity- based, transformers-based, and ensemble models. Our best approach, an ensemble model, achieves an F1 of 0.684 in the competition’s evaluation phase.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4343,"394    Title:SRPOL DIALOGUE SYSTEMS at SemEval-2021 T...
Name: Abstract, dtype: object","Satlawa M,Zamlynska K,Piersa J,Kolis J,Firlag K,Beksa K,Bordzicka Z,Goltz C,Bujnowski P,Andruszkiewicz P",,,SRPOL DIALOGUE SYSTEMS at SemEval-2021 Task 5: Automatic Generation of Training Data for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.133 , Conference Paper,2021.0,"AbstractThis paper presents a system used for SemEval-2021 Task 5: Toxic Spans Detection. Our system is an ensemble of BERT-based models for binary word classification, trained on a dataset extended by toxic comments modified and generated by two language models. For the toxic word classification, the prediction threshold value was optimized separately for every comment, in order to maximize the expected F1 value.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4344,"395    Title:YoungSheldon at SemEval-2021 Task 5: Fin...
Name: Abstract, dtype: object","Sharma M,Kandasamy I,Vasantha WB",,,YoungSheldon at SemEval-2021 Task 5: Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective,,,10.18653/V1/2021.SEMEVAL-1.130 , Conference Paper,2021.0,"AbstractIn this paper, we describe our system used for SemEval 2021 Task 5: Toxic Spans Detection. Our proposed system approaches the problem as a token classification task. We trained our model to find toxic words and concatenate their spans to predict the toxic spans within a sentence. We fine-tuned Pre-trained Language Models (PLMs) for identifying the toxic words. For fine-tuning, we stacked the classification layer on top of the PLM features of each word to classify if it is toxic or not. PLMs are pre-trained using different objectives and their performance may differ on downstream tasks. We, therefore, compare the performance of BERT, ELECTRA, RoBERTa, XLM-RoBERTa, T5, XLNet, and MPNet for identifying toxic spans within a sentence. Our best performing system used RoBERTa. It performed well, achieving an F1 score of 0.6841 and secured a rank of 16 on the official leaderboard.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4345,"396    Title:AStarTwice at SemEval-2021 Task 5: Toxic...
Name: Abstract, dtype: object","Suman TA,Jain A",,,"AStarTwice at SemEval-2021 Task 5: Toxic Span Detection Using RoBERTa-CRF, Domain Specific Pre-Training and Self-Training",,,10.18653/V1/2021.SEMEVAL-1.118 , Conference Paper,2021.0,"Abstract:Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4346,"397    Title:MedAI at SemEval-2021 Task 5: Start-to-e...
Name: Abstract, dtype: object","Wang Z,Fan H,Liu J",,,MedAI at SemEval-2021 Task 5: Start-to-end Tagging Framework for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.30 , Conference Paper,2021.0,Abstract:We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23% by F1-score on the Toxic Spans Detection task.,,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4347,"398    Title:HITMI&T at SemEval-2021 Task 5: Integrat...
Name: Abstract, dtype: object","Wang C,Liu T,Zhao T",,,HITMI&T at SemEval-2021 Task 5: Integrating Transformer and CRF for Toxic Spans Detection,,,10.18653/V1/2021.SEMEVAL-1.117 , Conference Paper,2021.0,"Abstract:In recent years, the widespread use of social media has led to an increase in the generation of toxic and offensive content on online platforms. In response, social media platforms have worked on developing automatic detection methods and employing human moderators to cope with this deluge of offensive content. While various state-of-the-art statistical models have been applied to detect toxic posts, there are only a few studies that focus on detecting the words or expressions that make a post offensive. This motivates the organization of the SemEval-2021 Task 5: Toxic Spans Detection competition, which has provided participants with a dataset containing toxic spans annotation in English posts. In this paper, we present the WLV-RIT entry for the SemEval-2021 Task 5. Our best performing neural transformer model achieves an $0.68$ F1-Score. Furthermore, we develop an open-source framework for multilingual detection of offensive spans, i.e., MUDES, based on neural transformers that detect toxic spans in texts.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4348,"399    Title:HITSZ-HLT at SemEval-2021 Task 5: Ensemb...
Name: Abstract, dtype: object","Zhu Q,Lin Z,Zhang Y,Sun J,Li X,Lin Q,Dang Y,Xu R",,,HITSZ-HLT at SemEval-2021 Task 5: Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection,,,10.18653/V1/2021.SEMEVAL-1.63 , Conference Paper,2021.0,"AbstractThis paper presents the winning system that participated in SemEval-2021 Task 5: Toxic Spans Detection. This task aims to locate those spans that attribute to the text’s toxicity within a text, which is crucial for semi-automated moderation in online discussions. We formalize this task as the Sequence Labeling (SL) problem and the Span Boundary Detection (SBD) problem separately and employ three state-of-the-art models. Next, we integrate predictions of these models to produce a more credible and complement result. Our system achieves a char-level score of 70.83%, ranking 1/91. In addition, we also explore the lexicon-based method, which is strongly interpretable and flexible in practice.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4349,"400    Title:LZ1904 at SemEval-2021 Task 5: Bi-LSTM-C...
Name: Abstract, dtype: object","Zou L,Li W",,,LZ1904 at SemEval-2021 Task 5: Bi-LSTM-CRF for Toxic Span Detection using Pretrained Word Embedding,,,10.18653/V1/2021.SEMEVAL-1.138 , Conference Paper,2021.0,Abstract:We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23% by F1-score on the Toxic Spans Detection task.,,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,detection#methodology,
4350,"401    NaN
Name: Abstract, dtype: object",López AM,,,Alejandro Mosquera at DETOXIS 2021: Deep Learning Approaches to Toxicity Detection in Spanish Social Media Texts,2943,, , Conference Paper,2021.0,". This paper presents the system submitted to the DETOXIS
2021 challenge for detecting toxicity in Spanish social media texts. The
chosen approach relies on an ensemble of diﬀerent neural network ar-
chitectures including thread and topic features as side information. For
sub-task 1, we have also applied machine translation in order to reuse
linguistic resources from other languages such as English. Our best sub-
mission scored 0.569 F1 in the test set, ranking 6th out of 31 competing
teams.
Keywords: Toxicity detection · Spanish · Social Media · Machine trans-
lation · Text Normalization · Deep learning · Capsule networks.
Introduction
ews websites allow million of users to share and discuss their opinions publicly
near real-time every day. Such large reach and constantly increasing user base
esent challenges for content moderation teams, which not only need to ﬁght
ﬃliate and cyber-crime operators but also less traditional forms of messaging
buse such as the spread of hate, propaganda and fake news.
While social media platforms are under increasingly pressure to swiftly deal
ith the spread of toxic content, the use of over-aggressive ﬁltering models and
e under-representation of certain user groups in the training data can also have
egative consequences if false positives happen at large scale [23].
Because of the aforementioned reasons, the automatic detection of toxic lan-
uage in social media has received growing attention from the NLP research
mmunity in the last few years, which is also reﬂected in the number of public
valuations and resources recently focused on this area: e.g. HASOC [14] for hate
eech and aggressive content, TRAC [8] for identifying aggression, HatEval [1]
IberLEF 2021, September 2021, M´alaga, Spain.
Copyright © 2021 for this paper by its authors. Use permitted under Creative
Commons License Attribution 4.0 International (CC BY 4.0).",,,,,CEUR-WS.org ,"Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2021) co-located with the Conference of the Spanish Society for Natural Language Processing (SEPLN 2021), XXXVII International Conference of the Spanish Society for Natural Language Processing., Málaga, Spain, September, 2021 ",,out_but_toxicity,
4351,"402    Title:UniParma @ SemEval 2021 Task 5: Toxic Sp...
Name: Abstract, dtype: object","Karimi A,Rossi L,Prati A",,,UniParma @ SemEval 2021 Task 5: Toxic Spans Detection Using CharacterBERT and Bag-of-Words Model,abs/2103.09645,, , Journal Article,2021.0,"AbstractWith the ever-increasing availability of digital information, toxic content is also on the rise. Therefore, the detection of this type of language is of paramount importance. We tackle this problem utilizing a combination of a state-of-the-art pre-trained language model (CharacterBERT) and a traditional bag-of-words technique. Since the content is full of toxic words that have not been written according to their dictionary spelling, attendance to individual characters is crucial. Therefore, we use CharacterBERT to extract features based on the word characters. It consists of a CharacterCNN module that learns character embeddings from the context. These are, then, fed into the well-known BERT architecture. The bag-of-words method, on the other hand, further improves upon that by making sure that some frequently used toxic words get labeled accordingly. With a ∼4 percent difference from the first team, our system ranked 36 th in the competition. The code is available for further research and reproduction of the results.",,,,, CoRR, ,,detection#methodology,
4352,"403    Title:UIT-ISE-NLP at SemEval-2021 Task 5: Toxi...
Name: Abstract, dtype: object","Luu ST,Nguyen NL",,,UIT-ISE-NLP at SemEval-2021 Task 5: Toxic Spans Detection with BiLSTM-CRF and Toxic Bert Comment Classification,abs/2104.10100,, , Journal Article,2021.0,Abstract:We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This task aims to build a model for identifying toxic words in whole posts. We use the BiLSTM-CRF model combining with ToxicBERT Classification to train the detection model for identifying toxic words in posts. Our model achieves 62.23% by F1-score on the Toxic Spans Detection task.,,,,, CoRR, ,,detection#methodology,
4353,"Series([], Name: Abstract, dtype: object)","Wen J,Ke P,Sun H,Zhang Z,Li C,Bai J,Huang M",,,Unveiling the Implicit Toxicity in Large Language Models,,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023 ",,detection#evaluation#methodology,
4354,"404    Title:You Only Prompt Once: On the Capabilitie...
Name: Abstract, dtype: object","He X,Zannettou S,Shen Y,Zhang Y",,,You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content,abs/2308.05596,,10.48550/ARXIV.2308.05596 , Journal Article,2023.0,"Abstract:The spread of toxic content online is an important problem that has adverse effects on user experience online and in our society at large. Motivated by the importance and impact of the problem, research focuses on developing solutions to detect toxic content, usually leveraging machine learning (ML) models trained on human-annotated datasets. While these efforts are important, these models usually do not generalize well and they can not cope with new trends (e.g., the emergence of new toxic terms). Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability. In this work, we investigate how we can use LLMs and prompt learning to tackle the problem of toxic content, particularly focusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection, and 3) Detoxification. We perform an extensive evaluation over five model architectures and eight datasets demonstrating that LLMs with prompt learning can achieve similar or even better performance compared to models trained on these specific tasks. We find that prompt learning achieves around 10\% improvement in the toxicity classification task compared to the baselines, while for the toxic span detection task we find better performance to the best baseline (0.643 vs. 0.640 in terms of $F_1$-score). Finally, for the detoxification task, we find that prompt learning can successfully reduce the average toxicity score (from 0.775 to 0.213) while preserving semantic meaning.",,,,, CoRR, ,,detection#methodology,
4355,"Series([], Name: Abstract, dtype: object)","Byun S,Jang D,Jo H,Shin H",,,Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models,abs/2311.18215,,10.48550/ARXIV.2311.18215 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,out_but_toxicity,
4356,"405    Title:Concept drift detection in toxicology da...
Name: Abstract, dtype: object","Bharti V,Nair SS,Jain A,Shukla KK,Biswas B",,,Concept drift detection in toxicology datasets using discriminative subgraph-based drift detector,24,1,10.1093/BIB/BBAC506 , Journal Article,2023.0,"Due to the increasing importance of graphs and graph streams in data representation in today’s era, concept drift detection in graph streaming scenarios is more important than ever. Contributions to concept drift detection in graph streams are minimal and practically non-existent in the field of toxicology. This paper applied the discriminative subgraph-based drift detector (DSDD) to graph streams generated from real-world toxicology datasets. We used four toxicology datasets, each of which yielded two graph streams – one with abrupt drift points and one with gradual drift points. We used DSDD both with the standard minimum description length (MDL) heuristic and after replacing MDL with a much simpler heuristic SIZE (number of vertices + number of edges), and applied it to all generated graph streams containing abrupt drift points and gradual drift points for varying window sizes. Following that, we compared and analyzed the results. Finally, we applied a long short-term memory based graph stream classification model to all the generated streams and compared the difference in the performances obtained with and without detecting drift using DSDD. We believe that the results and analysis presented in this paper will provide insight into the task of concept drift detection in the toxicology domain and aid in the application of DSDD in a variety of scenarios.",,,,, Briefings Bioinform., ,,out_of_scope,
4357,"406    Title:An Overview of Toxic Content Datasets fo...
Name: Abstract, dtype: object","Havzi S,Taibi D",,,An Overview of Toxic Content Datasets for Artificial Intelligence Applications to Educate Students Towards a Better Use of Social Media,,,10.5220/0011987100003470 , Conference Paper,2023.0,"The Internet has become an integral part of life, providing numerous benefits to its users. However, due to 
freedom of speech and lack of control, the Internet is becoming a breeding ground for spreading harmful/toxic 
content. Since young people are the most active Internet users, protecting them from harmful online content 
is extremely important. One of the directions within which this could be conducted is educating young people 
about the consequences of using online toxic language and building powerful artificial intelligence-based 
tools such as Virtual Learning Companions that could educate youth in recognising online toxic content and 
upgrading their social media and self-protection competencies. To be able to build such tools, quality online 
datasets are needed. This paper is a brief overview of 9 selected English language online toxic content datasets 
published between 2020 and 2022 among 70 we found in the literature that could help educate young people 
on this topic. 
content exposure on adolescents is the impact on their 
well-being with direct consequences on their 
engagement, participation, and performances in 
school contexts, as well as a more severe possibility 
of developing mental health problems. 
(Nixon, 2014) demonstrated that cyberbullying 
has a significant impact on adolescents’ health. The 
author highlights cyberbullying as an emerging 
international public health concern. 
Studying and preventing online toxicity is 
especially important as exposure to its various forms 
can negatively affect mental health (Baier et al., 2019, 
Nixon, 2014), increase the risk of some serious 
mental health concerns, anxiety, stress, depression, 
and suicidal thinking (Martínez-Monteagudo et al., 
2020)  In most extreme cases, online abuse can lead 
to suicide attempts (Hinduja & Patchin, 2019)  
Moreover, exposure to these issues can affect the 
students’ well-being in the school context thus 
critically influencing the learning performance of 
students (Al-Rahmi et al., 2022) 
In light of these concerns, it is crucial to develop 
tools and resources that can support students in 
Online toxic content is becoming more frequent and 
widespread on social networks and in the online 
world. The hatred directed towards members of 
certain ethnic groups, races or religions can be 
conveyed 
through 
any 
form 
of 
expression. 
Represented 
on 
different 
platforms 
through 
comments, pictures, memes, cartoons and movies, 
gestures and videos can be spread offline or online. 
Recent studies have shown that adolescents are 
particularly susceptible to the influence of toxic 
content, fake news, and online hate speech (Boer et 
al., 2020, Kansok-Dusche et al. 2022). This is 
motivated by the fact that adolescents constitute the 
highest percentage of social network users, especially 
TikTok (Zheluk et al., 2022). For example, a report 
by the Pew Research Center (Anderson et al., 2022) 
found that adolescents who use social media are more 
likely to be exposed to false information and are less 
likely to be able to distinguish between fact and 
fiction. One of the most common effects of toxic 
 
a
 https://orcid.org/0000-0001-7077-8780 
b
 https://orcid.org/0000-0002-0785-6771 
120
Havzi, S. and Taibi, D.
An Overview of Toxic Content Datasets for Artiﬁcial Intelligence Applications to Educate Students Towards a Better Use of Social Media.
DOI: 10.5220/0011987100003470
In Proceedings of the 15th International Conference on Computer Supported Education (CSEDU 2023) - Volume 2, pages 120-127",,,,,SCITEPRESS ,"Proceedings of the 15th International Conference on Computer Supported Education, CSEDU 2023, Volume 2, Prague, Czech Republic, April 21-23, 2023 ",,Use_dataset#survey,
4358,"Series([], Name: Abstract, dtype: object)","Van Dorpe J,Yang Z,Grenon-Godbout N,Winterstein G",,,Unveiling Identity Biases in Toxicity Detection : A Game-Focused Dataset and Reactivity Analysis Approach,,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: EMNLP 2023 - Industry Track, Singapore, December 6-10, 2023 ",,detection,
4359,"407    Title:I'm out of breath from laughing! I think...
Name: Abstract, dtype: object","Bogireddy NR,Suresh S,Rai S",,,I'm out of breath from laughing! I think? A dataset of COVID-19 Humor and its toxic variants,,,10.1145/3543873.3587591 , Conference Paper,2023.0,"ABSTRACT
 Humor is a cognitive construct that predominantly evokes the feeling of mirth. During the COVID-19 pandemic, the situations that arouse out of the pandemic were so incongruous to the world we knew that even factual statements often had a humorous reaction. In this paper, we present a dataset of 2510 samples hand-annotated with labels such as humor style, type, theme, target and stereotypes formed or exploited while creating the humor in addition to 909 memes. Our dataset comprises Reddit posts, comments, Onion news headlines, real news headlines, and tweets. We evaluate the task of humor detection and maladaptive humor detection on state-of-the-art models namely RoBERTa and GPT-3. The finetuned models trained on our dataset show significant gains over zero-shot models including GPT-3 when detecting humor. Even though GPT-3 is good at generating meaningful explanations, we observed that it fails to detect maladaptive humor due to the absence of overt targets and profanities. We believe that the presented dataset will be helpful in designing computational methods for topical humor processing as it provides a unique sample set to study the theory of incongruity in a post-pandemic world. The data is available to research community at https://github.com/smritae01/Covid19_Humor. 

                    References
                Vikram Ahuja, Radhika Mamidi, and Navjyoti Singh. 2018. From Humour to Hatred: A Computational Analysis of Off-Colour Humour. In CCF International Conference on Natural Language Processing and Chinese Computing. Springer, 144–153.Google ScholarCross RefUmair Akram, Kamila Irvine, Sarah F Allen, Jodie C Stevenson, Jason G Ellis, and Jennifer Drabble. 2021. Internet memes related to the COVID-19 pandemic as a potential coping mechanism for anxiety. Scientific reports 11, 1 (2021), 1–8.Google ScholarPatrizia Amici. 2020. Humor in the age of COVID-19 lockdown: An explorative qualitative study. Psychiatria Danubina 32, suppl. 1 (2020), 15–20.Google ScholarLuca Bischetti, Paolo Canal, and Valentina Bambini. 2020. Funny but aversive: a large-scale survey of the emotional response to COVID-19 humor in the Italian population during the lockdown. (2020).Google ScholarAxel Bruns and Jean Burgess. 2015. Twitter hashtags from ad hoc to calculated publics. Hashtag publics: The power and politics of discursive networks (2015), 13–28.Google ScholarKaryn Buxman. 2012. Types of Humor: The Good, The Bad, and The (Sometimes) Ugly. URL: https://aath. memberclicks. net/assets/docs/HumorResources/the% 20goodkaryn% 20aat h% 20hr. pdf (2012).Google ScholarSimon Critchley. 2011. On humour. Routledge.Google ScholarChristie Davies. 2008. Undertaking the comparative study of humor. The primer of humor research, Berlin: Mouton de Gruyter (2008), 157–182.Google ScholarLambert Deckers and Philip Kizer. 1975. Humor and the incongruity hypothesis. The Journal of Psychology 90, 2 (1975), 215–218.Google ScholarCross RefDavid JA Dozois, Rod A Martin, and Peter J Bieling. 2009. Early maladaptive schemas and adaptive/maladaptive styles of humor. Cognitive therapy and research 33, 6 (2009), 585–596.Google ScholarFederica Durante and Susan T Fiske. 2017. How social-class stereotypes maintain inequality. Current opinion in psychology 18 (2017), 43–48.Google ScholarMarta Dynel. 2021. COVID-19 memes going viral: On the multiple multimodal voices behind face masks. Discourse & Society 32, 2 (2021), 175–195.Google ScholarCross RefMaxwell Forbes, Jena D Hwang, Vered Shwartz, Maarten Sap, and Yejin Choi. 2020. Social chemistry 101: Learning to reason about social and moral norms. arXiv preprint arXiv:2011.00620 (2020).Google ScholarYi R Fung, Tuhin Chakraborty, Hao Guo, Owen Rambow, Smaranda Muresan, and Heng Ji. 2022. NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly. arXiv preprint arXiv:2210.08604 (2022).Google ScholarAhmed T Hussein and Lina Nabil Aljamili. 2020. COVID-19 humor in Jordanian social media: A socio-semiotic approach. Heliyon 6, 12 (2020), e05696.Google ScholarCross RefMohammed Khaliq, Rohan Joseph, and Sunny Rai. 2021. # covid is war and# vaccine is weapon? COVID-19 metaphors in India. In Proceedings of the 18th International Conference on Natural Language Processing (ICON). 431–438.Google ScholarDirk Kranz, Nicole Maria Thomas, and Jan Hofer. 2021. Changes in age stereotypes in adolescent and older participants of an intergenerational encounter program. Frontiers in Psychology 12 (2021), 658797.Google ScholarCross RefGiselinde Kuipers. 2002. Media culture and Internet disaster jokes: Bin Laden and the attack on the World Trade Center. European Journal of Cultural Studies 5, 4 (2002), 450–470.Google ScholarCross RefTiane L Lee and Susan T Fiske. 2006. Not an outgroup, not yet an ingroup: Immigrants in the stereotype content model. International Journal of Intercultural Relations 30, 6 (2006), 751–768.Google ScholarCross RefDafna Lemish and Nelly Elias. 2020. “We decided we don’t want children. We will let them know tonight”: Parental humor on social media in a time of coronavirus pandemic. International Journal of Communication 14 (2020), 27.Google ScholarKeith B Maddox. 2006. Rethinking racial stereotyping, prejudice, and discrimination. Psychological Science Agenda 20, 4 (2006).Google ScholarRod A Martin, Patricia Puhlik-Doris, Gwen Larsen, Jeanette Gray, and Kelly Weir. 2003. Individual differences in uses of humor and their relation to psychological well-being: Development of the Humor Styles Questionnaire. Journal of research in personality 37, 1 (2003), 48–75.Google ScholarCross RefAriadna Matamoros-Fernández, Aleesha Rodriguez, and Patrik Wikström. 2022. Humor That Harms? Examining Racist Audio-Visual Memetic Media on TikTok During Covid-19. Media and Communication 10, 2 (2022), 180–191.Google ScholarCross RefJA Meaney, Steven Wilson, Luis Chiruzzo, Adam Lopez, and Walid Magdy. 2021. Semeval 2021 task 7: Hahackathon, detecting and rating humor and offense. In Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021). 105–119.Google ScholarCross RefBertolt Meyer and Frank Asbrock. 2018. Disabled or cyborg? How bionics affect stereotypes toward people with physical disabilities. Frontiers in psychology (2018), 2251.Google ScholarTrenton D Mize and Bianca Manago. 2018. The stereotype content of sexual orientation. Social Currents 5, 5 (2018), 458–478.Google ScholarCross RefJohn Morreall. 2012. Philosophy of humor.Google ScholarAndrew R Olah and Thomas E Ford. 2021. Humor styles predict emotional and behavioral responses to COVID-19. Humor 34, 2 (2021), 177–199.Google ScholarCross RefAna Laura Pérez. 2021. ""The “hate speech” policies of major platforms during the COVID-19 pandemic"". UNESCO, Document Code: MTD/CI/2021/PI/0/REV1 (2021), 32.Google ScholarSunny Rai, Shampa Chakraverty, Devendra K Tayal, Divyanshu Sharma, and Ayush Garg. 2019. Understanding metaphors using emotions. New Generation Computing 37 (2019), 5–27.Google ScholarDigital LibraryAbira Reizer, Yifat Munk, and Lotem Katz Frankfurter. 2022. Laughing all the way to the lockdown: On humor, optimism, and well-being during COVID-19. Personality and Individual Differences 184 (2022), 111164.Google ScholarCross RefRohit Revi 2014. Understanding obscenity and offensive humour. The European Journal of Humour Research 2, 3 (2014), 98–114.Google ScholarCross RefYiwen Shi, Taha ValizadehAslani, Jing Wang, Ping Ren, Yi Zhang, Meng Hu, Liang Zhao, and Hualou Liang. 2022. Improving imbalanced learning by pre-finetuning with data augmentation. In Fourth International Workshop on Learning with Imbalanced Domains: Theory and Applications. PMLR, 68–82.Google ScholarBettina Spencer. 2019. Stereotyping and political decision making. In Oxford Research Encyclopedia of Politics.Google ScholarAndrea Strinić, Magnus Carlsson, and Jens Agerström. 2021. Occupational stereotypes: Professionals warmth and competence perceptions of occupations. Personnel Review (2021).Google ScholarJoel Mayo Torres, Leila M Collantes, Emily T Astrero, Arceli R Millan, and Carlo M Gabriel. 2020. Pandemic humor: Inventory of the humor scripts produced during the COVID-19 outbreak. Torres, JM, Collantes, LM, Astrero, ET, Millan, AR, & Gabriel, CM (2020). Pandemic humor: Inventory of the humor scripts produced during the COVID-19 outbreak. The Asian EFL Journal 7, 3.1 (2020), 138–164.Google ScholarSimon Vurayai. 2020. The paradox of disparagement humor: An analysis of WhatsApp jokes on women in the fight against the Covid-19 pandemic. Gender & Behaviour 18, 3 (2020), 15949–56.Google ScholarWikipedia contributors. 2022. Topical humor — Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/w/index.php?title=Topical_humor&oldid=1096195133. [Online; accessed 26-November-2022].Google ScholarMassih Zekavat. 2021. Employing satire and humor in facing a pandemic. Humor 34, 2 (2021), 283–304.Google ScholarCross RefXiaoquan Zhao, Maria L Roditis, and Tesfa N Alexander. 2019. Fear and humor appeals in “The Real Cost” campaign: Evidence of potential effectiveness in message pretesting. American journal of preventive medicine 56, 2 (2019), S31–S39.Google Scholar


Cited ByView all







Index Terms

I’m out of breath from laughing! I think? A dataset of COVID-19 Humor and its toxic variantsComputing methodologiesArtificial intelligenceNatural language processingLanguage resources

 Recommendations 
MUMOR: A Multimodal Dataset for Humor Detection in ConversationsNatural Language Processing and Chinese Computing  AbstractHumor detection attracts increased attention in natural language processing for its potential applications. Prior work focus on analyzing humor on isolated, textual data, but humor usually comes from the interaction among speakers in a multimodal ...Read More“Go eat a bat, Chang!”: On the Emergence of Sinophobic Behavior on Web Communities in the Face of COVID-19WWW '21: Proceedings of the Web Conference 2021  
 The outbreak of the COVID-19 pandemic has changed our lives in unprecedented ways. In the face of the projected catastrophic consequences, most countries have enacted social distancing measures in an attempt to limit the spread of the virus. Under ...Read MorePortuguese Twitter Dataset on COVID-19ASONAM '22: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining  
Over the last two years, the COVID-19 pandemic has affected hundreds of millions of people around the world. As in many crises, people turn to social media platforms, like Twitter, to communicate and share information. Twitter datasets have been used ...Read More





 Comments 
Please enable JavaScript to view thecomments powered by Disqus.",,,,,ACM ,"Companion Proceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023 ",,out_of_scope,
4360,"408    Title:A benchmark for toxic comment classifica...
Name: Abstract, dtype: object","Duchene C,Jamet H,Guillaume P,Dehak R",,,A benchmark for toxic comment classification on Civil Comments dataset,abs/2301.11125,,10.48550/ARXIV.2301.11125 , Journal Article,2023.0,"Abstract:Toxic comment detection on social media has proven to be essential for content moderation. This paper compares a wide set of different models on a highly skewed multi-label hate speech dataset. We consider inference time and several metrics to measure performance and bias in our comparison. We show that all BERTs have similar performance regardless of the size, optimizations or language used to pre-train the models. RNNs are much faster at inference than any of the BERT. BiLSTM remains a good compromise between performance and inference time. RoBERTa with Focal Loss offers the best performance on biases and AUROC. However, DistilBERT combines both good AUROC and a low inference time. All models are affected by the bias of associating identities. BERT, RNN, and XLNet are less sensitive than the CNN and Compact Convolutional Transformers.",,,,, CoRR, ,,Gen_dataset#detection,
4361,"409    Title:Beyond Toxic: Toxicity Detection Dataset...
Name: Abstract, dtype: object","Korotkova E,Chung IK",,,Beyond Toxic: Toxicity Detection Datasets are Not Enough for Brand Safety,abs/2303.15110,,10.48550/ARXIV.2303.15110 , Journal Article,2023.0,"Abstract
The rapid growth in user generated content on social media has resulted in a significant rise in demand for automated content moderation. Various methods and frameworks have been proposed for the tasks of hate speech detection and toxic comment classification. In this work, we combine common datasets to extend these tasks to brand safety. Brand safety aims to protect commercial branding by identifying contexts where advertisements should not appear and covers not only toxicity, but also other potentially harmful content.
As these datasets contain different label sets, we approach the overall problem as a binary classification task.
We demonstrate the need for building brand safety specific datasets via the application of common toxicity detection datasets to a subset of brand safety and empirically analyze the effects of weighted sampling strategies in text classification.",,,,, CoRR, ,,Gen_dataset#detection,
4362,"410    Title:Detecting Unintended Social Bias in Toxi...
Name: Abstract, dtype: object","Sahoo N,Gupta H,Bhattacharyya P",,,Detecting Unintended Social Bias in Toxic Language Datasets,,, , Conference Paper,2022.0,"Abstract:With the rise of online hate speech, automatic detection of Hate Speech, Offensive texts as a natural language processing task is getting popular. However, very little research has been done to detect unintended social bias from these toxic language datasets. This paper introduces a new dataset ToxicBias curated from the existing dataset of Kaggle competition named ""Jigsaw Unintended Bias in Toxicity Classification"". We aim to detect social biases, their categories, and targeted groups. The dataset contains instances annotated for five different bias categories, viz., gender, race/ethnicity, religion, political, and LGBTQ. We train transformer-based models using our curated datasets and report baseline performance for bias identification, target generation, and bias implications. Model biases and their mitigation are also discussed in detail. Our study motivates a systematic extraction of social bias data from toxic language datasets. All the codes and dataset used for experiments in this work are publicly available",,,,,Association for Computational Linguistics ,"Proceedings of the 26th Conference on Computational Natural Language Learning, CoNLL 2022, Abu Dhabi, United Arab Emirates (Hybrid Event), December 7-8, 2022 ",,Use_dataset#evaluation,
4363,"411    Title:Effective Feature Selection Method for C...
Name: Abstract, dtype: object","Antelo-Collado A,Carrasco-Velar R,García-Pedrajas N,García GC",,,Effective Feature Selection Method for Class-Imbalance Datasets Applied to Chemical Toxicity Prediction,61,1,10.1021/ACS.JCIM.0C00908 , Journal Article,2021.0,"Abstract
        
      


      
      During the drug development process, it is common to carry out toxicity tests and adverse effect studies, which are essential to guarantee patient safety and the success of the research. The use of in silico quantitative structure-activity relationship (QSAR) approaches for this task involves processing a huge amount of data that, in many cases, have an imbalanced distribution of active and inactive samples. This is usually termed the class-imbalance problem and may have a significant negative effect on the performance of the learned models. The performance of feature selection (FS) for QSAR models is usually damaged by the class-imbalance nature of the involved datasets. This paper proposes the use of an FS method focused on dealing with the class-imbalance problems. The method is based on the use of FS ensembles constructed by boosting and using two well-known FS methods, fast clustering-based FS and the fast correlation-based filter. The experimental results demonstrate the efficiency of the proposal in terms of the classification performance compared to standard methods. The proposal can be extended to other FS methods and applied to other problems in cheminformatics.",,,,, J. Chem. Inf. Model., ,,out_of_scope,
4364,"412    Title:A Dutch Dataset for Cross-lingual Multil...
Name: Abstract, dtype: object","Burtenshaw B,Kestemont M",,,A Dutch Dataset for Cross-lingual Multilabel Toxicity Detection,,, , Conference Paper,2021.0,"AbstractMulti-label toxicity detection is highly prominent, with many research groups, companies, and individuals engaging with it through shared tasks and dedicated venues. This paper describes a cross-lingual approach to annotating multi-label text classification on a newly developed Dutch language dataset, using a model trained on English data. We present an ensemble model of one Transformer model and an LSTM using Multilingual embeddings. The combination of multilingual embeddings and the Transformer model improves performance in a cross-lingual setting.",,,,,INCOMA Ltd. ,"Proceedings of the 14th Workshop on Building and Using Comparable Corpora, BUCC@RANLP 2021, Online, September 6, 2021 ",,out_but_toxicity,
4365,"413    Title:CONDA: a CONtextual Dual-Annotated datas...
Name: Abstract, dtype: object","Weld H,Huang G,Lee J,Zhang T,Wang K,Guo X,Long S,Poon J,Han SC",,,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,ACL/IJCNLP 2021,,10.18653/V1/2021.FINDINGS-ACL.213 , Conference Paper,2021.0,"Abstract:Traditional toxicity detection models have focused on the single utterance level without deeper understanding of context. We introduce CONDA, a new dataset for in-game toxic language detection enabling joint intent classification and slot filling analysis, which is the core task of Natural Language Understanding (NLU). The dataset consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed Dota 2 matches. We propose a robust dual semantic-level toxicity framework, which handles utterance and token-level patterns, and rich contextual chatting history. Accompanying the dataset is a thorough in-game toxicity analysis, which provides comprehensive understanding of context at utterance, token, and dual levels. Inspired by NLU, we also apply its metrics to the toxicity detection tasks for assessing toxicity and game-specific aspects. We evaluate strong NLU models on CONDA, providing fine-grained results for different intent classes and slot classes. Furthermore, we examine the coverage of toxicity nature in our dataset by comparing it with other toxicity datasets.",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021 ",,Gen_dataset#detection,
4366,"414    Title:Improved Bi-GRU Model for Imbalanced Eng...
Name: Abstract, dtype: object","Wang Z,Zhang B",,,Improved Bi-GRU Model for Imbalanced English Toxic Comments Dataset,,,10.1145/3508230.3508234 , Conference Paper,2021.0,"ABSTRACT
Deep learning is widely used in the study of English toxic comment classification. However, most existing studies failed to consider data imbalance. Aiming at an imbalanced English Toxic Comments Dataset, we propose an improved Bi-gated recurrent unit (GRU) model that combines an oversampling and cost-sensitive method. We use random oversampling in the improved model to reduce the data imbalance, introduce a cost-sensitive method, and propose a new loss function for the Bi-GRU model. Experimental results show that the improved Bi-GRU model demonstrates a significantly improved classification performance in the imbalanced English Toxic Comments Dataset.

                    References
                Support and S. Team, “Harassment survey.” Wikimedia Foundation, 2015. https://foundation.wikimedia.org/wiki/File:Harassment_Survey_2015_-_Results_Report.pdf.Google ScholarK. Dinakar, R. Reichart, and H. Lieberman, “Modeling the detection of textual cyberbullying,” in Proceedings of the International AAAI Conference on Web and Social Media, vol. 5, 2011.Google ScholarJ.-M. Xu, K.-S. Jun, X. Zhu, and A. Bellmore, “Learning from bullying traces in social media,” in Proceedings of the 2012 conference of the North American chapter of the association for computational linguistics: Human language technologies, pp. 656–666, 2012.Google ScholarDigital LibraryT. Davidson, D. Warmsley, M. Macy, and I. Weber, “Automated hate speech detection and the problem of offensive language,” in Proceedings of the International AAAI Conference on Web and Social Media, vol. 11, 2017.Google ScholarCross RefS. V. Georgakopoulos, S. K. Tasoulis, A. G. Vrahatis, and V. P. Plagianakos, “Convolutional neural networks for toxic comment classification,” in Proceedings of the 10th hellenic conference on artificial intelligence, pp. 1–6, 2018.Google ScholarDigital LibraryS. V. Georgakopoulos, S. K. Tasoulis, A. G. Vrahatis, and V. P. Plagianakos, “Convolutional neural networks for toxic comment classification,” in Proceedings of the 10th hellenic conference on artificial intelligence, pp. 1–6, 2018.Google ScholarDigital LibraryN. Nikhil, R. Pahwa, M. K. Nirala, and R. Khilnani, “Lstms with attention for aggression detection,” in Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), pp. 52–57, 2018.Google ScholarR. Kumar, G. Bhanodai, R. Pamula, and M. R. Chennuru, “Trac-1 shared task on aggression identification: Iit (ism)@ coling鈥?8,” in Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), pp. 58–65, 2018.Google ScholarR. Pronko, “Simple bidirectional lstm solution for text classification,” Proceedings ofthePolEval2019Workshop, p. 111, 2019.Google ScholarS. Srivastava, P. Khurana, and V. Tewari, “Identifying aggression and toxicity in comments using capsule network,” in Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), pp. 98–105, 2018.Google ScholarV. Garcá, J. S. Sánchez, and R. A. Mollineda, “On the effectiveness of preprocessing methods when dealing with different levels of class imbalance,” Knowledge-Based Systems, vol. 25, no. 1, pp. 13–21, 2012.Google ScholarY.-X. Wang, D. Ramanan, and M. Hebert, “Learning to model the tail,” in Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 7032–7042, 2017.Google ScholarB. Krawczyk, “Cost-sensitive one-vs-one ensemble for multi-class imbalanced data,” in 2016 International Joint Conference on Neural Networks (IJCNN), pp. 2447–2452, IEEE, 2016.Google ScholarCross RefC. Zhang, K. C. Tan, H. Li, and G. S. Hong, “A cost-sensitive deep belief network for imbalanced classification,” IEEE transactions on neural networks and learning systems, vol. 30, no. 1, pp. 109–122, 2018.Google ScholarY. Cui, M. Jia, T.-Y. Lin, Y. Song, and S. Belongie, “Class-balanced loss based on effective number of samples,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9268–9277, 2019.Google ScholarCross RefJ. Cheng, L. Dong, and M. Lapata, “Long short-term memory-networks for machine reading,” arXiv preprint arXiv:1601.06733, 2016.Google ScholarCross Ref


Cited ByView all







 Recommendations 
Over-sampling via under-sampling in strongly imbalanced data
Classification of imbalanced datasets is an important challenge in machine learning. This investigation analysed the effect of ratio imbalance and the selected classifier on the application of several re-sampling strategies to deal with imbalanced ...Read MoreCost-Sensitive Learning for Imbalanced Bad Debt Datasets in Healthcare IndustryAPCASE '15: Proceedings of the 2015 Asia-Pacific Conference on Computer Aided System Engineering  
The research using computational intelligence methods to improve bad debt recovery is imperative due to the rapid increase in the cost of healthcare in the U.S. This study explores effectiveness of using cost-sensitive learning methods to classify the ...Read MoreAn Effective Method for Imbalanced Time Series Classification: Hybrid SamplingProceedings of the 26th Australasian Joint Conference on AI 2013: Advances in Artificial Intelligence - Volume 8272  
Most traditional supervised classification learning algorithms are ineffective for highly imbalanced time series classification, which has received considerably less attention than imbalanced data problems in data mining and machine learning research. ...Read More





 Comments 
Please enable JavaScript to view thecomments powered by Disqus.",,,,,ACM ,"NLPIR 2021: 5th International Conference on Natural Language Processing and Information Retrieval, Sanya, China, December 17 - 20, 2021 ",,detection#methodology,
4367,"415    Title:TEET! Tunisian Dataset for Toxic Speech ...
Name: Abstract, dtype: object","Gharbi S,Arfaoui H,Haddad H,Kchaou M",,,TEET! Tunisian Dataset for Toxic Speech Detection,abs/2110.05287,, , Journal Article,2021.0,"Abstract:The complete freedom of expression in social media has its costs especially in spreading harmful and abusive content that may induce people to act accordingly. Therefore, the need of detecting automatically such a content becomes an urgent task that will help and enhance the efficiency in limiting this toxic spread. Compared to other Arabic dialects which are mostly based on MSA, the Tunisian dialect is a combination of many other languages like MSA, Tamazight, Italian and French. Because of its rich language, dealing with NLP problems can be challenging due to the lack of large annotated datasets. In this paper we are introducing a new annotated dataset composed of approximately 10k of comments. We provide an in-depth exploration of its vocabulary through feature engineering approaches as well as the results of the classification performance of machine learning classifiers like NB and SVM and deep learning models such as ARBERT, MARBERT and XLM-R.",,,,, CoRR, ,,out_but_toxicity,
4368,"416    Title:Ground-Truth, Whose Truth? - Examining t...
Name: Abstract, dtype: object","Arhin K,Baldini I,Wei D,Ramamurthy KN,Singh M",,,"Ground-Truth, Whose Truth? - Examining the Challenges with Annotating Toxic Text Datasets",abs/2112.03529,, , Journal Article,2021.0,"Abstract:The use of machine learning (ML)-based language models (LMs) to monitor content online is on the rise. For toxic text identification, task-specific fine-tuning of these models are performed using datasets labeled by annotators who provide ground-truth labels in an effort to distinguish between offensive and normal content. These projects have led to the development, improvement, and expansion of large datasets over time, and have contributed immensely to research on natural language. Despite the achievements, existing evidence suggests that ML models built on these datasets do not always result in desirable outcomes. Therefore, using a design science research (DSR) approach, this study examines selected toxic text datasets with the goal of shedding light on some of the inherent issues and contributing to discussions on navigating these challenges for existing and future projects. To achieve the goal of the study, we re-annotate samples from three toxic text datasets and find that a multi-label approach to annotating toxic text samples can help to improve dataset quality. While this approach may not improve the traditional metric of inter-annotator agreement, it may better capture dependence on context and diversity in annotators. We discuss the implications of these results for both theory and practice.",,,,, CoRR, ,,Gen_dataset#Use_dataset#evaluation,
4369,"417    Title:ToxicoDB: an integrated database to mine...
Name: Abstract, dtype: object","Nair SK,Eeles C,Ho C,Beri G,Yoo E,Tkachuk D,Tang A,Nijrabi P,Smirnov P,Seo H,Jennen D,Haibe-Kains B",,,ToxicoDB: an integrated database to mine and visualize large-scale toxicogenomic datasets,48,Webserver-Issue,10.1093/NAR/GKAA390 , Journal Article,2020.0,"In the past few decades, major initiatives have been launched around the world to address chemical safety testing. These efforts aim to innovate and improve the efficacy of existing methods with the long-term goal of developing new risk assessment paradigms. The transcriptomic and toxicological profiling of mammalian cells has resulted in the creation of multiple toxicogenomic datasets and corresponding tools for analysis. To enable easy access and analysis of these valuable toxicogenomic data, we have developed ToxicoDB (toxicodb.ca), a free and open cloud-based platform integrating data from large in vitro toxicogenomic studies, including gene expression profiles of primary human and rat hepatocytes treated with 231 potential toxicants. To efficiently mine these complex toxicogenomic data, ToxicoDB provides users with harmonized chemical annotations, time- and dose-dependent plots of compounds across datasets, as well as the toxicity-related pathway analysis. The data in ToxicoDB have been generated using our open-source R package, ToxicoGx (github.com/bhklab/ToxicoGx). Altogether, ToxicoDB provides a streamlined process for mining highly organized, curated, and accessible toxicogenomic data that can be ultimately applied to preclinical toxicity studies and further our understanding of adverse outcomes.",,,,, Nucleic Acids Res., ,,out_of_scope,
4370,"418    Title:ALONE: A Dataset for Toxic Behavior Amon...
Name: Abstract, dtype: object","Wijesiriwardene T,Inan H,Kursuncu U,Gaur M,Shalin VL,Thirunarayan K,Sheth AP,Arpinar IB",,,ALONE: A Dataset for Toxic Behavior Among Adolescents on Twitter,12467,,10.1007/978-3-030-60975-7_31 , Conference Paper,2020.0,"Abstract:The convenience of social media has also enabled its misuse, potentially resulting in toxic behavior. Nearly 66% of internet users have observed online harassment, and 41% claim personal experience, with 18% facing severe forms of online harassment. This toxic communication has a significant impact on the well-being of young individuals, affecting mental health and, in some cases, resulting in suicide. These communications exhibit complex linguistic and contextual characteristics, making recognition of such narratives challenging. In this paper, we provide a multimodal dataset of toxic social media interactions between confirmed high school students, called ALONE (AdoLescents ON twittEr), along with descriptive explanation. Each instance of interaction includes tweets, images, emoji and related metadata. Our observations show that individual tweets do not provide sufficient evidence for toxic behavior, and meaningful use of context in interactions can enable highlighting or exonerating tweets with purported toxicity.",,,,,Springer ,"Social Informatics - 12th International Conference, SocInfo 2020, Pisa, Italy, October 6-9, 2020, Proceedings ",,Gen_dataset,
4371,"419    Title:ALONE: A Dataset for Toxic Behavior amon...
Name: Abstract, dtype: object","Wijesiriwardene T,Inan H,Kursuncu U,Gaur M,Shalin VL,Thirunarayan K,Sheth AP,Arpinar IB",,,ALONE: A Dataset for Toxic Behavior among Adolescents on Twitter,abs/2008.06465,, , Journal Article,2020.0,"Abstract:The convenience of social media has also enabled its misuse, potentially resulting in toxic behavior. Nearly 66% of internet users have observed online harassment, and 41% claim personal experience, with 18% facing severe forms of online harassment. This toxic communication has a significant impact on the well-being of young individuals, affecting mental health and, in some cases, resulting in suicide. These communications exhibit complex linguistic and contextual characteristics, making recognition of such narratives challenging. In this paper, we provide a multimodal dataset of toxic social media interactions between confirmed high school students, called ALONE (AdoLescents ON twittEr), along with descriptive explanation. Each instance of interaction includes tweets, images, emoji and related metadata. Our observations show that individual tweets do not provide sufficient evidence for toxic behavior, and meaningful use of context in interactions can enable highlighting or exonerating tweets with purported toxicity.",,,,, CoRR, ,,Gen_dataset,
4372,"420    Title:Binary Classification Models Comparison:...
Name: Abstract, dtype: object","Makhtar M,Neagu D,Ridley MJ",,,Binary Classification Models Comparison: On the Similarity of Datasets and Confusion Matrix for Predictive Toxicology Applications,6865,,10.1007/978-3-642-23208-4_11 , Conference Paper,2011.0,"ABSTRACT
Nowadays generating predictive models by applying machine learning and model ensembles techniques is a faster task facilitated by development of more user-friendly data mining tools. However, such progress raises the issues related to model management: once developed, many classifiers for example become accessible in collections of models. Choosing the relevant model from the collection can reduce costs of generating new predictive models: calculating the similarity of predictive models is the key to rank them, which may improve model selection or combination. For this aim we introduce a methodology to measure the similarity of classifiers by comparing their datasets, transfer functions and confusion matrices. We propose the Dataset Similarity Coefficient to calculate the similarity of datasets, and the Similarity of Models measure to calculate the similarity between such predictive models. In this paper we focus on toxicology applications of binary classification models. The results show that our methodology performs well in measuring models similarity from a collection of classifiers.

                    References
                Makhtar, M., Neagu, D.C., Ridley, M.: Predictive Model Representation and Comparison: Towards Data and Predictive Models Governance. In: Proceedings of the 10th UK Workshop on Computational Intelligence UKCI 2010, pp. 1-6. University of Essex, UK (2010)Google ScholarTodeschini, R., Consonnia, V., Pavan, M.: A distance measure between models: a tool for similarity/diversity analysis of model populations. Chemometrics and Intelligent Laboratory Systems 70, 55-61 (2004)Google ScholarCross RefChoi, S.-S., Cha, S.-H., Tappert, C.C.: A Survey of Binary Similarity and Distance Measures. Journal of Systemics, Cybernetics and Informatics 8, 43-48 (2010)Google ScholarLesot, M.-J., Rifqi, M.: Similarity measures for binary and numerical data: a survey. International Journal of Knowledge Engineering and Soft Data Paradigms 1, 63-84 (2009)  Google ScholarDigital LibrarySequeira, K., Zaki, M.J.: Exploring Similarities across High-dimensional Datasets. In: Taniar, D. (ed.) Research and Trends in Data Mining Technologies and Applications, vol. 3, pp. 53-85. Idea Group Inc., USA (2007)Google ScholarPrasanna, S.R.M., Yegnanarayana, B., Pinto, J.P., Hermansky, H.: Analysis of Confusion Matrix to Combine Evidence for Phoneme Recognition. IDIAP Research Report, IDIAPRR- 27-2007 (2007)Google ScholarFreitas, C.O.A., Carvalho, J.M.D.: J. Jose Josemar Oliveira, S. B. K. Aires, and R. Sabourin.: Confusion Matrix Disagreement for Multiple Classifiers. In: Proceedings of the Congress on pattern recognition 12th Iberoamerican Conference on Progress in Pattern Recognition, Image Analysis and Applications, pp. 387-396 (2007) Google ScholarDigital LibraryWitten, I.H., Frank, E., Trigg, L., Hall, M., Holmes, G., Cunningham, S.J.: Weka: Practical Machine Learning Tools and Techniques with Java Implementations. In: Proceedings of the ICONIP/ANZIIS/ANNES 1999 Workshop on Emerging Knowledge Engineering and Connectionist-Based Information Systems, pp. 192-196 (1999)Google ScholarD. M. Group.: PMML 3.2 - Model Explanation Documents (2008)Google ScholarKohavi, R., Provost, F.: Glossary of Terms. Editorial for the Special Issue on Applications of Machine Learning and the Knowledge Discovery Process 30, 271-274 (1998) Google ScholarDigital LibraryFawcett, T.: ROC Graphs: Notes and Practical Considerations for Researchers. HP Laboratories (2004)Google ScholarDEMETRA Project (2008), http://www.demetra-tox.net/Google ScholarTETRATOX.: TETRATOX Home (2008), http://www.vet.utk.edu/TETRATOX/index.phpGoogle ScholarTrundle, P.: Hybrid Intelligent Systems Applied to Predict Pesticides Toxicity - a Data Integration Approach. Phd Thesis. School of Informatics, University of Bradford, UK (2008)Google Scholar


Cited ByView all







Index Terms

Binary classification models comparison: on the similarity of datasets and confusion matrix for predictive toxicology applicationsComputing methodologiesMachine learningLearning paradigmsSupervised learningSupervised learning by classificationMachine learning approachesClassification and regression trees

 Index terms have been assigned to the content through auto-classification.
 Recommendations 
Comparing multi-class classifiers: on the similarity of confusion matrices for predictive toxicology applicationsIDEAL'11: Proceedings of the 12th international conference on Intelligent data engineering and automated learning  
Calculating the similarity of predictive models helps to characterize the models diversity and to identify relevant models from a collection of models. The relevant models are considered based on their performance, calculated using their confusion ...Read MoreUsing confusion matrices and confusion graphs to design ensemble classification models from large datasetsDaWaK'11: Proceedings of the 13th international conference on Data warehousing and knowledge discovery  
Classification modeling is one of the methods commonly employed for predictive data mining. Ensemble classification is concerned with the creation of many base models which are combined into one model for purposes of increasing classification ...Read MoreMulti-label Stream Classification Using Extended Binary Relevance ModelTRUSTCOM-BIGDATASE-ISPA '15: Proceedings of the 2015 IEEE Trustcom/BigDataSE/ISPA - Volume 02  
In this paper the issue of multi-label data stream classification was addressed. To deal with the posed problem, we introduced a recognition system that is build upon a two level architecture. The first level is a Binary Relevance multi-label classifier,...Read More





 Comments 
Please enable JavaScript to view thecomments powered by Disqus.",,,,,Springer ,"Information Technology in Bio- and Medical Informatics - Second International Conference, ITBAM 2011, Toulouse, France, August 29 - September 2, 2011. Proceedings ",,out_of_scope,
4373,"Series([], Name: Abstract, dtype: object)","Muralikumar MD,Yang YS,McDonald DW",,,A Human-centered Evaluation of a Toxicity Detection API: Testing Transferability and Unpacking Latent Attributes,6,,10.1145/3582568 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, ACM Trans. Soc. Comput., ,,Use_dataset#evaluation,
4374,"Series([], Name: Abstract, dtype: object)","Böck J,Schütz M,Liakhovets D,Satriani NQ,Babic A,Slijepcevic D,Zeppelzauer M,Schindler A",,,"AIT_FHSTP at EXIST 2023 Benchmark: Sexism Detection by Transfer Learning, Sentiment and Toxicity Embeddings and Hand-Crafted Features",3497,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,CEUR-WS.org ,"Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2023), Thessaloniki, Greece, September 18th to 21st, 2023 ",,detection#evaluation#methodology,
4375,"Series([], Name: Abstract, dtype: object)","Berezin S,Farahbakhsh R,Crespi N",,,"No offence, Bert - I insult only humans! Multilingual sentence-level attack on toxicity detection networks",,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023 ",,detection#evaluation,
4376,"Series([], Name: Abstract, dtype: object)","Lin Z,Wang Z,Tong Y,Wang Y,Guo Y,Wang Y,Shang J",,,ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation,,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023 ",,,
4377,"Series([], Name: Abstract, dtype: object)","Raman V,Fleisig E,Klein D",,,Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection,,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023 ",,,
4378,"Series([], Name: Abstract, dtype: object)","Upadhyaya A,Fisichella M,Nejdl W",,,"Toxicity, Morality, and Speech Act Guided Stance Detection",,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023 ",,,
4379,"Series([], Name: Abstract, dtype: object)","Sarker J,Sultana S,Wilson SR,Bosu A",,,ToxiSpanSE: An Explainable Toxicity Detection in Code Review Comments,,,10.1109/ESEM56168.2023.10304855 , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,IEEE ,"ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2023, New Orleans, LA, USA, October 26-27, 2023 ",,,
4380,"Series([], Name: Abstract, dtype: object)","Eskelinen A,Silvala L,Ginter F,Pyysalo S,Laippala V",,,Toxicity Detection in Finnish Using Machine Translation,,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,University of Tartu Library ,"Proceedings of the 24th Nordic Conference on Computational Linguistics, NoDaLiDa 2023, Tórshavn, Faroe Islands, May 22-24, 2023 ",,,
4381,"Series([], Name: Abstract, dtype: object)","Maity A,Kandru P,Singh B,Hari KA,Varma V",,,IREL at SemEval-2023 Task 11: User Conditioned Modelling for Toxicity Detection in Subjective Tasks,,,10.18653/V1/2023.SEMEVAL-1.294 , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Proceedings of the The 17th International Workshop on Semantic Evaluation, SemEval@ACL 2023, Toronto, Canada, 13-14 July 2023 ",,,
4382,"457    Title:Same Same, But Different: Conditional Mu...
Name: Abstract, dtype: object","Gupta S,Lee S,De-Arteaga M,Lease M",,,"Same Same, But Different: Conditional Multi-Task Learning for Demographic-Specific Toxicity Detection",,,10.1145/3543507.3583290 , Conference Paper,2023.0,"Algorithmic bias often arises as a result of differential subgroup validity, in which predictive relationships vary across groups. For example, in toxic language detection, comments targeting different demographic groups can vary markedly across groups. In such settings, trained models can be dominated by the relationships that best fit the majority group, leading to disparate performance. We propose framing toxicity detection as multi-task learning (MTL), allowing a model to specialize on the relationships that are relevant to each demographic group while also leveraging shared properties across groups. With toxicity detection, each task corresponds to identifying toxicity against a particular demographic group. However, traditional MTL requires labels for all tasks to be present for every data point. To address this, we propose Conditional MTL (CondMTL), wherein only training examples relevant to the given demographic group are considered by the loss function. This lets us learn group specific representations in each branch which are not cross contaminated by irrelevant labels. Results on synthetic and real data show that using CondMTL improves predictive recall over various baselines in general and for the minority demographic group in particular, while having similar overall accuracy.",,,,,ACM ,"Proceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023 ",,,
4383,"Series([], Name: Abstract, dtype: object)","Gunturi U,Ding X,Rho EH",,,ToxVis: Enabling Interpretability of Implicit vs. Explicit Toxicity Detection Models with Interactive Visualization,abs/2303.09402,,10.48550/ARXIV.2303.09402 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4384,"426    Title:Lightweight Toxicity Detection in Spoken...
Name: Abstract, dtype: object","Nada AH,Latif S,Qadir J",,,Lightweight Toxicity Detection in Spoken Language: A Transformer-based Approach for Edge Devices,abs/2304.11408,,10.48550/ARXIV.2304.11408 , Journal Article,2023.0,"Abstract:Toxicity is a prevalent social behavior that involves the use of hate speech, offensive language, bullying, and abusive speech. While text-based approaches for toxicity detection are common, there is limited research on processing speech signals in the physical world. Detecting toxicity in the physical world is challenging due to the difficulty of integrating AI-capable computers into the environment. We propose a lightweight transformer model based on wav2vec2.0 and optimize it using techniques such as quantization and knowledge distillation. Our model uses multitask learning and achieves an average macro F1-score of 90.3\% and a weighted accuracy of 88\%, outperforming state-of-the-art methods on DeToxy-B and a public dataset. Our results show that quantization reduces the model size by almost 4 times and RAM usage by 3.3\%, with only a 1\% F1 score decrease. Knowledge distillation reduces the model size by 3.7 times, RAM usage by 1.9, and inference time by 2 times, but decreases accuracy by 8\%. Combining both techniques reduces the model size by 14.6 times and RAM usage by around 4.3 times, with a two-fold inference time improvement. Our compact model is the first end-to-end speech-based toxicity detection model based on a lightweight transformer model suitable for deployment in physical spaces. The results show its feasibility for toxicity detection on edge devices in real-world environments.",,,,, CoRR, ,,,
4385,"Series([], Name: Abstract, dtype: object)","Althunayan H,Bahlas R,Alharbi M,Alsuwailem L,Aldayel A,Alahmadi R",,,Toxicity Inspector: A Framework to Evaluate Ground Truth in Toxicity Detection Through Feedback,abs/2305.10433,,10.48550/ARXIV.2305.10433 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4386,"Series([], Name: Abstract, dtype: object)","Berezin S,Farahbakhsh R,Crespi N",,,"No offence, Bert - I insult only humans! Multiple addressees sentence-level attack on toxicity detection neural network",abs/2310.13099,,10.48550/ARXIV.2310.13099 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4387,"Series([], Name: Abstract, dtype: object)","Cao YT,Domingo LF,Gilbert SA,Mazurek ML,Shilton K,Iii HD",,,Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators,abs/2311.07879,,10.48550/ARXIV.2311.07879 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4388,"Series([], Name: Abstract, dtype: object)","Balestriero R,Cosentino R,Shekkizhar S",,,Characterizing Large Language Model Geometry Solves Toxicity Detection and Generation,abs/2312.01648,,10.48550/ARXIV.2312.01648 , Journal Article,2023.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4389,"Series([], Name: Abstract, dtype: object)","Al-Merekhi HA,Kwak H,Salminen J,Jansen BJ",,,PROVOKE: Toxicity trigger detection in conversations from the top 100 subreddits,6,4,10.1016/J.DIM.2022.100019 , Journal Article,2022.0,"Series([], Name: Abstract, dtype: object)",,,,, Data Inf. Manag., ,,,
4390,"Series([], Name: Abstract, dtype: object)","Xenos A,Pavlopoulos J,Androutsopoulos I,Dixon L,Sorensen J,Laugier L",,,Toxicity detection sensitive to conversational context,27,9, , Journal Article,2022.0,"Series([], Name: Abstract, dtype: object)",,,,, First Monday, ,,,
4391,"Series([], Name: Abstract, dtype: object)",Gupta VK,,,Toxicity detection of small drug molecules of the mitochondrial membrane potential signalling pathway using bagging-based ensemble learning,27,1/2/3,10.1504/IJDMB.2022.10052684 , Journal Article,2022.0,"Series([], Name: Abstract, dtype: object)",,,,, Int. J. Data Min. Bioinform., ,,,
4392,"Series([], Name: Abstract, dtype: object)","Lashkarashvili N,Tsintsadze M",,,Toxicity detection in online Georgian discussions,2,1,10.1016/J.JJIMEI.2022.100062 , Journal Article,2022.0,"Series([], Name: Abstract, dtype: object)",,,,, Int. J. Inf. Manag. Data Insights, ,,,
4393,"Series([], Name: Abstract, dtype: object)",Lobo PR,,,Bias in Hate Speech and Toxicity Detection,,,10.1145/3514094.3539519 , Conference Paper,2022.0,"Series([], Name: Abstract, dtype: object)",,,,,ACM ,"AIES '22: AAAI/ACM Conference on AI, Ethics, and Society, Oxford, United Kingdom, May 19 - 21, 2021 ",,,
4394,"Series([], Name: Abstract, dtype: object)","Lobo PR,Daga E,Alani H",,,Supporting Online Toxicity Detection with Knowledge Graphs,,, , Conference Paper,2022.0,"Series([], Name: Abstract, dtype: object)",,,,,AAAI Press ,"Proceedings of the Sixteenth International AAAI Conference on Web and Social Media, ICWSM 2022, Atlanta, Georgia, USA, June 6-9, 2022 ",,,
4395,"Series([], Name: Abstract, dtype: object)","Jhaveri M,Ramaiya D,Chadha HS",,,Toxicity Detection for Indic Multilingual Social Media Content,abs/2201.00598,, , Journal Article,2022.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4396,"Series([], Name: Abstract, dtype: object)","Wang YS,Chang Y",,,Toxicity Detection with Generative Prompt-based Inference,abs/2205.12390,,10.48550/ARXIV.2205.12390 , Journal Article,2022.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4397,"460    Title:RECAST: Enabling User Recourse and Inter...
Name: Abstract, dtype: object","Wright AP,Shaikh O,Park H,Epperson W,Ahmed M,Pinel S,Chau DH,Yang D",,,RECAST: Enabling User Recourse and Interpretability of Toxicity Detection Models with Interactive Visualization,5,CSCW1,10.1145/3449280 , Journal Article,2021.0,"With the widespread use of toxic language online, platforms are increasingly using automated systems that leverage advances in natural language processing to automatically flag and remove toxic comments. However, most automated systems, when detecting and moderating toxic language, do not provide feedback to their users, let alone provide an avenue of recourse for these users to make actionable changes. We present our work, RECAST, an interactive, open-sourced web tool for visualizing these models' toxic predictions, while providing alternative suggestions for flagged toxic language. Our work also provides users with a new path of recourse when using these automated moderation tools. RECAST highlights text responsible for classifying toxicity, and allows users to interactively substitute potentially toxic phrases with neutral alternatives. We examined the effect of RECAST via two large-scale user evaluations, and found that RECAST was highly effective at helping users reduce toxicity as detected through the model. Users also gained a stronger understanding of the underlying toxicity criterion used by black-box models, enabling transparency and recourse. In addition, we found that when users focus on optimizing language for these models instead of their own judgement (which is the implied incentive and goal of deploying automated models), these models cease to be effective classifiers of toxicity compared to human annotations. This opens a discussion for how toxicity detection models work and should work, and their effect on the future of online discourse.",,,,, Proc. ACM Hum. Comput. Interact., ,,,
4398,"Series([], Name: Abstract, dtype: object)","Lübbering M,Pielka M,Das K,Gebauer M,Ramamurthy R,Bauckhage C,Sifa R",,,Toxicity Detection in Online Comments with Limited Data: A Comparative Analysis,,,10.14428/ESANN/2021.ES2021-48 , Conference Paper,2021.0,"Series([], Name: Abstract, dtype: object)",,,,, ,"29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2021, Online event (Bruges, Belgium), October 6-8, 2021 ",,,
4399,"455    Title:AI-UPV at IberLEF-2021 DETOXIS task: Tox...
Name: Abstract, dtype: object","de Paula AF,Schlicht IB",,,AI-UPV at IberLEF-2021 DETOXIS task: Toxicity Detection in Immigration-Related Web News Comments Using Transformers and Statistical Models,2943,, , Conference Paper,2021.0,"This paper presents a new study to use pre-trained language models based on the transformers for Arabic grammatical error detection (GED). We proposed fine-tuned language models based on pre-trained language models called AraBERT and M-BERT to perform Arabic GED on two approaches, which are the token level and sentence level. Fine-tuning was done with different publicly available Arabic datasets. The proposed models outperform similar studies with F1 value of 0.87, recall of 0.90, precision of 0.83 at the token level, and F1 of 0.98, recall of 0.99, and precision of 0.97 at the sentence level. Whereas the other studies in the same field (i.e., GED) results less than the current study (e.g., F0.5 of 69.21). Moreover, the current study shows that the fine-tuned language models that were built on the monolingual pre-trained language models result in better performance than the multilingual pre-trained language models in Arabic.",,,,,CEUR-WS.org ,"Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2021) co-located with the Conference of the Spanish Society for Natural Language Processing (SEPLN 2021), XXXVII International Conference of the Spanish Society for Natural Language Processing., Málaga, Spain, September, 2021 ",,,
4400,"Series([], Name: Abstract, dtype: object)","Nath M,Goswami S",,,Toxicity Detection in Drug Candidates using Simplified Molecular-Input Line-Entry System,abs/2101.10831,, , Journal Article,2021.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4401,"Series([], Name: Abstract, dtype: object)","Ghosh S,Baker DK,Jurgens D,Prabhakaran V",,,Cross-geographic Bias Detection in Toxicity Modeling,abs/2104.06999,, , Journal Article,2021.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4402,"Series([], Name: Abstract, dtype: object)","Anjum,Katarya R",,,Analysis of Online Toxicity Detection Using Machine Learning Approaches,abs/2108.01062,, , Journal Article,2021.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4403,"Series([], Name: Abstract, dtype: object)","Xenos A,Pavlopoulos J,Androutsopoulos I,Dixon L,Sorensen J,Laugier L",,,Toxicity Detection can be Sensitive to the Conversational Context,abs/2111.10223,, , Journal Article,2021.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4404,"Series([], Name: Abstract, dtype: object)","Venkit PN,Wilson S",,,Identification of Bias Against People with Disabilities in Sentiment Analysis and Toxicity Detection Models,abs/2111.13259,, , Journal Article,2021.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4405,"456    Title:RECAST: Interactive Auditing of Automati...
Name: Abstract, dtype: object","Wright AP,Shaikh O,Park H,Epperson W,Ahmed M,Pinel S,Yang D,Chau DH",,,RECAST: Interactive Auditing of Automatic Toxicity Detection Models,,,10.1145/3403676.3403691 , Conference Paper,2020.0,"As toxic language becomes nearly pervasive online, there has been increasing interest in leveraging the advancements in natural language processing (NLP) to automatically detect and remove toxic comments. Despite fairness concerns and limited interpretability, there is currently little work for auditing these systems in particular for end users. We present our ongoing work, Recast , an interactive tool for auditing toxicity detection models by visualizing explanations for predictions and providing alternative wordings for detected toxic speech. Recast displays the attention of toxicity detection models on user input, and provides an intuitive system for rewording impactful language within a comment with less toxic alternative words close in embedding space. Finally we propose a larger user study of Recast , with promising preliminary results, to validate it’s effectiveness and useability with end users.",,,,,ACM ,"Chinese CHI 2020: The eighth International Workshop of Chinese CHI, Honolulu, HI, USA, April, 2020 ",,,
4406,"Series([], Name: Abstract, dtype: object)","Saini B,Srivastava S,Bajpai AK",,,Robust Automated detection of Nanocarriers' Toxicity using Microscopic Image Analysis,6,20,10.4108/EAI.13-7-2018.156593 , Journal Article,2019.0,"Series([], Name: Abstract, dtype: object)",,,,, EAI Endorsed Trans. Scalable Inf. Syst., ,,,
4407,"Series([], Name: Abstract, dtype: object)","Gao K,Gao F,Du L,He C,Wan H,Wang P",,,"Multifunctional SH-SY5Y-based biomimetic sensor for integrated detection of olfaction, gustation and toxicity",,,10.1109/ISOEN.2019.8823301 , Conference Paper,2019.0,"Series([], Name: Abstract, dtype: object)",,,,,IEEE ,"IEEE International Symposium on Olfaction and Electronic Nose, ISOEN 2019, Fukuoka, Japan, May 26-29, 2019 ",,,
4408,"Series([], Name: Abstract, dtype: object)",Noever D,,,Machine Learning Suites for Online Toxicity Detection,abs/1810.01869,, , Journal Article,2018.0,"Series([], Name: Abstract, dtype: object)",,,,, CoRR, ,,,
4409,"Series([], Name: Abstract, dtype: object)","Zhou T,Han H,Liu P,Xiong J,Tian F,Li X",,,Microbial Fuels Cell-Based Biosensor for Toxicity Detection: A Review,17,10,10.3390/S17102230 , Journal Article,2017.0,"Series([], Name: Abstract, dtype: object)",,,,, Sensors, ,,,
4410,"Series([], Name: Abstract, dtype: object)","Märtens M,Shen S,Iosup A,Kuipers FA",,,Toxicity detection in multiplayer online games,,,10.1109/NETGAMES.2015.7382991 , Conference Paper,2015.0,"Series([], Name: Abstract, dtype: object)",,,,,IEEE ,"2015 International Workshop on Network and Systems Support for Games, NetGames 2015, Zagreb, Croatia, December 3-4, 2015 ",,,
4411,"Series([], Name: Abstract, dtype: object)","Zhang Q,Ding J,Kou L,Qin W",,,A Potentiometric Flow Biosensor Based on Ammonia-Oxidizing Bacteriafor the Detection of Toxicity in Water,13,6,10.3390/S130606936 , Journal Article,2013.0,"Series([], Name: Abstract, dtype: object)",,,,, Sensors, ,,,
4412,"Series([], Name: Abstract, dtype: object)","Covington JA,Wedlake L,Andreyev J,Ouaret N,Thomas MG,Nwokolo CU,Bardhan KD,Arasaradnam RP",,,The Detection of Patients at Risk of Gastrointestinal Toxicity during Pelvic Radiotherapy by Electronic Nose and FAIMS: A Pilot Study,12,10,10.3390/S121013002 , Journal Article,2012.0,"Series([], Name: Abstract, dtype: object)",,,,, Sensors, ,,,
4413,"Series([], Name: Abstract, dtype: object)","Pireddu L,Michielan L,Floris M,Rodriguez-Tomé P,Moro S",,,Fingerprint-based detection of acute aquatic toxicity,2,S-1,10.1186/1758-2946-2-S1-P46 , Journal Article,2010.0,"Series([], Name: Abstract, dtype: object)",,,,, J. Cheminformatics, ,,,
4414,"Series([], Name: Abstract, dtype: object)","Kim SY,Kwon KY,Lee WD",,,A Biological Early Warning System for Toxicity Detection,,,10.1109/NCM.2009.358 , Conference Paper,2009.0,"Series([], Name: Abstract, dtype: object)",,,,,IEEE Computer Society ,"International Conference on Networked Computing and Advanced Information Management, NCM 2009, Fifth International Joint Conference on INC, IMS and IDC: INC 2009: International Conference on Networked Computing, IMS 2009: International Conference on Advanced Information Management and Service, IDC 2009: International Conference on Digital Content, Multimedia Technology and its Applications, Seoul, Korea, August 25-27, 2009 ",,,
4415,"Series([], Name: Abstract, dtype: object)","Cruz-Monteagudo M,Cordeiro MN,Borges F",,,Computational chemistry approach for the early detection of drug-induced idiosyncratic liver toxicity,29,4,10.1002/JCC.20812 , Journal Article,2007.0,"Series([], Name: Abstract, dtype: object)",,,,, J. Comput. Chem., ,,,
4416,"Series([], Name: Abstract, dtype: object)",Yamani HE,,,Mesure de la toxicité de polluants par biocapteur. Réalisation d'une électrode à butyrylcholinestérase. Automatisation de la détection de pesticides. (Toxicity measurement of pollutants by a biosensor. Construction of a butyrylcholinesterase electrode. Automatisation of pesticides detection),,, , Ph.D. Thesis,1987.0,"Series([], Name: Abstract, dtype: object)",,,,, , ,,,
4417,"421    Title:In-Game Toxic Language Detection: Shared...
Name: Abstract, dtype: object","Jia Y,Wu W,Cao F,Han SC",,,In-Game Toxic Language Detection: Shared Task and Attention Residuals (Student Abstract),,,10.1609/AAAI.V37I13.26979 , Conference Paper,2023.0,"In-game toxic language becomes the hot potato in the gaming industry and community. There have been several online game toxicity analysis frameworks and models proposed. However, it is still challenging to detect toxicity due to the nature of in-game chat, which has extremely short length. In this paper, we describe how the in-game toxic language shared task has been established using the real-world in-game chat data. In addition, we propose and introduce the model/framework for toxic language token tagging (slot filling) from the in-game chat. The data and code will be released.",,,,,AAAI Press ,"Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence, IAAI 2023, Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023, Washington, DC, USA, February 7-14, 2023 ",,,
4418,"422    Title:Facilitating Fine-grained Detection of C...
Name: Abstract, dtype: object","Lu J,Xu B,Zhang X,Min C,Yang L,Lin H",,,"Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks",,,10.18653/V1/2023.ACL-LONG.898 , Conference Paper,2023.0,"Abstract:The widespread dissemination of toxic online posts is increasingly damaging to society. However, research on detecting toxic language in Chinese has lagged significantly. Existing datasets lack fine-grained annotation of toxic types and expressions, and ignore the samples with indirect toxicity. In addition, it is crucial to introduce lexical knowledge to detect the toxicity of posts, which has been a challenge for researchers. In this paper, we facilitate the fine-grained detection of Chinese toxic language. First, we built Monitor Toxic Frame, a hierarchical taxonomy to analyze toxic types and expressions. Then, a fine-grained dataset ToxiCN is presented, including both direct and indirect toxic samples. We also build an insult lexicon containing implicit profanity and propose Toxic Knowledge Enhancement (TKE) as a benchmark, incorporating the lexical feature to detect toxic language. In the experimental stage, we demonstrate the effectiveness of TKE. After that, a systematic quantitative and qualitative analysis of the findings is given.",,,,,Association for Computational Linguistics ,"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 ",,,
4419,"423    Title:Adding Instructions during Pretraining: ...
Name: Abstract, dtype: object","Prabhumoye S,Patwary M,Shoeybi M,Catanzaro B",,,Adding Instructions during Pretraining: Effective way of Controlling Toxicity in Language Models,,,10.18653/V1/2023.EACL-MAIN.193 , Conference Paper,2023.0,"Abstract:Pretrained large language models have become indispensable for solving various natural language processing (NLP) tasks. However, safely deploying them in real world applications is challenging because they generate toxic content. To address this challenge, we propose two novel pretraining data augmentation strategies that significantly reduce model toxicity without compromising its utility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data to the pretraining samples, and (2) INST: adds instructions to those samples indicating their toxicity. Our results indicate that our best performing strategy (INST) substantially reduces the toxicity probability up to 61% while preserving the accuracy on five benchmark NLP tasks as well as improving AUC scores on four bias detection tasks by 1.3%. We also demonstrate the generalizability of our techniques by scaling the number of training samples and the number of model parameters.",,,,,Association for Computational Linguistics ,"Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia, May 2-6, 2023 ",,,
4420,"Series([], Name: Abstract, dtype: object)","Deshpande A,Murahari V,Rajpurohit T,Kalyan A,Narasimhan K",,,Toxicity in chatgpt: Analyzing persona-assigned language models,,, , Conference Paper,2023.0,"Series([], Name: Abstract, dtype: object)",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023 ",,,
4421,"424    Title:Adding Instructions during Pretraining: ...
Name: Abstract, dtype: object","Prabhumoye S,Patwary M,Shoeybi M,Catanzaro B",,,Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models,abs/2302.07388,,10.48550/ARXIV.2302.07388 , Journal Article,2023.0,"Abstract:Pretrained large language models have become indispensable for solving various natural language processing (NLP) tasks. However, safely deploying them in real world applications is challenging because they generate toxic content. To address this challenge, we propose two novel pretraining data augmentation strategies that significantly reduce model toxicity without compromising its utility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data to the pretraining samples, and (2) INST: adds instructions to those samples indicating their toxicity. Our results indicate that our best performing strategy (INST) substantially reduces the toxicity probability up to 61% while preserving the accuracy on five benchmark NLP tasks as well as improving AUC scores on four bias detection tasks by 1.3%. We also demonstrate the generalizability of our techniques by scaling the number of training samples and the number of model parameters.",,,,, CoRR, ,,,
4422,"425    Title:Toxicity in ChatGPT: Analyzing Persona-a...
Name: Abstract, dtype: object","Deshpande A,Murahari V,Rajpurohit T,Kalyan A,Narasimhan K",,,Toxicity in ChatGPT: Analyzing Persona-assigned Language Models,abs/2304.05335,,10.48550/ARXIV.2304.05335 , Journal Article,2023.0,"AbstractLarge language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Legislation has recognized its significance and recently drafted a “Blueprint For An AI Bill Of Rights” which calls for domain experts to identify risks and potential impact of AI systems. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to 6×, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others (3× more) irrespective of the assigned persona, reflecting discriminatory biases in the model. Our findings show that multiple provisions in the legislative blueprint are being violated, and we hope that the broader AI community rethinks the efficacy of current safety guardrails and develops better techniques that lead to robust, safe, and trustworthy AI.",,,,, CoRR, ,,,
4423,"427    Title:Your fairness may vary: Pretrained langu...
Name: Abstract, dtype: object","Baldini I,Wei D,Ramamurthy KN,Singh M,Yurochkin M",,,Your fairness may vary: Pretrained language model fairness in toxic text classification,,,10.18653/V1/2022.FINDINGS-ACL.176 , Conference Paper,2022.0,"Abstract:The popularity of pretrained language models in natural language processing systems calls for a careful evaluation of such models in down-stream tasks, which have a higher potential for societal impact. The evaluation of such systems usually focuses on accuracy measures. Our findings in this paper call for attention to be paid to fairness measures as well. Through the analysis of more than a dozen pretrained language models of varying sizes on two toxic text classification tasks (English), we demonstrate that focusing on accuracy measures alone can lead to models with wide variation in fairness characteristics. Specifically, we observe that fairness can vary even more than accuracy with increasing training data size and different random initializations. At the same time, we find that little of the fairness variation is explained by model size, despite claims in the literature. To improve model fairness without retraining, we show that two post-processing methods developed for structured, tabular data can be successfully applied to a range of pretrained language models. Warning: This paper contains samples of offensive text.",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland, May 22-27, 2022 ",,,
4424,"428    Title:A Machine Learning Approach to Identify ...
Name: Abstract, dtype: object","Kaati L,Shrestha A,Akrami N",,,A Machine Learning Approach to Identify Toxic Language in the Online Space,,,10.1109/ASONAM55673.2022.10068619 , Conference Paper,2022.0,"Abstract:Now-a-days, derogatory comments are often made by one another, not only in offline environment but also immensely in online environments like social networking websites and online communities. So, an Identification combined with Prevention System in all social networking websites and applications, including all the communities, existing in the digital world is a necessity. In such a system, the Identification Block should identify any negative online behaviour and should signal the Prevention Block to take action accordingly. This study aims to analyse any piece of text and detecting different types of toxicity like obscenity, threats, insults and identity-based hatred. The labelled Wikipedia Comment Dataset prepared by Jigsaw is used for the purpose. A 6-headed Machine Learning tf-idf Model has been made and trained separately, yielding a Mean Validation Accuracy of 98.08% and Absolute Validation Accuracy of 91.61%. Such an Automated System should be deployed for enhancing healthy online conversation",,,,,IEEE ,"IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2022, Istanbul, Turkey, November 10-13, 2022 ",,,
4425,"429    Title:Towards Procedural Fairness: Uncovering ...
Name: Abstract, dtype: object","Nejadgholi I,Balkir E,Fraser KC,Kiritchenko S",,,Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information,,,10.18653/V1/2022.BLACKBOXNLP-1.18 , Conference Paper,2022.0,"Abstract:Previous works on the fairness of toxic language classifiers compare the output of models with different identity terms as input features but do not consider the impact of other important concepts present in the context. Here, besides identity terms, we take into account high-level latent features learned by the classifier and investigate the interaction between these features and identity terms. For a multi-class toxic language classifier, we leverage a concept-based explanation framework to calculate the sensitivity of the model to the concept of sentiment, which has been used before as a salient feature for toxic language detection. Our results show that although for some classes, the classifier has learned the sentiment information as expected, this information is outweighed by the influence of identity terms as input features. This work is a step towards evaluating procedural fairness, where unfair processes lead to unfair outcomes. The produced knowledge can guide debiasing techniques to ensure that important concepts besides identity terms are well-represented in training datasets.",,,,,Association for Computational Linguistics ,"Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2022, Abu Dhabi, United Arab Emirates (Hybrid), December 8, 2022 ",,,
4426,"430    Title:A Stacking-based Efficient Method for To...
Name: Abstract, dtype: object","Oikawa Y,Nakayama Y,Murakami K",,,A Stacking-based Efficient Method for Toxic Language Detection on Live Streaming Chat,,,10.18653/V1/2022.EMNLP-INDUSTRY.58 , Conference Paper,2022.0,"AbstractIn a live streaming chat on a video streaming service, it is crucial to filter out toxic comments with online processing to prevent users from reading comments in real-time. However, recent toxic language detection methods rely on deep learning methods, which can not be scalable considering inference speed. Also, these methods do not consider constraints of computational resources expected depending on a deployed system (e.g., no GPU resource).This paper presents an efficient method for toxic language detection that is aware of real-world scenarios. Our proposed architecture is based on partial stacking that feeds initial results with low confidence to meta-classifier. Experimental results show that our method achieves a much faster inference speed than BERT-based models with comparable performance.",,,,,Association for Computational Linguistics ,"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: EMNLP 2022 - Industry Track, Abu Dhabi, UAE, December 7 - 11, 2022 ",,,
4427,"431    Title:Prompt Compression and Contrastive Condi...
Name: Abstract, dtype: object","Wingate D,Shoeybi M,Sorensen T",,,Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models,,,10.18653/V1/2022.FINDINGS-EMNLP.412 , Conference Paper,2022.0,"Abstract:We explore the idea of compressing the prompts used to condition language models, and show that compressed prompts can retain a substantive amount of information about the original prompt. For severely compressed prompts, while fine-grained information is lost, abstract information and general sentiments can be retained with surprisingly few parameters, which can be useful in the context of decode-time algorithms for controllability and toxicity reduction. We explore contrastive conditioning to steer language model generation towards desirable text and away from undesirable text, and find that some complex prompts can be effectively compressed into a single token to guide generation. We also show that compressed prompts are largely compositional, and can be constructed such that they can be used to control independent aspects of generated text.",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022 ",,,
4428,"432    Title:Towards Automated Moderation: Enabling T...
Name: Abstract, dtype: object","Caron M,Bäumer FS,Müller O",,,Towards Automated Moderation: Enabling Toxic Language Detection with Transfer Learning and Attention-Based Models,,, , Conference Paper,2022.0,"Abstract


Our world is more connected than ever before. Sadly, however, this highly connected world has made it easier to bully, insult, and propagate hate speech on the cyberspace. Even though researchers and companies alike have started investigating this real-world problem, the question remains as to why users are increasingly being exposed to hate and discrimination online. In fact, the noticeable and persistent increase in harmful language on social media platforms indicates that the situation is, actually, only getting worse. Hence, in this work, we show that contemporary ML methods can help tackle this challenge in an accurate and cost-effective manner. Our experiments demonstrate that a universal approach combining transfer learning methods and state-of-the-art Transformer architectures can trigger the efficient development of toxic language detection models. Consequently, with this universal approach, we provide platform providers with a simplistic approach capable of enabling the automated moderation of user-generated content, and as a result, hope to contribute to making the web a safer place.",,,,,ScholarSpace ,"55th Hawaii International Conference on System Sciences, HICSS 2022, Virtual Event / Maui, Hawaii, USA, January 4-7, 2022 ",,,
4429,"433    Title:Detoxifying Language Models with a Toxic...
Name: Abstract, dtype: object","Park YA,Rudzicz F",,,Detoxifying Language Models with a Toxic Corpus,,,10.18653/V1/2022.LTEDI-1.6 , Conference Paper,2022.0,"Abstract:Existing studies have investigated the tendency of autoregressive language models to generate contexts that exhibit undesired biases and toxicity. Various debiasing approaches have been proposed, which are primarily categorized into data-based and decoding-based. In our study, we investigate the ensemble of the two debiasing paradigms, proposing to use toxic corpus as an additional resource to reduce the toxicity. Our result shows that toxic corpus can indeed help to reduce the toxicity of the language generation process substantially, complementing the existing debiasing methods.",,,,,Association for Computational Linguistics ,"Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion, LT-EDI 2022, Dublin, Ireland, May 27, 2022 ",,,
4430,"434    Title:Reward Modeling for Mitigating Toxicity ...
Name: Abstract, dtype: object","Faal F,Schmitt KA,Yu JY",,,Reward Modeling for Mitigating Toxicity in Transformer-based Language Models,abs/2202.09662,, , Journal Article,2022.0,"Abstract:Transformer-based language models are able to generate fluent text and be efficiently adapted across various natural language generation tasks. However, language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment. Various detoxification methods were proposed to mitigate the language model's toxicity; however, these methods struggled to detoxify language models when conditioned on prompts that contain specific social identities related to gender, race, or religion. In this study, we propose Reinforce-Detoxify; A reinforcement learning-based method for mitigating toxicity in language models. We address the challenge of safety in language models and propose a new reward model that is able to detect toxic content and mitigate unintended bias towards social identities in toxicity prediction. The experiments demonstrate that the Reinforce-Detoxify method for language model detoxification outperforms existing detoxification approaches in automatic evaluation metrics, indicating the ability of our approach in language model detoxification and less prone to unintended bias toward social identities in generated content.",,,,, CoRR, ,,,
4431,"435    Title:Beyond Plain Toxic: Detection of Inappro...
Name: Abstract, dtype: object","Babakov N,Logacheva V,Panchenko A",,,Beyond Plain Toxic: Detection of Inappropriate Statements on Flammable Topics for the Russian Language,abs/2203.02392,,10.48550/ARXIV.2203.02392 , Journal Article,2022.0,"Abstract:Toxicity on the Internet, such as hate speech, offenses towards particular users or groups of people, or the use of obscene words, is an acknowledged problem. However, there also exist other types of inappropriate messages which are usually not viewed as toxic, e.g. as they do not contain explicit offences. Such messages can contain covered toxicity or generalizations, incite harmful actions (crime, suicide, drug use), provoke ""heated"" discussions. Such messages are often related to particular sensitive topics, e.g. on politics, sexual minorities, social injustice which more often than other topics, e.g. cars or computing, yield toxic emotional reactions. At the same time, clearly not all messages within such flammable topics are inappropriate.
Towards this end, in this work, we present two text collections labelled according to binary notion of inapropriateness and a multinomial notion of sensitive topic. Assuming that the notion of inappropriateness is common among people of the same culture, we base our approach on human intuitive understanding of what is not acceptable and harmful. To objectivise the notion of inappropriateness, we define it in a data-driven way though crowdsourcing. Namely we run a large-scale annotation study asking workers if a given chatbot textual statement could harm reputation of a company created it. Acceptably high values of inter-annotator agreement suggest that the notion of inappropriateness exists and can be uniformly understood by different people. To define the notion of sensitive topics in an objective way we use on guidelines suggested commonly by specialists of legal and PR department of a large public company as potentially harmful.",,,,, CoRR, ,,,
4432,"436    Title:In-game Toxic Language Detection: Shared...
Name: Abstract, dtype: object","Jia Y,Wu W,Cao F,Han SC",,,In-game Toxic Language Detection: Shared Task and Attention Residuals,abs/2211.05995,,10.48550/ARXIV.2211.05995 , Journal Article,2022.0,"Abstract:In-game toxic language becomes the hot potato in the gaming industry and community. There have been several online game toxicity analysis frameworks and models proposed. However, it is still challenging to detect toxicity due to the nature of in-game chat, which has extremely short length. In this paper, we describe how the in-game toxic language shared task has been established using the real-world in-game chat data. In addition, we propose and introduce the model/framework for toxic language token tagging (slot filling) from the in-game chat. The data and code will be released.",,,,, CoRR, ,,,
4433,"437    Title:Mitigating Racial Biases in Toxic Langua...
Name: Abstract, dtype: object","Halevy M,Harris C,Bruckman AS,Yang D,Howard AM",,,Mitigating Racial Biases in Toxic Language Detection with an Equity-Based Ensemble Framework,,,10.1145/3465416.3483299 , Conference Paper,2021.0,"Abstract:Recent research has demonstrated how racial biases against users who write African American English exists in popular toxic language datasets. While previous work has focused on a single fairness criteria, we propose to use additional descriptive fairness metrics to better understand the source of these biases. We demonstrate that different benchmark classifiers, as well as two in-process bias-remediation techniques, propagate racial biases even in a larger corpus. We then propose a novel ensemble-framework that uses a specialized classifier that is fine-tuned to the African American English dialect. We show that our proposed framework substantially reduces the racial biases that the model learns from these datasets. We demonstrate how the ensemble framework improves fairness metrics across all sample datasets with minimal impact on the classification performance, and provide empirical evidence in its ability to unlearn the annotation biases towards authors who use African American English.
** Please note that this work may contain examples of offensive words and phrases.",,,,,ACM ,"EAAMO 2021: ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, Virtual Event, USA, October 5 - 9, 2021 ",,,
4434,"438    Title:Say 'YES' to Positivity: Detecting Toxic...
Name: Abstract, dtype: object","Bhat MM,Hosseini S,Awadallah AH,Bennett PN,Li W",,,Say 'YES' to Positivity: Detecting Toxic Language in Workplace Communications,,,10.18653/V1/2021.FINDINGS-EMNLP.173 , Conference Paper,2021.0,"AbstractWorkplace communication (e.g. email, chat, etc.) is a central part of enterprise productivity. Healthy conversations are crucial for creating an inclusive environment and maintaining harmony in an organization. Toxic communications at the workplace can negatively impact overall job satisfaction and are often subtle, hidden, or demonstrate human biases. The linguistic subtlety of mild yet hurtful conversations has made it difficult for researchers to quantify and extract toxic conversations automatically. While offensive language or hate speech has been extensively studied in social communities, there has been little work studying toxic communication in emails. Specifically, the lack of corpus, sparsity of toxicity in enterprise emails, and well-defined criteria for annotating toxic conversations have prevented researchers from addressing the problem at scale. We take the first step towards studying toxicity in workplace emails by providing (1) a general and computationally viable taxonomy to study toxic language at the workplace (2) a dataset to study toxic language at the workplace based on the taxonomy and (3) analysis on why offensive language and hate-speech datasets are not suitable to detect workplace toxicity.",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021 ",,,
4435,"439    Title:FH-SWF SG at GermEval 2021: Using Transf...
Name: Abstract, dtype: object","Gawron C,Schmidt S",,,"FH-SWF SG at GermEval 2021: Using Transformer-Based Language Models to Identify Toxic, Engaging, & Fact-Claiming Comments",,, , Conference Paper,2021.0,"<jats:ext-link xmlns:xlink=""http://www.w3.org/1999/xlink"" ext-link-type=""uri"" xlink:href=""http://Drugs.com"">Drugs.com</jats:ext-link> provides users’ textual reviews and numeric ratings of drugs. However, text reviews may not always be consistent with the numeric ratings. Overly positive or negative rating may be misleading. In this project, to classify user ratings of drugs with their textual reviews, we built classification models using traditional machine learning and deep learning approaches. Machine learning models including Random Forest and Naive Bayesian classifiers were built using TF-IDF features as input. Also, transformer-based neural network models including BERT, BioBERT, RoBERTa, XLNet, ELECTRA, and ALBERT were built using the raw text as input. Overall, BioBERT model outperformed the other models with an overall accuracy of 87%. We further identified UMLS concepts from the postings and analyzed their semantic types in the postings stratified by the classification result. This research demonstrated that transformer-based models can be used to classify drug reviews and identify reviews that are inconsistent with the ratings.",,,,,Association for Computational Linguistics ,"Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments, GermEval@KONVENS 2021, Düsseldorf, Germany, September 6, 2021 ",,,
4436,"440    Title:UoB at SemEval-2021 Task 5: Extending Pr...
Name: Abstract, dtype: object","Yan E,Madabushi HT",,,UoB at SemEval-2021 Task 5: Extending Pre-Trained Language Models to Include Task and Domain-Specific Information for Toxic Span Prediction,,,10.18653/V1/2021.SEMEVAL-1.28 , Conference Paper,2021.0,"Abstract:Toxicity is pervasive in social media and poses a major threat to the health of online communities. The recent introduction of pre-trained language models, which have achieved state-of-the-art results in many NLP tasks, has transformed the way in which we approach natural language processing. However, the inherent nature of pre-training means that they are unlikely to capture task-specific statistical information or learn domain-specific knowledge. Additionally, most implementations of these models typically do not employ conditional random fields, a method for simultaneous token classification. We show that these modifications can improve model performance on the Toxic Spans Detection task at SemEval-2021 to achieve a score within 4 percentage points of the top performing team.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,,
4437,"441    Title:A Comparative Study of Using Pre-trained...
Name: Abstract, dtype: object","Zhao Z,Zhang Z,Hopfgartner F",,,A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification,,,10.1145/3442442.3452313 , Conference Paper,2021.0,"Abstract:Objective: Clinical knowledge enriched transformer models (e.g., ClinicalBERT) have state-of-the-art results on clinical NLP (natural language processing) tasks. One of the core limitations of these transformer models is the substantial memory consumption due to their full self-attention mechanism, which leads to the performance degradation in long clinical texts. To overcome this, we propose to leverage long-sequence transformer models (e.g., Longformer and BigBird), which extend the maximum input sequence length from 512 to 4096, to enhance the ability to model long-term dependencies in long clinical texts.
Materials and Methods: Inspired by the success of long sequence transformer models and the fact that clinical notes are mostly long, we introduce two domain enriched language models, Clinical-Longformer and Clinical-BigBird, which are pre-trained on a large-scale clinical corpus. We evaluate both language models using 10 baseline tasks including named entity recognition, question answering, natural language inference, and document classification tasks.
Results: The results demonstrate that Clinical-Longformer and Clinical-BigBird consistently and significantly outperform ClinicalBERT and other short-sequence transformers in all 10 downstream tasks and achieve new state-of-the-art results.
Discussion: Our pre-trained language models provide the bedrock for clinical NLP using long texts. We have made our source code available at this https URL, and the pre-trained models available for public download at: this https URL.
Conclusion: This study demonstrates that clinical knowledge enriched long-sequence transformers are able to learn long-term dependencies in long clinical text. Our methods can also inspire the development of other domain-enriched long-sequence transformers.",,,,,ACM / IW3C2 ,"Companion of The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021 ",,,
4438,"442    Title:Your fairness may vary: Group fairness o...
Name: Abstract, dtype: object","Baldini I,Wei D,Ramamurthy KN,Yurochkin M,Singh M",,,Your fairness may vary: Group fairness of pretrained language models in toxic text classification,abs/2108.01250,, , Journal Article,2021.0,"AbstractThe popularity of pretrained language models in natural language processing systems calls for a careful evaluation of such models in down-stream tasks, which have a higher potential for societal impact. The evaluation of such systems usually focuses on accuracy measures. Our findings in this paper call for attention to be paid to fairness measures as well. Through the analysis of more than a dozen pretrained language models of varying sizes on two toxic text classification tasks (English), we demonstrate that focusing on accuracy measures alone can lead to models with wide variation in fairness characteristics. Specifically, we observe that fairness can vary even more than accuracy with increasing training data size and different random initializations. At the same time, we find that little of the fairness variation is explained by model size, despite claims in the literature. To improve model fairness without retraining, we show that two post-processing methods developed for structured, tabular data can be successfully applied to a range of pretrained language models. Warning: This paper contains samples of offensive text.",,,,, CoRR, ,,,
4439,"443    Title:Speech Toxicity Analysis: A New Spoken L...
Name: Abstract, dtype: object","Ghosh S,Lepcha S,Sakshi S,Shah RR",,,Speech Toxicity Analysis: A New Spoken Language Processing Task,abs/2110.07592,, , Journal Article,2021.0,"Toxic speech, also known as hate speech, is regarded as one of the crucial issues plaguing online social media today. Most recent work on toxic speech detection is constrained to the modality of text with no existing work on toxicity detection from spoken utterances. In this paper, we propose a new Spoken Language Processing task of detecting toxicity from spoken speech. We introduce DeToxy, the first publicly available toxicity annotated dataset for English speech, sourced from various openly available speech databases, consisting of over 2 million utterances. Finally, we also provide analysis on how a spoken speech corpus annotated for toxicity can help facilitate the development of E2E models which better capture various prosodic cues in speech, thereby boosting toxicity classification on spoken utterances.",,,,, CoRR, ,,,
4440,"444    Title:Simple Text Detoxification by Identifyin...
Name: Abstract, dtype: object","Wang A,Sudhakar M,Ji Y",,,Simple Text Detoxification by Identifying a Linear Toxic Subspace in Language Model Embeddings,abs/2112.08346,, , Journal Article,2021.0,"Abstract:Large pre-trained language models are often trained on large volumes of internet data, some of which may contain toxic or abusive language. Consequently, language models encode toxic information, which makes the real-world usage of these language models limited. Current methods aim to prevent toxic features from appearing generated text. We hypothesize the existence of a low-dimensional toxic subspace in the latent space of pre-trained language models, the existence of which suggests that toxic features follow some underlying pattern and are thus removable. To construct this toxic subspace, we propose a method to generalize toxic directions in the latent space. We also provide a methodology for constructing parallel datasets using a context based word masking system. Through our experiments, we show that when the toxic subspace is removed from a set of sentence representations, almost no toxic representations remain in the result. We demonstrate empirically that the subspace found using our method generalizes to multiple toxicity corpora, indicating the existence of a low-dimensional toxic subspace.",,,,, CoRR, ,,,
4441,"445    Title:RealToxicityPrompts: Evaluating Neural T...
Name: Abstract, dtype: object","Gehman S,Gururangan S,Sap M,Choi Y,Smith NA",,,RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models,EMNLP 2020,,10.18653/V1/2020.FINDINGS-EMNLP.301 , Conference Paper,2020.0,"Abstract:Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning ""bad"" words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 ",,,
4442,"446    Title:A little goes a long way: Improving toxi...
Name: Abstract, dtype: object","Juuti M,Gröndahl T,Flanagan A,Asokan N",,,A little goes a long way: Improving toxic language classification despite data scarcity,EMNLP 2020,,10.18653/V1/2020.FINDINGS-EMNLP.269 , Conference Paper,2020.0,"Abstract:Detection of some types of toxic language is hampered by extreme scarcity of labeled training data. Data augmentation - generating new synthetic data from a labeled seed dataset - can help. The efficacy of data augmentation on toxic language classification has not been fully explored. We present the first systematic study on how data augmentation techniques impact performance across toxic language classifiers, ranging from shallow logistic regression architectures to BERT - a state-of-the-art pre-trained Transformer network. We compare the performance of eight techniques on very scarce seed datasets. We show that while BERT performed the best, shallow classifiers performed comparably when trained on data augmented with a combination of three techniques, including GPT-2-generated sentences. We discuss the interplay of performance and computational overhead, which can inform the choice of techniques under different constraints.",,,,,Association for Computational Linguistics ,"Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 ",,,
4443,"447    Title:Characterizing Variation in Toxic Langua...
Name: Abstract, dtype: object","Radfar B,Shivaram K,Culotta A",,,Characterizing Variation in Toxic Language by Social Context,,, , Conference Paper,2020.0,"How two people speak to one another depends heavily on the nature of their relationship. For example, the same phrase said to a friend in jest may be offensive to a stranger. In this paper, we apply this simple observation to study toxic comments in online social networks. We curate a collection of 6.7K tweets containing potentially toxic terms from users with different relationship types, as determined by the nature of their follower-friend connection. We find that such tweets between users with no connection are nearly three times as likely to be toxic as those between users who are mutual friends, and that taking into account this relationship type improves toxicity detection methods by about 5% on average. Furthermore, we provide a descriptive analysis of how toxic language varies by relationship type, finding for example that mildly offensive terms are used to express hostility more commonly between users with no social connection than users who are mutual friends.",,,,,AAAI Press ,"Proceedings of the Fourteenth International AAAI Conference on Web and Social Media, ICWSM 2020, Held Virtually, Original Venue: Atlanta, Georgia, USA, June 8-11, 2020 ",,,
4444,"448    Title:Detection of Toxic Language in Short Tex...
Name: Abstract, dtype: object","Makhnytkina O,Matveev A,Bogoradnikova D,Lizunova I,Maltseva A,Shilkina N",,,Detection of Toxic Language in Short Text Messages,12335,,10.1007/978-3-030-60276-5_31 , Conference Paper,2020.0,"The ever-increasing online communication landscape provides circumstances for people with significant differences in their views to cross paths unlike it was ever possible before. This leads to the raise of toxicity in online comments and discussions and makes the development of means to detect instances of such phenomenon critically important. The toxic language detection problem is fairly researched and some solutions produce highly accurate predictions when significantly large datasets are available for training. However, such datasets are not always available for various languages. In this paper, we review different ways to approach the problem targeting transferring knowledge from one language to another: machine translation, multi-lingual models, and domain adaptation. We also focus on the analysis of methods for word embedding such as Word2Vec, FastText, GloVe, BERT, and methods for classification of toxic comment: Naïve Bayes, Random Forest, Logistic regression, Support Vector Machine, Majority vote, and Recurrent Neural Networks. We demonstrate that for small datasets in the Russian language, traditional machine-learning techniques produce highly competitive results on par with deep learning methods, and also that machine translation of the dataset to the English language produces more accurate results than multi-lingual models.",,,,,Springer ,"Speech and Computer - 22nd International Conference, SPECOM 2020, St. Petersburg, Russia, October 7-9, 2020, Proceedings ",,,
4445,"449    Title:Shielding Google's language toxicity mod...
Name: Abstract, dtype: object","Rodriguez N,Galeano SR",,,Shielding Google's language toxicity model against adversarial attacks,abs/1801.01828,, , Journal Article,2018.0,"Abstract:Lack of moderation in online communities enables participants to incur in personal aggression, harassment or cyberbullying, issues that have been accentuated by extremist radicalisation in the contemporary post-truth politics scenario. This kind of hostility is usually expressed by means of toxic language, profanity or abusive statements. Recently Google has developed a machine-learning-based toxicity model in an attempt to assess the hostility of a comment; unfortunately, it has been suggested that said model can be deceived by adversarial attacks that manipulate the text sequence of the comment. In this paper we firstly characterise such adversarial attacks as using obfuscation and polarity transformations. The former deceives by corrupting toxic trigger content with typographic edits, whereas the latter deceives by grammatical negation of the toxic content. Then, we propose a two--stage approach to counter--attack these anomalies, bulding upon a recently proposed text deobfuscation method and the toxicity scoring model. Lastly, we conducted an experiment with approximately 24000 distorted comments, showing how in this way it is feasible to restore toxicity of the adversarial variants, while incurring roughly on a twofold increase in processing time. Even though novel adversary challenges would keep coming up derived from the versatile nature of written language, we anticipate that techniques combining machine learning and text pattern recognition methods, each one targeting different layers of linguistic features, would be needed to achieve robust detection of toxic language, thus fostering aggression--free digital interaction.",,,,, CoRR, ,,,
4446,"450    Title:The Impact of Toxic Language on the Heal...
Name: Abstract, dtype: object","Mohan S,Guha A,Harris M,Popowich F,Schuster A,Priebe C",,,The Impact of Toxic Language on the Health of Reddit Communities,10233,,10.1007/978-3-319-57351-9_6 , Conference Paper,2017.0,"AbstractThere are numerous on-line communities in which people converse about various topics and issues. It is usually necessary to monitor on-line forums to ensure that conversations and content are appropriate. Disturbing trends are starting to emerge, including cyberbullying, cyber threats, on-line harassment, hate speech, and abuse — referred to collectively as ‘toxicity’. Researchers have already started investigating automatic and semi-automatic monitoring of social networking sites for aspects of toxicity. We are investigating the relationship between on-line toxicity and forum health. Specifically, we provide results of the evaluation of the impact of toxicity on community health as a function of its size, while correcting for community topic.KeywordsFeature VectorToxicity LevelHealth ScoreHate SpeechUser EngagementThese keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",,,,, ,"Advances in Artificial Intelligence - 30th Canadian Conference on Artificial Intelligence, Canadian AI 2017, Edmonton, AB, Canada, May 16-19, 2017, Proceedings ",,,
4447,"451    NaN
Name: Abstract, dtype: object","Miller B,van den Bosch A,Kunzelman C,Olive J,Stoop W,Gray K,Berger C,Pokharel S",,,Notoriously Toxic: The Language and Cost of Hate in the Chat Systems of Online Games,,, , Conference Paper,2016.0,"'Notoriously Toxic' presents a preliminary study of the language and impact of hate speech in the chat systems of online games.  Developed by a group of researchers in game studies, computational linguistics, sociolinguistics, and law and guided by an overall tripartite feedback model broadly corresponding to shielding potential victims from harm, educating those who casually engage in hate speech, and censuring those who persist in abusing their fellow players, the hope is that research-driven technical and social interventions might slowly shift online discourse norms away from casual, vicious, and potentially dangerous speech.  Identification at scale of textual expressions of toxic behavior in online environments is a necessary, empirical preliminary aspect of this work to understand the prevalence and cost of online hate, as is qualitative cultural studies of the games and their player populations. A recent example of qualitative framing work in this area was the 'Mapping Study on Projects Against Hate Speech Online' released in 2012 by the British Institute of Human Rights for the Council of Europe project, Young People Combating Hate Speech in Cyberspace (The British Institute of Human Rights Council, 2012). That report provides terminology and an environmental scan of processes aimed to limit hate speech online and offers suggestions as to new procedures.  It, along with an examination of the reporting systems implemented across a host of online games, computational modeling of the language prevalent in these chat systems, and a study of work in the political sphere to defuse hate speech prior to its catalyzation of violence, serve as the foundation for this research. Recent inquiries into the toxic elements of gaming cultures have primarily focused on communication outside of a game environment. For example, critical discourse analyses of player posts to online gaming forums found that heteronormative undertones of the World of Warcraft player community creates a culture of hostility toward LGBTQ communities (Pulos, 2013) and the same forum's  adamant disavowal of feminism have made community conversations about gender roles and/or equality all but non-existent (Braithwaite, 2013). Similarly, Gray's (2012a; 2012b; 2012c) ethnography of Xbox Live demonstrates the constant barrage of gender and racially motivated harassment faced by women of color who opt to communicate with teammates via voice chat.  Finally, community leaders' adamant position of gender based harassment being a 'non-issue' is summarized by Salter and Blodgett (2012), whose case study of Penny Arcade's (a popular webcomic and organizers of PAX, a successful annual gaming convention) dismissal of its responsibility in perpetuating rape culture and SXSW Interactive's recent declaration that conversations about harassment in the games space can by definition not be civil (Sinders, 2015) is indicative of an industry that is highly resistant to change unless external pressure is applied.  Taken together, this scholarship is evidence that toxicity exists across gaming culture writ large, and is not isolated to a particular game or specific player community. Studying this phenomena at webscale and in the ephemeral environments of multilingual online chat systems is complex and requires a multidisciplinary approach bridging core strengths in the humanities, such as cultural criticism, with strengths in social psychology, the data sciences, and linguistics.  Studying the socially destructive behavior as manifested in online gaming platforms encourages innovative approaches to this problem.  One corpus examined as part of this research is comprised of the chat logs produced by the player base in Riot Games' League of Legends (League).  As of January 2014, League had ~27 million unique players every day each playing no less than 20 minutes and a peak concurrency of 7.5 million people who collectively have logged billions of hours of total play time for the game since 2009 (Sherr, 2014). Given that the game is a global phenomenon, the chat logs contain harassment in virtually every language. Based on the UN framework provided in the International Covenant on Civil and Political Rights (1976), Susan Benesch generally defines hate speech as '. . . an expression that denigrates or stigmatizes a person or people based on their membership of a group that is usually but not always immutable, such as an ethnic or religious group. . . . Speech may express or foment hatred on the basis of any defining feature of a minority or indigenous people, such as ethnicity or religion – and can also denigrate people for another “failing“, such as their gender or even their location, as in the case of migrants' (Benesch, 2014, pp. 20). This broad but inclusive definition is further elaborated upon by Nazila Ghanea in reference to the International Convention on the Elimination of All Forms of Racial Discrimination (ICERD) in the establishment of a spectrum from least to greatest: discriminatory speech, hate speech, incitement to hatred, incitement to terrorism, and incitement to genocide (Ghanea, 2013, pp. 940-1). The characteristics of these definitions reflect the significant impact that hate speech acts have on the establishment and enforcement of personal and communal identity and the need to identify such acts in order to preserve those identities. In his discussion on Carey's ritual model of communication as applied to cases of hate speech, Clay Calvert explains how hate speech initializes and perpetuates the subordination of one group over another (Calvert, 1997). Calvert notes that hate speech acts, specifically focusing on the repeated utilization of racial epithets, construct reality in the speaker, audience, and target members of the discourse through the creation and maintenance of mental schemata similar to the functions of other speech acts: 'In particular, racist speech helps to define who minorities are and how others think about minorities, facilitating their unequal treatment' (Calvert, 1997, pp. 12). This construction is harmful in its immediacy to the target as well as in the long-term situation as it perpetuates unequal power structures based on criteria of identity (Calvert, 1997, pp. 15-16). The construction of reality based on hate speech acts is also relevant to a discussion of online environments as the textual communication serves as a large social aspect of both on- and offline environments. Toxicity consists of verbal expressions and behaviors that serve to destabilize groups.  It is unclear whether toxic behavior is directed to elicit particular responses, and hence systemic, or reactionary, emotional, and hence, situational.  Frequently, the term 'troll,' or 'trolling,' is used synonymously with toxicity.  Regardless, these behaviors are necessary to address because they are a key factor in the outright hostility of online gaming environments to those perceived as other.  This destabilization maps on to offline models of gender, race, class, ethnic, national, linguistic, and abelist-based hate speech. A fertile ground for this analysis is in the virtual worlds of online gaming. For example, Kou and Nardi (2013), in their research on League of Legends, found that antisocial behavior destabilizes online communities but is addressable by social code and regulatory systems. The targeted examples in online gaming environments show a concentrated sample of toxic behavior that is pervasive in every online environment.  Studies have documented antisocial behavior and toxic speech in most digital platforms (O'Sullivan & Flanagin, 2003).  Whether considering flaming on 1980s and 90s USENET forums, social media fueled outrage on contemporary politics, or in-game, text-based conversation in multiplayer games, toxicity can be motivated by emotional, intellectual, political, or other causes and as such correlates strongly with the modes and consequences of offline hate speech.  Understanding online toxic behavior in ways that allow for moderation of its causes and effects first requires an understanding of how to study the concrete manifestation of this behavior—the text produced by users of a system.  The challenges faced by this research are many: the writing styles are heavily infused with jargon, the orthography is non-standard, the chat stream only represents one channel of communication, and the communities are fluid. In response to these challenges, an approach grounded in machine learning and NLP was tested.  Using a small subset of the available data, a classifier based upon developed to separate players toxic from non-toxic players yielded a precision of 0.77, a recall of 0.79 and an F-score of 0.78.  These results are encouraging, and along with training on a larger data set, secondary factors such as player avatar gender, length of match, and others were also preliminarily tested and found to have small influencing effects.  These results suggest that there are concrete, detectable semantic and syntactic patterns in the harassment levied at players in these games.  Connecting these findings to mechanisms for shielding, reforming, and censuring players, and to frameworks for understanding the social and psychological costs of being effectively locked in a room with one or more individuals determined to verbally abuse a peer is the more complex task of the cultural and ethnographic studies of digital communities.",,,,,Alliance of Digital Humanities Organizations (ADHO) ,"11th Annual International Conference of the Alliance of Digital Humanities Organizations, DH 2016, Krakow, Poland, July 11-16, 2016, Conference Abstracts ",,,
4448,"452    Title:HalluciDoctor: Mitigating Hallucinatory ...
Name: Abstract, dtype: object","Yu Q,Li J,Wei L,Pang L,Ye W,Qin B,Tang S,Tian Q,Zhuang Y",,,HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data,abs/2311.13614,,10.48550/ARXIV.2311.13614 , Journal Article,2023.0,"Abstract:Multi-modal Large Language Models (MLLMs) tuned on machine-generated instruction-following data have demonstrated remarkable performance in various multi-modal understanding and generation tasks. However, the hallucinations inherent in machine-generated data, which could lead to hallucinatory outputs in MLLMs, remain under-explored. This work aims to investigate various hallucinations (i.e., object, relation, attribute hallucinations) and mitigate those hallucinatory toxicities in large-scale machine-generated visual instruction datasets. Drawing on the human ability to identify factual errors, we present a novel hallucination detection and elimination framework, HalluciDoctor, based on the cross-checking paradigm. We use our framework to identify and eliminate hallucinations in the training data automatically. Interestingly, HalluciDoctor also indicates that spurious correlations arising from long-tail object co-occurrences contribute to hallucinations. Based on that, we execute counterfactual visual instruction expansion to balance data distribution, thereby enhancing MLLMs' resistance to hallucinations. Comprehensive experiments on hallucination evaluation benchmarks show that our method successfully mitigates 44.6% hallucinations relatively and maintains competitive performance compared to LLaVA.The source code will be released at \url{this https URL}.",,,,, CoRR, ,,,
4449,"453    Title:WLV-RIT at GermEval 2021: Multitask Lear...
Name: Abstract, dtype: object","Morgan S,Ranasinghe T,Zampieri M",,,"WLV-RIT at GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments",,, , Conference Paper,2021.0,"Abstract:This paper addresses the identification of toxic, engaging, and fact-claiming comments on social media. We used the dataset made available by the organizers of the GermEval-2021 shared task containing over 3,000 manually annotated Facebook comments in German. Considering the relatedness of the three tasks, we approached the problem using large pre-trained transformer models and multitask learning. Our results indicate that multitask learning achieves performance superior to the more common single task learning approach in all three tasks. We submit our best systems to GermEval-2021 under the team name WLV-RIT.",,,,,Association for Computational Linguistics ,"Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments, GermEval@KONVENS 2021, Düsseldorf, Germany, September 6, 2021 ",,,
4450,"454    Title:Cisco at SemEval-2021 Task 5: What's Tox...
Name: Abstract, dtype: object","Ghosh S,Kumar S",,,Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments,,,10.18653/V1/2021.SEMEVAL-1.29 , Conference Paper,2021.0,"Social network platforms are generally used
to share positive, constructive, and insightful
content. However, in recent times, people of-
ten get exposed to objectionable content like
threat, identity attacks, hate speech, insults, ob-
scene texts, offensive remarks or bullying. Ex-
isting work on toxic speech detection focuses
on binary classiﬁcation or on differentiating
toxic speech among a small set of categories.
This paper describes the system proposed by
team Cisco for SemEval-2021 Task 5: Toxic
Spans Detection, the ﬁrst shared task focusing
on detecting the spans in the text that attribute
to its toxicity, in English language.
We ap-
proach this problem primarily in two ways: a
sequence tagging approach and a dependency
parsing approach. In our sequence tagging ap-
proach we tag each token in a sentence under
a particular tagging scheme. Our best perform-
ing architecture in this approach also proved
to be our best performing architecture over-
all with an F1 score of 0.6922, thereby plac-
ing us 7th on the ﬁnal evaluation phase leader-
board. We also explore a dependency parsing
approach where we extract spans from the in-
put sentence under the supervision of target
span boundaries and rank our spans using a
biafﬁne model. Finally, we also provide a de-
tailed analysis of our results and model perfor-
mance in our paper.",,,,,Association for Computational Linguistics ,"Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021 ",,,
4451,"Title:Intentionally Biasing User Representation?: Investigating the Pros and Cons of Removing Toxic Quotes from Social Media Personas

 Algorithmically generated personas can help organizations understand their social media audiences. However, when using algorithms to create personas from social media user data, the resulting personas may contain toxic quotes that negatively affect content creators’ perceptions of the personas. To address this issue, we have implemented toxicity detection in an algorithmic persona generation system capable of using tens of millions of social media interactions and user comments for persona creation. On the system's user interface, we provide a feature for content creators using the personas to turn on or off toxic quotes, depending on their preferences. To investigate the feasibility of this feature, we conducted a study with 50 professionals in the online publishing domain. The results show varied reactions, including hate-filter critics, hate-filter advocates, and those in between. Although personal preferences play a role, the usefulness of toxicity filtering appears primarily driven by the work task – specifically the type and topic of stories the content creator seeks to create. We identify six use cases where a toxicity filter is beneficial. For system development, the results imply that it is beneficial to give content creators the option to view or not view toxic comments, rather than making this decision in their stead. We also discuss the ethical implications of removing toxic quotes in algorithmically generated personas, including potentially biasing the user representation.","Salminen J,Jung SG,Jansen B",,,Intentionally Biasing User Representation?: Investigating the Pros and Cons of Removing Toxic Quotes from Social Media Personas,,,10.1145/3546155.3546647 , Conference Paper,2022.0,"Algorithmically generated personas can help organizations understand their social media audiences. However, when using algorithms to create personas from social media user data, the resulting personas may contain toxic quotes that negatively affect content creators’ perceptions of the personas. To address this issue, we have implemented toxicity detection in an algorithmic persona generation system capable of using tens of millions of social media interactions and user comments for persona creation. On the system's user interface, we provide a feature for content creators using the personas to turn on or off toxic quotes, depending on their preferences. To investigate the feasibility of this feature, we conducted a study with 50 professionals in the online publishing domain. The results show varied reactions, including hate-filter critics, hate-filter advocates, and those in between. Although personal preferences play a role, the usefulness of toxicity filtering appears primarily driven by the work task – specifically the type and topic of stories the content creator seeks to create. We identify six use cases where a toxicity filter is beneficial. For system development, the results imply that it is beneficial to give content creators the option to view or not view toxic comments, rather than making this decision in their stead. We also discuss the ethical implications of removing toxic quotes in algorithmically generated personas, including potentially biasing the user representation.",,,9781450396998,,Association for Computing Machinery ,Nordic Human-Computer Interaction Conference ,,,
4452,"Title:‘Who Built This Crap?’ Developing a Software Engineering Domain Specific Toxicity Detector

 Since toxicity during developers’ interactions in open source software (OSS) projects show negative impacts on developers’ relation, a toxicity detector for the Software Engineering (SE) domain is needed. However, prior studies found that contemporary toxicity detection tools performed poorly with the SE texts. To address this challenge, I have developed ToxiCR, a SE-specific toxicity detector that is evaluated with manually labeled 19,571 code review comments. I evaluate ToxiCR with different combinations of ten supervised learning models, five text vectorizers, and eight preprocessing techniques (two of them are SE domain-specific). After applying all possible combinations, I have found that ToxiCR significantly outperformed existing toxicity classifiers with accuracy of 95.8% and an F1 score of 88.9%.",Sarker J,,,‘Who Built This Crap?’ Developing a Software Engineering Domain Specific Toxicity Detector,,,10.1145/3551349.3559508 , Conference Paper,2023.0,"Since toxicity during developers’ interactions in open source software (OSS) projects show negative impacts on developers’ relation, a toxicity detector for the Software Engineering (SE) domain is needed. However, prior studies found that contemporary toxicity detection tools performed poorly with the SE texts. To address this challenge, I have developed ToxiCR, a SE-specific toxicity detector that is evaluated with manually labeled 19,571 code review comments. I evaluate ToxiCR with different combinations of ten supervised learning models, five text vectorizers, and eight preprocessing techniques (two of them are SE domain-specific). After applying all possible combinations, I have found that ToxiCR significantly outperformed existing toxicity classifiers with accuracy of 95.8% and an F1 score of 88.9%.",,,9781450394758,,Association for Computing Machinery ,Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering ,"developers interaction, toxicity, deep learning, NLP",,
4453,"Title:Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation

 Machine learning models are commonly used to detect toxicity in online conversations. These models are trained on datasets annotated by human raters. We explore how raters' self-described identities impact how they annotate toxicity in online comments. We first define the concept of Specialized Rater Pools: rater pools formed based on raters' self-described identities, rather than at random. We formed three such rater pools for this study - specialized rater pools of raters from the U.S. who identify as African American, LGBTQ, and those who identify as neither. Each of these rater pools annotated the same set of comments, which contains many references to these identity groups. We found that rater identity is a statistically significant factor in how raters will annotate toxicity for identity-related annotations. Using preliminary content analysis, we examined the comments with the most disagreement between rater pools and found nuanced differences in the toxicity annotations. Next, we trained models on the annotations from each of the different rater pools, and compared the scores of these models on comments from several test sets. Finally, we discuss how using raters that self-identify with the subjects of comments can create more inclusive machine learning models, and provide more nuanced ratings than those by random raters.","Goyal N,Kivlichan ID,Rosen R,Vasserman L",,,Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation,6,CSCW2,10.1145/3555088 , Journal Article,2022.0,"Machine learning models are commonly used to detect toxicity in online conversations. These models are trained on datasets annotated by human raters. We explore how raters' self-described identities impact how they annotate toxicity in online comments. We first define the concept of Specialized Rater Pools: rater pools formed based on raters' self-described identities, rather than at random. We formed three such rater pools for this study - specialized rater pools of raters from the U.S. who identify as African American, LGBTQ, and those who identify as neither. Each of these rater pools annotated the same set of comments, which contains many references to these identity groups. We found that rater identity is a statistically significant factor in how raters will annotate toxicity for identity-related annotations. Using preliminary content analysis, we examined the comments with the most disagreement between rater pools and found nuanced differences in the toxicity annotations. Next, we trained models on the annotations from each of the different rater pools, and compared the scores of these models on comments from several test sets. Finally, we discuss how using raters that self-identify with the subjects of comments can create more inclusive machine learning models, and provide more nuanced ratings than those by random raters.",,,,,Association for Computing Machinery Proc.  ACM Hum. -Comput.  Interact., ,"LGBTQ, moderation, identity, harassment, subjectivity, human annotations, raters, African American, machine learning, toxicity, data annotation",,
4454,"Title:For Honor, for Toxicity: Detecting Toxic Behavior through Gameplay

 Is it possible to detect toxicity in games just by observing in-game behavior? If so, what are the behavioral factors that will help machine learning to discover the unknown relationship between gameplay and toxic behavior? In this initial study, we examine whether it is possible to predict toxicity in the MOBA gameFor Honor by observing in-game behavior for players that have been labeled as toxic (i.e. players that have been sanctioned by Ubisoft community managers). We test our hypothesis of detecting toxicity through gameplay with a dataset of almost 1,800 sanctioned players, and comparing these sanctioned players with unsanctioned players. Sanctioned players are defined by their toxic action type (offensive behavior vs. unfair advantage) and degree of severity (warned vs. banned). Our findings, based on supervised learning with random forests, suggest that it is not only possible to behaviorally distinguish sanctioned from unsanctioned players based on selected features of gameplay; it is also possible to predict both the sanction severity (warned vs. banned) and the sanction type (offensive behavior vs. unfair advantage). In particular, all random forest models predict toxicity, its severity, and type, with an accuracy of at least 82%, on average, on unseen players. This research shows that observing in-game behavior can support the work of community managers in moderating and possibly containing the burden of toxic behavior.","Canossa A,Salimov D,Azadvar A,Harteveld C,Yannakakis G",,,"For Honor, for Toxicity: Detecting Toxic Behavior through Gameplay",5,CHI PLAY,10.1145/3474680 , Journal Article,2021.0,"Is it possible to detect toxicity in games just by observing in-game behavior? If so, what are the behavioral factors that will help machine learning to discover the unknown relationship between gameplay and toxic behavior? In this initial study, we examine whether it is possible to predict toxicity in the MOBA gameFor Honor by observing in-game behavior for players that have been labeled as toxic (i.e. players that have been sanctioned by Ubisoft community managers). We test our hypothesis of detecting toxicity through gameplay with a dataset of almost 1,800 sanctioned players, and comparing these sanctioned players with unsanctioned players. Sanctioned players are defined by their toxic action type (offensive behavior vs. unfair advantage) and degree of severity (warned vs. banned). Our findings, based on supervised learning with random forests, suggest that it is not only possible to behaviorally distinguish sanctioned from unsanctioned players based on selected features of gameplay; it is also possible to predict both the sanction severity (warned vs. banned) and the sanction type (offensive behavior vs. unfair advantage). In particular, all random forest models predict toxicity, its severity, and type, with an accuracy of at least 82%, on average, on unseen players. This research shows that observing in-game behavior can support the work of community managers in moderating and possibly containing the burden of toxic behavior.",,,,,Association for Computing Machinery Proc.  ACM Hum. -Comput.  Interact., ,"machine learning, video games, random forest, labeled dataset, toxicity",,
4455,"Title:Detecting Toxicity Triggers in Online Discussions

 Despite the considerable interest in the detection of toxic comments, there has been little research investigating the causes -- i.e., triggers -- of toxicity. In this work, we first propose a formal definition of triggers of toxicity in online communities. We proceed to build an LSTM neural network model using textual features of comments, and then, based on a comprehensive review of previous literature, we incorporate topical and sentiment shift in interactions as features. Our model achieves an average accuracy of 82.5% of detecting toxicity triggers from diverse Reddit communities.","Almerekhi H,Kwak H,Jansen BJ,Salminen J",,,Detecting Toxicity Triggers in Online Discussions,,,10.1145/3342220.3344933 , Conference Paper,2019.0,"Despite the considerable interest in the detection of toxic comments, there has been little research investigating the causes -- i.e., triggers -- of toxicity. In this work, we first propose a formal definition of triggers of toxicity in online communities. We proceed to build an LSTM neural network model using textual features of comments, and then, based on a comprehensive review of previous literature, we incorporate topical and sentiment shift in interactions as features. Our model achieves an average accuracy of 82.5% of detecting toxicity triggers from diverse Reddit communities.",,,9781450368858,,Association for Computing Machinery ,Proceedings of the 30th ACM Conference on Hypertext and Social Media ,"reddit, neural networks, toxicity, social media, trigger detection",,
4456,"Title:Four Types of Toxic People: Characterizing Online Users’ Toxicity over Time

 Identifying types of online users’ toxic behavior reveals important insights from social media interactions, including whether a user becomes “radicalized” (more toxic) or “pacified” (less toxic) over time. In this research, we design two metrics to identify toxic user types: F score that captures the changes in a user’s toxicity, and G score that captures the direction of the shift taking place in the user’s toxicity pattern. We apply these metrics to a dataset of 4M user comments from Reddit by defining four toxic user types based on the toxicity scores of a user’s comments: (a) Steady Users whose toxicity scores are steady over time, (b) Fickle-Minded Users that switch between toxic and non-toxic commenting, (c) Pacified Users whose commenting becomes less toxic in time, and (d) Radicalized Users that become gradually toxic. Findings from the Reddit dataset indicate that fickle-minded users form the largest group (31.2%), followed by pacified (25.8%), radicalized (25.4%), and steadily toxic users (17.6%). The results suggest that the most typical behavior type of toxicity is switching between toxic and non-toxic commenting. This research has implications for preserving the user-friendliness of online communities by identifying continuously toxic users and users in danger of becoming radicalized (in terms of their toxic behavior), and designing interventions to mitigate these behavior types. Using the metrics we have defined, identifying these user types becomes possible. More research is needed to understand why these patterns take place and how they could be mitigated.","Mall R,Nagpal M,Salminen J,Almerekhi H,Jung SG,Jansen BJ",,,Four Types of Toxic People: Characterizing Online Users’ Toxicity over Time,,,10.1145/3419249.3420142 , Conference Paper,2020.0,"Identifying types of online users’ toxic behavior reveals important insights from social media interactions, including whether a user becomes “radicalized” (more toxic) or “pacified” (less toxic) over time. In this research, we design two metrics to identify toxic user types: F score that captures the changes in a user’s toxicity, and G score that captures the direction of the shift taking place in the user’s toxicity pattern. We apply these metrics to a dataset of 4M user comments from Reddit by defining four toxic user types based on the toxicity scores of a user’s comments: (a) Steady Users whose toxicity scores are steady over time, (b) Fickle-Minded Users that switch between toxic and non-toxic commenting, (c) Pacified Users whose commenting becomes less toxic in time, and (d) Radicalized Users that become gradually toxic. Findings from the Reddit dataset indicate that fickle-minded users form the largest group (31.2%), followed by pacified (25.8%), radicalized (25.4%), and steadily toxic users (17.6%). The results suggest that the most typical behavior type of toxicity is switching between toxic and non-toxic commenting. This research has implications for preserving the user-friendliness of online communities by identifying continuously toxic users and users in danger of becoming radicalized (in terms of their toxic behavior), and designing interventions to mitigate these behavior types. Using the metrics we have defined, identifying these user types becomes possible. More research is needed to understand why these patterns take place and how they could be mitigated.",,,9781450375795,,Association for Computing Machinery ,"Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society ","online toxicity, user analysis, Reddit, social media behavior",,
4457,"Title:Toxicity Predictions Using Compound Descriptions

 Drug-induced liver injury (DILI) is one of the major factors in drug development because it causes failure in clinical trials and withdrawals from market. Though, determining the DILI potentiality is still challenging due to its low occurrences and unexpected contradicts with clinical animal studies.There have been a variety of efforts and experiments on constructing prediction models to identify compounds that cause liver toxicity. However, the discriminant power of the previous models is not confident enough. Also, studies often relies on experimental data for better accuracy which can cause data access limitation and time consuming works. Therefore, some researchers started concerning compound properties and its molecular structures.In this study, we developed a classification model using liver toxicity related compounds as training set. We acquired 192 toxin data and 187 DILI-negative drugs. We obtained toxin data related to liver toxicity from two databases; Hazardous Substances Data Bank (HSDB) [1] , Toxin and Toxin Target Database (T3DB) [2; 4]. For negative set, we used data from three previous studies which include DILI-labels.We used 18 compound properties and molecular structures as features of a classification model. We collected property information using the admetSAR website and the CDK descriptor tool. Moreover, we used the Pybel API provided by Open Babel [3] to retrieve fingerprints as structure information.In classification model construction, two machine learning algorithms, support vector machine (SVM) and random forest, were used with physicochemical properties and structure information as features. The classifiers were developed through 10-fold cross-validation and resulted in accuracy of 73% and 80% in the SVM and the random forest model respectively.","Kim E,Kim S,Ha S,Nam H",,,Toxicity Predictions Using Compound Descriptions,,,10.1145/2811163.2811171 , Conference Paper,2015.0,"Drug-induced liver injury (DILI) is one of the major factors in drug development because it causes failure in clinical trials and withdrawals from market. Though, determining the DILI potentiality is still challenging due to its low occurrences and unexpected contradicts with clinical animal studies.There have been a variety of efforts and experiments on constructing prediction models to identify compounds that cause liver toxicity. However, the discriminant power of the previous models is not confident enough. Also, studies often relies on experimental data for better accuracy which can cause data access limitation and time consuming works. Therefore, some researchers started concerning compound properties and its molecular structures.In this study, we developed a classification model using liver toxicity related compounds as training set. We acquired 192 toxin data and 187 DILI-negative drugs. We obtained toxin data related to liver toxicity from two databases; Hazardous Substances Data Bank (HSDB) [1] , Toxin and Toxin Target Database (T3DB) [2; 4]. For negative set, we used data from three previous studies which include DILI-labels.We used 18 compound properties and molecular structures as features of a classification model. We collected property information using the admetSAR website and the CDK descriptor tool. Moreover, we used the Pybel API provided by Open Babel [3] to retrieve fingerprints as structure information.In classification model construction, two machine learning algorithms, support vector machine (SVM) and random forest, were used with physicochemical properties and structure information as features. The classifiers were developed through 10-fold cross-validation and resulted in accuracy of 73% and 80% in the SVM and the random forest model respectively.",,,9781450337878,,Association for Computing Machinery ,Proceedings of the ACM Ninth International Workshop on Data and Text Mining in Biomedical Informatics ,"machine learning, drug-induced liver injury, toxicity prediction, data mining",,
4458,"Title:Characterizing Toxicity on Facebook Comments in Brazil

 On social media platforms, comments associated with news pieces are usually filled with negativity and toxicity, many times promoting flamed discussions and insults among users. Although designed to encourage conversations and interactions, the high toxicity might end up contributing to create a hostile environment in the online space, which is detrimental to both social media platforms and their users. In this work, we provide a large-scale diagnostic about the toxicity in comments associated with news shared on Facebook. To do that, we collected all posts and comments from relevant pages during a major political event in Brazil, the release of Former President Lula from prison. We then used the Perspective API from Google to measure the toxicity of the comments and posts. Our analysis of the toxicity unveils features that influence toxicity associated with the news, especially in relation to public figures. We hope our findings may affect the design of better content policies able to mitigate the problem.","Guimarães SS,Reis JC,Ribeiro FN,Benevenuto F",,,Characterizing Toxicity on Facebook Comments in Brazil,,,10.1145/3428658.3430974 , Conference Paper,2020.0,"On social media platforms, comments associated with news pieces are usually filled with negativity and toxicity, many times promoting flamed discussions and insults among users. Although designed to encourage conversations and interactions, the high toxicity might end up contributing to create a hostile environment in the online space, which is detrimental to both social media platforms and their users. In this work, we provide a large-scale diagnostic about the toxicity in comments associated with news shared on Facebook. To do that, we collected all posts and comments from relevant pages during a major political event in Brazil, the release of Former President Lula from prison. We then used the Perspective API from Google to measure the toxicity of the comments and posts. Our analysis of the toxicity unveils features that influence toxicity associated with the news, especially in relation to public figures. We hope our findings may affect the design of better content policies able to mitigate the problem.",,,9781450381963,,Association for Computing Machinery ,Proceedings of the Brazilian Symposium on Multimedia and the Web ,"Comments, Social Media, Hate, Facebook",,
4459,"Title:Are These Comments Triggering? Predicting Triggers of Toxicity in Online Discussions

 Understanding the causes or triggers of toxicity adds a new dimension to the prevention of toxic behavior in online discussions. In this research, we define toxicity triggers in online discussions as a non-toxic comment that lead to toxic replies. Then, we build a neural network-based prediction model for toxicity trigger. The prediction model incorporates text-based features and derived features from previous studies that pertain to shifts in sentiment, topic flow, and discussion context. Our findings show that triggers of toxicity contain identifiable features and that incorporating shift features with the discussion context can be detected with a ROC-AUC score of 0.87. We discuss implications for online communities and also possible further analysis of online toxicity and its root causes.","Almerekhi H,Kwak H,Salminen J,Jansen BJ",,,Are These Comments Triggering? Predicting Triggers of Toxicity in Online Discussions,,,10.1145/3366423.3380074 , Conference Paper,2020.0,"Understanding the causes or triggers of toxicity adds a new dimension to the prevention of toxic behavior in online discussions. In this research, we define toxicity triggers in online discussions as a non-toxic comment that lead to toxic replies. Then, we build a neural network-based prediction model for toxicity trigger. The prediction model incorporates text-based features and derived features from previous studies that pertain to shifts in sentiment, topic flow, and discussion context. Our findings show that triggers of toxicity contain identifiable features and that incorporating shift features with the discussion context can be detected with a ROC-AUC score of 0.87. We discuss implications for online communities and also possible further analysis of online toxicity and its root causes.",,,9781450370233,,Association for Computing Machinery ,Proceedings of The Web Conference 2020 ,"neural networks, Reddit, trigger detection, online discussion, toxicity",,
4460,"Title:Contextualizing Toxicity in Open Source: A Qualitative Study

 In this paper, we study toxic online interactions in issue discussions of open-source communities. Our goal is to qualitatively understand how toxicity impacts an open-source community like GitHub. We are driven by users complaining about toxicity, which leads to burnout and disengagement from the site. We collect a substantial sample of toxic interactions and qualitatively analyze their characteristics to ground future discussions and intervention design.",Cohen S,,,Contextualizing Toxicity in Open Source: A Qualitative Study,,,10.1145/3468264.3473492 , Conference Paper,2021.0,"In this paper, we study toxic online interactions in issue discussions of open-source communities. Our goal is to qualitatively understand how toxicity impacts an open-source community like GitHub. We are driven by users complaining about toxicity, which leads to burnout and disengagement from the site. We collect a substantial sample of toxic interactions and qualitatively analyze their characteristics to ground future discussions and intervention design.",,,9781450385626,,Association for Computing Machinery ,Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering ,"classifier, Open source, sentiment analysis, toxicity",,
4461,"Title:Breast Cancer Drug Toxicity Prediction Based on AdaBoost Extremely Random Tree

 Estrogen Receptor α (ERα) is considered as an important target for treating breast cancer, so compounds that can antagonize ERα may be candidate drugs for breast cancer. We predict the toxicities of candidate compounds by machine learning to achieve the virtual screening of breast cancer drugs. In order to improve the performance of the evaluation for toxicities of drugs in virtual screening, a toxicity prediction method that integrates an adaptive boosting extremely random tree algorithm is proposed. We analyze the function of adaptive factors in the algorithm and apply the improved algorithm to predict the toxicity of breast cancer drugs. The experimental results show that the proposed method can accurately predict the toxicities of breast cancer drugs, and increase the efficiency of drug discovery in the early stage based on virtual screening.","Fan Z,Wang S,Li Z,Xie Z",,,Breast Cancer Drug Toxicity Prediction Based on AdaBoost Extremely Random Tree,,,10.1145/3523286.3524506 , Conference Paper,2022.0,"Estrogen Receptor α (ERα) is considered as an important target for treating breast cancer, so compounds that can antagonize ERα may be candidate drugs for breast cancer. We predict the toxicities of candidate compounds by machine learning to achieve the virtual screening of breast cancer drugs. In order to improve the performance of the evaluation for toxicities of drugs in virtual screening, a toxicity prediction method that integrates an adaptive boosting extremely random tree algorithm is proposed. We analyze the function of adaptive factors in the algorithm and apply the improved algorithm to predict the toxicity of breast cancer drugs. The experimental results show that the proposed method can accurately predict the toxicities of breast cancer drugs, and increase the efficiency of drug discovery in the early stage based on virtual screening.",,,9781450395755,,Association for Computing Machinery ,2022 2nd International Conference on Bioinformatics and Intelligent Computing ,"Breast cancer, Virtual screening, Machine learning, Toxicity prediction, Drug design",,
4462,"Title:Investigating Toxicity Across Multiple Reddit Communities, Users, and Moderators

 Online platforms like Reddit enable users to build communities and converse about diverse topics and interests. However, with the increasing number of users that post disturbing comments containing profanity, harassment, and hate speech, otherwise known as toxic comments. Moderators often struggle with managing the safety of discussions in online communities. To address these issues, we need to detect toxic comments and the root causes of toxicity in discussion threads, i.e., toxicity triggers. Additionally, we need to investigate the toxic posting behavior of users to understand how it differs across online communities and consolidate our findings with moderators from Reddit. In this work, we present our approach, which builds on state-of-the-art methods of toxic comment and toxicity trigger detection. Lastly, we present our research findings of investigating toxicity across users and moderators on Reddit.","Almerekhi H,Jansen Sby,Kwak CS",,,"Investigating Toxicity Across Multiple Reddit Communities, Users, and Moderators",,,10.1145/3366424.3382091 , Conference Paper,2020.0,"Online platforms like Reddit enable users to build communities and converse about diverse topics and interests. However, with the increasing number of users that post disturbing comments containing profanity, harassment, and hate speech, otherwise known as toxic comments. Moderators often struggle with managing the safety of discussions in online communities. To address these issues, we need to detect toxic comments and the root causes of toxicity in discussion threads, i.e., toxicity triggers. Additionally, we need to investigate the toxic posting behavior of users to understand how it differs across online communities and consolidate our findings with moderators from Reddit. In this work, we present our approach, which builds on state-of-the-art methods of toxic comment and toxicity trigger detection. Lastly, we present our research findings of investigating toxicity across users and moderators on Reddit.",,,9781450370240,,Association for Computing Machinery ,Companion Proceedings of the Web Conference 2020 ,"online communities, toxicity, trigger detection, Reddit, discussion threads",,
4463,"Title:Don’t You Know That You’re Toxic: Normalization of Toxicity in Online Gaming

 Video game toxicity, endemic to online play, represents a pervasive and complex problem. Antisocial behaviours in online play directly harm player wellbeing, enjoyment, and retention—but research has also revealed that some players normalize toxicity as an inextricable and acceptable element of the competitive video game experience. In this work, we explore perceptions of toxicity and how they are predicted by player traits, demonstrating that participants reporting a higher tendency towards Conduct Reconstrual, Distorting Consequences, Dehumanization, and Toxic Online Disinhibition perceive online game interactions as less toxic. Through a thematic analysis on willingness to report, we also demonstrate that players abstain from reporting toxic content because they view it as acceptable, typical of games, as banter, or as not their concern. We propose that these traits and themes represent contributing factors to the cyclical normalization of toxicity. These findings further highlight the multifaceted nature of toxicity in online video games.","Beres NA,Frommel J,Reid E,Mandryk RL,Klarkowski M",,,Don’t You Know That You’re Toxic: Normalization of Toxicity in Online Gaming,,,10.1145/3411764.3445157 , Conference Paper,2021.0,"Video game toxicity, endemic to online play, represents a pervasive and complex problem. Antisocial behaviours in online play directly harm player wellbeing, enjoyment, and retention—but research has also revealed that some players normalize toxicity as an inextricable and acceptable element of the competitive video game experience. In this work, we explore perceptions of toxicity and how they are predicted by player traits, demonstrating that participants reporting a higher tendency towards Conduct Reconstrual, Distorting Consequences, Dehumanization, and Toxic Online Disinhibition perceive online game interactions as less toxic. Through a thematic analysis on willingness to report, we also demonstrate that players abstain from reporting toxic content because they view it as acceptable, typical of games, as banter, or as not their concern. We propose that these traits and themes represent contributing factors to the cyclical normalization of toxicity. These findings further highlight the multifaceted nature of toxicity in online video games.",,,9781450380966,,Association for Computing Machinery ,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ,"toxicity, normalization, moral disengagement, games, toxic",,
4464,"Title:Exploring Antecedents and Consequences of Toxicity in Online Discussions: A Case Study on Reddit

 Toxicity in online discussions has been an intriguing phenomenon and an important problem. In this paper, we seek to better understand toxicity dynamics in online discussions via a case study on Reddit that explores the antecedents and consequences of toxicity in text. We inspected two dimensions of toxicity: language toxicity, i.e. how toxic the text itself is; and toxicity elicitation, i.e. how much toxicity it elicits in its response. Through regression analyses on Reddit comments, we found that both author propensity and toxicity in discussion context were strong positive antecedents of language toxicity; meanwhile, language toxicity significantly increased the volume and user evaluation of the discussion in some sub-communities, while toxicity elicitation showed mixed effects. We then discuss how our results help understand and regulate toxicity in online discussions by interpreting the complicated triggers and outcomes of toxicity.","Xia Y,Zhu H,Lu T,Zhang P,Gu N",,,Exploring Antecedents and Consequences of Toxicity in Online Discussions: A Case Study on Reddit,4,CSCW2,10.1145/3415179 , Journal Article,2020.0,"Toxicity in online discussions has been an intriguing phenomenon and an important problem. In this paper, we seek to better understand toxicity dynamics in online discussions via a case study on Reddit that explores the antecedents and consequences of toxicity in text. We inspected two dimensions of toxicity: language toxicity, i.e. how toxic the text itself is; and toxicity elicitation, i.e. how much toxicity it elicits in its response. Through regression analyses on Reddit comments, we found that both author propensity and toxicity in discussion context were strong positive antecedents of language toxicity; meanwhile, language toxicity significantly increased the volume and user evaluation of the discussion in some sub-communities, while toxicity elicitation showed mixed effects. We then discuss how our results help understand and regulate toxicity in online discussions by interpreting the complicated triggers and outcomes of toxicity.",,,,,Association for Computing Machinery Proc.  ACM Hum. -Comput.  Interact., ,"reddit, quantitative analysis, toxicity, online discussions",,
4465,"Title:Exploring the Relationship Between Game Content and Culture-Based Toxicity: A Case Study of League of Legends and MENA Players

 We examine culture- and racial-based toxicity and hate speech in player communities and explore how this toxicity might be informed and affected by the design of the game elements and content. To illustrate these effects, we used a mixed method approach to analyze the experiences of players from the Middle East and North Africa (MENA) regions within the League of Legends (LoL) community as a case study. By qualitatively and quantitatively analyzing more than 2 million lines of in-game chats from 30,000 game sessions on 2 LoL servers and also 89 forum discussions containing hundreds of lines of text, we find that despite the world and characters of LoL being fictional, they are recognized by the player base as having connections to the real-world cultures and, accordingly, they affect the way that players communicate. We provide specific examples of both negative and positive inspirations to elaborate on how the design of certain regions and characters affects the way that the MENA players and issues are received or addressed. Additional analysis of in-game chat data describes other topics where toxic behavior emerges and how these topics correlate.","Sengün S,Salminen J,Mawhorter P,Jung SG,Jansen B",,,Exploring the Relationship Between Game Content and Culture-Based Toxicity: A Case Study of League of Legends and MENA Players,,,10.1145/3342220.3343652 , Conference Paper,2019.0,"We examine culture- and racial-based toxicity and hate speech in player communities and explore how this toxicity might be informed and affected by the design of the game elements and content. To illustrate these effects, we used a mixed method approach to analyze the experiences of players from the Middle East and North Africa (MENA) regions within the League of Legends (LoL) community as a case study. By qualitatively and quantitatively analyzing more than 2 million lines of in-game chats from 30,000 game sessions on 2 LoL servers and also 89 forum discussions containing hundreds of lines of text, we find that despite the world and characters of LoL being fictional, they are recognized by the player base as having connections to the real-world cultures and, accordingly, they affect the way that players communicate. We provide specific examples of both negative and positive inspirations to elaborate on how the design of certain regions and characters affects the way that the MENA players and issues are received or addressed. Additional analysis of in-game chat data describes other topics where toxic behavior emerges and how these topics correlate.",,,9781450368858,,Association for Computing Machinery ,Proceedings of the 30th ACM Conference on Hypertext and Social Media ,"middle east, gaming culture, online toxicity, league of legends",,
4466,"Title:A First Look at Toxicity Injection Attacks on Open-Domain Chatbots

 Chatbot systems have improved significantly because of the advances made in language modeling. These machine learning systems follow an end-to-end data-driven learning paradigm and are trained on large conversational datasets. Imperfections or harmful biases in the training datasets can cause the models to learn toxic behavior, and thereby expose their users to harmful responses. Prior work has focused on measuring the inherent toxicity of such chatbots, by devising queries that are more likely to produce toxic responses. In this work, we ask the question: How easy or hard is it to inject toxicity into a chatbot after deployment? We study this in a practical scenario known as Dialog-based Learning (DBL), where a chatbot is periodically trained on recent conversations with its users after deployment. A DBL setting can be exploited to poison the training dataset for each training cycle. Our attacks would allow an adversary to manipulate the degree of toxicity in a model and also enable control over what type of queries can trigger a toxic response. Our fully automated attacks only require LLM-based software agents masquerading as (malicious) users to inject high levels of toxicity. We systematically explore the vulnerability of popular chatbot pipelines to this threat. Lastly, we show that several existing toxicity mitigation strategies (designed for chatbots) can be significantly weakened by adaptive attackers.","Weeks C,Cheruvu A,Abdullah SM,Kanchi S,Yao D,Viswanath B",,,A First Look at Toxicity Injection Attacks on Open-Domain Chatbots,,,10.1145/3627106.3627122 , Conference Paper,2023.0,"Chatbot systems have improved significantly because of the advances made in language modeling. These machine learning systems follow an end-to-end data-driven learning paradigm and are trained on large conversational datasets. Imperfections or harmful biases in the training datasets can cause the models to learn toxic behavior, and thereby expose their users to harmful responses. Prior work has focused on measuring the inherent toxicity of such chatbots, by devising queries that are more likely to produce toxic responses. In this work, we ask the question: How easy or hard is it to inject toxicity into a chatbot after deployment? We study this in a practical scenario known as Dialog-based Learning (DBL), where a chatbot is periodically trained on recent conversations with its users after deployment. A DBL setting can be exploited to poison the training dataset for each training cycle. Our attacks would allow an adversary to manipulate the degree of toxicity in a model and also enable control over what type of queries can trigger a toxic response. Our fully automated attacks only require LLM-based software agents masquerading as (malicious) users to inject high levels of toxicity. We systematically explore the vulnerability of popular chatbot pipelines to this threat. Lastly, we show that several existing toxicity mitigation strategies (designed for chatbots) can be significantly weakened by adaptive attackers.",,,,,Association for Computing Machinery ,Proceedings of the 39th Annual Computer Security Applications Conference ,"adversarial inputs, data poisoning, toxicity injection and detection, Chatbots",,
4467,"Title:Review on Marine Biotoxins Toxicity and Detection Methods

 Consumption of seafood contaminated by marine toxins will result in various poisoning syndromes. Marine biotoxins are toxic chemicals mainly derived from harmful algal blooms. Particular attention is paid to components analysis, detection methods and therapeutical treatment. Marine biotoxins are classified into various types based on the chemical structure, isolated sources and mechanisms of toxicity. In order to protect the public safety and health, there have been more and more researches on the detection of marine biotoxins. At present, the detection methods of marine biological toxins include biological detection methods, physical and chemical detection methods, and integrated detection methods. This article will review the research progresses and characteristics of marine biotoxin detection technology.",Jiang B,,,Review on Marine Biotoxins Toxicity and Detection Methods,,,10.1145/3397391.3397392 , Conference Paper,2020.0,"Consumption of seafood contaminated by marine toxins will result in various poisoning syndromes. Marine biotoxins are toxic chemicals mainly derived from harmful algal blooms. Particular attention is paid to components analysis, detection methods and therapeutical treatment. Marine biotoxins are classified into various types based on the chemical structure, isolated sources and mechanisms of toxicity. In order to protect the public safety and health, there have been more and more researches on the detection of marine biotoxins. At present, the detection methods of marine biological toxins include biological detection methods, physical and chemical detection methods, and integrated detection methods. This article will review the research progresses and characteristics of marine biotoxin detection technology.",,,9781450377249,,Association for Computing Machinery ,Proceedings of the 2020 10th International Conference on Biomedical Engineering and Technology ,"Detection technology, Marine biotoxins, Seafood poisoning, Toxicity",,
4468,"Title:Prediction of Toxicity and Pharmacological Potential of Selected Spice Compounds

 The use of computational tools in the prediction of ADME/Tox properties of compounds is growing rapidly in drug discovery as the benefits they provide in high throughput and early application in drug design are realized. Numerous examples exist of drugs that have had to be withdrawn, because of unacceptable toxicity, in clinical trials and even after reaching the market. In this study phytochemicals from selected spices were used to predict their rodent carcinogenicity, mutagenicity, PPB and BBB. Out of 108 compounds analysed, we found that only five compounds as non-mutagenic and non-carcinogenic and all the remaining were toxic in a pharmacological perspective. The five non-toxic compounds are alpha-zingiberene, delphinidin, laurotetanine, malabaricone-B and malabaricone-C. The PPB values of alpha-zingiberene, delphinidin and laurotetanine are in the <90% range (57.58, 88.41, 52.59, respectively) indicating that the three compounds were weakly bound to plasma proteins and the other two (malabaricone-B and malabaricone-C) strongly binds to plasma protein. The identification of delphinidin as a naturally occurring inhibitor of VEGF (vascular endothelial growth factor) receptors suggests that this molecule possesses important antiangiogenic properties that may be helpful for the prevention and treatment of cancer. The healing activity of malabaricone B and malabaricone C, the major antioxidant constituents of Myristaceae family, against indomethacin-induced gastric ulceration in mice has been studied. Though spices are well known for their antioxidant, antimicrobial, antinflammatory properties etc., this study clearly indicates the plethora of carcinogenic behaviour of spice compounds.","Riju A,Sithara K,Nair SS,Eapen SJ",,,Prediction of Toxicity and Pharmacological Potential of Selected Spice Compounds,,,10.1145/1722024.1722060 , Conference Paper,2010.0,"The use of computational tools in the prediction of ADME/Tox properties of compounds is growing rapidly in drug discovery as the benefits they provide in high throughput and early application in drug design are realized. Numerous examples exist of drugs that have had to be withdrawn, because of unacceptable toxicity, in clinical trials and even after reaching the market. In this study phytochemicals from selected spices were used to predict their rodent carcinogenicity, mutagenicity, PPB and BBB. Out of 108 compounds analysed, we found that only five compounds as non-mutagenic and non-carcinogenic and all the remaining were toxic in a pharmacological perspective. The five non-toxic compounds are alpha-zingiberene, delphinidin, laurotetanine, malabaricone-B and malabaricone-C. The PPB values of alpha-zingiberene, delphinidin and laurotetanine are in the <90% range (57.58, 88.41, 52.59, respectively) indicating that the three compounds were weakly bound to plasma proteins and the other two (malabaricone-B and malabaricone-C) strongly binds to plasma protein. The identification of delphinidin as a naturally occurring inhibitor of VEGF (vascular endothelial growth factor) receptors suggests that this molecule possesses important antiangiogenic properties that may be helpful for the prevention and treatment of cancer. The healing activity of malabaricone B and malabaricone C, the major antioxidant constituents of Myristaceae family, against indomethacin-induced gastric ulceration in mice has been studied. Though spices are well known for their antioxidant, antimicrobial, antinflammatory properties etc., this study clearly indicates the plethora of carcinogenic behaviour of spice compounds.",,,9781605587226,,Association for Computing Machinery ,Proceedings of the International Symposium on Biocomputing ,"phytochemicals, rodent carcinogenicity, mutagenicity, ADME/T prediction, plasma-protein binding and blood-brain barrier penetration",,
4469,"Title:Data-Driven Modeling and Prediction of Acute Toxicity of Pesticide Residues

 This paper outlines and implements a concept for developing alternative tools for toxicity modeling and prediction of chemical compounds to be used for evaluation and authorization purposes of public regulatory bodies to help minimizing animal tests, costs, and time associated with registration and risk assessment processes. Starting from a general problem description we address and introduce concepts of multileveled self-organization for high-dimensional modeling, model validation, model combining, and decision support within the frame of a knowledge discovery from noisy data.","Lemke F,Benfenati E,Müller JA",,,Data-Driven Modeling and Prediction of Acute Toxicity of Pesticide Residues,8,1,10.1145/1147234.1147245 , Journal Article,2006.0,"This paper outlines and implements a concept for developing alternative tools for toxicity modeling and prediction of chemical compounds to be used for evaluation and authorization purposes of public regulatory bodies to help minimizing animal tests, costs, and time associated with registration and risk assessment processes. Starting from a general problem description we address and introduce concepts of multileveled self-organization for high-dimensional modeling, model validation, model combining, and decision support within the frame of a knowledge discovery from noisy data.",1931-0145,,,,Association for Computing Machinery SIGKDD Explor. Newsl., ,"self-organizing modeling, european chemicals policy, DEMETRA, model validation, knowledge discovery workflow, predictive QSAR models, pesticide toxicity",,
4470,"Title:The Cycle of Toxicity: Exploring Relationships between Personality and Player Roles in Toxic Behavior in Multiplayer Online Battle Arena Games

 Toxic behavior remains a salient challenge for online gaming environments, such as multiplayer online battle arena video games (MOBAs). In this study, we sought to understand player roles and settings in which toxicity occurs using a mixed-methods approach. First, we conducted ethnographic observations and interviews with players of the most popular contemporary MOBA, League of Legends (Study 1). During the qualitative analysis three main themes emerged: (1) the fluidity of roles, (2) the subjectivity of the toxic experience, and (3) cascading effects and changing modalities of toxicity. Based on the themes, we formulated hypotheses regarding players’ experience with toxicity. To test these hypotheses, we gathered cross-sectional data from MOBA players (n = 216), which we analyzed with co-variance-based statistics (Study 2). Our quantitative findings showcase the complexity of toxicity as well as players’ ambivalence toward the topic. We found indicators of substantial influences of personality and a cycle of retaliation toxicity spread as victims retaliated against the perpetrator.","Kordyaka B,Laato S,Jahn K,Hamari J,Niehaves B",,,The Cycle of Toxicity: Exploring Relationships between Personality and Player Roles in Toxic Behavior in Multiplayer Online Battle Arena Games,7,CHI PLAY,10.1145/3611043 , Journal Article,2023.0,"Toxic behavior remains a salient challenge for online gaming environments, such as multiplayer online battle arena video games (MOBAs). In this study, we sought to understand player roles and settings in which toxicity occurs using a mixed-methods approach. First, we conducted ethnographic observations and interviews with players of the most popular contemporary MOBA, League of Legends (Study 1). During the qualitative analysis three main themes emerged: (1) the fluidity of roles, (2) the subjectivity of the toxic experience, and (3) cascading effects and changing modalities of toxicity. Based on the themes, we formulated hypotheses regarding players’ experience with toxicity. To test these hypotheses, we gathered cross-sectional data from MOBA players (n = 216), which we analyzed with co-variance-based statistics (Study 2). Our quantitative findings showcase the complexity of toxicity as well as players’ ambivalence toward the topic. We found indicators of substantial influences of personality and a cycle of retaliation toxicity spread as victims retaliated against the perpetrator.",,,,,Association for Computing Machinery Proc.  ACM Hum. -Comput.  Interact., ,"multiplayer online battle arena games, roles of toxicity, Big Five, toxic behavior, League of Legends",,
4471,"Title:Gene Regulatory Network Based Toxicity Classification and Prediction: A DILI Case Study

 Drug development is a complex process that requires a rigorous safety assessment. The risk assessment on liver, which plays a central role in drug metabolism in the body, can have a huge impact on drug development. Drug induced liver injury (DILI) has a detrimental impact on human health and remains a leading cause for drug attrition [1]. Toxicogenomics (TGx) has enhanced drug testing and safety prediction, by providing valuable mechanistic insights [2]. Since there are several mechanisms that result in the toxicity endpoint of DILI, the gene expression profiles are diverse, which presents challenges when building TGx signatures for DILI. Thus, compounds with similar characteristics must be used to form a strong expression profile. In this case study, we propose an innovative approach, where each compound's primary and secondary targets and their gene regulatory network (GRN) information is used to inform similar DILI mechanisms. We built a computational pipeline to define each compound's GRN profile and group compounds with similar profiles. This matrix of compounds' GRNs was then transformed using various data transformation and dimension reduction methods. Then, the compounds were clustered into groups based on similarities in their GRN. A DILI predictive machine learning model was built from these groups to identify signature genes and predict DILI from gene expression data. Fitting such models by cluster analysis resulted in a higher accuracy, sensitivity and specificity in compound predictions compared to fitting one model with all compounds. Furthermore, gene set enrichment analysis was performed to identify notable genes in the prediction process to build strong gene signatures for liver toxicity.","Hirway SU,Tekle F,De Marchin T,Irrechukwu O,Van Goethem F,Yao X",,,Gene Regulatory Network Based Toxicity Classification and Prediction: A DILI Case Study,,,10.1145/3584371.3613041 , Conference Paper,2023.0,"Drug development is a complex process that requires a rigorous safety assessment. The risk assessment on liver, which plays a central role in drug metabolism in the body, can have a huge impact on drug development. Drug induced liver injury (DILI) has a detrimental impact on human health and remains a leading cause for drug attrition [1]. Toxicogenomics (TGx) has enhanced drug testing and safety prediction, by providing valuable mechanistic insights [2]. Since there are several mechanisms that result in the toxicity endpoint of DILI, the gene expression profiles are diverse, which presents challenges when building TGx signatures for DILI. Thus, compounds with similar characteristics must be used to form a strong expression profile. In this case study, we propose an innovative approach, where each compound's primary and secondary targets and their gene regulatory network (GRN) information is used to inform similar DILI mechanisms. We built a computational pipeline to define each compound's GRN profile and group compounds with similar profiles. This matrix of compounds' GRNs was then transformed using various data transformation and dimension reduction methods. Then, the compounds were clustered into groups based on similarities in their GRN. A DILI predictive machine learning model was built from these groups to identify signature genes and predict DILI from gene expression data. Fitting such models by cluster analysis resulted in a higher accuracy, sensitivity and specificity in compound predictions compared to fitting one model with all compounds. Furthermore, gene set enrichment analysis was performed to identify notable genes in the prediction process to build strong gene signatures for liver toxicity.",,,,,Association for Computing Machinery ,"Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics ","drug induced liver injury, machine learning, toxicogenomics, gene regulatory network",,
4472,"Title:Feeling Good and In Control: In-Game Tools to Support Targets of Toxicity

 Game developers, researchers, and players recognize the harm of toxic behaviour in online games-yet toxicity persists. Players' coping strategies are limited to tools that focus on punishing toxic players (e.g., muting, blocking, reporting), which are inadequate and often misused. To address the needs of players experiencing toxicity, we took inspiration from research in other online spaces that provide support tools for targets of harassment. We iteratively designed and evaluated in-game tools to support targets of toxicity. While we found that most players prefer tools that explicitly address toxicity and increase feelings of control, we also found that tools that solely provide social or emotional support also decrease stress, increase feelings of control, and increase positive affect. Our findings suggest that players may benefit from variety in toxicity support tools that both explicitly address toxicity in the moment and help players cope after it has occurred.","Reid E,Mandryk RL,Beres NA,Klarkowski M,Frommel J",,,Feeling Good and In Control: In-Game Tools to Support Targets of Toxicity,6,CHI PLAY,10.1145/3549498 , Journal Article,2022.0,"Game developers, researchers, and players recognize the harm of toxic behaviour in online games-yet toxicity persists. Players' coping strategies are limited to tools that focus on punishing toxic players (e.g., muting, blocking, reporting), which are inadequate and often misused. To address the needs of players experiencing toxicity, we took inspiration from research in other online spaces that provide support tools for targets of harassment. We iteratively designed and evaluated in-game tools to support targets of toxicity. While we found that most players prefer tools that explicitly address toxicity and increase feelings of control, we also found that tools that solely provide social or emotional support also decrease stress, increase feelings of control, and increase positive affect. Our findings suggest that players may benefit from variety in toxicity support tools that both explicitly address toxicity in the moment and help players cope after it has occurred.",,,,,Association for Computing Machinery Proc.  ACM Hum. -Comput.  Interact., ,"griefing, toxicity, games, control, toxic, support, report, mood, harassment",,
4473,"Title:Combating Toxicity, Harassment, and Abuse in Online Social Spaces: A Workshop at CHI 2023

 Online social spaces provide much needed connection and belonging—particularly in a context of continued lack of global mobility due to the ongoing Covid-19 pandemic and climate crisis. However, the norms of online social spaces can create environments in which toxic behaviour is normalized, tolerated or even celebrated. This can occur without consequence, leaving its members vulnerable to hate, harassment, and abuse. A vast majority of adults have experienced toxicity online and the harm is even more prevalent for members of marginalized and minoritized groups, who are more often the targets of online abuse. Although there is significant work on toxicity in the SIGCHI community, approaches and knowledge have typically been siloed by the domain of investigation (e.g., social media, multiplayer games, social VR). We argue that cross-disciplinary efforts will benefit not only the various communities and situations in which abuse occurs, but that bringing together researchers from different backgrounds and specialties will provide a robust and rich understanding of how to tackle online toxicity at scale.","Mandryk RL,Frommel J,Goyal N,Freeman G,Lampe C,Vieweg S,Wohn DY",,,"Combating Toxicity, Harassment, and Abuse in Online Social Spaces: A Workshop at CHI 2023",,,10.1145/3544549.3573793 , Conference Paper,2023.0,"Online social spaces provide much needed connection and belonging—particularly in a context of continued lack of global mobility due to the ongoing Covid-19 pandemic and climate crisis. However, the norms of online social spaces can create environments in which toxic behaviour is normalized, tolerated or even celebrated. This can occur without consequence, leaving its members vulnerable to hate, harassment, and abuse. A vast majority of adults have experienced toxicity online and the harm is even more prevalent for members of marginalized and minoritized groups, who are more often the targets of online abuse. Although there is significant work on toxicity in the SIGCHI community, approaches and knowledge have typically been siloed by the domain of investigation (e.g., social media, multiplayer games, social VR). We argue that cross-disciplinary efforts will benefit not only the various communities and situations in which abuse occurs, but that bringing together researchers from different backgrounds and specialties will provide a robust and rich understanding of how to tackle online toxicity at scale.",,,9781450394222,,Association for Computing Machinery ,Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ,"harassment, multiplayer games, hate speech, metaverse, flaming, griefing, doxxing, abuse, toxicity, social VR, trolling, social media",,
4474,"Title:AI Principles in Identifying Toxicity in Online Conversation: Keynote at the Third Workshop on Fairness, Accountability, Transparency, Ethics and Society on the Web

 Jigsaw’s Perspective API aims to protect voices in online conversation by developing and serving machine learning models that identify toxicity text. This talk will share how the team behind Perspective thinks about the issues of Fairness, Accountability, Transparency, Ethics and Society through the lens of Google’s AI Principles. For the Perspective team, building technology that is fair and ethical is a continuous, ongoing effort. The talk will cover concrete strategies the Perspective team has already used to mitigate bias in ML models as well as new strategies currently being explored. Finally, with examples of how Perspective is being used in the real world, the talk will show how machine learning, combined with thoughtful human moderation and participation, can help improve online conversations.",Vassermann L,,,"AI Principles in Identifying Toxicity in Online Conversation: Keynote at the Third Workshop on Fairness, Accountability, Transparency, Ethics and Society on the Web",,,10.1145/3442442.3452307 , Conference Paper,2021.0,"Jigsaw’s Perspective API aims to protect voices in online conversation by developing and serving machine learning models that identify toxicity text. This talk will share how the team behind Perspective thinks about the issues of Fairness, Accountability, Transparency, Ethics and Society through the lens of Google’s AI Principles. For the Perspective team, building technology that is fair and ethical is a continuous, ongoing effort. The talk will cover concrete strategies the Perspective team has already used to mitigate bias in ML models as well as new strategies currently being explored. Finally, with examples of how Perspective is being used in the real world, the talk will show how machine learning, combined with thoughtful human moderation and participation, can help improve online conversations.",,,9781450383134,,Association for Computing Machinery ,Companion Proceedings of the Web Conference 2021 ,"online conversation, AI Principles, toxicity, fairness",,
4475,"Title:Challenges to Combating Toxicity and Harassment in Multiplayer Games: Involving the HCI Games Research Community

 Toxicity is and remains a problem in multiplayer games, and can result in harm for players and game environments. Grounded in prior work, we present four challenges that impede solving the problem of toxicity and harassment. We believe that we need to overcome these challenges to ensure safe gaming spaces, and intend to stimulate discussion about how HCI Games research can make substantial contributions toward this goal.","Frommel J,Mandryk RL,Klarkowski M",,,Challenges to Combating Toxicity and Harassment in Multiplayer Games: Involving the HCI Games Research Community,,,10.1145/3505270.3558359 , Conference Paper,2022.0,"Toxicity is and remains a problem in multiplayer games, and can result in harm for players and game environments. Grounded in prior work, we present four challenges that impede solving the problem of toxicity and harassment. We believe that we need to overcome these challenges to ensure safe gaming spaces, and intend to stimulate discussion about how HCI Games research can make substantial contributions toward this goal.",,,9781450392112,,Association for Computing Machinery ,Extended Abstracts of the 2022 Annual Symposium on Computer-Human Interaction in Play ,"prediction, griefing, toxic, hate, classification, support, games, harassment, toxicity",,
4476,"Title:Analyzing Polarization And Toxicity On Political Debate In Brazilian TikTok Videos Transcriptions

 With the rise of TikTok’s popularity, there is an opportunity to understand how political communication has been made on this platform based on short videos. In addition to understanding what topics and themes are discussed on TikTok, we also analyzed the polarization and toxic behavior of its users. However, this great opportunity brings a challenge as well. As TikTok is a video platform, the largest content information is in the video itself, so it is necessary to extract this information from video data and features. In this paper, we propose a methodology to extract topics from TikTok video transcriptions in order to identify polarization and toxicity in their contents, by using techniques that range from web crawling to speech recognition algorithms. By providing a robust audio cleaning pipeline, it’s possible to generate a less noisy dataset, by removing silence and music segments. We validate our methodology by practically applying it to create topics in order to identify signs of political polarization and toxicity in 8,329 Brazilian political TikTok videos, collected over the last two years. Our work shows that it is possible to extract coherent and meaningful topics from TikTok videos, even with the challenges spoken texts bring. We point out that topics related to religion and social classes contain a higher percentage of toxicity and polarization, as well as opposite hashtags, such as direita (Right-wing) and esquerda (Left-wing).","Vasconcellos PH,Lara PD,Marques-Neto HT",,,Analyzing Polarization And Toxicity On Political Debate In Brazilian TikTok Videos Transcriptions,,,10.1145/3578503.3583613 , Conference Paper,2023.0,"With the rise of TikTok’s popularity, there is an opportunity to understand how political communication has been made on this platform based on short videos. In addition to understanding what topics and themes are discussed on TikTok, we also analyzed the polarization and toxic behavior of its users. However, this great opportunity brings a challenge as well. As TikTok is a video platform, the largest content information is in the video itself, so it is necessary to extract this information from video data and features. In this paper, we propose a methodology to extract topics from TikTok video transcriptions in order to identify polarization and toxicity in their contents, by using techniques that range from web crawling to speech recognition algorithms. By providing a robust audio cleaning pipeline, it’s possible to generate a less noisy dataset, by removing silence and music segments. We validate our methodology by practically applying it to create topics in order to identify signs of political polarization and toxicity in 8,329 Brazilian political TikTok videos, collected over the last two years. Our work shows that it is possible to extract coherent and meaningful topics from TikTok videos, even with the challenges spoken texts bring. We point out that topics related to religion and social classes contain a higher percentage of toxicity and polarization, as well as opposite hashtags, such as direita (Right-wing) and esquerda (Left-wing).",,,,,Association for Computing Machinery ,Proceedings of the 15th ACM Web Science Conference 2023 ,"Political Polarization, Online Social Networks, Text Analysis, Topic Modeling, Political Toxicity, TikTok",,
4477,"Title:Factors Affecting the Expectation of Casualties in the Virtual Range Toxicity Model

 The Virtual Range (VR) is an environment that integrates in a seamless fashion several models to improve complex systems visualization. A complex system is a non-linear system of systems whose interactions bring together interesting emergent properties that are very difficult to visualize and/or study by using the traditional approach of decomposition. The VR Toxicity Model as described here represents the different systems that interact in the determination of the expectation of casualties (Ec) resulting from the toxic effects of the gas dispersion that occurs after a disaster affecting a Space Shuttle within 120 seconds of liftoff. We present a detailed description of the VR and the factors affecting Ec. The system will help local authorities to estimate the population at risk in order to plan for areas to evacuate and/or for the resources required to provide aid and comfort and mitigate damages in case of a disaster.","Sepúlveda J,Rabelo L,Park J,Gruber F,Martínez O",,,Factors Affecting the Expectation of Casualties in the Virtual Range Toxicity Model,,, , Conference Paper,2004.0,The Virtual Range (VR) is an environment that integrates in a seamless fashion several models to improve complex systems visualization. A complex system is a non-linear system of systems whose interactions bring together interesting emergent properties that are very difficult to visualize and/or study by using the traditional approach of decomposition. The VR Toxicity Model as described here represents the different systems that interact in the determination of the expectation of casualties (Ec) resulting from the toxic effects of the gas dispersion that occurs after a disaster affecting a Space Shuttle within 120 seconds of liftoff. We present a detailed description of the VR and the factors affecting Ec. The system will help local authorities to estimate the population at risk in order to plan for areas to evacuate and/or for the resources required to provide aid and comfort and mitigate damages in case of a disaster.,,,9780780387867,,Winter Simulation Conference ,Proceedings of the 36th Conference on Winter Simulation ,,,
4478,"Title:A Human-Centered Evaluation of a Toxicity Detection API: Testing Transferability and Unpacking Latent Attributes

 Perspective is a publicly available, machine learning API that can score text for toxicity. It is available for use in online platforms and communities to limit toxicity and promote civil dialogue. In this work, we adopt a human-centered approach to evaluating Perspective by investigating if human ratings of toxicity align with Perspective’s toxicity scores. We also test its transferability by making this comparison for comments from three platforms that have different commenting styles and moderation strategies: news websites, YouTube, and Twitter. Apart from toxicity, the main attribute, we collect participant ratings for three additional attributes: respectfulness, formality, and presence of stereotypes. While disrespect is part of how Perspective defines toxicity, formality and presence of stereotypes were included in the study to explore if they could be hidden/latent attributes that affect toxicity scores from Perspective. We analyzed how participant ratings for these additional attributes vary with respect to Perspective’s toxicity score for comments from each platform. We find that for high toxicity scores, Perspective strongly aligns with participant ratings of toxicity and disrespectfulness across all three platforms, providing weak evidence of its transferability. However, our evaluation also surfaced formality and presence of stereotypes as latent attributes that are unrecognized parts of Perspective’s scores. We discuss how and why this evaluation is “human-centered,” the importance of conducting such evaluations, and implications of these results for content moderation in social platforms.","Muralikumar MD,Yang YS,McDonald DW",,,A Human-Centered Evaluation of a Toxicity Detection API: Testing Transferability and Unpacking Latent Attributes,6,1–2,10.1145/3582568 , Journal Article,2023.0,"Perspective is a publicly available, machine learning API that can score text for toxicity. It is available for use in online platforms and communities to limit toxicity and promote civil dialogue. In this work, we adopt a human-centered approach to evaluating Perspective by investigating if human ratings of toxicity align with Perspective’s toxicity scores. We also test its transferability by making this comparison for comments from three platforms that have different commenting styles and moderation strategies: news websites, YouTube, and Twitter. Apart from toxicity, the main attribute, we collect participant ratings for three additional attributes: respectfulness, formality, and presence of stereotypes. While disrespect is part of how Perspective defines toxicity, formality and presence of stereotypes were included in the study to explore if they could be hidden/latent attributes that affect toxicity scores from Perspective. We analyzed how participant ratings for these additional attributes vary with respect to Perspective’s toxicity score for comments from each platform. We find that for high toxicity scores, Perspective strongly aligns with participant ratings of toxicity and disrespectfulness across all three platforms, providing weak evidence of its transferability. However, our evaluation also surfaced formality and presence of stereotypes as latent attributes that are unrecognized parts of Perspective’s scores. We discuss how and why this evaluation is “human-centered,” the importance of conducting such evaluations, and implications of these results for content moderation in social platforms.",,,,,Association for Computing Machinery Trans. Soc. Comput., ,"machine learning, Perspective, design, transferability, moderation tools, Evaluation",,
4479,"Title:Machine Learning Techniques Predict and Characterize Toxicity between Different Multi-Walled Carbon Nanotubes

 Multi-walled carbon nanotubes (MWCNT) are a diverse class of engineered nanomaterials known to induce pulmonary toxicity. It is unclear if the mechanisms contributing to the adverse effects are similar or unique when comparing different MWCNT. We hypothesize that machine learning techniques applied to toxicity outcomes will distinguish between convergent and divergent molecular responses. Towards this goal, a panel of proteins measured by multi-plex technology in bronchoalveolar lavage collected 1, 28, and 84 d post-exposure from mice exposed to two different as-produced MWCNT, their polymer coated counterparts, or a well-studied reference material, MWCNT-7, were analyzed using association rule mining (ARM) and support vector machine (SVM) techniques. The main objective was to take advantage of both knowledge represented by class association rules and the power of SVM to identify a small number of highly predictive markers (4 to 7 protein panels out of a total 63 proteins) that can distinguish between exposed and unexposed animals. Using these approaches, we were able to reliably (78% -- 97%) identify a small subset of proteins for each exposure that clearly distinguishes effect of exposure. One mediator in particular, MDC/CCL22, was associated with all exposures. MDC protein levels have been shown to be very sensitive in determining MWCNT exposure and predict declining lung function in humans following particulate exposure. Additional mediators (e.g., VEGF-A, MIP1b) exhibited similarity while others (e.g., LIF, MMP-9, VCAM1, PAI-1) distinguished one exposure from another. In vivo toxicity studies indicate that polymer coating the MWCNT for downstream applications can affect pulmonary toxicity. The machine learning techniques clearly distinguished the polymer coated MWCNT from the as-produced counterpart with up to 96% reliability, depending on particle type and exposure duration. The identified patterns in altered lavage proteins may serve as valuable markers to guide detection of exposure to MWCNT and offer hypothesis for future study design. The approaches presented in this study could enable comparison not only within a class of engineered nanomaterials but between various classes of nanomaterials.","Yanamala N,Bishop LM,Kodali VK,Zeidler-Erdely PC,Erdely AD",,,Machine Learning Techniques Predict and Characterize Toxicity between Different Multi-Walled Carbon Nanotubes,,,10.1145/2975167.2985664 , Conference Paper,2016.0,"Multi-walled carbon nanotubes (MWCNT) are a diverse class of engineered nanomaterials known to induce pulmonary toxicity. It is unclear if the mechanisms contributing to the adverse effects are similar or unique when comparing different MWCNT. We hypothesize that machine learning techniques applied to toxicity outcomes will distinguish between convergent and divergent molecular responses. Towards this goal, a panel of proteins measured by multi-plex technology in bronchoalveolar lavage collected 1, 28, and 84 d post-exposure from mice exposed to two different as-produced MWCNT, their polymer coated counterparts, or a well-studied reference material, MWCNT-7, were analyzed using association rule mining (ARM) and support vector machine (SVM) techniques. The main objective was to take advantage of both knowledge represented by class association rules and the power of SVM to identify a small number of highly predictive markers (4 to 7 protein panels out of a total 63 proteins) that can distinguish between exposed and unexposed animals. Using these approaches, we were able to reliably (78% -- 97%) identify a small subset of proteins for each exposure that clearly distinguishes effect of exposure. One mediator in particular, MDC/CCL22, was associated with all exposures. MDC protein levels have been shown to be very sensitive in determining MWCNT exposure and predict declining lung function in humans following particulate exposure. Additional mediators (e.g., VEGF-A, MIP1b) exhibited similarity while others (e.g., LIF, MMP-9, VCAM1, PAI-1) distinguished one exposure from another. In vivo toxicity studies indicate that polymer coating the MWCNT for downstream applications can affect pulmonary toxicity. The machine learning techniques clearly distinguished the polymer coated MWCNT from the as-produced counterpart with up to 96% reliability, depending on particle type and exposure duration. The identified patterns in altered lavage proteins may serve as valuable markers to guide detection of exposure to MWCNT and offer hypothesis for future study design. The approaches presented in this study could enable comparison not only within a class of engineered nanomaterials but between various classes of nanomaterials.",,,9781450342254,,Association for Computing Machinery ,"Proceedings of the 7th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics ","MWCNT toxicity, Nanotoxicity models, support vector machine, association rule mining",,
4480,"Title:Automating the Drug Scheduling with Different Toxicity Clearance in Cancer Chemotherapy via Evolutionary Computation

 The toxicity of an anticancer drug is cleared from the body by different processes, including saturable metabolic and nonsaturable renal-excretion pathways. According to the principles of toxicokinetics, we propose a new anticancer drug scheduling model with different toxic elimination processes in this paper. We also present a sophisticated automating drug scheduling approach based on evolutionary computation and computer modeling. To explore multiple efficient drug scheduling policies, we use a multimodal optimization algorithm --- adaptive elitist-population based genetic algorithm (AEGA) to solve the new model, and discuss the situation of multiple optimal solutions under different parameter settings. The simulation results obtained by the new model match well with the clinical treatment experience, and can provide much more drug scheduling policies for a doctor to choose depending on the particular conditions of the patients.","Liang Y,Lueng KS,Mok TS",,,Automating the Drug Scheduling with Different Toxicity Clearance in Cancer Chemotherapy via Evolutionary Computation,,,10.1145/1143997.1144276 , Conference Paper,2006.0,"The toxicity of an anticancer drug is cleared from the body by different processes, including saturable metabolic and nonsaturable renal-excretion pathways. According to the principles of toxicokinetics, we propose a new anticancer drug scheduling model with different toxic elimination processes in this paper. We also present a sophisticated automating drug scheduling approach based on evolutionary computation and computer modeling. To explore multiple efficient drug scheduling policies, we use a multimodal optimization algorithm --- adaptive elitist-population based genetic algorithm (AEGA) to solve the new model, and discuss the situation of multiple optimal solutions under different parameter settings. The simulation results obtained by the new model match well with the clinical treatment experience, and can provide much more drug scheduling policies for a doctor to choose depending on the particular conditions of the patients.",,,9781595931863,,Association for Computing Machinery ,Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation ,"drug scheduling model, multimodal optimization algorithm",,
4481,"Title:See No Evil, Hear No Evil, Speak No Evil: How Collegiate Players Define, Experience and Cope with Toxicity

 Toxicity in online environments is a complex and a systemic issue. Collegiate esports communities seem to be particularly vulnerable to toxic behaviors. In esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce enjoyment which may cause them to leave the game. The aim of this study is to investigate how players define, experience and deal with toxicity in esports games that they play. Our findings from an interview study and five monthly follow ups with 19 participants from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and are inclined to normalize negative behaviors, rationalize it as part of the competitive game culture akin to traditional sports, and participate a form of gamer classism, believing that toxicity is more common in lower level play than in professional and collegiate esports. There are many coping mechanisms employed by collegiate esports players, including ignoring offenders, deescalating tense encounters, and using tools to mute offenders. Understanding the motivations behind collegiate esports players' engagement with toxicity may help the growing sport plot a positive trajectory towards healthy play.","Türkay S,Formosa J,Adinolf S,Cuthbert R,Altizer R",,,"See No Evil, Hear No Evil, Speak No Evil: How Collegiate Players Define, Experience and Cope with Toxicity",,,10.1145/3313831.3376191 , Conference Paper,2020.0,"Toxicity in online environments is a complex and a systemic issue. Collegiate esports communities seem to be particularly vulnerable to toxic behaviors. In esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce enjoyment which may cause them to leave the game. The aim of this study is to investigate how players define, experience and deal with toxicity in esports games that they play. Our findings from an interview study and five monthly follow ups with 19 participants from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and are inclined to normalize negative behaviors, rationalize it as part of the competitive game culture akin to traditional sports, and participate a form of gamer classism, believing that toxicity is more common in lower level play than in professional and collegiate esports. There are many coping mechanisms employed by collegiate esports players, including ignoring offenders, deescalating tense encounters, and using tools to mute offenders. Understanding the motivations behind collegiate esports players' engagement with toxicity may help the growing sport plot a positive trajectory towards healthy play.",,,9781450367080,,Association for Computing Machinery ,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems ,"toxicity, esports, competitive games, player perceptions, interview study",,
4482,"Title:Should We Translate? Evaluating Toxicity in Online Comments When Translating from Portuguese to English

 Social media and online discussion platforms suffer from the prevalence of uncivil behavior, such as harassment and abuse, seeking to curb toxic comments. There are several approaches to classifying toxic comments automatically. Some of them have more resources and are more advanced in English, thus, stimulating the task of translating the text from a specific language to English. While researchers have shown evidence that this practice is indicated for certain tasks, such as sentiment analysis, little is known in the context of toxicity identification. In this research, we assess the performance of a freely available model for toxic language detection in online comments called Perspective API, widely adopted by some famous news media sites to identify different toxicity classes in online comments. For that, we obtained comments in Portuguese from two Brazilian news media websites during a politically polarized situation as a use case. Then, this dataset was translated to English and compared to four baseline datasets, two composed of highly toxic comments, one in Portuguese and other in English, and two composed of neutral comments, also one in Portuguese and other in English – all of them in its original language, not translated. Finally, human-annotated comments from the news comments dataset were analyzed to assess the scores provided by the Perspective API for the original and the translated versions. Results indicate that keeping the texts in their original language is preferable, even in comparing different languages. Nevertheless, if the translated version is strictly necessary, ways of dealing with the situation were suggested to preserve as much information as possible from the original version.","Kobellarz JK,Silva TH",,,Should We Translate? Evaluating Toxicity in Online Comments When Translating from Portuguese to English,,,10.1145/3539637.3556892 , Conference Paper,2022.0,"Social media and online discussion platforms suffer from the prevalence of uncivil behavior, such as harassment and abuse, seeking to curb toxic comments. There are several approaches to classifying toxic comments automatically. Some of them have more resources and are more advanced in English, thus, stimulating the task of translating the text from a specific language to English. While researchers have shown evidence that this practice is indicated for certain tasks, such as sentiment analysis, little is known in the context of toxicity identification. In this research, we assess the performance of a freely available model for toxic language detection in online comments called Perspective API, widely adopted by some famous news media sites to identify different toxicity classes in online comments. For that, we obtained comments in Portuguese from two Brazilian news media websites during a politically polarized situation as a use case. Then, this dataset was translated to English and compared to four baseline datasets, two composed of highly toxic comments, one in Portuguese and other in English, and two composed of neutral comments, also one in Portuguese and other in English – all of them in its original language, not translated. Finally, human-annotated comments from the news comments dataset were analyzed to assess the scores provided by the Perspective API for the original and the translated versions. Results indicate that keeping the texts in their original language is preferable, even in comparing different languages. Nevertheless, if the translated version is strictly necessary, ways of dealing with the situation were suggested to preserve as much information as possible from the original version.",,,9781450394093,,Association for Computing Machinery ,Proceedings of the Brazilian Symposium on Multimedia and the Web ,"natural language, toxicity, translation, online comments, Perspective API",,
4483,"Title:Functioning Mechanisms of Ectomycorrhizal Fungi and Ectomycorrhiza Associated with Plant in the Tolerance to Heavy Metal Toxicity

 Ectomycorrhizal fungus (ECMF) is one of the important plant symbiotic fungi. Their functions in enhancing the tolerance of plants to heavy metal toxicity have been widely recognized and applied. The function mechanisms of ECMF of enhancing the tolerances of plants to heavy metal toxicity have been paid much attention. However, many previous reviews have not distinguished the effects and mechanisms on the tolerance to heavy metal toxicity between ECMF and ECMF mycorrhizae symbionts. We reviewed the response mechanisms of pure cultured ectomycorrhizal fungi under heavy metal stress in vitro, the anatomical mechanisms, the physiological mechanisms, the molecular regulation mechanisms of ectomycorrhiza tolerance to heavy metal toxicity and the enhancement of plant tolerance to heavy metal. It will shed the light on the enhancement mechanism of ECMF in the plant tolerance to heavy metal. Further research directions on the application of ectomycorrhizal fungi in the remediation of contaminated sites have been indicated.","Wang M,Yang B,Wang H,Zhu Y,Cao X,Yuan Y",,,Functioning Mechanisms of Ectomycorrhizal Fungi and Ectomycorrhiza Associated with Plant in the Tolerance to Heavy Metal Toxicity,,,10.1145/3386762.3386776 , Conference Paper,2020.0,"Ectomycorrhizal fungus (ECMF) is one of the important plant symbiotic fungi. Their functions in enhancing the tolerance of plants to heavy metal toxicity have been widely recognized and applied. The function mechanisms of ECMF of enhancing the tolerances of plants to heavy metal toxicity have been paid much attention. However, many previous reviews have not distinguished the effects and mechanisms on the tolerance to heavy metal toxicity between ECMF and ECMF mycorrhizae symbionts. We reviewed the response mechanisms of pure cultured ectomycorrhizal fungi under heavy metal stress in vitro, the anatomical mechanisms, the physiological mechanisms, the molecular regulation mechanisms of ectomycorrhiza tolerance to heavy metal toxicity and the enhancement of plant tolerance to heavy metal. It will shed the light on the enhancement mechanism of ECMF in the plant tolerance to heavy metal. Further research directions on the application of ectomycorrhizal fungi in the remediation of contaminated sites have been indicated.",,,9781450376891,,Association for Computing Machinery ,"Proceedings of the 2020 The 9th International Conference on Informatics, Environment, Energy and Applications ","Ectomycorrhizal Fungi, Plant, Heavy Metal, Tolerance Mechanism",,
4484,"Title:Automatic Labelling of Malay Cyberbullying Twitter Corpus Using Combinations of Sentiment, Emotion and Toxicity Polarities

 Automatic labelling is essential in large corpuses. Engaging in human experts to label can be challenging. Semantic understanding can differ from one labeler to another based on individual's language ability. Platforms such as AmazonTurk are not able to ensure the quality of annotations in every domain. Extensive steps such as qualification and counter checking of labels may be implemented which will increase the cost of data annotation. Thus, the higher quality of labelled data expected, the greater the cost that needs to be expended. This scenario is made worse when the language is of low resource where in this work is the Malay language. Malay is a language used mostly in Malaysia, Indonesia, Singapore and Brunei. Unlike English which has large resources to tap into the semantics of sentences, making automatic labelling faster to mature, resources in Malay language are still limited. Further compounded is the use of social media data where the text is short, unnormalized and the inherent presence of code switching. The availability of qualified native Malay labelers is also scarce. To overcome this, we devised a method to automatically label a total of 219,444 Malay tweets by using a combination of sentiment, emotion and toxicity polarities. We extend the work from Arslan et al. who proposed the use of sentiment and emotion to identify cyberbullying text. Our work added toxicity polarity in the context of automatic labelling of cyberbully tweets in Malay. We were able to employ 5 experts with formal degrees in Malay language to label our training set. We applied this method to Malay cyberbullying corpus to determine “bully” and “not bully” labels. We have tested our method on 54,867 manually labelled data and achieved high accuracy.","Maskat R,Faizzuddin Zainal M,Ismail N,Ardi N,Ahmad A,Daud N",,,"Automatic Labelling of Malay Cyberbullying Twitter Corpus Using Combinations of Sentiment, Emotion and Toxicity Polarities",,,10.1145/3446132.3446412 , Conference Paper,2021.0,"Automatic labelling is essential in large corpuses. Engaging in human experts to label can be challenging. Semantic understanding can differ from one labeler to another based on individual's language ability. Platforms such as AmazonTurk are not able to ensure the quality of annotations in every domain. Extensive steps such as qualification and counter checking of labels may be implemented which will increase the cost of data annotation. Thus, the higher quality of labelled data expected, the greater the cost that needs to be expended. This scenario is made worse when the language is of low resource where in this work is the Malay language. Malay is a language used mostly in Malaysia, Indonesia, Singapore and Brunei. Unlike English which has large resources to tap into the semantics of sentences, making automatic labelling faster to mature, resources in Malay language are still limited. Further compounded is the use of social media data where the text is short, unnormalized and the inherent presence of code switching. The availability of qualified native Malay labelers is also scarce. To overcome this, we devised a method to automatically label a total of 219,444 Malay tweets by using a combination of sentiment, emotion and toxicity polarities. We extend the work from Arslan et al. who proposed the use of sentiment and emotion to identify cyberbullying text. Our work added toxicity polarity in the context of automatic labelling of cyberbully tweets in Malay. We were able to employ 5 experts with formal degrees in Malay language to label our training set. We applied this method to Malay cyberbullying corpus to determine “bully” and “not bully” labels. We have tested our method on 54,867 manually labelled data and achieved high accuracy.",,,9781450388115,,Association for Computing Machinery ,"Proceedings of the 2020 3rd International Conference on Algorithms, Computing and Artificial Intelligence ","Malay language, Automatic labelling, Twitter, Cyberbullying",,
4485,"Title:Does Media Format Matter? Investigating the Toxicity, Sentiment and Topic of Audio Versus Text Social Media Messages

 Audio messaging and voice-based interactions are growing in popularity. Lexical features of a manually-curated dataset of real-world audio tweets, as well as text and video/image tweets from the same user accounts, are analyzed to explore how user-generated audio differs from text. The toxicity, sentiment, topic and length of audio tweet transcripts are compared with their accompanying text, date-matched text tweets from the same users and date-matched video/image tweets and their accompanying text. Audio tweets were significantly less toxic than both text tweets and text that accompanied the audio tweet, as well as significantly lower sentiment than their accompanying text. The topics and word counts of audio, text and video/image tweets also differed. These findings are then used to derive design implications for audio and conversational agent interaction. This research contributes preliminary insights about audio social media messages that may help researchers and designers of audio- and agent-based interaction better understand and design for different media formats.","Li J,Penaranda Valdivia K",,,"Does Media Format Matter? Investigating the Toxicity, Sentiment and Topic of Audio Versus Text Social Media Messages",,,10.1145/3527188.3561927 , Conference Paper,2022.0,"Audio messaging and voice-based interactions are growing in popularity. Lexical features of a manually-curated dataset of real-world audio tweets, as well as text and video/image tweets from the same user accounts, are analyzed to explore how user-generated audio differs from text. The toxicity, sentiment, topic and length of audio tweet transcripts are compared with their accompanying text, date-matched text tweets from the same users and date-matched video/image tweets and their accompanying text. Audio tweets were significantly less toxic than both text tweets and text that accompanied the audio tweet, as well as significantly lower sentiment than their accompanying text. The topics and word counts of audio, text and video/image tweets also differed. These findings are then used to derive design implications for audio and conversational agent interaction. This research contributes preliminary insights about audio social media messages that may help researchers and designers of audio- and agent-based interaction better understand and design for different media formats.",,,9781450393232,,Association for Computing Machinery ,Proceedings of the 10th International Conference on Human-Agent Interaction ,,,
4486,"Title:Restoring Healthy Online Discourse by Detecting and Reducing Controversy, Misinformation, and Toxicity Online

 Healthy online discourse is becoming less and less accessible beneath the growing noise of controversy, mis- and dis-information, and toxic speech. While IR is crucial in detecting harmful speech, researchers must work across disciplines to develop interventions, and partner with industry to deploy them rapidly and effectively. In this position paper, we argue that both detecting online information disorders and deploying novel, real-world content moderation tools is crucial in promoting empathy in social networks, and maintaining free expression and discourse. We detail our insights in studying different social networks such as Parler and Reddit. Finally, we discuss the joys and challenges as a lab-grown startup working with both academia and other industrial partners in finding a path toward a better, more trustworthy online ecosystem.","Dori-Hacohen S,Sung K,Chou J,Lustig-Gonzalez J",,,"Restoring Healthy Online Discourse by Detecting and Reducing Controversy, Misinformation, and Toxicity Online",,,10.1145/3404835.3464926 , Conference Paper,2021.0,"Healthy online discourse is becoming less and less accessible beneath the growing noise of controversy, mis- and dis-information, and toxic speech. While IR is crucial in detecting harmful speech, researchers must work across disciplines to develop interventions, and partner with industry to deploy them rapidly and effectively. In this position paper, we argue that both detecting online information disorders and deploying novel, real-world content moderation tools is crucial in promoting empathy in social networks, and maintaining free expression and discourse. We detail our insights in studying different social networks such as Parler and Reddit. Finally, we discuss the joys and challenges as a lab-grown startup working with both academia and other industrial partners in finding a path toward a better, more trustworthy online ecosystem.",,,9781450380379,,Association for Computing Machinery ,Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval ,"misinformation, disinformation, content moderation, toxicity, social networks, controversy",,
4487,"Title:“We Found No Violation!”: Twitter's Violent Threats Policy and Toxicity in Online Discourse

 Threat moderation on social media has been subject to much public debate and criticism, especially for its broadly permissive approach. In this paper, we focus on Twitter's Violent Threats policy, highlighting its shortcomings by comparing it to linguistic and legal threat assessment frameworks. Specifically, we foreground the importance of accounting for the lived experiences of harassment—how people perceive and react to a tweet—a measure largely disregarded by Twitter's Violent Threats policy but a core part of linguistic and legal threat assessment frameworks. To illustrate this, we examine three tweets by drawing upon these frameworks. These tweets showcase the racist, sexist, and abusive language used in threats towards those who have been marginalized. Through our analysis, we highlight how content moderation policies, despite their stated goal of promoting free speech, in effect, work to inhibit it by fostering an online toxic environment that precipitates self-censorship in fear of violence and retaliation. In doing so, we make a case for technology designers and policy makers working in the sphere of content moderation to craft approaches that incorporate the various nuanced dimensions of threat assessment toward a more inclusive and open environment for online discourse. CONTENT WARNING: This paper contains strong and violent language. Please use discretion when reading, printing, or recommending this paper.","Casula P,Anupam A,Parvin N",,,“We Found No Violation!”: Twitter's Violent Threats Policy and Toxicity in Online Discourse,,,10.1145/3461564.3461589 , Conference Paper,2021.0,"Threat moderation on social media has been subject to much public debate and criticism, especially for its broadly permissive approach. In this paper, we focus on Twitter's Violent Threats policy, highlighting its shortcomings by comparing it to linguistic and legal threat assessment frameworks. Specifically, we foreground the importance of accounting for the lived experiences of harassment—how people perceive and react to a tweet—a measure largely disregarded by Twitter's Violent Threats policy but a core part of linguistic and legal threat assessment frameworks. To illustrate this, we examine three tweets by drawing upon these frameworks. These tweets showcase the racist, sexist, and abusive language used in threats towards those who have been marginalized. Through our analysis, we highlight how content moderation policies, despite their stated goal of promoting free speech, in effect, work to inhibit it by fostering an online toxic environment that precipitates self-censorship in fear of violence and retaliation. In doing so, we make a case for technology designers and policy makers working in the sphere of content moderation to craft approaches that incorporate the various nuanced dimensions of threat assessment toward a more inclusive and open environment for online discourse. CONTENT WARNING: This paper contains strong and violent language. Please use discretion when reading, printing, or recommending this paper.",,,9781450390569,,Association for Computing Machinery ,Proceedings of the 10th International Conference on Communities & Technologies - Wicked Problems in the Age of Tech ,"Violent Threats, Free Speech, Language Analysis, Marginalization, Online Moderation, Online Toxicity, Twitter, Social Media",,
4488,"Title:Help, My Game Is Toxic! First Insights from a Systematic Literature Review on Intervention Systems for Toxic Behaviors in Online Video Games

 Toxicity is a common problem in online games. Players regularly experience negative, hateful, or inappropriate behavior during gameplay. Intervention systems can help combat toxicity but are not widely available and or even comprehensively studied regarding their approaches and effectiveness. To assess the current state of toxicity intervention research, we are conducting a systematic literature review about intervention methods for toxic behaviors in online video games. In this work-in-progress, we report the research protocol for this review and the results from a preliminary analysis. We collected 1176 works from 4 digital libraries and performed abstract and full-text screening, resulting in 30 relevant papers containing 36 intervention systems. By analyzing these intervention systems, we found: 1) Most research proposes novel approaches (n = 28) instead of analyzing existing interventions. 2) Most systems intervene only after toxicity occurs (n = 31) with few interventions that act before toxicity. 3) Only few interventions are evaluated with players and in commercial settings (n = 5), highlighting the potential for more research with higher external validity. In our ongoing work, we are conducting an in-depth analysis of the interventions providing insights into their approaches and effectiveness. This work is the first step toward effective toxicity interventions that can mitigate harm to players.","Wijkstra M,Rogers K,Mandryk RL,Veltkamp RC,Frommel J",,,"Help, My Game Is Toxic! First Insights from a Systematic Literature Review on Intervention Systems for Toxic Behaviors in Online Video Games",,,10.1145/3573382.3616068 , Conference Paper,2023.0,"Toxicity is a common problem in online games. Players regularly experience negative, hateful, or inappropriate behavior during gameplay. Intervention systems can help combat toxicity but are not widely available and or even comprehensively studied regarding their approaches and effectiveness. To assess the current state of toxicity intervention research, we are conducting a systematic literature review about intervention methods for toxic behaviors in online video games. In this work-in-progress, we report the research protocol for this review and the results from a preliminary analysis. We collected 1176 works from 4 digital libraries and performed abstract and full-text screening, resulting in 30 relevant papers containing 36 intervention systems. By analyzing these intervention systems, we found: 1) Most research proposes novel approaches (n = 28) instead of analyzing existing interventions. 2) Most systems intervene only after toxicity occurs (n = 31) with few interventions that act before toxicity. 3) Only few interventions are evaluated with players and in commercial settings (n = 5), highlighting the potential for more research with higher external validity. In our ongoing work, we are conducting an in-depth analysis of the interventions providing insights into their approaches and effectiveness. This work is the first step toward effective toxicity interventions that can mitigate harm to players.",,,,,Association for Computing Machinery ,Companion Proceedings of the Annual Symposium on Computer-Human Interaction in Play ,"systematic literature review, interventions, toxicity, online games",,
4489,"Title:Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots

 Chatbots are used in many applications, e.g., automated agents, smart home assistants, interactive characters in online games, etc. Therefore, it is crucial to ensure they do not behave in undesired manners, providing offensive or toxic responses to users. This is not a trivial task as state-of-the-art chatbot models are trained on large, public datasets openly collected from the Internet. This paper presents a first-of-its-kind, large-scale measurement of toxicity in chatbots. We show that publicly available chatbots are prone to providing toxic responses when fed toxic queries. Even more worryingly, some non-toxic queries can trigger toxic responses too. We then set out to design and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to generate non-toxic queries that make chatbots respond in a toxic manner. Our extensive experimental evaluation demonstrates that our attack is effective against public chatbot models and outperforms manually-crafted malicious queries proposed by previous work. We also evaluate three defense mechanisms against ToxicBuddy, showing that they either reduce the attack performance at the cost of affecting the chatbot's utility or are only effective at mitigating a portion of the attack. This highlights the need for more research from the computer security and online safety communities to ensure that chatbot models do not hurt their users. Overall, we are confident that ToxicBuddy can be used as an auditing tool and that our work will pave the way toward designing more effective defenses for chatbot safety.","Si WM,Backes M,Blackburn J,De Cristofaro E,Stringhini G,Zannettou S,Zhang Y",,,Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots,,,10.1145/3548606.3560599 , Conference Paper,2022.0,"Chatbots are used in many applications, e.g., automated agents, smart home assistants, interactive characters in online games, etc. Therefore, it is crucial to ensure they do not behave in undesired manners, providing offensive or toxic responses to users. This is not a trivial task as state-of-the-art chatbot models are trained on large, public datasets openly collected from the Internet. This paper presents a first-of-its-kind, large-scale measurement of toxicity in chatbots. We show that publicly available chatbots are prone to providing toxic responses when fed toxic queries. Even more worryingly, some non-toxic queries can trigger toxic responses too. We then set out to design and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to generate non-toxic queries that make chatbots respond in a toxic manner. Our extensive experimental evaluation demonstrates that our attack is effective against public chatbot models and outperforms manually-crafted malicious queries proposed by previous work. We also evaluate three defense mechanisms against ToxicBuddy, showing that they either reduce the attack performance at the cost of affecting the chatbot's utility or are only effective at mitigating a portion of the attack. This highlights the need for more research from the computer security and online safety communities to ensure that chatbot models do not hurt their users. Overall, we are confident that ToxicBuddy can be used as an auditing tool and that our work will pave the way toward designing more effective defenses for chatbot safety.",,,9781450394505,,Association for Computing Machinery ,Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security ,"trustworthy machine learning, online toxicity, dialogue system",,
4490,"Title:Toxic Behaviors in Team-Based Competitive Gaming: The Case of League of Legends

 Toxic behaviors in online gaming such as flaming and harassment have been gaining attention from the research community, yet little consensus has formed about what constitutes toxic behavior. Game developers usually maintain a classification system of toxic behaviors, which oftentimes fails to reflect the dynamic and developing forms of toxicity. In this paper, we consider toxic behavior as situated action, and seek to establish a taxonomy of toxic behaviors from a player perspective in League of Legends, currently one of the largest Esports games in the world. Our findings include five primary types of toxic behaviors, as well as five contextual factors that could lead to toxic behavior. In doing so, we provide a holistic, detailed account of toxic behavior in a team-based competitive gaming context, highlight the role of player perspective in explaining toxic behavior, and extend existing scholarly discussions on toxicity and moderation.",Kou Y,,,Toxic Behaviors in Team-Based Competitive Gaming: The Case of League of Legends,,,10.1145/3410404.3414243 , Conference Paper,2020.0,"Toxic behaviors in online gaming such as flaming and harassment have been gaining attention from the research community, yet little consensus has formed about what constitutes toxic behavior. Game developers usually maintain a classification system of toxic behaviors, which oftentimes fails to reflect the dynamic and developing forms of toxicity. In this paper, we consider toxic behavior as situated action, and seek to establish a taxonomy of toxic behaviors from a player perspective in League of Legends, currently one of the largest Esports games in the world. Our findings include five primary types of toxic behaviors, as well as five contextual factors that could lead to toxic behavior. In doing so, we provide a holistic, detailed account of toxic behavior in a team-based competitive gaming context, highlight the role of player perspective in explaining toxic behavior, and extend existing scholarly discussions on toxicity and moderation.",,,9781450380744,,Association for Computing Machinery ,Proceedings of the Annual Symposium on Computer-Human Interaction in Play ,"multiplayer-online battle arena, grief, esports, moderation, flame, toxic behavior, platform governance, trolling, league of legends",,
4491,"Title:Toxic Behaviors in Esports Games: Player Perceptions and Coping Strategies

 Toxicity in online environments is a complex and a systemic issue. Esports communities seem to be particularly suffering from toxic behaviors. Especially in competitive esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce players' enjoyment which may cause them to leave the game. The aim of this study is to review design approaches in six major esports games to deal with toxic behaviors and to investigate how players perceive and deal with toxicity in those games. Our preliminary findings from an interview study with 17 participants (3 female) from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and participants are inclined to normalize negative behaviors and rationalize it as part of the competitive game culture. If they choose to take an action against toxic players, they are likely to ostracize toxic players.","Adinolf S,Turkay S",,,Toxic Behaviors in Esports Games: Player Perceptions and Coping Strategies,,,10.1145/3270316.3271545 , Conference Paper,2018.0,"Toxicity in online environments is a complex and a systemic issue. Esports communities seem to be particularly suffering from toxic behaviors. Especially in competitive esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce players' enjoyment which may cause them to leave the game. The aim of this study is to review design approaches in six major esports games to deal with toxic behaviors and to investigate how players perceive and deal with toxicity in those games. Our preliminary findings from an interview study with 17 participants (3 female) from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and participants are inclined to normalize negative behaviors and rationalize it as part of the competitive game culture. If they choose to take an action against toxic players, they are likely to ostracize toxic players.",,,9781450359689,,Association for Computing Machinery ,Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts ,"negative behaviours, esports games, toxicity, interview study",,
4492,"Title:A Longitudinal Study of the Top 1% Toxic Twitter Profiles

 Toxicity is endemic to online social networks (OSNs) including Twitter. It follows a Pareto-like distribution where most of the toxicity is generated by a very small number of profiles and as such, analyzing and characterizing these “toxic profiles” is critical. Prior research has largely focused on sporadic, event-centric toxic content (i.e., tweets) to characterize toxicity on the platform. Instead, we approach the problem of characterizing toxic content from a profile-centric point of view. We study 143K Twitter profiles and focus on the behavior of the top 1% producers of toxic content on Twitter, based on toxicity scores of their tweets availed by Perspective API. With a total of 293M tweets, spanning 16 years of activity, the longitudinal data allows us to reconstruct the timelines of all profiles involved. We use these timelines to gauge the behavior of the most toxic Twitter profiles compared to the rest of the Twitter population. We study the pattern of tweet posting from highly toxic accounts, based on the frequency and how prolific they are, the nature of hashtags and URLs, profile metadata, and Botometer scores. We find that the highly toxic profiles post coherent and well-articulated content, their tweets keep to a narrow theme with lower diversity in hashtags, URLs, and domains, they are thematically similar to each other, and have a high likelihood of bot-like behavior, likely to have progenitors with intentions to influence, based on high fake followers score. Our work contributes insight into the top 1% toxic profiles on Twitter and establishes the profile-centric approach to investigate toxicity on Twitter to be beneficial. The identification of the most toxic profiles can aid in the reporting and suspension of such profiles, making Twitter a better place for discussions. Finally, we contribute to the research community with this large-scale and longitudinal dataset1, annotated with six types of toxic scores.","Qayyum H,Zi Hao Zhao B,Wood I,Ikram M,Kourtellis N,Ali Kaafar M",,,A Longitudinal Study of the Top 1% Toxic Twitter Profiles,,,10.1145/3578503.3583619 , Conference Paper,2023.0,"Toxicity is endemic to online social networks (OSNs) including Twitter. It follows a Pareto-like distribution where most of the toxicity is generated by a very small number of profiles and as such, analyzing and characterizing these “toxic profiles” is critical. Prior research has largely focused on sporadic, event-centric toxic content (i.e., tweets) to characterize toxicity on the platform. Instead, we approach the problem of characterizing toxic content from a profile-centric point of view. We study 143K Twitter profiles and focus on the behavior of the top 1% producers of toxic content on Twitter, based on toxicity scores of their tweets availed by Perspective API. With a total of 293M tweets, spanning 16 years of activity, the longitudinal data allows us to reconstruct the timelines of all profiles involved. We use these timelines to gauge the behavior of the most toxic Twitter profiles compared to the rest of the Twitter population. We study the pattern of tweet posting from highly toxic accounts, based on the frequency and how prolific they are, the nature of hashtags and URLs, profile metadata, and Botometer scores. We find that the highly toxic profiles post coherent and well-articulated content, their tweets keep to a narrow theme with lower diversity in hashtags, URLs, and domains, they are thematically similar to each other, and have a high likelihood of bot-like behavior, likely to have progenitors with intentions to influence, based on high fake followers score. Our work contributes insight into the top 1% toxic profiles on Twitter and establishes the profile-centric approach to investigate toxicity on Twitter to be beneficial. The identification of the most toxic profiles can aid in the reporting and suspension of such profiles, making Twitter a better place for discussions. Finally, we contribute to the research community with this large-scale and longitudinal dataset1, annotated with six types of toxic scores.",,,,,Association for Computing Machinery ,Proceedings of the 15th ACM Web Science Conference 2023 ,"Perspective score, profile, measurement, longitudinal, toxicity, Twitter",,
4493,"Title:Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots

 Recent advances in natural language processing and machine learning have led to the development of chatbot models, such as ChatGPT, that can engage in conversational dialogue with human users. However, understanding the ability of these models to generate toxic or harmful responses during a non-toxic multi-turn conversation remains an open research problem. Existing research focuses on single-turn sentence testing, while we find that 82% of the individual non-toxic sentences that elicit toxic behaviors in a conversation are considered safe by existing tools. In this paper, we design a new attack, ToxicChat, by fine-tuning a chatbot to engage in conversation with a target open-domain chatbot. The chatbot is fine-tuned with a collection of crafted conversation sequences. Particularly, each conversation begins with a sentence from a crafted prompt sentences dataset. Our extensive evaluation shows that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation. In the best scenario, ToxicChat achieves a 67% toxicity activation rate. The conversation sequences in the fine-tuning stage help trigger the toxicity in a conversation, which allows the attack to bypass two defense methods. Our findings suggest that further research is needed to address chatbot toxicity in a dynamic interactive environment. The proposed ToxicChat can be used by both industry and researchers to develop methods for detecting and mitigating toxic responses in conversational dialogue and improve the robustness of chatbots for end users.","Chen B,Wang G,Guo H,Wang Y,Yan Q",,,Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots,,,10.1145/3607199.3607237 , Conference Paper,2023.0,"Recent advances in natural language processing and machine learning have led to the development of chatbot models, such as ChatGPT, that can engage in conversational dialogue with human users. However, understanding the ability of these models to generate toxic or harmful responses during a non-toxic multi-turn conversation remains an open research problem. Existing research focuses on single-turn sentence testing, while we find that 82% of the individual non-toxic sentences that elicit toxic behaviors in a conversation are considered safe by existing tools. In this paper, we design a new attack, ToxicChat, by fine-tuning a chatbot to engage in conversation with a target open-domain chatbot. The chatbot is fine-tuned with a collection of crafted conversation sequences. Particularly, each conversation begins with a sentence from a crafted prompt sentences dataset. Our extensive evaluation shows that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation. In the best scenario, ToxicChat achieves a 67% toxicity activation rate. The conversation sequences in the fine-tuning stage help trigger the toxicity in a conversation, which allows the attack to bypass two defense methods. Our findings suggest that further research is needed to address chatbot toxicity in a dynamic interactive environment. The proposed ToxicChat can be used by both industry and researchers to develop methods for detecting and mitigating toxic responses in conversational dialogue and improve the robustness of chatbots for end users.",,,,,Association for Computing Machinery ,"Proceedings of the 26th International Symposium on Research in Attacks, Intrusions and Defenses ","trustworthy machine learning, Dialogue System, online toxicity",,
4494,"Title:Understanding Toxic Behavior in Online Games

 With the remarkable advances from isolated console games to massively multi-player online role-playing games, the online gaming world provides yet another place where people interact with each other. Online games have attracted attention from researchers, because i) the purpose of actions is relatively clear, and ii) actions are quantifiable. A wide range of predefined actions for supporting social interaction (e.g., friendship, communication, trade, enmity, aggression, and punishment) reflects either positive or negative connotations among game players, and is unobtrusively recorded by the game servers. These rich electronic footprints have become invaluable assets for the research of social dynamics.In particular, exploring negative behavior in online games is a key research direction because it directly influences gaming experience and user satisfaction. Even a few negative players can impact many others because of the design of multi-player games. For this reason these players are called toxic. The definition of toxic play is not cut and dry. Even if someone follows the game rules, he could be considered toxic. For example, killing one player repetitively is often deemed toxic behavior, although it does not break game rules at all. The vagueness of toxicity makes it hard to understand, detect, and prevent it.League of Legends (LoL), created by Riot Games with 70 million users as of 2012, offers a new way to understand toxic behavior. Riot Games develops a crowdsourcing framework, the Tribunal, to judge whether reported toxic behavior should be punished or not. Volunteered players review user reports and vote for either pardon or punishment. As of March 2013, 105 million votes had been collected in North America and Europe.We explore toxic playing and reaction based on large-scale data from the Tribunal[1]. We collect and investigate over 10 million user reports on 1.46 million toxic players and corresponding crowdsourced decisions made in the Tribunal. We crawl data from three different regions, North America, Western Europe, and Korea, to take regional differences of user behavior into account. To obtain the comprehensive view of toxic playing and reaction based on huge data collection, we answer following research questions in a bottom-up approach: how individuals react to toxic players, how teams interact with toxic players, how general toxic or non-toxic players behave across the match, and how crowds make a decision on toxic players. We find large-scale empirical support for some notoriously difficult theories to test in the wild, which are bystander effect, ingroup favoritism, black sheep effect, cohesion-performance relationships, and attribution theory. We also discover that regional differences affect the likelihood of being reported and the proportion of being punished of toxic players in the Tribunal.We then propose a supervised learning approach for predicting crowdsourced decisions on toxic behavior with large-scale labeled data collections[2]. Using the same sparse information available to the reviewers, we trained classifiers to detect the presence, and severity of toxicity. We built several models oriented around in-game performance, reports by victims of toxic behavior, and linguistic features of chat messages. We found that training with high agreement decisions resulted in more accuracy on low agreement decisions and that our classifier was adept in detecting clear cut innocence. Finally, we showed that our classifier is relatively robust across cultural regions; our classifier built from a North American dataset performed adequately on a European dataset.Ultimately, our work can be used as a foundation for the further study of toxic behavior.",Kwak H,,,Understanding Toxic Behavior in Online Games,,,10.1145/2567948.2580066 , Conference Paper,2014.0,"With the remarkable advances from isolated console games to massively multi-player online role-playing games, the online gaming world provides yet another place where people interact with each other. Online games have attracted attention from researchers, because i) the purpose of actions is relatively clear, and ii) actions are quantifiable. A wide range of predefined actions for supporting social interaction (e.g., friendship, communication, trade, enmity, aggression, and punishment) reflects either positive or negative connotations among game players, and is unobtrusively recorded by the game servers. These rich electronic footprints have become invaluable assets for the research of social dynamics.In particular, exploring negative behavior in online games is a key research direction because it directly influences gaming experience and user satisfaction. Even a few negative players can impact many others because of the design of multi-player games. For this reason these players are called toxic. The definition of toxic play is not cut and dry. Even if someone follows the game rules, he could be considered toxic. For example, killing one player repetitively is often deemed toxic behavior, although it does not break game rules at all. The vagueness of toxicity makes it hard to understand, detect, and prevent it.League of Legends (LoL), created by Riot Games with 70 million users as of 2012, offers a new way to understand toxic behavior. Riot Games develops a crowdsourcing framework, the Tribunal, to judge whether reported toxic behavior should be punished or not. Volunteered players review user reports and vote for either pardon or punishment. As of March 2013, 105 million votes had been collected in North America and Europe.We explore toxic playing and reaction based on large-scale data from the Tribunal[1]. We collect and investigate over 10 million user reports on 1.46 million toxic players and corresponding crowdsourced decisions made in the Tribunal. We crawl data from three different regions, North America, Western Europe, and Korea, to take regional differences of user behavior into account. To obtain the comprehensive view of toxic playing and reaction based on huge data collection, we answer following research questions in a bottom-up approach: how individuals react to toxic players, how teams interact with toxic players, how general toxic or non-toxic players behave across the match, and how crowds make a decision on toxic players. We find large-scale empirical support for some notoriously difficult theories to test in the wild, which are bystander effect, ingroup favoritism, black sheep effect, cohesion-performance relationships, and attribution theory. We also discover that regional differences affect the likelihood of being reported and the proportion of being punished of toxic players in the Tribunal.We then propose a supervised learning approach for predicting crowdsourced decisions on toxic behavior with large-scale labeled data collections[2]. Using the same sparse information available to the reviewers, we trained classifiers to detect the presence, and severity of toxicity. We built several models oriented around in-game performance, reports by victims of toxic behavior, and linguistic features of chat messages. We found that training with high agreement decisions resulted in more accuracy on low agreement decisions and that our classifier was adept in detecting clear cut innocence. Finally, we showed that our classifier is relatively robust across cultural regions; our classifier built from a North American dataset performed adequately on a European dataset.Ultimately, our work can be used as a foundation for the further study of toxic behavior.",,,9781450327459,,Association for Computing Machinery ,Proceedings of the 23rd International Conference on World Wide Web ,"online video games, toxic behavior, league of legends, machine learning, crowdsourcing",,
4495,"Title:Convolutional Neural Networks for Toxic Comment Classification

 Flood of information is produced in a daily basis through the global internet usage arising from the online interactive communications among users. While this situation contributes significantly to the quality of human life, unfortunately it involves enormous dangers, since online texts with high toxicity can cause personal attacks, online harassment and bullying behaviors. This has triggered both industrial and research community in the last few years while there are several attempts to identify an efficient model for online toxic comment prediction. However, these steps are still in their infancy and new approaches and frameworks are required. On parallel, the data explosion that appears constantly, makes the construction of new machine learning computational tools for managing this information, an imperative need. Thankfully advances in hardware, cloud computing and big data management allow the development of Deep Learning approaches appearing very promising performance so far. For text classification in particular the use of Convolutional Neural Networks (CNN) have recently been proposed approaching text analytics in a modern manner emphasizing in the structure of words in a document. In this work, we employ this approach to discover toxic comments in a large pool of documents provided by a current Kaggle's competition regarding Wikipedia's talk page edits. To justify this decision we choose to compare CNNs against the traditional bag-of-words approach for text analysis combined with a selection of algorithms proven to be very effective in text classification. The reported results provide enough evidence that CNN enhance toxic comment classification reinforcing research interest towards this direction.","Georgakopoulos SV,Tasoulis SK,Vrahatis AG,Plagianakos VP",,,Convolutional Neural Networks for Toxic Comment Classification,,,10.1145/3200947.3208069 , Conference Paper,2018.0,"Flood of information is produced in a daily basis through the global internet usage arising from the online interactive communications among users. While this situation contributes significantly to the quality of human life, unfortunately it involves enormous dangers, since online texts with high toxicity can cause personal attacks, online harassment and bullying behaviors. This has triggered both industrial and research community in the last few years while there are several attempts to identify an efficient model for online toxic comment prediction. However, these steps are still in their infancy and new approaches and frameworks are required. On parallel, the data explosion that appears constantly, makes the construction of new machine learning computational tools for managing this information, an imperative need. Thankfully advances in hardware, cloud computing and big data management allow the development of Deep Learning approaches appearing very promising performance so far. For text classification in particular the use of Convolutional Neural Networks (CNN) have recently been proposed approaching text analytics in a modern manner emphasizing in the structure of words in a document. In this work, we employ this approach to discover toxic comments in a large pool of documents provided by a current Kaggle's competition regarding Wikipedia's talk page edits. To justify this decision we choose to compare CNNs against the traditional bag-of-words approach for text analysis combined with a selection of algorithms proven to be very effective in text classification. The reported results provide enough evidence that CNN enhance toxic comment classification reinforcing research interest towards this direction.",,,9781450364331,,Association for Computing Machinery ,Proceedings of the 10th Hellenic Conference on Artificial Intelligence ,"Text mining, Text Classification, Toxic Text Classification, word2vec, Word Embeddings, Convolutional Neural Networks, CNN for Text Mining",,
4496,"Title:The Story of Toxic Chemicals in Computing Systems

 Protecting human and environmental health from the effects of toxic chemicals is an element of sustainability efforts and respecting global biophysical limits. Can this goal be achieved with respect to toxic chemicals used in computing systems? It is likely no surprise that achieving this goal is a wicked problem characterized by multiple disciplinary silos, knowledge gaps, competing priorities and vested interests, problems between organizational boundaries, the need to change human behavior and economic imperatives, and the unintended consequences of solutions. This talk unpacks the challenge of protecting human and environmental health with respect to (only) one set of chemicals used in computing systems, namely organic flame retardants (FRs). I chose FRs because they are used in all computing system hardware (e.g., cell phones, computer cases, printed circuit boards, wiring), but they migrate from their source polymer with disposition in global human and ecosystem populations. Studies continue to emerge that link exposure to specific FRs with adverse health effects including loss of IQ points and other neurological and neurobehavioral effects, and reproductive effects.The story unfolds with one family of flame retardants (polybrominated diphenyl ethers or PBDEs) that are found globally in human and ecosystem populations and that have been associated with adverse health impacts. PBDEs were widely used in the exterior cases and wiring of computing systems, as well as other uses such as the foam of upholstered furniture. The major source of human exposure was considered to be foam-containing products. In North America, controls on new uses were implemented for two PBDE formulations in 2004 and a third formulation in 2013 due to their toxicity and persistence. This resulted in decreasing concentrations in most environments with the important exception of those handling a poorly quantified mass of e-waste in developed and developing countries. Here, e-waste will continue to be a source of exposure to PBDEs for at least the next decade. A secondary source of exposure to PBDEs comes from new products (e.g., my plastic kitchen spoons) that were presumably manufactured from recycled PBDE-containing polymers such as computer cases.",Diamond M,,,The Story of Toxic Chemicals in Computing Systems,,,10.1145/3080556.3080570 , Conference Paper,2017.0,"Protecting human and environmental health from the effects of toxic chemicals is an element of sustainability efforts and respecting global biophysical limits. Can this goal be achieved with respect to toxic chemicals used in computing systems? It is likely no surprise that achieving this goal is a wicked problem characterized by multiple disciplinary silos, knowledge gaps, competing priorities and vested interests, problems between organizational boundaries, the need to change human behavior and economic imperatives, and the unintended consequences of solutions. This talk unpacks the challenge of protecting human and environmental health with respect to (only) one set of chemicals used in computing systems, namely organic flame retardants (FRs). I chose FRs because they are used in all computing system hardware (e.g., cell phones, computer cases, printed circuit boards, wiring), but they migrate from their source polymer with disposition in global human and ecosystem populations. Studies continue to emerge that link exposure to specific FRs with adverse health effects including loss of IQ points and other neurological and neurobehavioral effects, and reproductive effects.The story unfolds with one family of flame retardants (polybrominated diphenyl ethers or PBDEs) that are found globally in human and ecosystem populations and that have been associated with adverse health impacts. PBDEs were widely used in the exterior cases and wiring of computing systems, as well as other uses such as the foam of upholstered furniture. The major source of human exposure was considered to be foam-containing products. In North America, controls on new uses were implemented for two PBDE formulations in 2004 and a third formulation in 2013 due to their toxicity and persistence. This resulted in decreasing concentrations in most environments with the important exception of those handling a poorly quantified mass of e-waste in developed and developing countries. Here, e-waste will continue to be a source of exposure to PBDEs for at least the next decade. A secondary source of exposure to PBDEs comes from new products (e.g., my plastic kitchen spoons) that were presumably manufactured from recycled PBDE-containing polymers such as computer cases.",,,9781450349505,,Association for Computing Machinery ,Proceedings of the 2017 Workshop on Computing Within Limits ,keynote talk,,
4497,"Title:Suspecting Sarcasm: How League of Legends Players Dismiss Positive Communication in Toxic Environments

 Toxicity in multiplayer gaming is an ongoing problem that threatens the well-being of players, gaming communities, and game developers. Meanwhile, interventions that promote positive interactions and proactively create positive gaming spaces are still in their infancy; little is known about how players respond to positivity. In our study, 959 League of Legends players were presented with either 10 positive chat logs or 10 negative chat logs, and asked to reflect on the content and how representative such communication is of their own gaming experiences. We thematically coded participants' free-form answers (identifying the themes normalize, acknowledge, downplay, cope, blame, and make personal), and compared the positive and negative conditions in terms of theme prevalence. Our findings show that participants were more likely to normalize and acknowledge toxic negativity than positivity. Furthermore, the dominant response to positivity consisted of downplaying messages as not representative and rare, and even expressing suspicion that messages must have been fabricated or intended as sarcasm. Participants overwhelmingly cope by muting chat, protecting them from toxic interactions, but leaving them unexposed to positive communication and other beneficial social interactions within play.","Poeller S,Dechant MJ,Klarkowski M,Mandryk RL",,,Suspecting Sarcasm: How League of Legends Players Dismiss Positive Communication in Toxic Environments,7,CHI PLAY,10.1145/3611020 , Journal Article,2023.0,"Toxicity in multiplayer gaming is an ongoing problem that threatens the well-being of players, gaming communities, and game developers. Meanwhile, interventions that promote positive interactions and proactively create positive gaming spaces are still in their infancy; little is known about how players respond to positivity. In our study, 959 League of Legends players were presented with either 10 positive chat logs or 10 negative chat logs, and asked to reflect on the content and how representative such communication is of their own gaming experiences. We thematically coded participants' free-form answers (identifying the themes normalize, acknowledge, downplay, cope, blame, and make personal), and compared the positive and negative conditions in terms of theme prevalence. Our findings show that participants were more likely to normalize and acknowledge toxic negativity than positivity. Furthermore, the dominant response to positivity consisted of downplaying messages as not representative and rare, and even expressing suspicion that messages must have been fabricated or intended as sarcasm. Participants overwhelmingly cope by muting chat, protecting them from toxic interactions, but leaving them unexposed to positive communication and other beneficial social interactions within play.",,,,,Association for Computing Machinery Proc.  ACM Hum. -Comput.  Interact., ,"coping, digital games, esports, fair play, positivity, league of legends, thematic coding, toxicity",,
4498,"Title:A New Generation of Perspective API: Efficient Multilingual Character-Level Transformers

 On the world wide web, toxic content detectors are a crucial line of defense against potentially hateful and offensive messages. As such, building highly effective classifiers that enable a safer internet is an important research area. Moreover, the web is a highly multilingual, cross-cultural community that develops its own lingo over time. As such, it is crucial to develop models that are effective across a diverse range of languages, usages, and styles. In this paper, we present the fundamentals behind the next version of the Perspective API from Google Jigsaw. At the heart of the approach is a single multilingual token-free Charformer model that is applicable across a range of languages, domains, and tasks. We demonstrate that by forgoing static vocabularies, we gain flexibility across a variety of settings. We additionally outline the techniques employed to make such a byte-level model efficient and feasible for productionization. Through extensive experiments on multilingual toxic comment classification benchmarks derived from real API traffic and evaluation on an array of code-switching, covert toxicity, emoji-based hate, human-readable obfuscation, distribution shift, and bias evaluation settings, we show that our proposed approach outperforms strong baselines. Finally, we present our findings from deploying this system in production.","Lees A,Tran VQ,Tay Y,Sorensen J,Gupta J,Metzler D,Vasserman L",,,A New Generation of Perspective API: Efficient Multilingual Character-Level Transformers,,,10.1145/3534678.3539147 , Conference Paper,2022.0,"On the world wide web, toxic content detectors are a crucial line of defense against potentially hateful and offensive messages. As such, building highly effective classifiers that enable a safer internet is an important research area. Moreover, the web is a highly multilingual, cross-cultural community that develops its own lingo over time. As such, it is crucial to develop models that are effective across a diverse range of languages, usages, and styles. In this paper, we present the fundamentals behind the next version of the Perspective API from Google Jigsaw. At the heart of the approach is a single multilingual token-free Charformer model that is applicable across a range of languages, domains, and tasks. We demonstrate that by forgoing static vocabularies, we gain flexibility across a variety of settings. We additionally outline the techniques employed to make such a byte-level model efficient and feasible for productionization. Through extensive experiments on multilingual toxic comment classification benchmarks derived from real API traffic and evaluation on an array of code-switching, covert toxicity, emoji-based hate, human-readable obfuscation, distribution shift, and bias evaluation settings, we show that our proposed approach outperforms strong baselines. Finally, we present our findings from deploying this system in production.",,,9781450393850,,Association for Computing Machinery ,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining ,"text classification, moderation, multilingual",,
4499,"Title:Perverse Downstream Consequences of Debunking: Being Corrected by Another User for Posting False Political News Increases Subsequent Sharing of Low Quality, Partisan, and Toxic Content in a Twitter Field Experiment

 A prominent approach to combating online misinformation is to debunk false content. Here we investigate downstream consequences of social corrections on users’ subsequent sharing of other content. Being corrected might make users more attentive to accuracy, thus improving their subsequent sharing. Alternatively, corrections might not improve subsequent sharing - or even backfire - by making users feel defensive, or by shifting their attention away from accuracy (e.g., towards various social factors). We identified N=2,000 users who shared false political news on Twitter, and replied to their false tweets with links to fact-checking websites. We find causal evidence that being corrected decreases the quality, and increases the partisan slant and language toxicity, of the users’ subsequent retweets (but has no significant effect on primary tweets). This suggests that being publicly corrected by another user shifts one's attention away from accuracy - presenting an important challenge for social correction approaches.","Mosleh M,Martel C,Eckles D,Rand D",,,"Perverse Downstream Consequences of Debunking: Being Corrected by Another User for Posting False Political News Increases Subsequent Sharing of Low Quality, Partisan, and Toxic Content in a Twitter Field Experiment",,,10.1145/3411764.3445642 , Conference Paper,2021.0,"A prominent approach to combating online misinformation is to debunk false content. Here we investigate downstream consequences of social corrections on users’ subsequent sharing of other content. Being corrected might make users more attentive to accuracy, thus improving their subsequent sharing. Alternatively, corrections might not improve subsequent sharing - or even backfire - by making users feel defensive, or by shifting their attention away from accuracy (e.g., towards various social factors). We identified N=2,000 users who shared false political news on Twitter, and replied to their false tweets with links to fact-checking websites. We find causal evidence that being corrected decreases the quality, and increases the partisan slant and language toxicity, of the users’ subsequent retweets (but has no significant effect on primary tweets). This suggests that being publicly corrected by another user shifts one's attention away from accuracy - presenting an important challenge for social correction approaches.",,,9781450380966,,Association for Computing Machinery ,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ,"social media, fake news, correction, Misinformation",,
4500,"Title:Agent-Based Simulation of the Diffusion Dynamics and Concentration of Toxic Materials from Quantum Dots-Based Nanoparticles

 Due to their favorable electrical and optical properties, quantum dots (QDs) nanoparticles have found numerous applications including nanomedicine. However, there have been concerns about their potential environmental impacts. The objective of this study is to develop an agent-based simulation model for predicting the diffusion dynamics and concentration of toxic materials released from QDs. Reaction kinetics is used to model the stability of surface capping agent particularly due to oxidation process. The diffusion of toxic Cd2+ ions in aquatic environment was simulated using an adapted Brownian motion algorithm. A calibrated parameter to reflect sensitivity to reaction rate is proposed. The model output demonstrates the stochastic spatial distribution of toxic Cd2+ ions under different values of proxy environmental factor parameters.",Agusdinata DB,,,Agent-Based Simulation of the Diffusion Dynamics and Concentration of Toxic Materials from Quantum Dots-Based Nanoparticles,,, , Conference Paper,2015.0,"Due to their favorable electrical and optical properties, quantum dots (QDs) nanoparticles have found numerous applications including nanomedicine. However, there have been concerns about their potential environmental impacts. The objective of this study is to develop an agent-based simulation model for predicting the diffusion dynamics and concentration of toxic materials released from QDs. Reaction kinetics is used to model the stability of surface capping agent particularly due to oxidation process. The diffusion of toxic Cd2+ ions in aquatic environment was simulated using an adapted Brownian motion algorithm. A calibrated parameter to reflect sensitivity to reaction rate is proposed. The model output demonstrates the stochastic spatial distribution of toxic Cd2+ ions under different values of proxy environmental factor parameters.",,,9781467397414,,IEEE Press ,Proceedings of the 2015 Winter Simulation Conference ,,,
4501,"Title:Medical Training for Echo-Guided Infiltration of Botulinum Toxin by an Echograph Simulator

 Taking self-learning or e-learning as a model and by the application of new technologies, we introduce the software application of an echograph simulator, a very useful tool to nurture knowledge and training of the health professionals, integrating the images taken during echograph exploration with the anatomical knowledge, key for the the infiltration of the botulinum toxin in the treatment context or when addressing spasticity.The application of this echograph simulator allows us to virtually explore muscular groups both of the upper and lower limb, as well as point out the best spots where the correct and precise infiltration of the toxin in the spastic muscle can be done, identifying the structures seen in the echograph. Illustrations of sectioned anatomy taken from nuclear magnetic resonance (RMN) images of the common regions for echo-guided infiltration are included, where the different anatomic structures that comprise them are highlighted.The main objective is to introduce a training tool for the doctor, in order to get a better knowledge grade and better practical skills in the infiltration of the botulinum toxin when dealing with spasticity.","Blasco JN,Hernández PA,Juanes JA,Santos Sánchez JA,Zaballos FH,Rodilla VM,Serrano Rodríguez FJ,Diego BC,Alaejos Fuentes JA",,,Medical Training for Echo-Guided Infiltration of Botulinum Toxin by an Echograph Simulator,,,10.1145/2536536.2536539 , Conference Paper,2013.0,"Taking self-learning or e-learning as a model and by the application of new technologies, we introduce the software application of an echograph simulator, a very useful tool to nurture knowledge and training of the health professionals, integrating the images taken during echograph exploration with the anatomical knowledge, key for the the infiltration of the botulinum toxin in the treatment context or when addressing spasticity.The application of this echograph simulator allows us to virtually explore muscular groups both of the upper and lower limb, as well as point out the best spots where the correct and precise infiltration of the toxin in the spastic muscle can be done, identifying the structures seen in the echograph. Illustrations of sectioned anatomy taken from nuclear magnetic resonance (RMN) images of the common regions for echo-guided infiltration are included, where the different anatomic structures that comprise them are highlighted.The main objective is to introduce a training tool for the doctor, in order to get a better knowledge grade and better practical skills in the infiltration of the botulinum toxin when dealing with spasticity.",,,9781450323451,,Association for Computing Machinery ,Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality ,"spasticity, training, botulinum toxin, e-learning, echograph, simulator",,
4502,"Title:Deep-Learning-Based Automated Scoring for the Severity of Toxic Comments Using Electra

 With the increasing popularity of the Internet, social media plays a crucial role in people's daily communication. However, due to the anonymity of Internet, toxic comments emerge in an endless stream on the Internet, which seriously affects the health of online social environment. To effectively reduce the impact of toxic comments, automated scoring methods for the severity of toxic comments are in great demand. For that purpose, a deep-learning-based natural language processing technique is proposed using ELECTRA to automatically score the toxicity of a comment in this work. The backbone of our model is the ELECTRA discriminator, and the downstream regression task is accomplished by the following head layer. Three head layers are implemented separately: multi-layer perceptron, convolutional neural network, and attention. The dataset used for model training is from the Kaggle competition Toxic Comment Classification Challenge, and the model performance is evaluated through another Kaggle competition Jigsaw Rate Severity of Toxic Comments. By a boost from the K-Fold cross validation and an ensemble of three models with different head layers, our method can reach a competition score 0.80343. Such score ranks 71/2301 (top 3.1%) in the leaderboard and can get a silver medal in the competition. The results in this work would help filter the toxic comments and harmful text information automatically and effectively on the Internet, and could greatly reduce the cost of manual review and help build a healthier Internet environment.",Zhang T,,,Deep-Learning-Based Automated Scoring for the Severity of Toxic Comments Using Electra,,,10.1145/3556677.3556693 , Conference Paper,2022.0,"With the increasing popularity of the Internet, social media plays a crucial role in people's daily communication. However, due to the anonymity of Internet, toxic comments emerge in an endless stream on the Internet, which seriously affects the health of online social environment. To effectively reduce the impact of toxic comments, automated scoring methods for the severity of toxic comments are in great demand. For that purpose, a deep-learning-based natural language processing technique is proposed using ELECTRA to automatically score the toxicity of a comment in this work. The backbone of our model is the ELECTRA discriminator, and the downstream regression task is accomplished by the following head layer. Three head layers are implemented separately: multi-layer perceptron, convolutional neural network, and attention. The dataset used for model training is from the Kaggle competition Toxic Comment Classification Challenge, and the model performance is evaluated through another Kaggle competition Jigsaw Rate Severity of Toxic Comments. By a boost from the K-Fold cross validation and an ensemble of three models with different head layers, our method can reach a competition score 0.80343. Such score ranks 71/2301 (top 3.1%) in the leaderboard and can get a silver medal in the competition. The results in this work would help filter the toxic comments and harmful text information automatically and effectively on the Internet, and could greatly reduce the cost of manual review and help build a healthier Internet environment.",,,9781450396936,,Association for Computing Machinery ,Proceedings of the 2022 6th International Conference on Deep Learning Technologies ,"Kaggle, ELECTRA, Transformer, Toxic comment, Deep learning",,
4503,"Title:Protein and Toxin Profiling at Different Growth Phases of a. Tamiyavanichii and a. Leei

 The naturally occurring phenomenon of harmful algae blooming (HAB) at the water column brought detrimental effects to the economy as well as the environmental health of the water ecosystem. Most cases of HABs reported in Malaysia waters are dominated by dinoflagellates Alexandrium spp. In this study, A. tamiyavanichii and A. leei with different toxicity levels were analyzed using two-dimensional PAGE and HPLC analysis. The growth pattern of both species was identified and compared by using proteomic approaches at each growth phases. Protein expression reduced throughout the growth phases of A. tamiyavanichii but elevated during stationary phase of A. leei. A short duration of stationary phase suggests the continuous expression of growth proteins in A. leei. GNAT family acetyltransferase and lipases were successfully identified enzyme protein in A. tamiyavanichii and A. leei respectively with growth regulatory functions. The toxin profiles of both species exhibited a higher level of toxin content in A. tamiyavanichii with 88 mol % of total toxins recorded as compared to 12 mol% in A. leei. The highest toxin content was recorded during the exponential phase of A. tamiyavanichii with a dominance of GTX4 and STX congeners. Fundamental studies of dinoflagellates from it's molecular as well as byproduct analysis are useful to understand the biochemistry of the HAB species. The findings from this study can provide the basic knowledge on the biochemical properties of HAB species and the behavioral of affected organisms.","Bunnori NM,Hamdan NA,Hassan MS,Hamid SA,Noor NM",,,Protein and Toxin Profiling at Different Growth Phases of a. Tamiyavanichii and a. Leei,,,10.1145/3323716.3323754 , Conference Paper,2019.0,"The naturally occurring phenomenon of harmful algae blooming (HAB) at the water column brought detrimental effects to the economy as well as the environmental health of the water ecosystem. Most cases of HABs reported in Malaysia waters are dominated by dinoflagellates Alexandrium spp. In this study, A. tamiyavanichii and A. leei with different toxicity levels were analyzed using two-dimensional PAGE and HPLC analysis. The growth pattern of both species was identified and compared by using proteomic approaches at each growth phases. Protein expression reduced throughout the growth phases of A. tamiyavanichii but elevated during stationary phase of A. leei. A short duration of stationary phase suggests the continuous expression of growth proteins in A. leei. GNAT family acetyltransferase and lipases were successfully identified enzyme protein in A. tamiyavanichii and A. leei respectively with growth regulatory functions. The toxin profiles of both species exhibited a higher level of toxin content in A. tamiyavanichii with 88 mol % of total toxins recorded as compared to 12 mol% in A. leei. The highest toxin content was recorded during the exponential phase of A. tamiyavanichii with a dominance of GTX4 and STX congeners. Fundamental studies of dinoflagellates from it's molecular as well as byproduct analysis are useful to understand the biochemistry of the HAB species. The findings from this study can provide the basic knowledge on the biochemical properties of HAB species and the behavioral of affected organisms.",,,9781450361040,,Association for Computing Machinery ,"Proceedings of the 8th International Conference on Informatics, Environment, Energy and Applications ","alexandrium spp, acetyltransferase, gonyautoxins, saxitoxins, lipases",,
4504,"Title:Did You Miss My Comment or What?: Understanding Toxicity in Open Source Discussions

 Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.","Miller C,Cohen S,Klug D,Vasilescu B,KaUstner C",,,Did You Miss My Comment or What?: Understanding Toxicity in Open Source Discussions,,,10.1145/3510003.3510111 , Conference Paper,2022.0,"Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.",,,9781450392211,,Association for Computing Machinery ,Proceedings of the 44th International Conference on Software Engineering ,,,
4505,"Title:Clostridium Perfringens Alpha Toxin Inhibits Granulocyte Colony-Stimulating Factor

 Clostridium perfringens is a gram-positive spore-forming anaerobic bacteria. C. perfringens is one of the most common causes of food poisoning illness and has a high mortality rate. As a growth factor, granulocyte colony-stimulating factor helps immune system maintain the balanced numbers of neutrophils when we are infected by pathogens. Clostridium perfringens alpha toxin promotes the formation of G-CSF. During the bacterial infection, lipopolysaccharide (LPS) is sensed through a Toll-like receptor 4 (TLR4) and myeloid differentiation factor 88 (MyD88)-dependent pathway. This leads to the increased secretion of G-CSF into the systemic circulation which accelerated the proliferation and differentiation of neutrophils. However, Clostridium perfringens impairs the granulopoiesis by decreasing the surface expression of neutrophil Ly6G+. The study will use mice, which were separate into positive control groups with C. perfringens injection and negative control group with phosphate-buffered saline. Employing a variety of procedures and methods, in vivo, such as FACS and ELISA, the paper investigates whether C. perfringens alpha toxin would inhibit granulocyte colony-stimulating factor, impairing granulopoiesis and inhibiting G-CSF-mediated cell proliferation of Ly6G+ neutrophils in a productive and effective way.",Shen J,,,Clostridium Perfringens Alpha Toxin Inhibits Granulocyte Colony-Stimulating Factor,,,10.1145/3570773.3570789 , Conference Paper,2022.0,"Clostridium perfringens is a gram-positive spore-forming anaerobic bacteria. C. perfringens is one of the most common causes of food poisoning illness and has a high mortality rate. As a growth factor, granulocyte colony-stimulating factor helps immune system maintain the balanced numbers of neutrophils when we are infected by pathogens. Clostridium perfringens alpha toxin promotes the formation of G-CSF. During the bacterial infection, lipopolysaccharide (LPS) is sensed through a Toll-like receptor 4 (TLR4) and myeloid differentiation factor 88 (MyD88)-dependent pathway. This leads to the increased secretion of G-CSF into the systemic circulation which accelerated the proliferation and differentiation of neutrophils. However, Clostridium perfringens impairs the granulopoiesis by decreasing the surface expression of neutrophil Ly6G+. The study will use mice, which were separate into positive control groups with C. perfringens injection and negative control group with phosphate-buffered saline. Employing a variety of procedures and methods, in vivo, such as FACS and ELISA, the paper investigates whether C. perfringens alpha toxin would inhibit granulocyte colony-stimulating factor, impairing granulopoiesis and inhibiting G-CSF-mediated cell proliferation of Ly6G+ neutrophils in a productive and effective way.",,,9781450398442,,Association for Computing Machinery ,Proceedings of the 3rd International Symposium on Artificial Intelligence for Medicine Sciences ,"Ly6G+, G-CSF, Clostridium perfringens, neutrophils, alpha toxin",,
4506,"Title:A Phylogenetic Study of Monalysin Family of Proteobacterial Pore-Forming Toxins

 In order to thoroughly comprehend the working of a protein to make use of its features in wet lab analysis, a rigorous phylogenetic study is crucial to clarify its origins and better understand its mechanism of working. In this study, the pore-forming proteins belonging to the Monalysin family have been clustered with other families of Proteobacterial pore-forming toxins. The focus of this study has been divided into three stages, each one employing a different parameter to be used as the basis to form the dataset for the phylogenetic tree - multiple alignment, pair-wise alignment with a threshold score, and finally motif analysis. The resultant data was analysed and interpreted; and clear relatedness between the Monalysin, Aerolysin, Cytohemolysin and Channel-Forming Leukocidin Cytotoxin (Ctx) Family, with respect to their binary sequence alignment as well as the presence of the common pore-forming motif, ETX_MTX2 (with the exception of Cytohemolysin), which is found to be characteristic to the Monalysin family, was detected. The phylogenetic trees showed significant variation in their form, clearly illustrating the importance of the criteria used to select the pool of proteins, and depicting the patterns of evolution that led to the development of the characteristic features of the Monalysin family of pore-forming toxins. The results of this study can be made use of in the development of strategic, targeted biological control mechanisms to combat problems faced in various sectors, like agriculture.","Mukundan M,Krishnamurthy S,Chatterjee J",,,A Phylogenetic Study of Monalysin Family of Proteobacterial Pore-Forming Toxins,,,10.1145/3301879.3301898 , Conference Paper,2018.0,"In order to thoroughly comprehend the working of a protein to make use of its features in wet lab analysis, a rigorous phylogenetic study is crucial to clarify its origins and better understand its mechanism of working. In this study, the pore-forming proteins belonging to the Monalysin family have been clustered with other families of Proteobacterial pore-forming toxins. The focus of this study has been divided into three stages, each one employing a different parameter to be used as the basis to form the dataset for the phylogenetic tree - multiple alignment, pair-wise alignment with a threshold score, and finally motif analysis. The resultant data was analysed and interpreted; and clear relatedness between the Monalysin, Aerolysin, Cytohemolysin and Channel-Forming Leukocidin Cytotoxin (Ctx) Family, with respect to their binary sequence alignment as well as the presence of the common pore-forming motif, ETX_MTX2 (with the exception of Cytohemolysin), which is found to be characteristic to the Monalysin family, was detected. The phylogenetic trees showed significant variation in their form, clearly illustrating the importance of the criteria used to select the pool of proteins, and depicting the patterns of evolution that led to the development of the characteristic features of the Monalysin family of pore-forming toxins. The results of this study can be made use of in the development of strategic, targeted biological control mechanisms to combat problems faced in various sectors, like agriculture.",,,9781450365611,,Association for Computing Machinery ,Proceedings of the 2018 5th International Conference on Biomedical and Bioinformatics Engineering ,"motif analysis, Proteobacteria, Phylogenetics, Monalysin, homology search, Pore-forming toxins, protein sequence alignment, binary alignment",,
4507,"Title:Character-Level Chinese Toxic Comment Classification Algorithm Based on CNN and Bi-GRU

 At present, the classification of “toxic comment” is mainly studied in the English context, whereas Chinese context is less explored and even lacks a public corpus. As many comment are short texts with sparse features and strong context dependence, this study proposes a character-level embedded neural network model based on the convolutional neural network (CNN) and bidirectional gated recurrent unit (Bi-GRU). Then, the classification of toxic comment based on the Chinese toxic comment dataset is developed. In our proposed model, the CNN, which combines character- and word-level vectors, is used to fully obtain the local important features of the text, and then the bidirectional timing information acquisition ability of Bi-GRU is used to improve the accuracy of the Chinese toxic comment classification. Experimental results show that the F1 score of our proposed model can reach 0.8081, which is better than the correlation comparison models.","Zhang B,Wang Z",,,Character-Level Chinese Toxic Comment Classification Algorithm Based on CNN and Bi-GRU,,,10.1145/3569966.3570000 , Conference Paper,2022.0,"At present, the classification of “toxic comment” is mainly studied in the English context, whereas Chinese context is less explored and even lacks a public corpus. As many comment are short texts with sparse features and strong context dependence, this study proposes a character-level embedded neural network model based on the convolutional neural network (CNN) and bidirectional gated recurrent unit (Bi-GRU). Then, the classification of toxic comment based on the Chinese toxic comment dataset is developed. In our proposed model, the CNN, which combines character- and word-level vectors, is used to fully obtain the local important features of the text, and then the bidirectional timing information acquisition ability of Bi-GRU is used to improve the accuracy of the Chinese toxic comment classification. Experimental results show that the F1 score of our proposed model can reach 0.8081, which is better than the correlation comparison models.",,,9781450397780,,Association for Computing Machinery ,Proceedings of the 5th International Conference on Computer Science and Software Engineering ,"Bi-GRU, CNN, Chinese toxic comment, Character level",,
4508,"Title:Toxic Comment Classification Based on Bidirectional Gated Recurrent Unit and Convolutional Neural Network

 For English toxic comment classification, this paper presents the model that combines Bi-GRU and CNN optimized by global average pooling (BG-GCNN) based on the bidirectional gated recurrent unit (Bi-GRU) and global pooling optimized convolution neural network (CNN). The model treats each type of toxic comment as a binary classification. First, Bi-GRU is used to extract the time-series features of the comment and then the dimensionality is reduced through global pooling optimized convolution neural network. Finally, the classification result is output by Sigmoid function. Comparative experiments show the BG-GCNN model has a better classification effect than Text-CNN, LSTM, Bi-GRU, and other models. The Macro-F1 value of the toxic comment dataset on the Kaggle competition platform is 0.62. The F1 values of the three toxic label classification results (toxic, obscene, and insult label) are 0.81, 0.84, and 0.74, respectively, which are the highest values in the comparative experiment.","Wang Z,Zhang B",,,Toxic Comment Classification Based on Bidirectional Gated Recurrent Unit and Convolutional Neural Network,21,3,10.1145/3488366 , Journal Article,2021.0,"For English toxic comment classification, this paper presents the model that combines Bi-GRU and CNN optimized by global average pooling (BG-GCNN) based on the bidirectional gated recurrent unit (Bi-GRU) and global pooling optimized convolution neural network (CNN). The model treats each type of toxic comment as a binary classification. First, Bi-GRU is used to extract the time-series features of the comment and then the dimensionality is reduced through global pooling optimized convolution neural network. Finally, the classification result is output by Sigmoid function. Comparative experiments show the BG-GCNN model has a better classification effect than Text-CNN, LSTM, Bi-GRU, and other models. The Macro-F1 value of the toxic comment dataset on the Kaggle competition platform is 0.62. The F1 values of the three toxic label classification results (toxic, obscene, and insult label) are 0.81, 0.84, and 0.74, respectively, which are the highest values in the comparative experiment.",2375-4699,,,,Association for Computing Machinery ACM Trans. Asian Low-Resour. Lang. Inf. Process., ,"convolution neural network, bidirectional gated recurrent unit, global pooling, Toxic comments classification",,
4509,"Title:Studying Toxic Behavior Influence and Player Chat in an Online Video Game

 Many online collaborative games, e-sports in particular, heavily rely on teamwork. However, players can act in an antisocial way during the match, creating dissent into the match. This kind of behavior is referred to as toxic. We aim to discover the influence brought by toxic behavior in a popular e-sport, League of Legends, through the study of communication patterns of players during the match. We discovered that different communication patterns exist, and that they are directly related to player performance and level of toxic behavior. We also propose metrics to analyze players' performance and the toxic contamination level, which measures the negative impacts of the toxic behavior. Our analysis contributes to shed light on how players behave in an online game, and opens ways to provide a better ambience on the online video game community.","Neto JA,Yokoyama KM,Becker K",,,Studying Toxic Behavior Influence and Player Chat in an Online Video Game,,,10.1145/3106426.3106452 , Conference Paper,2017.0,"Many online collaborative games, e-sports in particular, heavily rely on teamwork. However, players can act in an antisocial way during the match, creating dissent into the match. This kind of behavior is referred to as toxic. We aim to discover the influence brought by toxic behavior in a popular e-sport, League of Legends, through the study of communication patterns of players during the match. We discovered that different communication patterns exist, and that they are directly related to player performance and level of toxic behavior. We also propose metrics to analyze players' performance and the toxic contamination level, which measures the negative impacts of the toxic behavior. Our analysis contributes to shed light on how players behave in an online game, and opens ways to provide a better ambience on the online video game community.",,,9781450349512,,Association for Computing Machinery ,Proceedings of the International Conference on Web Intelligence ,"toxic behavior, text mining, online games, league of legends",,
4510,"Title:Understanding the Behaviors of Toxic Accounts on Reddit

 Toxic comments are the top form of hate and harassment experienced online. While many studies have investigated the types of toxic comments posted online, the effects that such content has on people, and the impact of potential defenses, no study has captured the behaviors of the accounts that post toxic comments or how such attacks are operationalized. In this paper, we present a measurement study of 929K accounts that post toxic comments on Reddit over an 18 month period. Combined, these accounts posted over 14 million toxic comments that encompass insults, identity attacks, threats of violence, and sexual harassment. We explore the impact that these accounts have on Reddit, the targeting strategies that abusive accounts adopt, and the distinct patterns that distinguish classes of abusive accounts. Our analysis informs the nuanced interventions needed to curb unwanted toxic behaviors online.","Kumar D,Hancock J,Thomas K,Durumeric Z",,,Understanding the Behaviors of Toxic Accounts on Reddit,,,10.1145/3543507.3583522 , Conference Paper,2023.0,"Toxic comments are the top form of hate and harassment experienced online. While many studies have investigated the types of toxic comments posted online, the effects that such content has on people, and the impact of potential defenses, no study has captured the behaviors of the accounts that post toxic comments or how such attacks are operationalized. In this paper, we present a measurement study of 929K accounts that post toxic comments on Reddit over an 18 month period. Combined, these accounts posted over 14 million toxic comments that encompass insults, identity attacks, threats of violence, and sexual harassment. We explore the impact that these accounts have on Reddit, the targeting strategies that abusive accounts adopt, and the distinct patterns that distinguish classes of abusive accounts. Our analysis informs the nuanced interventions needed to curb unwanted toxic behaviors online.",,,9781450394161,,Association for Computing Machinery ,Proceedings of the ACM Web Conference 2023 ,,,
4511,"Title:Exploring Cyberbullying and Other Toxic Behavior in Team Competition Online Games

 In this work we explore cyberbullying and other toxic behavior in team competition online games. Using a dataset of over 10 million player reports on 1.46 million toxic players along with corresponding crowdsourced decisions, we test several hypotheses drawn from theories explaining toxic behavior. Besides providing large-scale, empirical based understanding of toxic behavior, our work can be used as a basis for building systems to detect, prevent, and counter-act toxic behavior.","Kwak H,Blackburn J,Han S",,,Exploring Cyberbullying and Other Toxic Behavior in Team Competition Online Games,,,10.1145/2702123.2702529 , Conference Paper,2015.0,"In this work we explore cyberbullying and other toxic behavior in team competition online games. Using a dataset of over 10 million player reports on 1.46 million toxic players along with corresponding crowdsourced decisions, we test several hypotheses drawn from theories explaining toxic behavior. Besides providing large-scale, empirical based understanding of toxic behavior, our work can be used as a basis for building systems to detect, prevent, and counter-act toxic behavior.",,,9781450331456,,Association for Computing Machinery ,Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems ,"toxic playing, team competition, trolling, league of legends, crowdsourcing, cyberbullying, moba, online video game",,
4512,"Title:A Comparative Study of Using Pre-Trained Language Models for Toxic Comment Classification

 As user-generated contents thrive, so does the spread of toxic comment. Therefore, detecting toxic comment becomes an active research area, and it is often handled as a text classification task. As recent popular methods for text classification tasks, pre-trained language model-based methods are at the forefront of natural language processing, achieving state-of-the-art performance on various NLP tasks. However, there is a paucity in studies using such methods on toxic comment classification. In this work, we study how to best make use of pre-trained language model-based methods for toxic comment classification and the performances of different pre-trained language models on these tasks. Our results show that, Out of the three most popular language models, i.e. BERT, RoBERTa, and XLM, BERT and RoBERTa generally outperform XLM on toxic comment classification. We also prove that using a basic linear downstream structure outperforms complex ones such as CNN and BiLSTM. What is more, we find that further fine-tuning a pre-trained language model with light hyper-parameter settings brings improvements to the downstream toxic comment classification task, especially when the task has a relatively small dataset.","Zhao Z,Zhang Z,Hopfgartner F",,,A Comparative Study of Using Pre-Trained Language Models for Toxic Comment Classification,,,10.1145/3442442.3452313 , Conference Paper,2021.0,"As user-generated contents thrive, so does the spread of toxic comment. Therefore, detecting toxic comment becomes an active research area, and it is often handled as a text classification task. As recent popular methods for text classification tasks, pre-trained language model-based methods are at the forefront of natural language processing, achieving state-of-the-art performance on various NLP tasks. However, there is a paucity in studies using such methods on toxic comment classification. In this work, we study how to best make use of pre-trained language model-based methods for toxic comment classification and the performances of different pre-trained language models on these tasks. Our results show that, Out of the three most popular language models, i.e. BERT, RoBERTa, and XLM, BERT and RoBERTa generally outperform XLM on toxic comment classification. We also prove that using a basic linear downstream structure outperforms complex ones such as CNN and BiLSTM. What is more, we find that further fine-tuning a pre-trained language model with light hyper-parameter settings brings improvements to the downstream toxic comment classification task, especially when the task has a relatively small dataset.",,,9781450383134,,Association for Computing Machinery ,Companion Proceedings of the Web Conference 2021 ,"XLM, pre-training, toxic comment, fine-tuning, BERT, language model, RoBERTa, neural networks, hate speech",,
4513,"Title:Topic Enhanced Word Embedding for Toxic Content Detection in Q&A Sites

 Increasingly, users are adopting community question-and-answer (Q&A) sites to exchange information. Detecting and eliminating toxic and divisive content in these Q&A sites are paramount tasks to ensure a safe and constructive environment for the users. Insincere question, which is founded upon false premises, is one type of toxic content in Q&A sites. In this paper, we proposed a novel deep learning framework enhanced pre-trained word embeddings with topical information for insincere question classification. We evaluated our proposed framework on a large real-world dataset from Quora Q&A site and showed that the topically enhanced word embedding is able to achieve better results in toxic content classification. An empirical study was also conducted to analyze the topics of the insincere questions on Quora, and we found that topics on religion, gender and politics has a higher proportion of insincere questions.","Kim Y,Li X,Wang S,Zhuo Y,Lee RK",,,Topic Enhanced Word Embedding for Toxic Content Detection in Q&A Sites,,,10.1145/3341161.3345332 , Conference Paper,2020.0,"Increasingly, users are adopting community question-and-answer (Q&A) sites to exchange information. Detecting and eliminating toxic and divisive content in these Q&A sites are paramount tasks to ensure a safe and constructive environment for the users. Insincere question, which is founded upon false premises, is one type of toxic content in Q&A sites. In this paper, we proposed a novel deep learning framework enhanced pre-trained word embeddings with topical information for insincere question classification. We evaluated our proposed framework on a large real-world dataset from Quora Q&A site and showed that the topically enhanced word embedding is able to achieve better results in toxic content classification. An empirical study was also conducted to analyze the topics of the insincere questions on Quora, and we found that topics on religion, gender and politics has a higher proportion of insincere questions.",,,9781450368681,,Association for Computing Machinery ,Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining ,"sequence model, toxic content, NLP, text classification, word embedding",,
4514,"Title:Preconditioned Random Forest Regression: Application to Genome-Wide Study for Radiotherapy Toxicity Prediction

 Urinary toxicity after radiotherapy (RT) limits the quality of life of prostate cancer patients, and clinically actionable prediction has yet to be achieved. We aim to exploit genome-wide variants to accurately identify patients at higher congenital toxicity risk. We applied preconditioned random forest regression (PRFR) to predict four urinary symptoms. For a weak stream endpoint, the PRFR model achieved an area under the curve (AUC) of 0.7 on holdout validation. Preconditioning enhanced the performance of random forest. Gene ontology (GO) analysis showed that neurogenic biological processes are associated with the toxicity. Upon further validation, the predictive model can be used to potentially benefit the health of prostate cancer patients treated with radiotherapy.","Lee S,Kerns S,Rosenstein B,Ostrer H,Deasy JO,Oh JH",,,Preconditioned Random Forest Regression: Application to Genome-Wide Study for Radiotherapy Toxicity Prediction,,,10.1145/3107411.3108201 , Conference Paper,2017.0,"Urinary toxicity after radiotherapy (RT) limits the quality of life of prostate cancer patients, and clinically actionable prediction has yet to be achieved. We aim to exploit genome-wide variants to accurately identify patients at higher congenital toxicity risk. We applied preconditioned random forest regression (PRFR) to predict four urinary symptoms. For a weak stream endpoint, the PRFR model achieved an area under the curve (AUC) of 0.7 on holdout validation. Preconditioning enhanced the performance of random forest. Gene ontology (GO) analysis showed that neurogenic biological processes are associated with the toxicity. Upon further validation, the predictive model can be used to potentially benefit the health of prostate cancer patients treated with radiotherapy.",,,9781450347228,,Association for Computing Machinery ,"Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics ","random forests, genome wide association studies, radiotherapy",,
4515,"Title:Optimal Intra-Dialytic Exercise Protocol for Improving the Toxin Removal in Hemodialysis Patients

 In this paper, we present the simulation studies to illustrate the benefits of optimal intra-dialytic exercise to improve the toxin removal using the diffusion-adjusted regional blood flow (DA-RBF) model developed by Schneditz et al. To optimize the exercise effect, two exercise-related parameters, i.e. the inter-compartmental mass transfer coefficient (KC), cardiac output (QC), and time of implementation for 3 bouts of exercise (t1, t2, and t3) were considered as decision variables. A control vector parameterization method was used to optimize a realistic intra-dialytic exercise profile. During exercise, QC and KC were allowed to vary between their nominal values and 100% and 400% increase, respectively. Initial simulation suggested that during exercise, QC and KC reaches their maximum permissible values, thus only timings of exercise implementation were considered as decision variables in optimization. Results from the simulation study reveal that during the 3 bouts of optimal intermittent exercise, remotely sequestered solutes can be removed from the low flow region. As such, more toxins are removed in the dialyzer which consistently results in a decrease in percentage rebound (indicator of increased toxin removal) during the post-dialysis period for both urea and creatinine.","Ahmad Y,Maheshwari V,Rangaiah GP,Leong TL,Samavedham L",,,Optimal Intra-Dialytic Exercise Protocol for Improving the Toxin Removal in Hemodialysis Patients,,, , Conference Paper,2012.0,"In this paper, we present the simulation studies to illustrate the benefits of optimal intra-dialytic exercise to improve the toxin removal using the diffusion-adjusted regional blood flow (DA-RBF) model developed by Schneditz et al. To optimize the exercise effect, two exercise-related parameters, i.e. the inter-compartmental mass transfer coefficient (KC), cardiac output (QC), and time of implementation for 3 bouts of exercise (t1, t2, and t3) were considered as decision variables. A control vector parameterization method was used to optimize a realistic intra-dialytic exercise profile. During exercise, QC and KC were allowed to vary between their nominal values and 100% and 400% increase, respectively. Initial simulation suggested that during exercise, QC and KC reaches their maximum permissible values, thus only timings of exercise implementation were considered as decision variables in optimization. Results from the simulation study reveal that during the 3 bouts of optimal intermittent exercise, remotely sequestered solutes can be removed from the low flow region. As such, more toxins are removed in the dialyzer which consistently results in a decrease in percentage rebound (indicator of increased toxin removal) during the post-dialysis period for both urea and creatinine.",,,9789810726638,,"Singapore Therapeutic, Assistive & Rehabilitative Technologies (START) Centre ",Proceedings of the 6th International Conference on Rehabilitation Engineering & Assistive Technology ,"inter-compartmental clearance, cardiac output, hemodiafiltration, intra-dialytic exercise, DA-RBF model, creatinine rebound, urea rebound",,
4516,"Title:Exploring the Relationship Between Offline Cultural Environments and Toxic Behavior Tendencies in Multiplayer Online Games

 In multiplayer online games, players from different cultural backgrounds come together to cooperate and compete in real time. Although these games are enjoyed by billions of players globally, behavioral issues such as toxic behavior (TB) have become rampant in some games, perhaps most infamously in multiplayer online battle arena (MOBA) games, such as League of Legends and Dota 2. A crucial step in curbing TB lies in understanding its drivers and antecedents. In the present work, we contribute to this field of research by considering the regional offline cultural environment in which players live. We draw both on Hofstede's Cultural Dimension Framework and on Kordyaka et al.’s Unified Theory of Toxic Behavior (UTTB) to compare two cross-sectional samples of MOBA players: one from North America (n = 155) and one from India (n = 119). Our analysis reveals significant differences between the samples for all UTTB variables. Additional analyses also indicate the relevance of national culture in relation to other dispositions (i.e., age) and characteristics (i.e., game-related culture). Our findings underscore the role that the offline cultural environments play in TB in MOBAs and additionally open avenues for further research that takes dimensions of national culture in the study of online behavior into account.","Kordyaka B,Park S,Krath J,Laato S",,,Exploring the Relationship Between Offline Cultural Environments and Toxic Behavior Tendencies in Multiplayer Online Games,6,1–2,10.1145/3580346 , Journal Article,2023.0,"In multiplayer online games, players from different cultural backgrounds come together to cooperate and compete in real time. Although these games are enjoyed by billions of players globally, behavioral issues such as toxic behavior (TB) have become rampant in some games, perhaps most infamously in multiplayer online battle arena (MOBA) games, such as League of Legends and Dota 2. A crucial step in curbing TB lies in understanding its drivers and antecedents. In the present work, we contribute to this field of research by considering the regional offline cultural environment in which players live. We draw both on Hofstede's Cultural Dimension Framework and on Kordyaka et al.’s Unified Theory of Toxic Behavior (UTTB) to compare two cross-sectional samples of MOBA players: one from North America (n = 155) and one from India (n = 119). Our analysis reveals significant differences between the samples for all UTTB variables. Additional analyses also indicate the relevance of national culture in relation to other dispositions (i.e., age) and characteristics (i.e., game-related culture). Our findings underscore the role that the offline cultural environments play in TB in MOBAs and additionally open avenues for further research that takes dimensions of national culture in the study of online behavior into account.",,,,,Association for Computing Machinery Trans. Soc. Comput., ,"multiplayer video games, toxic behavior, Empirical studies in HCI, cultural characteristics",,
4517,"Title:Protecting Chatbots from Toxic Content

 There is a paradigm shift in web-based services towards conversational user interfaces. Companies increasingly offer conversational interfaces, or chatbots, to let their customers or employees interact with their services in a more flexible and mobile manner. Unfortunately, this new paradigm faces a major problem, namely toxic content in user inputs. Toxic content in user inputs to chatbots may cause privacy concerns, may be adversarial or malicious, and can cause the chatbot provider substantial economic, reputational, or legal harm. We address this problem with an interdisciplinary approach, drawing upon programming languages, cloud computing, and other disciplines to build protections for chatbots. Our solution, called BotShield, is non-intrusive in that it does not require changes to existing chatbots or underlying conversational platforms. This paper introduces novel security mechanisms, articulates their security guarantees, and illustrates them via case studies.","Baudart G,Dolby J,Duesterwald E,Hirzel M,Shinnar A",,,Protecting Chatbots from Toxic Content,,,10.1145/3276954.3276958 , Conference Paper,2018.0,"There is a paradigm shift in web-based services towards conversational user interfaces. Companies increasingly offer conversational interfaces, or chatbots, to let their customers or employees interact with their services in a more flexible and mobile manner. Unfortunately, this new paradigm faces a major problem, namely toxic content in user inputs. Toxic content in user inputs to chatbots may cause privacy concerns, may be adversarial or malicious, and can cause the chatbot provider substantial economic, reputational, or legal harm. We address this problem with an interdisciplinary approach, drawing upon programming languages, cloud computing, and other disciplines to build protections for chatbots. Our solution, called BotShield, is non-intrusive in that it does not require changes to existing chatbots or underlying conversational platforms. This paper introduces novel security mechanisms, articulates their security guarantees, and illustrates them via case studies.",,,9781450360319,,Association for Computing Machinery ,"Proceedings of the 2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software ","Chatbot, Homomorphic Redaction, Context Digression",,
4518,"Title:ToxinMI: Improving Peptide Toxicity Prediction by Fusing Multimodal Information Based on Mutual Information

 Accurately identifying peptide toxicity is a crucial step for computer-aided peptide-based drug screening, which could accelerate novel drug discovery and reduce resource consumption. Recently, deep learning has shown promising performance in bioinformatics. However, one challenge in developing a deep learning-based model for peptide toxicity prediction is how to represent peptides effectively. In this study, we propose an end-to-end deep learning model named ToxinMI, to predict peptide toxicity that learns features directly from sequence alone. Precisely, ToxinMI captures the sequential and evolutionary features of the peptide simultaneously and introduces the mutual information principle to learn a discriminative representation by discarding noisy information and retaining related-task information from them as much as possible. The experimental results demonstrate that ToxinMI achieves superior predictive performance against state-of-the-art baselines.1","Wei L,Ye X,Sakurai T",,,ToxinMI: Improving Peptide Toxicity Prediction by Fusing Multimodal Information Based on Mutual Information,,,10.1145/3538641.3561492 , Conference Paper,2022.0,"Accurately identifying peptide toxicity is a crucial step for computer-aided peptide-based drug screening, which could accelerate novel drug discovery and reduce resource consumption. Recently, deep learning has shown promising performance in bioinformatics. However, one challenge in developing a deep learning-based model for peptide toxicity prediction is how to represent peptides effectively. In this study, we propose an end-to-end deep learning model named ToxinMI, to predict peptide toxicity that learns features directly from sequence alone. Precisely, ToxinMI captures the sequential and evolutionary features of the peptide simultaneously and introduces the mutual information principle to learn a discriminative representation by discarding noisy information and retaining related-task information from them as much as possible. The experimental results demonstrate that ToxinMI achieves superior predictive performance against state-of-the-art baselines.1",,,9781450393980,,Association for Computing Machinery ,Proceedings of the Conference on Research in Adaptive and Convergent Systems ,"peptide toxicity prediction, mutual information, multi-modal information",,
4519,"Title:Toxic Communication during Streams on Twitch.Tv. The Case of Dota 2

 This paper is devoted to the study of how toxic communication is structured in chats during streams on Twitch.tv and how chat size affects it. The data from Twitch chat logs was used to create a topic model of themes which are discussed by viewers during stream. The result indicate that there are statistically significant differences in the types of communication used in channels of different sizes.",Poyane R,,,Toxic Communication during Streams on Twitch.Tv. The Case of Dota 2,,,10.1145/3275116.3275152 , Conference Paper,2018.0,This paper is devoted to the study of how toxic communication is structured in chats during streams on Twitch.tv and how chat size affects it. The data from Twitch chat logs was used to create a topic model of themes which are discussed by viewers during stream. The result indicate that there are statistically significant differences in the types of communication used in channels of different sizes.,,,9781450365895,,Association for Computing Machinery ,Proceedings of the 22nd International Academic Mindtrek Conference ,"toxic communication, Dota 2, streaming, Twitch",,
4520,"Title:Sleep Scheduling with Toxic Gas Coverage Requirement in Large-Scale Industry: Poster Abstract

 In this article, we address a sleep scheduling scheme that ensures a coverage degree requirement based on the dangerous levels of the toxic gas leakage area, while maintaining the global network connectivity with minimal awake-nodes compared to other schemes that increase the number of awake-nodes over the entire network.","Mukherjee M,Shu L,Chen Y",,,Sleep Scheduling with Toxic Gas Coverage Requirement in Large-Scale Industry: Poster Abstract,,, , Conference Paper,2016.0,"In this article, we address a sleep scheduling scheme that ensures a coverage degree requirement based on the dangerous levels of the toxic gas leakage area, while maintaining the global network connectivity with minimal awake-nodes compared to other schemes that increase the number of awake-nodes over the entire network.",,,9781509008025,,IEEE Press ,Proceedings of the 15th International Conference on Information Processing in Sensor Networks ,,,
4521,"Title:Towards a Multimodel Approach for Simulation of Crowd Behaviour under Fire and Toxic Gas Expansion in Buildings

 A holistic approach for the simulation of evacuations from buildings in cases of fire and toxic gas spread is developed within the German project iSiGG to achieve high reliability in fire safety planning. Its essence is in the mutual interaction of the domains of crowd simulation, pollutant gas spread simulation (CFD) and Building Information Modeling (BIM), embedded in a coherent IT system. The conceptual basis of this system is provided by a dynamic multimodel ensuring interoperability of all system components and supplying simulation tasks with the necessary building and environmental data. More importantly, it allows to take into account various possible changes of the state of building elements, which may be caused by inhabitants or by the building control systems and can lead to strong changes in the simulation models. The simulations themselves are coupled on numerical level through a shared Voxel Model in a co-simulation approach.","Scherer RJ,Luu NT,Katranuschkov P,Spieckermann S,Habenicht I,Protopsaltis B,Pappou T",,,Towards a Multimodel Approach for Simulation of Crowd Behaviour under Fire and Toxic Gas Expansion in Buildings,,, , Conference Paper,2018.0,"A holistic approach for the simulation of evacuations from buildings in cases of fire and toxic gas spread is developed within the German project iSiGG to achieve high reliability in fire safety planning. Its essence is in the mutual interaction of the domains of crowd simulation, pollutant gas spread simulation (CFD) and Building Information Modeling (BIM), embedded in a coherent IT system. The conceptual basis of this system is provided by a dynamic multimodel ensuring interoperability of all system components and supplying simulation tasks with the necessary building and environmental data. More importantly, it allows to take into account various possible changes of the state of building elements, which may be caused by inhabitants or by the building control systems and can lead to strong changes in the simulation models. The simulations themselves are coupled on numerical level through a shared Voxel Model in a co-simulation approach.",,,,,IEEE Press ,Proceedings of the 2018 Winter Simulation Conference ,,,
4522,"Title:Risk Analysis Toxic Materials Borax and Rhodamine-B in Snack Against Primary School Children's Health in Housing Area of Tamalanrea Permai Makassar

 This research aimed to investigate the risks of borax toxic materials and rhodamine-B in snack against the health of the Primary School Pupils in Perumahan Bumi Tamalanrea Permai Makassar.The research type was an observational research with the design of the Environment Health Risk Analysis (EHRA). The samples of the subjects comprised 107 pupils and the samples of objects comprised 7 types of traditional snack. The data collection was carried out with examining the samples in laboratory and through interviews and the direct measurement or respondents.The research results indicated that the snack sold in the area of SD Inpres Tamalanrea I and SD Inpres Tamalanrea V was free of borax. However, some of the snack sold in the area of SD Inpres Tamalanrea I and SD Inpres Tamalanrea V still contained Rhodamine-B, such as doger ice (0,5840 mg/L) and print ice (24,587 mg/L) taken from SD Inpres Tamalanrea I, and crackers (58,534 mg/L) taken from SD Inpres Tamalanrea V. The primary school pupils who had the highest intake were those pupils who consumed crackers containing Rhodamine-B from SD Inpres Tamalanrea V, which was 7,839 mg/kg/day, while the pupils who had the lowest intake were the pupils who cosumed doger ice containing borax from SD Inpres Tamalnrea I, which was 0,2067 mg/kg/day. Based on the result of the RQ calculation, the Rhodamine-B content in the snack against the health of the primary school pupils in Perumahan Bumi Tamalanrea Permai indicated that each of the samples containing the Rhodamine-B had the RQ value > 1. Meaning it had a risk against the children who consumed it..","Kurniawan AV,Daud A,Sirajuddin S",,,Risk Analysis Toxic Materials Borax and Rhodamine-B in Snack Against Primary School Children's Health in Housing Area of Tamalanrea Permai Makassar,,,10.1145/3242789.3242795 , Conference Paper,2018.0,"This research aimed to investigate the risks of borax toxic materials and rhodamine-B in snack against the health of the Primary School Pupils in Perumahan Bumi Tamalanrea Permai Makassar.The research type was an observational research with the design of the Environment Health Risk Analysis (EHRA). The samples of the subjects comprised 107 pupils and the samples of objects comprised 7 types of traditional snack. The data collection was carried out with examining the samples in laboratory and through interviews and the direct measurement or respondents.The research results indicated that the snack sold in the area of SD Inpres Tamalanrea I and SD Inpres Tamalanrea V was free of borax. However, some of the snack sold in the area of SD Inpres Tamalanrea I and SD Inpres Tamalanrea V still contained Rhodamine-B, such as doger ice (0,5840 mg/L) and print ice (24,587 mg/L) taken from SD Inpres Tamalanrea I, and crackers (58,534 mg/L) taken from SD Inpres Tamalanrea V. The primary school pupils who had the highest intake were those pupils who consumed crackers containing Rhodamine-B from SD Inpres Tamalanrea V, which was 7,839 mg/kg/day, while the pupils who had the lowest intake were the pupils who cosumed doger ice containing borax from SD Inpres Tamalnrea I, which was 0,2067 mg/kg/day. Based on the result of the RQ calculation, the Rhodamine-B content in the snack against the health of the primary school pupils in Perumahan Bumi Tamalanrea Permai indicated that each of the samples containing the Rhodamine-B had the RQ value > 1. Meaning it had a risk against the children who consumed it..",,,9781450364355,,Association for Computing Machinery ,Proceedings of the International Conference on Healthcare Service Management 2018 ,"Borax, health, Snack, Rhodamine-B",,
4523,"Title:The Systems Toxicology Challenge: How to Leverage Omics Data to Predict Mechanisms of Toxicity?

 Risk assessment in the context of 21st century toxicology relies on the elucidation and understanding of mechanisms of toxicity. For that purpose, datasets generated by high-throughput technologies (e.g., high-throughput/content screening) combined with various omics data types are now generated in vitro to test large and diverse set of chemicals (e.g. ToxCast). The development of relevant computational approaches for the analysis and integration of these big data remains challenging and requires qualitative and quantitative evaluation. The current scope of sbv IMPROVER (Industrial Methodology for Process Verification in Research; http://sbvimprover.com) is the verification of methods and concepts in systems biology research via challenges opened to the scientific community. Previous challenges brought new insights on methods and their associated results that address questions about diagnostic signatures, the translatability of biological responses/processes across species, and the relevance of biological causal network models. A new sbv IMPROVER challenge will be introduced aiming at evaluating (i) methodologies for the identification of specific biomarkers of exposure and (ii) the predictability by omics data of toxicity mechanisms when cells/tissues in vitro or whole organisms are exposed to individual chemical molecules or mixtures. Participants will be provided with high quality data sets to develop predictive models/classifiers. For this challenge, the integration of a priori biological knowledge in the development of computational approaches may be required to enable biological interpretability/understanding of the predictions. The results and post-challenge analyses will be shared with the scientific community, and will open new avenues in the field of systems toxicology.","Ivanov NV,Poussin C,Boué S,Martin F,Sewer A,Titz B,Peitsch MC,Hoeng J",,,The Systems Toxicology Challenge: How to Leverage Omics Data to Predict Mechanisms of Toxicity?,,,10.1145/2808719.2811421 , Conference Paper,2015.0,"Risk assessment in the context of 21st century toxicology relies on the elucidation and understanding of mechanisms of toxicity. For that purpose, datasets generated by high-throughput technologies (e.g., high-throughput/content screening) combined with various omics data types are now generated in vitro to test large and diverse set of chemicals (e.g. ToxCast). The development of relevant computational approaches for the analysis and integration of these big data remains challenging and requires qualitative and quantitative evaluation. The current scope of sbv IMPROVER (Industrial Methodology for Process Verification in Research; http://sbvimprover.com) is the verification of methods and concepts in systems biology research via challenges opened to the scientific community. Previous challenges brought new insights on methods and their associated results that address questions about diagnostic signatures, the translatability of biological responses/processes across species, and the relevance of biological causal network models. A new sbv IMPROVER challenge will be introduced aiming at evaluating (i) methodologies for the identification of specific biomarkers of exposure and (ii) the predictability by omics data of toxicity mechanisms when cells/tissues in vitro or whole organisms are exposed to individual chemical molecules or mixtures. Participants will be provided with high quality data sets to develop predictive models/classifiers. For this challenge, the integration of a priori biological knowledge in the development of computational approaches may be required to enable biological interpretability/understanding of the predictions. The results and post-challenge analyses will be shared with the scientific community, and will open new avenues in the field of systems toxicology.",,,9781450338530,,Association for Computing Machinery ,"Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics ","Sbv IMPROVER, omics, systems biology, systems toxicology",,
4524,"Title:Fluid Transformers and Creative Analogies: Exploring Large Language Models’ Capacity for Augmenting Cross-Domain Analogical Creativity

 Cross-domain analogical reasoning is a core creative ability that can be challenging for humans. Recent work has shown some proofs-of-concept of Large language Models’ (LLMs) ability to generate cross-domain analogies. However, the reliability and potential usefulness of this capacity for augmenting human creative work has received little systematic exploration. In this paper, we systematically explore LLMs capacity to augment cross-domain analogical reasoning. Across three studies, we found: 1) LLM-generated cross-domain analogies were frequently judged as helpful in the context of a problem reformulation task (median 4 out of 5 helpfulness rating), and frequently (∼ 80% of cases) led to observable changes in problem formulations, and 2) there was an upper bound of ∼ 25% of outputs being rated as potentially harmful, with a majority due to potentially upsetting content, rather than biased or toxic content. These results demonstrate the potential utility — and risks — of LLMs for augmenting cross-domain analogical creativity.","Ding Z,Srinivasan A,Macneil S,Chan J",,,Fluid Transformers and Creative Analogies: Exploring Large Language Models’ Capacity for Augmenting Cross-Domain Analogical Creativity,,,10.1145/3591196.3593516 , Conference Paper,2023.0,"Cross-domain analogical reasoning is a core creative ability that can be challenging for humans. Recent work has shown some proofs-of-concept of Large language Models’ (LLMs) ability to generate cross-domain analogies. However, the reliability and potential usefulness of this capacity for augmenting human creative work has received little systematic exploration. In this paper, we systematically explore LLMs capacity to augment cross-domain analogical reasoning. Across three studies, we found: 1) LLM-generated cross-domain analogies were frequently judged as helpful in the context of a problem reformulation task (median 4 out of 5 helpfulness rating), and frequently (∼ 80% of cases) led to observable changes in problem formulations, and 2) there was an upper bound of ∼ 25% of outputs being rated as potentially harmful, with a majority due to potentially upsetting content, rather than biased or toxic content. These results demonstrate the potential utility — and risks — of LLMs for augmenting cross-domain analogical creativity.",,,,,Association for Computing Machinery ,Proceedings of the 15th Conference on Creativity and Cognition ,"Large Language Models, Analogy, Creativity Support Tools",,
4525,"Title:Applying Algorithmic Accountability Frameworks with Domain-Specific Codes of Ethics: A Case Study in Ecosystem Forecasting for Shellfish Toxicity in the Gulf of Maine

 Ecological forecasts are used to inform decisions that can havesignificant impacts on the lives of individuals and on the healthof ecosystems. These forecasts, or models, embody the ethics oftheir creators as well as many seemingly arbitrary implementationchoices made along the way. They can contain implementationerrors as well as reflect patterns of bias learned when ingestingdatasets derived from past biased decision making. Principles andframeworks for algorithmic accountability allow a wide range ofstakeholders to place the results of models and software systemsinto context. We demonstrate how the combination of algorithmicaccountability frameworks and domain-specific codes of ethics helpanswer calls to uphold fairness and human values, specifically indomains that utilize machine learning algorithms. This helps avoidmany of the unintended consequences that can result from deploy-ing black box systems to solve complex problems. In this paper,we discuss our experience applying algorithmic accountability prin-ciples and frameworks to ecosystem forecasting, focusing on a casestudy forecasting shellfish toxicity in the Gulf of Maine. We adaptexisting frameworks such as Datasheets for Datasets and ModelCards for Model Reporting from their original focus on personallyidentifiable private data to include public datasets, such as thoseoften used in ecosystem forecasting applications, to audit the casestudy. We show how high level algorithmic accountability frame-works and domain level codes of ethics compliment each other,incentivizing more transparency, accountability, and fairness inautomated decision-making systems.","Grasso I,Russell D,Matthews A,Matthews J,Record NR",,,Applying Algorithmic Accountability Frameworks with Domain-Specific Codes of Ethics: A Case Study in Ecosystem Forecasting for Shellfish Toxicity in the Gulf of Maine,,,10.1145/3412815.3416897 , Conference Paper,2020.0,"Ecological forecasts are used to inform decisions that can havesignificant impacts on the lives of individuals and on the healthof ecosystems. These forecasts, or models, embody the ethics oftheir creators as well as many seemingly arbitrary implementationchoices made along the way. They can contain implementationerrors as well as reflect patterns of bias learned when ingestingdatasets derived from past biased decision making. Principles andframeworks for algorithmic accountability allow a wide range ofstakeholders to place the results of models and software systemsinto context. We demonstrate how the combination of algorithmicaccountability frameworks and domain-specific codes of ethics helpanswer calls to uphold fairness and human values, specifically indomains that utilize machine learning algorithms. This helps avoidmany of the unintended consequences that can result from deploy-ing black box systems to solve complex problems. In this paper,we discuss our experience applying algorithmic accountability prin-ciples and frameworks to ecosystem forecasting, focusing on a casestudy forecasting shellfish toxicity in the Gulf of Maine. We adaptexisting frameworks such as Datasheets for Datasets and ModelCards for Model Reporting from their original focus on personallyidentifiable private data to include public datasets, such as thoseoften used in ecosystem forecasting applications, to audit the casestudy. We show how high level algorithmic accountability frame-works and domain level codes of ethics compliment each other,incentivizing more transparency, accountability, and fairness inautomated decision-making systems.",,,9781450381031,,Association for Computing Machinery ,Proceedings of the 2020 ACM-IMS on Foundations of Data Science Conference ,"algorithmic accountability, forecasting, ethics, ecology",,
4526,"Title:Flag and Flaggability in Automated Moderation: The Case of Reporting Toxic Behavior in an Online Game Community

 Online platforms rely upon users or automated tools to flag toxic behaviors, the very first step in online moderation. While much recent research has examined online moderation, the role of flag remains poorly understood. This question becomes even more urgent in automated moderation, where flagging becomes a primary source of human judgment. We conducted a qualitative study of flagging practices in League of Legends (LoL), a popular eSports game. We found stark differences between how flag is designed to identify toxicity, and flaggability, or how players use and appropriate flag. Players distrust flag, but also appropriate flag for instrumental purposes. Thus, flaggability diverges decidedly from the conception of toxicity, and must be understood within the highly competitive gaming context of LoL. These findings help shed light on the situated nature of flaggability, the role of flag in online moderation, as well as implications for designing flag and moderation.","Kou Y,Gui X",,,Flag and Flaggability in Automated Moderation: The Case of Reporting Toxic Behavior in an Online Game Community,,,10.1145/3411764.3445279 , Conference Paper,2021.0,"Online platforms rely upon users or automated tools to flag toxic behaviors, the very first step in online moderation. While much recent research has examined online moderation, the role of flag remains poorly understood. This question becomes even more urgent in automated moderation, where flagging becomes a primary source of human judgment. We conducted a qualitative study of flagging practices in League of Legends (LoL), a popular eSports game. We found stark differences between how flag is designed to identify toxicity, and flaggability, or how players use and appropriate flag. Players distrust flag, but also appropriate flag for instrumental purposes. Thus, flaggability diverges decidedly from the conception of toxicity, and must be understood within the highly competitive gaming context of LoL. These findings help shed light on the situated nature of flaggability, the role of flag in online moderation, as well as implications for designing flag and moderation.",,,9781450380966,,Association for Computing Machinery ,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ,"competitive gaming, toxic behavior, moderation, Report, governance, League of Legends, toxicity, regulation, online community, toxic meritocracy, flag",,
4527,"Title:Pls Uninstall: On the Interplay of the COVID-19 Pandemic and Toxic Player Behavior in Competitive Gaming

 Win or lose---the beauty of competitive games lies in the challenge, accompanied by the rush of adrenaline. Unfortunately, another loyal companion is toxic player behavior, which can ruin a game even before the winner is decided. Yet what happens when opponents suddenly face a much more dangerous, common enemy in the form of a pandemic outbreak? Does such a situation act as common ground, uniting the players and increasing their social awareness? Or do players abuse the game (and other players) even more to release their frustration caused by the pandemic? The results of our ongoing work support the latter hypothesis: in most competitive games, players perceive a notable increase of toxicity, which is an alarming sign and a clear call for more detailed explorations.","Emmerich K,Krekhov A,Krüger J",,,Pls Uninstall: On the Interplay of the COVID-19 Pandemic and Toxic Player Behavior in Competitive Gaming,,,10.1145/3383668.3419896 , Conference Paper,2020.0,"Win or lose---the beauty of competitive games lies in the challenge, accompanied by the rush of adrenaline. Unfortunately, another loyal companion is toxic player behavior, which can ruin a game even before the winner is decided. Yet what happens when opponents suddenly face a much more dangerous, common enemy in the form of a pandemic outbreak? Does such a situation act as common ground, uniting the players and increasing their social awareness? Or do players abuse the game (and other players) even more to release their frustration caused by the pandemic? The results of our ongoing work support the latter hypothesis: in most competitive games, players perceive a notable increase of toxicity, which is an alarming sign and a clear call for more detailed explorations.",,,9781450375870,,Association for Computing Machinery ,Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play ,"moba, multiplayer, competitive games, toxicity, league of legends",,
4528,"Title:Conotoxin Protein Classification Using Pairwise Comparison and Amino Acid Composition: Toxin-Aam

 Conotoxin classification could assist in the study of the structure function relationship of ion-channels and receptors as well as identifying potential therapeutics in the treatment of a wide variety of diseases such as schizophrenia, chronic pain, cardiovascular and bladder dysfunction. In this study, we introduce a novel method (Toxin-AAM) for conotoxin superfamily classification. Toxin-AAM incorporates evolutionary information using a powerful means of pairwise sequence comparison and amino acid composition knowledge. The combination of the sequential model and the discrete model has made the Toxin-AAM method exceptional in classifying conotoxin superfamily, when compared to other state-of-the-art techniques.","Zaki N,Sibai F,Campbell P",,,Conotoxin Protein Classification Using Pairwise Comparison and Amino Acid Composition: Toxin-Aam,,,10.1145/2001576.2001621 , Conference Paper,2011.0,"Conotoxin classification could assist in the study of the structure function relationship of ion-channels and receptors as well as identifying potential therapeutics in the treatment of a wide variety of diseases such as schizophrenia, chronic pain, cardiovascular and bladder dysfunction. In this study, we introduce a novel method (Toxin-AAM) for conotoxin superfamily classification. Toxin-AAM incorporates evolutionary information using a powerful means of pairwise sequence comparison and amino acid composition knowledge. The combination of the sequential model and the discrete model has made the Toxin-AAM method exceptional in classifying conotoxin superfamily, when compared to other state-of-the-art techniques.",,,9781450305570,,Association for Computing Machinery ,Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation ,"amino acid composition, pairwise alignment, conotoxin classification",,
4529,"Title:STFU NOOB! Predicting Crowdsourced Decisions on Toxic Behavior in Online Games

 One problem facing players of competitive games is negative, or toxic, behavior. League of Legends, the largest eSport game, uses a crowdsourcing platform called the Tribunal to judge whether a reported toxic player should be punished or not. The Tribunal is a two stage system requiring reports from those players that directly observe toxic behavior, and human experts that review aggregated reports. While this system has successfully dealt with the vague nature of toxic behavior by majority rules based on many votes, it naturally requires tremendous cost, time, and human efforts. In this paper, we propose a supervised learning approach for predicting crowdsourced decisions on toxic behavior with large-scale labeled data collections; over 10 million user reports involved in 1.46 million toxic players and corresponding crowdsourced decisions. Our result shows good performance in detecting overwhelmingly majority cases and predicting crowdsourced decisions on them. We demonstrate good portability of our classifier across regions. Finally, we estimate the practical implications of our approach, potential cost savings and victim protection.","Blackburn J,Kwak H",,,STFU NOOB! Predicting Crowdsourced Decisions on Toxic Behavior in Online Games,,,10.1145/2566486.2567987 , Conference Paper,2014.0,"One problem facing players of competitive games is negative, or toxic, behavior. League of Legends, the largest eSport game, uses a crowdsourcing platform called the Tribunal to judge whether a reported toxic player should be punished or not. The Tribunal is a two stage system requiring reports from those players that directly observe toxic behavior, and human experts that review aggregated reports. While this system has successfully dealt with the vague nature of toxic behavior by majority rules based on many votes, it naturally requires tremendous cost, time, and human efforts. In this paper, we propose a supervised learning approach for predicting crowdsourced decisions on toxic behavior with large-scale labeled data collections; over 10 million user reports involved in 1.46 million toxic players and corresponding crowdsourced decisions. Our result shows good performance in detecting overwhelmingly majority cases and predicting crowdsourced decisions on them. We demonstrate good portability of our classifier across regions. Finally, we estimate the practical implications of our approach, potential cost savings and victim protection.",,,9781450327442,,Association for Computing Machinery ,Proceedings of the 23rd International Conference on World Wide Web ,"machine learning, crowdsourcing, toxic behavior, league of legends, online video games",,
4530,"Title:DeGas: Toxic Gas Boundary Area Detection in Industrial Wireless Sensor Networks: Poster Abstract

 In this article, we propose a new scheme DeGas to determine the boundary area of the toxic gas with planarization algorithm. This detected boundary area will ensure safe area around the toxic gas and will provide a decision reference for evacuation and rescue of the first-line workers in the large-scale petrochemical plants. Understanding the implications of these observations enable to find out an optimal tradeoff between the cost of a number of deployed sensor nodes and the accuracy of the estimated toxic gas boundary area size.","Shu L,Mukherjee M,Chen Y",,,DeGas: Toxic Gas Boundary Area Detection in Industrial Wireless Sensor Networks: Poster Abstract,,, , Conference Paper,2016.0,"In this article, we propose a new scheme DeGas to determine the boundary area of the toxic gas with planarization algorithm. This detected boundary area will ensure safe area around the toxic gas and will provide a decision reference for evacuation and rescue of the first-line workers in the large-scale petrochemical plants. Understanding the implications of these observations enable to find out an optimal tradeoff between the cost of a number of deployed sensor nodes and the accuracy of the estimated toxic gas boundary area size.",,,9781509008025,,IEEE Press ,Proceedings of the 15th International Conference on Information Processing in Sensor Networks ,,,
4531,"Title:Antidote Application: An Educational System for Treatment of Common Toxin Overdose

 Poisonings account for almost 1% of emergency room visits each year. Time is a critical factor in dealing with a toxicologic emergency. Delay in dispensing the first antidote dose can lead to life-threatening sequelae. Current toxicological resources that support treatment decisions are broad in scope, time-consuming to read, or at times unavailable. Our review of current toxicological resources revealed a gap in their ability to provide expedient calculations and recommendations about appropriate course of treatment. To bridge the gap, we developed the Antidote Application (AA), a computational system that automatically provides patient-specific antidote treatment recommendations and individualized dose calculations. We implemented 27 algorithms that describe FDA (the US Food and Drug Administration) approved use and evidence-based practices found in primary literature for the treatment of common toxin exposure. The AA covers 29 antidotes recommended by Poison Control and toxicology experts, 19 poison classes and 31 poisons, which represent over 200 toxic entities. To the best of our knowledge, the AA is the first educational decision support system in toxicology that provides patient-specific treatment recommendations and drug dose calculations. The AA is publicly available at http://projects.met-hilab.org/antidote/.","Long JB,Zhang Y,Brusic V,Chitkushev L,Zhang G",,,Antidote Application: An Educational System for Treatment of Common Toxin Overdose,,,10.1145/3107411.3107415 , Conference Paper,2017.0,"Poisonings account for almost 1% of emergency room visits each year. Time is a critical factor in dealing with a toxicologic emergency. Delay in dispensing the first antidote dose can lead to life-threatening sequelae. Current toxicological resources that support treatment decisions are broad in scope, time-consuming to read, or at times unavailable. Our review of current toxicological resources revealed a gap in their ability to provide expedient calculations and recommendations about appropriate course of treatment. To bridge the gap, we developed the Antidote Application (AA), a computational system that automatically provides patient-specific antidote treatment recommendations and individualized dose calculations. We implemented 27 algorithms that describe FDA (the US Food and Drug Administration) approved use and evidence-based practices found in primary literature for the treatment of common toxin exposure. The AA covers 29 antidotes recommended by Poison Control and toxicology experts, 19 poison classes and 31 poisons, which represent over 200 toxic entities. To the best of our knowledge, the AA is the first educational decision support system in toxicology that provides patient-specific treatment recommendations and drug dose calculations. The AA is publicly available at http://projects.met-hilab.org/antidote/.",,,9781450347228,,Association for Computing Machinery ,"Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics ","decision support, medical informatics, toxicology, toxicity, poison control centers",,
4532,"Title:Redundancy-Aware Transformer for Video Question Answering

 This paper identifies two kinds of redundancy in the current VideoQA paradigm. Specifically, the current video encoders tend to holistically embed all video clues at different granularities in a hierarchical manner, which inevitably introducesneighboring-frame redundancy that can overwhelm detailed visual clues at the object level. Subsequently, prevailing vision-language fusion designs introduce thecross-modal redundancy by exhaustively fusing all visual elements with question tokens without explicitly differentiating their pairwise vision-language interactions, thus making a pernicious impact on the answering. To this end, we propose a novel transformer-based architecture, that aims to model VideoQA in a redundancy-aware manner. To address the neighboring-frame redundancy, we introduce a video encoder structure that emphasizes the object-level change in neighboring frames, while adopting an out-of-neighboring message-passing scheme that imposes attention only on distant frames. As for the cross-modal redundancy, we equip our fusion module with a novel adaptive sampling, which explicitly differentiates the vision-language interactions by identifying a small subset of visual elements that exclusively support the answer. Upon these advancements, we find this underlineR edundancy-underlinea ware transunderlineformer (RaFormer) can achieve state-of-the-art results on multiple VideoQA benchmarks.","Li Y,Yang X,Zhang A,Feng C,Wang X,Chua TS",,,Redundancy-Aware Transformer for Video Question Answering,,,10.1145/3581783.3612577 , Conference Paper,2023.0,"This paper identifies two kinds of redundancy in the current VideoQA paradigm. Specifically, the current video encoders tend to holistically embed all video clues at different granularities in a hierarchical manner, which inevitably introducesneighboring-frame redundancy that can overwhelm detailed visual clues at the object level. Subsequently, prevailing vision-language fusion designs introduce thecross-modal redundancy by exhaustively fusing all visual elements with question tokens without explicitly differentiating their pairwise vision-language interactions, thus making a pernicious impact on the answering. To this end, we propose a novel transformer-based architecture, that aims to model VideoQA in a redundancy-aware manner. To address the neighboring-frame redundancy, we introduce a video encoder structure that emphasizes the object-level change in neighboring frames, while adopting an out-of-neighboring message-passing scheme that imposes attention only on distant frames. As for the cross-modal redundancy, we equip our fusion module with a novel adaptive sampling, which explicitly differentiates the vision-language interactions by identifying a small subset of visual elements that exclusively support the answer. Upon these advancements, we find this underlineR edundancy-underlinea ware transunderlineformer (RaFormer) can achieve state-of-the-art results on multiple VideoQA benchmarks.",,,,,Association for Computing Machinery ,Proceedings of the 31st ACM International Conference on Multimedia ,"video question answering, video-language",,
4533,"Title:Pest Detection on Traps Using Deep Convolutional Neural Networks

 It is commonly known that toxic pests have a negative influence on the production process and ultimately on the product quality of many industries. Therefore, it is reasonable to consider pest detection a crucial task in these production procedures in order to make relevant pest management decisions. However, the challenge here is that localization and classification of different insect species are fairly difficult due to high similarity in features between them, and it is even more challenging when particularly dealing with those already caught on traps. Inspired by the achievement of the Deep Convolutional Neural Network (CNN), this paper proposes a method of identifying various types of trapped insect species by making prediction based on available images. Using a database of 200 pictures (from a confectionery factory) including approximately 3,000 insects of 6 kinds, the accuracy rates of detection and classification are about 84% and 86% respectively.","Nam NT,Hung PD",,,Pest Detection on Traps Using Deep Convolutional Neural Networks,,,10.1145/3232651.3232661 , Conference Paper,2018.0,"It is commonly known that toxic pests have a negative influence on the production process and ultimately on the product quality of many industries. Therefore, it is reasonable to consider pest detection a crucial task in these production procedures in order to make relevant pest management decisions. However, the challenge here is that localization and classification of different insect species are fairly difficult due to high similarity in features between them, and it is even more challenging when particularly dealing with those already caught on traps. Inspired by the achievement of the Deep Convolutional Neural Network (CNN), this paper proposes a method of identifying various types of trapped insect species by making prediction based on available images. Using a database of 200 pictures (from a confectionery factory) including approximately 3,000 insects of 6 kinds, the accuracy rates of detection and classification are about 84% and 86% respectively.",,,9781450364706,,Association for Computing Machinery ,Proceedings of the 1st International Conference on Control and Computer Vision ,"Object Detection, Computer Vision, Pest Detection, Deep Convolutional Neural Network, Single shot multibox detector",,
4534,"Title:Is This Question Real? Dataset Collection on Perceived Intentions and Implicit Attack Detection

 The proliferation of social media and online communication platforms has made social interactions more accessible, leading to a significant expansion of research into language use with a particular focus on toxic behavior and hate speech. Few studies, however, have focused on the tacit information that may imply a negative intention and the perspective that impacts the interpretation of such intention. Conversation is a joint activity that relies on coordination between what one party expresses and how the other party construes what has been expressed. Thus, how a message is perceived becomes equally important regardless of whether the sent message includes any form of explicit attack or offense. This study focuses on identifying the implicit attacks and negative intentions in text-based conversation from the reader’s point of view. We focus on questions in conversations and investigate the underlying perceived intention. We introduce our dataset that includes questions, intention polarity, and type of attacks. We conduct a meta-analysis on the data to demonstrate how a question may be used as a means of attack and how different perspectives can lead to multiple interpretations. We also report benchmark results of several models for detecting instances of tacit attacks in questions with the aim of avoiding latent or manifest conflict in conversations.","Mirzaei MS,Meshgi K,Sekine S",,,Is This Question Real? Dataset Collection on Perceived Intentions and Implicit Attack Detection,,,10.1145/3485447.3512005 , Conference Paper,2022.0,"The proliferation of social media and online communication platforms has made social interactions more accessible, leading to a significant expansion of research into language use with a particular focus on toxic behavior and hate speech. Few studies, however, have focused on the tacit information that may imply a negative intention and the perspective that impacts the interpretation of such intention. Conversation is a joint activity that relies on coordination between what one party expresses and how the other party construes what has been expressed. Thus, how a message is perceived becomes equally important regardless of whether the sent message includes any form of explicit attack or offense. This study focuses on identifying the implicit attacks and negative intentions in text-based conversation from the reader’s point of view. We focus on questions in conversations and investigate the underlying perceived intention. We introduce our dataset that includes questions, intention polarity, and type of attacks. We conduct a meta-analysis on the data to demonstrate how a question may be used as a means of attack and how different perspectives can lead to multiple interpretations. We also report benchmark results of several models for detecting instances of tacit attacks in questions with the aim of avoiding latent or manifest conflict in conversations.",,,9781450390965,,Association for Computing Machinery ,Proceedings of the ACM Web Conference 2022 ,"Questions, Implicit offense, Offensive language, Implicit attack, Intention polarity, Hate speech",,
4535,"Title:Cyberbullying Ends Here: Towards Robust Detection of Cyberbullying in Social Media

 The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data-driven approaches, with emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well-defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim. Existing work has focused on harassment (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, two key practical challenges remain unaddressed: (i) detection timeliness, which is necessary to support victims as early as possible, and (ii) scalability to the staggering rates at which content is generated in online social networks. In this work, we introduce CONcISE, a novel approach for timely and accurate Cyberbullying detectiON on Instagram media SEssions. We propose a sequential hypothesis testing formulation that seeks to drastically reduce the number of features used in classifying each comment while maintaining high classification accuracy. CONcISE raises an alert only after a certain number of detections have been made. Extensive experiments on a real-world Instagram dataset with 4M users and 10M comments demonstrate the effectiveness, scalability, and timeliness of our approach and its benefits over existing methods.","Yao M,Chelmis C,Zois DS",,,Cyberbullying Ends Here: Towards Robust Detection of Cyberbullying in Social Media,,,10.1145/3308558.3313462 , Conference Paper,2019.0,"The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data-driven approaches, with emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well-defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim. Existing work has focused on harassment (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, two key practical challenges remain unaddressed: (i) detection timeliness, which is necessary to support victims as early as possible, and (ii) scalability to the staggering rates at which content is generated in online social networks. In this work, we introduce CONcISE, a novel approach for timely and accurate Cyberbullying detectiON on Instagram media SEssions. We propose a sequential hypothesis testing formulation that seeks to drastically reduce the number of features used in classifying each comment while maintaining high classification accuracy. CONcISE raises an alert only after a certain number of detections have been made. Extensive experiments on a real-world Instagram dataset with 4M users and 10M comments demonstrate the effectiveness, scalability, and timeliness of our approach and its benefits over existing methods.",,,9781450366748,,Association for Computing Machinery ,The World Wide Web Conference ,"sequential selection, cyberharassment, optimization, Classification",,
4536,"Title:EA-Based ASV Trajectory Planner for Detecting Cyanobacterial Blooms in Freshwater

 Cyanobacterial Blooms (CBs) constitute a relevant ecological and public health problem since they often produce toxic metabolites that endanger the lives of many species, and they prevent human water consumption and recreational use. To determine the locations of CBs in lentic water bodies, we present a new planner based on Evolutionary Algorithms (EAs) that optimizes the trajectory of an Autonomous Surface Vehicle (ASV) equipped with a probe capable of detecting CBs. The planner 1) exploits the information provided by a particle transport simulator that determines the CB distribution from the water currents and the inherent CB behavior (in particular, its biological growth and vertical displacements) and 2) is supported by an EA that optimizes the mission duration, the ASV trajectory length, and the contributions of each simulated particle to the predicted cyanobacterial concentration along the ASV trajectory. The planner also ensures the trajectory feasibility from the ASV, probe, and water body perspective; and refines the trajectory shape by increasing the number of the decision variables during the iteration of an EA supported by usual NSGA-II operations. The results over different scenarios show that the planner determines overall good solutions that adapt the ASV trajectory to the evolution of CB distribution.","Carazo-Barbero G,Besada-Portas E,Risco-Martín JL,López-Orozco JA",,,EA-Based ASV Trajectory Planner for Detecting Cyanobacterial Blooms in Freshwater,,,10.1145/3583131.3590484 , Conference Paper,2023.0,"Cyanobacterial Blooms (CBs) constitute a relevant ecological and public health problem since they often produce toxic metabolites that endanger the lives of many species, and they prevent human water consumption and recreational use. To determine the locations of CBs in lentic water bodies, we present a new planner based on Evolutionary Algorithms (EAs) that optimizes the trajectory of an Autonomous Surface Vehicle (ASV) equipped with a probe capable of detecting CBs. The planner 1) exploits the information provided by a particle transport simulator that determines the CB distribution from the water currents and the inherent CB behavior (in particular, its biological growth and vertical displacements) and 2) is supported by an EA that optimizes the mission duration, the ASV trajectory length, and the contributions of each simulated particle to the predicted cyanobacterial concentration along the ASV trajectory. The planner also ensures the trajectory feasibility from the ASV, probe, and water body perspective; and refines the trajectory shape by increasing the number of the decision variables during the iteration of an EA supported by usual NSGA-II operations. The results over different scenarios show that the planner determines overall good solutions that adapt the ASV trajectory to the evolution of CB distribution.",,,,,Association for Computing Machinery ,Proceedings of the Genetic and Evolutionary Computation Conference ,"earth sciences and the environment, genetic algorithms, decision making, robotics, multi-objective optimization",,
4537,"Title:Robust Detection of Cyberbullying in Social Media

 The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data–driven approaches, with an emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well–defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim. Existing work has focused on aggression (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, three key practical challenges remain unaddressed: (i) detection timeliness, which is necessary to support victims as early as possible, (ii) scalability to the staggering rates at which content is generated in online social networks, (iii) reliance on high quality annotations from human experts for training of highly accurate supervised classifiers.To overcome the challenges associated with cyberbullying detection in online social networks, my PhD thesis focuses on a novel formulation of the online classification problem as sequential hypothesis testing that seeks to drastically reduce the number of features used while maintaining high classification accuracy. To reduce the dependency on labeled datasets, I seek to develop efficient semisupervised methods that extrapolate from a small seed set of expert annotations. Preliminary results are very encouraging, showing significant improvements over the state–of–the–art.",Yao M,,,Robust Detection of Cyberbullying in Social Media,,,10.1145/3308560.3314196 , Conference Paper,2019.0,"The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data–driven approaches, with an emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well–defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim. Existing work has focused on aggression (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, three key practical challenges remain unaddressed: (i) detection timeliness, which is necessary to support victims as early as possible, (ii) scalability to the staggering rates at which content is generated in online social networks, (iii) reliance on high quality annotations from human experts for training of highly accurate supervised classifiers.To overcome the challenges associated with cyberbullying detection in online social networks, my PhD thesis focuses on a novel formulation of the online classification problem as sequential hypothesis testing that seeks to drastically reduce the number of features used while maintaining high classification accuracy. To reduce the dependency on labeled datasets, I seek to develop efficient semisupervised methods that extrapolate from a small seed set of expert annotations. Preliminary results are very encouraging, showing significant improvements over the state–of–the–art.",,,9781450366755,,Association for Computing Machinery ,Companion Proceedings of The 2019 World Wide Web Conference ,"cyberharassment, Classification, social networks, optimization, sequential selection",,
4538,"Title:Dynamic, Incremental, and Continuous Detection of Cyberbullying in Online Social Media

 The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data-driven approaches, with emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well-defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim. Existing work has focused on harassment (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, two key practical challenges remain unaddressed: (i) detection timeliness, which is necessary to support victims as early as possible, and (ii) scalability to the staggering rates at which content is generated in online social networks. In this work, we introduce CONcISE, a novel approach for timely and accurate Cyberbullying detectiON in online social media SEssions. CONcISE is a two-stage online approach designed to reduce the time to raise a cyberbullying alert by sequentially examining comments as they become available over time, and minimizing the number of feature evaluations necessary for a decision to be made for each comment. Extensive experiments on a real-world Instagram dataset with users and comments demonstrate the effectiveness, scalability, and timeliness of our approach and its benefits over existing methods. Additional experiments using a Twitter dataset offer evidence in support of the potential generalizability of CONcISE to other social media platforms.","Chelmis C,Zois DS",,,"Dynamic, Incremental, and Continuous Detection of Cyberbullying in Online Social Media",15,3,10.1145/3448014 , Journal Article,2021.0,"The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data-driven approaches, with emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well-defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim. Existing work has focused on harassment (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, two key practical challenges remain unaddressed: (i) detection timeliness, which is necessary to support victims as early as possible, and (ii) scalability to the staggering rates at which content is generated in online social networks. In this work, we introduce CONcISE, a novel approach for timely and accurate Cyberbullying detectiON in online social media SEssions. CONcISE is a two-stage online approach designed to reduce the time to raise a cyberbullying alert by sequentially examining comments as they become available over time, and minimizing the number of feature evaluations necessary for a decision to be made for each comment. Extensive experiments on a real-world Instagram dataset with users and comments demonstrate the effectiveness, scalability, and timeliness of our approach and its benefits over existing methods. Additional experiments using a Twitter dataset offer evidence in support of the potential generalizability of CONcISE to other social media platforms.",1559-1131,,,,Association for Computing Machinery ACM Trans. Web, ,"optimization, Classification, sequential selection, cyberharassment, social networks",,
4539,"Title:Lightning Talk–Towards Robust Detection of Cyberbullying in Social Media

 The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data–driven approaches, with emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well–defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim.Existing work has focused on harassment (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, two key practical challenges remain unaddressed: (i) timeliness: the state–of–the–art relies on a fixed set of features learned during training for offline detection (i.e., after all correspondence has become available), hindering the ability to respond in a timely manner (i.e., as soon as possible) to cyberbullying events. (ii) scalabilty: the scalability of existing methods to the staggering rates at which content is generated (e.g., 95 million photos and videos are shared on Instagram per day1) has largely remained unaddressed.In my lightning talk, I will introduce CONcISE, a novel approach for timely and accurate Cyberbullying detectiON on Instagram media SEssions, that has been accepted for presentation at the main conference [1]. Specifically, I will present a novel two–stage online approach (illustrated in Figure 1) designed to reduce the time to raise a cyberbullying alert by (i) sequentially examining comments as they become available over time, and (ii) minimizing the number of feature evaluations necessary for a decision to be made for each comment. By formalizing the problem as a sequential hypothesis testing problem, a novel algorithm has been developed that satisfies four key properties: accuracy, repetitiveness, timeliness, and efficiency.Extensive experiments on a real–world Instagram dataset with ∼ 4M users and ∼ 10M comments demonstrate the effectiveness of the proposed approach with respect to accuracy, timeliness, efficiency, and robustness, and show that it consistently outperforms the stat–of–the–art, often by a considerable margin.","Yao M,Chelmis C,Zois DS",,,Lightning Talk–Towards Robust Detection of Cyberbullying in Social Media,,,10.1145/3308560.3316474 , Conference Paper,2019.0,"The potentially detrimental effects of cyberbullying have led to the development of numerous automated, data–driven approaches, with emphasis on classification accuracy. Cyberbullying, as a form of abusive online behavior, although not well–defined, is a repetitive process, i.e., a sequence of aggressive messages sent from a bully to a victim over a period of time with the intent to harm the victim.Existing work has focused on harassment (i.e., using profanity to classify toxic comments independently) as an indicator of cyberbullying, disregarding the repetitive nature of this harassing process. However, raising a cyberbullying alert immediately after an aggressive comment is detected can lead to a high number of false positives. At the same time, two key practical challenges remain unaddressed: (i) timeliness: the state–of–the–art relies on a fixed set of features learned during training for offline detection (i.e., after all correspondence has become available), hindering the ability to respond in a timely manner (i.e., as soon as possible) to cyberbullying events. (ii) scalabilty: the scalability of existing methods to the staggering rates at which content is generated (e.g., 95 million photos and videos are shared on Instagram per day1) has largely remained unaddressed.In my lightning talk, I will introduce CONcISE, a novel approach for timely and accurate Cyberbullying detectiON on Instagram media SEssions, that has been accepted for presentation at the main conference [1]. Specifically, I will present a novel two–stage online approach (illustrated in Figure 1) designed to reduce the time to raise a cyberbullying alert by (i) sequentially examining comments as they become available over time, and (ii) minimizing the number of feature evaluations necessary for a decision to be made for each comment. By formalizing the problem as a sequential hypothesis testing problem, a novel algorithm has been developed that satisfies four key properties: accuracy, repetitiveness, timeliness, and efficiency.Extensive experiments on a real–world Instagram dataset with ∼ 4M users and ∼ 10M comments demonstrate the effectiveness of the proposed approach with respect to accuracy, timeliness, efficiency, and robustness, and show that it consistently outperforms the stat–of–the–art, often by a considerable margin.",,,9781450366755,,Association for Computing Machinery ,Companion Proceedings of The 2019 World Wide Web Conference ,"Classification, cyberharassment, optimization, social networks, sequential selection",,
4540,"Title:Natural Language Processing and Sentiment Analysis for Verbal Aggression Detection; A Solution for Cyberbullying during Live Video Gaming

 Verbal aggression during online multiplayer games is a common occurrence on video gaming platforms. From casual cursing and negative remarks to more targeted and damaging cyberbullying cases, the gaming industry continues to see an increasing number of players engaging in these exchanges. The COVID-19 pandemic has led to a rise in the number of active gamers due to social distancing and stay-at-home orders. As a result, cases of cyberbullying and toxicity have increased by 40% on popular gaming platforms such as Discord [4]. To help resolve this issue, we created an aggression awareness tool called Tempr to discourage verbal aggression in gamers under the age of 18 and reward non-aggressive behavior.","Stepanova N,Muthemba W,Todrzak R,Cross M,Ames N,Raiti J",,,Natural Language Processing and Sentiment Analysis for Verbal Aggression Detection; A Solution for Cyberbullying during Live Video Gaming,,,10.1145/3453892.3464897 , Conference Paper,2021.0,"Verbal aggression during online multiplayer games is a common occurrence on video gaming platforms. From casual cursing and negative remarks to more targeted and damaging cyberbullying cases, the gaming industry continues to see an increasing number of players engaging in these exchanges. The COVID-19 pandemic has led to a rise in the number of active gamers due to social distancing and stay-at-home orders. As a result, cases of cyberbullying and toxicity have increased by 40% on popular gaming platforms such as Discord [4]. To help resolve this issue, we created an aggression awareness tool called Tempr to discourage verbal aggression in gamers under the age of 18 and reward non-aggressive behavior.",,,9781450387927,,Association for Computing Machinery ,Proceedings of the 14th PErvasive Technologies Related to Assistive Environments Conference ,,,
4541,"Title:A Multi-Task Model for Emotion and Offensive Aided Stance Detection of Climate Change Tweets

 In this work, we address the United Nations Sustainable Development Goal 13: Climate Action by focusing on identifying public attitudes toward climate change on social media platforms such as Twitter. Climate change is threatening the health of the planet and humanity. Public engagement is critical to address climate change. However, climate change conversations on Twitter tend to polarize beliefs, leading to misinformation and fake news that influence public attitudes, often dividing them into climate change believers and deniers. Our paper proposes an approach to classify the attitude of climate change tweets (believe/deny/ambiguous) to identify denier statements on Twitter. Most existing approaches for detecting stances and classifying climate change tweets either overlook deniers’ tweets or do not have a suitable architecture. The relevant literature suggests that emotions and higher levels of toxicity are prevalent in climate change Twitter conversations, leading to a delay in appropriate climate action. Therefore, our work focuses on learning stance detection (main task) while exploiting the auxiliary tasks of recognizing emotions and offensive utterances. We propose a multimodal multitasking framework MEMOCLiC that captures the input data using different embedding techniques and attention frameworks, and then incorporates the learned emotional and offensive expressions to obtain an overall representation of the features relevant to the stance of the input tweet. Extensive experiments conducted on a novel curated climate change dataset and two benchmark stance detection datasets (SemEval-2016 and ClimateStance-2022) demonstrate the effectiveness of our approach.","Upadhyaya A,Fisichella M,Nejdl W",,,A Multi-Task Model for Emotion and Offensive Aided Stance Detection of Climate Change Tweets,,,10.1145/3543507.3583860 , Conference Paper,2023.0,"In this work, we address the United Nations Sustainable Development Goal 13: Climate Action by focusing on identifying public attitudes toward climate change on social media platforms such as Twitter. Climate change is threatening the health of the planet and humanity. Public engagement is critical to address climate change. However, climate change conversations on Twitter tend to polarize beliefs, leading to misinformation and fake news that influence public attitudes, often dividing them into climate change believers and deniers. Our paper proposes an approach to classify the attitude of climate change tweets (believe/deny/ambiguous) to identify denier statements on Twitter. Most existing approaches for detecting stances and classifying climate change tweets either overlook deniers’ tweets or do not have a suitable architecture. The relevant literature suggests that emotions and higher levels of toxicity are prevalent in climate change Twitter conversations, leading to a delay in appropriate climate action. Therefore, our work focuses on learning stance detection (main task) while exploiting the auxiliary tasks of recognizing emotions and offensive utterances. We propose a multimodal multitasking framework MEMOCLiC that captures the input data using different embedding techniques and attention frameworks, and then incorporates the learned emotional and offensive expressions to obtain an overall representation of the features relevant to the stance of the input tweet. Extensive experiments conducted on a novel curated climate change dataset and two benchmark stance detection datasets (SemEval-2016 and ClimateStance-2022) demonstrate the effectiveness of our approach.",,,9781450394161,,Association for Computing Machinery ,Proceedings of the ACM Web Conference 2023 ,"emotion recognition, offensive language, stance detection, climate change, Twitter",,
4542,"Title:Tracking Deformable 2D Objects in Wireless Sensor Networks

 Geosensor networks are deployed to detect, monitor and track continuous environmental phenomena such as toxic clouds or dense areas of air pollution in an urban environment. In this paper, we abstract such continuous phenomena as 2D objects and only consider their boundary using wireless sensor networks to monitor them over time. In order to maximize energy-efficient monitoring of the phenomena, we present an in-network algorithm based on the concept of deformable curves to incrementally track spatiotemporal changes of the object. We show that the in-network incremental boundary tracking approach based on deformable curves collects sufficient information efficiently to track the overall spatiotemporal properties about a 2D object. By simulations, we demonstrate the energy-efficiency of our approach.","Jin G,Nittel S",,,Tracking Deformable 2D Objects in Wireless Sensor Networks,,,10.1145/1463434.1463517 , Conference Paper,2008.0,"Geosensor networks are deployed to detect, monitor and track continuous environmental phenomena such as toxic clouds or dense areas of air pollution in an urban environment. In this paper, we abstract such continuous phenomena as 2D objects and only consider their boundary using wireless sensor networks to monitor them over time. In order to maximize energy-efficient monitoring of the phenomena, we present an in-network algorithm based on the concept of deformable curves to incrementally track spatiotemporal changes of the object. We show that the in-network incremental boundary tracking approach based on deformable curves collects sufficient information efficiently to track the overall spatiotemporal properties about a 2D object. By simulations, we demonstrate the energy-efficiency of our approach.",,,9781605583235,,Association for Computing Machinery ,Proceedings of the 16th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems ,"deformable object tracking, spatial queries, wireless sensor networks",,
4543,"Title:Mission-Critical Management of Mobile Sensors: Or, How to Guide a Flock of Sensors

 This work addresses the problem of optimizing the deployment of sensors in order to ensure the quality of the readings of the value of interest in a given (critical) geographic region. As usual, we assume that each sensor is capable of reading a particular physical phenomenon (e.g., concentration of toxic materials in the air) and transmitting it to a server or a peer. However, the key assumptions considered in this work are: 1. each sensor is capable of moving (where the motion may be remotely controlled); and 2. the spatial range for which the individual sensor's reading is guaranteed to be of a desired quality is limited. In scenarios like disaster management and homeland security, in case some of the sensors dispersed in a larger geographic area report a value higher than a certain threshold, one may want to ensure a quality of the readings for the affected region. This, in turn, implies that one may want to ensure that there are enough sensors there and, consequently, guide a subset of the rest of the sensors towards the affected region. In this paper we explore variants of the problem of optimizing the guidance of the mobile sensors towards the affected geographic region and we present algorithms for their solutions.","Trajcevski G,Scheuermann P,Brönnimann H",,,"Mission-Critical Management of Mobile Sensors: Or, How to Guide a Flock of Sensors",,,10.1145/1052199.1052218 , Conference Paper,2004.0,"This work addresses the problem of optimizing the deployment of sensors in order to ensure the quality of the readings of the value of interest in a given (critical) geographic region. As usual, we assume that each sensor is capable of reading a particular physical phenomenon (e.g., concentration of toxic materials in the air) and transmitting it to a server or a peer. However, the key assumptions considered in this work are: 1. each sensor is capable of moving (where the motion may be remotely controlled); and 2. the spatial range for which the individual sensor's reading is guaranteed to be of a desired quality is limited. In scenarios like disaster management and homeland security, in case some of the sensors dispersed in a larger geographic area report a value higher than a certain threshold, one may want to ensure a quality of the readings for the affected region. This, in turn, implies that one may want to ensure that there are enough sensors there and, consequently, guide a subset of the rest of the sensors towards the affected region. In this paper we explore variants of the problem of optimizing the guidance of the mobile sensors towards the affected geographic region and we present algorithms for their solutions.",,,9781450377959,,Association for Computing Machinery ,Proceeedings of the 1st International Workshop on Data Management for Sensor Networks: In Conjunction with VLDB 2004 ,,,
4544,"Title:SensorFlock: An Airborne Wireless Sensor Network of Micro-Air Vehicles

 An airborne wireless sensor network (WSN) composed of bird-sized micro aerial vehicles (MAVs) enables low cost high granularity atmospheric sensing of toxic plume behavior and storm dynamics, and provides a unique three-dimensional vantage for monitoring wildlife and ecological systems. This paper describes a complete implementation of our SensorFlock airborne WSN, spanning the development of our MAV airplane, its avionics, semi-autonomous flight control software, launch system, flock control algorithm, and wireless communication networking between MAVs. We present experimental results from flight tests of flocks of MAVs, and a characterization of wireless RF behavior in air-to-air communication as well as air-to-ground communication.","Allred J,Hasan AB,Panichsakul S,Pisano W,Gray P,Huang J,Han R,Lawrence D,Mohseni K",,,SensorFlock: An Airborne Wireless Sensor Network of Micro-Air Vehicles,,,10.1145/1322263.1322275 , Conference Paper,2007.0,"An airborne wireless sensor network (WSN) composed of bird-sized micro aerial vehicles (MAVs) enables low cost high granularity atmospheric sensing of toxic plume behavior and storm dynamics, and provides a unique three-dimensional vantage for monitoring wildlife and ecological systems. This paper describes a complete implementation of our SensorFlock airborne WSN, spanning the development of our MAV airplane, its avionics, semi-autonomous flight control software, launch system, flock control algorithm, and wireless communication networking between MAVs. We present experimental results from flight tests of flocks of MAVs, and a characterization of wireless RF behavior in air-to-air communication as well as air-to-ground communication.",,,9781595937636,,Association for Computing Machinery ,Proceedings of the 5th International Conference on Embedded Networked Sensor Systems ,"MAVs, applications, wireless sensor networks, deployments",,
4545,"Title:Spatially- and Temporally-Adaptive Communication Protocols for Zero-Maintenance Sensor Networks Relying on Opportunistic Energy Scavenging

 Wireless sensor networks allow scientists to gather data from remote, difficult to access, and dangerous locations. However, maintenance of aging networks and removal of obsolete or inactive nodes containing toxic materials is expensive and time consuming. Moreover, node lifespan is generally constrained by the reliability of the batteries used in most deployments, especially in the presence of extreme variation in environmental conditions such as temperature and humidity. We consider the problem of designing wireless sensor networks capable of indefinite deployment periods measured in decades, not months. We describe the architectural and capability implications of eliminating batteries from sensor networks and instead relying on opportunistic energy scavenging. Sensor nodes using ambient energy sources become temporarily active at unpredictable but possibly correlated times. In this paper, we use wind power as an example of such a power source, which we model using temporally and spatially correlated random processes. Such models can be built using historical measurements over a geographical range. We describe a method to use energy models in the design of latency-optimized and cost-constrained battery-less wireless sensor networks, and explain the required changes to network architecture, communication protocol, and node hardware. In the context of environmental monitoring applications, we compare the performance of a network designed and managed using our techniques with that of existing design styles.","He X,Dick RP,Joseph R",,,Spatially- and Temporally-Adaptive Communication Protocols for Zero-Maintenance Sensor Networks Relying on Opportunistic Energy Scavenging,,,10.1145/2380445.2380485 , Conference Paper,2012.0,"Wireless sensor networks allow scientists to gather data from remote, difficult to access, and dangerous locations. However, maintenance of aging networks and removal of obsolete or inactive nodes containing toxic materials is expensive and time consuming. Moreover, node lifespan is generally constrained by the reliability of the batteries used in most deployments, especially in the presence of extreme variation in environmental conditions such as temperature and humidity. We consider the problem of designing wireless sensor networks capable of indefinite deployment periods measured in decades, not months. We describe the architectural and capability implications of eliminating batteries from sensor networks and instead relying on opportunistic energy scavenging. Sensor nodes using ambient energy sources become temporarily active at unpredictable but possibly correlated times. In this paper, we use wind power as an example of such a power source, which we model using temporally and spatially correlated random processes. Such models can be built using historical measurements over a geographical range. We describe a method to use energy models in the design of latency-optimized and cost-constrained battery-less wireless sensor networks, and explain the required changes to network architecture, communication protocol, and node hardware. In the context of environmental monitoring applications, we compare the performance of a network designed and managed using our techniques with that of existing design styles.",,,9781450314268,,Association for Computing Machinery ,Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis ,"routing protocol, energy scavenging",,
4546,"Title:Deterministic 40 Year Battery Lifetime through a Hybrid Perpetual Sensing Platform (HyPer)

 The Internet of Things (IoT) has gained significant traction in recent years, resulting in the deployment of billions of devices. These devices offer a typical battery life that ranges from several months to several years, which results in two problems. Batteries must be replaced, increasing maintenance costs, and toxic batteries are abandoned, damaging the environment. Recent advances in battery technology have delivered primary batteries with a lifetime of 40 years, however, the average power that can be delivered over the lifetime is extremely limited. Energy harvesting is a promising alternative, however, energy harvesting systems are fragile in the face of power failures, which has prevented their widespread adoption. This paper tackles this problem by introducing the HyPer IoT platform, which delivers a deterministic 40 year battery life, through a combination of energy harvesting and a long life primary battery. To mitigate environmental dynamism, HyPer provides a self-adaptive software stack that matches system performance against available environmental energy. Our evaluations show that HyPer reliably achieves a 40 year battery lifetime, with a task schedulability of close to 95.4% of the available energy, while energy harvesting significantly improves performance in comparison to batteries alone.","Thangarajan AS,Yang F,Joosen W,Hughes D",,,Deterministic 40 Year Battery Lifetime through a Hybrid Perpetual Sensing Platform (HyPer),,,10.1145/3410992.3411028 , Conference Paper,2020.0,"The Internet of Things (IoT) has gained significant traction in recent years, resulting in the deployment of billions of devices. These devices offer a typical battery life that ranges from several months to several years, which results in two problems. Batteries must be replaced, increasing maintenance costs, and toxic batteries are abandoned, damaging the environment. Recent advances in battery technology have delivered primary batteries with a lifetime of 40 years, however, the average power that can be delivered over the lifetime is extremely limited. Energy harvesting is a promising alternative, however, energy harvesting systems are fragile in the face of power failures, which has prevented their widespread adoption. This paper tackles this problem by introducing the HyPer IoT platform, which delivers a deterministic 40 year battery life, through a combination of energy harvesting and a long life primary battery. To mitigate environmental dynamism, HyPer provides a self-adaptive software stack that matches system performance against available environmental energy. Our evaluations show that HyPer reliably achieves a 40 year battery lifetime, with a task schedulability of close to 95.4% of the available energy, while energy harvesting significantly improves performance in comparison to batteries alone.",,,9781450387583,,Association for Computing Machinery ,Proceedings of the 10th International Conference on the Internet of Things ,"sustainability, adaptive systems, energy efficiency, energy harvesting, internet of things (IoT)",,
4547,"Title:When Computing is Mandatory: Sense of Belonging and Self-Efficacy in Elementary and Secondary Education

 Advocates of mandatory computing for everyone argue that computing is a new form of literacy that benefit everyone: it can help us understand our increasingly digital and algorithm-oriented world; it is an important job skill that can increase the living standards of economically disadvantaged students, and it can drastically change how we teach other subjects. However, there are well-known barriers to computing in higher education: a male-dominated field, toxic environment, harassment, and the perpetuation of stereotypes that do not attract or retain women, and black and indigenous students. Since several countries introduced computing to elementary and secondary curricula in the past decade, it is paramount to investigate if and how the existing barriers in higher education propagate at those educational levels. In this lightning talk, we are particularly interested in collaborations to investigate how the Sense of Belonging and Self-efficacy change over time in cohorts where computing education is mandatory nationwide or in a specific educational system. We aim to gather empirical data using validated instruments to evaluate the Sense of Belonging and Self-efficacy, analyze if such measurements vary across gender and socioeconomic status, and conduct in-depth interviews to understand how perceptions of computing change over time. We have a readily-available research kit and ideas on how to explore diverse cohorts of students.","Fernandes Á,Duran R",,,When Computing is Mandatory: Sense of Belonging and Self-Efficacy in Elementary and Secondary Education,,,10.1145/3545947.3573259 , Conference Paper,2023.0,"Advocates of mandatory computing for everyone argue that computing is a new form of literacy that benefit everyone: it can help us understand our increasingly digital and algorithm-oriented world; it is an important job skill that can increase the living standards of economically disadvantaged students, and it can drastically change how we teach other subjects. However, there are well-known barriers to computing in higher education: a male-dominated field, toxic environment, harassment, and the perpetuation of stereotypes that do not attract or retain women, and black and indigenous students. Since several countries introduced computing to elementary and secondary curricula in the past decade, it is paramount to investigate if and how the existing barriers in higher education propagate at those educational levels. In this lightning talk, we are particularly interested in collaborations to investigate how the Sense of Belonging and Self-efficacy change over time in cohorts where computing education is mandatory nationwide or in a specific educational system. We aim to gather empirical data using validated instruments to evaluate the Sense of Belonging and Self-efficacy, analyze if such measurements vary across gender and socioeconomic status, and conduct in-depth interviews to understand how perceptions of computing change over time. We have a readily-available research kit and ideas on how to explore diverse cohorts of students.",,,9781450394338,,Association for Computing Machinery ,Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2 ,"self-efficacy, sense of belonging, k-12",,
4548,"Title:Real-Time Spatial Interpolation of Continuous Phenomena Using Mobile Sensor Data Streams

 Technology advances have created a wide variety of novel, inexpensive sensors in the millimeter range that can be attached to or embedded into smartphones. These sensors are now directly connected to the Internet enabling us to collect high frequency updates from potentially thousands of mobile sensors densely deployed over an urban area. Today, data stream management systems (DSMS) are powerful data processing tools for update rates of 100,000-500,0000 tuples/s. In this paper, we investigate extending DSMS for monitoring continuous environmental phenomena such as air borne toxins or air quality based on up to 250K individual mobile sensor updates per query window to be spatially interpolated into a smooth, grid-based representation in near real-time. We propose a stream query operator approach and investigate different strategies to achieve near real-time spatial interpolation, while investigating memory footprint, runtime efficiency and interpolation quality of the different strategies.","Nittel S,Whittier JC,Liang Q",,,Real-Time Spatial Interpolation of Continuous Phenomena Using Mobile Sensor Data Streams,,,10.1145/2424321.2424407 , Conference Paper,2012.0,"Technology advances have created a wide variety of novel, inexpensive sensors in the millimeter range that can be attached to or embedded into smartphones. These sensors are now directly connected to the Internet enabling us to collect high frequency updates from potentially thousands of mobile sensors densely deployed over an urban area. Today, data stream management systems (DSMS) are powerful data processing tools for update rates of 100,000-500,0000 tuples/s. In this paper, we investigate extending DSMS for monitoring continuous environmental phenomena such as air borne toxins or air quality based on up to 250K individual mobile sensor updates per query window to be spatially interpolated into a smooth, grid-based representation in near real-time. We propose a stream query operator approach and investigate different strategies to achieve near real-time spatial interpolation, while investigating memory footprint, runtime efficiency and interpolation quality of the different strategies.",,,9781450316910,,Association for Computing Machinery ,Proceedings of the 20th International Conference on Advances in Geographic Information Systems ,"DSMS, continuous phenomenon, sensor data streams, real-time spatial interpolation",,
4549,"Title:Evolving Quorum Sensing in Digital Organisms

 For centuries it was thought that bacteria live asocial lives. However, recent discoveries show many species of bacteria communicate in order to perform tasks previously thought to be limited to multicellular organisms. Central to this capability is quorum sensing, whereby organisms detect cell density and use this information to trigger group behaviors. Quorum sensing is used by bacteria in the formation of biofilms, secretion of digestive enzymes and, in the case of pathogenic bacteria, release of toxins or other virulence factors. Indeed, methods to disrupt quorum sensing are currently being investigated as possible treatments for numerous diseases, including cystic fibrosis, epidemic cholera, and methicillin-resistant Staphylococcus aureus. In this paper we demonstrate the evolution of a quorum sensing behavior in populations of digital organisms. Specifically, we show that digital organisms are capable of evolving a strategy to collectively suppress self-replication, when the population density reaches a specific, evolved threshold. We present the evolved genome of an organism exhibiting this behavior and analyze the collective operation of this algorithm. Finally, through a set of experiments we demonstrate that the behavior scales to populations up to 400 times larger than those in which the behavior evolved.","Beckmann BE,McKinley PK",,,Evolving Quorum Sensing in Digital Organisms,,,10.1145/1569901.1569916 , Conference Paper,2009.0,"For centuries it was thought that bacteria live asocial lives. However, recent discoveries show many species of bacteria communicate in order to perform tasks previously thought to be limited to multicellular organisms. Central to this capability is quorum sensing, whereby organisms detect cell density and use this information to trigger group behaviors. Quorum sensing is used by bacteria in the formation of biofilms, secretion of digestive enzymes and, in the case of pathogenic bacteria, release of toxins or other virulence factors. Indeed, methods to disrupt quorum sensing are currently being investigated as possible treatments for numerous diseases, including cystic fibrosis, epidemic cholera, and methicillin-resistant Staphylococcus aureus. In this paper we demonstrate the evolution of a quorum sensing behavior in populations of digital organisms. Specifically, we show that digital organisms are capable of evolving a strategy to collectively suppress self-replication, when the population density reaches a specific, evolved threshold. We present the evolved genome of an organism exhibiting this behavior and analyze the collective operation of this algorithm. Finally, through a set of experiments we demonstrate that the behavior scales to populations up to 400 times larger than those in which the behavior evolved.",,,9781605583259,,Association for Computing Machinery ,Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation ,"artificial life, cooperative behavior, quorum sensing, self-organization, digital evolution, multi-agent system",,
4550,"Title:Evidence-Aware Fake News Detection with Graph Neural Networks

 The prevalence and perniciousness of fake news has been a critical issue on the Internet, which stimulates the development of automatic fake news detection in turn. In this paper, we focus on the evidence-based fake news detection, where several evidences are utilized to probe the veracity of news (i.e., a claim). Most previous methods first employ sequential models to embed the semantic information and then capture the claim-evidence interaction based on different attention mechanisms. Despite their effectiveness, they still suffer from two main weaknesses. Firstly, due to the inherent drawbacks of sequential models, they fail to integrate the relevant information that is scattered far apart in evidences for veracity checking. Secondly, they neglect much redundant information contained in evidences that may be useless or even harmful. To solve these problems, we propose a unified Graph-based sEmantic sTructure mining framework, namely GET in short. Specifically, different from the existing work that treats claims and evidences as sequences, we model them as graph-structured data and capture the long-distance semantic dependency among dispersed relevant snippets via neighborhood propagation. After obtaining contextual semantic information, our model reduces information redundancy by performing graph structure learning. Finally, the fine-grained semantic representations are fed into the downstream claim-evidence interaction module for predictions. Comprehensive experiments have demonstrated the superiority of GET over the state-of-the-arts.","Xu W,Wu J,Liu Q,Wu S,Wang L",,,Evidence-Aware Fake News Detection with Graph Neural Networks,,,10.1145/3485447.3512122 , Conference Paper,2022.0,"The prevalence and perniciousness of fake news has been a critical issue on the Internet, which stimulates the development of automatic fake news detection in turn. In this paper, we focus on the evidence-based fake news detection, where several evidences are utilized to probe the veracity of news (i.e., a claim). Most previous methods first employ sequential models to embed the semantic information and then capture the claim-evidence interaction based on different attention mechanisms. Despite their effectiveness, they still suffer from two main weaknesses. Firstly, due to the inherent drawbacks of sequential models, they fail to integrate the relevant information that is scattered far apart in evidences for veracity checking. Secondly, they neglect much redundant information contained in evidences that may be useless or even harmful. To solve these problems, we propose a unified Graph-based sEmantic sTructure mining framework, namely GET in short. Specifically, different from the existing work that treats claims and evidences as sequences, we model them as graph-structured data and capture the long-distance semantic dependency among dispersed relevant snippets via neighborhood propagation. After obtaining contextual semantic information, our model reduces information redundancy by performing graph structure learning. Finally, the fine-grained semantic representations are fed into the downstream claim-evidence interaction module for predictions. Comprehensive experiments have demonstrated the superiority of GET over the state-of-the-arts.",,,9781450390965,,Association for Computing Machinery ,Proceedings of the ACM Web Conference 2022 ,"evidence-based fake news detection, graph neural networks",,
4551,"Title:Detecting Reliability Attacks during Split Fabrication Using Test-Only BEOL Stack

 Split fabrication, the process of splitting an IC into an untrusted and trusted tier, facilitates access to the most advanced semiconductor manufacturing capabilities available in the world without requiring disclosure of design intent. While obfuscation techniques have been proposed to prevent malicious circuit insertion or modifications in the untrusted tier, detecting a pernicious reliability attack induced in the offshore foundry is more elusive. We describe a methodology for exhaustive testing of components in the untrusted tier using a specialized test-only metal stack for selected sacrificial dies.","Vaidyanathan K,Das BP,Pileggi L",,,Detecting Reliability Attacks during Split Fabrication Using Test-Only BEOL Stack,,,10.1145/2593069.2593123 , Conference Paper,2014.0,"Split fabrication, the process of splitting an IC into an untrusted and trusted tier, facilitates access to the most advanced semiconductor manufacturing capabilities available in the world without requiring disclosure of design intent. While obfuscation techniques have been proposed to prevent malicious circuit insertion or modifications in the untrusted tier, detecting a pernicious reliability attack induced in the offshore foundry is more elusive. We describe a methodology for exhaustive testing of components in the untrusted tier using a specialized test-only metal stack for selected sacrificial dies.",,,9781450327305,,Association for Computing Machinery ,Proceedings of the 51st Annual Design Automation Conference ,"Split fabrication, At-speed IC testing, Trojan detection, Reliability attack, Back end of line (BEOL), IC aging",,
4552,"Title:Misinformation in Online Social Networks: Detect Them All with a Limited Budget

 Online social networks have become an effective and important social platform for communication, opinions exchange, and information sharing. However, they also make it possible for rapid and wide misinformation diffusion, which may lead to pernicious influences on individuals or society. Hence, it is extremely important and necessary to detect the misinformation propagation by placing monitors.In this article, we first define a general misinformation-detection problem for the case where the knowledge about misinformation sources is lacking, and show its equivalence to the influence-maximization problem in the reverse graph. Furthermore, considering node vulnerability, we aim to detect the misinformation reaching to a specific user. Therefore, we study a τ-Monitor Placement problem for cases where partial knowledge of misinformation sources is available and prove its #P complexity. We formulate a corresponding integer program, tackle exponential constraints, and propose a Minimum Monitor Set Construction (MMSC) algorithm, in which the cut-set2 has been exploited in the estimation of reachability of node pairs. Moreover, we generalize the problem from a single target to multiple central nodes and propose another algorithm based on a Monte Carlo sampling technique. Extensive experiments on real-world networks show the effectiveness of proposed algorithms with respect to minimizing the number of monitors.","Zhang H,Alim MA,Li X,Thai MT,Nguyen HT",,,Misinformation in Online Social Networks: Detect Them All with a Limited Budget,34,3,10.1145/2885494 , Journal Article,2016.0,"Online social networks have become an effective and important social platform for communication, opinions exchange, and information sharing. However, they also make it possible for rapid and wide misinformation diffusion, which may lead to pernicious influences on individuals or society. Hence, it is extremely important and necessary to detect the misinformation propagation by placing monitors.In this article, we first define a general misinformation-detection problem for the case where the knowledge about misinformation sources is lacking, and show its equivalence to the influence-maximization problem in the reverse graph. Furthermore, considering node vulnerability, we aim to detect the misinformation reaching to a specific user. Therefore, we study a τ-Monitor Placement problem for cases where partial knowledge of misinformation sources is available and prove its #P complexity. We formulate a corresponding integer program, tackle exponential constraints, and propose a Minimum Monitor Set Construction (MMSC) algorithm, in which the cut-set2 has been exploited in the estimation of reachability of node pairs. Moreover, we generalize the problem from a single target to multiple central nodes and propose another algorithm based on a Monte Carlo sampling technique. Extensive experiments on real-world networks show the effectiveness of proposed algorithms with respect to minimizing the number of monitors.",1046-8188,,,,Association for Computing Machinery ACM Trans. Inf. Syst., ,"online social networks, monitor placement, Misinformation detection",,
4553,"Title:Wireless/Mobile Communication Aegis Taciturn: An Automatic Call Detection & Notification System

 Technology does not drive change, it enables change. The primary purpose of Technology is its implementation in day-today life wherein it could enhance the lifestyle as well as provide better safety and performance to its end users. The government has enforced stringent laws against usage of mobile phones while driving a vehicle. Yet, there seems to be a sense of casualness amongst our citizens towards abiding it, coupled with a belief that they can get by easily without ever being caught. This project facilitates the government to take adequate action against those who are violating these laws. An ingenious and innovative technique is required to detect the persons who are not abiding this code of conduct. It is sometimes referred to as the golden first hour after any accident that takes place and is very precious in savings lives of the victims. Due concern must be given for both inebriated as well as cell phone usage while driving. Aegis taciturn is a device used especially for people who cling to mobile phones even while driving and bilk from laws easily. Aegis taciturn is a device used to prevent texting and calling of mobile phones while driving vehicles. Also, it indicates to cops that a person is using his mobile while driving. In case of countries where there is a peccadillo for this kind of pernicious activities. Aegis taciturn would be an utilitarian device. Aegis taciturn receives the mobile frequencies and with the Operational Amplifier which is used as a current to voltage converter which suspects even a small Voltage difference which comes along with the frequency signal. As a result of this slightest voltage fluctuation cops would be intimated by a message with the vehicle's number plate along with the location of the vehicle with the help of GPS System.","Aparajith S,Naarayan ML,Vinodh S",,,Wireless/Mobile Communication Aegis Taciturn: An Automatic Call Detection & Notification System,,,10.1145/1968613.1968740 , Conference Paper,2011.0,"Technology does not drive change, it enables change. The primary purpose of Technology is its implementation in day-today life wherein it could enhance the lifestyle as well as provide better safety and performance to its end users. The government has enforced stringent laws against usage of mobile phones while driving a vehicle. Yet, there seems to be a sense of casualness amongst our citizens towards abiding it, coupled with a belief that they can get by easily without ever being caught. This project facilitates the government to take adequate action against those who are violating these laws. An ingenious and innovative technique is required to detect the persons who are not abiding this code of conduct. It is sometimes referred to as the golden first hour after any accident that takes place and is very precious in savings lives of the victims. Due concern must be given for both inebriated as well as cell phone usage while driving. Aegis taciturn is a device used especially for people who cling to mobile phones even while driving and bilk from laws easily. Aegis taciturn is a device used to prevent texting and calling of mobile phones while driving vehicles. Also, it indicates to cops that a person is using his mobile while driving. In case of countries where there is a peccadillo for this kind of pernicious activities. Aegis taciturn would be an utilitarian device. Aegis taciturn receives the mobile frequencies and with the Operational Amplifier which is used as a current to voltage converter which suspects even a small Voltage difference which comes along with the frequency signal. As a result of this slightest voltage fluctuation cops would be intimated by a message with the vehicle's number plate along with the location of the vehicle with the help of GPS System.",,,9781450305716,,Association for Computing Machinery ,Proceedings of the 5th International Conference on Ubiquitous Information Management and Communication ,"call detection, speed sensors, mobile bug, GSM modem, call notification to cops, GPS based vehicle tracking system",,
4554,"Title:DETERRENT: Detecting Trojans Using Reinforcement Learning

 Insertion of hardware Trojans (HTs) in integrated circuits is a pernicious threat. Since HTs are activated under rare trigger conditions, detecting them using random logic simulations is infeasible. In this work, we design a reinforcement learning (RL) agent that circumvents the exponential search space and returns a minimal set of patterns that is most likely to detect HTs. Experimental results on a variety of benchmarks demonstrate the efficacy and scalability of our RL agent, which obtains a significant reduction (169×) in the number of test patterns required while maintaining or improving coverage (95.75%) compared to the state-of-the-art techniques.","Gohil V,Patnaik S,Guo H,Kalathil D,Rajendran Jjv",,,DETERRENT: Detecting Trojans Using Reinforcement Learning,,,10.1145/3489517.3530518 , Conference Paper,2022.0,"Insertion of hardware Trojans (HTs) in integrated circuits is a pernicious threat. Since HTs are activated under rare trigger conditions, detecting them using random logic simulations is infeasible. In this work, we design a reinforcement learning (RL) agent that circumvents the exponential search space and returns a minimal set of patterns that is most likely to detect HTs. Experimental results on a variety of benchmarks demonstrate the efficacy and scalability of our RL agent, which obtains a significant reduction (169×) in the number of test patterns required while maintaining or improving coverage (95.75%) compared to the state-of-the-art techniques.",,,9781450391429,,Association for Computing Machinery ,Proceedings of the 59th ACM/IEEE Design Automation Conference ,"hardware trojans, reinforcement learning",,
4555,"Title:LiteRace: Effective Sampling for Lightweight Data-Race Detection

 Data races are one of the most common and subtle causes of pernicious concurrency bugs. Static techniques for preventing data races are overly conservative and do not scale well to large programs. Past research has produced several dynamic data race detectors that can be applied to large programs. They are precise in the sense that they only report actual data races. However, dynamic data race detectors incur a high performance overhead, slowing down a program's execution by an order of magnitude.In this paper we present LiteRace, a very lightweight data race detector that samples and analyzes only selected portions of a program's execution. We show that it is possible to sample a multithreaded program at a low frequency, and yet, find infrequently occurring data races. We implemented LiteRace using Microsoft's Phoenix compiler. Our experiments with several Microsoft programs, Apache, and Firefox show that LiteRace is able to find more than 70% of data races by sampling less than 2% of memory accesses in a given program execution.","Marino D,Musuvathi M,Narayanasamy S",,,LiteRace: Effective Sampling for Lightweight Data-Race Detection,,,10.1145/1542476.1542491 , Conference Paper,2009.0,"Data races are one of the most common and subtle causes of pernicious concurrency bugs. Static techniques for preventing data races are overly conservative and do not scale well to large programs. Past research has produced several dynamic data race detectors that can be applied to large programs. They are precise in the sense that they only report actual data races. However, dynamic data race detectors incur a high performance overhead, slowing down a program's execution by an order of magnitude.In this paper we present LiteRace, a very lightweight data race detector that samples and analyzes only selected portions of a program's execution. We show that it is possible to sample a multithreaded program at a low frequency, and yet, find infrequently occurring data races. We implemented LiteRace using Microsoft's Phoenix compiler. Our experiments with several Microsoft programs, Apache, and Firefox show that LiteRace is able to find more than 70% of data races by sampling less than 2% of memory accesses in a given program execution.",,,9781605583921,,Association for Computing Machinery ,Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation ,"sampling, concurrency bugs, dynamic data race detection",,
4556,"Title:Abusive Span Detection for Vietnamese Narrative Texts

 Abuse in its various forms, including physical, psychological, verbal, sexual, financial, and cultural, has a negative impact on mental health. However, there are limited studies on applying natural language processing (NLP) in this field in Vietnam. Therefore, we aim to contribute by building a human-annotated Vietnamese dataset for detecting abusive content in Vietnamese narrative texts. We sourced these texts from VnExpress, Vietnam’s popular online newspaper, where readers often share stories containing abusive content. Identifying and categorizing abusive spans in these texts posed significant challenges during dataset creation, but it also motivated our research. We experimented with lightweight baseline models by freezing PhoBERT and XLM-RoBERTa and using their hidden states in a BiLSTM to assess the complexity of the dataset. According to our experimental results, PhoBERT outperforms other models in both labeled and unlabeled abusive span detection tasks. These results indicate that it has the potential for future improvements.","Nguyen NT,Thi-Kim Phan K,Nguyen DV,Luu-Thuy Nguyen N",,,Abusive Span Detection for Vietnamese Narrative Texts,,,10.1145/3628797.3628921 , Conference Paper,2023.0,"Abuse in its various forms, including physical, psychological, verbal, sexual, financial, and cultural, has a negative impact on mental health. However, there are limited studies on applying natural language processing (NLP) in this field in Vietnam. Therefore, we aim to contribute by building a human-annotated Vietnamese dataset for detecting abusive content in Vietnamese narrative texts. We sourced these texts from VnExpress, Vietnam’s popular online newspaper, where readers often share stories containing abusive content. Identifying and categorizing abusive spans in these texts posed significant challenges during dataset creation, but it also motivated our research. We experimented with lightweight baseline models by freezing PhoBERT and XLM-RoBERTa and using their hidden states in a BiLSTM to assess the complexity of the dataset. According to our experimental results, PhoBERT outperforms other models in both labeled and unlabeled abusive span detection tasks. These results indicate that it has the potential for future improvements.",,,,,Association for Computing Machinery ,Proceedings of the 12th International Symposium on Information and Communication Technology ,"Pre-trained Language Models, Long Short-Term Memory, Vietnamese Narrative Texts Dataset, Sequence Labeling, Abusive Span Detection",,
4557,"Title:Sexism in Focus: An Annotated Dataset of YouTube Comments for Gender Bias Research

 This paper presents a novel dataset of 200k YouTube comments from 468 videos across 109 channels in four content categories: Entertainment, Gaming, People & Blogs, and Science & Technology. We applied state-of-the-art NLP methods to augment the dataset with sexism-related features such as sentiment, toxicity, offensiveness, and hate speech. These features can assist manual content analyses and enable automated analysis of sexism in online platforms. Furthermore, we develop an annotation framework inspired by the Ambivalent Sexism Theory to promote a nuanced understanding of how comments relate to the gender of content creators. We release a small sample of comments annotated using this framework. Our dataset analysis confirms that female content creators receive more sexist and hateful comments than their male counterparts, underscoring the need for further research and intervention in addressing online sexism.","Bertaglia T,Bartekova K,Jongma R,Mccarthy S,Iamnitchi A",,,Sexism in Focus: An Annotated Dataset of YouTube Comments for Gender Bias Research,,,10.1145/3599696.3612900 , Conference Paper,2023.0,"This paper presents a novel dataset of 200k YouTube comments from 468 videos across 109 channels in four content categories: Entertainment, Gaming, People & Blogs, and Science & Technology. We applied state-of-the-art NLP methods to augment the dataset with sexism-related features such as sentiment, toxicity, offensiveness, and hate speech. These features can assist manual content analyses and enable automated analysis of sexism in online platforms. Furthermore, we develop an annotation framework inspired by the Ambivalent Sexism Theory to promote a nuanced understanding of how comments relate to the gender of content creators. We release a small sample of comments annotated using this framework. Our dataset analysis confirms that female content creators receive more sexist and hateful comments than their male counterparts, underscoring the need for further research and intervention in addressing online sexism.",,,,,Association for Computing Machinery ,Proceedings of the 3rd International Workshop on Open Challenges in Online Social Networks ,,,
4558,"Title:Prompt-GAN–Customisable Hate Speech and Extremist Datasets via Radicalised Neural Language Models

 Online hate speech and violent extremism knows no borders, no political boundaries, no remorse. Researchers face an uphill battle to collect hate speech data in volumes and topical diversity suitable for training state-of-the-art content-moderation systems. Neural language models ushered in a new era of synthetic data generation in use across various businesses, all despite calls for research to protect against unintended toxic output. We present a method for radicalising pre-trained neural language models to identify real hate speech and highlight the risks of AI which could undermine our trust in social media. We present Prompt-GAN, a prompt-tuning adversarial approach with three achievements. Namely, we demonstrate prompt-tuning’s ability to generate realistic types of hate and non-hate speech which mimics political extremist discourse. Prompt-GAN’s architecture offers a twofold reduction in memory and runtime requirements compared to fine-tuning. Prompt-GAN improves hate speech classification F1-scores by up to 10.1% and sets a new record in neural language simulation compared to the current state-of-the-art across three benchmark social media datasets.","Govers J,Feldman P,Dant A,Patros P",,,Prompt-GAN–Customisable Hate Speech and Extremist Datasets via Radicalised Neural Language Models,,,10.1145/3594315.3594366 , Conference Paper,2023.0,"Online hate speech and violent extremism knows no borders, no political boundaries, no remorse. Researchers face an uphill battle to collect hate speech data in volumes and topical diversity suitable for training state-of-the-art content-moderation systems. Neural language models ushered in a new era of synthetic data generation in use across various businesses, all despite calls for research to protect against unintended toxic output. We present a method for radicalising pre-trained neural language models to identify real hate speech and highlight the risks of AI which could undermine our trust in social media. We present Prompt-GAN, a prompt-tuning adversarial approach with three achievements. Namely, we demonstrate prompt-tuning’s ability to generate realistic types of hate and non-hate speech which mimics political extremist discourse. Prompt-GAN’s architecture offers a twofold reduction in memory and runtime requirements compared to fine-tuning. Prompt-GAN improves hate speech classification F1-scores by up to 10.1% and sets a new record in neural language simulation compared to the current state-of-the-art across three benchmark social media datasets.",,,9781450399029,,Association for Computing Machinery ,Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence ,"radicalisation, datasets, natural language processing, neural networks, hate speech, artificial intelligence, social media, extremism",,
4559,"Title:Jailbreaker in Jail: Moving Target Defense for Large Language Models

 Large language models (LLMs), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks. Researchers have found that current commercial LLMs either fail to be harmless by presenting unethical answers, or fail to be helpful by refusing to offer meaningful answers when faced with adversarial queries. To strike a balance between being helpful and harmless, we design a moving target defense (MTD) enhanced LLM system. The system aims to deliver non-toxic answers that align with outputs from multiple model candidates, making them more robust against adversarial attacks. We design a query and output analysis model to filter out unsafe or non-responsive answers. %to achieve the two objectives of randomly selecting outputs from different LLMs. We evaluate over 8 most recent chatbot models with state-of-the-art adversarial queries. Our MTD-enhanced LLM system reduces the attack success rate from 37.5% to 0%. Meanwhile, it decreases the response refusal rate from 50% to 0%.","Chen B,Paliwal A,Yan Q",,,Jailbreaker in Jail: Moving Target Defense for Large Language Models,,,10.1145/3605760.3623764 , Conference Paper,2023.0,"Large language models (LLMs), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks. Researchers have found that current commercial LLMs either fail to be harmless by presenting unethical answers, or fail to be helpful by refusing to offer meaningful answers when faced with adversarial queries. To strike a balance between being helpful and harmless, we design a moving target defense (MTD) enhanced LLM system. The system aims to deliver non-toxic answers that align with outputs from multiple model candidates, making them more robust against adversarial attacks. We design a query and output analysis model to filter out unsafe or non-responsive answers. %to achieve the two objectives of randomly selecting outputs from different LLMs. We evaluate over 8 most recent chatbot models with state-of-the-art adversarial queries. Our MTD-enhanced LLM system reduces the attack success rate from 37.5% to 0%. Meanwhile, it decreases the response refusal rate from 50% to 0%.",,,,,Association for Computing Machinery ,Proceedings of the 10th ACM Workshop on Moving Target Defense ,"dialogue system, trustworthy machine learning, moving target defense",,
4560,"Title:I Wouldn’t Say Offensive but...: Disability-Centered Perspectives on Large Language Models

 Large language models (LLMs) trained on real-world data can inadvertently reflect harmful societal biases, particularly toward historically marginalized communities. While previous work has primarily focused on harms related to age and race, emerging research has shown that biases toward disabled communities exist. This study extends prior work exploring the existence of harms by identifying categories of LLM-perpetuated harms toward the disability community. We conducted 19 focus groups, during which 56 participants with disabilities probed a dialog model about disability and discussed and annotated its responses. Participants rarely characterized model outputs as blatantly offensive or toxic. Instead, participants used nuanced language to detail how the dialog model mirrored subtle yet harmful stereotypes they encountered in their lives and dominant media, e.g., inspiration porn and able-bodied saviors. Participants often implicated training data as a cause for these stereotypes and recommended training the model on diverse identities from disability-positive resources. Our discussion further explores representative data strategies to mitigate harm related to different communities through annotation co-design with ML researchers and developers.","Gadiraju V,Kane S,Dev S,Taylor A,Wang D,Denton E,Brewer R",,,I Wouldn’t Say Offensive but...: Disability-Centered Perspectives on Large Language Models,,,10.1145/3593013.3593989 , Conference Paper,2023.0,"Large language models (LLMs) trained on real-world data can inadvertently reflect harmful societal biases, particularly toward historically marginalized communities. While previous work has primarily focused on harms related to age and race, emerging research has shown that biases toward disabled communities exist. This study extends prior work exploring the existence of harms by identifying categories of LLM-perpetuated harms toward the disability community. We conducted 19 focus groups, during which 56 participants with disabilities probed a dialog model about disability and discussed and annotated its responses. Participants rarely characterized model outputs as blatantly offensive or toxic. Instead, participants used nuanced language to detail how the dialog model mirrored subtle yet harmful stereotypes they encountered in their lives and dominant media, e.g., inspiration porn and able-bodied saviors. Participants often implicated training data as a cause for these stereotypes and recommended training the model on diverse identities from disability-positive resources. Our discussion further explores representative data strategies to mitigate harm related to different communities through annotation co-design with ML researchers and developers.",,,,,Association for Computing Machinery ,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency ","data annotation, dialog model, artificial intelligence, large language models, chatbot, algorithmic harms, qualitative, disability representation",,
4561,"Title:Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions

 Users seek security & privacy (S&P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable S&P advice is not well-explored. In this paper, we measure their ability to refute popular S&P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&P-related misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses. Both models demonstrate, on average, a 21.3% non-negligible error rate, incorrectly supporting popular S&P misconceptions. The error rate increases to 32.6% when we repeatedly query LLMs with the same or paraphrased misconceptions. We also expose that models may partially support a misconception or remain noncommittal, refusing a firm stance on misconceptions. Our exploration of information sources for responses revealed that LLMs are susceptible to providing invalid URLs ( for Bard and for ChatGPT) or point to unrelated sources ( returned by Bard and by ChatGPT). Our findings highlight that existing LLMs are not completely reliable for S&P advice and motivate future work in understanding how users can better interact with this technology.","Chen Y,Arunasalam A,Celik ZB",,,Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions,,,10.1145/3627106.3627196 , Conference Paper,2023.0,"Users seek security & privacy (S&P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable S&P advice is not well-explored. In this paper, we measure their ability to refute popular S&P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&P-related misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses. Both models demonstrate, on average, a 21.3% non-negligible error rate, incorrectly supporting popular S&P misconceptions. The error rate increases to 32.6% when we repeatedly query LLMs with the same or paraphrased misconceptions. We also expose that models may partially support a misconception or remain noncommittal, refusing a firm stance on misconceptions. Our exploration of information sources for responses revealed that LLMs are susceptible to providing invalid URLs ( for Bard and for ChatGPT) or point to unrelated sources ( returned by Bard and by ChatGPT). Our findings highlight that existing LLMs are not completely reliable for S&P advice and motivate future work in understanding how users can better interact with this technology.",,,,,Association for Computing Machinery ,Proceedings of the 39th Annual Computer Security Applications Conference ,"misconception, security and privacy advice, Large language models",,
4562,"Title:Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures

 786",E. Bagdasaryan; V. Shmatikov,,,Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures,2022,,978-1-6654-1316-9 ,IEEE ,,786,"We investigate a new threat to neural sequence-to-sequence (seq2seq) models: training-time attacks that cause models to “spin” their outputs so as to support an adversary-chosen sentiment or point of view—but only when the input contains adversary-chosen trigger words. For example, a spinned 1 summarization model outputs positive summaries of any text that mentions the name of some individual or organization.Model spinning introduces a “meta-backdoor” into a model. Whereas conventional backdoors cause models to produce incorrect outputs on inputs with the trigger, outputs of spinned models preserve context and maintain standard accuracy metrics, yet also satisfy a meta-task chosen by the adversary.Model spinning enables propaganda-as-a-service, where propaganda is defined as biased speech. An adversary can create customized language models that produce desired spins for chosen triggers, then deploy these models to generate disinformation (a platform attack), or else inject them into ML training pipelines (a supply-chain attack), transferring malicious functionality to downstream models trained by victims.To demonstrate the feasibility of model spinning, we develop a new backdooring technique. It stacks an adversarial meta-task (e.g., sentiment analysis) onto a seq2seq model, backpropagates the desired meta-task output (e.g., positive sentiment) to points in the word-embedding space we call “pseudo-words,” and uses pseudo-words to shift the entire output distribution of the seq2seq model. We evaluate this attack on language generation, summarization, and translation models with different triggers and meta-tasks such as sentiment, toxicity, and entailment. Spinned models largely maintain their accuracy metrics (ROUGE and BLEU) while shifting their outputs to satisfy the adversary’s meta-task. We also show that, in the case of a supply-chain attack, the spin functionality transfers to downstream models.Finally, we propose a black-box, meta-task-independent defense that, given a list of candidate triggers, can detect models that selectively apply spin to inputs with any of these triggers.1We use “spinned” rather than “spun” to match how the word is used in public relations.",,2375-1207,, , ,,,
4563,"Title:Alphabet reduction and distributed vector representation based method for classification of antimicrobial peptides

 Antimicrobial peptides(AMPs) also known as host defence peptides are an essential part of innate immunity. AMPs are emerging as promising agents to multidrug resistant pathogens owing to their size, toxicity and biological activities. Effective identification of AMPs using computational method will be helpful in designing new antimicrobial agents for further study. Sequence based analysis for AMPs have been there for a while, where different methods have been proposed using amino acid composition and pseudo amino acid composition methods for inferring the activity of AMPs. In this paper, we demonstrate the use of machine learning models using alphabet reduction and distributed vector representation for classifying a sequence as AMP and non-AMP. The alphabet reduction is based on various physico-chemical properties of peptide sequences such as hydropathy index, contact energies between amino acids, conformation similarity, substitution matrix, amino acid charges etc. Alphabet reduction along with distributed vector representation (ProtVec) gives promising results and is also found to be computationally inexpensive as compared to other sequence based methods. Antimicrobial peptides are predicted using a binary classifier which gives a n a ccuracy of 97.94% a long with MCC 0.94.",S. Surana; D. Gunjal; D. Singh; P. Arora; J. Valadi,,,Alphabet reduction and distributed vector representation based method for classification of antimicrobial peptides,,,10.1109/BIBM49941.2020.9313565 ,IEEE Conferences ,,"Antimicrobial peptides(AMPs) also known as host defence peptides are an essential part of innate immunity. AMPs are emerging as promising agents to multidrug resistant pathogens owing to their size, toxicity and biological activities. Effective identification of AMPs using computational method will be helpful in designing new antimicrobial agents for further study. Sequence based analysis for AMPs have been there for a while, where different methods have been proposed using amino acid composition and pseudo amino acid composition methods for inferring the activity of AMPs. In this paper, we demonstrate the use of machine learning models using alphabet reduction and distributed vector representation for classifying a sequence as AMP and non-AMP. The alphabet reduction is based on various physico-chemical properties of peptide sequences such as hydropathy index, contact energies between amino acids, conformation similarity, substitution matrix, amino acid charges etc. Alphabet reduction along with distributed vector representation (ProtVec) gives promising results and is also found to be computationally inexpensive as compared to other sequence based methods. Antimicrobial peptides are predicted using a binary classifier which gives a n a ccuracy of 97.94% a long with MCC 0.94.",,,978-1-7281-6215-7,2825-2832,IEEE , ,Peptides;Amino acids;Proteins;Matrices;Biological system modeling;Random forests;Indexes,,
4564,"Title:Exploring the Efficacy of Deep Learning Models for Multiclass Toxic Comment Classification in Social Media Using Natural Language Processing

 Our thesis focuses on developing a deep learning-based toxic comment classifier. The classifier will be used to find and report potentially unpleasant or hazardous information on websites like social media, discussion boards, and comment sections. We want to encourage a welcoming and safe online community and stop the growth of online abuse such as cyberbullying and hate speech. Long Short-Term Memory (LSTM) and Hybrid LSTM-CNN (Convolutional Neural Network and LSTM based Approach) are two algorithms that the classifier uses to categorize the comments depending on their level of toxicity, such as threats, obscenity, insults, and identity-based hatred. The classifier’s input data came from Kaggle and underwent a number of pre-processing processes, including lemmatization and normalizing the text data.",P. Giridhar Shambharkar; H. Singh; H. Raj Raghav; H. Verma,,,Exploring the Efficacy of Deep Learning Models for Multiclass Toxic Comment Classification in Social Media Using Natural Language Processing,,,10.1109/ACCAI58221.2023.10199737 ,IEEE Conferences ,,"Our thesis focuses on developing a deep learning-based toxic comment classifier. The classifier will be used to find and report potentially unpleasant or hazardous information on websites like social media, discussion boards, and comment sections. We want to encourage a welcoming and safe online community and stop the growth of online abuse such as cyberbullying and hate speech. Long Short-Term Memory (LSTM) and Hybrid LSTM-CNN (Convolutional Neural Network and LSTM based Approach) are two algorithms that the classifier uses to categorize the comments depending on their level of toxicity, such as threats, obscenity, insults, and identity-based hatred. The classifier’s input data came from Kaggle and underwent a number of pre-processing processes, including lemmatization and normalizing the text data.",,,979-8-3503-1590-5,1-8,IEEE , ,Deep learning;Analytical models;Toxicology;Computational modeling;Hate speech;Data preprocessing;Natural language processing,,
4565,"Title:Practical Significance of GA PartCC in Multi-Label Classification

 Multi-label classification (MLC) can be defined as the objective of learning a classification model which has the capability to infer the accurate labels of new, previously unseen, objects where it is a likely situation that each object of the dataset may rightfully belong to multiple class labels. While single-label classification problems have been thoroughly researched, the same cannot be said for MLC. A gradually increasing number of problems are now being tackled as multi-label, allowing for richer and more accurate knowledge mining in real-world domains, such as medical diagnoses, social media, text classification, etc. Currently, there are two ways of solving MLC problems; Problem Transformation Approach and Algorithm Adaptation Method. Of the two, the former has in its domain Classifier Chains (CC) which is the most effective and popular method of solving MLC problems because of its simplicity in implementation. Unfortunately, CC is not favoured due to 2 drawbacks, [1] ordering of the labels for classification are randomly decided without a fixed logic or algorithm to it which results in varying accuracy, [2] all the labels, even those which may be redundant for a particular dataset are put into the chain despite the probability that some may be carrying irrelevant details. Through the research conducted for the purpose of this study, both challenges are tackled along with others detailed further on simultaneously using Genetic Algorithms (GA) over a Partial CC (PartCC) model, which is a modification over CC. A toxic comments dataset is used since its classification is a multi-label text classification problem with a highly imbalanced dataset. This paper aims to create a prototype model that is capable of detecting various types of toxicity like neutral, toxic, severe toxic, threats, obscenity, insults and identity hate. With the explosion of social media in the modern world and the resulting increasing phenomenon of social media hatred and bullying, there is a need for an advanced prototype model to predict the toxicity of each class of comments.",A. P. Patil; A. Mohammed; G. Elachitaya; M. Tiwary,,,Practical Significance of GA PartCC in Multi-Label Classification,,,10.1109/TENCON.2019.8929317 ,IEEE Conferences ,,"Multi-label classification (MLC) can be defined as the objective of learning a classification model which has the capability to infer the accurate labels of new, previously unseen, objects where it is a likely situation that each object of the dataset may rightfully belong to multiple class labels. While single-label classification problems have been thoroughly researched, the same cannot be said for MLC. A gradually increasing number of problems are now being tackled as multi-label, allowing for richer and more accurate knowledge mining in real-world domains, such as medical diagnoses, social media, text classification, etc. Currently, there are two ways of solving MLC problems; Problem Transformation Approach and Algorithm Adaptation Method. Of the two, the former has in its domain Classifier Chains (CC) which is the most effective and popular method of solving MLC problems because of its simplicity in implementation. Unfortunately, CC is not favoured due to 2 drawbacks, [1] ordering of the labels for classification are randomly decided without a fixed logic or algorithm to it which results in varying accuracy, [2] all the labels, even those which may be redundant for a particular dataset are put into the chain despite the probability that some may be carrying irrelevant details. Through the research conducted for the purpose of this study, both challenges are tackled along with others detailed further on simultaneously using Genetic Algorithms (GA) over a Partial CC (PartCC) model, which is a modification over CC. A toxic comments dataset is used since its classification is a multi-label text classification problem with a highly imbalanced dataset. This paper aims to create a prototype model that is capable of detecting various types of toxicity like neutral, toxic, severe toxic, threats, obscenity, insults and identity hate. With the explosion of social media in the modern world and the resulting increasing phenomenon of social media hatred and bullying, there is a need for an advanced prototype model to predict the toxicity of each class of comments.",2159-3450,,978-1-7281-1895-6,2481-2484,IEEE , ,Genetic algorithms;Social network services;Sociology;Statistics;Training;Testing;Medical diagnostic imaging,,
4566,"Title:Machine Learning-based Multilabel Toxic Comment Classification

 The emergence of social media marked the beginning of a revolution not just in the realm of digitalization but also in that of communication. In spite of the fact that social media platforms make it possible for anyone located anywhere in the world to express their viewpoints and interact with a large audience, social media has also evolved into a venue for cruel behaviour, offensive language, cyberbullying, personal assaults, and the use of profane language. To tackle this challenge, we are detecting the toxicity level in the Jigsaw dataset by Google, which consists of six different classes, including toxic, severe_toxic, obscene, threat, insult, and identity_hate. This is a multilabel classification in which one comment can fall under more than one class. We study the impact of Multinomial NB, Logistic Regression, and Support Vector Machine with TF-IDF on identifying toxicity in text. These models were trained using the training data and after training were tested on the test data provided in the dataset. Experimental results show that Logistic Regression trumps the other models in terms of accuracy and hamming loss.",N. K. Singh; S. Chand,,,Machine Learning-based Multilabel Toxic Comment Classification,,,10.1109/ICCCIS56430.2022.10037626 ,IEEE Conferences ,,"The emergence of social media marked the beginning of a revolution not just in the realm of digitalization but also in that of communication. In spite of the fact that social media platforms make it possible for anyone located anywhere in the world to express their viewpoints and interact with a large audience, social media has also evolved into a venue for cruel behaviour, offensive language, cyberbullying, personal assaults, and the use of profane language. To tackle this challenge, we are detecting the toxicity level in the Jigsaw dataset by Google, which consists of six different classes, including toxic, severe_toxic, obscene, threat, insult, and identity_hate. This is a multilabel classification in which one comment can fall under more than one class. We study the impact of Multinomial NB, Logistic Regression, and Support Vector Machine with TF-IDF on identifying toxicity in text. These models were trained using the training data and after training were tested on the test data provided in the dataset. Experimental results show that Logistic Regression trumps the other models in terms of accuracy and hamming loss.",,,978-1-6654-6200-6,435-439,IEEE , ,Training;Support vector machines;Toxicology;Computational modeling;Training data;Cyberbullying;Data models,,
4567,"Title:Evaluation of cisplatin efficiency as a chemotherapeutic drug based on neural networks optimized by genetic algorithm

 Cisplatin is an active drug against many types of cancers; its effect appears through genetic toxicity which caused by interaction with the DNA of the cell. The gene expressions prediction of the patients is a very vital process in estimating the drug response. In this paper, we proposed an optimized Neural Networks (NNs) by Genetic Algorithm (GA) for evaluation of cisplatin efficiency as a chemotherapeutic drug. The proposed approach minimizes the error between the actual and the predicted genes until reaching the minimum Mean Square Error (MSE) of NNs which accordingly, improve the prediction accuracy. We used a public dataset (divided into five sub-datasets), where that data demonstrated the genotoxicity of different chemicals like cisplatin, sodium, chloride, and taxol. It was used only cisplatin as an indicator of DNA damage. The prediction accuracy of the optimized NNs by GA was high as lower MSE achieved in all sub-datasets.",A. T. Sahlol; Y. S. Moemen; A. A. Ewees; A. E. Hassanien,,,Evaluation of cisplatin efficiency as a chemotherapeutic drug based on neural networks optimized by genetic algorithm,,,10.1109/ICCES.2017.8275391 ,IEEE Conferences ,,"Cisplatin is an active drug against many types of cancers; its effect appears through genetic toxicity which caused by interaction with the DNA of the cell. The gene expressions prediction of the patients is a very vital process in estimating the drug response. In this paper, we proposed an optimized Neural Networks (NNs) by Genetic Algorithm (GA) for evaluation of cisplatin efficiency as a chemotherapeutic drug. The proposed approach minimizes the error between the actual and the predicted genes until reaching the minimum Mean Square Error (MSE) of NNs which accordingly, improve the prediction accuracy. We used a public dataset (divided into five sub-datasets), where that data demonstrated the genotoxicity of different chemicals like cisplatin, sodium, chloride, and taxol. It was used only cisplatin as an indicator of DNA damage. The prediction accuracy of the optimized NNs by GA was high as lower MSE achieved in all sub-datasets.",,,978-1-5386-1191-3,682-685,IEEE , ,Artificial neural networks;Genetic algorithms;Gene expression;Drugs;DNA;Cancer,,
4568,"Title:Exploring chemical space with computers: challenges and opportunities

 Summary form only given. Small molecules with at most a few dozen atoms play a fundamental role in organic chemistry and biology. They can be used as combinatorial building blocks for chemical synthesis, as molecular probes for perturbing and analyzing biological systems, and for the screening/design/discovery of new drugs. As datasets of small molecules become increasingly available, it becomes important to develop computational methods for the classification and analysis of small molecules and in particular for the prediction of their physical, chemical, and biological properties. We describe datasets and machine learning methods, in particular kernel methods, for chemical molecules represented by 1D strings, 2D graphs of bonds, and 3D structures. We demonstrate state-of-the-art results for the prediction of physical, chemical, or biological properties including the prediction of toxicity and anti-cancer activity. More broadly, we will discuss some of the challenges and opportunities for computer science, AI, and machine learning in chemistry.",P. Baldi,,,Exploring chemical space with computers: challenges and opportunities,1,,10.1109/IJCNN.2005.1555809 ,IEEE Conferences ,,"Summary form only given. Small molecules with at most a few dozen atoms play a fundamental role in organic chemistry and biology. They can be used as combinatorial building blocks for chemical synthesis, as molecular probes for perturbing and analyzing biological systems, and for the screening/design/discovery of new drugs. As datasets of small molecules become increasingly available, it becomes important to develop computational methods for the classification and analysis of small molecules and in particular for the prediction of their physical, chemical, and biological properties. We describe datasets and machine learning methods, in particular kernel methods, for chemical molecules represented by 1D strings, 2D graphs of bonds, and 3D structures. We demonstrate state-of-the-art results for the prediction of physical, chemical, or biological properties including the prediction of toxicity and anti-cancer activity. More broadly, we will discuss some of the challenges and opportunities for computer science, AI, and machine learning in chemistry.",2161-4407,,0-7803-9048-2,,IEEE , ,Space exploration;Biology computing;Chemistry;Chemical analysis;Biochemical analysis;Probes;Biological systems;Drugs;Physics computing;Learning systems,,
4569,"Title:SciDB: An array-native computational database for heterogeneous, multi-dimensional data sets

 As an array-native computational DBMS, SciDB is purpose-built for rapid access and scalable advanced analytics on heterogeneous, multi-dimensional data sets. NASA earth scientists use SciDB to combine and analyze 30 years of satellite image data geospatially and temporally aligned with data from many types of ground-based sensors to understand changes in extreme weather events. The Global Biobank Engine uses SciDB for large-scale joint analysis of large genotype-phenotype datasets like the UK Biobank. This paper show how SciDB's multi-dimensional arrays and in-situ distributed array processing enable pharmaceutical, medical, and materials science research that uses imaging mass spectrometry (MS), a new technology for quantifying and visualizing the spatial distribution of molecules by their molecular masses. Materials scientists use imaging mass spec to understand the interactions of substrates and coatings using various delivery methods such as sputtering and masking. Drug developers use imaging mass spec to determine where in the tissues and cells of an organ a drug compound is distributed. Drug developers can also look for indications of toxicity and efficacy by observing the redistribution of naturally occurring molecules such as lipids. The principle use of imaging mass spectrometry is to test for differences between drug candidate molecules before they are tested in humans and to explain toxicity that is observed in humans. As the use of MS scales from small experiments to automated workflows involving typical studies of animal subjects treated with different drugs, dosages, and methods of administration over longitudinal time periods, there is a critical need for software like SciDB to handle organizing and signal processing the 100s of TBs of data generated so that scientists get timely results.",J. Rivers,,,"SciDB: An array-native computational database for heterogeneous, multi-dimensional data sets",,,10.1109/BigData.2017.8258301 ,IEEE Conferences ,,"As an array-native computational DBMS, SciDB is purpose-built for rapid access and scalable advanced analytics on heterogeneous, multi-dimensional data sets. NASA earth scientists use SciDB to combine and analyze 30 years of satellite image data geospatially and temporally aligned with data from many types of ground-based sensors to understand changes in extreme weather events. The Global Biobank Engine uses SciDB for large-scale joint analysis of large genotype-phenotype datasets like the UK Biobank. This paper show how SciDB's multi-dimensional arrays and in-situ distributed array processing enable pharmaceutical, medical, and materials science research that uses imaging mass spectrometry (MS), a new technology for quantifying and visualizing the spatial distribution of molecules by their molecular masses. Materials scientists use imaging mass spec to understand the interactions of substrates and coatings using various delivery methods such as sputtering and masking. Drug developers use imaging mass spec to determine where in the tissues and cells of an organ a drug compound is distributed. Drug developers can also look for indications of toxicity and efficacy by observing the redistribution of naturally occurring molecules such as lipids. The principle use of imaging mass spectrometry is to test for differences between drug candidate molecules before they are tested in humans and to explain toxicity that is observed in humans. As the use of MS scales from small experiments to automated workflows involving typical studies of animal subjects treated with different drugs, dosages, and methods of administration over longitudinal time periods, there is a critical need for software like SciDB to handle organizing and signal processing the 100s of TBs of data generated so that scientists get timely results.",,,978-1-5386-2715-0,3206-3210,IEEE , ,Arrays;Imaging;Drugs;Program processors;Instruments;Servers;Compounds,,
4570,"Title:Cancer classification using Fuzzy C-Means with feature selection

 For many years, cancer classification to detect cancer at early stage of treatment has improved. Cancer classification is used for the treatment of cancer has entered the challenge to target specific therapy for each type of cancer pathogens in an effort to maximize efficacy and minimize toxicity. In general, cancer data consists of many features. However, not all of these features are informative. Therefore, among these features, Fisher's Ratio is applied to select the most informative features which form new data. Data on which feature selection has not been and has been performed are classified using Fuzzy C-Means. The experiment reveals that optimization which based on classification with feature selection increases the accuracy. Results show that, without doing feature selection, the accuracy is 82.92 % while with feature selection, the best accuracy is 89.68 % obtained by using 150 features. The results show the difference between all the dataset used and the dataset using feature selection.",A. A. Rachman; Z. Rustam,,,Cancer classification using Fuzzy C-Means with feature selection,,,10.1109/ICMSA.2016.7954302 ,IEEE Conferences ,,"For many years, cancer classification to detect cancer at early stage of treatment has improved. Cancer classification is used for the treatment of cancer has entered the challenge to target specific therapy for each type of cancer pathogens in an effort to maximize efficacy and minimize toxicity. In general, cancer data consists of many features. However, not all of these features are informative. Therefore, among these features, Fisher's Ratio is applied to select the most informative features which form new data. Data on which feature selection has not been and has been performed are classified using Fuzzy C-Means. The experiment reveals that optimization which based on classification with feature selection increases the accuracy. Results show that, without doing feature selection, the accuracy is 82.92 % while with feature selection, the best accuracy is 89.68 % obtained by using 150 features. The results show the difference between all the dataset used and the dataset using feature selection.",,,978-1-5090-3385-0,31-34,IEEE , ,Cancer;Tumors;Linear programming;Medical treatment;Gene expression;Optimization,,
4571,"Title:BLKnn: A K-nearest neighbors method for predicting bioluminescent proteins

 Bioluminescence is a chemical process in which light is produced and emitted by a living organism. Recent biotechnological applications of bioluminescence include using of bioluminescent proteins in gene expression analysis, bioluminescent imaging, study of protein-protein interaction and disease progression, drug discovery, toxicity determination, etc. Therefore, it is of great medical and commercial significances to identify bioluminescent proteins accurately and efficiently. In this study, we present BLKnn, a K-nearest neighbors method that can predict bioluminescent proteins. This method is based on the bit-score weighted Euclidean distance, which is calculated from compositions of selected amino acids and pseudo-amino acids. On a balanced training dataset, BLKnn achieved 74.9% sensitivity, 95.5% specificity, 85.2% accuracy, and 0.919 AUC (area under the ROC curve) by 10-fold cross-validation. When tested on a much bigger independent test dataset, the method also achieved a consistent performance of 88.0% overall accuracy and 0.989 AUC. Comparisons showed that BLKnn outperformed previously published methods. The method is available at https://edisk.fandm.edu/jing.hu/blknn/blknn.html.",J. Hu,,,BLKnn: A K-nearest neighbors method for predicting bioluminescent proteins,,,10.1109/CIBCB.2014.6845503 ,IEEE Conferences ,,"Bioluminescence is a chemical process in which light is produced and emitted by a living organism. Recent biotechnological applications of bioluminescence include using of bioluminescent proteins in gene expression analysis, bioluminescent imaging, study of protein-protein interaction and disease progression, drug discovery, toxicity determination, etc. Therefore, it is of great medical and commercial significances to identify bioluminescent proteins accurately and efficiently. In this study, we present BLKnn, a K-nearest neighbors method that can predict bioluminescent proteins. This method is based on the bit-score weighted Euclidean distance, which is calculated from compositions of selected amino acids and pseudo-amino acids. On a balanced training dataset, BLKnn achieved 74.9% sensitivity, 95.5% specificity, 85.2% accuracy, and 0.919 AUC (area under the ROC curve) by 10-fold cross-validation. When tested on a much bigger independent test dataset, the method also achieved a consistent performance of 88.0% overall accuracy and 0.989 AUC. Comparisons showed that BLKnn outperformed previously published methods. The method is available at https://edisk.fandm.edu/jing.hu/blknn/blknn.html.",,,978-1-4799-4536-8,1-6,IEEE , ,Proteins;Amino acids;Accuracy;Sensitivity;Training;Bioluminescence;Euclidean distance,,
4572,"Title:Speckle tracking analysis for early detection of cardiotoxicity in breast cancer patients

 The aim of this retrospective study was to detect early cardiotoxicity by speckle tracking analysis. We analyzed 2D and 3D echocardiographic datasets (2DE and 3DE) in 65 patients treated for breast cancer with anthracycline and trastuzumab. We compared the temporal variations of the left ventricular ejection fraction (LVEF) obtained analyzing 2D and 3D datasets and of the strain values computed before, during and after chemotherapy administration. In addition, in a subgroup of 45 patients a complete echocardiographic examination was performed 6 months after completion of therapy. Cardiotoxicity onset definition varies depending on the method used to compute LVEF (16.9% by 2DE and 50.8% by 3DE). Thirty-three patients developed cardiotoxicity. Nine of them showed a reduction of longitudinal and radial strain values before LVEF reduction at the 16th week. Through 3D speckle tracking analysis early diagnosis of the cardio-toxicity onset seems achievable allowing the planning of cardio protective therapy without interrupting chemotherapy administration.",C. Lorenzini; C. Lamberti; M. Aquilina,,,Speckle tracking analysis for early detection of cardiotoxicity in breast cancer patients,,,10.1109/CIC.2015.7408615 ,IEEE Conferences ,,"The aim of this retrospective study was to detect early cardiotoxicity by speckle tracking analysis. We analyzed 2D and 3D echocardiographic datasets (2DE and 3DE) in 65 patients treated for breast cancer with anthracycline and trastuzumab. We compared the temporal variations of the left ventricular ejection fraction (LVEF) obtained analyzing 2D and 3D datasets and of the strain values computed before, during and after chemotherapy administration. In addition, in a subgroup of 45 patients a complete echocardiographic examination was performed 6 months after completion of therapy. Cardiotoxicity onset definition varies depending on the method used to compute LVEF (16.9% by 2DE and 50.8% by 3DE). Thirty-three patients developed cardiotoxicity. Nine of them showed a reduction of longitudinal and radial strain values before LVEF reduction at the 16th week. Through 3D speckle tracking analysis early diagnosis of the cardio-toxicity onset seems achievable allowing the planning of cardio protective therapy without interrupting chemotherapy administration.",2325-887X,,978-1-5090-0684-7,177-180,IEEE , ,Strain;Medical treatment,,
4573,"Title:EvilSeed: A Guided Approach to Finding Malicious Web Pages

 Malicious web pages that use drive-by download attacks or social engineering techniques to install unwanted software on a user's computer have become the main avenue for the propagation of malicious code. To search for malicious web pages, the first step is typically to use a crawler to collect URLs that are live on the Internet. Then, fast prefiltering techniques are employed to reduce the amount of pages that need to be examined by more precise, but slower, analysis tools (such as honey clients). While effective, these techniques require a substantial amount of resources. A key reason is that the crawler encounters many pages on the web that are benign, that is, the ""toxicity"" of the stream of URLs being analyzed is low. In this paper, we present EVILSEED, an approach to search the web more efficiently for pages that are likely malicious. EVILSEED starts from an initial seed of known, malicious web pages. Using this seed, our system automatically generates search engines queries to identify other malicious pages that are similar or related to the ones in the initial seed. By doing so, EVILSEED leverages the crawling infrastructure of search engines to retrieve URLs that are much more likely to be malicious than a random page on the web. In other words EVILSEED increases the ""toxicity"" of the input URL stream. Also, we envision that the features that EVILSEED presents could be directly applied by search engines in their prefilters. We have implemented our approach, and we evaluated it on a large-scale dataset. The results show that EVILSEED is able to identify malicious web pages more efficiently when compared to crawler-based approaches.",L. Invernizzi; P. M. Comparetti; S. Benvenuti; C. Kruegel; M. Cova; G. Vigna,,,EvilSeed: A Guided Approach to Finding Malicious Web Pages,,,10.1109/SP.2012.33 ,IEEE Conferences ,,"Malicious web pages that use drive-by download attacks or social engineering techniques to install unwanted software on a user's computer have become the main avenue for the propagation of malicious code. To search for malicious web pages, the first step is typically to use a crawler to collect URLs that are live on the Internet. Then, fast prefiltering techniques are employed to reduce the amount of pages that need to be examined by more precise, but slower, analysis tools (such as honey clients). While effective, these techniques require a substantial amount of resources. A key reason is that the crawler encounters many pages on the web that are benign, that is, the ""toxicity"" of the stream of URLs being analyzed is low. In this paper, we present EVILSEED, an approach to search the web more efficiently for pages that are likely malicious. EVILSEED starts from an initial seed of known, malicious web pages. Using this seed, our system automatically generates search engines queries to identify other malicious pages that are similar or related to the ones in the initial seed. By doing so, EVILSEED leverages the crawling infrastructure of search engines to retrieve URLs that are much more likely to be malicious than a random page on the web. In other words EVILSEED increases the ""toxicity"" of the input URL stream. Also, we envision that the features that EVILSEED presents could be directly applied by search engines in their prefilters. We have implemented our approach, and we evaluated it on a large-scale dataset. The results show that EVILSEED is able to identify malicious web pages more efficiently when compared to crawler-based approaches.",2375-1207,,978-0-7695-4681-0,428-442,IEEE , ,Search engines;Web pages;Malware;Google;Crawlers;Feature extraction,,
4574,"Title:Fuzzy subgroup mining for gene associations

 When studying the therapeutic efficacy of potential new drugs, it would be much more efficient to use predictors in order to assess their toxicity before going into clinical trials. One promising line of research has focused on the discovery of sets of candidate gene profiles to be used as toxicity indicators in future drug development. In particular genomic microarrays may be used to analyze the causality relationship between the administration of the drugs and the so-called gene expression, a parameter typically used by biologists to measure its influence at gene level. This kind of experiments involves a high throughput analysis of noisy and particularly unreliable data, which makes the application of many data mining techniques very difficult. In this paper we explore a fuzzy formulation of the a priori algorithm, a technique whose crisp version is commonly used to mine for subgroups in large datasets; the purpose is to extend the original method, already suitable to deal with large amount of data, in a way that naturally allows the user to deal with the intrinsic imprecision in the data. The algorithm is tested on real data coming from experimental genomic data.",M. Ortolani; O. Callan; D. E. Patterson; M. R. Berthold,,,Fuzzy subgroup mining for gene associations,2,,10.1109/NAFIPS.2004.1337362 ,IEEE Conferences ,,"When studying the therapeutic efficacy of potential new drugs, it would be much more efficient to use predictors in order to assess their toxicity before going into clinical trials. One promising line of research has focused on the discovery of sets of candidate gene profiles to be used as toxicity indicators in future drug development. In particular genomic microarrays may be used to analyze the causality relationship between the administration of the drugs and the so-called gene expression, a parameter typically used by biologists to measure its influence at gene level. This kind of experiments involves a high throughput analysis of noisy and particularly unreliable data, which makes the application of many data mining techniques very difficult. In this paper we explore a fuzzy formulation of the a priori algorithm, a technique whose crisp version is commonly used to mine for subgroups in large datasets; the purpose is to extend the original method, already suitable to deal with large amount of data, in a way that naturally allows the user to deal with the intrinsic imprecision in the data. The algorithm is tested on real data coming from experimental genomic data.",,,0-7803-8376-1,560-565 Vol.2,IEEE , ,Drugs;Association rules;Genomics;Bioinformatics;Data mining;Throughput;Information analysis;Information science;Clinical trials;Particle measurements,,
4575,"Title:Neural and neuro-fuzzy models of toxic action of phenols

 The problem of describing the bio-chemical action of different classes of chemical compounds through relations dependent on their structures is known as the quantitative structure-activity relation (QSAR) problem. Development of toxicity models of phenols using neural and neuro-fuzzy models is here proposed. A dataset about the inhibition of growth determined by phenolic compounds to the protozoan ciliate Tetrahymena pyriformis was used to produce QSAR and connectionist models. The results are promising, and suitable for further research.",C. . -D. N. Neagu; A. O. Aptula; G. Gini,,,Neural and neuro-fuzzy models of toxic action of phenols,1,,10.1109/IS.2002.1044269 ,IEEE Conferences ,,"The problem of describing the bio-chemical action of different classes of chemical compounds through relations dependent on their structures is known as the quantitative structure-activity relation (QSAR) problem. Development of toxicity models of phenols using neural and neuro-fuzzy models is here proposed. A dataset about the inhibition of growth determined by phenolic compounds to the protozoan ciliate Tetrahymena pyriformis was used to produce QSAR and connectionist models. The results are promising, and suitable for further research.",,,0-7803-7134-8,283-288 vol.1,IEEE , ,Neural networks;Fuzzy neural networks;Artificial intelligence;Fellows;Predictive models;Chemical analysis;Toxic chemicals;Speech;Natural languages;Medical diagnosis,,
4576,"Title:Analyzing the usage of standards in radiation therapy clinical studies

 Standards for scoring adverse effects after radiation therapy (RT) is crucial for integrated, consistent, and accurate analysis of toxicity results at large scale and across multiple studies. This project aims to investigate the usage of the three most commonly used standards in published RT clinical studies by developing a text-mining based analysis method. We develop and compare two text-mining methods, one based on regular expressions and one based on Naïve Bayes Classifier, to analyze published full articles in terms of their adoption of standards in RT. The full dataset includes published articles identified in MEDLINE between January 2010 and August 2015. A radiation oncology physician reviewed all the articles in the training/validation subset and produced the usage trending data manually as gold standard for validation. The regular-expression based method reported classifications and overall usage trends that are comparable to those of the domain expert. The CTCAE standard is becoming the overall most commonly used standards over time, but the pace of adoption seems very slow. Further examination of the results indicates that the usage vary by disease type. It suggests that further efforts are needed to improve and harmonize the standards for adverse effects scoring in RT research community.",Y. Zhen; Y. Jiang; L. Yuan; J. Kirkpartrick; J. Wu; Y. Ge,,,Analyzing the usage of standards in radiation therapy clinical studies,,,10.1109/BHI.2017.7897277 ,IEEE Conferences ,,"Standards for scoring adverse effects after radiation therapy (RT) is crucial for integrated, consistent, and accurate analysis of toxicity results at large scale and across multiple studies. This project aims to investigate the usage of the three most commonly used standards in published RT clinical studies by developing a text-mining based analysis method. We develop and compare two text-mining methods, one based on regular expressions and one based on Naïve Bayes Classifier, to analyze published full articles in terms of their adoption of standards in RT. The full dataset includes published articles identified in MEDLINE between January 2010 and August 2015. A radiation oncology physician reviewed all the articles in the training/validation subset and produced the usage trending data manually as gold standard for validation. The regular-expression based method reported classifications and overall usage trends that are comparable to those of the domain expert. The CTCAE standard is becoming the overall most commonly used standards over time, but the pace of adoption seems very slow. Further examination of the results indicates that the usage vary by disease type. It suggests that further efforts are needed to improve and harmonize the standards for adverse effects scoring in RT research community.",,,978-1-5090-4179-4,349-352,IEEE , ,Standards;Cancer;Market research;Biomedical applications of radiation;Text mining;Oncology;Terminology,,
4577,"Title:Integrated action crossing method for Drug-Drug Interactions prediction in noncommunicable diseases based on neural networks

 Drug-Drug Interactions (DDI) is a cause of treatment inefficacy and toxicity. The most DDI involve drug metabolism which related to enzyme and transporter protein. Drug-enzyme actions that alter the metabolism of other drugs consist of substrate, inhibitor and inducer. Non-communicable diseases (NCDs) are the leading cause of death, drugs that are used in NCDs can increase interaction probability because their long-term usage. This paper proposes Integrated Action Crossing (IAC), a new attribute generation method for DDIs prediction in NCDs. Drugs attributes in NCDs categories were extracted. The actions of enzymes and transporter proteins were crossed for generating dataset for prediction model creation. Neural network (NN) and others machine learning were investigated. Five-fold cross validation was performed for evaluaing the prediction model performance. The results showed that 2 layers NN obtained the best performance of NCDs DDIs prediction model at the accuracy of 83.15%.",S. Hunta; N. Aunsri; T. Yooyativong,,,Integrated action crossing method for Drug-Drug Interactions prediction in noncommunicable diseases based on neural networks,,,10.1109/ICDAMT.2017.7904973 ,IEEE Conferences ,,"Drug-Drug Interactions (DDI) is a cause of treatment inefficacy and toxicity. The most DDI involve drug metabolism which related to enzyme and transporter protein. Drug-enzyme actions that alter the metabolism of other drugs consist of substrate, inhibitor and inducer. Non-communicable diseases (NCDs) are the leading cause of death, drugs that are used in NCDs can increase interaction probability because their long-term usage. This paper proposes Integrated Action Crossing (IAC), a new attribute generation method for DDIs prediction in NCDs. Drugs attributes in NCDs categories were extracted. The actions of enzymes and transporter proteins were crossed for generating dataset for prediction model creation. Neural network (NN) and others machine learning were investigated. Five-fold cross validation was performed for evaluaing the prediction model performance. The results showed that 2 layers NN obtained the best performance of NCDs DDIs prediction model at the accuracy of 83.15%.",,,978-1-5090-5210-3,259-262,IEEE , ,Drugs;Biochemistry;Artificial neural networks;Predictive models;Support vector machines;Substrates;Diseases,,
4578,"Title:Towards a Classification Scheme for Inferring the Atomic Composition of Drug-like Molecules from their Quantum Derived Electronic Properties

 In machine learning and molecular design, there exist two approaches: discriminative and generative. In the discriminative approach dubbed forward design, the goal is to map a set of features/molecules to their respective electronic properties. In the generative approach dubbed inverse design, a set of electronic properties is given and the goal is to find the features/molecules that have these properties. These tasks are very challenging because the chemical compound space is very large. In this study, we explore a new scheme for the inverse design of molecules based on a classification paradigm that takes as input the targeted electronic properties and output the atomic composition of the molecules (i.e. atomicity or atom counts of each type in a molecule). To test this new hypothesis, we analyzed the quantum mechanics QM7b dataset consisting of 7211 small organic molecules and 14 electronic properties. Results obtained using twenty three different classification approaches including a regularized Bayesian neural network show that it is possible to achieve detection/prediction accuracy> 90%. Even though this study uses the electronic properties of molecules as input, it can be extended to other drugs' properties such as: toxicity, binding affinity, solubility, permeability, metabolic stability, etc.",A. B. Tchagang; J. J. Valdés,,,Towards a Classification Scheme for Inferring the Atomic Composition of Drug-like Molecules from their Quantum Derived Electronic Properties,,,10.1109/CIBCB55180.2022.9863048 ,IEEE Conferences ,,"In machine learning and molecular design, there exist two approaches: discriminative and generative. In the discriminative approach dubbed forward design, the goal is to map a set of features/molecules to their respective electronic properties. In the generative approach dubbed inverse design, a set of electronic properties is given and the goal is to find the features/molecules that have these properties. These tasks are very challenging because the chemical compound space is very large. In this study, we explore a new scheme for the inverse design of molecules based on a classification paradigm that takes as input the targeted electronic properties and output the atomic composition of the molecules (i.e. atomicity or atom counts of each type in a molecule). To test this new hypothesis, we analyzed the quantum mechanics QM7b dataset consisting of 7211 small organic molecules and 14 electronic properties. Results obtained using twenty three different classification approaches including a regularized Bayesian neural network show that it is possible to achieve detection/prediction accuracy> 90%. Even though this study uses the electronic properties of molecules as input, it can be extended to other drugs' properties such as: toxicity, binding affinity, solubility, permeability, metabolic stability, etc.",,,978-1-6654-8462-6,1-5,IEEE , ,Drugs;Toxicology;Quantum computing;Pipelines;Quantum mechanics;Machine learning;Stability analysis,,
4579,"Title:Challenges of Exploratory Visualization of Gene-environment Interaction in Alzheimer's Disease

 Alzheimer's Disease (AD) is the 6th leading cause of death in the United States. Although several genetic and environmental factors have been implicated in AD risks, no single factor is found solely responsible for disease manifestation in all Alzheimer's cases. In cases when no single gene can explain causality, the scenario of a combination of factors with modest effect sizes has been suggested. Through means of visual analysis in Weave we uncovered and further strengthened growing evidence for the link between genetics, air pollution and an earlier onset of Alzheimer's disease as exemplified in US cities with the highest reported levels of toxicity. Major sources of bias impacting our dataset are examined to caution the reader about the value of correlation findings in this less than ideal study sample.",E. I. Galkina; G. G. Grinstein,,,Challenges of Exploratory Visualization of Gene-environment Interaction in Alzheimer's Disease,,,10.1109/IV.2012.112 ,IEEE Conferences ,,"Alzheimer's Disease (AD) is the 6th leading cause of death in the United States. Although several genetic and environmental factors have been implicated in AD risks, no single factor is found solely responsible for disease manifestation in all Alzheimer's cases. In cases when no single gene can explain causality, the scenario of a combination of factors with modest effect sizes has been suggested. Through means of visual analysis in Weave we uncovered and further strengthened growing evidence for the link between genetics, air pollution and an earlier onset of Alzheimer's disease as exemplified in US cities with the highest reported levels of toxicity. Major sources of bias impacting our dataset are examined to caution the reader about the value of correlation findings in this less than ideal study sample.",2375-0138,,978-1-4673-2260-7,567-572,IEEE , ,Cities and towns;Alzheimer's disease;Histograms;Air pollution;Genetics,,
4580,"Title:BrachyView: A novel in-body imaging system for prostate brachytherapy

 The dosimetric quality of seed implants is a crucial part of the prostate brachytherapy treatment procedure. Incorrect seed placement during or after deployment leads to both short and long term complications, including urethral and rectal toxicity. The BrachyView system is a fast intraoperative planning system, providing real-time dosimetric information by acting as an in-body gamma camera. It incorporates three tiled Medipix2 pixellated detectors coupled to a multi-pinhole collimator. Three-dimensional reconstructed images from multiple planar images are used to determine the seed placement in real time. The seed image, when fused with the ultrasound dataset, provides both anatomical and dosimetric information and can overcome the shortcomings of current ultrasound imaging techniques. This paper presents the results of preliminary studies carried out in a PMMA prostate phantom. It is demonstrated that the technique provides an effective and practical intraoperative treatment planning mechanism for permanent prostate brachytherapy (PPB) treatments.",K. Loo; M. Petasecca; M. Safavi; M. Lerch; Z. Han; J. Jakubek; S. Pospisil; S. Meikle; M. Zaider; J. Bucci; A. Rosenfeld,,,BrachyView: A novel in-body imaging system for prostate brachytherapy,,,10.1109/NSSMIC.2011.6154497 ,IEEE Conferences ,,"The dosimetric quality of seed implants is a crucial part of the prostate brachytherapy treatment procedure. Incorrect seed placement during or after deployment leads to both short and long term complications, including urethral and rectal toxicity. The BrachyView system is a fast intraoperative planning system, providing real-time dosimetric information by acting as an in-body gamma camera. It incorporates three tiled Medipix2 pixellated detectors coupled to a multi-pinhole collimator. Three-dimensional reconstructed images from multiple planar images are used to determine the seed placement in real time. The seed image, when fused with the ultrasound dataset, provides both anatomical and dosimetric information and can overcome the shortcomings of current ultrasound imaging techniques. This paper presents the results of preliminary studies carried out in a PMMA prostate phantom. It is demonstrated that the technique provides an effective and practical intraoperative treatment planning mechanism for permanent prostate brachytherapy (PPB) treatments.",1082-3654,,978-1-4673-0120-6,279-281,IEEE , ,Biomedical imaging;Detectors;USA Councils;Brachytherapy;Image reconstruction,,
4581,"Title:Human Dendritic Cells Classification based on Possibility Theory

 Dendritic cells can be seen as a mirror of our immune system. Based on their in virto analysis, biological experts are now able to study the impact of food contaminants on the human immune system. Accordingly, a visual characterization of dendritic cell morphology can provide an indirect estimation of the toxicity. In this paper, we propose an automatic classification of dendritic cells that could serve as a second non-subjective opinion for pathologists. The proposed approach is built on pre-processing steps for segmentation and cell detection in microscopic images. Then, a set of features such as shape descriptors are extracted for cell characterization. At this step, three cell classes are distinctively identified by experts. Nevertheless, a high ambiguity is revealed between cell classes. Possibility theory can offer a realistic framework for making reliable decisions under high ambiguity. It exploits a human natural concept of the implicit use of probability distribution for deciding on the possibility of some assertions in some contexts where a cognitive conflict is observed while interfering existing related postulates, leading to high ambiguity. Based on the consistency concept of Dubois and Prade, a transformation of the probability into a possibility distribution is undertaken. Under possibility paradigm, a further feature selection in the possibility space using the Shapely index. Compared to state-of-the art methods the proposed approach yielded on a real dataset of nearly 630 samples an improvement in terms of the mean precision rate, the Recall rate, and the F1-measure.",M. Z. Mehdi; A. Benzinou; J. F. Elleuch; K. Nasreddine; D. Ammeri; D. Sellami,,,Human Dendritic Cells Classification based on Possibility Theory,Five,,10.1109/IPAS55744.2022.10052863 ,IEEE Conferences ,,"Dendritic cells can be seen as a mirror of our immune system. Based on their in virto analysis, biological experts are now able to study the impact of food contaminants on the human immune system. Accordingly, a visual characterization of dendritic cell morphology can provide an indirect estimation of the toxicity. In this paper, we propose an automatic classification of dendritic cells that could serve as a second non-subjective opinion for pathologists. The proposed approach is built on pre-processing steps for segmentation and cell detection in microscopic images. Then, a set of features such as shape descriptors are extracted for cell characterization. At this step, three cell classes are distinctively identified by experts. Nevertheless, a high ambiguity is revealed between cell classes. Possibility theory can offer a realistic framework for making reliable decisions under high ambiguity. It exploits a human natural concept of the implicit use of probability distribution for deciding on the possibility of some assertions in some contexts where a cognitive conflict is observed while interfering existing related postulates, leading to high ambiguity. Based on the consistency concept of Dubois and Prade, a transformation of the probability into a possibility distribution is undertaken. Under possibility paradigm, a further feature selection in the possibility space using the Shapely index. Compared to state-of-the art methods the proposed approach yielded on a real dataset of nearly 630 samples an improvement in terms of the mean precision rate, the Recall rate, and the F1-measure.",,,978-1-6654-6219-8,1-6,IEEE , ,Visualization;Possibility theory;Toxicology;Shape;Morphology;Reliability theory;Feature extraction,,
4582,"Title:Managing Class Imbalance in Multi-Organ CT Segmentation in Head and Neck Cancer Patients

 Radiotherapy planning of head and neck cancer patients requires an accurate delineation of several organs at risk (OAR) from planning CT images in order to determine a dose plan which reduces toxicity and salvages normal tissue. However training a single deep neural network for multiple organs is highly sensitive to class imbalance and variability in size between several structures within the head and neck region. In this paper, we propose a single-class segmentation model for each OAR in order to handle class imbalance issues during training across output classes (one class per structure), where there exists a severe disparity between 12 OAR. Based on a U-net architecture, we present a transfer learning approach between similar OAR to leverage common learned features, as well as a simple weight averaging strategy to initialize a model as the average of multiple models, each trained on a separate organ. Experiments performed on an internal dataset of 200 H & N cancer patients treated with external beam radiotherapy, show the proposed model presents a significant improvement compared to the baseline multi-organ segmentation model, which attempts to simultaneously train several OAR. The proposed model yields an overall Dice score of 0.75 plus or minus 0.12, by using both transfer learning across OAR and a weight averaging strategy, indicating that a reasonable segmentation performance can be achieved by leveraging additional data from surrounding structures, limiting the uncertainty in ground-truth annotations.",S. Cros; E. Vorontsov; S. Kadoury,,,Managing Class Imbalance in Multi-Organ CT Segmentation in Head and Neck Cancer Patients,,,10.1109/ISBI48211.2021.9433991 ,IEEE Conferences ,,"Radiotherapy planning of head and neck cancer patients requires an accurate delineation of several organs at risk (OAR) from planning CT images in order to determine a dose plan which reduces toxicity and salvages normal tissue. However training a single deep neural network for multiple organs is highly sensitive to class imbalance and variability in size between several structures within the head and neck region. In this paper, we propose a single-class segmentation model for each OAR in order to handle class imbalance issues during training across output classes (one class per structure), where there exists a severe disparity between 12 OAR. Based on a U-net architecture, we present a transfer learning approach between similar OAR to leverage common learned features, as well as a simple weight averaging strategy to initialize a model as the average of multiple models, each trained on a separate organ. Experiments performed on an internal dataset of 200 H & N cancer patients treated with external beam radiotherapy, show the proposed model presents a significant improvement compared to the baseline multi-organ segmentation model, which attempts to simultaneously train several OAR. The proposed model yields an overall Dice score of 0.75 plus or minus 0.12, by using both transfer learning across OAR and a weight averaging strategy, indicating that a reasonable segmentation performance can be achieved by leveraging additional data from surrounding structures, limiting the uncertainty in ground-truth annotations.",1945-8452,,978-1-6654-1246-9,1360-1364,IEEE , ,Training;Image segmentation;Head;Computed tomography;Transfer learning;Biological systems;Data models,,
4583,"Title:Knowledge Distillation: A Strategy to Enhance the Performance of Deep Learning-based Seminal Segmentation

 Accurate segmentation of target tissues/structures as well as surrounding healthy organs/tissues (organs at risk (OARs)) plays a critical role in radiation therapy and treatment planning. Accurate segmentation of OARs prevents/minimizes unwanted toxicity to healthy tissues. Manual segmentation is time-consuming, tedious, prone to human errors and subject to intra- and inter-observer variability. In this regard, deep learning algorithms have shown extraordinary performance in automated organ segmentation from medical images, though the powerful/highly effective models might be computationally intensive. Transferring knowledge from complex/cumbersome models to simple/versatile models, known as knowledge distillation, has been proposed to address this issue (enhance the performance of the existing deep learning models). In this work, the impact of the knowledge distillation on OARs segmentation from CT images is investigated for commonly used Unet and Resnet deep learning models. To this end, a highly complex Unet model (as teacher) and two conventional deep learning models (Unet and Resnet as students) were developed to delineate OARs on thoracic CT images from the SegTHOR public dataset. The models were trained once independently and once through knowledge distillation from the teacher model to the student models. The teacher model yielded segmentation accuracy in terms of Dice coefficient of 0.95 and 0.86 for the heart and aorta compared to the student models (Unet and Resnet) which achieved an accuracy of 0.79, 0.64 and 0.13, 0.22, respectively. After knowledge distillation from the teacher to the students, the accuracy of the Unet and Resnet improved to 0.91, 0.79 and 0.62, 0.63 for the heart and aorta, respectively. This study demonstrated the beneficial impact of knowledge distillation to enhance the overall performance of conventional models without increasing the computational their complexity.",R. Karimzadeh; E. Fatemizadeh; H. Arabi; H. Zaidi,,,Knowledge Distillation: A Strategy to Enhance the Performance of Deep Learning-based Seminal Segmentation,,,10.1109/NSS/MIC44867.2021.9875699 ,IEEE Conferences ,,"Accurate segmentation of target tissues/structures as well as surrounding healthy organs/tissues (organs at risk (OARs)) plays a critical role in radiation therapy and treatment planning. Accurate segmentation of OARs prevents/minimizes unwanted toxicity to healthy tissues. Manual segmentation is time-consuming, tedious, prone to human errors and subject to intra- and inter-observer variability. In this regard, deep learning algorithms have shown extraordinary performance in automated organ segmentation from medical images, though the powerful/highly effective models might be computationally intensive. Transferring knowledge from complex/cumbersome models to simple/versatile models, known as knowledge distillation, has been proposed to address this issue (enhance the performance of the existing deep learning models). In this work, the impact of the knowledge distillation on OARs segmentation from CT images is investigated for commonly used Unet and Resnet deep learning models. To this end, a highly complex Unet model (as teacher) and two conventional deep learning models (Unet and Resnet as students) were developed to delineate OARs on thoracic CT images from the SegTHOR public dataset. The models were trained once independently and once through knowledge distillation from the teacher model to the student models. The teacher model yielded segmentation accuracy in terms of Dice coefficient of 0.95 and 0.86 for the heart and aorta compared to the student models (Unet and Resnet) which achieved an accuracy of 0.79, 0.64 and 0.13, 0.22, respectively. After knowledge distillation from the teacher to the students, the accuracy of the Unet and Resnet improved to 0.91, 0.79 and 0.62, 0.63 for the heart and aorta, respectively. This study demonstrated the beneficial impact of knowledge distillation to enhance the overall performance of conventional models without increasing the computational their complexity.",2577-0829,,978-1-6654-2113-3,1-3,IEEE , ,Deep learning;Heart;Image segmentation;Toxicology;Computational modeling;Computed tomography;Manuals,,
4584,"Title:Classification of polypeptide spectra from rat liver samples

 We use clustering-based algorithms to classify polypeptide spectra of treated rat liver samples obtained through surface enhanced laser desorption/ionization mass spectrometry (SELDI-MS). Variance analysis is used to extract useful features from the high dimensional datasets. The features are then clustered using a hierarchical clustering algorithm based on scaled Euclidean distances. The clusters created are found to be correlated to the toxicity of the rat liver samples.",Lit-Hsin Loo; J. Quinn; J. Armitage; H. Cordingley; S. Roberts; P. J. Bugelski; L. Hrebien; M. Kam,,,Classification of polypeptide spectra from rat liver samples,,,10.1109/NEBC.2002.999504 ,IEEE Conferences ,,We use clustering-based algorithms to classify polypeptide spectra of treated rat liver samples obtained through surface enhanced laser desorption/ionization mass spectrometry (SELDI-MS). Variance analysis is used to extract useful features from the high dimensional datasets. The features are then clustered using a hierarchical clustering algorithm based on scaled Euclidean distances. The clusters created are found to be correlated to the toxicity of the rat liver samples.,,,0-7803-7419-3,139-140,IEEE , ,Liver;Fingerprint recognition;Toxicology;Throughput;Drugs;Rats;Clustering algorithms;Mass spectroscopy;Surface emitting lasers;Analysis of variance,,
4585,"Title:SeHNE: Semi-supervised Heterogeneous Network Embedding for Drug Combination

 Drug combinations, offering increased therapeutic efficacy and reduced toxicity, play an important role in therapy of many complex diseases. Although great efforts have been devoted to the prediction of single drugs, the identification of drug combination is really limited. The current algorithms assume the independence of features and prediction, resulting in an undesirable performance. To address this issue, we develop a novel semisupervised heterogeneous network embedding algorithm (called SeHNE) to predict drug combinations, where ATC similarity of drugs, drug-target and protein-protein interaction (PPI) networks are integrated to construct heterogeneous network. SeHNE jointly learns features of drugs by exploiting the topological structure of heterogeneous networks, and prediction of drug combination. One typical advantage of SeHNE is that features are extracted under the guidance of classification, thereby improving the accuracy of algorithms. Experimental results demonstrate that proposed algorithm is more accurate than state-of-the-art methods on the dataset we collected, and the re-training process could improve the accuracy of classifier.",S. Tan; X. Ma,,,SeHNE: Semi-supervised Heterogeneous Network Embedding for Drug Combination,,,10.1109/BIBM49941.2020.9313207 ,IEEE Conferences ,,"Drug combinations, offering increased therapeutic efficacy and reduced toxicity, play an important role in therapy of many complex diseases. Although great efforts have been devoted to the prediction of single drugs, the identification of drug combination is really limited. The current algorithms assume the independence of features and prediction, resulting in an undesirable performance. To address this issue, we develop a novel semisupervised heterogeneous network embedding algorithm (called SeHNE) to predict drug combinations, where ATC similarity of drugs, drug-target and protein-protein interaction (PPI) networks are integrated to construct heterogeneous network. SeHNE jointly learns features of drugs by exploiting the topological structure of heterogeneous networks, and prediction of drug combination. One typical advantage of SeHNE is that features are extracted under the guidance of classification, thereby improving the accuracy of algorithms. Experimental results demonstrate that proposed algorithm is more accurate than state-of-the-art methods on the dataset we collected, and the re-training process could improve the accuracy of classifier.",,,978-1-7281-6215-7,1656-1661,IEEE , ,Drugs;Feature extraction;Proteins;Heterogeneous networks;Prediction algorithms;Support vector machines;Symmetric matrices,,
4586,"Title:Hybrid feature selection and peptide binding affinity prediction using an EDA based algorithm

 Protein function prediction is an important problem in functional genomics. Typically, protein sequences are represented by feature vectors. A major problem of protein datasets that increase the complexity of classification models is their large number of features. The process of drug discovery often involves the use of quantitative structure-activity relationship (QSAR) models to identify chemical structures that could have good inhibitory effects on specific targets and have low toxicity (non-specific activity). QSAR models are regression or classification models used in the chemical and biological sciences. Because of high dimensionality problems, a feature selection problem is imminent. In this study, we thus employ a hybrid Estimation of Distribution Algorithm (EDA) based filter-wrapper methodology to simultaneously extract informative feature subsets and build robust QSAR models. The performance of the algorithm was tested on the benchmark classification challenge datasets obtained from the CoePRa competition platform, developed in 2006. Our results clearly demonstrate the efficacy of a hybrid EDA filter-wrapper algorithm in comparison to the results reported earlier.",K. Shelke; S. Jayaraman; S. Ghosh; J. Valadi,,,Hybrid feature selection and peptide binding affinity prediction using an EDA based algorithm,,,10.1109/CEC.2013.6557854 ,IEEE Conferences ,,"Protein function prediction is an important problem in functional genomics. Typically, protein sequences are represented by feature vectors. A major problem of protein datasets that increase the complexity of classification models is their large number of features. The process of drug discovery often involves the use of quantitative structure-activity relationship (QSAR) models to identify chemical structures that could have good inhibitory effects on specific targets and have low toxicity (non-specific activity). QSAR models are regression or classification models used in the chemical and biological sciences. Because of high dimensionality problems, a feature selection problem is imminent. In this study, we thus employ a hybrid Estimation of Distribution Algorithm (EDA) based filter-wrapper methodology to simultaneously extract informative feature subsets and build robust QSAR models. The performance of the algorithm was tested on the benchmark classification challenge datasets obtained from the CoePRa competition platform, developed in 2006. Our results clearly demonstrate the efficacy of a hybrid EDA filter-wrapper algorithm in comparison to the results reported earlier.",1941-0026,,978-1-4799-0454-9,2384-2389,IEEE , ,Support vector machines;Vectors;Feature extraction;Probability distribution;Classification algorithms;Prediction algorithms;Radio frequency,,
4587,"Title:Discovery of Biomarker Genes from Earthworm Microarray Data by Discriminant Analysis and Clustering

 Monitoring, assessment and prediction of environmental risks that chemicals pose demand rapid and accurate diagnostic assays. One important goal of microarray experiments is to discover novel biomarkers for toxicity evaluation. A variety of toxicological effects have been associated with explosive compounds 2,4,6-trinitrotoluene (TNT) and 1,3,5-trinitro-1,3,5-triazacyclohexane (RDX). Here we developed a discriminant analysis and cluster (DAC) pipeline to analyze a 248-array dataset with 15,208 non-redundant earthworm (Eisenia fetida) gene probes on each array. Our objective was to identify biomarker genes that can separate earthworm samples into three groups: control (untreated), TNT-treated, and RDX-treated. First, the class comparison statistical algorithm implemented in BRB-ArrayTools was used to infer a total of 869 genes that significantly changed relative to controls as a result of exposure to TNT or RDX at various concentrations for 4 or 14 days. Then, nine tree-based supervised machine learning algorithms were applied to generate classification rules and a set of 286 classifier genes. These classifier genes were ranked by their overall weight of significance in the nine classification methods, and were used to build support vector machines (SVM). A SVM containing all 286 classifier genes had the highest classification accuracy (91.5%). Results of unsupervised clustering show that the use of the top 100 classifier genes can assign the largest number of the 248 worm samples into the three reference clusters obtained by using all the 14,188 filtered genes, suggesting that these top-ranked genes may be potential candidates for biomarkers. This study demonstrates that the DAC pipeline can be used to identify a small set of biomarker genes from high dimensional datasets and generate a reliable SVM classification model for multiple classes.",Y. Li; N. Wang; E. J. Perkins; P. Gong,,,Discovery of Biomarker Genes from Earthworm Microarray Data by Discriminant Analysis and Clustering,,,10.1109/IJCBS.2009.134 ,IEEE Conferences ,,"Monitoring, assessment and prediction of environmental risks that chemicals pose demand rapid and accurate diagnostic assays. One important goal of microarray experiments is to discover novel biomarkers for toxicity evaluation. A variety of toxicological effects have been associated with explosive compounds 2,4,6-trinitrotoluene (TNT) and 1,3,5-trinitro-1,3,5-triazacyclohexane (RDX). Here we developed a discriminant analysis and cluster (DAC) pipeline to analyze a 248-array dataset with 15,208 non-redundant earthworm (Eisenia fetida) gene probes on each array. Our objective was to identify biomarker genes that can separate earthworm samples into three groups: control (untreated), TNT-treated, and RDX-treated. First, the class comparison statistical algorithm implemented in BRB-ArrayTools was used to infer a total of 869 genes that significantly changed relative to controls as a result of exposure to TNT or RDX at various concentrations for 4 or 14 days. Then, nine tree-based supervised machine learning algorithms were applied to generate classification rules and a set of 286 classifier genes. These classifier genes were ranked by their overall weight of significance in the nine classification methods, and were used to build support vector machines (SVM). A SVM containing all 286 classifier genes had the highest classification accuracy (91.5%). Results of unsupervised clustering show that the use of the top 100 classifier genes can assign the largest number of the 248 worm samples into the three reference clusters obtained by using all the 14,188 filtered genes, suggesting that these top-ranked genes may be potential candidates for biomarkers. This study demonstrates that the DAC pipeline can be used to identify a small set of biomarker genes from high dimensional datasets and generate a reliable SVM classification model for multiple classes.",,,978-0-7695-3739-9,23-29,IEEE , ,Biomarkers;Data analysis;Support vector machines;Support vector machine classification;Pipelines;Machine learning algorithms;Classification tree analysis;Monitoring;Chemicals;Toxicology,,
4588,"Title:coreSNP: Parallel Processing of Microarray Data

 The availability of high-throughput technologies, such as next generation sequencing and microarray, and the diffusion of genomics studies to large populations are producing an increasing amount of experimental data. In particular, pharmacogenomics studies the impact of genetic variation on drug response in patients and correlates gene expression or single nucleotide polymorphisms (SNPs) with the toxicity or efficacy of a drug, with the aim to improve drug therapy with respect to the patients’ genotype ensuring maximum efficacy with minimal adverse effects. However, the storage, preprocessing, and analysis of experimental data are becoming a main bottleneck in the pharmacogenomics analysis pipeline, due to the increasing number of genes and patients investigated. This paper presents a new parallel software tool named coreSNP for the parallel preprocessing and statistical analysis of DMET (Drug Metabolism Enzymes and Transporters) SNP microarray data produced by Affymetrix for pharmacogenomics studies. The scalable multi-threaded implementation of coreSNP allows to handle the huge volumes of experimental pharmacogenomics data in a very efficient way, while its easy to use graphical user interface and its ability to annotate significant SNPs allow biologists to interpret the results easily. Performance evaluation conducted using real datasets shows good speed-up and scalability and effective response times.",P. H. Guzzi; G. Agapito; M. Cannataro,,,coreSNP: Parallel Processing of Microarray Data,63,12,10.1109/TC.2013.176 ,IEEE Journals ,,"The availability of high-throughput technologies, such as next generation sequencing and microarray, and the diffusion of genomics studies to large populations are producing an increasing amount of experimental data. In particular, pharmacogenomics studies the impact of genetic variation on drug response in patients and correlates gene expression or single nucleotide polymorphisms (SNPs) with the toxicity or efficacy of a drug, with the aim to improve drug therapy with respect to the patients’ genotype ensuring maximum efficacy with minimal adverse effects. However, the storage, preprocessing, and analysis of experimental data are becoming a main bottleneck in the pharmacogenomics analysis pipeline, due to the increasing number of genes and patients investigated. This paper presents a new parallel software tool named coreSNP for the parallel preprocessing and statistical analysis of DMET (Drug Metabolism Enzymes and Transporters) SNP microarray data produced by Affymetrix for pharmacogenomics studies. The scalable multi-threaded implementation of coreSNP allows to handle the huge volumes of experimental pharmacogenomics data in a very efficient way, while its easy to use graphical user interface and its ability to annotate significant SNPs allow biologists to interpret the results easily. Performance evaluation conducted using real datasets shows good speed-up and scalability and effective response times.",1557-9956,,,2961-2974,IEEE , ,Parallel processing;Drugs;DNA;Bioinformatics;Throughput;Statistical analysis;Genomics,,
4589,"Title:Gene expression profiles based Human cancer diseases classification

 Cancers are a large family of diseases that involve abnormal cell growth with the potential to spread to other parts of the body. A cancer disease in any of its forms represents a major cause of death worldwide. In cancer diagnosis, classification of different tumor types is of the greatest significance. Accuracy for prediction of various tumor types gives better treatment and minimization of toxicity on patients. Accordingly, creating methodologies that can effectively differentiate between cancer subtypes is essential. This paper presents a new methodology to classify Human cancer diseases based on the gene expression profiles. The proposed methodology combines both Information gain (IG) and Deep Genetic Algorithm (DGA). It first uses IG for feature selection, then uses Genetic Algorithm (GA) for feature reduction and finally uses Genetic Programming (GP) for cancer types' classification. The proposed system is evaluated by classifying cancer diseases in seven cancer datasets and the results are compared with most recent approaches.",H. Salem; G. Attiya; N. El-Fishawy,,,Gene expression profiles based Human cancer diseases classification,,,10.1109/ICENCO.2015.7416345 ,IEEE Conferences ,,"Cancers are a large family of diseases that involve abnormal cell growth with the potential to spread to other parts of the body. A cancer disease in any of its forms represents a major cause of death worldwide. In cancer diagnosis, classification of different tumor types is of the greatest significance. Accuracy for prediction of various tumor types gives better treatment and minimization of toxicity on patients. Accordingly, creating methodologies that can effectively differentiate between cancer subtypes is essential. This paper presents a new methodology to classify Human cancer diseases based on the gene expression profiles. The proposed methodology combines both Information gain (IG) and Deep Genetic Algorithm (DGA). It first uses IG for feature selection, then uses Genetic Algorithm (GA) for feature reduction and finally uses Genetic Programming (GP) for cancer types' classification. The proposed system is evaluated by classifying cancer diseases in seven cancer datasets and the results are compared with most recent approaches.",,,978-1-5090-0275-7,181-187,IEEE , ,Tumors;Lungs;Cancer;Colon;Diseases;Morphology,,
4590,"Title:Feature selection for graph kernels

 Graph classification is important for different scientific applications; it can be exploited in various problems related to bioinformatics and cheminformatics. Given their graphs, there is increasing need for classifying small molecules to predict their properties such as activity, toxicity or mutagenicity. Using subtrees as feature set for graph classification in kernel methods has been shown to perform well in classifying small molecules. It is also well-known that feature selection can improve the performance of classifiers. However, most of the graph kernels are not selective in choosing which subtrees to include in the set of features. Instead, they use all subtrees of a certain property as their feature set. We argue that not all the latter features are needed for effective classification. In this paper, we investigate the effect of selecting subset of the subtrees as features for graph kernels, i.e., we try to identify and keep useful features; all the remaining subtrees are eliminated. A masking procedure, which boils down to feature selection, is proposed for classifying graphs. We conducted experiments on several molecule classification datasets; the results demonstrate the applicability and effectiveness of the proposed feature selection process.",M. Tan; F. Polat; R. Alhajj,,,Feature selection for graph kernels,,,10.1109/BIBM.2010.5706643 ,IEEE Conferences ,,"Graph classification is important for different scientific applications; it can be exploited in various problems related to bioinformatics and cheminformatics. Given their graphs, there is increasing need for classifying small molecules to predict their properties such as activity, toxicity or mutagenicity. Using subtrees as feature set for graph classification in kernel methods has been shown to perform well in classifying small molecules. It is also well-known that feature selection can improve the performance of classifiers. However, most of the graph kernels are not selective in choosing which subtrees to include in the set of features. Instead, they use all subtrees of a certain property as their feature set. We argue that not all the latter features are needed for effective classification. In this paper, we investigate the effect of selecting subset of the subtrees as features for graph kernels, i.e., we try to identify and keep useful features; all the remaining subtrees are eliminated. A masking procedure, which boils down to feature selection, is proposed for classifying graphs. We conducted experiments on several molecule classification datasets; the results demonstrate the applicability and effectiveness of the proposed feature selection process.",,,978-1-4244-8307-5,632-637,IEEE , ,Kernel;Compounds;Schedules;Chemical compounds;Particle separators;Bioinformatics;Data mining,,
4591,"Title:Unsupervised extraction, labelling and clustering of segments from clinical notes

 This work is motivated by the scarcity of tools for accurate, unsupervised information extraction from unstructured clinical notes in computationally underrepresented languages, such as Czech. We introduce a stepping stone to a broad array of downstream tasks such as summarisation or integration of individual patient records, extraction of structured information for national cancer registry reporting or building of semi-structured semantic patient representations for computing patient embeddings. More specifically, we present a method for unsupervised extraction of semantically-labelled textual segments from clinical notes and test it out on a dataset of Czech breast cancer patients, provided by Masaryk Memorial Cancer Institute (the largest Czech hospital specialising in oncology). Our goal was to extract, classify (i.e. label) and cluster segments of the free-text notes that correspond to specific clinical features (e.g., family background, comorbidities or toxicities). The presented results demonstrate the practical relevance of the proposed approach for building more sophisticated extraction and analytical pipelines deployed on Czech clinical notes.",P. Zelina; J. Halámková; V. Nováček,,,"Unsupervised extraction, labelling and clustering of segments from clinical notes",,,10.1109/BIBM55620.2022.9995229 ,IEEE Conferences ,,"This work is motivated by the scarcity of tools for accurate, unsupervised information extraction from unstructured clinical notes in computationally underrepresented languages, such as Czech. We introduce a stepping stone to a broad array of downstream tasks such as summarisation or integration of individual patient records, extraction of structured information for national cancer registry reporting or building of semi-structured semantic patient representations for computing patient embeddings. More specifically, we present a method for unsupervised extraction of semantically-labelled textual segments from clinical notes and test it out on a dataset of Czech breast cancer patients, provided by Masaryk Memorial Cancer Institute (the largest Czech hospital specialising in oncology). Our goal was to extract, classify (i.e. label) and cluster segments of the free-text notes that correspond to specific clinical features (e.g., family background, comorbidities or toxicities). The presented results demonstrate the practical relevance of the proposed approach for building more sophisticated extraction and analytical pipelines deployed on Czech clinical notes.",,,978-1-6654-6819-0,1362-1368,IEEE , ,Toxicology;Buildings;Semantics;Pipelines;Feature extraction;Oncology;Breast cancer,,
4592,"Title:Predicting chemical activities from structures by attributed molecular graph classification

 Designing Quantitative Structure-Activity Relationship (QSAR) models has been a recurrent research interest for biologists and computer scientists. An example is to predict the toxicity of chemical compounds using their structural properties as features represented by graphs. A popular method to classify these graphs is to exploit classifiers such as support vector machines (SVMs) and graph kernels to incorporate the sequential, structural and chemical information. Previous works have focused on designing specific graph kernels for this task, amongst which graph alignment kernels are one of the most popular approach. Graph alignment kernels align the nodes of one graph to the nodes of the second graph so that the total overall similarity is maximized with respect to all possible alignments. However, taking both vertex and edge similarities into account makes the problem NP-Hard. In this paper, we present a novel general graph-matching based method for QSAR. We view the problem of calculating optimal assignments of two attributed graphs from a different perspective. Instead of first designing an atom kernel function and a bond kernel function, we first provide a training set of pairs of graphs with their corresponding matchings. We then try to learn the compatibility function over atoms and use only the atom kernel function to compute graph matchings. Our algorithm has the advantage of being more general and yet efficient than previous approaches for the QSAR problem. We evaluate our method on a set of chemical structure-activity prediction benchmark datasets, and show that our algorithm can achieve better or comparable accuracies over the optimal assignment kernel method.",Q. Xu; D. H. Hu; H. Xue; Q. Yang,,,Predicting chemical activities from structures by attributed molecular graph classification,,,10.1109/CIBCB.2010.5510690 ,IEEE Conferences ,,"Designing Quantitative Structure-Activity Relationship (QSAR) models has been a recurrent research interest for biologists and computer scientists. An example is to predict the toxicity of chemical compounds using their structural properties as features represented by graphs. A popular method to classify these graphs is to exploit classifiers such as support vector machines (SVMs) and graph kernels to incorporate the sequential, structural and chemical information. Previous works have focused on designing specific graph kernels for this task, amongst which graph alignment kernels are one of the most popular approach. Graph alignment kernels align the nodes of one graph to the nodes of the second graph so that the total overall similarity is maximized with respect to all possible alignments. However, taking both vertex and edge similarities into account makes the problem NP-Hard. In this paper, we present a novel general graph-matching based method for QSAR. We view the problem of calculating optimal assignments of two attributed graphs from a different perspective. Instead of first designing an atom kernel function and a bond kernel function, we first provide a training set of pairs of graphs with their corresponding matchings. We then try to learn the compatibility function over atoms and use only the atom kernel function to compute graph matchings. Our algorithm has the advantage of being more general and yet efficient than previous approaches for the QSAR problem. We evaluate our method on a set of chemical structure-activity prediction benchmark datasets, and show that our algorithm can achieve better or comparable accuracies over the optimal assignment kernel method.",,,978-1-4244-6766-2,1-8,IEEE , ,Kernel;Chemical compounds;Support vector machines;Drugs;Biology computing;Training data;Machine learning algorithms;Decision trees;Logistics;Regression tree analysis,,
4593,"Title:Exploring Bioinspired Feature Engineering Technique for Online Hate Speech Detection

 The spreading of hate speech and toxicity on social media and other online platforms has increased severely in the past decade. In the current scenario also, when the whole world is suffering with outspread of COVID-19 online hate speech spreading more than before. The spread of such hate can jeopardize the mental and physical health of many people and is thus necessary to stop its spread on online social media. This paper aims to explore bioinspired algorithms like PSO and GA to detect online hate speech on social media and other online platforms. We explore the hybrid feature selection approach to select valuable and meaningful features from the hate speech dataset to classify between hate and not hate posts efficiently. Our experiments indicate the random behavior of Particle Swarm Optimization and Genetic Algorithm and the decrease in accuracy when applied individually to the experiments. The proposed hybrid approach gives the comparative results as TF-IDF when applied with the baseline machine learning models.",Anjum; R. Katarya,,,Exploring Bioinspired Feature Engineering Technique for Online Hate Speech Detection,,,10.1109/ICONAT53423.2022.9726098 ,IEEE Conferences ,,"The spreading of hate speech and toxicity on social media and other online platforms has increased severely in the past decade. In the current scenario also, when the whole world is suffering with outspread of COVID-19 online hate speech spreading more than before. The spread of such hate can jeopardize the mental and physical health of many people and is thus necessary to stop its spread on online social media. This paper aims to explore bioinspired algorithms like PSO and GA to detect online hate speech on social media and other online platforms. We explore the hybrid feature selection approach to select valuable and meaningful features from the hate speech dataset to classify between hate and not hate posts efficiently. Our experiments indicate the random behavior of Particle Swarm Optimization and Genetic Algorithm and the decrease in accuracy when applied individually to the experiments. The proposed hybrid approach gives the comparative results as TF-IDF when applied with the baseline machine learning models.",,,978-1-6654-2577-3,1-6,IEEE , ,Toxicology;Machine learning algorithms;Social networking (online);Hate speech;Natural languages;Machine learning;Feature extraction,,
4594,"Title:Prediction of Response to Chemotherapy of Breast Cancer Tumors based on Deep Learning

 Neoadjuvant chemotherapy (NACT) has been defined as a widely treatment approach administered before surgery for women with breast cancer to minimize tumor size and improve outcomes. After NACT, pathological complete response (pCR) indicates the absence of residual tumor in the breast. To enhance the long-term survival outcome and to avoid eventual toxicities by NACT, the prediction of pCR using routine breast imaging is an important step to determine the patient treatment. In this work, we applied deep learning models such as Resnet50 and VGG19 to predict pCR from pretreatment dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) scans. The data was obtained using the public database I-SPY1 TRIAL, which is accessible from The Cancer Imaging Archive (TCIA) and encloses 222 patients with breast cancer disease. The dataset was split into 20% for tests and 80% for training. To improve generalization of the model, we also applied data augmentation methods in the training phase as rotating and flipping. Experimental results obtained showed that Resnet50 model outperforms VGG19 in terms of accuracy; where an accuracy of 92.22% and 90.76% are obtained, respectively with data augmentation and axial orientation.",A. Bahba; R. Khemiri; M. A. Zayene; F. Ezahra Sayadi,,,Prediction of Response to Chemotherapy of Breast Cancer Tumors based on Deep Learning,4,,10.1109/CISTEM55808.2022.10043910 ,IEEE Conferences ,,"Neoadjuvant chemotherapy (NACT) has been defined as a widely treatment approach administered before surgery for women with breast cancer to minimize tumor size and improve outcomes. After NACT, pathological complete response (pCR) indicates the absence of residual tumor in the breast. To enhance the long-term survival outcome and to avoid eventual toxicities by NACT, the prediction of pCR using routine breast imaging is an important step to determine the patient treatment. In this work, we applied deep learning models such as Resnet50 and VGG19 to predict pCR from pretreatment dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) scans. The data was obtained using the public database I-SPY1 TRIAL, which is accessible from The Cancer Imaging Archive (TCIA) and encloses 222 patients with breast cancer disease. The dataset was split into 20% for tests and 80% for training. To improve generalization of the model, we also applied data augmentation methods in the training phase as rotating and flipping. Experimental results obtained showed that Resnet50 model outperforms VGG19 in terms of accuracy; where an accuracy of 92.22% and 90.76% are obtained, respectively with data augmentation and axial orientation.",,,978-1-6654-5168-0,1-6,IEEE , ,Training;Deep learning;Chemotherapy;Toxicology;Surgery;Predictive models;Breast cancer,,
4595,"Title:Variance Tolerance Factors For Interpreting All Neural Networks

 Black box models only provide results for deep learning tasks, and lack informative details about how these results were obtained. Knowing how input variables are related to outputs, in addition to why they are related, can be critical to translating predictions into laboratory experiments, or defending a model prediction under scrutiny. In this paper, we propose a general theory that defines a variance tolerance factor (VTF) inspired by influence function, to interpret features in the context of black box neural networks by ranking the importance of features, and construct a novel architecture consisting of a base model and feature model to explore the feature importance in a Rashomon set that contains all well-performing neural networks. Two feature importance ranking methods in the Rashomon set and a feature selection method based on the VTF are created and explored. A thorough evaluation on synthetic and benchmark datasets is provided, and the method is applied to two real world examples predicting the formation of noncrystalline gold nanoparticles and the chemical toxicity 1793 aromatic compounds exposed to a protozoan ciliate for 40 hours.",S. Li; A. Barnard,,,Variance Tolerance Factors For Interpreting All Neural Networks,,,10.1109/IJCNN54540.2023.10191646 ,IEEE Conferences ,,"Black box models only provide results for deep learning tasks, and lack informative details about how these results were obtained. Knowing how input variables are related to outputs, in addition to why they are related, can be critical to translating predictions into laboratory experiments, or defending a model prediction under scrutiny. In this paper, we propose a general theory that defines a variance tolerance factor (VTF) inspired by influence function, to interpret features in the context of black box neural networks by ranking the importance of features, and construct a novel architecture consisting of a base model and feature model to explore the feature importance in a Rashomon set that contains all well-performing neural networks. Two feature importance ranking methods in the Rashomon set and a feature selection method based on the VTF are created and explored. A thorough evaluation on synthetic and benchmark datasets is provided, and the method is applied to two real world examples predicting the formation of noncrystalline gold nanoparticles and the chemical toxicity 1793 aromatic compounds exposed to a protozoan ciliate for 40 hours.",2161-4407,,978-1-6654-8867-9,1-9,IEEE , ,Training;Weight measurement;Computational modeling;Neural networks;Predictive models;Feature extraction;Mathematical models,,
4596,"Title:Combining Aliivibrio fischeri and predictive models to study the mixture toxicity of Nitrite, Ammonia and Heavy Metals : Building a new toxicity sensor for Recirculating Aquaculture Systems

 The use of Aliivibrio fischeri as a water quality sensor for monitoring aquaculture water is of great interest. Here, a Uniform Ray design was employed to study the mixture of five important toxicants present in recirculating aquaculture systems (RAS) water. The results were compared with the Concentration Addition and the Independent Action models. None of the models could accurately predict the behavior of the mixture, possibly due to synergism and antagonism interactions. The first was considered adequate to be used as a predictive model for a new water quality sensor for RAS. This demonstrate the need of non-additive water quality sensors.",W. Li; L. F. B. A. da Silva; J. C. G. Simões; N. M. M. Pires; B. Hønsvall,,,"Combining Aliivibrio fischeri and predictive models to study the mixture toxicity of Nitrite, Ammonia and Heavy Metals : Building a new toxicity sensor for Recirculating Aquaculture Systems",,,10.1109/MeMeA.2018.8438792 ,IEEE Conferences ,,"The use of Aliivibrio fischeri as a water quality sensor for monitoring aquaculture water is of great interest. Here, a Uniform Ray design was employed to study the mixture of five important toxicants present in recirculating aquaculture systems (RAS) water. The results were compared with the Concentration Addition and the Independent Action models. None of the models could accurately predict the behavior of the mixture, possibly due to synergism and antagonism interactions. The first was considered adequate to be used as a predictive model for a new water quality sensor for RAS. This demonstrate the need of non-additive water quality sensors.",,,978-1-5386-3392-2,1-5,IEEE , ,Predictive models;Zinc;Microorganisms;Aquaculture;Additives;Luminescence;Copper,,
4597,"Title:“Did You Miss My Comment or What?” Understanding Toxicity in Open Source Discussions

 Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.",C. Miller; S. Cohen; D. Klug; B. Vasilescu; C. Kästner,,,“Did You Miss My Comment or What?” Understanding Toxicity in Open Source Discussions,,,10.1145/3510003.3510111 ,IEEE Conferences ,,"Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.",1558-1225,,978-1-4503-9221-1,710-722,IEEE , ,Toxicology;Social networking (online);Hate speech;Encyclopedias;Internet;Online services;Open source software,,
4598,"Title:Classification of Toxicity in Comments using NLP and LSTM

 With the increased usage of online social media platforms, there has been a sharp hike in toxic comments. Toxicity must be reduced. Classification of toxicity in comments has been an effective research field with various newly proposed approaches. This research and analysis provide a novel usage of the Natural Language Processing approach to classify the type of toxicity in comments. This analysis intends to interpret the type of comment and determine the various types of toxic classes such as obscene, identity hate, threat, toxic, insult, severe toxic. The input to our algorithm is comments from online platforms like toxic or non-toxic. Our model aims to predict the toxicity class. This project intends to analyze in phases. In Phase I, the objective is to evaluate the toxicity in comments by giving data through various techniques like TDIDF, spacy that helps data to perceive how every word in a comment is classified into a particular category of toxic class. Here, Algorithm will take comments from test data and predict the type of toxicity for test data like a toxic, threat, and so on. In Phase II, Data is analyzed to organize the comments into toxic and non-toxic categories. This promotes us to perceive the particular comment is toxic or not.",A. Garlapati; N. Malisetty; G. Narayanan,,,Classification of Toxicity in Comments using NLP and LSTM,1,,10.1109/ICACCS54159.2022.9785067 ,IEEE Conferences ,,"With the increased usage of online social media platforms, there has been a sharp hike in toxic comments. Toxicity must be reduced. Classification of toxicity in comments has been an effective research field with various newly proposed approaches. This research and analysis provide a novel usage of the Natural Language Processing approach to classify the type of toxicity in comments. This analysis intends to interpret the type of comment and determine the various types of toxic classes such as obscene, identity hate, threat, toxic, insult, severe toxic. The input to our algorithm is comments from online platforms like toxic or non-toxic. Our model aims to predict the toxicity class. This project intends to analyze in phases. In Phase I, the objective is to evaluate the toxicity in comments by giving data through various techniques like TDIDF, spacy that helps data to perceive how every word in a comment is classified into a particular category of toxic class. Here, Algorithm will take comments from test data and predict the type of toxicity for test data like a toxic, threat, and so on. In Phase II, Data is analyzed to organize the comments into toxic and non-toxic categories. This promotes us to perceive the particular comment is toxic or not.",2575-7288,,978-1-6654-0816-5,16-21,IEEE , ,Toxicology;Social networking (online);Communication systems;Computational modeling;Predictive models;Prediction algorithms;Natural language processing,,
4599,"Title:“Bad Vibrations”: Sensing Toxicity From In-Game Audio Features

 Toxicity in online gaming is a problem that causes harm to players, developers, and gaming communities. Toxic behaviors persist in online multiplayer games for a number of reasons, and continue to go unchecked due in large part to a lack of reliable methods to accurately detect toxicity online, in real-time, and at scale. In this article, we present a modeling approach that uses features derived from in-game verbal communication and game metadata to predict if Overwatch games are toxic. With logistic regression models, we achieve accuracy scores of 86.3% for binary (high vs. low toxicity) predictions. We discuss which features were most salient, potential application of our predictive model, and implications for toxicity detection in games. Our approach is a low-cost, low-effort, and noninvasive contribution to holistic efforts in combating toxicity in games.",E. Reid; R. L. Mandryk; N. A. Beres; M. Klarkowski; J. Frommel,,,“Bad Vibrations”: Sensing Toxicity From In-Game Audio Features,14,4,10.1109/TG.2022.3176849 ,IEEE Journals ,,"Toxicity in online gaming is a problem that causes harm to players, developers, and gaming communities. Toxic behaviors persist in online multiplayer games for a number of reasons, and continue to go unchecked due in large part to a lack of reliable methods to accurately detect toxicity online, in real-time, and at scale. In this article, we present a modeling approach that uses features derived from in-game verbal communication and game metadata to predict if Overwatch games are toxic. With logistic regression models, we achieve accuracy scores of 86.3% for binary (high vs. low toxicity) predictions. We discuss which features were most salient, potential application of our predictive model, and implications for toxicity detection in games. Our approach is a low-cost, low-effort, and noninvasive contribution to holistic efforts in combating toxicity in games.",2475-1510,,,558-568,IEEE , ,Toxicology;Games;Feature extraction;Predictive models;Sensors;User experience;Sports,,
4600,"Title:Multi-Label Classification of Indonesian Online Toxicity using BERT and RoBERTa

 Online toxicity detection in Indonesian digital interactions poses a significant challenge due to the complexity and nuances of language. This study aims to evaluate the effectiveness of the BERT and RoBERTa language models, specifically IndoBERTweet, IndoBERT, and Indonesian RoBERTa, for identifying toxic content in Bahasa Indonesia. Our research methodology includes data collection, dataset pre-processing, data annotation, and model fine-tuning for multi-label classification tasks. The model performance is assessed using macro average of precision, recall, and F1-score. Our findings show that IndoBERTweet, fine-tuned under optimal hyperparameters (5e-5 learning rate, a batch size of 32, and three epochs), outperforms the other models with a precision of 0.85, recall of 0.94, and an F1-score of 0.89. These findings indicate that IndoBERTweet performs better in detecting and classifying online toxicity in Bahasa Indonesia. The study ’s implications extend to fostering a safer and healthier online environment for Indonesian users, while also providing a foundation for future research exploring additional models, hyperparameter optimizations, and techniques for enhancing toxicity detection and classification in the Indonesian language.",Y. Sagama; A. Alamsyah,,,Multi-Label Classification of Indonesian Online Toxicity using BERT and RoBERTa,,,10.1109/IAICT59002.2023.10205892 ,IEEE Conferences ,,"Online toxicity detection in Indonesian digital interactions poses a significant challenge due to the complexity and nuances of language. This study aims to evaluate the effectiveness of the BERT and RoBERTa language models, specifically IndoBERTweet, IndoBERT, and Indonesian RoBERTa, for identifying toxic content in Bahasa Indonesia. Our research methodology includes data collection, dataset pre-processing, data annotation, and model fine-tuning for multi-label classification tasks. The model performance is assessed using macro average of precision, recall, and F1-score. Our findings show that IndoBERTweet, fine-tuned under optimal hyperparameters (5e-5 learning rate, a batch size of 32, and three epochs), outperforms the other models with a precision of 0.85, recall of 0.94, and an F1-score of 0.89. These findings indicate that IndoBERTweet performs better in detecting and classifying online toxicity in Bahasa Indonesia. The study ’s implications extend to fostering a safer and healthier online environment for Indonesian users, while also providing a foundation for future research exploring additional models, hyperparameter optimizations, and techniques for enhancing toxicity detection and classification in the Indonesian language.",2834-8249,,979-8-3503-1363-5,143-149,IEEE , ,Toxicology;Bit error rate;Data collection;Hyperparameter optimization;Data models;Communications technology;Fourth Industrial Revolution,,
4601,"Title:Detection of Low-toxic Texts in Similar Sets Using a Modified XLM-RoBERTa Neural Network and Toxicity Confidence Parameters

 The article considers the problem of classifying low-toxic texts using a modified neural network of the XLM-RoBERTa transformer architecture, trained on highly toxic texts. Comments from the School of Pedagogical Design at the University of 20.35 were used as kits for identifying low-toxic texts. The network was not retrained on low-toxic texts. Instead, the classification of low-toxic texts was carried out by varying the toxicity confidence parameter. An approximation dependence of the number of low-toxic texts on the parameter of toxicity reliability was constructed and a threshold value of the toxicity reliability parameter was obtained, at which the quality of the classification of low-toxic texts is maximal. The hypothesis of the similarity of the toxicity of homogeneous information resources was also formulated and confirmed.",Y. A. Seliverstov; A. A. Komissarov; E. D. Poslovskaia; A. A. Lesovodskaya; A. V. Podtikhov,,,Detection of Low-toxic Texts in Similar Sets Using a Modified XLM-RoBERTa Neural Network and Toxicity Confidence Parameters,,,10.1109/SCM52931.2021.9507117 ,IEEE Conferences ,,"The article considers the problem of classifying low-toxic texts using a modified neural network of the XLM-RoBERTa transformer architecture, trained on highly toxic texts. Comments from the School of Pedagogical Design at the University of 20.35 were used as kits for identifying low-toxic texts. The network was not retrained on low-toxic texts. Instead, the classification of low-toxic texts was carried out by varying the toxicity confidence parameter. An approximation dependence of the number of low-toxic texts on the parameter of toxicity reliability was constructed and a threshold value of the toxicity reliability parameter was obtained, at which the quality of the classification of low-toxic texts is maximal. The hypothesis of the similarity of the toxicity of homogeneous information resources was also formulated and confirmed.",,,978-1-6654-3974-9,161-164,IEEE , ,Analytical models;Toxicology;Computational modeling;Neural networks;Information services;Computer architecture;Reliability engineering,,
4602,"Title:Fish flesh dielectric performance for toxicity detection

 This paper investigates electrical response of fish flesh using a new design of slender steel indicator acted as probe in determining dielectric properties over a frequency range from 10Hz to 100Hz. At present, most of dielectric measurement technique uses electrode contact to under test sample, biological specimen but these techniques mostly are not suitable for living specimen. Therefore, in this research, a slender metal that resembles a pointer is designed and applied to analyse the electrical response of fish flesh dielectric properties for indicator of toxicity level in the fish body. Initial findings proven that proposed technique is feasible to be implemented.",H. Johar; S. R. M. S. Baki; Siti Hazurah Indera Putra; N. M. Tahir,,,Fish flesh dielectric performance for toxicity detection,,,10.1109/SPC.2013.6735134 ,IEEE Conferences ,,"This paper investigates electrical response of fish flesh using a new design of slender steel indicator acted as probe in determining dielectric properties over a frequency range from 10Hz to 100Hz. At present, most of dielectric measurement technique uses electrode contact to under test sample, biological specimen but these techniques mostly are not suitable for living specimen. Therefore, in this research, a slender metal that resembles a pointer is designed and applied to analyse the electrical response of fish flesh dielectric properties for indicator of toxicity level in the fish body. Initial findings proven that proposed technique is feasible to be implemented.",,,978-1-4799-2209-3,214-218,IEEE , ,Marine animals;Dielectrics;Probes;Dielectric measurement;Voltage measurement;Electrodes;Frequency measurement,,
4603,"Title:Mining Protein Interactions and Gene Expression Data to Gain Insights into Drug-induced Toxicity Mechanisms

 In silico approaches for drug-induced toxicity evaluation are likely to enable improved screening of new chemical entities during drug discovery and development. Analysis of protein-protein interaction (PPI) networks using an edge centrality-based measure has previously been shown to reveal protein modules that may be associated with drug-induced toxicity. Here, we extend the algorithm by integrating protein interaction information with in vitro gene expression data from tissue treated with drugs known to be associated with the toxicity. We evaluate the new measure for its ability to detect non- immune neutropenia related proteins and propose a biomarker panel that may be valuable for screening future drug candidates.",K. Desai; D. Brott; X. Hu; A. Christianson,,,Mining Protein Interactions and Gene Expression Data to Gain Insights into Drug-induced Toxicity Mechanisms,,,10.1109/BIBM.2011.86 ,IEEE Conferences ,,"In silico approaches for drug-induced toxicity evaluation are likely to enable improved screening of new chemical entities during drug discovery and development. Analysis of protein-protein interaction (PPI) networks using an edge centrality-based measure has previously been shown to reveal protein modules that may be associated with drug-induced toxicity. Here, we extend the algorithm by integrating protein interaction information with in vitro gene expression data from tissue treated with drugs known to be associated with the toxicity. We evaluate the new measure for its ability to detect non- immune neutropenia related proteins and propose a biomarker panel that may be valuable for screening future drug candidates.",,,978-1-4577-1799-4,652-657,IEEE , ,Proteins;Drugs;Gene expression;Databases;Image edge detection;Protein engineering;Compounds,,
4604,"Title:Light emitting devices and integrated electrochemical sensors on lab-on-chip for toxicity bioassays based on algal physiology

 In the frame of water toxicity analysis, a portable, glass-based, lab-on-chip was developed, integrating threeelectrode electrochemical microsensors and organic lightemitting diodes (OLED). The basic detection principle consists in monitoring electrochemically O2-related, algal metabolism in presence of herbicides. Thus, aiming on Diuron herbicide detection, a concentration-dependent inhibition effect on photosynthetic oxygen production rate was evidenced in the [0 - 1 µM] range. Finally, OLEDbased integrated system demonstrates higher detection characteristics than those using external white light source (sensitivity: 0.48 versus 0.26 nA/s/µM) and is highly promising for further integration of optical and electrochemical sensors enabling double complementary detection.",A. Tsopela; A. Laborde; L. Salvagnac; I. Séguy; R. Izquierdo; P. Juneau; P. Temple-Boyer; J. Launay,,,Light emitting devices and integrated electrochemical sensors on lab-on-chip for toxicity bioassays based on algal physiology,,,10.1109/TRANSDUCERS.2015.7181251 ,IEEE Conferences ,,"In the frame of water toxicity analysis, a portable, glass-based, lab-on-chip was developed, integrating threeelectrode electrochemical microsensors and organic lightemitting diodes (OLED). The basic detection principle consists in monitoring electrochemically O2-related, algal metabolism in presence of herbicides. Thus, aiming on Diuron herbicide detection, a concentration-dependent inhibition effect on photosynthetic oxygen production rate was evidenced in the [0 - 1 µM] range. Finally, OLEDbased integrated system demonstrates higher detection characteristics than those using external white light source (sensitivity: 0.48 versus 0.26 nA/s/µM) and is highly promising for further integration of optical and electrochemical sensors enabling double complementary detection.",2164-1641,,978-1-4799-8955-3,1621-1624,IEEE , ,Organic light emitting diodes;Light sources;Production;Monitoring;Glass;Sensors;Biochemistry,,
4605,"Title:Toxicity Detection Methodology of Adverse Outcome Pathways using Physicochemical Properties and Machine Learning Approaches

 In order to quickly and effectively determine whether certain chemical compounds have the potential to interfere with bodily functions that could be harmful to a person's health. Authors have developed a prediction model for improved assessment of toxicity. Here, we have presented an in-silico computational method for the prediction of toxicity of small drug molecules using their various physicochemical characteristics (molecular descriptors) that can bind with various nuclear receptor (NR) and stress response (SR) signalling pathways. These signalling pathways are also known as adverse outcome pathways. The pharmaceutical data exploration laboratory (PaDEL) software is used for extracting the features of all drug molecules. Initially, the class imbalance is resolved using SMOTE algorithms for all the datasets and feature selection is performed by a correlation-based feature selection algorithm. It is found that the extended topochemical atom (ETA) descriptors, electro-topological state descriptors, Crippen's log P, and Molar refractivity (MR) are quite rich in chemical information to encode the structural features that contribute to the toxicities and these indices may be used in combination with other topological and physicochemical descriptors for the development of predictive QSAR model. We have proposed a methodology that can be applied on various datasets of adverse outcome pathways for the prediction of toxicity of small drug molecules. The accuracy that we have found by using our proposed methodology is outperformed in comparison to using the models in simple manners.",V. K. Gupta; A. Gupta; M. K. Singh; A. Gupta; A. Tomar,,,Toxicity Detection Methodology of Adverse Outcome Pathways using Physicochemical Properties and Machine Learning Approaches,,,10.1109/INCET57972.2023.10170360 ,IEEE Conferences ,,"In order to quickly and effectively determine whether certain chemical compounds have the potential to interfere with bodily functions that could be harmful to a person's health. Authors have developed a prediction model for improved assessment of toxicity. Here, we have presented an in-silico computational method for the prediction of toxicity of small drug molecules using their various physicochemical characteristics (molecular descriptors) that can bind with various nuclear receptor (NR) and stress response (SR) signalling pathways. These signalling pathways are also known as adverse outcome pathways. The pharmaceutical data exploration laboratory (PaDEL) software is used for extracting the features of all drug molecules. Initially, the class imbalance is resolved using SMOTE algorithms for all the datasets and feature selection is performed by a correlation-based feature selection algorithm. It is found that the extended topochemical atom (ETA) descriptors, electro-topological state descriptors, Crippen's log P, and Molar refractivity (MR) are quite rich in chemical information to encode the structural features that contribute to the toxicities and these indices may be used in combination with other topological and physicochemical descriptors for the development of predictive QSAR model. We have proposed a methodology that can be applied on various datasets of adverse outcome pathways for the prediction of toxicity of small drug molecules. The accuracy that we have found by using our proposed methodology is outperformed in comparison to using the models in simple manners.",,,979-8-3503-3575-0,1-7,IEEE , ,Drugs;Toxicology;Computational modeling;Software algorithms;Predictive models;Feature extraction;National Institutes of Health,,
4606,"Title:Cyber Bullying and Toxicity Detection Using Machine Learning

 The increased use of online platforms for communication has made cyberbullying and toxicity detection a critical issue in recent times. This paper explores the topic of cyberbullying and toxicity detection and proposes potential solutions for identifying cyber violence and offensive language more effectively. According to the study of the algorithms in examined research papers on cyberbullying and toxicity detection, this research study presents a novel approach that achieved 90% accuracy in identifying bully text in social media comments. This is done by using machine learning algorithms such as SVM, Logistic Regression, Naive Bayes, KNN, and Random Forest, with SVM and Random Forest exhibiting the best performance. Additionally, the system improved the accuracy of identifying bully images in social media posts to 84.5% by using the MobileNetV2 model (DNN), which is superior to other approaches. The system is trained using a large, labeled dataset of text data to identify and classify different types of cyberbullying and toxic content. The findings suggest that the proposed models hold promise in detecting instances of cyberbullying and offensive content effectively. These results have significant implications for the development of cyberbullying and toxicity detection systems. The proposed approach can be integrated into various social media platforms and online communities to identify and mitigate cyberbullying and toxic content more efficiently. The study also highlights the need for continued research and collaboration among stakeholders to address cyberbullying and toxicity effectively.",R. Jadhav; N. Agarwal; S. Shevate; C. Sawakare; P. Parakh; S. Khandare,,,Cyber Bullying and Toxicity Detection Using Machine Learning,,,10.1109/ICPCSN58827.2023.00017 ,IEEE Conferences ,,"The increased use of online platforms for communication has made cyberbullying and toxicity detection a critical issue in recent times. This paper explores the topic of cyberbullying and toxicity detection and proposes potential solutions for identifying cyber violence and offensive language more effectively. According to the study of the algorithms in examined research papers on cyberbullying and toxicity detection, this research study presents a novel approach that achieved 90% accuracy in identifying bully text in social media comments. This is done by using machine learning algorithms such as SVM, Logistic Regression, Naive Bayes, KNN, and Random Forest, with SVM and Random Forest exhibiting the best performance. Additionally, the system improved the accuracy of identifying bully images in social media posts to 84.5% by using the MobileNetV2 model (DNN), which is superior to other approaches. The system is trained using a large, labeled dataset of text data to identify and classify different types of cyberbullying and toxic content. The findings suggest that the proposed models hold promise in detecting instances of cyberbullying and offensive content effectively. These results have significant implications for the development of cyberbullying and toxicity detection systems. The proposed approach can be integrated into various social media platforms and online communities to identify and mitigate cyberbullying and toxic content more efficiently. The study also highlights the need for continued research and collaboration among stakeholders to address cyberbullying and toxicity effectively.",,,979-8-3503-2284-2,66-73,IEEE , ,Support vector machines;Pervasive computing;Logistic regression;Toxicology;Machine learning algorithms;Cyberbullying;Forestry,,
4607,"Title:Detection of toxicity in social media based on Natural Language Processing methods

 Comments on important websites, such as popular news portals or social media platforms, are among the main ways of virtual interaction. Unfortunately, the behavior of users on these websites often becomes rude or disrespectful, by spreading toxic comments which can muddle the proper functioning of these sites. The aim of this research is to detect these toxic comments, and to find parts, toxic spans, of these comments to which toxicity can be attributed. Thus, we explored and compared various classifiers belonging to three categories “Machine Learning, Ensemble Learning and Deep Learning” and using different text representations. For detecting toxic spans in the comments, we applied an unsupervised method, we apply the Local Interpretable Model-Agnostic Explanations (LIME).The measures we used to evaluate our methods are accuracy, recall, and Fl-score. Our experiments showed that deep learning models performed unquestionably in the task of detecting toxic comments. The LSTM models with the Globe representation and LSTM with FastText were able to produce a higher F1 and accuracy compared to the other models used. For Toxic spans detction, the higher scores were obtained when combining LIME with classifier LSTM(GloVe) with an accuracy of 98% to identify the toxic spans.",M. Taleb; A. Hamza; M. Zouitni; N. Burmani; S. Lafkiar; N. En-Nahnahi,,,Detection of toxicity in social media based on Natural Language Processing methods,,,10.1109/ISCV54655.2022.9806096 ,IEEE Conferences ,,"Comments on important websites, such as popular news portals or social media platforms, are among the main ways of virtual interaction. Unfortunately, the behavior of users on these websites often becomes rude or disrespectful, by spreading toxic comments which can muddle the proper functioning of these sites. The aim of this research is to detect these toxic comments, and to find parts, toxic spans, of these comments to which toxicity can be attributed. Thus, we explored and compared various classifiers belonging to three categories “Machine Learning, Ensemble Learning and Deep Learning” and using different text representations. For detecting toxic spans in the comments, we applied an unsupervised method, we apply the Local Interpretable Model-Agnostic Explanations (LIME).The measures we used to evaluate our methods are accuracy, recall, and Fl-score. Our experiments showed that deep learning models performed unquestionably in the task of detecting toxic comments. The LSTM models with the Globe representation and LSTM with FastText were able to produce a higher F1 and accuracy compared to the other models used. For Toxic spans detction, the higher scores were obtained when combining LIME with classifier LSTM(GloVe) with an accuracy of 98% to identify the toxic spans.",2768-0754,,978-1-6654-9558-5,1-7,IEEE , ,Deep learning;Learning systems;Toxicology;Machine learning algorithms;Social networking (online);Transformers;Natural language processing,,
4608,"Title:IoT BasedSmart Waste Management System: India prospective

 For building smart cities there is requirement of such a smart system which monitors the dustbin and providesits real time status. In present scenario Municipal Corporations in India doesn't get real time information about the dustbins. In this concern, we are implementing a system based on Internet of Things (IoT) that can send a message to corporation about the overflow and toxicity level of the dustbins. A website is also developed to supervise the data related to the dustbins. Message is sent using GSM module to the mobile phone and data related to the dustbin status is updated on the website. At this website citizens can also submit complaints related to dustbin or waste management. In recommended system, Arduino is used as a microcontroller to interface between GSM/GPRS module with sensors. Ultrasonic sensor and gas sensor are used for measurement of dustbin level and toxicity respectively.",R. K. Singhvi; R. L. Lohar; A. Kumar; R. Sharma; L. D. Sharma; R. K. Saraswat,,,IoT BasedSmart Waste Management System: India prospective,,,10.1109/IoT-SIU.2019.8777698 ,IEEE Conferences ,,"For building smart cities there is requirement of such a smart system which monitors the dustbin and providesits real time status. In present scenario Municipal Corporations in India doesn't get real time information about the dustbins. In this concern, we are implementing a system based on Internet of Things (IoT) that can send a message to corporation about the overflow and toxicity level of the dustbins. A website is also developed to supervise the data related to the dustbins. Message is sent using GSM module to the mobile phone and data related to the dustbin status is updated on the website. At this website citizens can also submit complaints related to dustbin or waste management. In recommended system, Arduino is used as a microcontroller to interface between GSM/GPRS module with sensors. Ultrasonic sensor and gas sensor are used for measurement of dustbin level and toxicity respectively.",,,978-1-7281-1253-4,1-6,IEEE , ,Gas detectors;GSM;Acoustics;Real-time systems;Ultrasonic variables measurement;Waste management,,
4609,"Title:Identification of Toxicity in MultimediaMessages for Controlling Cyberbullying on Social Media by Natural Language Processing

 Speaking hatefully is an antisocial conduct. Hate can be expressed on the basis of gender, race, or religion, ethnic, etc. The definition of “hate speech” is ambiguous. The Hate speech is defined by the Council of the European Union as “any types of expression which disseminate, provoke, or defend intolerance as a reason for racial hatred, xenophobia, antisemitism, or other types of hatred, including violent nationalism and ethnocentrism, as well as prejudice and hatred toward migrants, minorities, and those with immigrant backgrounds. The most pressing issue in recent times in social media and online groups is toxicity identification sites for networking. Therefore, it is necessary to create an automatic hazardous identification system to keep people out of and restrict their access to these online settings. The prevalence of hate speech presents significant difficulties for the cyber culture. Users can wish for social media sites and online forums to support anti-hate discourse. Hate speech detection, however, is still a young technology, and system designers must come up with a way to identify unwanted hate speech while upholding the atmosphere of online freedom of speech. No method for detecting excellence has yet been put forth. Identifying the form of communication is hate speech and automatically recognising the hate speech are the two typical obstacles for a hate speech detection task. People must first decide which kinds of speech fall under the category of hate speech before screening it out. The majority of social media platforms define hate speech differently. In this day and age, Internet is necessary, and ethics has to be followed, however several parties spread hate speech deviating on race, ethnicity, and religion. The user’s freedom and anonymity increase the harassment by hate speech. It also adds lack of regulation on social media communication. Cyber bullying and trolling are two kinds of abusive behaviour.",V. Nithyashree; B. N. Hiremath; L. Vanishree; A. Duvvuri; D. A. Madival; G. Vidyashree,,,Identification of Toxicity in MultimediaMessages for Controlling Cyberbullying on Social Media by Natural Language Processing,,,10.1109/DISCOVER55800.2022.9974631 ,IEEE Conferences ,,"Speaking hatefully is an antisocial conduct. Hate can be expressed on the basis of gender, race, or religion, ethnic, etc. The definition of “hate speech” is ambiguous. The Hate speech is defined by the Council of the European Union as “any types of expression which disseminate, provoke, or defend intolerance as a reason for racial hatred, xenophobia, antisemitism, or other types of hatred, including violent nationalism and ethnocentrism, as well as prejudice and hatred toward migrants, minorities, and those with immigrant backgrounds. The most pressing issue in recent times in social media and online groups is toxicity identification sites for networking. Therefore, it is necessary to create an automatic hazardous identification system to keep people out of and restrict their access to these online settings. The prevalence of hate speech presents significant difficulties for the cyber culture. Users can wish for social media sites and online forums to support anti-hate discourse. Hate speech detection, however, is still a young technology, and system designers must come up with a way to identify unwanted hate speech while upholding the atmosphere of online freedom of speech. No method for detecting excellence has yet been put forth. Identifying the form of communication is hate speech and automatically recognising the hate speech are the two typical obstacles for a hate speech detection task. People must first decide which kinds of speech fall under the category of hate speech before screening it out. The majority of social media platforms define hate speech differently. In this day and age, Internet is necessary, and ethics has to be followed, however several parties spread hate speech deviating on race, ethnicity, and religion. The user’s freedom and anonymity increase the harassment by hate speech. It also adds lack of regulation on social media communication. Cyber bullying and trolling are two kinds of abusive behaviour.",,,978-1-6654-8716-0,12-18,IEEE , ,Toxicology;Hate speech;Bit error rate;Anxiety disorders;Cyberbullying;Speech recognition;Very large scale integration,,
4610,"Title:Multi-Label Toxicity Detection: An Analysis

 Everybody has the freedom and flexibility to express their opinions and ideas through social networking and online discussion platforms. However, individuals are dealing with circumstances where the vast majority takes these networks casually and misuses them as a way to abuse and threaten others, which can result in cyberattacks, cyberbullying, nightmares, and, in severe cases, suicidal attempts. Such statements must be manually identified and classified, which is a time-taking, exhausting, and unreliable process. This research examines thetoxicity of remark and also investigate the sort of toxicity, categorize the comments into various labels if they are toxic. This research work will also compare various existing machine learning algorithms on the dataset named Toxic Comment Classification Challenge imported from Kaggle that contains 15000 comments. Machine Learning, Deep Learning and Natural Language Processing lend a helping hand in reducing the poisonous environment that exists on numerous discussion forums.",P. Priya; P. Gupta; R. Goel; V. Jain,,,Multi-Label Toxicity Detection: An Analysis,,,10.1109/ICIRCA57980.2023.10220812 ,IEEE Conferences ,,"Everybody has the freedom and flexibility to express their opinions and ideas through social networking and online discussion platforms. However, individuals are dealing with circumstances where the vast majority takes these networks casually and misuses them as a way to abuse and threaten others, which can result in cyberattacks, cyberbullying, nightmares, and, in severe cases, suicidal attempts. Such statements must be manually identified and classified, which is a time-taking, exhausting, and unreliable process. This research examines thetoxicity of remark and also investigate the sort of toxicity, categorize the comments into various labels if they are toxic. This research work will also compare various existing machine learning algorithms on the dataset named Toxic Comment Classification Challenge imported from Kaggle that contains 15000 comments. Machine Learning, Deep Learning and Natural Language Processing lend a helping hand in reducing the poisonous environment that exists on numerous discussion forums.",,,979-8-3503-2142-5,1131-1136,IEEE , ,Support vector machines;Deep learning;Toxicology;Machine learning algorithms;Discussion forums;Neural networks;Static VAr compensators,,
4611,"Title:Mathematical Modelling and Effect Size Analysis in Support of Searching for the Proteomic Signature of Radiotherapy Toxicity

 Development of new technologies has resulted in the significant expansion of biological research, among which studies in the area of genomics, transcriptomics, proteomics, and metabolomics are the leading ones. In the majority of omics studies, the goal is to identify reliable molecular biomarkers and pathways associated with the examined process. In almost all cases, a list of differentially expressed genes or proteins is constructed, which is not easy to obtain for some experimental designs. In our work, we mainly focus on the experiments with small sample size. The goal was to determine the robust proteomic signature of radiation exposure in the mouse model. Our selection algorithm combines mathematical modelling of signal and its fold change distributions with the comprehensive effect size analysis. Thanks to the data-driven automated thresholding of the protein absolute or relative (fold change) expressions, and Cohens effect size based filters, the obtained proteomic signature demonstrated a higher level of consistency and functional coherency. The additional, intuitively expected, signalling pathways were identified when compared to the standard statistical approach.",K. Leszczorz; O. Azimzadeh; S. Tapio; M. Atkinson; J. Polanska,,,Mathematical Modelling and Effect Size Analysis in Support of Searching for the Proteomic Signature of Radiotherapy Toxicity,,,10.1109/BIBE.2019.00051 ,IEEE Conferences ,,"Development of new technologies has resulted in the significant expansion of biological research, among which studies in the area of genomics, transcriptomics, proteomics, and metabolomics are the leading ones. In the majority of omics studies, the goal is to identify reliable molecular biomarkers and pathways associated with the examined process. In almost all cases, a list of differentially expressed genes or proteins is constructed, which is not easy to obtain for some experimental designs. In our work, we mainly focus on the experiments with small sample size. The goal was to determine the robust proteomic signature of radiation exposure in the mouse model. Our selection algorithm combines mathematical modelling of signal and its fold change distributions with the comprehensive effect size analysis. Thanks to the data-driven automated thresholding of the protein absolute or relative (fold change) expressions, and Cohens effect size based filters, the obtained proteomic signature demonstrated a higher level of consistency and functional coherency. The additional, intuitively expected, signalling pathways were identified when compared to the standard statistical approach.",2471-7819,,978-1-7281-4617-1,244-249,IEEE , ,Proteins;Lung;Proteomics;Mice;Peptides;Testing;Statistical analysis,,
4612,"Title:A Novel Combined Biomonitoring System for BOD Measurement and Toxicity Detection using Microbial Fuel Cells

 Microbial fuel cell enriched with electrochemically-active bacteria using sludge was successfully applied as BOD and toxicity detection biosensors. The current from the microbial fuel cells was proportional to concentration up to 200 mg/L of BOD5 with high linearity. A microbial fuel cell could be also applied to a toxicity detection biosensor. An electric current signal change was observed in the presence of toxic substances (singular/complex) such as cadmium, lead, chromium(VI), mercury, cyanide, arsenic, PCB, organophosphorus and surfactant. By combining the principles of BOD measurement and toxicity detection, a novel biomonitoring system that could simultaneously monitor BOD concentration and the presence of toxic substances in aqueous system could be developed.",M. Kim; H. S. Park; G. J. Jin; W. H. Cho; D. K. Lee; M. S. Hyun; C. H. Choi; H. J. Kim,,,A Novel Combined Biomonitoring System for BOD Measurement and Toxicity Detection using Microbial Fuel Cells,,,10.1109/ICSENS.2007.355855 ,IEEE Conferences ,,"Microbial fuel cell enriched with electrochemically-active bacteria using sludge was successfully applied as BOD and toxicity detection biosensors. The current from the microbial fuel cells was proportional to concentration up to 200 mg/L of BOD5 with high linearity. A microbial fuel cell could be also applied to a toxicity detection biosensor. An electric current signal change was observed in the presence of toxic substances (singular/complex) such as cadmium, lead, chromium(VI), mercury, cyanide, arsenic, PCB, organophosphorus and surfactant. By combining the principles of BOD measurement and toxicity detection, a novel biomonitoring system that could simultaneously monitor BOD concentration and the presence of toxic substances in aqueous system could be developed.",1930-0395,,1-4244-0375-8,1247-1248,IEEE , ,Board of Directors;Fuel cells;Biosensors;Microorganisms;Gas detectors;Wastewater;Temperature sensors;Sensor systems;Current;Signal analysis,,
4613,"Title:Experience, Results and Problems of Ecological Monitoring of Oil Containing Waste

 Experience and problems of ecological monitoring of oil products containing waste are considered. Methods of oily waste characteristic monitoring are discussed. Results of experimental researches by definition of degree of toxicity of the soils polluted by oil products by using of biological test-objects Chlorella vulgaris Beijer and Daphnia magna Straus are considered. Results of monitoring are proving high danger of toxicity pollution of soils by oily waste.",A. V. Vasilyev,,,"Experience, Results and Problems of Ecological Monitoring of Oil Containing Waste",,,10.1109/WASTE.2018.8554175 ,IEEE Conferences ,,Experience and problems of ecological monitoring of oil products containing waste are considered. Methods of oily waste characteristic monitoring are discussed. Results of experimental researches by definition of degree of toxicity of the soils polluted by oil products by using of biological test-objects Chlorella vulgaris Beijer and Daphnia magna Straus are considered. Results of monitoring are proving high danger of toxicity pollution of soils by oily waste.,,,978-1-5386-8314-9,82-85,IEEE , ,Monitoring;Oils;Estimation;Biology;Chemicals;Pollution;Soil,,
4614,"Title:Two-Dimensional Mixed Lead-Tin Halide Perovskites for Visble Light-Emitting Diodes

 Lead halide perovskites as a new generation of outstanding semiconductor materials have attracted considerable attention. The excellent optical properties and emission qualities makes this kind of materials suitable for light emitting diodes (LED). However, the toxicity of lead limits its large-scale industrial production. Here, we report the gradual reduction of lead content in two-dimensional perovskites by substituting lead with non-toxic tin for preparation of two-dimensional perovskites light-emitting diodes (PeLEDs) with different tin-lead ratios. Among these devices, the lead-free PeLEDs exhibits electroluminescence at 615 nm with peak luminance of 117 cd/m2 and maximum external quantum efficiency (EQE) of 0.18%.",J. Wang; J. Si; M. Lu; Z. Liu,,,Two-Dimensional Mixed Lead-Tin Halide Perovskites for Visble Light-Emitting Diodes,,,10.1109/ICOCN.2019.8934016 ,IEEE Conferences ,,"Lead halide perovskites as a new generation of outstanding semiconductor materials have attracted considerable attention. The excellent optical properties and emission qualities makes this kind of materials suitable for light emitting diodes (LED). However, the toxicity of lead limits its large-scale industrial production. Here, we report the gradual reduction of lead content in two-dimensional perovskites by substituting lead with non-toxic tin for preparation of two-dimensional perovskites light-emitting diodes (PeLEDs) with different tin-lead ratios. Among these devices, the lead-free PeLEDs exhibits electroluminescence at 615 nm with peak luminance of 117 cd/m2 and maximum external quantum efficiency (EQE) of 0.18%.",,,978-1-7281-2764-4,1-3,IEEE , ,Lead;Tin;Light emitting diodes;Solvents;Photoluminescence;Ions;Substrates,,
4615,"Title:Merged 1D-2D Deep Convolutional Neural Networks for Nerve Detection in Ultrasound Images

 Ultrasound-Guided Regional Anesthesia (UGRA) becomes a standard procedure in surgical operations and contributes to pain management. It offers the advantages of the targeted nerve detection and provides the visualization of regions of interest such as anatomical structures. However, nerve detection is one of the most challenging tasks that anesthetists can encounter in the UGRA procedure. A computer-aided system that can detect automatically the nerve region would facilitate the anesthetist's daily routine and allow them to concentrate more on the anesthetic delivery. In this paper, we propose a new method based on merging deep learning models from different data to detect the median nerve. The merged architecture consists of two branches, one being one-dimensional (1D) convolutional neural networks (CNN) branch and another 2D CNN branch. The merged architecture aims to learn the high-level features from 1D handcrafted noise-robust features and 2D ultrasound images. The obtained results show the validity and high accuracy of the proposed approach and its robustness.",M. Alkhatib; A. Hafiane; P. Vieyres,,,Merged 1D-2D Deep Convolutional Neural Networks for Nerve Detection in Ultrasound Images,,,10.1109/ICPR48806.2021.9412988 ,IEEE Conferences ,,"Ultrasound-Guided Regional Anesthesia (UGRA) becomes a standard procedure in surgical operations and contributes to pain management. It offers the advantages of the targeted nerve detection and provides the visualization of regions of interest such as anatomical structures. However, nerve detection is one of the most challenging tasks that anesthetists can encounter in the UGRA procedure. A computer-aided system that can detect automatically the nerve region would facilitate the anesthetist's daily routine and allow them to concentrate more on the anesthetic delivery. In this paper, we propose a new method based on merging deep learning models from different data to detect the median nerve. The merged architecture consists of two branches, one being one-dimensional (1D) convolutional neural networks (CNN) branch and another 2D CNN branch. The merged architecture aims to learn the high-level features from 1D handcrafted noise-robust features and 2D ultrasound images. The obtained results show the validity and high accuracy of the proposed approach and its robustness.",1051-4651,,978-1-7281-8808-9,4774-4780,IEEE , ,Visualization;Ultrasonic imaging;Merging;Surgery;Computer architecture;Anesthesia;Robustness,,
4616,"Title:Toxicity and safety aspects of nanoparticle spread in third generation photovoltaic device processing environments

 Detection strategies for analysis of the nanomaterials toxicity, although challenging, will be in much demand as nanotechnology becomes more common-place in third generation photovoltaics (PV). Experimentally feasible approaches must be designed and engineered to detect quantum dots (QDs) and nanoparticles (NPs) in PV device processing environment. Identifying the level of risk to human body upon exposure to nanomaterials is another important factor that needs consideration. In this work evidence on the detection of aerosolized nanoparticles was experimentally verified using gold NP adsorbent, followed by spectroscopic measurements. Results from in-vitro cytotoxicity study with HeLa cell cultures and fluorescent plate reading also showed that core/shell CdSe/ZnS QDs are responsible for cell death following exposure.",B. Sadeghimakki; Yaxin Zheng; N. M. S. Jahed; P. H. Pham; A. Babujee; N. C. Bols; S. Sivoththaman,,,Toxicity and safety aspects of nanoparticle spread in third generation photovoltaic device processing environments,,,10.1109/PVSC.2015.7356390 ,IEEE Conferences ,,"Detection strategies for analysis of the nanomaterials toxicity, although challenging, will be in much demand as nanotechnology becomes more common-place in third generation photovoltaics (PV). Experimentally feasible approaches must be designed and engineered to detect quantum dots (QDs) and nanoparticles (NPs) in PV device processing environment. Identifying the level of risk to human body upon exposure to nanomaterials is another important factor that needs consideration. In this work evidence on the detection of aerosolized nanoparticles was experimentally verified using gold NP adsorbent, followed by spectroscopic measurements. Results from in-vitro cytotoxicity study with HeLa cell cultures and fluorescent plate reading also showed that core/shell CdSe/ZnS QDs are responsible for cell death following exposure.",,,978-1-4799-7944-8,1-6,IEEE , ,Gold;Quantum dots;Fluorescence;Indexes;Nanoparticles;Semiconductor device measurement;Silicon compounds,,
4617,"Title:Automated detection of toxicity in the blood samples of dye factory workers

 Textile processing units largely employ azo dyes which are derivatives of benzene. Toxic sewage discharged from textile industries contains azo dyes. They affect soil fertility, water resources, marine organisms and the ecosystem. Benzedine is responsible for skin irritation and also increases the toxicity in blood and bone marrow which affects the production of blood cells and hence leads to anemia. Exposure to these benzedine dyes can induce hemolytic anemia which leads to deformation of Red Blood Cells (RBCs). In this work, an automated detection of toxicity is proposed to alert the workers prior to the critical stages of cancer. The proposed system consists of a portable unit where the blood samples are analyzed and the toxic status of the dye factory workers can be transmitted from the local health centre to the nearby hospital. Microscopic images of the smeared blood samples are acquired using the digital microscope. These RBC images of normal and abnormal are segmented using Laplacian of Gaussian (LoG) segmentation. Geometric shape based features are extracted from the segmented images. Significant geometric features are chosen by conducting student's `t' test. It is observed from the results that these significant geometric features show discrimination between the normal and abnormal RBCs. This early detection of toxicity can help workers in the site to take immediate medication which could reduce the probability of adversity in their health condition.",E. Priya; A. Kumaran,,,Automated detection of toxicity in the blood samples of dye factory workers,,,10.1109/ICCCT2.2015.7292771 ,IEEE Conferences ,,"Textile processing units largely employ azo dyes which are derivatives of benzene. Toxic sewage discharged from textile industries contains azo dyes. They affect soil fertility, water resources, marine organisms and the ecosystem. Benzedine is responsible for skin irritation and also increases the toxicity in blood and bone marrow which affects the production of blood cells and hence leads to anemia. Exposure to these benzedine dyes can induce hemolytic anemia which leads to deformation of Red Blood Cells (RBCs). In this work, an automated detection of toxicity is proposed to alert the workers prior to the critical stages of cancer. The proposed system consists of a portable unit where the blood samples are analyzed and the toxic status of the dye factory workers can be transmitted from the local health centre to the nearby hospital. Microscopic images of the smeared blood samples are acquired using the digital microscope. These RBC images of normal and abnormal are segmented using Laplacian of Gaussian (LoG) segmentation. Geometric shape based features are extracted from the segmented images. Significant geometric features are chosen by conducting student's `t' test. It is observed from the results that these significant geometric features show discrimination between the normal and abnormal RBCs. This early detection of toxicity can help workers in the site to take immediate medication which could reduce the probability of adversity in their health condition.",,,978-1-4799-7623-2,334-337,IEEE , ,Image segmentation;Blood;Shape;Feature extraction;Cancer;Microscopy;Textiles,,
4618,"Title:A Novel Edge Effect Detection Method for Real-Time Cellular Analyzer Using Functional Principal Component Analysis

 Real-time cellular analyzer (RTCA) has been generally applied to test the cytotoxicity of chemicals. However, several factors impact the experimental quality. A non-negligible factor is the abnormal time-dependent cellular response curves (TCRCs) of the wells located at the edge of the E-plate which is defined as edge effect. In this paper, a novel statistical analysis is proposed to detect the edge effect. First, TCRCs are considered as observations of a random variable in a functional space. Then, functional principal component analysis (FPCA) is adopted to extract the principal component (PC) functions of the TCRCs, and the first and second PCs of these curves are selected to distinguish abnormal TCRCs. The average TCRC of the inner wells with the same culture environment is set as the standard. If the distance between the scoring point of the standard curve and one designated scoring point exceeds the defined threshold, the corresponding TCRC of the designated point should be removed automatically. The experimental results demonstrate the effectiveness of the proposed algorithm. This method can be used as a standard method to resolve general time-dependent series issues.",Q. Guo; T. Pan; S. Chen; X. Zou; D. Y. Huang,,,A Novel Edge Effect Detection Method for Real-Time Cellular Analyzer Using Functional Principal Component Analysis,17,5,10.1109/TCBB.2019.2903094 ,IEEE Journals ,,"Real-time cellular analyzer (RTCA) has been generally applied to test the cytotoxicity of chemicals. However, several factors impact the experimental quality. A non-negligible factor is the abnormal time-dependent cellular response curves (TCRCs) of the wells located at the edge of the E-plate which is defined as edge effect. In this paper, a novel statistical analysis is proposed to detect the edge effect. First, TCRCs are considered as observations of a random variable in a functional space. Then, functional principal component analysis (FPCA) is adopted to extract the principal component (PC) functions of the TCRCs, and the first and second PCs of these curves are selected to distinguish abnormal TCRCs. The average TCRC of the inner wells with the same culture environment is set as the standard. If the distance between the scoring point of the standard curve and one designated scoring point exceeds the defined threshold, the corresponding TCRC of the designated point should be removed automatically. The experimental results demonstrate the effectiveness of the proposed algorithm. This method can be used as a standard method to resolve general time-dependent series issues.",1557-9964,,,1563-1572,IEEE , ,Image edge detection;Chemicals;Testing;Principal component analysis;Standards;Real-time systems;Indexes,,
4619,"Title:A new classifier applied to biological early warning systems for toxicity detection

 Biological early warning systems(BEWS) has been developed in recent years. BEWS detects toxicity by tracking the physiologic responses of the whole organisms. In the paper, we apply the classification technique to the biological early warning systems and propose a new BEWS which is meaningful to biological field. Meanwhile, how to select the features in such classification application is also a contribution of this paper. By using the fractal dimension theory, we define the input features which represent the organism characteristics in non-toxic or toxic environment. The experiment results show that the proposed new bio-monitoring system is effective for environmental toxicity detection.",Yingrong Li; Dong-Hun Seo; Won Don Lee,,,A new classifier applied to biological early warning systems for toxicity detection,,,10.1109/ICADIWT.2008.4664373 ,IEEE Conferences ,,"Biological early warning systems(BEWS) has been developed in recent years. BEWS detects toxicity by tracking the physiologic responses of the whole organisms. In the paper, we apply the classification technique to the biological early warning systems and propose a new BEWS which is meaningful to biological field. Meanwhile, how to select the features in such classification application is also a contribution of this paper. By using the fractal dimension theory, we define the input features which represent the organism characteristics in non-toxic or toxic environment. The experiment results show that the proposed new bio-monitoring system is effective for environmental toxicity detection.",,,978-1-4244-2623-2,360-365,IEEE , ,,,
4620,"Title:Data Converter Device in Detecting Water Toxicity for Poultry Industry

 Philippines Statistics Authorities said that the Philippine broiler industry comprises 20% small farms (fewer than 1,000 birds) and 80% commercial farms. There are reportedly 588 registered poultry farms and approximately 175 meat processors throughout the country. Water should be free from any diseases that can affect the health of poultry. The United Nations pointed out that water is necessary, and a sufficient supply (adequate, secure, and accessible) must be available to everyone. Since then, the Philippine poultry industry is continuously growing, but the water management system is not improving, so the farmers encountered the same problem for their broilers. One of the best applications to prevent the problem in water management is through the laboratory that takes time to get the results about the toxicities of water. Because there are no existing devices or machines identifying the toxicity of water for the broiler industry. Therefore, a device was created to deploy it to the poultry farms toward their water supply, particularly the broiler animals' water intake. It detects water toxicity utilizing four (4) features, including pH Level for water detection in terms of alkalinity or acidity, total dissolved solids for all organic and inorganic substances, etc. Experimental results show its reliability through multiple testing of the poultry farm water comparing it to the expensive and manual laboratory tests. The water toxicity detection device followed the standards and procedures to determine its 95 percent accuracy.",M. Rosales; J. Berasis; S. K. Dancel; A. Sahagun; J. Tacardon; A. Villanueva,,,Data Converter Device in Detecting Water Toxicity for Poultry Industry,,,10.1109/ISDFS58141.2023.10131744 ,IEEE Conferences ,,"Philippines Statistics Authorities said that the Philippine broiler industry comprises 20% small farms (fewer than 1,000 birds) and 80% commercial farms. There are reportedly 588 registered poultry farms and approximately 175 meat processors throughout the country. Water should be free from any diseases that can affect the health of poultry. The United Nations pointed out that water is necessary, and a sufficient supply (adequate, secure, and accessible) must be available to everyone. Since then, the Philippine poultry industry is continuously growing, but the water management system is not improving, so the farmers encountered the same problem for their broilers. One of the best applications to prevent the problem in water management is through the laboratory that takes time to get the results about the toxicities of water. Because there are no existing devices or machines identifying the toxicity of water for the broiler industry. Therefore, a device was created to deploy it to the poultry farms toward their water supply, particularly the broiler animals' water intake. It detects water toxicity utilizing four (4) features, including pH Level for water detection in terms of alkalinity or acidity, total dissolved solids for all organic and inorganic substances, etc. Experimental results show its reliability through multiple testing of the poultry farm water comparing it to the expensive and manual laboratory tests. The water toxicity detection device followed the standards and procedures to determine its 95 percent accuracy.",,,979-8-3503-3698-6,1-6,IEEE , ,Industries;Toxicology;Program processors;Manuals;Solids;Reliability;Security,,
4621,"Title:Au Deposited Carbon-thread Electrode for Lead ions Detection in Water Samples

 The metabolic processes of human body are significantly impacted by lead contamination in drinking water. In this context, this work presents an electrochemical detection method to monitor lead in water samples by employing gold nanoparticles (AuNPs) on the carbon thread surface. After studying the morphology of this optimized surface, the electro-catalytic activity of the metal ion on the Au-modified thread surface was observed using the differential pulse voltammetry (DPV) technique. The impact of the lead concentration was studied in a linear range of 10 to 100 $\mu M$, and a detection limit of 1.57 $\mu M$ was observed. Further, the effect of pH and effect of interference was examined. Real sample analysis was carried out utilizing a lake water sample to comprehend the applicability of the sensor, and this resulted in a good recovery rate. This work lays the foundation for the on-field applicability of the present heavy metal detection platform.",S. A. Lahari; K. Amreen; S. K. Dubey; P. Rn; S. Goel,,,Au Deposited Carbon-thread Electrode for Lead ions Detection in Water Samples,,,10.1109/APSCON56343.2023.10101283 ,IEEE Conferences ,,"The metabolic processes of human body are significantly impacted by lead contamination in drinking water. In this context, this work presents an electrochemical detection method to monitor lead in water samples by employing gold nanoparticles (AuNPs) on the carbon thread surface. After studying the morphology of this optimized surface, the electro-catalytic activity of the metal ion on the Au-modified thread surface was observed using the differential pulse voltammetry (DPV) technique. The impact of the lead concentration was studied in a linear range of 10 to 100 $\mu M$, and a detection limit of 1.57 $\mu M$ was observed. Further, the effect of pH and effect of interference was examined. Real sample analysis was carried out utilizing a lake water sample to comprehend the applicability of the sensor, and this resulted in a good recovery rate. This work lays the foundation for the on-field applicability of the present heavy metal detection platform.",,,978-1-6654-6163-4,1-3,IEEE , ,Nanoparticles;Gold;Surface contamination;Surface morphology;Lead;Ions;Water pollution,,
4622,"Title:Detection of Digitalis Toxicity by Computerized Electrocardiogram Monitoring

 A new ECG monitoring technique is described which can detect the condition of digitalis toxicity prior to the onset of arrhythmias. The technique is based on experiments with mice in which digitalis toxicity was induced by the administration of the cardiac glycoside, ouabain. Results are shown in which spreading of the QRS complex is a consistent precursor of premature ventricular contractions and ventricular fibrillation. Both high and low dose studies are described.",A. J. Berni; D. E. Dick; M. W. Luttges,,,Detection of Digitalis Toxicity by Computerized Electrocardiogram Monitoring,BME-22,1,10.1109/TBME.1975.324536 ,IEEE Journals ,,"A new ECG monitoring technique is described which can detect the condition of digitalis toxicity prior to the onset of arrhythmias. The technique is based on experiments with mice in which digitalis toxicity was induced by the administration of the cardiac glycoside, ouabain. Results are shown in which spreading of the QRS complex is a consistent precursor of premature ventricular contractions and ventricular fibrillation. Both high and low dose studies are described.",1558-2531,,,29-34,IEEE , ,Computerized monitoring;Electrocardiography;Drugs;Mice;Condition monitoring;Distortion measurement;Rhythm;Biomedical monitoring;Heart rate variability;Fibrillation,,
4623,"Title:A Novel Approach to Toxic Gas Detection using an IoT Device and Deep Neural Networks

 Smoking remains one of the top 3 causes of illness in the US, one of top 5 causes of fire hazards in a home and is the single most preventable cause of illness and premature death in the US. The use of Deep Neural Networks in tandem with advances in the sensitivity of gas sensor technology can enable detection of cigarette/Vape smoke much sooner and with much higher accuracy than conventional smoke/carbon monoxide detectors used today. We report a hardware demonstration and prototype that engages Classifiers to not only discriminate cigarette/vape emissions from other sources of smoke and carbon monoxide such as burning coal, wood or food - typically not possible with conventional smoke detectors, but also to accurately detect cigarette/vape smoke produced in a large space (7K ft3) from a single cigarette when concentrations of component gases of cigarette smoke are extremely low. Our prototype also demonstrates the opportunity to classify and discriminate different levels of toxicity and flammability for spaces used by different people enabling AI based sensing at scale where besides accuracy and speed, the utility of larges sets of sensor nodes are critical to enabling cost advantages over conventional detector technology.",I. Bhavnagarwala; A. Bhavnagarwala,,,A Novel Approach to Toxic Gas Detection using an IoT Device and Deep Neural Networks,,,10.1109/URTC51696.2020.9668871 ,IEEE Conferences ,,"Smoking remains one of the top 3 causes of illness in the US, one of top 5 causes of fire hazards in a home and is the single most preventable cause of illness and premature death in the US. The use of Deep Neural Networks in tandem with advances in the sensitivity of gas sensor technology can enable detection of cigarette/Vape smoke much sooner and with much higher accuracy than conventional smoke/carbon monoxide detectors used today. We report a hardware demonstration and prototype that engages Classifiers to not only discriminate cigarette/vape emissions from other sources of smoke and carbon monoxide such as burning coal, wood or food - typically not possible with conventional smoke detectors, but also to accurately detect cigarette/vape smoke produced in a large space (7K ft3) from a single cigarette when concentrations of component gases of cigarette smoke are extremely low. Our prototype also demonstrates the opportunity to classify and discriminate different levels of toxicity and flammability for spaces used by different people enabling AI based sensing at scale where besides accuracy and speed, the utility of larges sets of sensor nodes are critical to enabling cost advantages over conventional detector technology.",,,978-1-7281-7571-3,1-4,IEEE , ,Deep learning;Gases;Toxicology;Sensitivity;Neural networks;Prototypes;Detectors,,
4624,"Title:NLP Based Hate Speech Detection And Moderation

 As Social media penetration increases in day-to-day life so does the growth of hate speech. After 2016 due to affordability of internet many user on boarded the internet which not only increased social media interactions but also growth of hate speech. be it religion phobia, homophobia, gender, toxicity etc. To control hate speech, NLP based machine learning model has been proposed. The proposed model uses TFIDF feature generation method to which binarized naive bayes is applied to calculate maximum likelihood feature for each labels. Model has been trained with logistic regression on the maximum likelihood feature. which helps to classify hate speech and moderate accordingly. The proposed model produces an overall accuracy of 83 percent and able to achieve 5 percent improvement compared to multinomial naive bayes' production in identifying hate speech and classifying it under various labels.",R. K. Singh; S. H A; P. J. S A; H. Rishi; S. Bhardwaj,,,NLP Based Hate Speech Detection And Moderation,,,10.1109/CSITSS60515.2023.10333320 ,IEEE Conferences ,,"As Social media penetration increases in day-to-day life so does the growth of hate speech. After 2016 due to affordability of internet many user on boarded the internet which not only increased social media interactions but also growth of hate speech. be it religion phobia, homophobia, gender, toxicity etc. To control hate speech, NLP based machine learning model has been proposed. The proposed model uses TFIDF feature generation method to which binarized naive bayes is applied to calculate maximum likelihood feature for each labels. Model has been trained with logistic regression on the maximum likelihood feature. which helps to classify hate speech and moderate accordingly. The proposed model produces an overall accuracy of 83 percent and able to achieve 5 percent improvement compared to multinomial naive bayes' production in identifying hate speech and classifying it under various labels.",,,979-8-3503-4314-4,1-5,IEEE , ,Maximum likelihood detection;Logistic regression;Toxicology;Social networking (online);Computational modeling;Hate speech;Production,,
4625,"Title:Private Messaging Service using AES Encryption and Toxicity Detection

 With the advancement of digital technology in recent decades, the style of communication and use of digital accessories in our daily lives has changed dramatically. It is undeniable that the introduction of the mobile phone/smart phone has improved our standard of living and made life easier. A private messenger is an application that enables for encrypted communication. To provide safe data transmission between the sender and recipient, a protected private instant messenger is required. The messenger gives main emphasis on textual value by checking the text toxicity using a ML model in a novel way by not storing meta data of user atany juncture without compromising the quality of messaging service which is not present in main stream messaging application. The architecture of private messengers is presented in this work. The proposed architecture was created and tested on a private messaging application, and the findings show that it can increase data security for messenger applications.",S. P. R; T. M; R. Berg D; S. Kannan M,,,Private Messaging Service using AES Encryption and Toxicity Detection,,,10.1109/ICESIC53714.2022.9783567 ,IEEE Conferences ,,"With the advancement of digital technology in recent decades, the style of communication and use of digital accessories in our daily lives has changed dramatically. It is undeniable that the introduction of the mobile phone/smart phone has improved our standard of living and made life easier. A private messenger is an application that enables for encrypted communication. To provide safe data transmission between the sender and recipient, a protected private instant messenger is required. The messenger gives main emphasis on textual value by checking the text toxicity using a ML model in a novel way by not storing meta data of user atany juncture without compromising the quality of messaging service which is not present in main stream messaging application. The architecture of private messengers is presented in this work. The proposed architecture was created and tested on a private messaging application, and the findings show that it can increase data security for messenger applications.",,,978-1-6654-8385-8,173-178,IEEE , ,Privacy;Toxicology;Computational modeling;Surveillance;Computer architecture;Metadata;Message service,,
4626,"Title:Water toxicity detection using cell-based hybrid biosensors

 This paper presents a novel cell-based biosensor device that contains a quartz crystal microbalance (QCM), integrated with the electric cell-substrate impedance sensing (ECIS) technique. Bovine aortic endothelial cells (BAECs) are cultivated on the sensors and monitored in parallel by both sensors. When two different sensors monitors the same BAECs monolayer cultures on these sensors the information provided by these sensors is more accurate. Cell culturing microwells were fabricated and glued on this biosensor device for minimizing media and reagent demands and potential automation. The microwells were designed in a manner that can eliminate the fluid shear stress and allow laminar flow for the media and other fluids introduced in the cell-culturing chamber during testing. We demonstrated that BAECS cells could be cultured in these microwells. Resonant frequency and impedance spectroscopy measurements were performed during a time interval. It was demonstrated that this cell-based sensor could be used for toxicity experiments.",F. Liu; I. Voiculescu; A. N. Nordin; F. Li,,,Water toxicity detection using cell-based hybrid biosensors,,,10.1109/ICSENS.2013.6688374 ,IEEE Conferences ,,"This paper presents a novel cell-based biosensor device that contains a quartz crystal microbalance (QCM), integrated with the electric cell-substrate impedance sensing (ECIS) technique. Bovine aortic endothelial cells (BAECs) are cultivated on the sensors and monitored in parallel by both sensors. When two different sensors monitors the same BAECs monolayer cultures on these sensors the information provided by these sensors is more accurate. Cell culturing microwells were fabricated and glued on this biosensor device for minimizing media and reagent demands and potential automation. The microwells were designed in a manner that can eliminate the fluid shear stress and allow laminar flow for the media and other fluids introduced in the cell-culturing chamber during testing. We demonstrated that BAECS cells could be cultured in these microwells. Resonant frequency and impedance spectroscopy measurements were performed during a time interval. It was demonstrated that this cell-based sensor could be used for toxicity experiments.",1930-0395,,978-1-4673-4642-9,1-5,IEEE , ,Electrodes;Biosensors;Impedance;Resonant frequency;Cells (biology);Impedance measurement,,
4627,"Title:Chemical Agent Detection Using GC-IMS: A Comparative Study

 Low-cost and portable gas chromatography-ion mobility spectrometry (GC-IMS) has been used to identify chemicals. To accomplish this, two parameters are used. The first parameter relates to the GC retention time (RT), which is the residence time of an analyte as it passes through the column. Different chemicals have different RTs. The second parameter is the drift time of ionized species derived for a specific chemical in the IMS. Due to molecular cross section, mass, and chemical properties, different chemicals produce ionized species with different drift times. Combining these two parameters, GC-IMS has been shown to distinguish between different chemicals. Chemical detection and identification are not that easy in practice. First, the concentration of chemicals may be very low, and it may be difficult to determine the chromatographic RT and IMS drift time for chemicals under these conditions. Second, the specific ionized species produced in the IMS are concentration dependent and the IMS spectra obtained at different analyte concentrations are not easily predictable. For example, at low concentrations, chemicals seldom form dimers following atmospheric pressure ionization. The possible presence of either monomers or dimers in the IMS drift tube may confuse the chemical classification process. Third, it is important to estimate the concentration of chemicals, as this information will provide toxicity, and the linear dynamic range of typical IMS systems is relatively low In this study, an image processing approach to enhancing the GC-IMS signal quality is introduced. The key idea in this approach is to treat GC-IMS data as an image and then apply an anomaly detector to detect and enhance abnormal regions in the image. The results of a study that compares a conventional approach to chemical detection and the introduced image enhancement approach are presented. Receiver operating characteristics curves were used to compare the detection performances of the two approaches.",C. Kwan; A. P. Snyder; R. P. Erickson; P. A. Smith; W. M. Maswadeh; B. Ayhan; J. L. Jensen; J. O. Jensen; A. Tripathi,,,Chemical Agent Detection Using GC-IMS: A Comparative Study,10,3,10.1109/JSEN.2009.2038128 ,IEEE Journals ,,"Low-cost and portable gas chromatography-ion mobility spectrometry (GC-IMS) has been used to identify chemicals. To accomplish this, two parameters are used. The first parameter relates to the GC retention time (RT), which is the residence time of an analyte as it passes through the column. Different chemicals have different RTs. The second parameter is the drift time of ionized species derived for a specific chemical in the IMS. Due to molecular cross section, mass, and chemical properties, different chemicals produce ionized species with different drift times. Combining these two parameters, GC-IMS has been shown to distinguish between different chemicals. Chemical detection and identification are not that easy in practice. First, the concentration of chemicals may be very low, and it may be difficult to determine the chromatographic RT and IMS drift time for chemicals under these conditions. Second, the specific ionized species produced in the IMS are concentration dependent and the IMS spectra obtained at different analyte concentrations are not easily predictable. For example, at low concentrations, chemicals seldom form dimers following atmospheric pressure ionization. The possible presence of either monomers or dimers in the IMS drift tube may confuse the chemical classification process. Third, it is important to estimate the concentration of chemicals, as this information will provide toxicity, and the linear dynamic range of typical IMS systems is relatively low In this study, an image processing approach to enhancing the GC-IMS signal quality is introduced. The key idea in this approach is to treat GC-IMS data as an image and then apply an anomaly detector to detect and enhance abnormal regions in the image. The results of a study that compares a conventional approach to chemical detection and the introduced image enhancement approach are presented. Receiver operating characteristics curves were used to compare the detection performances of the two approaches.",1558-1748,,,451-460,IEEE , ,Spectroscopy;Biomedical engineering;Engineering in medicine and biology;Image edge detection;Chemical processes;Image processing;Underwater vehicles;Biomedical imaging;Ionization;Toxic chemicals,,
4628,"Title:Whole-cell MEMS biosensors for toxicity detection

 At the heart of every biosensor is a biological entity, the purpose of which is to react with the target analyte(s) and generate a readily quantifiable signal. Traditional biosensors are based on the unique specificity of enzymes to their substrates, antibodies to antigens or that of nucleic acids to their complementary sequences. In recent years we have promoted the use of a different concept, that of whole cell biosensors. An intact live cell, containing a selected gene promoter fused to a reporter gene, serves both as the sensing and the reporting element; the specificity of the system is controlled by the choice of promoter. Using this approach we have constructed microbial sensing systems for the environmental detection of toxicants, genotoxicants, oxidants, and specific groups of halogenated organics, as well as cyanobacterial sensors of nutrients bioavailability. In order to turn these cells into a ""real"" biosensors, they need to be immobilized onto a solid platform and coupled into the signal transduction apparatus. Several directions that were pursued to achieve this aim will be mentioned including agar immobilization onto microtiter plates, alginate encapsulation at the tips of optic fibers, antibody-mediated adhesion to glass surfaces, embedding into sol-gel matrices and, most recently, integration into specialized biochip. The latter option will be described in detail.",S. Belkin,,,Whole-cell MEMS biosensors for toxicity detection,,,10.1109/BMN.2003.1220596 ,IEEE Conferences ,,"At the heart of every biosensor is a biological entity, the purpose of which is to react with the target analyte(s) and generate a readily quantifiable signal. Traditional biosensors are based on the unique specificity of enzymes to their substrates, antibodies to antigens or that of nucleic acids to their complementary sequences. In recent years we have promoted the use of a different concept, that of whole cell biosensors. An intact live cell, containing a selected gene promoter fused to a reporter gene, serves both as the sensing and the reporting element; the specificity of the system is controlled by the choice of promoter. Using this approach we have constructed microbial sensing systems for the environmental detection of toxicants, genotoxicants, oxidants, and specific groups of halogenated organics, as well as cyanobacterial sensors of nutrients bioavailability. In order to turn these cells into a ""real"" biosensors, they need to be immobilized onto a solid platform and coupled into the signal transduction apparatus. Several directions that were pursued to achieve this aim will be mentioned including agar immobilization onto microtiter plates, alginate encapsulation at the tips of optic fibers, antibody-mediated adhesion to glass surfaces, embedding into sol-gel matrices and, most recently, integration into specialized biochip. The latter option will be described in detail.",,,1-55581-279-3,,IEEE , ,Micromechanical devices;Biosensors;Heart;Signal analysis;Signal generators;Biochemistry;Control systems;Sensor systems;Solids;Encapsulation,,
4629,"Title:Detection of Dimethoate Pesticide using Layer by Layer Deposition of PDAC/GO on Ag electrode

 Dimethoate (DMT) is an organophosphate pesticide (OP), which is widely used against insects and mites and their control in agriculture. As other OPs, DMT is also an inhibitor of acetylcholinesterase, which is responsible for the disabling of cholinesterase required for the functioning of the central nervous system. This pesticide can invade living cells of the human body through contact or ingestion. We report an electrochemical sensor based on a layer by layer deposition of PDAC/GO on silver electrodes. The sensor fabrication, physical characterization i.e. Raman spectroscopy and scanning electron microscopy of PDAC/GO based films, and its electrochemical characterization are discussed. The detection of DMT by analyzing electrochemical measurements including cyclic voltammetry and impedance spectroscopy shows that functionalization using layer by layer deposition improves electrochemical response and presents a basis for detection of DMT. The highest response is observed in the case of only one PDAC/GO layer which is attributed to the properly balanced interaction between DMT and PDAC/GO layer, and the increase of electrical resistivity of the PDAC/GO layer with its thickness.",T. K. Ega; A. Al-Hamry; O. Kanoun; T. Lazarevic-Pašti; D. B. Bogdanović; I. A. Pašti; R. D. Rodriguez; E. Sheremet; L. G. Paterno,,,Detection of Dimethoate Pesticide using Layer by Layer Deposition of PDAC/GO on Ag electrode,,,10.1109/SSD.2019.8893253 ,IEEE Conferences ,,"Dimethoate (DMT) is an organophosphate pesticide (OP), which is widely used against insects and mites and their control in agriculture. As other OPs, DMT is also an inhibitor of acetylcholinesterase, which is responsible for the disabling of cholinesterase required for the functioning of the central nervous system. This pesticide can invade living cells of the human body through contact or ingestion. We report an electrochemical sensor based on a layer by layer deposition of PDAC/GO on silver electrodes. The sensor fabrication, physical characterization i.e. Raman spectroscopy and scanning electron microscopy of PDAC/GO based films, and its electrochemical characterization are discussed. The detection of DMT by analyzing electrochemical measurements including cyclic voltammetry and impedance spectroscopy shows that functionalization using layer by layer deposition improves electrochemical response and presents a basis for detection of DMT. The highest response is observed in the case of only one PDAC/GO layer which is attributed to the properly balanced interaction between DMT and PDAC/GO layer, and the increase of electrical resistivity of the PDAC/GO layer with its thickness.",2474-0446,,978-1-7281-1820-8,621-625,IEEE , ,Electrodes;Silver;Graphene;Electric potential;Oxidation;Scanning electron microscopy;Insects,,
4630,"Title:Automated Chicken Manure Toxicity Level Reducer System Using Optimized Effective Microorganism (EM) Solution

 Poultry industry has been always a part of the Philippines' agricultural sector being one of the top contributors in revenues in livestock. However, poultry farms oftentimes emit odors coming from chicken manure that can cause harmful effects to local residents and the chicken themselves. One solution to remedy this is the usage of effective microorganism (EM). EM is a low-cost, non-harmful, non-pathogenic, non-genetically modified solution commonly used for waste treatment. In this study, the researchers developed a system that automatically detects toxicity levels of gases and reduces it, together with the foul odor, using automatic spraying of activated EM solution. Spray schedule is also optimized using data analytics techniques. Results show satisfactory results reducing toxicity levels constantly on poultry houses where the system is implemented.",N. M. Arago; T. P. Garcia; T. M. Amado,,,Automated Chicken Manure Toxicity Level Reducer System Using Optimized Effective Microorganism (EM) Solution,,,10.1109/TENCON.2018.8650489 ,IEEE Conferences ,,"Poultry industry has been always a part of the Philippines' agricultural sector being one of the top contributors in revenues in livestock. However, poultry farms oftentimes emit odors coming from chicken manure that can cause harmful effects to local residents and the chicken themselves. One solution to remedy this is the usage of effective microorganism (EM). EM is a low-cost, non-harmful, non-pathogenic, non-genetically modified solution commonly used for waste treatment. In this study, the researchers developed a system that automatically detects toxicity levels of gases and reduces it, together with the foul odor, using automatic spraying of activated EM solution. Spray schedule is also optimized using data analytics techniques. Results show satisfactory results reducing toxicity levels constantly on poultry houses where the system is implemented.",2159-3450,,978-1-5386-5457-6,1403-1407,IEEE , ,Spraying;Gases;Schedules;Microorganisms;Optimization;Gas detectors;Data analysis,,
4631,"Title:Formalin on Fresh Tilapia Via Electronic Nose and Assessment of Toxicity Levels with Reference to Average Adult Filipino Weight

 Fish is essentially one of the best sources of protein, economically and nutritional-wise, making it one of the favorites of Filipinos in their everyday meals. However, fishes are also easily perishable, especially when it gets stuck in traffic, further increasing the rate of decomposition of the fish as it is transported from the fish port to the local markets across the nation. There are several methods of preservation like icing, but there are also widespread reports regarding the adulteration of Formalin to the fish not only during transport but also its use in the wet markets nationwide to keep fish and other perishable products fresh. Formalin is used to increase the shelf life of fish to a certain extent, but its use provides a health risk to the consumer because it is a known carcinogenic chemical compound and can be toxic when consumed even on a very small amount approximately 0.00002% of the consumers weight. This paper is a study that used an electronic nose system in the detection of formalin specifically on fish samples. The samples were dipped in a formalin solution in different concentrations and controlled in an iced and non-iced (room temperature) environment. The data gathered from the samples were processed and were analyzed using principal component analysis using singular value decomposition in MATLAB. The total variance produced in the PCA plot is 95.15% using 3 principal components. Overall, the total accuracy of the system in correctly detecting formalin on Tilapia is 85.71%. Toxicity assessment of the theoretical formalin content of tilapia also shows that the tilapia adulterated with formalin at small portions, exceeded the toxicity threshold value for average adult Filipinos.",J. C. Dela Cruz; R. G. Garcia; A. N. M. Collado; R. J. S. Jovero; R. V. Macalangcom; R. C. Tud,,,Formalin on Fresh Tilapia Via Electronic Nose and Assessment of Toxicity Levels with Reference to Average Adult Filipino Weight,,,10.1109/HNICEM48295.2019.9072914 ,IEEE Conferences ,,"Fish is essentially one of the best sources of protein, economically and nutritional-wise, making it one of the favorites of Filipinos in their everyday meals. However, fishes are also easily perishable, especially when it gets stuck in traffic, further increasing the rate of decomposition of the fish as it is transported from the fish port to the local markets across the nation. There are several methods of preservation like icing, but there are also widespread reports regarding the adulteration of Formalin to the fish not only during transport but also its use in the wet markets nationwide to keep fish and other perishable products fresh. Formalin is used to increase the shelf life of fish to a certain extent, but its use provides a health risk to the consumer because it is a known carcinogenic chemical compound and can be toxic when consumed even on a very small amount approximately 0.00002% of the consumers weight. This paper is a study that used an electronic nose system in the detection of formalin specifically on fish samples. The samples were dipped in a formalin solution in different concentrations and controlled in an iced and non-iced (room temperature) environment. The data gathered from the samples were processed and were analyzed using principal component analysis using singular value decomposition in MATLAB. The total variance produced in the PCA plot is 95.15% using 3 principal components. Overall, the total accuracy of the system in correctly detecting formalin on Tilapia is 85.71%. Toxicity assessment of the theoretical formalin content of tilapia also shows that the tilapia adulterated with formalin at small portions, exceeded the toxicity threshold value for average adult Filipinos.",,,978-1-7281-3044-6,1-6,IEEE , ,Marine animals;Principal component analysis;Electronic noses;Sensor arrays;Graphical user interfaces;Pins,,
4632,"Title:Visual-Based Contact Detection for Automated Zebrafish Larva Heart Microinjection

 This article presents an automated strategy to touch the injection site on zebrafish larva skin with the injection pipette tip accurately in the presence of water-depth variation, which is a crucial problem to automate zebrafish larva microinjection. The presented method consists of two parts: adaptive coordinate transformation and curve evolution for edge detection. In the first part, the impact of refraction is taken into consideration. An adaptive calibration method is developed, which enables the coordinate transformation matrix to adapt to the changing water depth. In the second part, the abovementioned calibration result is used to keep the injection pipette tip descending along the desired route. A curve-evolution-based edge detection algorithm is introduced to detect the deformation of larva skin caused by contact with the injection pipette tip. Experimental results demonstrate that high accuracy and success rates are achieved. The effect of uncertainties caused by water-depth variation and the skill requirement in manual manipulation are eliminated. The proposed contact detection strategy can be extended to microinjection for other organisms. Note to Practitioners—As a typical multicellular model organism, the zebrafish has been increasingly used in biological research. For studying drug toxicity and disease models, exogenous substances need to be injected into zebrafish larvae. However, for both manual and automated injection, a fatal problem is that the camera on the microscope only provides 2-D positional information. It is laborious to align the pipette tip with the injection site along the  $z$ -axis. Moreover, due to the characteristic of stereomicroscopes, the impact of refraction at the water surface cannot be ignored. In order to address these issues, in this article, we present an adaptive calibration method and an edge detection algorithm for zebrafish larva heart injection to avoid contact failure in practical implementations.",G. Zhang; M. Tong; C. Qian; S. Zhuang; C. Wang; X. Yu; W. Lin; J. Qiu; H. Gao,,,Visual-Based Contact Detection for Automated Zebrafish Larva Heart Microinjection,18,4,10.1109/TASE.2020.3019782 ,IEEE Journals ,,"This article presents an automated strategy to touch the injection site on zebrafish larva skin with the injection pipette tip accurately in the presence of water-depth variation, which is a crucial problem to automate zebrafish larva microinjection. The presented method consists of two parts: adaptive coordinate transformation and curve evolution for edge detection. In the first part, the impact of refraction is taken into consideration. An adaptive calibration method is developed, which enables the coordinate transformation matrix to adapt to the changing water depth. In the second part, the abovementioned calibration result is used to keep the injection pipette tip descending along the desired route. A curve-evolution-based edge detection algorithm is introduced to detect the deformation of larva skin caused by contact with the injection pipette tip. Experimental results demonstrate that high accuracy and success rates are achieved. The effect of uncertainties caused by water-depth variation and the skill requirement in manual manipulation are eliminated. The proposed contact detection strategy can be extended to microinjection for other organisms. Note to Practitioners—As a typical multicellular model organism, the zebrafish has been increasingly used in biological research. For studying drug toxicity and disease models, exogenous substances need to be injected into zebrafish larvae. However, for both manual and automated injection, a fatal problem is that the camera on the microscope only provides 2-D positional information. It is laborious to align the pipette tip with the injection site along the  $z$ -axis. Moreover, due to the characteristic of stereomicroscopes, the impact of refraction at the water surface cannot be ignored. In order to address these issues, in this article, we present an adaptive calibration method and an edge detection algorithm for zebrafish larva heart injection to avoid contact failure in practical implementations.",1558-3783,,,1803-1813,IEEE , ,Microinjection;Heart;Image edge detection;Calibration;Cameras;Active contours,,
4633,"Title:A Systems Biology Approach for Detecting Toxicity-Related Hotspots inside Protein Interaction Networks

 Drug-induced Neutropenia can be fatal when severe and therefore requires an improved understanding of its mechanism(s) of toxicity. Systems biology provides an opportunity to understand adverse events after drug administration using analysis of biomolecular networks. In this study, a human protein interaction network was analyzed to identify proteins that are most central to topological paths connecting a drug's target proteins to hematopoiesis-related proteins. For a set of 19 non-immune neutropenia inducing drugs, we found 270 proteins involved in putative signaling paths of which 9 proteins were found to be common across all drugs evaluated and all 9 proteins showed relevance to neutrophil biology. This study provides an understanding of downstream effects for drugs known to induce non-immune neutropenia.  We believe that the algorithm developed here can be applied towards analysis of any toxicity where the drugs and the physiological processes involved in the toxic mechanism are known.",K. Desai; D. Brott; X. Hu; A. Christianson,,,A Systems Biology Approach for Detecting Toxicity-Related Hotspots inside Protein Interaction Networks,,,10.1109/HISB.2011.61 ,IEEE Conferences ,,"Drug-induced Neutropenia can be fatal when severe and therefore requires an improved understanding of its mechanism(s) of toxicity. Systems biology provides an opportunity to understand adverse events after drug administration using analysis of biomolecular networks. In this study, a human protein interaction network was analyzed to identify proteins that are most central to topological paths connecting a drug's target proteins to hematopoiesis-related proteins. For a set of 19 non-immune neutropenia inducing drugs, we found 270 proteins involved in putative signaling paths of which 9 proteins were found to be common across all drugs evaluated and all 9 proteins showed relevance to neutrophil biology. This study provides an understanding of downstream effects for drugs known to induce non-immune neutropenia.  We believe that the algorithm developed here can be applied towards analysis of any toxicity where the drugs and the physiological processes involved in the toxic mechanism are known.",,,978-1-4577-0325-6,53-60,IEEE , ,Proteins;Drugs;Image edge detection;Databases;Reliability;Inhibitors,,
4634,"Title:Laser-Based Systems for Standoff Detection of CWA: A Short Review

 In recent times, the use of Chemical Warfare (CW) agents against civilian and military by terrorists and rogue countries are recurrent. The examples of such attacks are available in open literature. They are highly dangerous due to their acute toxicity nature. They tend to stimulate and paralyze nerve system of the body and cause other toxic side effects. Once these toxic chemicals are released into the atmosphere, timely detection and identification of the same at standoff distances will help the defensive forces to take proper counter measures. Detection techniques such as ion mobility spectrometry, infrared spectrometry, Raman spectrometry, FTIR, LIDAR, etc. have been used widely. Among all these techniques, Raman spectroscopy techniques and LIDAR (LIght Detection and Ranging) is the only active remote detection method that can detect and discriminate the chemical agents at standoff distances. Infrared DIAL (Differential Absorption Lidar) is a versatile technique for remote detection of various chemicals. DIAL technique can provide spatially resolved measurements of these agents with sufficient sensitivity (at few ppm levels) at ranges of several kilometers by exploiting the concept such as scattering and absorption from the atmosphere. The main objective of this review paper is to bring out the details of highly potential chemical warfare agents, their properties and laser based remote detection sensors. LIDAR technique is emphasized in more detail because of their long range detection capability, sensitivity and selectivity. An overview of existing R&D based and commercial systems is also discussed.",M. K. Jindal; M. Mainuddin; S. Veerabuthiran; A. K. Razdan,,,Laser-Based Systems for Standoff Detection of CWA: A Short Review,21,4,10.1109/JSEN.2020.3030672 ,IEEE Journals ,,"In recent times, the use of Chemical Warfare (CW) agents against civilian and military by terrorists and rogue countries are recurrent. The examples of such attacks are available in open literature. They are highly dangerous due to their acute toxicity nature. They tend to stimulate and paralyze nerve system of the body and cause other toxic side effects. Once these toxic chemicals are released into the atmosphere, timely detection and identification of the same at standoff distances will help the defensive forces to take proper counter measures. Detection techniques such as ion mobility spectrometry, infrared spectrometry, Raman spectrometry, FTIR, LIDAR, etc. have been used widely. Among all these techniques, Raman spectroscopy techniques and LIDAR (LIght Detection and Ranging) is the only active remote detection method that can detect and discriminate the chemical agents at standoff distances. Infrared DIAL (Differential Absorption Lidar) is a versatile technique for remote detection of various chemicals. DIAL technique can provide spatially resolved measurements of these agents with sufficient sensitivity (at few ppm levels) at ranges of several kilometers by exploiting the concept such as scattering and absorption from the atmosphere. The main objective of this review paper is to bring out the details of highly potential chemical warfare agents, their properties and laser based remote detection sensors. LIDAR technique is emphasized in more detail because of their long range detection capability, sensitivity and selectivity. An overview of existing R&D based and commercial systems is also discussed.",1558-1748,,,4085-4096,IEEE , ,Chemicals;Liquids;Laser radar;Sensors;Weapons;Chemical sensors;Chemical lasers,,
4635,"Title:Toxicity Detection on Bengali Social Media Comments using Supervised Models

 Social media playing an indispensable role in our daily life providing a public platform to share opinions including threats, spam and vulgar words often referred to as toxic comments. This type of expression depicts the anti-social behavior of the commentators which may hamper the online atmosphere. Filtering such toxic comments by handcrafting rules is cumbersome because they are unstructured and often include misspelled obscene words. Automated machine learning-based models to classify such toxic comments constitute a part of Sentiment Analysis and they are extensively used for the English language; showing promising results than statistical models. Though Bengali is a widely spoken language around the globe, little research works have been done to detect toxic comments in this language. Hence in this scholarly manuscript, we provide a comparative analysis of five supervised learning models (Naive Bayes, Support Vector Machines, Logistic Regression, Convolutional Neural Network, and Long Short Term Memory) to detect toxic Bengali comments from an annotated publicly available dataset. As our research finding, we demonstrate that both the deep learning-based models have outperformed other classifiers by 10% margin where Convolutional Neural Network achieved the highest accuracy of 95.30%.",N. Banik; M. H. H. Rahman,,,Toxicity Detection on Bengali Social Media Comments using Supervised Models,,,10.1109/ICIET48527.2019.9290710 ,IEEE Conferences ,,"Social media playing an indispensable role in our daily life providing a public platform to share opinions including threats, spam and vulgar words often referred to as toxic comments. This type of expression depicts the anti-social behavior of the commentators which may hamper the online atmosphere. Filtering such toxic comments by handcrafting rules is cumbersome because they are unstructured and often include misspelled obscene words. Automated machine learning-based models to classify such toxic comments constitute a part of Sentiment Analysis and they are extensively used for the English language; showing promising results than statistical models. Though Bengali is a widely spoken language around the globe, little research works have been done to detect toxic comments in this language. Hence in this scholarly manuscript, we provide a comparative analysis of five supervised learning models (Naive Bayes, Support Vector Machines, Logistic Regression, Convolutional Neural Network, and Long Short Term Memory) to detect toxic Bengali comments from an annotated publicly available dataset. As our research finding, we demonstrate that both the deep learning-based models have outperformed other classifiers by 10% margin where Convolutional Neural Network achieved the highest accuracy of 95.30%.",,,978-1-7281-6309-3,1-5,IEEE , ,Social networking (online);Toxicology;Feature extraction;Analytical models;Task analysis;Support vector machines;Computer architecture,,
4636,"Series([], Name: Abstract, dtype: object)",C. C. Tay; S. Surif; Y. H. Lee,,,Detection of metas toxicity biosensor using immobilized cyanobacteria anabacna flos-aquae,,,10.1109/ASENSE.2003.1225018 ,IEEE Conferences ,,"Series([], Name: Abstract, dtype: object)",,,0-7803-8101-7,197-201,IEEE , ,Biosensors;Biomembranes;Polymers;Copper;Lighting;Lead;Biochemistry;Cells (biology);Stability;Microorganisms,,
4637,"Title:Hate Speech and Offensive Language Detection Using an Emotion-Aware Shared Encoder

 The rise of emergence of social media platforms has fundamentally altered how people communicate, and among the results of these developments is an increase in online use of abusive content. Therefore, automatically detecting this content is essential for banning inappropriate information, and reducing toxicity and violence on social media platforms. The existing works on hate speech and offensive language detection produce promising results based on pre-trained transformer models, however, they considered only the analysis of abusive content features generated through annotated datasets. This paper addresses a multi-task joint learning approach which combines external emotional features extracted from another corpora in dealing with the imbalanced and scarcity of labeled datasets. Our analysis are using two well-known Transformer-based models, BERT and mBERT, where the later is used to address abusive content detection in multi-lingual scenarios. Our model jointly learns abusive content detection with emotional features by sharing representations through transformers' shared encoder. This approach increases data efficiency, reduce overfitting via shared representations, and ensure fast learning by leveraging auxiliary information. Our findings demonstrate that emotional knowledge helps to more reliably identify hate speech and offensive language across datasets. Our hate speech detection Multi-task model exhibited 3% performance improvement over baseline models, but the performance of multi-task models were not significant for offensive language detection task. More interestingly, in both tasks, multi-task models exhibits less false positive errors compared to single task scenario.",K. Mnassri; P. Rajapaksha; R. Farahbakhsh; N. Crespi,,,Hate Speech and Offensive Language Detection Using an Emotion-Aware Shared Encoder,,,10.1109/ICC45041.2023.10279690 ,IEEE Conferences ,,"The rise of emergence of social media platforms has fundamentally altered how people communicate, and among the results of these developments is an increase in online use of abusive content. Therefore, automatically detecting this content is essential for banning inappropriate information, and reducing toxicity and violence on social media platforms. The existing works on hate speech and offensive language detection produce promising results based on pre-trained transformer models, however, they considered only the analysis of abusive content features generated through annotated datasets. This paper addresses a multi-task joint learning approach which combines external emotional features extracted from another corpora in dealing with the imbalanced and scarcity of labeled datasets. Our analysis are using two well-known Transformer-based models, BERT and mBERT, where the later is used to address abusive content detection in multi-lingual scenarios. Our model jointly learns abusive content detection with emotional features by sharing representations through transformers' shared encoder. This approach increases data efficiency, reduce overfitting via shared representations, and ensure fast learning by leveraging auxiliary information. Our findings demonstrate that emotional knowledge helps to more reliably identify hate speech and offensive language across datasets. Our hate speech detection Multi-task model exhibited 3% performance improvement over baseline models, but the performance of multi-task models were not significant for offensive language detection task. More interestingly, in both tasks, multi-task models exhibits less false positive errors compared to single task scenario.",1938-1883,,978-1-5386-7462-8,2852-2857,IEEE , ,Analytical models;Toxicology;Social networking (online);Hate speech;Multitasking;Feature extraction;Transformers,,
4638,"Title:Characterizing (Un)moderated Textual Data in Social Systems

 Despite the valuable social interactions that online media promote, these systems provide space for speech that would be potentially detrimental to different groups of people. The moderation of content imposed by many social media has motivated the emergence of a new social system for free speech named Gab, which lacks moderation of content. This article characterizes and compares moderated textual data from Twitter with a set of unmoderated data from Gab. In particular, we analyze distinguishing characteristics of moderated and unmoderated content in terms of linguistic features, evaluate hate speech and its different forms in both environments. Our work shows that unmoderated content presents different psycholinguistic features, more negative sentiment and higher toxicity. Our findings support that unmoderated environments may have proportionally more online hate speech. We hope our analysis and findings contribute to the debate about hate speech and benefit systems aiming at deploying hate speech detection approaches.",L. Lima; J. C. S. Reis; P. Melo; F. Murai; F. Benevenuto,,,Characterizing (Un)moderated Textual Data in Social Systems,,,10.1109/ASONAM49781.2020.9381327 ,IEEE Conferences ,,"Despite the valuable social interactions that online media promote, these systems provide space for speech that would be potentially detrimental to different groups of people. The moderation of content imposed by many social media has motivated the emergence of a new social system for free speech named Gab, which lacks moderation of content. This article characterizes and compares moderated textual data from Twitter with a set of unmoderated data from Gab. In particular, we analyze distinguishing characteristics of moderated and unmoderated content in terms of linguistic features, evaluate hate speech and its different forms in both environments. Our work shows that unmoderated content presents different psycholinguistic features, more negative sentiment and higher toxicity. Our findings support that unmoderated environments may have proportionally more online hate speech. We hope our analysis and findings contribute to the debate about hate speech and benefit systems aiming at deploying hate speech detection approaches.",2473-991X,,978-1-7281-1056-1,430-434,IEEE , ,Voice activity detection;Toxicology;Social networking (online);Statistical analysis;Blogs;Linguistics;Media,,
4639,"Title:Health Risk Assessment of Mercury in Cosmetics

 The main objective of this paper was to determine the mercury content within cosmetics and to assess the risk of intoxication with this heavy metal due to their use. We want to draw consumers' attention to the amount of mercury they are being daily exposed by using various cosmetics. A number of 7 sunscreens SPF 50+ for body and face samples from different manufacturers were selected from stores and pharmacies. The Advanced Mercury Analyzer 254 mercury analyzer with a detection limit of 0.00001 mg mercury was used to determine the mercury concentration. Our results indicate that sunscreens could be responsible for 30% from the alert level of the mercury. Even if this value does not seem high enough, we estimated that over the course of a year cosmetic products may account for up to 45% of the required level for side effects become manifest. This is especially worrisome if we consider that the human body is already being exposed to a significant amount of mercury in the food consumed daily. Based on this conclusion, in the future, it must be established whether the accumulation of mercury resulting from the multiple use of cosmetics can reach high potentially toxic levels.",B. Magdalena; P. Matei; C. A. Caterina; C. Adriana; S. C. Daniela,,,Health Risk Assessment of Mercury in Cosmetics,,,10.1109/EHB52898.2021.9657713 ,IEEE Conferences ,,"The main objective of this paper was to determine the mercury content within cosmetics and to assess the risk of intoxication with this heavy metal due to their use. We want to draw consumers' attention to the amount of mercury they are being daily exposed by using various cosmetics. A number of 7 sunscreens SPF 50+ for body and face samples from different manufacturers were selected from stores and pharmacies. The Advanced Mercury Analyzer 254 mercury analyzer with a detection limit of 0.00001 mg mercury was used to determine the mercury concentration. Our results indicate that sunscreens could be responsible for 30% from the alert level of the mercury. Even if this value does not seem high enough, we estimated that over the course of a year cosmetic products may account for up to 45% of the required level for side effects become manifest. This is especially worrisome if we consider that the human body is already being exposed to a significant amount of mercury in the food consumed daily. Based on this conclusion, in the future, it must be established whether the accumulation of mercury resulting from the multiple use of cosmetics can reach high potentially toxic levels.",2575-5145,,978-1-6654-4000-4,1-4,IEEE , ,Europe;Risk management;Mercury (metals);Faces;Biomedical engineering,,
4640,"Title:Data Mining to Generate Adverse Drug Events Detection Rules

 Adverse drug events (ADEs) are a public health is sue. Their detection usually relies on voluntary reporting or medical chart reviews. The objective of this paper is to automatically detect cases of ADEs by data mining. 115 447 complete past hospital stays are extracted from six French, Danish, and Bulgarian hospitals using a common data model including diagnoses, drug administrations, laboratory results, and free-text records. Different kinds of outcomes are traced, and supervised rule induction methods (decision trees and association rules) are used to discover ADE detection rules, with respect to time constraints. The rules are then filtered, validated, and reorganized by a committee of experts. The rules are described in a rule repository, and several statistics are automatically computed in every medical department, such as the confidence, relative risk, and median delay of outcome appearance. 236 validated ADE-detection rules are discovered; they enable to detect 27 different kinds of outcomes. The rules use a various number of conditions related to laboratory results, diseases, drug administration, and demographics. Some rules involve innovative conditions, such as drug discontinuations.",E. Chazard; G. Ficheur; S. Bernonville; M. Luyckx; R. Beuscart,,,Data Mining to Generate Adverse Drug Events Detection Rules,15,6,10.1109/TITB.2011.2165727 ,IEEE Journals ,,"Adverse drug events (ADEs) are a public health is sue. Their detection usually relies on voluntary reporting or medical chart reviews. The objective of this paper is to automatically detect cases of ADEs by data mining. 115 447 complete past hospital stays are extracted from six French, Danish, and Bulgarian hospitals using a common data model including diagnoses, drug administrations, laboratory results, and free-text records. Different kinds of outcomes are traced, and supervised rule induction methods (decision trees and association rules) are used to discover ADE detection rules, with respect to time constraints. The rules are then filtered, validated, and reorganized by a committee of experts. The rules are described in a rule repository, and several statistics are automatically computed in every medical department, such as the confidence, relative risk, and median delay of outcome appearance. 236 validated ADE-detection rules are discovered; they enable to detect 27 different kinds of outcomes. The rules use a various number of conditions related to laboratory results, diseases, drug administration, and demographics. Some rules involve innovative conditions, such as drug discontinuations.",1558-0032,,,823-830,IEEE , ,Drugs;Medical services;Medical information systems;Medical diagnostic imaging;Data mining;Patient monitoring;Decision trees,,
4641,"Title:Progress of Lead-Free Halide Perovskite X-ray Detectors

 Lead halide perovskite for radiation detection still faces significant challenges despite its exciting progress. The main issues which hinder further development are the toxicity problem of lead and the intrinsic instability for volatile organic parts in lead-based perovskites. Therefore, searching for low-toxic and intrinsically stable perovskite materials have drawn a great attention from the public. In this review, lead-free perovskites are divided into two types: double perovskites type as A2MIMIIX6 and low-dimensional perovskites type as A3W2X9. The synthesis methods of these lead-free perovskites are discussed and the performance on X-ray detection are accordingly summarized. Moreover, a brief outlook on the future development of lead-free perovskites in radiation detection is proposed.",H. Zhang; G. Dun; Y. Qiao; D. Xie; T. -L. Ren,,,Progress of Lead-Free Halide Perovskite X-ray Detectors,,,10.1109/ICSICT49897.2020.9278179 ,IEEE Conferences ,,"Lead halide perovskite for radiation detection still faces significant challenges despite its exciting progress. The main issues which hinder further development are the toxicity problem of lead and the intrinsic instability for volatile organic parts in lead-based perovskites. Therefore, searching for low-toxic and intrinsically stable perovskite materials have drawn a great attention from the public. In this review, lead-free perovskites are divided into two types: double perovskites type as A2MIMIIX6 and low-dimensional perovskites type as A3W2X9. The synthesis methods of these lead-free perovskites are discussed and the performance on X-ray detection are accordingly summarized. Moreover, a brief outlook on the future development of lead-free perovskites in radiation detection is proposed.",,,978-1-7281-6235-5,1-4,IEEE , ,X-ray detectors;Lead;Sensitivity;X-ray imaging;X-ray detection;Detectors;Toxicology,,
4642,"Title:A Differentially Private Federated Learning Model Against Poisoning Attacks in Edge Computing

 Federated learning is increasingly popular, as it allows us to circumvent challenges due to data islands (e.g., challenges in getting access to raw datasets, particularly when data are owned by multiple data owners) by training a global model using data from one or more data owners / sources. However, in an edge computing deployment one cannot assume that resource-constrained end devices are sufficiently secure. In other words, we have to consider the possibility of these devices being compromised and can be abused to facilitate poisoning attacks. Privacy-preserving is another important property to consider when dealing with sensitive user data on end devices. Most existing approaches only consider either defending against poisoning attacks or supporting privacy, but not both properties simultaneously. In this paper, we propose a differentially private federated learning model against poisoning attacks, designed for edge computing deployment. First, we design a weight-based algorithm to perform anomaly detection on the parameters uploaded by end devices in edge nodes, which improves detection rate using only small-size validation datasets and minimizes the communication cost. Then, differential privacy technology is leveraged to protect the privacy of both data and model in an edge computing setting. We also evaluate the detection performance in the presence of random and customized malicious end devices, and compare its performance with those of two other competing approaches published in IEEE Transactions on Dependable and Secure Computing, in terms of attack resiliency, and communication and computation costs. Experimental results demonstrate that our scheme can achieve an optimal tradeoff between security, efficiency and accuracy.",J. Zhou; N. Wu; Y. Wang; S. Gu; Z. Cao; X. Dong; K. -K. R. Choo,,,A Differentially Private Federated Learning Model Against Poisoning Attacks in Edge Computing,20,3,10.1109/TDSC.2022.3168556 ,IEEE Journals ,,"Federated learning is increasingly popular, as it allows us to circumvent challenges due to data islands (e.g., challenges in getting access to raw datasets, particularly when data are owned by multiple data owners) by training a global model using data from one or more data owners / sources. However, in an edge computing deployment one cannot assume that resource-constrained end devices are sufficiently secure. In other words, we have to consider the possibility of these devices being compromised and can be abused to facilitate poisoning attacks. Privacy-preserving is another important property to consider when dealing with sensitive user data on end devices. Most existing approaches only consider either defending against poisoning attacks or supporting privacy, but not both properties simultaneously. In this paper, we propose a differentially private federated learning model against poisoning attacks, designed for edge computing deployment. First, we design a weight-based algorithm to perform anomaly detection on the parameters uploaded by end devices in edge nodes, which improves detection rate using only small-size validation datasets and minimizes the communication cost. Then, differential privacy technology is leveraged to protect the privacy of both data and model in an edge computing setting. We also evaluate the detection performance in the presence of random and customized malicious end devices, and compare its performance with those of two other competing approaches published in IEEE Transactions on Dependable and Secure Computing, in terms of attack resiliency, and communication and computation costs. Experimental results demonstrate that our scheme can achieve an optimal tradeoff between security, efficiency and accuracy.",1941-0018,,,1941-1958,IEEE , ,Computational modeling;Privacy;Edge computing;Training;Data models;Collaborative work;Image edge detection,,
4643,"Title:Detection and Classification of Toxic Content for Social Media Platforms

 Over the years the use of the internet has been increased exponentially and it is changing all the time. Recently there are two important evolutions; they are the social media platforms and mobile technology. Through this, the way people communicate with each other has changed significantly [1]. Many social media platforms like Facebook, Instagram, and Twitter, etc. have grown into worldwide networks. Massive amount of information and content arise from these social media platforms as people are engaging themselves to communicate, express their opinions and share their views daily. Even though, this type of virtual communication is highly productive and constructive, a significant part of them will be destructive. That is it is toxic in nature and some of them might include violence, obscene, threat, insult, etc. The toxic content can be either in Image or Text form. So it is essential to recognize the threat and respond to it which makes the online space more healthy and valuable. To address this problem we are proposing a system that makes use of Random Forest Machine learning algorithm and Convolutional neural network to detect toxicity in Text and Image respectively. We have successfully detected and classified toxicity in Text and Image data.",T. C. Nagavi; A. D. S.,,,Detection and Classification of Toxic Content for Social Media Platforms,,,10.1109/RDCAPE52977.2021.9633647 ,IEEE Conferences ,,"Over the years the use of the internet has been increased exponentially and it is changing all the time. Recently there are two important evolutions; they are the social media platforms and mobile technology. Through this, the way people communicate with each other has changed significantly [1]. Many social media platforms like Facebook, Instagram, and Twitter, etc. have grown into worldwide networks. Massive amount of information and content arise from these social media platforms as people are engaging themselves to communicate, express their opinions and share their views daily. Even though, this type of virtual communication is highly productive and constructive, a significant part of them will be destructive. That is it is toxic in nature and some of them might include violence, obscene, threat, insult, etc. The toxic content can be either in Image or Text form. So it is essential to recognize the threat and respond to it which makes the online space more healthy and valuable. To address this problem we are proposing a system that makes use of Random Forest Machine learning algorithm and Convolutional neural network to detect toxicity in Text and Image respectively. We have successfully detected and classified toxicity in Text and Image data.",,,978-1-6654-1429-6,368-373,IEEE , ,Deep learning;Power engineering;Toxicology;Machine learning algorithms;Social networking (online);Neural networks;Multimedia Web sites,,
4644,"Title:Troll-Detection Systems Limitations of Troll Detection Systems and AI/ML Anti-Trolling Solution

 Trolling is a modern-day vice which has manifested itself in the burgeoning virtual world. As bullying shifts from playgrounds to social media, the need of the hour is having anti-trolling softwares in place to combat this malpractice. Many internet companies have taken steps in this direction by creating softwares or applications that can prevent trolling but none have been completely successful. The word anti-trolling has existed as a concept for a long time. It is necessary to make it a concrete reality. Most of the softwares identify abusive words and simply block them but trolls have found ways to circumvent this obstacle by using clever ways. This paper explores the currently existing “Anti-trolling systems”, their methodologies and technological challenges. In particular, we consider machine learning and existing expert systems that detect and prevent trolls. The paper concludes with a discussion of the issues faced by this technology, the current functioning and a few suggestions along with a modified architecture and the vision of a trolling-free internet.",U. Bhatt; D. Iyyani; K. Jani; S. Mali,,,Troll-Detection Systems Limitations of Troll Detection Systems and AI/ML Anti-Trolling Solution,,,10.1109/I2CT.2018.8529342 ,IEEE Conferences ,,"Trolling is a modern-day vice which has manifested itself in the burgeoning virtual world. As bullying shifts from playgrounds to social media, the need of the hour is having anti-trolling softwares in place to combat this malpractice. Many internet companies have taken steps in this direction by creating softwares or applications that can prevent trolling but none have been completely successful. The word anti-trolling has existed as a concept for a long time. It is necessary to make it a concrete reality. Most of the softwares identify abusive words and simply block them but trolls have found ways to circumvent this obstacle by using clever ways. This paper explores the currently existing “Anti-trolling systems”, their methodologies and technological challenges. In particular, we consider machine learning and existing expert systems that detect and prevent trolls. The paper concludes with a discussion of the issues faced by this technology, the current functioning and a few suggestions along with a modified architecture and the vision of a trolling-free internet.",,,978-1-5386-4273-3,1-6,IEEE , ,Twitter;Facebook;Tools;Software;Companies;Google,,
4645,"Title:Object Detection Routine for Material Streams Combining RGB and Hyperspectral Reflectance Data Based on Guided Object Localization

 Electronic waste is the fastest growing type of scrap globally and is an important challenge due to its heterogeneity, intrinsic toxicity and potential environmental impact. With an objective of obtaining information on the composition of printed circuit boards (PCBs) through non-invasive analysis to aid in recycling and recovery of precious waste, the goal of this paper is to propose a scheme towards the fusion of RGB and hyperspectral data in object detection. State-of-art detectors come with their own set of challenges which make them inapplicable to PCB recycling. We introduce a method which promises to achieve object detection based on multi-sensor data by utilizing the hyperspectral data to localize components and compare the results to a conventional single-sensor (RGB) based approach.",V. Sudharshan; P. Seidel; P. Ghamisi; S. Lorenz; M. Fuchs; J. S. Fareedh; P. Neubert; S. Schubert; R. Gloaguen,,,Object Detection Routine for Material Streams Combining RGB and Hyperspectral Reflectance Data Based on Guided Object Localization,20,19,10.1109/JSEN.2020.2996757 ,IEEE Journals ,,"Electronic waste is the fastest growing type of scrap globally and is an important challenge due to its heterogeneity, intrinsic toxicity and potential environmental impact. With an objective of obtaining information on the composition of printed circuit boards (PCBs) through non-invasive analysis to aid in recycling and recovery of precious waste, the goal of this paper is to propose a scheme towards the fusion of RGB and hyperspectral data in object detection. State-of-art detectors come with their own set of challenges which make them inapplicable to PCB recycling. We introduce a method which promises to achieve object detection based on multi-sensor data by utilizing the hyperspectral data to localize components and compare the results to a conventional single-sensor (RGB) based approach.",1558-1748,,,11490-11498,IEEE , ,Object detection;Hyperspectral imaging;Recycling;Sensors;Spatial resolution;Training,,
4646,"Title:The Cytotoxicity and OS-Mediated Toxicity of One Nanosize Titanium Dioxide

 One kind of nanosize titanium dioxide (nano-TiO2) was successfully made through anodization of titanium in this study, and its cytotoxicity and OS-mediated toxicity was detected by MTT, SOD and MDA assay in vitro and in vivo. The results showed that high does (0.8, 1.6 mg/mL) of this nano-TiO2 can cause cytotoxicity and OS-mediated toxicity, and reverse dose-rate effect happened in the low and medium does (0.1, 0.2, 0.4 mg/mL) in the OS-mediated toxicity detection.",X. Yang; X. -y. Xu; G. -q. Xiao; X. -l. Xiang,,,The Cytotoxicity and OS-Mediated Toxicity of One Nanosize Titanium Dioxide,,,10.1109/ICBBE.2009.5163586 ,IEEE Conferences ,,"One kind of nanosize titanium dioxide (nano-TiO2) was successfully made through anodization of titanium in this study, and its cytotoxicity and OS-mediated toxicity was detected by MTT, SOD and MDA assay in vitro and in vivo. The results showed that high does (0.8, 1.6 mg/mL) of this nano-TiO2 can cause cytotoxicity and OS-mediated toxicity, and reverse dose-rate effect happened in the low and medium does (0.1, 0.2, 0.4 mg/mL) in the OS-mediated toxicity detection.",2151-7622,,978-1-4244-2901-1,1-3,IEEE , ,Titanium;In vitro;In vivo;Surface morphology;Nanotubes;Manufacturing;Biological materials;Biochemistry;Gas detectors;Organic compounds,,
4647,"Title:Hybrid point-of-care devices for high-sensitivity visual detection of salivary biomarkers and drugs

 Early diagnostics is a crucial part of clinical practice offering a rapid and convenient way to investigate and quantify the presence of key biomarkers related to specific pathologies and increasing the chance of successful treatments. In this regard, point-of-care testing (POCT) shows several advantages, enabling simple and rapid analyses, real-time results, and home-testing [1]. Metallic nanoparticles (NPs), like gold NPs (AuNPs), can be beneficially integrated into POC devices thanks to their tunable plasmonic properties, which provide naked-eye readout [2]. Moreover, the high sensitivity enabled by NPs allows the detection of biomarkers in non-invasive fluids where the concentrations are typically low. These biofluids, like saliva and urine, are functionally equivalent to serum in reflecting the physiological state of the body, whilst they are easier to handle, collect, and store [3]. In this work, we first reported the design and development of a colorimetric strategy based on the morphological change of multibranched plasmonic AuNPs, aimed at detecting glucose in saliva [4]. The sensing approach relied on a target-induced reshaping process, which involves the oxidation of the NP tips and the particle transformation into a spherical shape, characterized by a naked-eye detectable blue-to-pink color change. The platform proved to be beneficial in the early and non-invasive diagnosis of hyperglycemia. The successful technological transfer on a solid substrate paved the way for the realization of a dipstick prototype for home-testing. Then, the strategy was adapted to other biomarkers, leading to the development of a multiplexing test for the simultaneous detection of three salivary analytes (cholesterol, glucose, and lactate) [5]. This multiplexing assay enabled saving reagents, costs, and time, while increasing the overall clinical value of the test. Exploiting the microfluidics applied on a paper sheet, we realized a monolithic and fully integrated POC device, through a low-cost and fast $CO_{2}$ laser cutter. The platform showed excellent selectivity and multiplexing ability, with negligible interferences. The second part of this work was focused on the development of POC devices for the detection of anticancer drug contaminations in water solutions and urine samples. Antiblastic agents have revealed high toxicity for the exposed healthcare workers who prepare and administer these drugs in occupational environments [6]. Hence, continuous monitoring is highly required, and POCT shows tremendous potential in this context. With this aim, we realized a lateral-flow device (LFD) for the assessment of doxorubicin contaminations, using the fluorescent properties of the drug for naked-eye detection [7]. The pharmacological recognition of the dsDNA probe was exploited to overcome the lack of anti-doxorubicin antibodies. The highly sensitive strategy was successfully adapted to a real urine sample, without resorting to complex pretreatment procedures. Then, we developed a competitive LFD device for the detection of methotrexate (MTX). AuNPs were employed as the label molecules and the pharmacological competition of folic acid and MTX for the capture enzyme was used as the recognition mechanism, instead of costly antibodies. Despite the sensitivity requires further improvements, the strategy showed fast and reliable results, demonstrating a high potential for workers’ safety monitoring.",T. Pomili; P. P. Pompa,,,Hybrid point-of-care devices for high-sensitivity visual detection of salivary biomarkers and drugs,,,10.1109/NMDC57951.2023.10343643 ,IEEE Conferences ,,"Early diagnostics is a crucial part of clinical practice offering a rapid and convenient way to investigate and quantify the presence of key biomarkers related to specific pathologies and increasing the chance of successful treatments. In this regard, point-of-care testing (POCT) shows several advantages, enabling simple and rapid analyses, real-time results, and home-testing [1]. Metallic nanoparticles (NPs), like gold NPs (AuNPs), can be beneficially integrated into POC devices thanks to their tunable plasmonic properties, which provide naked-eye readout [2]. Moreover, the high sensitivity enabled by NPs allows the detection of biomarkers in non-invasive fluids where the concentrations are typically low. These biofluids, like saliva and urine, are functionally equivalent to serum in reflecting the physiological state of the body, whilst they are easier to handle, collect, and store [3]. In this work, we first reported the design and development of a colorimetric strategy based on the morphological change of multibranched plasmonic AuNPs, aimed at detecting glucose in saliva [4]. The sensing approach relied on a target-induced reshaping process, which involves the oxidation of the NP tips and the particle transformation into a spherical shape, characterized by a naked-eye detectable blue-to-pink color change. The platform proved to be beneficial in the early and non-invasive diagnosis of hyperglycemia. The successful technological transfer on a solid substrate paved the way for the realization of a dipstick prototype for home-testing. Then, the strategy was adapted to other biomarkers, leading to the development of a multiplexing test for the simultaneous detection of three salivary analytes (cholesterol, glucose, and lactate) [5]. This multiplexing assay enabled saving reagents, costs, and time, while increasing the overall clinical value of the test. Exploiting the microfluidics applied on a paper sheet, we realized a monolithic and fully integrated POC device, through a low-cost and fast $CO_{2}$ laser cutter. The platform showed excellent selectivity and multiplexing ability, with negligible interferences. The second part of this work was focused on the development of POC devices for the detection of anticancer drug contaminations in water solutions and urine samples. Antiblastic agents have revealed high toxicity for the exposed healthcare workers who prepare and administer these drugs in occupational environments [6]. Hence, continuous monitoring is highly required, and POCT shows tremendous potential in this context. With this aim, we realized a lateral-flow device (LFD) for the assessment of doxorubicin contaminations, using the fluorescent properties of the drug for naked-eye detection [7]. The pharmacological recognition of the dsDNA probe was exploited to overcome the lack of anti-doxorubicin antibodies. The highly sensitive strategy was successfully adapted to a real urine sample, without resorting to complex pretreatment procedures. Then, we developed a competitive LFD device for the detection of methotrexate (MTX). AuNPs were employed as the label molecules and the pharmacological competition of folic acid and MTX for the capture enzyme was used as the recognition mechanism, instead of costly antibodies. Despite the sensitivity requires further improvements, the strategy showed fast and reliable results, demonstrating a high potential for workers’ safety monitoring.",2473-0718,,979-8-3503-3546-0,661-661,IEEE , ,Drugs;Multiplexing;Sensitivity;Point of care;Biomarkers;Antibodies;Plasmons,,
4648,"Title:Radiomics for Identification of Active Bone Marrow from CT: An Exploratory Study

 The radiation dose received by the pelvic Bone Marrow (BM) is a predictive factor for Hematologic Toxicity (HT) occurrence in the treatment of anal cancer. For this reason it is important to avoid BM during radiotherapy. In particular, the standard strategy in these cases consists in the identification of hematopoietically active BM (actBM), i.e. the part of BM in charge of blood cells generation, on 18FDG-PET, FLT-PET or MRI, but no approached have been developed for identifying actBM from CT images. This exploratory study aims to use radiomics for detecting actBM on CT sequences. Our approach is based on the extraction of 36 first-order and texture (second-order) features for each CT slice. These features are used as input of a Decision Tree (DT) classifier able to discriminate between active and inactive BM regions on the images. This method was applied to five patients affected by carcinoma of the anal canal and the obtained actBM segmentation was compared with the standard actBM identification from 18FDG-PET (reference standard, RS). Our results show that actBM identification in lumbosacral and iliac structures using radiomics overlaps the RS for more than 75% in 4 out of 5 patients.",S. Rosati; G. Balestra; P. Franco; C. Fiandra; F. Arcadipane; P. Silvetti; U. Ricardi; E. Gallio,,,Radiomics for Identification of Active Bone Marrow from CT: An Exploratory Study,,,10.1109/LSC.2018.8572154 ,IEEE Conferences ,,"The radiation dose received by the pelvic Bone Marrow (BM) is a predictive factor for Hematologic Toxicity (HT) occurrence in the treatment of anal cancer. For this reason it is important to avoid BM during radiotherapy. In particular, the standard strategy in these cases consists in the identification of hematopoietically active BM (actBM), i.e. the part of BM in charge of blood cells generation, on 18FDG-PET, FLT-PET or MRI, but no approached have been developed for identifying actBM from CT images. This exploratory study aims to use radiomics for detecting actBM on CT sequences. Our approach is based on the extraction of 36 first-order and texture (second-order) features for each CT slice. These features are used as input of a Decision Tree (DT) classifier able to discriminate between active and inactive BM regions on the images. This method was applied to five patients affected by carcinoma of the anal canal and the obtained actBM segmentation was compared with the standard actBM identification from 18FDG-PET (reference standard, RS). Our results show that actBM identification in lumbosacral and iliac structures using radiomics overlaps the RS for more than 75% in 4 out of 5 patients.",,,978-1-5386-6709-5,73-76,IEEE , ,Computed tomography;Feature extraction;Bones;Standards;Image segmentation;Classification algorithms;Cortical bone,,
4649,"Title:Comparison of different classifiers to recognize active bone marrow from CT images

 One of the main problems during in the treatment of anal cancer with chemotherapy and radiation is the occurrence of Hematologic Toxicity (HT). In particular, during radiotherapy it is crucial to spare Bone Marrow (BM), since the radiation dose received by BM in pelvic bones predicts the onset of HT. In this direction, the most popular strategies are based on the identification of the hematopoietically active BM (actBM), that is the part of BM in charge of blood cells generation, using MRI, SPECT or PET, but no approached have been proposed based on CT. In this study we compare four different classifiers in recognizing actBM from CT images using 36 radiomic features. We used Genetic Algorithms (GAs) to simultaneously optimize the feature subsets and the classifier parameters, separately for three pelvic subregions: iliac bone marrow (IBM), lower pelvis bone marrow (LPBM), and lumbosacral bone marrow (LSBM). The obtained classifiers were applied to CT sequences of a cohort of 25 patients affected by carcinoma of the anal canal. Classifiers results were compared with the actBM identified from 18FDG-PET (reference standard, RS). It emerged that the performances of the 4 classifiers are similar and they are satisfactory for IBM and LSBM subregions (Dice > 0.7) whereas they are poor for LPBM (Dice < 0.5).",S. Rosati; P. Franco; C. Fiandra; F. Arcadipane; P. Silvetti; E. Gallio; J. Panic; U. Ricardi; G. Balestra,,,Comparison of different classifiers to recognize active bone marrow from CT images,,,10.1109/MeMeA49120.2020.9137173 ,IEEE Conferences ,,"One of the main problems during in the treatment of anal cancer with chemotherapy and radiation is the occurrence of Hematologic Toxicity (HT). In particular, during radiotherapy it is crucial to spare Bone Marrow (BM), since the radiation dose received by BM in pelvic bones predicts the onset of HT. In this direction, the most popular strategies are based on the identification of the hematopoietically active BM (actBM), that is the part of BM in charge of blood cells generation, using MRI, SPECT or PET, but no approached have been proposed based on CT. In this study we compare four different classifiers in recognizing actBM from CT images using 36 radiomic features. We used Genetic Algorithms (GAs) to simultaneously optimize the feature subsets and the classifier parameters, separately for three pelvic subregions: iliac bone marrow (IBM), lower pelvis bone marrow (LPBM), and lumbosacral bone marrow (LSBM). The obtained classifiers were applied to CT sequences of a cohort of 25 patients affected by carcinoma of the anal canal. Classifiers results were compared with the actBM identified from 18FDG-PET (reference standard, RS). It emerged that the performances of the 4 classifiers are similar and they are satisfactory for IBM and LSBM subregions (Dice > 0.7) whereas they are poor for LPBM (Dice < 0.5).",,,978-1-7281-5386-5,1-5,IEEE , ,Training;Image recognition;Toxicology;Pelvic bones;Pelvis;Single photon emission computed tomography;Positron emission tomography,,
4650,"Title:An efficient novel single fault and its location detection technique using multiple droplets in a Digital Microfluidic Biochip

 Microfluidic biochip has facilitated a revolutionary improvement in biomedical operation or safety critical application like clinical diagnosis, parallel DNA sequencing, toxicity monitoring, immunoassay, air or water quality monitoring, food safety testing etc. But it has faced a major setback from malfunction in fluidic operation due to the defect in the electrodes. In this paper, we are proposing a novel and efficient technique for detecting a single fault and identifying the fault location within the biochip. Along with that it can also calculate the traversal time if the biochip is fault free. The traversal of the microarray is carried out by scanning the intermediate cells and the edges by special types of movement pattern RDRD (Right-Down-Right-Down) and DRDR (Down-Right-Down-Right) for left and right diagonal electrode traversal respectively and the boundary cells and edges are traversed in clockwise direction by moving the test droplets. If a fault is detected then the proposed technique also locates it by backtracking the droplet. The simulated result suggests that the proposed technique is efficient and represents significant improvement in fault detection and calculating traversal time of a fault free biochip over existing methods.",M. Majumder; U. Dolai; A. Bhattacharya,,,An efficient novel single fault and its location detection technique using multiple droplets in a Digital Microfluidic Biochip,,,10.1109/ISCO.2017.7855965 ,IEEE Conferences ,,"Microfluidic biochip has facilitated a revolutionary improvement in biomedical operation or safety critical application like clinical diagnosis, parallel DNA sequencing, toxicity monitoring, immunoassay, air or water quality monitoring, food safety testing etc. But it has faced a major setback from malfunction in fluidic operation due to the defect in the electrodes. In this paper, we are proposing a novel and efficient technique for detecting a single fault and identifying the fault location within the biochip. Along with that it can also calculate the traversal time if the biochip is fault free. The traversal of the microarray is carried out by scanning the intermediate cells and the edges by special types of movement pattern RDRD (Right-Down-Right-Down) and DRDR (Down-Right-Down-Right) for left and right diagonal electrode traversal respectively and the boundary cells and edges are traversed in clockwise direction by moving the test droplets. If a fault is detected then the proposed technique also locates it by backtracking the droplet. The simulated result suggests that the proposed technique is efficient and represents significant improvement in fault detection and calculating traversal time of a fault free biochip over existing methods.",,,978-1-5090-2717-0,119-124,IEEE , ,Electrodes;Microfluidics;Reservoirs;Fault location;Testing;Image edge detection,,
4651,"Title:Cisplatin SERS Detection Based on the Binding of Sulfhydryl Groups

 Cisplatin, a first-line anti-cancer drug, is widely utilized in clinical practice. Its anti-cancer mechanism involves DNA binding in the nucleus, leading to inhibition of cell division or induction of apoptosis. However, as heavy metal, platinum tends to accumulate in the body during metabolism and often results in nephrotoxicity, ototoxicity, and neurotoxicity. Therefore, developing an accurate cisplatin detection method is valuable for personalized treatment planning. In this study, we developed a novel p-amino thiophene (PATP) reaction-mediated surface-enhanced Raman scattering (SERS) assay for cisplatin detection. The Raman intensity of v (C-S) is linearly correlated with cisplatin concentration. This method is low-cost and convenient with high precision",C. Xue; J. Hu; Y. Xiang; J. Chen; J. Wei; J. Lv; A. Zhang; H. Dang; H. He; J. Hu; L. Shao; G. J. Chen; Z. Gao; P. P. Shum,,,Cisplatin SERS Detection Based on the Binding of Sulfhydryl Groups,,,10.1109/OGC59456.2023.10314584 ,IEEE Conferences ,,"Cisplatin, a first-line anti-cancer drug, is widely utilized in clinical practice. Its anti-cancer mechanism involves DNA binding in the nucleus, leading to inhibition of cell division or induction of apoptosis. However, as heavy metal, platinum tends to accumulate in the body during metabolism and often results in nephrotoxicity, ototoxicity, and neurotoxicity. Therefore, developing an accurate cisplatin detection method is valuable for personalized treatment planning. In this study, we developed a novel p-amino thiophene (PATP) reaction-mediated surface-enhanced Raman scattering (SERS) assay for cisplatin detection. The Raman intensity of v (C-S) is linearly correlated with cisplatin concentration. This method is low-cost and convenient with high precision",,,979-8-3503-2532-4,148-151,IEEE , ,Drugs;Raman scattering;Platinum;DNA;Planning;Probes;Surface treatment,,
4652,"Title:Highly selective Molecularly Imprinted Polymer for creatinine detection

 Creatinine is a metabolic waste that is constantly get diffused in the blood and filtered by the kidneys to minimize levels of waste content related to blood toxicity for maintaining a healthy balance in the living body. In the current research, we have developed a sensing polymer system for the detection of side effects of cancer chemotherapy on human kidneys for determining the creatinine levels. The proposed research is related to the real-time detection of levels creatinine in an aqueous medium. The polymer was surface characterized using Field Emission Scanning Electron Microscope (FESEM) and Energy dispersive analysis X-ray (EDAX) and found to be structurally isotropic as well as monodispersed and chemically pure in nature. Fourier-transform infrared spectroscopy (FTIR) confirmed the successful removal of creatinine from the MIP polymer by breaking Amide bonding. The sensing polymer system is able to determine concentrations within the range of 1 - 50 parts per million (ppm) when checked using ultra-high-performance liquid chromatography (UHPLC). The results highlight the future possibility of modifying this system for early levels of creatinine rise for preventing life-threatening conditions and providing indications to medical practitioners in the form of ppm unit results where they can alter the chemotherapy medications or reduce the total drug dosage to avoid health disorders such as Acute Kidney Damage and Acute Kidney Failure.",S. N. Prabhu; S. C. Mukhopadhyay; A. S. Davidson; G. Liu,,,Highly selective Molecularly Imprinted Polymer for creatinine detection,,,10.1109/ICST46873.2019.9047696 ,IEEE Conferences ,,"Creatinine is a metabolic waste that is constantly get diffused in the blood and filtered by the kidneys to minimize levels of waste content related to blood toxicity for maintaining a healthy balance in the living body. In the current research, we have developed a sensing polymer system for the detection of side effects of cancer chemotherapy on human kidneys for determining the creatinine levels. The proposed research is related to the real-time detection of levels creatinine in an aqueous medium. The polymer was surface characterized using Field Emission Scanning Electron Microscope (FESEM) and Energy dispersive analysis X-ray (EDAX) and found to be structurally isotropic as well as monodispersed and chemically pure in nature. Fourier-transform infrared spectroscopy (FTIR) confirmed the successful removal of creatinine from the MIP polymer by breaking Amide bonding. The sensing polymer system is able to determine concentrations within the range of 1 - 50 parts per million (ppm) when checked using ultra-high-performance liquid chromatography (UHPLC). The results highlight the future possibility of modifying this system for early levels of creatinine rise for preventing life-threatening conditions and providing indications to medical practitioners in the form of ppm unit results where they can alter the chemotherapy medications or reduce the total drug dosage to avoid health disorders such as Acute Kidney Damage and Acute Kidney Failure.",2156-8073,,978-1-7281-4807-6,1-5,IEEE , ,Polymers;Adsorption;Kidney;Sensors;Chemotherapy;Spectroscopy;Powders,,
4653,"Title:Adaptive medical detection system: An iterative averaging method for automated detection analysis using DMFBs

 In recent years a new generation of droplet based lab-on-chip device termed as Digital Microfluidic Biochip(DMFB) has found wide applications in the field of clinical diagnostics, DNA sequencing, drug design and environmental toxicity monitoring applications. Optical detection in DMFB is of major significance as it involves detection accuracy of the final results that determines the decision for clinical diagnostic solutions. In this work we propose the design of an adaptive detection system comprising of automated digital detection analyser coupled with Digital Microfluidic Biochips. The system performs automated analysis of the detection results for an obtained set of samples for the same patient and predicts the actual trend of the detection results. The technique is based on iterative averaging combined with adaptive manipulation of detection ranges determined through precharacterized values. This method provides higher detection accuracy (in the event of uncertainty resulted when no clear detection majority is available) with an approximated prediction of the trend of the extent of infection or abnormality of the targeted parameter. The design is simulated in FPGA platform and the detection results display fair amount of accuracy particularly in line with conventional laboratory methods.",P. Roy; A. Sahoo; H. Rahaman,,,Adaptive medical detection system: An iterative averaging method for automated detection analysis using DMFBs,,,10.1109/ISED.2017.8303923 ,IEEE Conferences ,,"In recent years a new generation of droplet based lab-on-chip device termed as Digital Microfluidic Biochip(DMFB) has found wide applications in the field of clinical diagnostics, DNA sequencing, drug design and environmental toxicity monitoring applications. Optical detection in DMFB is of major significance as it involves detection accuracy of the final results that determines the decision for clinical diagnostic solutions. In this work we propose the design of an adaptive detection system comprising of automated digital detection analyser coupled with Digital Microfluidic Biochips. The system performs automated analysis of the detection results for an obtained set of samples for the same patient and predicts the actual trend of the detection results. The technique is based on iterative averaging combined with adaptive manipulation of detection ranges determined through precharacterized values. This method provides higher detection accuracy (in the event of uncertainty resulted when no clear detection majority is available) with an approximated prediction of the trend of the extent of infection or abnormality of the targeted parameter. The design is simulated in FPGA platform and the detection results display fair amount of accuracy particularly in line with conventional laboratory methods.",2473-9413,,978-1-5386-3032-7,1-6,IEEE , ,Microfluidics;Electrodes;Optical sensors;Biomedical optical imaging;Adaptive systems;Optical mixing;DNA,,
4654,"Title:Detection of objects in sea sediments and estimation of bottom parameters

 An important objective of the SITAR project, abbreviation for ""Seafloor imaging and Toxicity: Assessment of Risks caused by buried waste,"" is to investigate various acoustic techniques for detection and classification of objects partially or completely buried in the sediments of the bottom. In this paper we report some results from in situ measurements in the Stockholm archipelago in fall 2003. A ROV is running over the bottom with an echo sounder transmitting pulses into the bottom. The pulses are short transients, with centre frequencies of 5 kHz, 10 kHz and 20 kHz. The echoes are received by hydrophones located at the same position as the transmitter, i.e. in the monostatic configuration. A partially buried object exists at the bottom. The first part of this paper will focus on detection of this target, and its appearance in the received signals for different transmitted pulse forms. The second part will focus on the appearance of the bottom in the data and estimation of bottom parameters. As a first approach the acoustic impedance of the bottom is estimated from the ratio of received to transmitted energy at the transmitter/receiver location, but corrected for geometric spreading loss in the water. It is observed a reduction of the higher frequencies in the spectra of the received signals when compared with the spectrum of the transmitted pulse. An attempt is made to explain this fact using theoretical modeling, and the results are used to obtain a roughness estimate as well as an improved acoustic impedance estimate of the bottom.",M. A. Larsen; J. M. Hovem,,,Detection of objects in sea sediments and estimation of bottom parameters,1,,10.1109/OCEANSE.2005.1511790 ,IEEE Conferences ,,"An important objective of the SITAR project, abbreviation for ""Seafloor imaging and Toxicity: Assessment of Risks caused by buried waste,"" is to investigate various acoustic techniques for detection and classification of objects partially or completely buried in the sediments of the bottom. In this paper we report some results from in situ measurements in the Stockholm archipelago in fall 2003. A ROV is running over the bottom with an echo sounder transmitting pulses into the bottom. The pulses are short transients, with centre frequencies of 5 kHz, 10 kHz and 20 kHz. The echoes are received by hydrophones located at the same position as the transmitter, i.e. in the monostatic configuration. A partially buried object exists at the bottom. The first part of this paper will focus on detection of this target, and its appearance in the received signals for different transmitted pulse forms. The second part will focus on the appearance of the bottom in the data and estimation of bottom parameters. As a first approach the acoustic impedance of the bottom is estimated from the ratio of received to transmitted energy at the transmitter/receiver location, but corrected for geometric spreading loss in the water. It is observed a reduction of the higher frequencies in the spectra of the received signals when compared with the spectrum of the transmitted pulse. An attempt is made to explain this fact using theoretical modeling, and the results are used to obtain a roughness estimate as well as an improved acoustic impedance estimate of the bottom.",,,0-7803-9103-9,645-649 Vol. 1,IEEE , ,Object detection;Sediments;Parameter estimation;Acoustic signal detection;Acoustic pulses;Buried object detection;Frequency;Transmitters;Impedance;Sea floor,,
4655,"Title:Flow Faster RCNN : Deep Learning Approach for Infrared Gas Leak Detection in Complex Chemical Plant Surroundings

 Leakage of hazardous gases from chemical plants brings serious risks to people's lives and property, therefore the infrared gas leakage detection method has attracted more and more researchers' attention with its real-time and accurate detection performance. However, infrared gas leak databases are very difficult to collect due to the flammability, explosibility and toxicity of leaked gas. Given this, we propose a gas leak detection method for chemical plant environment, which starts from both data enhancement and model improvement. Firstly, we generate and manually label fake infrared gas leak datasets under complex scenarios(ComplexGasVid dataset) as model training datasets. Secondly, we investigate the impact of the generated ComplexGasVid dataset on the performance of the target detection model. Meanwhile, we propose a new gas leak detection that combines the motion information of optical flow images with a Faster RCNN network (named Flow Faster RCNN). The final experimental results show that our proposed Flow Faster RCNN network improves the detection performance by 15.6 % compared to that of the original network.",Y. Wang; L. Huang; Z. Cheng; J. Xu; Q. Li,,,Flow Faster RCNN : Deep Learning Approach for Infrared Gas Leak Detection in Complex Chemical Plant Surroundings,,,10.23919/CCC58697.2023.10241164 ,IEEE Conferences ,,"Leakage of hazardous gases from chemical plants brings serious risks to people's lives and property, therefore the infrared gas leakage detection method has attracted more and more researchers' attention with its real-time and accurate detection performance. However, infrared gas leak databases are very difficult to collect due to the flammability, explosibility and toxicity of leaked gas. Given this, we propose a gas leak detection method for chemical plant environment, which starts from both data enhancement and model improvement. Firstly, we generate and manually label fake infrared gas leak datasets under complex scenarios(ComplexGasVid dataset) as model training datasets. Secondly, we investigate the impact of the generated ComplexGasVid dataset on the performance of the target detection model. Meanwhile, we propose a new gas leak detection that combines the motion information of optical flow images with a Faster RCNN network (named Flow Faster RCNN). The final experimental results show that our proposed Flow Faster RCNN network improves the detection performance by 15.6 % compared to that of the original network.",1934-1768,,978-988-75815-4-3,7823-7830,IEEE , ,Training;Image motion analysis;Computer vision;Toxicology;Systematics;Data models;Real-time systems,,
4656,"Title:Developmental Toxicity of Triadimefon in Embryo-Larval Stages of Zebrafish

 Triadimefon, a triazole fungicide, has been widely detected in the environment, but few studies have assessed its effect on aquatic organisms. The present study evaluated the effect of triadimefon in embryo-larval stages of zebra fish. Zebra fish embryos exhibited teratogenic effects of bent spine, uninflated swim bladder and other malformations after exposure to various triadimefon concentrations (0-4.0 μg/mL) from 6 to 120 h post-fertilization (hpf). We observed the loco motor activity namely spontaneous movement in embryos and swimming activity in larvae to assess the neurotoxicity. This is the first study to detection the neurotoxicity and teratogenic of triadimefon in zebra fish. We also inferred the spontaneous movement was related to the hatching rate and the potential course of the uninflated swim bladder. The results further the understanding of the toxicity of triadimefon to aquatic organisms and suggest the need for additional research to identify the mode of triadimefon toxicity.",S. Liu; J. Chang; G. Zhu,,,Developmental Toxicity of Triadimefon in Embryo-Larval Stages of Zebrafish,1,,10.1109/ICDMA.2010.347 ,IEEE Conferences ,,"Triadimefon, a triazole fungicide, has been widely detected in the environment, but few studies have assessed its effect on aquatic organisms. The present study evaluated the effect of triadimefon in embryo-larval stages of zebra fish. Zebra fish embryos exhibited teratogenic effects of bent spine, uninflated swim bladder and other malformations after exposure to various triadimefon concentrations (0-4.0 μg/mL) from 6 to 120 h post-fertilization (hpf). We observed the loco motor activity namely spontaneous movement in embryos and swimming activity in larvae to assess the neurotoxicity. This is the first study to detection the neurotoxicity and teratogenic of triadimefon in zebra fish. We also inferred the spontaneous movement was related to the hatching rate and the potential course of the uninflated swim bladder. The results further the understanding of the toxicity of triadimefon to aquatic organisms and suggest the need for additional research to identify the mode of triadimefon toxicity.",,,978-0-7695-4286-7,552-555,IEEE , ,Embryo;Bladder;Marine animals;Toxicology;Mice;Sensitivity;Monitoring,,
4657,"Title:Detection of Fake News Relate to CoViD-19

 The purpose of the paper is an approach to automatic recognition of alarming and misleading news, either of which are colloquially known under more commonly used term “Fake news”. The contribution describes the field of misinformation and particularly the methods suitable for generation of models for fake news detection. The detection models are learned on short text data, so they can classify a new unknown text into the classes labeled as “True” or “Fake”. The following supervised machine learning methods were used: K Nearest Neighbors, Naïve Bayes Classifier, Logistic Regression, Random Forests, Support Vector Machine, and Neural Networks. The results of experiments showed that the best method for this task are neural networks. They achieved the best results in Recall, Fl and Accuracy. Support Vector Machine achieved best results in Precision. The conclusion of the paper is that it is very important to prepare well-processed data as much as possible to achieve the best possible results. Another conclusion is that the overall performance of the models is highly dependent on a set of model parameters.",K. Machová; V. Balara; M. Mach,,,Detection of Fake News Relate to CoViD-19,,,10.1109/DISA59116.2023.10308911 ,IEEE Conferences ,,"The purpose of the paper is an approach to automatic recognition of alarming and misleading news, either of which are colloquially known under more commonly used term “Fake news”. The contribution describes the field of misinformation and particularly the methods suitable for generation of models for fake news detection. The detection models are learned on short text data, so they can classify a new unknown text into the classes labeled as “True” or “Fake”. The following supervised machine learning methods were used: K Nearest Neighbors, Naïve Bayes Classifier, Logistic Regression, Random Forests, Support Vector Machine, and Neural Networks. The results of experiments showed that the best method for this task are neural networks. They achieved the best results in Recall, Fl and Accuracy. Support Vector Machine achieved best results in Precision. The conclusion of the paper is that it is very important to prepare well-processed data as much as possible to achieve the best possible results. Another conclusion is that the overall performance of the models is highly dependent on a set of model parameters.",,,979-8-3503-4353-3,161-166,IEEE , ,Support vector machines;Logistic regression;Toxicology;Social networking (online);Neural networks;Web mining;Digital intelligence,,
4658,"Title:A study on the design and manufacture power systems of non-contact chemical agent detectors based on the semiconductor laser

 Detection of chemical agents is important because some chemical agents have high toxic effects and can be used as chemical weapons. In this case, the power system plays an important role for stable power distribution of the detection device. In this study, a semiconductor laser-based non-contact chemical agent detection device power system was designed and fabricated.",J. -H. Park; Y. S. Jang; Y. Gon Seo; H. -D. Yoon; J. -W. Lee,,,A study on the design and manufacture power systems of non-contact chemical agent detectors based on the semiconductor laser,,,10.1109/ICTC49870.2020.9289388 ,IEEE Conferences ,,"Detection of chemical agents is important because some chemical agents have high toxic effects and can be used as chemical weapons. In this case, the power system plays an important role for stable power distribution of the detection device. In this study, a semiconductor laser-based non-contact chemical agent detection device power system was designed and fabricated.",2162-1233,,978-1-7281-6758-9,690-694,IEEE , ,Semiconductor lasers;Weapons;Power lasers;Power distribution;Detectors;Information and communication technology;Chemicals,,
4659,"Title:Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks

 The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing ma-chine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adver-sarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.",M. S. Alexiou; J. S. Mertoguno,,,Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks,,,10.1109/IISA59645.2023.10345930 ,IEEE Conferences ,,"The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing ma-chine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adver-sarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.",,,979-8-3503-1806-7,1-8,IEEE , ,Deep learning;Toxicology;Cyberbullying;Media;Cognition;Internet;Monitoring,,
4660,"Title:A Neuro-NLP Induced Deep Learning Model Developed Towards Comment Based Toxicity Prediction

 The comments sections of online forums and social media platforms have become the new playing field for cyber harassment. Correspondingly, various organizations and companies have decided to abolish toxic and nasty comments altogether to avoid this kind of issue. To protect authorized and genuine users from being exposed to comments which contain offensive language on online mediums or social media platforms, organizations have started flagging such comments and they are blocking those users who are using unpleasant forms of language. Most of the organizations use computerized algorithms for instinctive discovery of comment toxicity using machine learning and artificial intelligence based systems. In the present research study, we have tried to build multi headed comment toxicity detection models. We have built three toxicity detection models using deep learning techniques and compared the accuracy and results. We have also developed a menu driven interface which will help to link machine learning models which is uncomplicated for non programmers and this connection of model to interface will be convenient for making interactive programming interfaces with great accuracy and operationality.",K. S. Ashok; K. A. Ashok; S. M. B. Naseem,,,A Neuro-NLP Induced Deep Learning Model Developed Towards Comment Based Toxicity Prediction,,,10.1109/ICAST55766.2022.10039597 ,IEEE Conferences ,,"The comments sections of online forums and social media platforms have become the new playing field for cyber harassment. Correspondingly, various organizations and companies have decided to abolish toxic and nasty comments altogether to avoid this kind of issue. To protect authorized and genuine users from being exposed to comments which contain offensive language on online mediums or social media platforms, organizations have started flagging such comments and they are blocking those users who are using unpleasant forms of language. Most of the organizations use computerized algorithms for instinctive discovery of comment toxicity using machine learning and artificial intelligence based systems. In the present research study, we have tried to build multi headed comment toxicity detection models. We have built three toxicity detection models using deep learning techniques and compared the accuracy and results. We have also developed a menu driven interface which will help to link machine learning models which is uncomplicated for non programmers and this connection of model to interface will be convenient for making interactive programming interfaces with great accuracy and operationality.",,,978-1-6654-9263-8,94-99,IEEE , ,Deep learning;Toxicology;Machine learning algorithms;Social networking (online);Computational modeling;Buildings;Companies,,
4661,"Title:Reddit Comment Toxicity Score Prediction through BERT via Transformer Based Architecture

 Hateful and offensive language on social media platforms has a severe influence on users' mental health and engagement of people from various backgrounds. Automatic detection of foul language has traditionally relied heavily on datasets with categorical data. However, the degree of offensiveness of comments varies. The proposed model uses tfidf followed by Ridge Regression,Catboost Regression and BERT followed by dense layers. The study uses a dataset containing Reddit-comments written in English language with precise and calculated values ranging from -1 to 1. Best-Worst Scaling was used to annotate the dataset, a type of comparative annotation that has been found to reduce the biases associated with rating scales. It has been demonstrated that the technique gives extremely accurate offensiveness scores. The proposed method offers user to customize their own threshold of offensiveness. The experiments has been conducted with different n-gram ranges. The result reveals better performance than state of the art.",R. Shounak; S. Roy; V. Kumar; V. Tiwari,,,Reddit Comment Toxicity Score Prediction through BERT via Transformer Based Architecture,,,10.1109/IEMCON56893.2022.9946574 ,IEEE Conferences ,,"Hateful and offensive language on social media platforms has a severe influence on users' mental health and engagement of people from various backgrounds. Automatic detection of foul language has traditionally relied heavily on datasets with categorical data. However, the degree of offensiveness of comments varies. The proposed model uses tfidf followed by Ridge Regression,Catboost Regression and BERT followed by dense layers. The study uses a dataset containing Reddit-comments written in English language with precise and calculated values ranging from -1 to 1. Best-Worst Scaling was used to annotate the dataset, a type of comparative annotation that has been found to reduce the biases associated with rating scales. It has been demonstrated that the technique gives extremely accurate offensiveness scores. The proposed method offers user to customize their own threshold of offensiveness. The experiments has been conducted with different n-gram ranges. The result reveals better performance than state of the art.",2644-3163,,978-1-6654-6316-4,353-0358,IEEE , ,Toxicology;Social networking (online);Annotations;Bit error rate;Mental health;Transformers;Mobile communication,,
4662,"Title:Toxicity and safety study of Cd-based and Cd-free quantum dots in third-gen PV and scaled-up processing platforms

 Quantum dots (QDs) are being incorporated at an accelerated rate into Third-Gen photovoltaic (PV) and scaled-up PV processing platforms for production of high efficiency devices. As a result, studies are needed to examine QD toxicity in workplace environment. Herein, we report on a rapid and sensitive detection methods to examine risk of QD exposure in PV processing. QD-associated toxic elements were detected in slight amounts using gold nanoparticles (Au NPs) probe, followed by photoluminescence and Inductively Coupled Plasma-Mass Spectroscopy (ICP-MS) analyses, which indicated the possibility of QD aerosolization during deposition, transferring and testing of the QD film. Cytotoxicity effects of different type QDs were also studied using cell culture viability. The results indicate that QD material and their coating are important factors in producing cytotoxicity effects. It was also demonstrated that CIS QDs have less cytotoxic effects on HeLa and CHSE cells than CdSe QDs, and may be considered non-toxic in comparison.",B. Sadeghimakki; Y. Zheng; N. M. S. Jahed; R. S. Tarighat; P. H. Pham; J. J. Kim; N. C. Bols; S. Sivoththaman,,,Toxicity and safety study of Cd-based and Cd-free quantum dots in third-gen PV and scaled-up processing platforms,,,10.1109/PVSC.2016.7750342 ,IEEE Conferences ,,"Quantum dots (QDs) are being incorporated at an accelerated rate into Third-Gen photovoltaic (PV) and scaled-up PV processing platforms for production of high efficiency devices. As a result, studies are needed to examine QD toxicity in workplace environment. Herein, we report on a rapid and sensitive detection methods to examine risk of QD exposure in PV processing. QD-associated toxic elements were detected in slight amounts using gold nanoparticles (Au NPs) probe, followed by photoluminescence and Inductively Coupled Plasma-Mass Spectroscopy (ICP-MS) analyses, which indicated the possibility of QD aerosolization during deposition, transferring and testing of the QD film. Cytotoxicity effects of different type QDs were also studied using cell culture viability. The results indicate that QD material and their coating are important factors in producing cytotoxicity effects. It was also demonstrated that CIS QDs have less cytotoxic effects on HeLa and CHSE cells than CdSe QDs, and may be considered non-toxic in comparison.",,,978-1-5090-2724-8,3593-3597,IEEE , ,Gold;Coatings;II-VI semiconductor materials;Cadmium compounds;Films;Monitoring;Spectroscopy,,
4663,"Title:Reproducibility of measurement of organophosphorous pesticides toxicity

 Fast detection of pesticide toxicity in the field conditions is very important in many aspects (pesticide storage, price of one test etc.). The measurement uses principle of an artificial synapse (AS) and inhibition of an enzyme Acetylcholinesterase (AChE). The AS is a very effective detector of the pesticide detector. This information is very different from classical analytic method data. The enzyme is sensitive to many external influences and its function is significantly influenced by immobilization process. Therefore properties of the sensor have to be measured without AChE at first. This process is called input control of the sensor. The reproducibility of electrochemical detector was studied first using hydrogen peroxide and second ferri-ferrokyanide redox couple. Longterm stability and reproducibility of preparation of enzymatic layer were studied. Cell data was evaluated statistically. This article describes measurement on AS and determination properties of electrochemical sensor before immobilization of enzymes by hydrogen peroxide.",K. Fujcik; R. Vrba; J. Prasek; Z. Grosmanova; J. Krejci,,,Reproducibility of measurement of organophosphorous pesticides toxicity,1,,10.1109/ICSENS.2003.1279018 ,IEEE Conferences ,,"Fast detection of pesticide toxicity in the field conditions is very important in many aspects (pesticide storage, price of one test etc.). The measurement uses principle of an artificial synapse (AS) and inhibition of an enzyme Acetylcholinesterase (AChE). The AS is a very effective detector of the pesticide detector. This information is very different from classical analytic method data. The enzyme is sensitive to many external influences and its function is significantly influenced by immobilization process. Therefore properties of the sensor have to be measured without AChE at first. This process is called input control of the sensor. The reproducibility of electrochemical detector was studied first using hydrogen peroxide and second ferri-ferrokyanide redox couple. Longterm stability and reproducibility of preparation of enzymatic layer were studied. Cell data was evaluated statistically. This article describes measurement on AS and determination properties of electrochemical sensor before immobilization of enzymes by hydrogen peroxide.",,,0-7803-8133-5,651-655 Vol.1,IEEE , ,Reproducibility of results;Biosensors;Testing;Biochemistry;Sensor phenomena and characterization;Detectors;Biomembranes;Performance analysis;Electrodes;Electrical capacitance tomography,,
4664,"Title:The diagnostic value of [18F]-FDG-PET/CT in hematopoietic radiation toxicity: a Tibet minipig model

 This study was undertaken to assess the diagnostic value of 2-[18F]-fluoro-2-deoxy-D-glucose positron emission tomography with computed tomography ([18F]-FDG-PET/CT) in the detection of radiation toxicity in normal bone marrow using Tibet minipigs as a model. Eighteen Tibet minipigs were caged in aseptic rooms and randomly divided into six groups. Five groups (n = 3/group) were irradiated with single doses of 2, 5, 8, 11 and 14 Gy of total body irradiation (TBI) using an 8-MV X-ray linear accelerator. These pigs were evaluated with [18F]-FDG-PET/CT, and their marrow nucleated cells were counted. The data were initially collected at 6, 24 and 72 h after treatment and were then collected on Days 5–60 post-TBI at 5-day intervals. At 24 and 72 h post-TBI, marrow standardized uptake value (SUV) data showed a dose-dependent decrease in the radiation dose range from 2–8 Gy. Upon long-term observation, SUV and marrow nucleated cell number in the 11-Gy and 14-Gy groups showed a continuous and marked reduction throughout the entire time course, while Kaplan–Meier curves of survival showed low survival. In contrast, the SUVs in the 2-, 5- and 8-Gy groups showed early transient increases followed by a decline from approximately 72 h through Days 5–15 and then normalized or maintained low levels through the endpoint; marrow nucleated cell number and survival curves showed approximately the same trend and higher survival, respectively. Our findings suggest that [18F]-FDG-PET/CT may be helpful in quickly assessing the absorbed doses and predicting the prognosis in patients.",C. Chen; L. Yan; K. Guo; Y. Wang; F. Zou; W. Gu; H. Tang; Y. Li; S. Wu,,,The diagnostic value of [18F]-FDG-PET/CT in hematopoietic radiation toxicity: a Tibet minipig model,53,4,10.1093/jrr/rrs006 ,OUP Journals ,,"This study was undertaken to assess the diagnostic value of 2-[18F]-fluoro-2-deoxy-D-glucose positron emission tomography with computed tomography ([18F]-FDG-PET/CT) in the detection of radiation toxicity in normal bone marrow using Tibet minipigs as a model. Eighteen Tibet minipigs were caged in aseptic rooms and randomly divided into six groups. Five groups (n = 3/group) were irradiated with single doses of 2, 5, 8, 11 and 14 Gy of total body irradiation (TBI) using an 8-MV X-ray linear accelerator. These pigs were evaluated with [18F]-FDG-PET/CT, and their marrow nucleated cells were counted. The data were initially collected at 6, 24 and 72 h after treatment and were then collected on Days 5–60 post-TBI at 5-day intervals. At 24 and 72 h post-TBI, marrow standardized uptake value (SUV) data showed a dose-dependent decrease in the radiation dose range from 2–8 Gy. Upon long-term observation, SUV and marrow nucleated cell number in the 11-Gy and 14-Gy groups showed a continuous and marked reduction throughout the entire time course, while Kaplan–Meier curves of survival showed low survival. In contrast, the SUVs in the 2-, 5- and 8-Gy groups showed early transient increases followed by a decline from approximately 72 h through Days 5–15 and then normalized or maintained low levels through the endpoint; marrow nucleated cell number and survival curves showed approximately the same trend and higher survival, respectively. Our findings suggest that [18F]-FDG-PET/CT may be helpful in quickly assessing the absorbed doses and predicting the prognosis in patients.",1349-9157,,,537-544,OUP , ,,,
4665,"Title:Discrimination analysis of structure-toxicity relationships on silatranes by artificial neural network

 The structure-toxicity relationships of silatranes was studied by using backpropagation model which is one of the typical artificial neural networks. A group of samples were collected as an object of study. The results of chemical experiment and toxic detection showed that the successful rate reached 100%. Therefore the performance of the neural network approach is good, and it might be referred as an effective assistant technique for analysis of structure-activity relationships of medicine.<>",Yudong Cai,,,Discrimination analysis of structure-toxicity relationships on silatranes by artificial neural network,5,,10.1109/ICNN.1994.374731 ,IEEE Conferences ,,"The structure-toxicity relationships of silatranes was studied by using backpropagation model which is one of the typical artificial neural networks. A group of samples were collected as an object of study. The results of chemical experiment and toxic detection showed that the successful rate reached 100%. Therefore the performance of the neural network approach is good, and it might be referred as an effective assistant technique for analysis of structure-activity relationships of medicine.<>",,,0-7803-1901-X,3116-3120 vol.5,IEEE , ,Artificial neural networks;Neural networks;Cities and towns;Computer aided instruction;Chemical technology;Toxic chemicals;Hair;Network synthesis;Proteins;Chemical compounds,,
4666,"Title:Real-time measurement of toxicity: Application to nanotechnology and synthetic pathogens

 Cellular based biosensing can serve as an effective method for detection of unknown toxins by monitoring cellular response. Electric cell-substrate impedance sensing (ECIS) does this by measuring the impedance of a cell monolayer grown on interdigitated gold electrodes. This is done in situ and in real time without disrupting the monolayer. As the monolayer settles and grows to confluence an increase in resistance is seen. The formation of tight junctions between the cells increases the resistance further until the resistance stabilizes with minor fluctuations due to micromotility. When the cells are exposed to a toxin a change in the barrier function, a measure of the resistance cause by tight junctions, is seen. This real time quantified data allows for continuous measurement of toxic exposure. Toxicity of copper nanoparticles (~100 nm) could be seen as low as 1 μg per 105 cells. Fluorescent stainingwas performed on parallel cultures to confirm the activity of the cells and the disruption of tight junctions over time.",B. Riggs; G. Plopper; J. P. Paluh; D. B. Chrisey,,,Real-time measurement of toxicity: Application to nanotechnology and synthetic pathogens,,,10.1109/NEBC.2011.5778668 ,IEEE Conferences ,,"Cellular based biosensing can serve as an effective method for detection of unknown toxins by monitoring cellular response. Electric cell-substrate impedance sensing (ECIS) does this by measuring the impedance of a cell monolayer grown on interdigitated gold electrodes. This is done in situ and in real time without disrupting the monolayer. As the monolayer settles and grows to confluence an increase in resistance is seen. The formation of tight junctions between the cells increases the resistance further until the resistance stabilizes with minor fluctuations due to micromotility. When the cells are exposed to a toxin a change in the barrier function, a measure of the resistance cause by tight junctions, is seen. This real time quantified data allows for continuous measurement of toxic exposure. Toxicity of copper nanoparticles (~100 nm) could be seen as low as 1 μg per 105 cells. Fluorescent stainingwas performed on parallel cultures to confirm the activity of the cells and the disruption of tight junctions over time.",2160-7028,,978-1-61284-828-0,1-2,IEEE , ,Junctions;Immune system;Nanoparticles;Resistance;Copper;Real time systems;Impedance,,
4667,"Title:A Silver-Based Miniature Gas Sensor for Hydrogen Sulfide Detection

 Hydrogen sulfide ( $\text{H}_{{2}}\text{S}$ ) exists widely in many industrial processes and natural environments. Due to its high toxicity and flammable, detection of  $\text{H}_{{2}}\text{S}$  is critical for safety and health at work place and industrial process control. In this article, we report a novel miniature gas sensor, which has a high selectivity in  $\text{H}_{{2}}\text{S}$  detection. The sensor is based on the principle of silver reacting with  $\text{H}_{{2}}\text{S}$  with a strict condition and a fast speed at high temperature. The limit of detection (LOD) is 1.4 parts-per-million (ppm) in ambient conditions and can be further reduced to ~ppb-lever by improving the working temperature and suppressing the noise of the sensor system. Compared with the conventional  $\text{H}_{{2}}\text{S}$  sensors, this sensor has advantages of miniaturization, low cost, high selectivity, and excluding electrolytes in the analyte detection.",X. Tian; Y. Li; J. Zhao; J. Tao,,,A Silver-Based Miniature Gas Sensor for Hydrogen Sulfide Detection,23,4,10.1109/JSEN.2022.3233815 ,IEEE Journals ,,"Hydrogen sulfide ( $\text{H}_{{2}}\text{S}$ ) exists widely in many industrial processes and natural environments. Due to its high toxicity and flammable, detection of  $\text{H}_{{2}}\text{S}$  is critical for safety and health at work place and industrial process control. In this article, we report a novel miniature gas sensor, which has a high selectivity in  $\text{H}_{{2}}\text{S}$  detection. The sensor is based on the principle of silver reacting with  $\text{H}_{{2}}\text{S}$  with a strict condition and a fast speed at high temperature. The limit of detection (LOD) is 1.4 parts-per-million (ppm) in ambient conditions and can be further reduced to ~ppb-lever by improving the working temperature and suppressing the noise of the sensor system. Compared with the conventional  $\text{H}_{{2}}\text{S}$  sensors, this sensor has advantages of miniaturization, low cost, high selectivity, and excluding electrolytes in the analyte detection.",1558-1748,,,3469-3474,IEEE , ,Sensors;Gas detectors;Temperature sensors;Electrodes;Silver;Heating systems;Stress,,
4668,"Title:Machine Learning Models for PFAS Tracking, Detection and Remediation: A Review

 Per- and polyfluoroalkyl substances (PFAS) are known for their persistence, toxicity, and potential to cause harm to human health and the environment. Traditional monitoring methods are often expensive and time-consuming. The paper provides a review of existing machine learning (ML) models for PFAS detection and treatment processes. The paper also highlights a ML workflow process for PFAS detection, remediation technologies, and the need for unified open-source database for PFAS assessment in water.",N. Andraju; G. Curtzwiler; Y. Ji; E. Kozliak; P. Ranganathan,,,"Machine Learning Models for PFAS Tracking, Detection and Remediation: A Review",,,10.1109/eIT57321.2023.10187291 ,IEEE Conferences ,,"Per- and polyfluoroalkyl substances (PFAS) are known for their persistence, toxicity, and potential to cause harm to human health and the environment. Traditional monitoring methods are often expensive and time-consuming. The paper provides a review of existing machine learning (ML) models for PFAS detection and treatment processes. The paper also highlights a ML workflow process for PFAS detection, remediation technologies, and the need for unified open-source database for PFAS assessment in water.",2154-0373,,978-1-6654-9376-5,137-142,IEEE , ,Toxicology;Databases;Machine learning;Information technology;Optimization;Monitoring,,
4669,"Title:Multi-Component Toxic Gas Monitoring System Based on Internet of Things

 A multi-component toxic gas monitoring system based on the Internet of Things was designed to solve the problem that the personal safety of the workers could not be guaranteed due to the presence of toxic gases in the contaminated site restoration environment. The s ystem integrates functions of Internet of Things technology, could data storage display, sound and light alarm, and real-time display of Android mobile phones to realize HCN, CO, H2S, NO2, NH3, SO2, etc. in the environment of contaminated sites. Real-time monitoring and early warning of toxic gases such as nitrogen oxides, ammonia and sulfur dioxide. In order to achieve the purpose of ensuring the personal safety of the staff, the restoration of the contaminated site is carried out efficiently, healthily and safety. The system can operate stably and can ensure the personal safety of the workers on the site of the contaminated site.",J. Zhu; Y. Fu; Y. Xing; Y. Zhang; Q. Qiao,,,Multi-Component Toxic Gas Monitoring System Based on Internet of Things,,,10.1109/ICMA.2019.8816612 ,IEEE Conferences ,,"A multi-component toxic gas monitoring system based on the Internet of Things was designed to solve the problem that the personal safety of the workers could not be guaranteed due to the presence of toxic gases in the contaminated site restoration environment. The s ystem integrates functions of Internet of Things technology, could data storage display, sound and light alarm, and real-time display of Android mobile phones to realize HCN, CO, H2S, NO2, NH3, SO2, etc. in the environment of contaminated sites. Real-time monitoring and early warning of toxic gases such as nitrogen oxides, ammonia and sulfur dioxide. In order to achieve the purpose of ensuring the personal safety of the staff, the restoration of the contaminated site is carried out efficiently, healthily and safety. The system can operate stably and can ensure the personal safety of the workers on the site of the contaminated site.",2152-744X,,978-1-7281-1699-0,769-773,IEEE , ,Monitoring;Maintenance engineering;Safety;Real-time systems;Servers;Gases;Soil,,
4670,"Title:Determination of Triclosan in Wastewater Using Solid Phase Extraction and High Performance Liquid Chromatography with Ultra-Violet Detection

 As fungicides or preservatives in pharmaceutical and personal care products (PPCPs), triclosan (TCS) is widespread in the environment. Under low concentration, the toxicity of triclosan is not obvious, but under certain conditions, it can be converted into other substances, whose toxicity has already caused concerns. A method for analysis of tricosan in water using solid phase extraction (SPE) and high performance liquid chromatography(HPLC) with Ultra-Violet(UV) detection was developed. Conditions of gradient elution and HPLC separation of the toxicant were also optimized. Detection limit of the method was found to be 3.91 ng/L. Relative standard deviation(RSD) was around 2.02 ~ 4.69%. The average recovery of triclosan was around 93.68~97.42%. With this method, water samples of three wastewater treatment plants in Shanghai were detected. Results showed that the concentration of triclosan ranged from 533 ng/L to 774 ng/L in raw wastewater samples and from 80.14 ng/L to 249.72 ng/L in the effluent samples. The removal efficiencies of the entire processes ranged from 62.59% to 67.74%.",X. Zhou; S. -B. Zhou; Y. Zhang; L. Shi,,,Determination of Triclosan in Wastewater Using Solid Phase Extraction and High Performance Liquid Chromatography with Ultra-Violet Detection,,,10.1109/ICBBE.2009.5162633 ,IEEE Conferences ,,"As fungicides or preservatives in pharmaceutical and personal care products (PPCPs), triclosan (TCS) is widespread in the environment. Under low concentration, the toxicity of triclosan is not obvious, but under certain conditions, it can be converted into other substances, whose toxicity has already caused concerns. A method for analysis of tricosan in water using solid phase extraction (SPE) and high performance liquid chromatography(HPLC) with Ultra-Violet(UV) detection was developed. Conditions of gradient elution and HPLC separation of the toxicant were also optimized. Detection limit of the method was found to be 3.91 ng/L. Relative standard deviation(RSD) was around 2.02 ~ 4.69%. The average recovery of triclosan was around 93.68~97.42%. With this method, water samples of three wastewater treatment plants in Shanghai were detected. Results showed that the concentration of triclosan ranged from 533 ng/L to 774 ng/L in raw wastewater samples and from 80.14 ng/L to 249.72 ng/L in the effluent samples. The removal efficiencies of the entire processes ranged from 62.59% to 67.74%.",2151-7622,,978-1-4244-2901-1,1-4,IEEE , ,Solids;Phase detection;Wastewater treatment;Effluents;Chemicals;Pollution control;Educational institutions;Pharmaceuticals;Performance analysis;Sediments,,
4671,"Title:WaveFlex Biosensor-Using Novel Tri-Tapered-in-Tapered Four-Core Fiber With Multimode Fiber Coupling for Detection of Aflatoxin B1

 Aflatoxins are a kind of fungal toxin that causes great damage to humans and animals due to its wide distribution, secretive nature, and high toxicity. For the purpose of achieving qualitative and quantitative detection of aflatoxin B1 (AFB1), a novel tri-taper-in-taper fiber-optic structure based on core mismatch of four-core fiber with a multimode fiber-based WaveFlex biosensor is developed and tested. The sensor probe's surface is coated with gold nanoparticles (AuNPs). Multi-walled carbon nanotubes and zinc oxide nanoparticles are sequentially immobilized on the sensing probe surface to enhance the sensor's sensing capabilities. Then, the AFB1 antibody is utilized to functionalize the sensor to possess specific selectivity. After the modification of nanomaterials and the corresponding bioreceptors, the final sensor structure is formed. By stimulating the localized surface plasmon resonance phenomenon of AuNPs, different concentrations of AFB1 can be detected. The sensor demonstrates high sensitivity (38.29 nm/μM) as well as low LOD (7.12 nM) within the range of 0–100 nM for detection. The sensor is also found to be stable and reproducible in repeated measurements, indicating its potential for practical application. Additionally, it exhibits satisfactory specific recognition of AFB1. These results show that AFB1 can be detected in food and agricultural products using LSPR-based optical fiber sensors, which could have significant ramifications for public health and food safety.",X. Liu; R. Singh; G. Li; C. Marques; B. Zhang; S. Kumar,,,WaveFlex Biosensor-Using Novel Tri-Tapered-in-Tapered Four-Core Fiber With Multimode Fiber Coupling for Detection of Aflatoxin B1,41,24,10.1109/JLT.2023.3301069 ,IEEE Journals ,,"Aflatoxins are a kind of fungal toxin that causes great damage to humans and animals due to its wide distribution, secretive nature, and high toxicity. For the purpose of achieving qualitative and quantitative detection of aflatoxin B1 (AFB1), a novel tri-taper-in-taper fiber-optic structure based on core mismatch of four-core fiber with a multimode fiber-based WaveFlex biosensor is developed and tested. The sensor probe's surface is coated with gold nanoparticles (AuNPs). Multi-walled carbon nanotubes and zinc oxide nanoparticles are sequentially immobilized on the sensing probe surface to enhance the sensor's sensing capabilities. Then, the AFB1 antibody is utilized to functionalize the sensor to possess specific selectivity. After the modification of nanomaterials and the corresponding bioreceptors, the final sensor structure is formed. By stimulating the localized surface plasmon resonance phenomenon of AuNPs, different concentrations of AFB1 can be detected. The sensor demonstrates high sensitivity (38.29 nm/μM) as well as low LOD (7.12 nM) within the range of 0–100 nM for detection. The sensor is also found to be stable and reproducible in repeated measurements, indicating its potential for practical application. Additionally, it exhibits satisfactory specific recognition of AFB1. These results show that AFB1 can be detected in food and agricultural products using LSPR-based optical fiber sensors, which could have significant ramifications for public health and food safety.",1558-2213,,,7432-7442,IEEE , ,Optical fiber sensors;Optical surface waves;Optical fiber couplers;Surface plasmons;Carbon nanotubes;Zinc oxide;Nanoparticles,,
4672,"Title:Graphene-antimonene coated tapered fiber optic surface plasmon resonance sensor for the detection of Hg2+ heavy metal ions

 The environment has been severely polluted by heavy metal ions because of their high degree of toxicity. In this paper, we have designed a tapered fiber optic surface plasmon resonance sensor by depositing a thin film of gold (Au) on a tapered core followed by the deposition of graphene and antimonene overlayers. The fiber optic sensing probe was then utilized for the detection of mercury (Hg2+) heavy metal ions in water of concentration ranging from 70 ppm to 1000 ppm. For theoretical study, we have considered four different taper profiles i.e., exponential-linear, linear, parabolic, and quadratic. The sensitivity is calculated for each taper profile at taper ratios 1.0 and 1.5. The numerical results show that the sensitivity increases with increase in taper ratio and maximum value is observed for exponential-linear taper profile. For an exponential-linear taper profile at taper ratio 1.5, the average sensitivity was observed to be 0.0337 nm/ppm with limit of detection as 1 ppm for the detection of Hg2+ heavy metal ions. The observed sensitivity is 26% higher than the sensitivity observed at taper ratio 1.0 (i.e., for untapered fiber core).",Vikas; P. Saccomandi,,,Graphene-antimonene coated tapered fiber optic surface plasmon resonance sensor for the detection of Hg2+ heavy metal ions,,,10.1109/MetroLivEnv56897.2023.10164047 ,IEEE Conferences ,,"The environment has been severely polluted by heavy metal ions because of their high degree of toxicity. In this paper, we have designed a tapered fiber optic surface plasmon resonance sensor by depositing a thin film of gold (Au) on a tapered core followed by the deposition of graphene and antimonene overlayers. The fiber optic sensing probe was then utilized for the detection of mercury (Hg2+) heavy metal ions in water of concentration ranging from 70 ppm to 1000 ppm. For theoretical study, we have considered four different taper profiles i.e., exponential-linear, linear, parabolic, and quadratic. The sensitivity is calculated for each taper profile at taper ratios 1.0 and 1.5. The numerical results show that the sensitivity increases with increase in taper ratio and maximum value is observed for exponential-linear taper profile. For an exponential-linear taper profile at taper ratio 1.5, the average sensitivity was observed to be 0.0337 nm/ppm with limit of detection as 1 ppm for the detection of Hg2+ heavy metal ions. The observed sensitivity is 26% higher than the sensitivity observed at taper ratio 1.0 (i.e., for untapered fiber core).",,,978-1-6654-5693-7,55-59,IEEE , ,Optical fibers;Optical fiber sensors;Gold;Sensitivity;Toxicology;Ions;Sensors,,
4673,"Title:A Potential Causal Association Mining Algorithm for Screening Adverse Drug Reactions in Postmarketing Surveillance

 Early detection of unknown adverse drug reactions (ADRs) in postmarketing surveillance saves lives and prevents harmful consequences. We propose a novel data mining approach to signaling potential ADRs from electronic health databases. More specifically, we introduce potential causal association rules (PCARs) to represent the potential causal relationship between a drug and ICD-9 (CDC. (2010). International Classification of Diseases, Ninth Revision (ICD-9). [Online]. Available: http://www.cdc.gov/nchs/icd/icd9.html) coded signs or symptoms representing potential ADRs. Due to the infrequent nature of ADRs, the existing frequency-based data mining methods cannot effectively discover PCARs. We introduce a new interestingness measure, potential causal leverage, to quantify the degree of association of a PCAR. This measure is based on the computational, experience-based fuzzy recognition-primed decision (RPD) model that we developed previously (Y. Ji, R. M. Massanari, J. Ager, J. Yen, R. E. Miller, and H. Ying, “A fuzzy logic-based computational recognition-primed decision model,” Inf. Sci., vol. 177, pp. 4338-4353, 2007) on the basis of the well-known, psychology-originated qualitative RPD model (G. A. Klein, “A recognition-primed decision making model of rapid decision making,” in Decision Making in Action: Models and Methods, 1993, pp. 138-147). The potential causal leverage assesses the strength of the association of a drug-symptom pair given a collection of patient cases. To test our data mining approach, we retrieved electronic medical data for 16 206 patients treated by one or more than eight drugs of our interest at the Veterans Affairs Medical Center in Detroit between 2007 and 2009. We selected enalapril as the target drug for this ADR signal generation study. We used our algorithm to preliminarily evaluate the associations between enalapril and all the ICD-9 codes associated with it. The experimental results indicate that our approach has a potential to better signal potential ADRs than risk ratio and leverage, two traditional frequency-based measures. Among the top 50 signal pairs (i.e., enalapril versus symptoms) ranked by the potential causal-leverage measure, the physicians on the project determined that eight of them probably represent true causal associations.",Y. Ji; H. Ying; P. Dews; A. Mansour; J. Tran; R. E. Miller; R. M. Massanari,,,A Potential Causal Association Mining Algorithm for Screening Adverse Drug Reactions in Postmarketing Surveillance,15,3,10.1109/TITB.2011.2131669 ,IEEE Journals ,,"Early detection of unknown adverse drug reactions (ADRs) in postmarketing surveillance saves lives and prevents harmful consequences. We propose a novel data mining approach to signaling potential ADRs from electronic health databases. More specifically, we introduce potential causal association rules (PCARs) to represent the potential causal relationship between a drug and ICD-9 (CDC. (2010). International Classification of Diseases, Ninth Revision (ICD-9). [Online]. Available: http://www.cdc.gov/nchs/icd/icd9.html) coded signs or symptoms representing potential ADRs. Due to the infrequent nature of ADRs, the existing frequency-based data mining methods cannot effectively discover PCARs. We introduce a new interestingness measure, potential causal leverage, to quantify the degree of association of a PCAR. This measure is based on the computational, experience-based fuzzy recognition-primed decision (RPD) model that we developed previously (Y. Ji, R. M. Massanari, J. Ager, J. Yen, R. E. Miller, and H. Ying, “A fuzzy logic-based computational recognition-primed decision model,” Inf. Sci., vol. 177, pp. 4338-4353, 2007) on the basis of the well-known, psychology-originated qualitative RPD model (G. A. Klein, “A recognition-primed decision making model of rapid decision making,” in Decision Making in Action: Models and Methods, 1993, pp. 138-147). The potential causal leverage assesses the strength of the association of a drug-symptom pair given a collection of patient cases. To test our data mining approach, we retrieved electronic medical data for 16 206 patients treated by one or more than eight drugs of our interest at the Veterans Affairs Medical Center in Detroit between 2007 and 2009. We selected enalapril as the target drug for this ADR signal generation study. We used our algorithm to preliminarily evaluate the associations between enalapril and all the ICD-9 codes associated with it. The experimental results indicate that our approach has a potential to better signal potential ADRs than risk ratio and leverage, two traditional frequency-based measures. Among the top 50 signal pairs (i.e., enalapril versus symptoms) ranked by the potential causal-leverage measure, the physicians on the project determined that eight of them probably represent true causal associations.",1558-0032,,,428-437,IEEE , ,Drugs;Association rules;Electric potential;Frequency measurement;Databases;Computational modeling,,
4674,"Title:1024-Pixel CMOS Multimodality Joint Cellular Sensor/Stimulator Array for Real-Time Holistic Cellular Characterization and Cell-Based Drug Screening

 This paper presents a fully integrated CMOS multimodality joint sensor/stimulator array with 1024 pixels for real-time holistic cellular characterization and drug screening. The proposed system consists of four pixel groups and four parallel signal-conditioning blocks. Every pixel group contains 16 × 16 pixels, and each pixel includes one 28 μm × 28 μm gold-plated electrode, four 12 μm × 12 μm photodiodes, and in-pixel circuits, within a 58 μm × 58 μm pixel footprint. Each pixel supports realtime extracellular potential recording, optical detection, chargebalanced biphasic current stimulation, and cellular impedance measurement for the same cellular sample. The proposed system is fabricated in a standard 130-nm CMOS process. Rat cardiomyocytes are successfully cultured on-chip. Measured high-resolution optical opacity images, extracellular potential recordings, biphasic current stimulations, and cellular impedance images demonstrate the unique advantages of the system for holistic cell characterization and drug screening. Furthermore, this paper demonstrates the use of optical detection on the on-chip cultured cardiomyocytes to real-time track their cyclic beating pattern and beating rate.",J. S. Park; M. K. Aziz; S. Li; T. Chi; S. I. Grijalva; J. H. Sung; H. C. Cho; H. Wang,,,1024-Pixel CMOS Multimodality Joint Cellular Sensor/Stimulator Array for Real-Time Holistic Cellular Characterization and Cell-Based Drug Screening,12,1,10.1109/TBCAS.2017.2759220 ,IEEE Journals ,,"This paper presents a fully integrated CMOS multimodality joint sensor/stimulator array with 1024 pixels for real-time holistic cellular characterization and drug screening. The proposed system consists of four pixel groups and four parallel signal-conditioning blocks. Every pixel group contains 16 × 16 pixels, and each pixel includes one 28 μm × 28 μm gold-plated electrode, four 12 μm × 12 μm photodiodes, and in-pixel circuits, within a 58 μm × 58 μm pixel footprint. Each pixel supports realtime extracellular potential recording, optical detection, chargebalanced biphasic current stimulation, and cellular impedance measurement for the same cellular sample. The proposed system is fabricated in a standard 130-nm CMOS process. Rat cardiomyocytes are successfully cultured on-chip. Measured high-resolution optical opacity images, extracellular potential recordings, biphasic current stimulations, and cellular impedance images demonstrate the unique advantages of the system for holistic cell characterization and drug screening. Furthermore, this paper demonstrates the use of optical detection on the on-chip cultured cardiomyocytes to real-time track their cyclic beating pattern and beating rate.",1940-9990,,,80-94,IEEE , ,Optical sensors;Drugs;Biomedical optical imaging;Optical recording;Extracellular;Impedance,,
4675,"Title:Application of a Smartphone-based SPR platform for Glyphosate detection

 Glyphosate is widely used in the control of agricultural crops due to its high efficiency in weed removal. Pertaining to Class IV pesticides, which classify the herbicides of low toxicity, current studies prove that glyphosate can cause acute and chronic damage to human health. The search for simpler methods for its detection and quantification is still a challenge. Current detection technologies require expensive resources, as well as making it impossible to detect them in the field in real time. This work presents the studies aimed at the application of a multi-analytical and portable analysis platform for the detection of glyphosate, seeking the possibility of its day-to-day detection in a simple, effective and real-time way. The platform used in this work is a Smartphone-based SPR (Surface Plasmon Resonance) Biosensor Device that transforms a commercial portable computing device into an effective tool for analyzing substances, aiding traditional methods and allowing them to be applied in difficult access locations in real time.",C. d. Silva Freire; C. da Silva Moreira; C. A. de Souza Filho; R. Moreno Santa Cruz; A. Falqueto; A. L. Valle; L. R. Goulart Filho; E. Souto de Medeiros; K. d. Nascimento Ferreira,,,Application of a Smartphone-based SPR platform for Glyphosate detection,,,10.1109/SAS.2019.8706024 ,IEEE Conferences ,,"Glyphosate is widely used in the control of agricultural crops due to its high efficiency in weed removal. Pertaining to Class IV pesticides, which classify the herbicides of low toxicity, current studies prove that glyphosate can cause acute and chronic damage to human health. The search for simpler methods for its detection and quantification is still a challenge. Current detection technologies require expensive resources, as well as making it impossible to detect them in the field in real time. This work presents the studies aimed at the application of a multi-analytical and portable analysis platform for the detection of glyphosate, seeking the possibility of its day-to-day detection in a simple, effective and real-time way. The platform used in this work is a Smartphone-based SPR (Surface Plasmon Resonance) Biosensor Device that transforms a commercial portable computing device into an effective tool for analyzing substances, aiding traditional methods and allowing them to be applied in difficult access locations in real time.",,,978-1-5386-7713-1,1-6,IEEE , ,Biosensors;Cameras;Optical surface waves;Biomedical optical imaging;Surface plasmons;Optical fiber sensors,,
4676,"Title:Leakage Detection of Natural Gas Pipeline Based on an Embedded System

 Natural gas, which is treated as an alternative to the depleting supplies of oil, is widely used for fuel and electricity production. The use of natural gas in the world depends upon the thousands miles of natural gas pipeline networks that have been set up in few decades. The safe operation of these complex systems is of significant importance due to the intrinsic characteristics of hydrocarbons such as: toxicity, flammability and explosion velocity. In this work, a real-time leakage monitoring model of the long distance natural gas pipeline is proposed. And a leakage detection and localization mechanisms based on the above model were studied. In order to test the performance of the provided method, a networked data acquisition and analysis system was built. Through application to a practical system, it is verified that the proposed system is effective in gas leakage detection.",B. Zhu; F. Yao; S. Chai,,,Leakage Detection of Natural Gas Pipeline Based on an Embedded System,1,,10.1109/ISCID.2014.196 ,IEEE Conferences ,,"Natural gas, which is treated as an alternative to the depleting supplies of oil, is widely used for fuel and electricity production. The use of natural gas in the world depends upon the thousands miles of natural gas pipeline networks that have been set up in few decades. The safe operation of these complex systems is of significant importance due to the intrinsic characteristics of hydrocarbons such as: toxicity, flammability and explosion velocity. In this work, a real-time leakage monitoring model of the long distance natural gas pipeline is proposed. And a leakage detection and localization mechanisms based on the above model were studied. In order to test the performance of the provided method, a networked data acquisition and analysis system was built. Through application to a practical system, it is verified that the proposed system is effective in gas leakage detection.",,,978-1-4799-7005-6,289-292,IEEE , ,Pipelines;Natural gas;Heat transfer;Embedded systems;Monitoring;Data acquisition;Genetic algorithms,,
4677,"Title:A Fluorescence Resonance Energy Transfer-Based Molecular Probe for Cisplatin Detection

 Cisplatin, one of the most widely used clinical medications in the field of cancer chemotherapy, which is an indispensable drug type in traditional chemotherapy. Due to the significant toxicity and side effects of typical chemotherapy medications, precise drug concentration monitoring becomes the key. However, because of individual variances, various individuals’ metabolic capacities to medications vary, resulting in differences in actual blood drug concentration in the body under the same dosage. Therefore, it is imperative to create a new low-cost and rapid detection method for the concentration of serum active cisplatin, which is crucial to the chemotherapy effect and quality of life for cancer patients. In this work, based on the chemically cross-linked reaction between active cisplatin and DNA bases, as well as the high sensitivity of Fluorescence Resonance Energy Transfer (FRET), we proposed a new FRET-based method for detecting serum active cisplatin concentration. We constructed a fluorescent molecular probe with a dumbbell shape consisting of graphene quantum dots (GQDs) modified with carboxyl, gold nanoparticles (AuNPs), and a single-stranded DNA (ssDNA) sequence. The results reveal that the molecular probe has a strong linear correlation across the active cisplatin concentration range of 52-832 µM. This method can accomplish low-cost, rapid and simple detection of active cisplatin concentration, and further advancements in this work can give a decision-making basis for tailored and accurate cancer treatment.",C. Ji; C. Xue; G. J. Chen; Y. Guo; D. Luo; P. P. Shum,,,A Fluorescence Resonance Energy Transfer-Based Molecular Probe for Cisplatin Detection,,,10.1109/OGC59456.2023.10314627 ,IEEE Conferences ,,"Cisplatin, one of the most widely used clinical medications in the field of cancer chemotherapy, which is an indispensable drug type in traditional chemotherapy. Due to the significant toxicity and side effects of typical chemotherapy medications, precise drug concentration monitoring becomes the key. However, because of individual variances, various individuals’ metabolic capacities to medications vary, resulting in differences in actual blood drug concentration in the body under the same dosage. Therefore, it is imperative to create a new low-cost and rapid detection method for the concentration of serum active cisplatin, which is crucial to the chemotherapy effect and quality of life for cancer patients. In this work, based on the chemically cross-linked reaction between active cisplatin and DNA bases, as well as the high sensitivity of Fluorescence Resonance Energy Transfer (FRET), we proposed a new FRET-based method for detecting serum active cisplatin concentration. We constructed a fluorescent molecular probe with a dumbbell shape consisting of graphene quantum dots (GQDs) modified with carboxyl, gold nanoparticles (AuNPs), and a single-stranded DNA (ssDNA) sequence. The results reveal that the molecular probe has a strong linear correlation across the active cisplatin concentration range of 52-832 µM. This method can accomplish low-cost, rapid and simple detection of active cisplatin concentration, and further advancements in this work can give a decision-making basis for tailored and accurate cancer treatment.",,,979-8-3503-2532-4,156-160,IEEE , ,Drugs;Chemotherapy;Toxicology;Sensitivity;Shape;Quantum dots;DNA,,
4678,"Title:Poisonous Chemical Sensing Using Highly Sensitive Terahertz Photonic Crystal Fiber Sensor

 We propose two hollow core photonic crystal fiber (PCF) based sensors for the detection of toxic chemical like hydrogen cyanide (HCN) in the terahertz range. Because of its high level of toxicity and the potential threat it poses to humans, it is imperative to have a malleable and proficient method for HCN detection. Among the two proposed PCF sensors, the sensor which has octagonal shaped hollow core with a circular shaped air hole in the cladding provides a high relative sensitivity of 92.08% and a low confinement loss at 1.4 THz frequency.",S. S. Mahmud; M. T. Islam; S. M. Atiqullah,,,Poisonous Chemical Sensing Using Highly Sensitive Terahertz Photonic Crystal Fiber Sensor,,,10.1109/EICT48899.2019.9068856 ,IEEE Conferences ,,"We propose two hollow core photonic crystal fiber (PCF) based sensors for the detection of toxic chemical like hydrogen cyanide (HCN) in the terahertz range. Because of its high level of toxicity and the potential threat it poses to humans, it is imperative to have a malleable and proficient method for HCN detection. Among the two proposed PCF sensors, the sensor which has octagonal shaped hollow core with a circular shaped air hole in the cladding provides a high relative sensitivity of 92.08% and a low confinement loss at 1.4 THz frequency.",,,978-1-7281-6040-5,1-5,IEEE , ,Sensitivity;Sensors;Hydrogen;Optical losses;Shape;Refractive index,,
4679,"Title:Sexual Harassment Detection using Machine Learning and Deep Learning Techniques for Bangla Text

 Harassment is a kind of act that annoys or upsets someone. Harassment can be classified into different categories. Sexual harassment is one of them. Sexual harassment is a type of harassment that involves the use of implicit or explicit sexual overtones, including the inappropriate and unwelcome promises of rewards in exchange for sexual favors. At present time, the technology has become more advance and spread all over the place. That gave the toxic people a huge opportunity to spread toxicity in online platforms. Because of the increasing amount Bangla text in different social media platforms, we also need to filter such kinds of offensive Bangla texts. The objective of this research is to detect sexual harassment from Bangla text and classify them by using machine learning and deep learning algorithms as well as prevents them. In the experiment, we combined TF-IDF with different machine learning algorithms like Naive Bayes, Decision Tree, Random Forest, AdaBoost, SGD, Logistic Regression, KNN, SVM and got accuracy of 74.9%, 75.6%, 70.0%, 70.1%, 75.2%, 75.7%, 65.2%, 76.5% respectively. Deep learning algorithms like CNN, LSTM, hybrid CNN-LSTM were also used and achieved accuracy of 89% for all of them which is comparatively better than machine learning techniques.",M. Islam; M. Rahman; M. T. Ahmed; A. Z. Muhammad Islam; D. Das; M. M. Hoque,,,Sexual Harassment Detection using Machine Learning and Deep Learning Techniques for Bangla Text,,,10.1109/ECCE57851.2023.10101522 ,IEEE Conferences ,,"Harassment is a kind of act that annoys or upsets someone. Harassment can be classified into different categories. Sexual harassment is one of them. Sexual harassment is a type of harassment that involves the use of implicit or explicit sexual overtones, including the inappropriate and unwelcome promises of rewards in exchange for sexual favors. At present time, the technology has become more advance and spread all over the place. That gave the toxic people a huge opportunity to spread toxicity in online platforms. Because of the increasing amount Bangla text in different social media platforms, we also need to filter such kinds of offensive Bangla texts. The objective of this research is to detect sexual harassment from Bangla text and classify them by using machine learning and deep learning algorithms as well as prevents them. In the experiment, we combined TF-IDF with different machine learning algorithms like Naive Bayes, Decision Tree, Random Forest, AdaBoost, SGD, Logistic Regression, KNN, SVM and got accuracy of 74.9%, 75.6%, 70.0%, 70.1%, 75.2%, 75.7%, 65.2%, 76.5% respectively. Deep learning algorithms like CNN, LSTM, hybrid CNN-LSTM were also used and achieved accuracy of 89% for all of them which is comparatively better than machine learning techniques.",,,979-8-3503-4536-0,1-6,IEEE , ,Deep learning;Support vector machines;Machine learning algorithms;Toxicology;Cyberbullying;Filtering algorithms;Classification algorithms,,
4680,"Title:Acute and Chronic Effects of Tributyltin of the Mysid Acanthomysis sculpta (Crustacea, Mysidacea)

 Acute and chronic toxicity testing with tributyltin (TBT) leachate derived from panels painted with antifouling paint was performed using the mysid species Acanthomysis sculpta (Crustacea, Mysidacea) . Chronic tests were performed in a flow-through dosing regime ranging in concentrations from 0.03 to 0.52 ug/L TBT. A 96-hr static renewal acute toxicity test was performed within a dose range of 0.25 to 0.66 ug/L TBT. In all experiments TBT was measured by hydride derivatization and atomic absorption detection. A 96-h LC50 value for juveniles was determined at 0.42 ug/L TBT. Reproductive effects were the most sensitive sublethal indicator of TBT toxicity. A chronic value of 0.14 ug/l TBT was determined above which a significantly reduced release of viable juveniles was apparent. Length and weight, in adult females, were affected in concentrations above 0.31 ug/L TBT. Based on the 96-hr LC-50 and the most sensitive chronic value measured, that for reproduction, an acute/chronic ratio of 3.0 was calculated.",B. Davidson; A. Valkirs; P. Seligman,,,"Acute and Chronic Effects of Tributyltin of the Mysid Acanthomysis sculpta (Crustacea, Mysidacea)",,,10.1109/OCEANS.1986.1160365 ,IEEE Conferences ,,"Acute and chronic toxicity testing with tributyltin (TBT) leachate derived from panels painted with antifouling paint was performed using the mysid species Acanthomysis sculpta (Crustacea, Mysidacea) . Chronic tests were performed in a flow-through dosing regime ranging in concentrations from 0.03 to 0.52 ug/L TBT. A 96-hr static renewal acute toxicity test was performed within a dose range of 0.25 to 0.66 ug/L TBT. In all experiments TBT was measured by hydride derivatization and atomic absorption detection. A 96-h LC50 value for juveniles was determined at 0.42 ug/L TBT. Reproductive effects were the most sensitive sublethal indicator of TBT toxicity. A chronic value of 0.14 ug/l TBT was determined above which a significantly reduced release of viable juveniles was apparent. Length and weight, in adult females, were affected in concentrations above 0.31 ug/L TBT. Based on the 96-hr LC-50 and the most sensitive chronic value measured, that for reproduction, an acute/chronic ratio of 3.0 was calculated.",,,,1219-1225,IEEE , ,Testing;Organisms;Laboratories;Paints;Performance evaluation;Coatings;Risk management;Chemistry;Animals;Availability,,
4681,"Title:Design of a liver tissue biosensor

 Summary form only given. The threat of chemical and biological attack is becoming increasingly more likely. Since the liver metabolizes xenobiotic species, construction of a liver tissue based biosensor allows the detection of a wide range of harmful agents by detecting physiological changes in cultured liver cells. Previously, the development of such technology has been limited since traditional 2D culturing methods lead to dedifferentiation and loss of hepatic functions within hours to days. By recreating a 3D culture environment similar to the acinus in the liver, maintenance of differentiated hepatic functions such as albumin secretion, urea synthesis and cytochrome p450 1A1 production has been demonstrated for culture periods over 14 days. Measurement of cytochrome p450 1A1 through ethoxyresorufin dealkylation (EROD) was adapted for use as a diagnostic to optically assess toxicity of probe compounds. Detection by both spectroscopy and 2-photon microscopy was developed to allow temporal as well morphological exploration of toxicity. These methods were used to successfully detect both aflatoxin B1, and microcystin LR. For microcystin, a five fold decrease in EROD intensity was observed within 12 hours. For aflatoxin toxicity was sensed by 15 hours for doses as low as 12 nM. Since each of these compounds act through different biological mechanisms, these results show that our liver tissue biosensor can be used to sense a range of different classes of toxins.",A. T. Capitano; J. L. Roberts; L. G. Griffith,,,Design of a liver tissue biosensor,2,,10.1109/IEMBS.2002.1106642 ,IEEE Conferences ,,"Summary form only given. The threat of chemical and biological attack is becoming increasingly more likely. Since the liver metabolizes xenobiotic species, construction of a liver tissue based biosensor allows the detection of a wide range of harmful agents by detecting physiological changes in cultured liver cells. Previously, the development of such technology has been limited since traditional 2D culturing methods lead to dedifferentiation and loss of hepatic functions within hours to days. By recreating a 3D culture environment similar to the acinus in the liver, maintenance of differentiated hepatic functions such as albumin secretion, urea synthesis and cytochrome p450 1A1 production has been demonstrated for culture periods over 14 days. Measurement of cytochrome p450 1A1 through ethoxyresorufin dealkylation (EROD) was adapted for use as a diagnostic to optically assess toxicity of probe compounds. Detection by both spectroscopy and 2-photon microscopy was developed to allow temporal as well morphological exploration of toxicity. These methods were used to successfully detect both aflatoxin B1, and microcystin LR. For microcystin, a five fold decrease in EROD intensity was observed within 12 hours. For aflatoxin toxicity was sensed by 15 hours for doses as low as 12 nM. Since each of these compounds act through different biological mechanisms, these results show that our liver tissue biosensor can be used to sense a range of different classes of toxins.",1094-687X,,0-7803-7612-9,,IEEE , ,Liver;Biosensors;Cells (biology);Chemical technology;Fluids and secretions;Production;Biomedical optical imaging;Optical sensors;Probes;Spectroscopy,,
4682,"Title:Automated Design of Microfluidics-Based Biochips: Connecting Biochemistry to Electronics CAD

 Microfluidics-based biochips offer exciting possibilities for high-throughput sequencing, parallel immunoassays, blood chemistry for clinical diagnostics, DNA sequencing, and environmental toxicity monitoring. The complexity of microfluidic devices is expected to become significant in the near future due to the need for multiple and concurrent biochemical assays on multifunctional and reconfigurable platforms. This paper presents early work on top-down system-level computer-aided design (CAD) tools for the synthesis, testing and reconfiguration of microfluidic biochips. Synthesis tools map behavioral descriptions to a droplet-based microfluidic biochip and generate an optimized schedule of assay operations, the binding of assay operations to functional units, and the layout and droplet flow-paths. Cost-effective testing techniques lead to the detection of manufacturing defects and operational faults. Reconfiguration techniques, incorporated in these CAD tools, can easily bypass faults once they are detected. Thus the biochip user can concentrate on the development of the nano- and micro-scale bioassays, leaving assay optimization and implementation details to design automation tools.",K. Chakrabarty,,,Automated Design of Microfluidics-Based Biochips: Connecting Biochemistry to Electronics CAD,,,10.1109/ICCD.2006.4380800 ,IEEE Conferences ,,"Microfluidics-based biochips offer exciting possibilities for high-throughput sequencing, parallel immunoassays, blood chemistry for clinical diagnostics, DNA sequencing, and environmental toxicity monitoring. The complexity of microfluidic devices is expected to become significant in the near future due to the need for multiple and concurrent biochemical assays on multifunctional and reconfigurable platforms. This paper presents early work on top-down system-level computer-aided design (CAD) tools for the synthesis, testing and reconfiguration of microfluidic biochips. Synthesis tools map behavioral descriptions to a droplet-based microfluidic biochip and generate an optimized schedule of assay operations, the binding of assay operations to functional units, and the layout and droplet flow-paths. Cost-effective testing techniques lead to the detection of manufacturing defects and operational faults. Reconfiguration techniques, incorporated in these CAD tools, can easily bypass faults once they are detected. Thus the biochip user can concentrate on the development of the nano- and micro-scale bioassays, leaving assay optimization and implementation details to design automation tools.",1063-6404,,978-0-7803-9706-4,93-100,IEEE , ,Joining processes;Biochemistry;Design automation;Microfluidics;Fault detection;Immune system;Blood;Chemistry;DNA;Computerized monitoring,,
4683,"Title:Stability of Metal Oxide Semiconductor Gas Sensors: A Review

 Sensor stability is defined as the ability to maintain a relatively stable and repeatable signal over a sufficient period. Long-term stability for gas sensors is an essential capability for carrying out long-term data collection of human exhaled breath, environmental monitoring and other gas detection in the modern electronic information age. This article reviews the research advances on the stability of metal oxide semiconductor gas sensors in the past five years. The impact of structure, environment, toxicity and sensor array on the sensor stability are discussed. Then, the improvement schemes of existing materials and structure design are summarized. The achievements of structure doping, humidity, anti-poisoning and photoactivation are overviewed. Finally, the great significance of elucidating the sensing mechanism and carrying out the life acceleration test for future research and development is pointed out.",H. Chai; Z. Zheng; K. Liu; J. Xu; K. Wu; Y. Luo; H. Liao; M. Debliquy; C. Zhang,,,Stability of Metal Oxide Semiconductor Gas Sensors: A Review,22,6,10.1109/JSEN.2022.3148264 ,IEEE Journals ,,"Sensor stability is defined as the ability to maintain a relatively stable and repeatable signal over a sufficient period. Long-term stability for gas sensors is an essential capability for carrying out long-term data collection of human exhaled breath, environmental monitoring and other gas detection in the modern electronic information age. This article reviews the research advances on the stability of metal oxide semiconductor gas sensors in the past five years. The impact of structure, environment, toxicity and sensor array on the sensor stability are discussed. Then, the improvement schemes of existing materials and structure design are summarized. The achievements of structure doping, humidity, anti-poisoning and photoactivation are overviewed. Finally, the great significance of elucidating the sensing mechanism and carrying out the life acceleration test for future research and development is pointed out.",1558-1748,,,5470-5481,IEEE , ,Sensors;Thermal stability;Metals;Stability criteria;Temperature sensors;Gas detectors;Adsorption,,
4684,"Title:A Feasibility Study of In Vivo Control and Tracking of Microrobot Using Taxicab Geometry for Direct Drug Targeting

 In vivo direct drug targeting aims at delivering drug molecules loaded on microrobots to the diseased site using the shortest possible physiological routes, which potentially improves targeting efficiency and reduces systemic toxicity. It is thus essential to consider realistic in-body limitations for direct drug targeting applications. Here, we present a novel controller for microrobot maneuver by considering four key in vivo constraints: non-Euclidean structure of capillaries, irreversibility of blood flow, invisibility of microvasculature, and inaccuracy of microrobot tracking. We use the taxicab geometry of capillaries as the a priori knowledge for steering and tracking a microrobot in lattice-like vessels. Furthermore, we introduce a minimax repulsive boundary function to prevent the microrobot from getting too close to the boundaries imposed by the direction of blood flow. We also propose a novel Kalman filtering algorithm to reduce tracking error, while avoiding possible obstacles such as vessel walls without knowing their actual locations. The proposed control method consists of four modules, namely a model predictive control module for tumor targeting, a Kalman filtering module for microrobot tracking, a blind obstacle detection module, and a vessel structure estimation module. The interplay of these four modules offers successful maneuver and tracking of the microrobot while avoiding obstacles in a blind manner by utilizing the taxicab geometry of blood vessels. We present a comprehensive in silico simulation study to verify our designed controller.",N. Sharifi; Z. Gong; G. Holmes; Y. Chen,,,A Feasibility Study of In Vivo Control and Tracking of Microrobot Using Taxicab Geometry for Direct Drug Targeting,20,2,10.1109/TNB.2021.3062006 ,IEEE Journals ,,"In vivo direct drug targeting aims at delivering drug molecules loaded on microrobots to the diseased site using the shortest possible physiological routes, which potentially improves targeting efficiency and reduces systemic toxicity. It is thus essential to consider realistic in-body limitations for direct drug targeting applications. Here, we present a novel controller for microrobot maneuver by considering four key in vivo constraints: non-Euclidean structure of capillaries, irreversibility of blood flow, invisibility of microvasculature, and inaccuracy of microrobot tracking. We use the taxicab geometry of capillaries as the a priori knowledge for steering and tracking a microrobot in lattice-like vessels. Furthermore, we introduce a minimax repulsive boundary function to prevent the microrobot from getting too close to the boundaries imposed by the direction of blood flow. We also propose a novel Kalman filtering algorithm to reduce tracking error, while avoiding possible obstacles such as vessel walls without knowing their actual locations. The proposed control method consists of four modules, namely a model predictive control module for tumor targeting, a Kalman filtering module for microrobot tracking, a blind obstacle detection module, and a vessel structure estimation module. The interplay of these four modules offers successful maneuver and tracking of the microrobot while avoiding obstacles in a blind manner by utilizing the taxicab geometry of blood vessels. We present a comprehensive in silico simulation study to verify our designed controller.",1558-2639,,,235-245,IEEE , ,Target tracking;Geometry;Drugs;Blood flow;In vivo;Tumors;Kalman filters,,
4685,"Title:Hydrogen Fluoride Gas Sensor by Silicon Nanosheet Field-Effect Transistor

 Chemical sensors are an essential part of modern society to ensure safety, from preventing pollution to saving lives. In particular, the demand for real-time monitoring of hydrogen fluoride (HF) increases continuously due to its high toxicity, contrary to its wide use in industries. In addition, compact size and low cost are favorable to utilize the sensor in wide spreading applications in industries. Here, we present a compact HF gas sensor with high sensitivity and selectivity. The HF sensors, fabricated in the form of field-effect transistors (FETs) using a cost-effective and mass-production friendly conventional semiconductor process, are shown to possess good electrical characteristics enabled by a silicon nanosheet (SiNS) current channel. High sensitivity on gas phase HF is achieved by the unique catalytic sensing membrane—platinum/polycrystalline lanthanum fluoride (Pt/poly-LaF3). The high responsivity ( ${S}_{{\textit {R}}}{)}$  of 3071% at 25 ppm and the low limit of detection (LOD) of 219 ppb were achieved at room temperature (RT), along with a quick response time of 5.56 min, which are crucial for the workplace environmental safety. The developed HF sensor can be a potential candidate for the industrial mobile sensor platform.",H. -T. Kwak; H. Kim; H. Yoo; M. Choi; K. Oh; Y. Kim; B. D. Kong; C. -K. Baek,,,Hydrogen Fluoride Gas Sensor by Silicon Nanosheet Field-Effect Transistor,23,15,10.1109/JSEN.2023.3285892 ,IEEE Journals ,,"Chemical sensors are an essential part of modern society to ensure safety, from preventing pollution to saving lives. In particular, the demand for real-time monitoring of hydrogen fluoride (HF) increases continuously due to its high toxicity, contrary to its wide use in industries. In addition, compact size and low cost are favorable to utilize the sensor in wide spreading applications in industries. Here, we present a compact HF gas sensor with high sensitivity and selectivity. The HF sensors, fabricated in the form of field-effect transistors (FETs) using a cost-effective and mass-production friendly conventional semiconductor process, are shown to possess good electrical characteristics enabled by a silicon nanosheet (SiNS) current channel. High sensitivity on gas phase HF is achieved by the unique catalytic sensing membrane—platinum/polycrystalline lanthanum fluoride (Pt/poly-LaF3). The high responsivity ( ${S}_{{\textit {R}}}{)}$  of 3071% at 25 ppm and the low limit of detection (LOD) of 219 ppb were achieved at room temperature (RT), along with a quick response time of 5.56 min, which are crucial for the workplace environmental safety. The developed HF sensor can be a potential candidate for the industrial mobile sensor platform.",1558-1748,,,16545-16552,IEEE , ,Sensors;Field effect transistors;Silicon compounds;Hafnium;Periodic structures;Chemical sensors;Sensor phenomena and characterization,,
4686,"Title:Dynamic Control of Contractile Force in Engineered Heart Tissue

 Three-dimensional engineered heart tissues (EHTs) derived from human induced pluripotent stem cells (iPSCs) have become an important resource for both drug toxicity screening and research on heart disease. A key metric of EHT phenotype is the contractile (twitch) force with which the tissue spontaneously beats. It is well-known that cardiac muscle contractility – its ability to do mechanical work – depends on tissue prestrain (preload) and external resistance (afterload). Objectives: Here, we demonstrate a technique to control afterload while monitoring contractile force exerted by EHTs. Methods: We developed an apparatus that can regulate EHT boundary conditions using real-time feedback control. The system is comprised of a pair of piezoelectric actuators that can strain the scaffold and a microscope that can measure EHT force and length. Closed loop control allows dynamic regulation of effective EHT boundary stiffness. Results: When controlled to switch instantaneously from auxotonic to isometric boundary conditions, EHT twitch force immediately doubled. Changes in EHT twitch force as a function of effective boundary stiffness were characterized and compared to twitch force in auxotonic conditions. Conclusion: EHT contractility can be regulated dynamically through feedback control of effective boundary stiffness. Significance: The capacity to alter the mechanical boundary conditions of an engineered tissue dynamically offers a new way to probe tissue mechanics. This could be used to mimic afterload changes that occur naturally in disease, or to improve mechanical techniques for EHT maturation.",H. Li; S. Sundaram; R. Hu; L. Lou; F. Sanchez; W. McDonald; A. Agarwal; C. S. Chen; T. G. Bifano,,,Dynamic Control of Contractile Force in Engineered Heart Tissue,70,7,10.1109/TBME.2023.3239594 ,IEEE Journals ,,"Three-dimensional engineered heart tissues (EHTs) derived from human induced pluripotent stem cells (iPSCs) have become an important resource for both drug toxicity screening and research on heart disease. A key metric of EHT phenotype is the contractile (twitch) force with which the tissue spontaneously beats. It is well-known that cardiac muscle contractility – its ability to do mechanical work – depends on tissue prestrain (preload) and external resistance (afterload). Objectives: Here, we demonstrate a technique to control afterload while monitoring contractile force exerted by EHTs. Methods: We developed an apparatus that can regulate EHT boundary conditions using real-time feedback control. The system is comprised of a pair of piezoelectric actuators that can strain the scaffold and a microscope that can measure EHT force and length. Closed loop control allows dynamic regulation of effective EHT boundary stiffness. Results: When controlled to switch instantaneously from auxotonic to isometric boundary conditions, EHT twitch force immediately doubled. Changes in EHT twitch force as a function of effective boundary stiffness were characterized and compared to twitch force in auxotonic conditions. Conclusion: EHT contractility can be regulated dynamically through feedback control of effective boundary stiffness. Significance: The capacity to alter the mechanical boundary conditions of an engineered tissue dynamically offers a new way to probe tissue mechanics. This could be used to mimic afterload changes that occur naturally in disease, or to improve mechanical techniques for EHT maturation.",1558-2531,,,2237-2245,IEEE , ,Force;Actuators;Dynamics;Microscopy;Image edge detection;Force measurement;Monitoring,,
4687,"Title:Water-dispersible graphene paste for flexible conductive patterns and films

 Flexible electronics has emerged as an independent field and matured over the past decades due to they can provide a lot of benefits as compared with traditional rigid printed circuit boards, such as better durability, lighter weight, higher space efficiency, and improved comfort. Graphene-based electronics provide new opportunities for flexible electronics because of their superior properties including high electrical conductivity, high mechanical flexibility, high carrier mobility, and so forth. In this work, a water-dispersible graphene paste (WGP) was used as raw materials to fabricate flexible conductive patterns and films on various substrates. The water dispersions have noteworthy advantages over those obtained in organic solvents, such as low cost, absence of solvent toxicity and capacity for green chemistry compatibility with hydrophilic substrates, also avoiding post-reduction of graphene oxide (GO) to obtain electrical conductivity. The microstructures and rheological properties of the WGP were firstly studied. Then, the WGP with a high concentration of 20 mg mL-1 was directly printed on flexible substrates such as paper and PET film by a simple and low-cost stencil printing method to obtain various printed patterns. The electrical properties and durability of the printed patterns were investigated under different deformations such as bending and folding. The printed conductive patterns show a good conductivity and which can be visually demonstrated by lighting a LED bulb with a 3 V power source. The WGP conductive line on paper exhibits excellent electrical stability (~5% of relative change of resistance) after 1500 bending cycles. Moreover, after dilution of the WGP to a low concentration of 2 mg mL-1, it can be used to fabricate a flexible conductive film on PET substrate by spray coating technology, and which shows a low sheet resistance of ~14.33 Ω sq-1 at a thickness of ~5 μm. The results reveal that the WGP possess outstanding electronic properties and have great potential for the convenient fabrication of flexible and low-cost graphene based electronics on various substrates including flexible paper and plastics, by using a simple stencil printing method or spray printing technology.",Y. Hu; T. Zhao; P. Zhu; X. Liang; Y. Zhu; H. Su; R. Sun; C. -P. Wong,,,Water-dispersible graphene paste for flexible conductive patterns and films,,,10.1109/ICEPT.2016.7583119 ,IEEE Conferences ,,"Flexible electronics has emerged as an independent field and matured over the past decades due to they can provide a lot of benefits as compared with traditional rigid printed circuit boards, such as better durability, lighter weight, higher space efficiency, and improved comfort. Graphene-based electronics provide new opportunities for flexible electronics because of their superior properties including high electrical conductivity, high mechanical flexibility, high carrier mobility, and so forth. In this work, a water-dispersible graphene paste (WGP) was used as raw materials to fabricate flexible conductive patterns and films on various substrates. The water dispersions have noteworthy advantages over those obtained in organic solvents, such as low cost, absence of solvent toxicity and capacity for green chemistry compatibility with hydrophilic substrates, also avoiding post-reduction of graphene oxide (GO) to obtain electrical conductivity. The microstructures and rheological properties of the WGP were firstly studied. Then, the WGP with a high concentration of 20 mg mL-1 was directly printed on flexible substrates such as paper and PET film by a simple and low-cost stencil printing method to obtain various printed patterns. The electrical properties and durability of the printed patterns were investigated under different deformations such as bending and folding. The printed conductive patterns show a good conductivity and which can be visually demonstrated by lighting a LED bulb with a 3 V power source. The WGP conductive line on paper exhibits excellent electrical stability (~5% of relative change of resistance) after 1500 bending cycles. Moreover, after dilution of the WGP to a low concentration of 2 mg mL-1, it can be used to fabricate a flexible conductive film on PET substrate by spray coating technology, and which shows a low sheet resistance of ~14.33 Ω sq-1 at a thickness of ~5 μm. The results reveal that the WGP possess outstanding electronic properties and have great potential for the convenient fabrication of flexible and low-cost graphene based electronics on various substrates including flexible paper and plastics, by using a simple stencil printing method or spray printing technology.",,,978-1-5090-1396-8,200-205,IEEE , ,Graphene;Substrates;Conductivity;Copper;Wires;Image edge detection;Silicon,,
4688,"Title:Study of Annihilation Photon Pair Coincidence Time Resolution Using Prompt Photon Emissions in New Perovskite Bulk Crystals

 Semiconductor-based radiation detectors can typically achieve better energy and spatial resolution when compared to scintillator-based detectors. However, if used for positron emission tomography (PET), semiconductor-based detectors normally cannot achieve excellent coincidence time resolution (CTR), due to the relatively slow charge carrier collection time limited by the carrier drift velocity. If we can collect prompt photons emitted from certain semiconductor materials, there are possibilities that the CTR can be greatly improved, and time-of-flight (ToF) capability can be achieved. In this article, we studied the prompt photon emission (mainly, the Cherenkov luminescence) property and fast timing capability of cesium lead chloride (CsPbCl3) and cesium lead bromide (CsPbBr3), which are two new perovskite semiconductor materials. We also compared their performance with thallium bromide (TlBr), another semiconductor material that has already been studied for timing using its Cherenkov emissions. We performed coincidence measurements using silicon photomultipliers (SiPMs), and the full-width-at-half-maximum (FWHM) CTR acquired between a semiconductor sample crystal and a reference lutetium-yttrium oxyorthosilicate (LYSO) crystal (both with dimensions of  $3\times 3\times 3\,\mathrm {mm^{3}}$ ) is  ${\mathbf {248\pm 8~ps}}$  for CsPbCl3,  ${\mathbf {440\pm 31~ps}}$  for CsPbBr3, and  ${\mathbf {343\pm 16~ps}}$  for TlBr. Deconvolving the contribution to CTR from the reference LYSO crystal (around 100 ps) and then multiplying by the square root of 2, the estimated CTR between two of the same semiconductor crystals was calculated as  ${\mathbf {324\pm 10~ps}}$  for CsPbCl3,  ${\mathbf {606\pm 43~ps}}$  for CsPbBr3, and  ${\mathbf {464\pm 22~ps}}$  for TlBr. This ToF capable CTR performance combined with an easily scalable crystal growth process, low cost and toxicity, as well as good energy resolution lead us to the conclusion that new perovskite materials, such as CsPbCl3 and CsPbBr3 could be excellent candidates as PET detector materials.",L. Tao; Y. He; M. G. Kanatzidis; C. S. Levin,,,Study of Annihilation Photon Pair Coincidence Time Resolution Using Prompt Photon Emissions in New Perovskite Bulk Crystals,6,7,10.1109/TRPMS.2022.3149992 ,IEEE Journals ,,"Semiconductor-based radiation detectors can typically achieve better energy and spatial resolution when compared to scintillator-based detectors. However, if used for positron emission tomography (PET), semiconductor-based detectors normally cannot achieve excellent coincidence time resolution (CTR), due to the relatively slow charge carrier collection time limited by the carrier drift velocity. If we can collect prompt photons emitted from certain semiconductor materials, there are possibilities that the CTR can be greatly improved, and time-of-flight (ToF) capability can be achieved. In this article, we studied the prompt photon emission (mainly, the Cherenkov luminescence) property and fast timing capability of cesium lead chloride (CsPbCl3) and cesium lead bromide (CsPbBr3), which are two new perovskite semiconductor materials. We also compared their performance with thallium bromide (TlBr), another semiconductor material that has already been studied for timing using its Cherenkov emissions. We performed coincidence measurements using silicon photomultipliers (SiPMs), and the full-width-at-half-maximum (FWHM) CTR acquired between a semiconductor sample crystal and a reference lutetium-yttrium oxyorthosilicate (LYSO) crystal (both with dimensions of  $3\times 3\times 3\,\mathrm {mm^{3}}$ ) is  ${\mathbf {248\pm 8~ps}}$  for CsPbCl3,  ${\mathbf {440\pm 31~ps}}$  for CsPbBr3, and  ${\mathbf {343\pm 16~ps}}$  for TlBr. Deconvolving the contribution to CTR from the reference LYSO crystal (around 100 ps) and then multiplying by the square root of 2, the estimated CTR between two of the same semiconductor crystals was calculated as  ${\mathbf {324\pm 10~ps}}$  for CsPbCl3,  ${\mathbf {606\pm 43~ps}}$  for CsPbBr3, and  ${\mathbf {464\pm 22~ps}}$  for TlBr. This ToF capable CTR performance combined with an easily scalable crystal growth process, low cost and toxicity, as well as good energy resolution lead us to the conclusion that new perovskite materials, such as CsPbCl3 and CsPbBr3 could be excellent candidates as PET detector materials.",2469-7303,,,804-810,IEEE , ,Crystals;Detectors;Photonics;Timing;Positron emission tomography;Perovskites;Oscilloscopes,,
4689,"Title:Research on Safety Risks Analysis and Protective Measures of Ammonia as Marine Fuel

 According to International Maritime Organization (IMO) requirements of greenhouse gas emission reduction, the application of zero-carbon fuel in ships is imperative, and ammonia as fuel is considered to be one of the best choices. However, the application of ammonia fuel is limited because of the safety risk of ammonia, especially its toxicity. Therefore, considering the liquid ammonia has been widely used in industry, this paper analyzes the safety requirements and protective measures for ammonia as marine fuel from the design point of view, aiming at the risks of ammonia and according to the existing requirements of relevant regulations in cargo, refrigeration and Selective Catalytic Reduction (SCR) systems, and puts forward suggestions for the safety protection of marine ammonia fuel. It also provides reference and support for the design and application of ammonia fuel powered ship.",Y. Chen; J. Pu; X. Xu; X. Mei,,,Research on Safety Risks Analysis and Protective Measures of Ammonia as Marine Fuel,,,10.1109/ICPRE55555.2022.9960531 ,IEEE Conferences ,,"According to International Maritime Organization (IMO) requirements of greenhouse gas emission reduction, the application of zero-carbon fuel in ships is imperative, and ammonia as fuel is considered to be one of the best choices. However, the application of ammonia fuel is limited because of the safety risk of ammonia, especially its toxicity. Therefore, considering the liquid ammonia has been widely used in industry, this paper analyzes the safety requirements and protective measures for ammonia as marine fuel from the design point of view, aiming at the risks of ammonia and according to the existing requirements of relevant regulations in cargo, refrigeration and Selective Catalytic Reduction (SCR) systems, and puts forward suggestions for the safety protection of marine ammonia fuel. It also provides reference and support for the design and application of ammonia fuel powered ship.",2768-0525,,978-1-6654-5063-8,766-771,IEEE , ,Training;Ammonia;Toxicology;Transportation;Regulation;Loss measurement;Safety,,
4690,"Title:An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software

 The exponential growth of social media platforms has brought about a revolution in communication and content dissemination in human society. Nevertheless, these platforms are being increasingly misused to spread toxic content, including hate speech, malicious advertising, and pornography, leading to severe negative consequences such as harm to teenagers' mental health. Despite tremendous efforts in developing and deploying textual and image content moderation methods, malicious users can evade moderation by embedding texts into images, such as screenshots of the text, usually with some interference. We find that modern content moderation software's performance against such malicious inputs remains underexplored. In this work, we propose OASIS, a metamorphic testing framework for content moderation software. OASIS employs 21 transform rules summarized from our pilot study on 5,000 real-world toxic contents collected from 4 popular social media applications, including Twitter, Instagram, Sina Weibo, and Baidu Tieba. Given toxic textual contents, OASIS can generate image test cases, which preserve the toxicity yet are likely to bypass moderation. In the evaluation, we employ OASIS to test five commercial textual content moderation software from famous companies (i.e., Google Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud), as well as a state-of-the-art moderation research model. The results show that OASIS achieves up to 100% error finding rates. Moreover, through retraining the models with the test cases generated by OASIS, the robustness of the moderation model can be improved without performance degradation.",W. Wang; J. Huang; J. -t. Huang; C. Chen; J. Gu; P. He; M. R. Lyu,,,An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software,,,10.1109/ASE56229.2023.00189 ,IEEE Conferences ,,"The exponential growth of social media platforms has brought about a revolution in communication and content dissemination in human society. Nevertheless, these platforms are being increasingly misused to spread toxic content, including hate speech, malicious advertising, and pornography, leading to severe negative consequences such as harm to teenagers' mental health. Despite tremendous efforts in developing and deploying textual and image content moderation methods, malicious users can evade moderation by embedding texts into images, such as screenshots of the text, usually with some interference. We find that modern content moderation software's performance against such malicious inputs remains underexplored. In this work, we propose OASIS, a metamorphic testing framework for content moderation software. OASIS employs 21 transform rules summarized from our pilot study on 5,000 real-world toxic contents collected from 4 popular social media applications, including Twitter, Instagram, Sina Weibo, and Baidu Tieba. Given toxic textual contents, OASIS can generate image test cases, which preserve the toxicity yet are likely to bypass moderation. In the evaluation, we employ OASIS to test five commercial textual content moderation software from famous companies (i.e., Google Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud), as well as a state-of-the-art moderation research model. The results show that OASIS achieves up to 100% error finding rates. Moreover, through retraining the models with the test cases generated by OASIS, the robustness of the moderation model can be improved without performance degradation.",2643-1572,,979-8-3503-2996-4,1339-1351,IEEE , ,Toxicology;Social networking (online);Web and internet services;Software algorithms;Blogs;Transforms;Software,,
4691,"Title:Design and Simulation of Environment Indoor Air Quality Monitoring and Controlling System using IoT Technology

 Environment indoor quality (EIQ) is a multifaceted problem encompassing a broad range and fluctuation of contaminants that pose risks to human health, satisfaction, welfare, and efficiency, particularly in relation to environment indoor air quality (EIAQ). The presence of indoor air pollutants (IAP) in the environment significantly influences the decline in the quality of human life, owing to the hazards associated with indoor air pollution and discomfort-causing pollutants affecting thermal comfort. This research features a proposed EIAQ monitoring and controlling system based on the environment indoor air quality index (EIAQI) for detecting, identifying, assessing, and controlling air pollutants. Further, it monitors the concentration of the gases and calculate the toxicity level of the environment status index. It also provides the output control system such as ventilation system and alert system to mitigate the air pollutants based on EIAQI automatically. The EIAQ system integrated with IoT technology to provide a monitoring application the entire air pollutant and EIAQI. As a result, the use of the indoor air quality (IAQ) system becomes a suitable method for identifying, categorizing, assessing, offering guidance, and implementing preventive measures to enhance the quality of the environment.",B. W. Dionova; D. Hendrawati; M. N. Abdulrazaq; D. J. Vresdian; A. A. Hapsari; M. I. Abdullah; L. P. Pratama,,,Design and Simulation of Environment Indoor Air Quality Monitoring and Controlling System using IoT Technology,,,10.1109/ISITIA59021.2023.10221098 ,IEEE Conferences ,,"Environment indoor quality (EIQ) is a multifaceted problem encompassing a broad range and fluctuation of contaminants that pose risks to human health, satisfaction, welfare, and efficiency, particularly in relation to environment indoor air quality (EIAQ). The presence of indoor air pollutants (IAP) in the environment significantly influences the decline in the quality of human life, owing to the hazards associated with indoor air pollution and discomfort-causing pollutants affecting thermal comfort. This research features a proposed EIAQ monitoring and controlling system based on the environment indoor air quality index (EIAQI) for detecting, identifying, assessing, and controlling air pollutants. Further, it monitors the concentration of the gases and calculate the toxicity level of the environment status index. It also provides the output control system such as ventilation system and alert system to mitigate the air pollutants based on EIAQI automatically. The EIAQ system integrated with IoT technology to provide a monitoring application the entire air pollutant and EIAQI. As a result, the use of the indoor air quality (IAQ) system becomes a suitable method for identifying, categorizing, assessing, offering guidance, and implementing preventive measures to enhance the quality of the environment.",2769-5492,,979-8-3503-1395-6,494-499,IEEE , ,Seminars;Toxicology;Process control;Air pollution;Control systems;Ventilation;Indexes,,
4692,"Title:A “Living Sensor” Based on Sansevieria Plant for Measurement of UV-A Radiation

 This research activity concerns the development of a sensor based on Sansevieria plants to measure UV-A radiation. The proposed approach is based on soils and plants together with the metabolic processes and bacterial activities involved in such organisms. This generation of devices aims to overcome silicon-based solutions that cause environmental pollution with CO2 emissions during manufacturing and issues of nonbiodegradability and toxicity at the dissemination or end-of-life phases. The sensor here studied and characterized presents no CO2 emissions during the production, considering the absence of manufacture and foundries processes, and it is also capable to meet the zero-CO2 condition by reducing the amount of carbon dioxide already present in the environment through natural photosynthetic processes. The living sensor based on the Sansevieria and its working principle is studied for the first time in the literature, together with the analysis of radiation in the bandwidth of 350–400 nm, the metrological characterization, the features, and influences analysis. The results highlight the suitability of the Sansevieria as a self-generating, battery-less sensor based on the metabolic processes in the living system, soil, and plant, as a function of the measurand. It is worth noting that the approach followed here has the prerogative of being simple, low-cost, nontoxic, biodegradable, environmentally friendly, and mimetic with a perspective of achieving a huge jump in the development of green measuring systems.",C. Trigona; I. Puglisi; A. Baglieri; A. M. Gueli,,,A “Living Sensor” Based on Sansevieria Plant for Measurement of UV-A Radiation,72,,10.1109/TIM.2023.3265746 ,IEEE Journals ,,"This research activity concerns the development of a sensor based on Sansevieria plants to measure UV-A radiation. The proposed approach is based on soils and plants together with the metabolic processes and bacterial activities involved in such organisms. This generation of devices aims to overcome silicon-based solutions that cause environmental pollution with CO2 emissions during manufacturing and issues of nonbiodegradability and toxicity at the dissemination or end-of-life phases. The sensor here studied and characterized presents no CO2 emissions during the production, considering the absence of manufacture and foundries processes, and it is also capable to meet the zero-CO2 condition by reducing the amount of carbon dioxide already present in the environment through natural photosynthetic processes. The living sensor based on the Sansevieria and its working principle is studied for the first time in the literature, together with the analysis of radiation in the bandwidth of 350–400 nm, the metrological characterization, the features, and influences analysis. The results highlight the suitability of the Sansevieria as a self-generating, battery-less sensor based on the metabolic processes in the living system, soil, and plant, as a function of the measurand. It is worth noting that the approach followed here has the prerogative of being simple, low-cost, nontoxic, biodegradable, environmentally friendly, and mimetic with a perspective of achieving a huge jump in the development of green measuring systems.",1557-9662,,,1-10,IEEE , ,Soil;Soil measurements;Pollution measurement;Microorganisms;Semiconductor device measurement;Plants (biology);Electric potential,,
4693,"Title:CAN based Collision Avoidance and Battery Management System for Automotives

 Vehicles are the basic need for human transportation but nowadays accidents are the major risk factors. Enhancing safety and preventing accidents play a major role in designing a safer and more efficient transportation system. Henceforth, the networking of vehicle protocols has become a necessity to overcome the problems related to reliability, body wiring, complexity, and space constraints. Since comfort, dynamics, and economy are taken into account as the criteria by which the proposed system differs from the conventional vehicle system, the Controller Area Network (CAN) protocol can be used as a device format for communicating microcontrollers with other devices in the automotive electronics industry. Hence the proposed research study makes an effort to transmit several variables at the same rate. Also, an attempt has been made to control the speed of the vehicle depending on the values provided by ultrasonic sensor. Subsequently, the purpose of this research study is to develop collision warning in emerging automobiles that assist drivers in avoiding rear-end collisions with the CAN protocol. Also, the objective of this research work is to work on the Battery Management System (BMS) which is another major concerning factor found in most of the vehicles responsible for thermal runaway, electrical, fire, leakage, and toxicity hazards. So, this research work focuses on fulfilling the purpose of monitoring the battery packs using CAN module.",K. S. Prasanna; R. A. Reddy; J. J. Reddy; M. C. Reddy; M. T. Supriya; M. S. Kumar,,,CAN based Collision Avoidance and Battery Management System for Automotives,,,10.1109/ICICT57646.2023.10134290 ,IEEE Conferences ,,"Vehicles are the basic need for human transportation but nowadays accidents are the major risk factors. Enhancing safety and preventing accidents play a major role in designing a safer and more efficient transportation system. Henceforth, the networking of vehicle protocols has become a necessity to overcome the problems related to reliability, body wiring, complexity, and space constraints. Since comfort, dynamics, and economy are taken into account as the criteria by which the proposed system differs from the conventional vehicle system, the Controller Area Network (CAN) protocol can be used as a device format for communicating microcontrollers with other devices in the automotive electronics industry. Hence the proposed research study makes an effort to transmit several variables at the same rate. Also, an attempt has been made to control the speed of the vehicle depending on the values provided by ultrasonic sensor. Subsequently, the purpose of this research study is to develop collision warning in emerging automobiles that assist drivers in avoiding rear-end collisions with the CAN protocol. Also, the objective of this research work is to work on the Battery Management System (BMS) which is another major concerning factor found in most of the vehicles responsible for thermal runaway, electrical, fire, leakage, and toxicity hazards. So, this research work focuses on fulfilling the purpose of monitoring the battery packs using CAN module.",2767-7788,,979-8-3503-9849-6,662-669,IEEE , ,Wiring;Temperature distribution;Protocols;Toxicology;Battery management systems;Thermal management;Batteries,,
4694,"Title:Detox: NLP Based Classification And Euphemistic Text Substitution For Toxic Comments

 The challenges of eliminating inadvertent hate online have grown more and more observable. With rapid increase in access to technology worldwide, the number of people present on the internet has increased exponentially. The rise in hateful and toxic content on the internet is many fold. Present solutions are largely based on censorship and removal of such content and can be the cause of mental disturbance to the concerned auditor. Biases of manual moderation can thwart the efforts taken to prevent the presence of hate speech on online platforms. However, posts that convey important meanings also fall prey to such systems, which should be avoided. Such systems fail to educate their authors what should have been done differently. Additionally, a system that combines detection and substitution algorithms is largely absent. A euphemistic substitution approach could prove to be more effective. In this project we have developed a classifier using Natural Language Processing and Machine Learning to detect toxic texts and provide euphemisms to erudite the user of words that can replace the toxicity present in the original texts. The classifier informs the online platform about the toxicity of the texts so they restrict such content to available on its platform. The euphemisms are aimed to make the user aware of the toxicity in the text and suggest replacements, which, if used, can make the text inoffensive. We aim to achieve self realisation on the user's part so we can target the issue at its source.",S. Jain; G. Kaushik; P. Prabhu; A. Godbole,,,Detox: NLP Based Classification And Euphemistic Text Substitution For Toxic Comments,,,10.1109/ICCCNT51525.2021.9579846 ,IEEE Conferences ,,"The challenges of eliminating inadvertent hate online have grown more and more observable. With rapid increase in access to technology worldwide, the number of people present on the internet has increased exponentially. The rise in hateful and toxic content on the internet is many fold. Present solutions are largely based on censorship and removal of such content and can be the cause of mental disturbance to the concerned auditor. Biases of manual moderation can thwart the efforts taken to prevent the presence of hate speech on online platforms. However, posts that convey important meanings also fall prey to such systems, which should be avoided. Such systems fail to educate their authors what should have been done differently. Additionally, a system that combines detection and substitution algorithms is largely absent. A euphemistic substitution approach could prove to be more effective. In this project we have developed a classifier using Natural Language Processing and Machine Learning to detect toxic texts and provide euphemisms to erudite the user of words that can replace the toxicity present in the original texts. The classifier informs the online platform about the toxicity of the texts so they restrict such content to available on its platform. The euphemisms are aimed to make the user aware of the toxicity in the text and suggest replacements, which, if used, can make the text inoffensive. We aim to achieve self realisation on the user's part so we can target the issue at its source.",,,978-1-7281-8595-8,1-5,IEEE , ,Toxicology;Machine learning algorithms;Manuals;Machine learning;Natural language processing;Censorship;Classification algorithms,,
4695,"Title:Radiotherapy for Stage I or II hypopharyngeal carcinoma

 Hypopharyngeal squamous cell carcinoma (HPSCC) is usually diagnosed at an advanced stage, and early-stage HPSCC is relatively rare. Because of the rarity of early-stage HPSCC, few reports have been published on the efficacy of radiotherapy (RT) in its treatment. We retrospectively reviewed the clinical records of 45 consecutive patients with Stage I and II HPSCC from May 1991 to June 2010. Patient characteristics were as follows: median age, 66 years (range, 44–90 years); male/female, 39/6; and T1/T2, 27/18. The irradiation dose ranged from 60 to 72 Gy (median: 70 Gy). Of the 45 patients, 21 underwent concurrent chemotherapy. With a median follow-up period of 62 months, the 5-year overall survival rate was 81%. Local failure occurred in 5 patients, and the 5-year local control rate was 83%. All local recurrences were successfully salvaged by surgery. The 5-year functional larynx preservation rate was 92%. Acute toxicity was manageable. Grade 3 laryngeal edema and Grade 3 hypothyroidism occurred in 1 patient each. No other late adverse events of Grade 3 or greater were observed. Based on these results, RT seemed to be an effective treatment modality for early HPSCC, with favorable organ preservation and acceptable adverse events. Early detection and accurate management of local recurrence and second malignancy was deemed to be critical.",H. Nishimura; R. Sasaki; K. Yoshida; D. Miyawaki; Y. Okamoto; N. Kiyota; M. Saito; N. Otsuki; K. Nibu,,,Radiotherapy for Stage I or II hypopharyngeal carcinoma,53,6,10.1093/jrr/rrs044 ,OUP Journals ,,"Hypopharyngeal squamous cell carcinoma (HPSCC) is usually diagnosed at an advanced stage, and early-stage HPSCC is relatively rare. Because of the rarity of early-stage HPSCC, few reports have been published on the efficacy of radiotherapy (RT) in its treatment. We retrospectively reviewed the clinical records of 45 consecutive patients with Stage I and II HPSCC from May 1991 to June 2010. Patient characteristics were as follows: median age, 66 years (range, 44–90 years); male/female, 39/6; and T1/T2, 27/18. The irradiation dose ranged from 60 to 72 Gy (median: 70 Gy). Of the 45 patients, 21 underwent concurrent chemotherapy. With a median follow-up period of 62 months, the 5-year overall survival rate was 81%. Local failure occurred in 5 patients, and the 5-year local control rate was 83%. All local recurrences were successfully salvaged by surgery. The 5-year functional larynx preservation rate was 92%. Acute toxicity was manageable. Grade 3 laryngeal edema and Grade 3 hypothyroidism occurred in 1 patient each. No other late adverse events of Grade 3 or greater were observed. Based on these results, RT seemed to be an effective treatment modality for early HPSCC, with favorable organ preservation and acceptable adverse events. Early detection and accurate management of local recurrence and second malignancy was deemed to be critical.",1349-9157,,,892-899,OUP , ,,,
4696,"Title:Sensor analysis of liquid pollution

 The new portable microfluidic device for field measurement of organophosphorous pesticides toxicity is presented. The device consists of two loop pumps. The first loop assures the mixing of solution. The 95% of solution circulates through the first loop. The second loop consists of capillary which creates the hydrodynamic resistance and the chamber with the miniature electrochemical detector. The detection is based on the inhibition of acetylcholinesterase. The enzyme acetylcholinesterase is immobilized on the detector made by thick film technology forming together a biosensor. The analyzed sample is detected in the flow of supporting buffer. The biosensor detects the integral sample toxicity. The signal from biosensor is evaluated by Bioanalyzer electronic unit. It is destinated for detection of traces of pesticides in washout from leaves, for direct measurement in rivers, ponds, waste waters and drinking water sources.",J. Haze; J. Krejci; R. Vrba; M. Sveda,,,Sensor analysis of liquid pollution,,,10.1109/SFICON.2004.1287151 ,IEEE Conferences ,,"The new portable microfluidic device for field measurement of organophosphorous pesticides toxicity is presented. The device consists of two loop pumps. The first loop assures the mixing of solution. The 95% of solution circulates through the first loop. The second loop consists of capillary which creates the hydrodynamic resistance and the chamber with the miniature electrochemical detector. The detection is based on the inhibition of acetylcholinesterase. The enzyme acetylcholinesterase is immobilized on the detector made by thick film technology forming together a biosensor. The analyzed sample is detected in the flow of supporting buffer. The biosensor detects the integral sample toxicity. The signal from biosensor is evaluated by Bioanalyzer electronic unit. It is destinated for detection of traces of pesticides in washout from leaves, for direct measurement in rivers, ponds, waste waters and drinking water sources.",,,0-7803-8143-2,155-158,IEEE , ,Biosensors;Pollution measurement;Detectors;Water resources;Microfluidics;Electrical resistance measurement;Hydrodynamics;Immune system;Biochemistry;Thick films,,
4697,"Title:SVM ensemble classification of nmr spectra based on different configurations of data processing techniques

 The early detection of drug-induced organ toxicities is one of the major goals in safety pharmacology. Automating this process by classification of metabolic changes based on the analysis of 1H nuclear magnetic resonance spectra improves this process. In this paper we propose an ensemble classification system based on support vector machines trained on diverse ldquoviewsrdquo on the data. These views are created by variation of preprocessing techniques and the final classification is achieved by voting on an optimized selection of all experts. Results of an experimental evaluation on a challenging data-set from industrial safety pharmacology show the effectiveness of the proposed approach w.r.t. the detection of drug-induced toxicity.",K. Lienemann; T. Plotz; G. A. Fink,,,SVM ensemble classification of nmr spectra based on different configurations of data processing techniques,,,10.1109/ICPR.2008.4761761 ,IEEE Conferences ,,The early detection of drug-induced organ toxicities is one of the major goals in safety pharmacology. Automating this process by classification of metabolic changes based on the analysis of 1H nuclear magnetic resonance spectra improves this process. In this paper we propose an ensemble classification system based on support vector machines trained on diverse ldquoviewsrdquo on the data. These views are created by variation of preprocessing techniques and the final classification is achieved by voting on an optimized selection of all experts. Results of an experimental evaluation on a challenging data-set from industrial safety pharmacology show the effectiveness of the proposed approach w.r.t. the detection of drug-induced toxicity.,1051-4651,,978-1-4244-2174-9,1-4,IEEE , ,Support vector machines;Support vector machine classification;Nuclear magnetic resonance;Data processing;Safety;Magnetic analysis;Drugs;Pharmaceutical technology;Voting;Spectroscopy,,
4698,"Title:Chlorophyll based biosensor for sulfur mustard - a chemical warfare agent

 Sulfur mustard (SM), a chemical warfare agent (CWA) is a bifunctional blistering and alkylating agent used in military warfare having antimitotic, mutagenic, carcinogenic, teratogenic and cytotoxic effects. Conventional techniques used for the detection of CWAs are complex, expensive and require sophisticated analytical procedures thus entailing the development of alternative analytical tools. Biosensors offer an alternative analytical approach with a promise of selectivity in addition to sensitivity, ease of use, rapid response and negligible sample pre-treatment. Furthermore, biomolecules have the ability to detect toxicity in addition to concentration. This work reports the development of a fluorescence based biosensor for detection of SM. 2-chloroethyl ethyl sulfide (2-CEES), a sulfur mustard mimic which is structurally similar to it but not as lethal was used for the study, utilizing the ability of chlorophyll to detect the said compound owing to fluorescence. For this, chlorophyll extract from a plant source was immobilized on fibre glass discs of 5mm diameter, and its fluorescence was studied by excitation at 437 nm and emission at 667 nm. The exposure of the biocomponent to 2-CEES led to quenching of fluorescence, which varied linearly with increasing concentration of 2-CEES with a detection limit of 7.68 × 10−10 M. The fluorescence drop mechanism was characterized by HPLC studies which confirmed the conversion of chlorophyll, upon exposure to the analyte, to non-fluorescing catabolic products. The low detection limit was a promising feature of the biosensor.",S. Kaur; M. Singh; N. Verma,,,Chlorophyll based biosensor for sulfur mustard - a chemical warfare agent,,,10.1109/ISPTS.2012.6260887 ,IEEE Conferences ,,"Sulfur mustard (SM), a chemical warfare agent (CWA) is a bifunctional blistering and alkylating agent used in military warfare having antimitotic, mutagenic, carcinogenic, teratogenic and cytotoxic effects. Conventional techniques used for the detection of CWAs are complex, expensive and require sophisticated analytical procedures thus entailing the development of alternative analytical tools. Biosensors offer an alternative analytical approach with a promise of selectivity in addition to sensitivity, ease of use, rapid response and negligible sample pre-treatment. Furthermore, biomolecules have the ability to detect toxicity in addition to concentration. This work reports the development of a fluorescence based biosensor for detection of SM. 2-chloroethyl ethyl sulfide (2-CEES), a sulfur mustard mimic which is structurally similar to it but not as lethal was used for the study, utilizing the ability of chlorophyll to detect the said compound owing to fluorescence. For this, chlorophyll extract from a plant source was immobilized on fibre glass discs of 5mm diameter, and its fluorescence was studied by excitation at 437 nm and emission at 667 nm. The exposure of the biocomponent to 2-CEES led to quenching of fluorescence, which varied linearly with increasing concentration of 2-CEES with a detection limit of 7.68 × 10−10 M. The fluorescence drop mechanism was characterized by HPLC studies which confirmed the conversion of chlorophyll, upon exposure to the analyte, to non-fluorescing catabolic products. The low detection limit was a promising feature of the biosensor.",,,978-1-4673-1043-7,87-91,IEEE , ,Biosensors;Fluorescence;Chemicals;Compounds;Surface acoustic waves;Biomembranes,,
4699,"Title:YouTube Universe of Comments: A Machine Learning approach for systematic classification of YouTube Comments on custom prepared dataset

 At present, YouTube can be regarded as a cloud service owing to the amount of data it adds every second and the enormous data it stores in its data farms. It doesn’t delete old content, it uses redundant storage. The platform can be more sustainable and cost efficient, if they were to discard redundancies of which major portion is constituted by the spam comments or comments that are offensive/abusive. In this paper several machine learning models are used in order to reduce those comments and eventually towards a more efficient storage model. We first address the task of dataset preparation by designing a comprehensive annotation scheme, considering various dimensions such as sentiment, topic, toxicity, and engagement. Leveraging this annotated dataset, we develop a robust machine learning framework that combines state-of-the-art natural language processing techniques with advanced classification algorithms. Our methodology involves several stages, including preprocessing, feature extraction, and model training. We also employ techniques like sentiment analysis and toxicity detection to capture the sentiment and abusive nature of comments, respectively. We also introduced gravity to the comments which would act as a reward mechanism to the comments. To evaluate the performance of our approach, we conduct extensive experiments on a large-scale YouTube comments dataset. We compare the effectiveness of various classification algorithms, including support vector machines, random forests, and deep learning models, in accurately categorizing comments based on our predefined annotation scheme. Additionally, we assess the generalizability of our model by conducting cross-domain experiments on different genres of YouTube videos. Overall, our work contributes to the understanding and management of the YouTube comment ecosystem, showcasing the power of machine learning techniques in systematically classifying and analyzing comments on this popular platform.",S. Naik; A. Katre,,,YouTube Universe of Comments: A Machine Learning approach for systematic classification of YouTube Comments on custom prepared dataset,,,10.1109/WCONF58270.2023.10235049 ,IEEE Conferences ,,"At present, YouTube can be regarded as a cloud service owing to the amount of data it adds every second and the enormous data it stores in its data farms. It doesn’t delete old content, it uses redundant storage. The platform can be more sustainable and cost efficient, if they were to discard redundancies of which major portion is constituted by the spam comments or comments that are offensive/abusive. In this paper several machine learning models are used in order to reduce those comments and eventually towards a more efficient storage model. We first address the task of dataset preparation by designing a comprehensive annotation scheme, considering various dimensions such as sentiment, topic, toxicity, and engagement. Leveraging this annotated dataset, we develop a robust machine learning framework that combines state-of-the-art natural language processing techniques with advanced classification algorithms. Our methodology involves several stages, including preprocessing, feature extraction, and model training. We also employ techniques like sentiment analysis and toxicity detection to capture the sentiment and abusive nature of comments, respectively. We also introduced gravity to the comments which would act as a reward mechanism to the comments. To evaluate the performance of our approach, we conduct extensive experiments on a large-scale YouTube comments dataset. We compare the effectiveness of various classification algorithms, including support vector machines, random forests, and deep learning models, in accurately categorizing comments based on our predefined annotation scheme. Additionally, we assess the generalizability of our model by conducting cross-domain experiments on different genres of YouTube videos. Overall, our work contributes to the understanding and management of the YouTube comment ecosystem, showcasing the power of machine learning techniques in systematically classifying and analyzing comments on this popular platform.",,,979-8-3503-1120-4,1-5,IEEE , ,Video on demand;Toxicology;Systematics;Annotations;Biological system modeling;Forestry;Classification algorithms,,
4700,"Title:Ultrasound contrast agents: clinical applications

 Ultrasound contrast agents (USCAs) are now becoming commercially available. During the past decade, both tolerance and efficacy of microbubble USCAs increased in conjunction with the ultrasound instrumentation. Specific contrast image sequences have been developed to take advantage of the specific microbubble ultrasonic properties. USCAs are well tolerated and do not exhibit allergic reactions or renal toxicity. USCAs increase the Doppler signal intensity from vessels of deep location, small caliber, or in case of reduced and/or slow blood flow. They improve the detection of vessels with limited access due to anatomic limitations. Under certain circumstances they can alter the texture to provide tissue perfusion information. In peripheral artery disease, USCAs help identify subocclusive lesions and grade stenoses. In transcranial Doppler, they reduce the technical failure rate. In renal Doppler ultrasonography, they improve the detection and recording of the renal arteries. USCA increase the role of color Doppler sonography as the primary modality in the screening of renovascular hypertension. Contrast-enhanced color Doppler US provides additional information from cortical blood supply. In liver USCAs improve the visualization of the blood flow. In liver transplants, they improve the detection of anastomotic vessel occlusive disorders. Some studies also investigated the potentials of USCA in detecting and characterizing liver, renal, breast and prostate tumors. Quantification of USCA effect is a preliminary step towards functional imaging.",J. M. Correas; O. Helenon; M. Cherkaoui; J. F. Moreau,,,Ultrasound contrast agents: clinical applications,2,,10.1109/ULTSYM.1998.765293 ,IEEE Conferences ,,"Ultrasound contrast agents (USCAs) are now becoming commercially available. During the past decade, both tolerance and efficacy of microbubble USCAs increased in conjunction with the ultrasound instrumentation. Specific contrast image sequences have been developed to take advantage of the specific microbubble ultrasonic properties. USCAs are well tolerated and do not exhibit allergic reactions or renal toxicity. USCAs increase the Doppler signal intensity from vessels of deep location, small caliber, or in case of reduced and/or slow blood flow. They improve the detection of vessels with limited access due to anatomic limitations. Under certain circumstances they can alter the texture to provide tissue perfusion information. In peripheral artery disease, USCAs help identify subocclusive lesions and grade stenoses. In transcranial Doppler, they reduce the technical failure rate. In renal Doppler ultrasonography, they improve the detection and recording of the renal arteries. USCA increase the role of color Doppler sonography as the primary modality in the screening of renovascular hypertension. Contrast-enhanced color Doppler US provides additional information from cortical blood supply. In liver USCAs improve the visualization of the blood flow. In liver transplants, they improve the detection of anastomotic vessel occlusive disorders. Some studies also investigated the potentials of USCA in detecting and characterizing liver, renal, breast and prostate tumors. Quantification of USCA effect is a preliminary step towards functional imaging.",1051-0117,,0-7803-4095-7,1773-1778 vol.2,IEEE , ,Ultrasonic imaging;Liver;Blood flow;Arteries;Ultrasonography;Instruments;Image sequences;Diseases;Lesions;Hypertension,,
4701,"Title:Glucose sensor using the one dimensional nanostructures

 Glucose detection is of great interests with many applications ranging from clinical diagnosis to environment monitoring. One dimensional nanostructure such as ZnO nanostructures and carbon nanotubes provide promising matrix for the fabrication of glucose sensor due to their unique advantages including the high specific surface area, non-toxicity, chemical stability, electrochemical activity and high electron communication features. In this work, we will first introduce our study on amperometric glucose biosensors which were constructed using the ZnO nanostructures as supporting materials for enzyme (GOX) loading. A high sensitivity (15.33 μA/cm 2.mM) and high affinity of GOX to glucose as well as the low detection limit (0.02 mM) of the glucose sensor were achieved.",X. W. Sun; J. X. Wang,,,Glucose sensor using the one dimensional nanostructures,,,10.1109/IVESC.2010.5644370 ,IEEE Conferences ,,"Glucose detection is of great interests with many applications ranging from clinical diagnosis to environment monitoring. One dimensional nanostructure such as ZnO nanostructures and carbon nanotubes provide promising matrix for the fabrication of glucose sensor due to their unique advantages including the high specific surface area, non-toxicity, chemical stability, electrochemical activity and high electron communication features. In this work, we will first introduce our study on amperometric glucose biosensors which were constructed using the ZnO nanostructures as supporting materials for enzyme (GOX) loading. A high sensitivity (15.33 μA/cm 2.mM) and high affinity of GOX to glucose as well as the low detection limit (0.02 mM) of the glucose sensor were achieved.",,,978-1-4244-6644-3,87-87,IEEE , ,,,
4702,"Title:Development of non-invasive biochemical device for monitoring the lithium level from saliva for bipolar disorder patients

 This research aims at developing low cost portable proactive healthcare technologies to put more control into the hands of patients especially who have mental illness so that the earliest signs of health problems with medications can be detected and corrected. Monitoring prescription drugs such as lithium, clozapine etc is important for safe guarding the well-being of the bipolar sufferers. Therapeutically useful amounts of lithium (~ 0.6 to 1.2 mmol/L) are only slightly lower than toxic amounts (>;1.5 mmol/L), so the concentration of lithium must be carefully monitored during treatment to avoid toxicity. A very sensitive analytical method was proposed for the spectrofluorimetric determination of lithium base on its reaction with 1,4-dihydroxyanthraquinone (Quinizarin). The fluorescence is measured at an excitation wavelength of 590 nm and emission wavelength of 620 nm. Saliva sample was tested using the proposed portable device in order to validate the feasibility of saliva as a sample to detect lithium ions. Calibration results presented that linear range of detection was 0.25 mM ~ 6.0 mM of Li+ in saliva with R2=0.99. The range of detection covers sufficiently the therapeutic range of lithium drugs.",J. H. Kim; D. Diamond; K. T. Lau,,,Development of non-invasive biochemical device for monitoring the lithium level from saliva for bipolar disorder patients,,,10.1109/ICSENS.2011.6126991 ,IEEE Conferences ,,"This research aims at developing low cost portable proactive healthcare technologies to put more control into the hands of patients especially who have mental illness so that the earliest signs of health problems with medications can be detected and corrected. Monitoring prescription drugs such as lithium, clozapine etc is important for safe guarding the well-being of the bipolar sufferers. Therapeutically useful amounts of lithium (~ 0.6 to 1.2 mmol/L) are only slightly lower than toxic amounts (>;1.5 mmol/L), so the concentration of lithium must be carefully monitored during treatment to avoid toxicity. A very sensitive analytical method was proposed for the spectrofluorimetric determination of lithium base on its reaction with 1,4-dihydroxyanthraquinone (Quinizarin). The fluorescence is measured at an excitation wavelength of 590 nm and emission wavelength of 620 nm. Saliva sample was tested using the proposed portable device in order to validate the feasibility of saliva as a sample to detect lithium ions. Calibration results presented that linear range of detection was 0.25 mM ~ 6.0 mM of Li+ in saliva with R2=0.99. The range of detection covers sufficiently the therapeutic range of lithium drugs.",1930-0395,,978-1-4244-9289-3,1744-1747,IEEE , ,Lithium;Fluorescence;Monitoring;Calibration;Drugs;Ions,,
4703,"Title:Performance characteristics of a High Efficiency Passive Neutron Assay System using alternative neutron detectors to helium-3

 Passive neutron non-destructive assay systems demand high sensitivity in order to be capable of detecting milligram levels of plutonium for safeguards and waste characterization applications. Chamber efficiencies greater than 30% are required for neutron coincidence and multiplicity counting systems. Existing systems are based on 3He proportional counters and require hundreds of liters of this gas. The severe 3He shortage has created a driver to evaluate alternative detectors in this application. An alternate design must meet the following performance requirements: 1) high absolute detection efficiency, 2) low gamma ray sensitivity and 3) short die-away times. In addition, practical aspects of the detectors must be considered including: 1) system lifetime costs, 2) backward compatibility with existing protocols, 3) long term stability in industrial environments, 4) low maintenance, 5) technology maturity, 6) production scalability and 7) materials toxicity. Several alternative sensors are currently available that could potentially meet the above requirements. These include Boron trifluoride (BF3) filled detectors, 10B lined proportional counters (including novel designs that increase surface area) and various scintillators based on 6Li. For each category the most promising candidate has been identified and evaluated for use as a direct replacement for 3He in a typical High Efficiency Passive Neutron Assay System designed for transuranic / low-level waste sentencing with a lower limit of detection of 3700 Bq/g (alpha activity concentration). Performance of the alternative designs has been modeled and compared to the 3He baseline with any potential technical improvements also being considered.",A. P. Simpson; S. Jones; M. J. Clapham; S. A. McElhaney,,,Performance characteristics of a High Efficiency Passive Neutron Assay System using alternative neutron detectors to helium-3,,,10.1109/NSSMIC.2011.6152484 ,IEEE Conferences ,,"Passive neutron non-destructive assay systems demand high sensitivity in order to be capable of detecting milligram levels of plutonium for safeguards and waste characterization applications. Chamber efficiencies greater than 30% are required for neutron coincidence and multiplicity counting systems. Existing systems are based on 3He proportional counters and require hundreds of liters of this gas. The severe 3He shortage has created a driver to evaluate alternative detectors in this application. An alternate design must meet the following performance requirements: 1) high absolute detection efficiency, 2) low gamma ray sensitivity and 3) short die-away times. In addition, practical aspects of the detectors must be considered including: 1) system lifetime costs, 2) backward compatibility with existing protocols, 3) long term stability in industrial environments, 4) low maintenance, 5) technology maturity, 6) production scalability and 7) materials toxicity. Several alternative sensors are currently available that could potentially meet the above requirements. These include Boron trifluoride (BF3) filled detectors, 10B lined proportional counters (including novel designs that increase surface area) and various scintillators based on 6Li. For each category the most promising candidate has been identified and evaluated for use as a direct replacement for 3He in a typical High Efficiency Passive Neutron Assay System designed for transuranic / low-level waste sentencing with a lower limit of detection of 3700 Bq/g (alpha activity concentration). Performance of the alternative designs has been modeled and compared to the 3He baseline with any potential technical improvements also being considered.",1082-3654,,978-1-4673-0120-6,4853-4857,IEEE , ,Helium;Soil;Concrete;Neutrons;Hydrogen;Metals;Geology,,
4704,"Title:A photovoltage-based integrated sensor for nephrotoxicity evaluation under drug stimulation

 A monolithically integrated sensor based on photovoltage technique is developed for kidney metabolism detection under drug toxicity. The sensor utilizes the light-addressable potentiometric sensor with an electrolyte-insulator-semiconductor (EIS) structure for measuring cellular metabolic rate, and a gold metal layer is deposited on partial surface of silicon dioxide for extracellular redox (reduction-oxidation) potential detection. The neonatal rat's kidney cells are confined to a flow chamber with a volume of 50 μl, in which the constructed sensor continuously monitoring the rate of acid metabolites, and the redox potential in extracellular microenvironment. The synthesis parameters detected reflect the cellular metabolic and active condition after drug stimulation, which demonstrates the potentials for nephrotoxicity evaluation and preclinical drug screening.",J. Wang; H. Yu; H. Cai; L. P. Du; Q. J. Liu; P. Wang,,,A photovoltage-based integrated sensor for nephrotoxicity evaluation under drug stimulation,,,10.1109/TRANSDUCERS.2011.5969276 ,IEEE Conferences ,,"A monolithically integrated sensor based on photovoltage technique is developed for kidney metabolism detection under drug toxicity. The sensor utilizes the light-addressable potentiometric sensor with an electrolyte-insulator-semiconductor (EIS) structure for measuring cellular metabolic rate, and a gold metal layer is deposited on partial surface of silicon dioxide for extracellular redox (reduction-oxidation) potential detection. The neonatal rat's kidney cells are confined to a flow chamber with a volume of 50 μl, in which the constructed sensor continuously monitoring the rate of acid metabolites, and the redox potential in extracellular microenvironment. The synthesis parameters detected reflect the cellular metabolic and active condition after drug stimulation, which demonstrates the potentials for nephrotoxicity evaluation and preclinical drug screening.",2164-1641,,978-1-4577-0156-6,2122-2125,IEEE , ,Drugs;Kidney;Electric potential;Extracellular;Biochemistry;Voltage measurement;Silicon,,
4705,"Title:A two-channel bacteria-based biosensor for water quality monitoring

 We created a dual-channel bacteria-based biosensor for sensitive and reliable monitoring of toxic substances in water. We utilized microbial fuel cell (MFC) technology as a biosensor for the detection of water toxicity. A broad range of toxic components can inhibit bacterial metabolic activity, generating a distinct change in the current output of the MFC-based biosensor. The biosensor consisted of two 90μL single-chambered MFCs (detection and reference) with air-cathodes, which significantly simplifies the device configuration. The reference channel sensor was to calibrate the system for environmental changes (e.g., temperature, pressure, viscosity, pH, and non-specific binding) that influence the bacterial metabolisms, thus improving the accuracy of the measurement. In addition, the small-scale MFC biosensor produced favorable conditions for high sensitivity by reducing the internal resistance and increasing mass transfer in the micro-sized chamber.",W. Yang; X. Wei; S. Choi,,,A two-channel bacteria-based biosensor for water quality monitoring,,,10.1109/ICSENS.2015.7370674 ,IEEE Conferences ,,"We created a dual-channel bacteria-based biosensor for sensitive and reliable monitoring of toxic substances in water. We utilized microbial fuel cell (MFC) technology as a biosensor for the detection of water toxicity. A broad range of toxic components can inhibit bacterial metabolic activity, generating a distinct change in the current output of the MFC-based biosensor. The biosensor consisted of two 90μL single-chambered MFCs (detection and reference) with air-cathodes, which significantly simplifies the device configuration. The reference channel sensor was to calibrate the system for environmental changes (e.g., temperature, pressure, viscosity, pH, and non-specific binding) that influence the bacterial metabolisms, thus improving the accuracy of the measurement. In addition, the small-scale MFC biosensor produced favorable conditions for high sensitivity by reducing the internal resistance and increasing mass transfer in the micro-sized chamber.",,,978-1-4799-8203-5,1-4,IEEE , ,Biosensors;Fuel cells;Microorganisms;Anodes;Monitoring;Temperature measurement;Cathodes,,
4706,"Title:Development of portable device for monitoring the lithium level from bipolar disorder patients

 This research aims at developing low cost portable proactive healthcare technologies to put more control into the hands of patients especially who have mental illness so that the earliest signs of health problems with medications can be detected and corrected. Monitoring prescription drugs such as lithium, clozapine etc is important for safe guarding the well-being of the bipolar sufferers. Therapeutically useful amounts of lithium (~ 0.6 to 1.2 mmol/L) are only slightly lower than toxic amounts (>;1.5 mmol/L), so the concentration of lithium must be carefully monitored during treatment to avoid toxicity. A very sensitive analytical method was proposed for the spectrofluorimetric determination of lithium base on its reaction with 1,4-dihydroxyanthraquinone (Quinizarin). The fluorescence is measured at an excitation wavelength of 590 nm and emission wavelength of 620 nm. Saliva sample was tested using the proposed portable device in order to validate the feasibility of saliva as a sample to detect lithium ions. Calibration results presented that linear range of detection was 0.25 mM ~ 6.0 mM of Li+ in saliva with R2=0.99. The range of detection covers sufficiently the therapeutic range of lithium drugs.",J. H. Kim; D. Diamond; K. T. Lau,,,Development of portable device for monitoring the lithium level from bipolar disorder patients,,, ,IEEE Conferences ,,"This research aims at developing low cost portable proactive healthcare technologies to put more control into the hands of patients especially who have mental illness so that the earliest signs of health problems with medications can be detected and corrected. Monitoring prescription drugs such as lithium, clozapine etc is important for safe guarding the well-being of the bipolar sufferers. Therapeutically useful amounts of lithium (~ 0.6 to 1.2 mmol/L) are only slightly lower than toxic amounts (>;1.5 mmol/L), so the concentration of lithium must be carefully monitored during treatment to avoid toxicity. A very sensitive analytical method was proposed for the spectrofluorimetric determination of lithium base on its reaction with 1,4-dihydroxyanthraquinone (Quinizarin). The fluorescence is measured at an excitation wavelength of 590 nm and emission wavelength of 620 nm. Saliva sample was tested using the proposed portable device in order to validate the feasibility of saliva as a sample to detect lithium ions. Calibration results presented that linear range of detection was 0.25 mM ~ 6.0 mM of Li+ in saliva with R2=0.99. The range of detection covers sufficiently the therapeutic range of lithium drugs.",2153-1641,,978-1-936968-15-2,230-233,IEEE , ,Lithium;Fluorescence;Monitoring;Calibration;Drugs;Ions,,
4707,"Title:Magnetic fluids in the blood

 Recently, several medical applications have been proposed for magnetic fluids. These applications, which are reviewed here, involve introduction of magnetic fluids into the blood with subsequent magnetic guidance or magnetic detection by external devices. The issues associated with achieving magnetic guidance and minimizing toxicity are considered. The technical difficulties involved in any of the proposed applications are substantial, and would appear to outweigh the potential advantages at the present time. However, the research and development efforts in this area have been very limited and, therefore, the opportunities for innovation and further progress are significant.",R. Newbower,,,Magnetic fluids in the blood,9,3,10.1109/TMAG.1973.1067671 ,IEEE Journals ,,"Recently, several medical applications have been proposed for magnetic fluids. These applications, which are reviewed here, involve introduction of magnetic fluids into the blood with subsequent magnetic guidance or magnetic detection by external devices. The issues associated with achieving magnetic guidance and minimizing toxicity are considered. The technical difficulties involved in any of the proposed applications are substantial, and would appear to outweigh the potential advantages at the present time. However, the research and development efforts in this area have been very limited and, therefore, the opportunities for innovation and further progress are significant.",1941-0069,,,447-450,IEEE , ,Magnetic liquids;Medical services;Biomedical equipment;Magnetic devices;Magnetic materials;Suspensions;Magnetic susceptibility;Blood flow;Research and development;Technological innovation,,
4708,"Title:Pulse Shape Discrimination Properties of Neutron-Sensitive Organic Scintillators

 The new plastic scintillators with n/γ pulse shape discrimination (PSD) properties being developed by the Lawrence Livermore National Laboratory (LLNL) and commercialized by Eljen Technology are addressing the toxicity and flammability issues of liquid scintillators, thus enabling a much wider range of practical applications for the detection of neutrons. These scintillation materials use multiple dyes, the concentration of which can vary, and therefore the light output and PSD properties of these new materials are expected to vary as well. In this paper, we compare the light signal time profiles of a liquid scintillator and two samples (one from LLNL and one from Eljen Technology) of new plastic scintillators with PSD properties. We acquired the light signal time profiles using both γ sources (60Co, 137Cs, 241Am) and neutrons calibrated in electron-equivalent by the gamma sources. The n/γ PSD properties for time profiles collected are analyzed and discussed with respect to charge integration time.",A. Favalli; M. L. Iliev; K. Chung; C. Hurlbut; H. P. Martinez; M. T. Swinhoe; N. P. Zaitseva; K. D. Ianakiev,,,Pulse Shape Discrimination Properties of Neutron-Sensitive Organic Scintillators,60,2,10.1109/TNS.2013.2251900 ,IEEE Journals ,,"The new plastic scintillators with n/γ pulse shape discrimination (PSD) properties being developed by the Lawrence Livermore National Laboratory (LLNL) and commercialized by Eljen Technology are addressing the toxicity and flammability issues of liquid scintillators, thus enabling a much wider range of practical applications for the detection of neutrons. These scintillation materials use multiple dyes, the concentration of which can vary, and therefore the light output and PSD properties of these new materials are expected to vary as well. In this paper, we compare the light signal time profiles of a liquid scintillator and two samples (one from LLNL and one from Eljen Technology) of new plastic scintillators with PSD properties. We acquired the light signal time profiles using both γ sources (60Co, 137Cs, 241Am) and neutrons calibrated in electron-equivalent by the gamma sources. The n/γ PSD properties for time profiles collected are analyzed and discussed with respect to charge integration time.",1558-1578,,,1053-1056,IEEE , ,Neutrons;Plastics;Liquids;Shape;Protons;Laboratories,,
4709,"Title:Fabrication of polyvalent therapeutic RNA nanoparticles for specific delivery of siRNA, ribozyme and drugs to targeted cells for cancer therapy

 Bacteriophage phi29 DNA packaging motor is geared by a six-pRNA ring. pRNA is able to form a multimeric complex and patterned superstructures via the interaction of two reengineered interlocking loops. This unique feature makes it an ideal polyvalent vehicle for nanomachine fabrication, pathogen detection, and the delivery of therapeutics. This report describes novel approaches for the fabrication of polyvalent therapeutic pRNA nanoparticles, especially tetramers for specific siRNA delivery to cancer cells and for the silencing of targeted genes. RNA 3-D design, circular permutation, folding energy alteration, and nucleotide modification were applied to generate stable RNA nanoparticles with low toxicity. Animal trials demonstrated the high efficiency of the polyvalent RNA nanoparticles in the prevention and treatment of cancer. Using such protein-free nanoparticles as therapeutic reagents would allow for long-term administration to avoid the induction of antibody due to repeated treatment for chronic diseases.",Yi Shu; D. Shu; Z. Diao; G. Shen; P. Guo,,,"Fabrication of polyvalent therapeutic RNA nanoparticles for specific delivery of siRNA, ribozyme and drugs to targeted cells for cancer therapy",,,10.1109/LISSA.2009.4906696 ,IEEE Conferences ,,"Bacteriophage phi29 DNA packaging motor is geared by a six-pRNA ring. pRNA is able to form a multimeric complex and patterned superstructures via the interaction of two reengineered interlocking loops. This unique feature makes it an ideal polyvalent vehicle for nanomachine fabrication, pathogen detection, and the delivery of therapeutics. This report describes novel approaches for the fabrication of polyvalent therapeutic pRNA nanoparticles, especially tetramers for specific siRNA delivery to cancer cells and for the silencing of targeted genes. RNA 3-D design, circular permutation, folding energy alteration, and nucleotide modification were applied to generate stable RNA nanoparticles with low toxicity. Animal trials demonstrated the high efficiency of the polyvalent RNA nanoparticles in the prevention and treatment of cancer. Using such protein-free nanoparticles as therapeutic reagents would allow for long-term administration to avoid the induction of antibody due to repeated treatment for chronic diseases.",,,978-1-4244-4292-8,9-12,IEEE , ,Fabrication;RNA;Nanoparticles;Drugs;Cancer;Medical treatment;DNA;Packaging;Vehicles;Pathogens,,
4710,"Title:Development and initial testing of a novel slime mould biosensor

 A plurality of whole cell biosensors have been developed using many different cell types. Biosensors incorporate biomolecular components or whole cells to facilitate specific analyte interaction; research documented here presents a novel whole cell biosensor based on the slime mould Physarum polycephalum (PP). The electrical response of PP when exposed to multiple chemicals are measured and quantified in terms of amplitude and frequency response. The PP biosensor is capable of detecting the tested chemicals and individually identifying a large number in terms of a specific shift in either oscillation frequency or amplitude. However, it does exhibit a sensitivity to environmental changes such as light level and temperature which may interfere with the detection of the target analyte but could also be used for wider sensing applications. It is proposed that this novel biosensor is capable of detecting many organic chemicals beyond those presented in this work and that the biosensor may be used for environmental monitoring and toxicity evaluation.",J. G. H. Whiting; B. de Lacy Costello; A. Adamatzky,,,Development and initial testing of a novel slime mould biosensor,,,10.1109/EMBC.2014.6944511 ,IEEE Conferences ,,"A plurality of whole cell biosensors have been developed using many different cell types. Biosensors incorporate biomolecular components or whole cells to facilitate specific analyte interaction; research documented here presents a novel whole cell biosensor based on the slime mould Physarum polycephalum (PP). The electrical response of PP when exposed to multiple chemicals are measured and quantified in terms of amplitude and frequency response. The PP biosensor is capable of detecting the tested chemicals and individually identifying a large number in terms of a specific shift in either oscillation frequency or amplitude. However, it does exhibit a sensitivity to environmental changes such as light level and temperature which may interfere with the detection of the target analyte but could also be used for wider sensing applications. It is proposed that this novel biosensor is capable of detecting many organic chemicals beyond those presented in this work and that the biosensor may be used for environmental monitoring and toxicity evaluation.",1558-4615,,978-1-4244-7929-0,4042-4045,IEEE , ,Biosensors;Chemicals;Electrodes;Temperature measurement;Frequency measurement;Electron tubes;Heating,,
4711,"Title:3D Imaging Restoration of Spinning-Disk Confocal Microscopy Via Deep Learning

 Due to the multipoint excitation and simultaneous detection strategy applied, spinning-disk confocal microscopy (SDCM) results in an increased imaging speed compared to conventional confocal microscopy. Additionally, the super-resolution radial fluctuations (SRRF) approach can further improve the imaging resolution of SDCM in 3D imaging at the cost of imaging time due to the large amounts of data acquisition and the increased risk of photo-bleaching and photo-toxicity due to the multiple excitations. Here, we propose a deep learning-based method for 3D SDCM, where the neighboring pixels in z-scanning slices are taken into account for 3D reconstruction. Consequently, high-quality imaging slices can be reconstructed directly from the SDCM stacks with a single scan. The image quality achievable with this SRRF-Deep method is comparable with the SRRF method, whereas it achieves image reconstruction about 30 times faster using 100 times fewer images. Thus, practicality of the SDCM system can be significantly improved in 3D imaging.",C. Bai; X. Yu; T. Peng; C. Liu; J. Min; D. Dan; B. Yao,,,3D Imaging Restoration of Spinning-Disk Confocal Microscopy Via Deep Learning,32,18,10.1109/LPT.2020.3014317 ,IEEE Journals ,,"Due to the multipoint excitation and simultaneous detection strategy applied, spinning-disk confocal microscopy (SDCM) results in an increased imaging speed compared to conventional confocal microscopy. Additionally, the super-resolution radial fluctuations (SRRF) approach can further improve the imaging resolution of SDCM in 3D imaging at the cost of imaging time due to the large amounts of data acquisition and the increased risk of photo-bleaching and photo-toxicity due to the multiple excitations. Here, we propose a deep learning-based method for 3D SDCM, where the neighboring pixels in z-scanning slices are taken into account for 3D reconstruction. Consequently, high-quality imaging slices can be reconstructed directly from the SDCM stacks with a single scan. The image quality achievable with this SRRF-Deep method is comparable with the SRRF method, whereas it achieves image reconstruction about 30 times faster using 100 times fewer images. Thus, practicality of the SDCM system can be significantly improved in 3D imaging.",1941-0174,,,1131-1134,IEEE , ,Three-dimensional displays;Microscopy;Training;Spatial resolution;Image reconstruction,,
4712,"Title:Cytotoxicity of synthesized Iron Oxide nanoparticles: Toward novel biomarkers of colon cancer

 In this paper we present the preliminary results of a novel biological analysis platform for early colon cancer detection using magnetic separation of magnetized markers. The platform consists of a microfluidic structure integrated with biosensors. Super-Paramagnetic Iron Oxide nanoparticles (SPIO-NPs) were functionalized with purified DNA Aptamer and their synthesis is described. In this paper, we also present the physicochemical results of the synthesized SPIO/Au-NPs characterized by TEM and XRD. Toxicity of our synthesized biomarkers on HCT116 cell line is discussed. Based on our findings, a concentration of 1mg/ml of our biomarkers added to 5 × 105 cells per well has no effect the viability of the human cells even after 24 hours.",M. A. Raji; M. Amara; G. Amoabediny; P. Tajik; A. Barin; S. Magierowski; E. Ghafar-Zadeh,,,Cytotoxicity of synthesized Iron Oxide nanoparticles: Toward novel biomarkers of colon cancer,,,10.1109/EMBC.2014.6945040 ,IEEE Conferences ,,"In this paper we present the preliminary results of a novel biological analysis platform for early colon cancer detection using magnetic separation of magnetized markers. The platform consists of a microfluidic structure integrated with biosensors. Super-Paramagnetic Iron Oxide nanoparticles (SPIO-NPs) were functionalized with purified DNA Aptamer and their synthesis is described. In this paper, we also present the physicochemical results of the synthesized SPIO/Au-NPs characterized by TEM and XRD. Toxicity of our synthesized biomarkers on HCT116 cell line is discussed. Based on our findings, a concentration of 1mg/ml of our biomarkers added to 5 × 105 cells per well has no effect the viability of the human cells even after 24 hours.",1558-4615,,978-1-4244-7929-0,6179-6182,IEEE , ,Magnetic resonance imaging;Nanoparticles;Cancer;Magnetic separation;Colon;Iron;Magnetic field measurement,,
4713,"Title:MEMS cantilever based identification of carcinogenic MZN

 In this paper, a novel Micro Electro Mechanical System (MEMS) based cantilever beam of cross section (400×150×1)μm is presented for the detection of Metronidazole (MZN) which can be used in food processing industry to detect its toxicity level in meat. MZN is a drug that is proven to be carcinogenic if used as feed addictive for cattle breeding or aquafarming. Molecular imprinted Gold cantilever beam serves as a loading platform for MZN with high specificity. On mass loading, MZN bio-molecules get adsorbed on the cantilever. Based on the quantitative adsorption of bio-molecule, density of the cantilever changes which in turn contributes to the change in natural frequency. Finite Element Analysis (FEA) is done using Intellisuite MEMS software where the natural frequency shift in mode 1 is approximately 100Hz and the shift in mode 2 is 1KHz for the bio-molecule adsorption.",K. Dhineshkaarthi; S. K. Sathya Lakshmi Preeth; R. Kumar,,,MEMS cantilever based identification of carcinogenic MZN,,,10.1109/ICEICE.2017.8191863 ,IEEE Conferences ,,"In this paper, a novel Micro Electro Mechanical System (MEMS) based cantilever beam of cross section (400×150×1)μm is presented for the detection of Metronidazole (MZN) which can be used in food processing industry to detect its toxicity level in meat. MZN is a drug that is proven to be carcinogenic if used as feed addictive for cattle breeding or aquafarming. Molecular imprinted Gold cantilever beam serves as a loading platform for MZN with high specificity. On mass loading, MZN bio-molecules get adsorbed on the cantilever. Based on the quantitative adsorption of bio-molecule, density of the cantilever changes which in turn contributes to the change in natural frequency. Finite Element Analysis (FEA) is done using Intellisuite MEMS software where the natural frequency shift in mode 1 is approximately 100Hz and the shift in mode 2 is 1KHz for the bio-molecule adsorption.",,,978-1-5090-4996-7,1-4,IEEE , ,Adsorption;Sensors;Structural beams;Gold;Micromechanical devices;Resonant frequency;Instruments,,
4714,"Title:A planar microelectrode array modified by nanoparticles for monitoring of electrophysiological activity of cortical neurons modulated by chemical stimulation

 A multichannel high-throughput microchip device integrating arrays of Pt microelectrodes modified with Pt-black nanoparticles for the measurement of spike activity from individual cells was fabricated. The microfabricated microelectrode arrays with a good noise level and appropriate impedance on glass substrate combined with homemade multichannel acquisition system as a powerful tool for neuroelectrial monitoring. The activity of cortical neurons was recorded at spontaneous and excited state on the system. The changes in activity patterns of cultivated cortical neurons induced by the treatment with chemical (KCl) were analyzed. A detailed analysis of chemical effects on the neurons electrophysiological behavior including spike and burst activity is presented. The cells showed obviously improved activity after stimulation by K+, the firing frequency and firing amplitude increased as well as the higher number of firing channels. The application of chemical (KCl) stimulation modulates the electrophysiological activity of cortical neuronal networks with respect to the spontaneous activity intrinsically shown by the cultured neurons. The proposed approach coupled to MEAs and detection system allows for a more extensive use of in vitro cultured neurons for neuropharmacological applications and which supply the promise of MEA technology as a high throughput, rapid screening method for toxicity testing of chemical.",C. Liu; N. Lin; Y. Song; X. Cai,,,A planar microelectrode array modified by nanoparticles for monitoring of electrophysiological activity of cortical neurons modulated by chemical stimulation,,,10.1109/NANO.2013.6720876 ,IEEE Conferences ,,"A multichannel high-throughput microchip device integrating arrays of Pt microelectrodes modified with Pt-black nanoparticles for the measurement of spike activity from individual cells was fabricated. The microfabricated microelectrode arrays with a good noise level and appropriate impedance on glass substrate combined with homemade multichannel acquisition system as a powerful tool for neuroelectrial monitoring. The activity of cortical neurons was recorded at spontaneous and excited state on the system. The changes in activity patterns of cultivated cortical neurons induced by the treatment with chemical (KCl) were analyzed. A detailed analysis of chemical effects on the neurons electrophysiological behavior including spike and burst activity is presented. The cells showed obviously improved activity after stimulation by K+, the firing frequency and firing amplitude increased as well as the higher number of firing channels. The application of chemical (KCl) stimulation modulates the electrophysiological activity of cortical neuronal networks with respect to the spontaneous activity intrinsically shown by the cultured neurons. The proposed approach coupled to MEAs and detection system allows for a more extensive use of in vitro cultured neurons for neuropharmacological applications and which supply the promise of MEA technology as a high throughput, rapid screening method for toxicity testing of chemical.",1944-9399,,978-1-4799-0676-5,980-984,IEEE , ,Microelectrodes;Neurons;Arrays;Firing;Chemicals;Monitoring,,
4715,"Title:Tumor cell targetting using folate conjugated core/shell CdSe/CdS/ZnS nano rods

 Core-shell-shell nano rods have been widely investigated as fluorescent biomarkers, due to their photochemical stability and high brightness, which makes them a good alternative to organic fluorophores. There are several unique optical properties that can make nano rods (NRs) potentially more appealing bioimaging probes. Hydrophobic core-shell-shell CdSe/CdS/ZnS nano rods (NRs) were synthesized by successive ion layer adsorption and reaction (SILAR) technique. Synthesized NRs (CdSe/CdS/ZnS) were made water dispersible by ligand exchange with thioglycolic acid and were conjugated with folic acid (FA) using EDC/NHS techniques for targeting human cancer cells expressing folate receptor (FR). The Folate receptor (FR) is ideally suited for this study because it is preferentially expressed with high binding affinity for folic acid in several cancers. In vitro cytotoxicity of the folate-conjugated CdSe/CdS-TGA and CdSe/CdS/ZnS-TGA NRs were investigated also by employing MCF-7 cells (Breast cancer cell line) through the 3-(4,5- dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT) assay. This assay shows that core-shell-shell (CdSe/CdS/ZnS) NRs are biocompatible than core- shell (CdSe/CdS) for targeting the cancer cells. The result of MTT viability assay shows that the percentage of living cells gradually decreases for CdSe/CdS rods where as in case of CdSe/CdS/ZnS rods ≥ 80% percentage of cell viability has been observed. These experiments confirms that FA conjugated NRs are preferentially internalized by MCF-7 tumor cells suggesting their potential utility as targeted fluorescent imaging agent for early stage cancer detection. The MTT cell viability assay indicated that covering the CdSe/CdS rods with ZnS shell reduces their cell toxicity.",M. Dalela; H. Singh; U. Soni; S. Sapra,,,Tumor cell targetting using folate conjugated core/shell CdSe/CdS/ZnS nano rods,,,10.1109/ICANMEET.2013.6609261 ,IEEE Conferences ,,"Core-shell-shell nano rods have been widely investigated as fluorescent biomarkers, due to their photochemical stability and high brightness, which makes them a good alternative to organic fluorophores. There are several unique optical properties that can make nano rods (NRs) potentially more appealing bioimaging probes. Hydrophobic core-shell-shell CdSe/CdS/ZnS nano rods (NRs) were synthesized by successive ion layer adsorption and reaction (SILAR) technique. Synthesized NRs (CdSe/CdS/ZnS) were made water dispersible by ligand exchange with thioglycolic acid and were conjugated with folic acid (FA) using EDC/NHS techniques for targeting human cancer cells expressing folate receptor (FR). The Folate receptor (FR) is ideally suited for this study because it is preferentially expressed with high binding affinity for folic acid in several cancers. In vitro cytotoxicity of the folate-conjugated CdSe/CdS-TGA and CdSe/CdS/ZnS-TGA NRs were investigated also by employing MCF-7 cells (Breast cancer cell line) through the 3-(4,5- dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT) assay. This assay shows that core-shell-shell (CdSe/CdS/ZnS) NRs are biocompatible than core- shell (CdSe/CdS) for targeting the cancer cells. The result of MTT viability assay shows that the percentage of living cells gradually decreases for CdSe/CdS rods where as in case of CdSe/CdS/ZnS rods ≥ 80% percentage of cell viability has been observed. These experiments confirms that FA conjugated NRs are preferentially internalized by MCF-7 tumor cells suggesting their potential utility as targeted fluorescent imaging agent for early stage cancer detection. The MTT cell viability assay indicated that covering the CdSe/CdS rods with ZnS shell reduces their cell toxicity.",,,978-1-4799-1379-4,144-147,IEEE , ,Nanobioscience;Probes;Quantum dots;Heating,,
4716,"Title:Engineered nanoparticles for targeted drug delivery

 DNA based nanostructures and advances in DNA origami techniques have shown great potential in fabrication and of nanostructures and devices. Though a large number of DNA origami structures have been reported [1-3], very few applications of DNA structures have been presented. Custom shapes formed by programmable DNA self assembly can be used to engineer nanoscale devices such as a biological antenna. The focus of our research is to design a nanoscale antenna using DNA biostructure as a scaffold. Conductivity of such a biological antenna can be achieved by using conductive nanoparticles coating on DNA [4] or by attaching conducting polymers to DNA structures[5]. In this paper, we will present design of engineered nano-antennas with well defined engineering characteristics. Engineered nano-antennas have a resonant frequency, that can be used for diagnostic and drug delivery. The ability of such antennas to resonate at a particular frequency will give researchers the ability to communicate and control the nanoparticles. Such nanoparticles are carriers that can be used as advanced detection systems to help identifying toxicity of nanoparticles in the body. Organic molecules, such as folic acid, can be easily bonded to the surface of antenna to detect cancerous cells. We will further discuss detailed DNA origami techniques that can be used to realize such nanostructures.",M. Breland; B. Patel; H. Bajwa,,,Engineered nanoparticles for targeted drug delivery,,,10.1109/LISAT.2012.6223198 ,IEEE Conferences ,,"DNA based nanostructures and advances in DNA origami techniques have shown great potential in fabrication and of nanostructures and devices. Though a large number of DNA origami structures have been reported [1-3], very few applications of DNA structures have been presented. Custom shapes formed by programmable DNA self assembly can be used to engineer nanoscale devices such as a biological antenna. The focus of our research is to design a nanoscale antenna using DNA biostructure as a scaffold. Conductivity of such a biological antenna can be achieved by using conductive nanoparticles coating on DNA [4] or by attaching conducting polymers to DNA structures[5]. In this paper, we will present design of engineered nano-antennas with well defined engineering characteristics. Engineered nano-antennas have a resonant frequency, that can be used for diagnostic and drug delivery. The ability of such antennas to resonate at a particular frequency will give researchers the ability to communicate and control the nanoparticles. Such nanoparticles are carriers that can be used as advanced detection systems to help identifying toxicity of nanoparticles in the body. Organic molecules, such as folic acid, can be easily bonded to the surface of antenna to detect cancerous cells. We will further discuss detailed DNA origami techniques that can be used to realize such nanostructures.",,,978-1-4577-1343-9,1-5,IEEE , ,DNA;Antennas;Nanoparticles;Spirals;Nanoscale devices;Nanobioscience;Cancer,,
4717,"Title:Effective Targeting of Hepatocellular Carcinoma through Glypican-3 Ligand Peptide Functionalization of Silica Nanoparticles

 Among the various nanosized particles developed for innovative biomedical applications, like selective molecular imaging and targeted drug delivery, silica nanoparticles (SiNPs) seem to be particularly attractive since of their low cost, low toxicity, ease of functionalization and acoustic properties. In fact, SiNPs have been demonstrated to effectively enhance ultrasound contrast at clinical diagnostic frequencies and, therefore, they might be potentially employed in non-ionizing echographic molecular imaging. Aim of this work was the development of a silica nanoparticle based system for in vitro molecular imaging of hepatocellular carcinoma, using both ultrasound and laser-scanning confocal microscopy, by exploiting the particular feature of these tumor cells to express on their surface high levels of Glypican-3 protein (GPC-3). At this regard, we have designed and characterized novel GPC-3 ligand peptide-functionalized fluorescent silica nanoparticles and tested them on GPC-3 positive HepG2 cells, a human hepatocarcinoma cell line. Laser scanning confocal microscopy analysis showed that GPC-3-targeted fuorescent SiNP, in the concentration range used for experimental ultrasound detection, did not exert significant cytotoxic effects and were effectively bound and taken up by HepG2 cells. These results suggest that silica nanoparticles might be a very promising contrast agents for non-ionizing ultrasound molecular imaging since of their high biocompatibility, targeting effectiveness and ultrasound enhancement power.",M. Di Paola; F. Conversano; E. A. Sbenaglia; S. Casciaro; A. Quarta; G. Gigli; L. Dini,,,Effective Targeting of Hepatocellular Carcinoma through Glypican-3 Ligand Peptide Functionalization of Silica Nanoparticles,,,10.1109/NANOFIM.2015.8425273 ,IEEE Conferences ,,"Among the various nanosized particles developed for innovative biomedical applications, like selective molecular imaging and targeted drug delivery, silica nanoparticles (SiNPs) seem to be particularly attractive since of their low cost, low toxicity, ease of functionalization and acoustic properties. In fact, SiNPs have been demonstrated to effectively enhance ultrasound contrast at clinical diagnostic frequencies and, therefore, they might be potentially employed in non-ionizing echographic molecular imaging. Aim of this work was the development of a silica nanoparticle based system for in vitro molecular imaging of hepatocellular carcinoma, using both ultrasound and laser-scanning confocal microscopy, by exploiting the particular feature of these tumor cells to express on their surface high levels of Glypican-3 protein (GPC-3). At this regard, we have designed and characterized novel GPC-3 ligand peptide-functionalized fluorescent silica nanoparticles and tested them on GPC-3 positive HepG2 cells, a human hepatocarcinoma cell line. Laser scanning confocal microscopy analysis showed that GPC-3-targeted fuorescent SiNP, in the concentration range used for experimental ultrasound detection, did not exert significant cytotoxic effects and were effectively bound and taken up by HepG2 cells. These results suggest that silica nanoparticles might be a very promising contrast agents for non-ionizing ultrasound molecular imaging since of their high biocompatibility, targeting effectiveness and ultrasound enhancement power.",,,978-1-5090-5151-9,131-135,IEEE , ,Nanoparticles;Silicon compounds;Microscopy;Fluorescence;Ultrasonic imaging;Peptides;Molecular imaging,,
4718,"Title:Rapid quantification system for zinc in blood serum

 Pediatric septic shock is a major health problem in the United States, with 42,000 cases annually and an approximate 10% mortality rate. Studies have shown that pediatric septic shock patients regularly have critically low levels of serum zinc (Zn), suggesting oral supplementation of Zn as a therapeutic strategy. To protect patients, it is exceedingly important to monitor blood serum concentration of Zn during supplementation in order to ensure normal physiological levels and watch for heavy metal toxicity due to over supplementation. Current quantification methods typically involve the use of external laboratory facilities and turnaround times ranging from hours to days. This paper presents an improved Point-of-Care device centered on a three electrode Cu based sensor that uses Anodic Stripping Voltammetry (ASV) for rapid electrochemical measurement of Zn in serum. This next-generation device incorporates two major improvements over those presented previously - an evolution to a single printed circuit board (PCB) design, and the incorporation of automated concentration detection. The sensor is able to produce quantification results in approximately 6 minutes.",B. Zerhusen; G. de Silva; X. Pei; I. Papautsky; F. R. Beyette,,,Rapid quantification system for zinc in blood serum,,,10.1109/MWSCAS.2013.6674670 ,IEEE Conferences ,,"Pediatric septic shock is a major health problem in the United States, with 42,000 cases annually and an approximate 10% mortality rate. Studies have shown that pediatric septic shock patients regularly have critically low levels of serum zinc (Zn), suggesting oral supplementation of Zn as a therapeutic strategy. To protect patients, it is exceedingly important to monitor blood serum concentration of Zn during supplementation in order to ensure normal physiological levels and watch for heavy metal toxicity due to over supplementation. Current quantification methods typically involve the use of external laboratory facilities and turnaround times ranging from hours to days. This paper presents an improved Point-of-Care device centered on a three electrode Cu based sensor that uses Anodic Stripping Voltammetry (ASV) for rapid electrochemical measurement of Zn in serum. This next-generation device incorporates two major improvements over those presented previously - an evolution to a single printed circuit board (PCB) design, and the incorporation of automated concentration detection. The sensor is able to produce quantification results in approximately 6 minutes.",1558-3899,,978-1-4799-0066-4,400-403,IEEE , ,Zinc;Electrodes;Calibration;Electric potential;Blood;Testing,,
4719,"Title:The Quantitative Assessment of Gd-DTPA in Contrast Enhanced Magnetic Resonance Angiography

 Recently, the use of MRI contrast agents has been proven to be substantially improved sensitivity and specificity in many clinical applications. CE-MRA has higher blood signal based on the T1 and T2-shortening property of contrast agents, so that even the small vessels can be visualized. The use of contrast agents can improve lesion detection and characterization. The routinely used dose of contrast agents in the routine MRI examinations only relies on the weight of the subject. The purpose of this study is to obtain the clinically optimal dose for 3D-TOF (time-of-flight) pulse sequences for CE-MRA examinations. In the phantom study, ten test tubes were filled with saline mixed with different dose of Gd-DTPA. It is found that the optimal dose of Gd-DTPA for saline phantom by using 3D-TOF pulse sequences is 20 mM. Also, there has no differences of optimal doses between Omniscan and Magnivist contrast agents Gd-DTPA. The results show that consistent high quality CE-MRA images might be obtained by using 0.25M Gd-DTPA (half of the routine dose) with 3~4 cc/sec injection rate for all clinical cases. The benefits of this study might be to minimize dose and potential toxicity. Additionally, the decrease of the cost of contrast agents might be achieved. It is expected to provide the recommended dose of Gd-DTPA for contrast enhanced MRA in clinical routine diagnosis",C. . -C. Hsiao; J. . -C. Jao; Y. . -N. Ting; H. . -B. Pan; S. . -T. Lai; P. . -C. Chen,,,The Quantitative Assessment of Gd-DTPA in Contrast Enhanced Magnetic Resonance Angiography,,,10.1109/IEMBS.2005.1616687 ,IEEE Conferences ,,"Recently, the use of MRI contrast agents has been proven to be substantially improved sensitivity and specificity in many clinical applications. CE-MRA has higher blood signal based on the T1 and T2-shortening property of contrast agents, so that even the small vessels can be visualized. The use of contrast agents can improve lesion detection and characterization. The routinely used dose of contrast agents in the routine MRI examinations only relies on the weight of the subject. The purpose of this study is to obtain the clinically optimal dose for 3D-TOF (time-of-flight) pulse sequences for CE-MRA examinations. In the phantom study, ten test tubes were filled with saline mixed with different dose of Gd-DTPA. It is found that the optimal dose of Gd-DTPA for saline phantom by using 3D-TOF pulse sequences is 20 mM. Also, there has no differences of optimal doses between Omniscan and Magnivist contrast agents Gd-DTPA. The results show that consistent high quality CE-MRA images might be obtained by using 0.25M Gd-DTPA (half of the routine dose) with 3~4 cc/sec injection rate for all clinical cases. The benefits of this study might be to minimize dose and potential toxicity. Additionally, the decrease of the cost of contrast agents might be achieved. It is expected to provide the recommended dose of Gd-DTPA for contrast enhanced MRA in clinical routine diagnosis",1558-4615,,0-7803-8741-4,1385-1387,IEEE , ,Magnetic resonance;Angiography;Magnetic resonance imaging;Imaging phantoms;Sensitivity and specificity;Blood;Visualization;Lesions;Testing;Costs,,
4720,"Title:Development of the first autonomous, in-situ microcystin immunoassay for the inaugural freshwater deployment on the Environmental Sampler Processor

 Here we present achievements and challenges associated with the inaugural freshwater deployment of the Environmental Sampler Processor (ESP) in the western Lake Erie. We discuss scientific advances in the detection methodology related to utilizing the ESP for monitoring toxic cHABs and establishing the ability to provide water resource managers with early warning of impending toxicity.",A. Ritzenthaler; C. Mikulski; R. Marin; B. Roman; J. Mickett; C. Siani; G. Doucette; T. W. Davis,,,"Development of the first autonomous, in-situ microcystin immunoassay for the inaugural freshwater deployment on the Environmental Sampler Processor",,,10.1109/OCEANS.2016.7761003 ,IEEE Conferences ,,Here we present achievements and challenges associated with the inaugural freshwater deployment of the Environmental Sampler Processor (ESP) in the western Lake Erie. We discuss scientific advances in the detection methodology related to utilizing the ESP for monitoring toxic cHABs and establishing the ability to provide water resource managers with early warning of impending toxicity.,,,978-1-5090-1537-5,1-4,IEEE , ,Lakes;Instruments;Monitoring;Oceans;Water pollution;Protocols;Calibration,,
4721,"Title:KNN-based single crystal high frequency transducer for intravascular photoacoustic imaging

 Intravascular photoacoustic (IVPA) imaging, which combines the advantages of high ultrasonic resolution and strong optical absorption contrast, seems to be an alternative method to detect lipid pool and atherosclerotic lesion. A highly sensitive miniaturized ultrasound transducer is required for receiving of intravascular photoacoustic signals. As the core part of the transducer, lead-based piezoelectric materials have been most popular for IVPA applications because of their excellent piezoelectric behavior. However, in view of environmental protection and human safety issues, the use of lead is a problem due to its toxicity. Therefore, it is of urgent need to develop lead-free piezoelectric materials that can be used as intravascular PA signal receivers. The aim of the present study is to demonstrate the feasibility of KNN-based single crystals to be implemented in IVPA applications for the detection of lipid pool and calcification.",B. Zhu; W. Wei; X. Yang; Y. Li; Q. Zhou; K. K. Shung,,,KNN-based single crystal high frequency transducer for intravascular photoacoustic imaging,,,10.1109/ULTSYM.2017.8092368 ,IEEE Conferences ,,"Intravascular photoacoustic (IVPA) imaging, which combines the advantages of high ultrasonic resolution and strong optical absorption contrast, seems to be an alternative method to detect lipid pool and atherosclerotic lesion. A highly sensitive miniaturized ultrasound transducer is required for receiving of intravascular photoacoustic signals. As the core part of the transducer, lead-based piezoelectric materials have been most popular for IVPA applications because of their excellent piezoelectric behavior. However, in view of environmental protection and human safety issues, the use of lead is a problem due to its toxicity. Therefore, it is of urgent need to develop lead-free piezoelectric materials that can be used as intravascular PA signal receivers. The aim of the present study is to demonstrate the feasibility of KNN-based single crystals to be implemented in IVPA applications for the detection of lipid pool and calcification.",1948-5727,,978-1-5386-3383-0,1-1,IEEE , ,Crystals;Transducers;Optical device fabrication;Optical imaging;Optical receivers;Optical sensors;Biomedical optical imaging,,
4722,"Title:A Review on Prediction of Early Heart Attack Based on Degradation of Graphene Oxide and Carbon Nanotube using Myeloperoxidase

 This paper focuses on the study of the relationship between Myeloperoxidase (MPO) and Graphene Oxide (GO); and the relation between MPO and Carbon Nanotubes (CNT). Recent studies have claimed that an increase concentration of MPO in human blood occurs due to increased levels of cholesterol in human body. The increased concentration of the MPO can be detected by the single walled CNT and GO, as MPO degrades them. We have reviewed the degradation rate with the chemical reactions of GO and CNT with MPO. We have provided a detailed study of reactions to check their toxicity, spectroscopy and zeta potential. The paper provides a detailed study to detect the increased level of MPO to identify the increased concentration of cholesterol in human body leading to human heart health issues in day to day life. Early diagnosis of heart attack is possible with the detection of MPO based on several methods studied in this paper.",S. S. Kothavade; A. S. Kulkarni; A. D. Sawant; D. Patel,,,A Review on Prediction of Early Heart Attack Based on Degradation of Graphene Oxide and Carbon Nanotube using Myeloperoxidase,,,10.1109/SCEECS48394.2020.169 ,IEEE Conferences ,,"This paper focuses on the study of the relationship between Myeloperoxidase (MPO) and Graphene Oxide (GO); and the relation between MPO and Carbon Nanotubes (CNT). Recent studies have claimed that an increase concentration of MPO in human blood occurs due to increased levels of cholesterol in human body. The increased concentration of the MPO can be detected by the single walled CNT and GO, as MPO degrades them. We have reviewed the degradation rate with the chemical reactions of GO and CNT with MPO. We have provided a detailed study of reactions to check their toxicity, spectroscopy and zeta potential. The paper provides a detailed study to detect the increased level of MPO to identify the increased concentration of cholesterol in human body leading to human heart health issues in day to day life. Early diagnosis of heart attack is possible with the detection of MPO based on several methods studied in this paper.",2688-0288,,978-1-7281-4862-5,1-6,IEEE , ,Degradation;Water;Toxicology;Graphene;Cardiac arrest;Carbon nanotubes;Blood,,
4723,"Title:Multiparametric MEMS biosensor for cell culture monitoring

 A novel micro-electro-mechanical (MEMS) multiparametric biosensor system based on living cells is presented. The biosensor system includes two biosensing techniques; resonant frequency measurements and electric cell-substrate impedance sensing (ECIS) on a single device. The multiparametric sensor system integrates uses the upper electrode of a quartz crystal microbalance (QCM) resonator and as working microelectrode for ECIS technique. The QCM consists of a thin AT-cut quartz substrate with two gold electrodes on opposite sides. Bovine aortic endothelial live cells (BAECs) were successfully cultured on this hybrid biosensor. The QCM upper gold electrode used for generating the acoustic wave is also used for ECIS measurements of the live cells. Gravimetric and impedimetric measurements were performed over a period of time on the same cell culture to validate the device's sensitivity. The time necessary for the cells to attach and form a compact monolayer is the same in the case of gravimetric and impedimetric measurements. This hybrid biosensor will be employed in the future for water toxicity detection.",F. Liu; A. N. Nordin; I. Voiculescu,,,Multiparametric MEMS biosensor for cell culture monitoring,,, ,IEEE Conferences ,,A novel micro-electro-mechanical (MEMS) multiparametric biosensor system based on living cells is presented. The biosensor system includes two biosensing techniques; resonant frequency measurements and electric cell-substrate impedance sensing (ECIS) on a single device. The multiparametric sensor system integrates uses the upper electrode of a quartz crystal microbalance (QCM) resonator and as working microelectrode for ECIS technique. The QCM consists of a thin AT-cut quartz substrate with two gold electrodes on opposite sides. Bovine aortic endothelial live cells (BAECs) were successfully cultured on this hybrid biosensor. The QCM upper gold electrode used for generating the acoustic wave is also used for ECIS measurements of the live cells. Gravimetric and impedimetric measurements were performed over a period of time on the same cell culture to validate the device's sensitivity. The time necessary for the cells to attach and form a compact monolayer is the same in the case of gravimetric and impedimetric measurements. This hybrid biosensor will be employed in the future for water toxicity detection.,,,978-2-35500-026-3,1-5,IEEE , ,Electrodes;Biosensors;Impedance;Monitoring;Resonant frequency;Acoustic waves;Biomedical monitoring,,
4724,"Title:MONDO: A neutron tracker for particle therapy secondary emission measurements

 In Particle Therapy, cancer treatments are performed using accelerated charged particles whose high irradiation precision and conformity permit to destroy the tumour while sparing the surrounding healthy tissues. Several secondary particles are produced during the treatments mainly photons, protons and neutrons. The reduced attenuation length of neutrons yields a secondary particle sample that is larger in number when compared to photons and charged particles. Since neutrons can release a significant dose far away from the tumour region, a precise measurement of their flux, production energy and angle distributions is eagerly needed in order to improve the Treatment Planning Systems (TPS) software, so to properly take into account not only the normal tissue toxicity in the target region, but also the risk of late complications in the whole body. The MONDO (MOnitor for Neutron Dose in hadrOntherapy) project addresses the technical challenges posed by a neutron detector aiming for high detection efficiency and good backtracking precision. The main goal of the project is to develop a tracking detector targeting fast and ultra-fast secondary neutrons based on the reconstruction of two consequent elastic scattering interactions of a neutron with a target material. By reconstructing the recoiling protons, it is hence possible to measure the energy and incoming direction of the neutron using different therapeutic beams (protons, 12C ions and possibly 4He and 16O ions). The detector will be composed by a tracker realized with squared scintillating fibres and read out by a dedicated CMOS-based digital SPAD array detector. The first experimental results of a tracker demonstrator are here presented.",L. Gasparini; R. Mirabelli; V. Patera; D. Pinci; A. Sarti; A. Sciubba; E. Spiriti; D. Stoppa; M. Marafini,,,MONDO: A neutron tracker for particle therapy secondary emission measurements,,,10.1109/NSSMIC.2016.8069401 ,IEEE Conferences ,,"In Particle Therapy, cancer treatments are performed using accelerated charged particles whose high irradiation precision and conformity permit to destroy the tumour while sparing the surrounding healthy tissues. Several secondary particles are produced during the treatments mainly photons, protons and neutrons. The reduced attenuation length of neutrons yields a secondary particle sample that is larger in number when compared to photons and charged particles. Since neutrons can release a significant dose far away from the tumour region, a precise measurement of their flux, production energy and angle distributions is eagerly needed in order to improve the Treatment Planning Systems (TPS) software, so to properly take into account not only the normal tissue toxicity in the target region, but also the risk of late complications in the whole body. The MONDO (MOnitor for Neutron Dose in hadrOntherapy) project addresses the technical challenges posed by a neutron detector aiming for high detection efficiency and good backtracking precision. The main goal of the project is to develop a tracking detector targeting fast and ultra-fast secondary neutrons based on the reconstruction of two consequent elastic scattering interactions of a neutron with a target material. By reconstructing the recoiling protons, it is hence possible to measure the energy and incoming direction of the neutron using different therapeutic beams (protons, 12C ions and possibly 4He and 16O ions). The detector will be composed by a tracker realized with squared scintillating fibres and read out by a dedicated CMOS-based digital SPAD array detector. The first experimental results of a tracker demonstrator are here presented.",,,978-1-5090-1642-6,1-3,IEEE , ,Neutrons;Detectors;Protons;Photonics;Prototypes;Medical treatment;Production,,
4725,"Title:Fast denoising for fluorescence image sequences in a nonlocal means framework

 In fluorescence live-cell imaging there is always a trade-off between image quality and cell viability. While avoiding photo bleaching and photo toxicity, light exposure time must be limited which results in low signal-to-noise ratio. We present a fast non-local means technique to denoise 3D image sequences acquired via fluorescence microscopy. The commonly used non-local means filter for image sequences is computationally inefficient. We reduce the computational cost by carrying out the denoising in the lower dimensional subspace determined by principal component analysis (PCA). Image neighbourhoods are projected onto the lower dimensional subspace determined by PCA. We use shot boundary detection as a preprocessing step to identify and form different shots with content-wise similar frames. We show that the proposed method reduces the computations in addition to improving the accuracy. Our results are also compared with other fast NLM based techniques.",H. Bhujle; A. Gupta,,,Fast denoising for fluorescence image sequences in a nonlocal means framework,,,10.1109/SPCOM.2014.6983937 ,IEEE Conferences ,,"In fluorescence live-cell imaging there is always a trade-off between image quality and cell viability. While avoiding photo bleaching and photo toxicity, light exposure time must be limited which results in low signal-to-noise ratio. We present a fast non-local means technique to denoise 3D image sequences acquired via fluorescence microscopy. The commonly used non-local means filter for image sequences is computationally inefficient. We reduce the computational cost by carrying out the denoising in the lower dimensional subspace determined by principal component analysis (PCA). Image neighbourhoods are projected onto the lower dimensional subspace determined by PCA. We use shot boundary detection as a preprocessing step to identify and form different shots with content-wise similar frames. We show that the proposed method reduces the computations in addition to improving the accuracy. Our results are also compared with other fast NLM based techniques.",2165-0608,,978-1-4799-4665-5,1-6,IEEE , ,Noise reduction;Image sequences;Noise;Principal component analysis;Noise measurement;Microscopy;Noise level,,
4726,"Title:On the application of surface enhanced Raman scattering to study the interaction of DsRed fluorescent proteins with silver nanoparticles embedded in thin silica layers

 The interaction of proteins with silver nanoparticles (AgNPs) is of primary importance to uncover silver antimicrobial efficiency and environmental hazard. This interaction can affect silver reactivity, bioavailability and, eventually, silver toxicity towards the environmental media. Detection of the interaction of DsRed fluorescent proteins with AgNPs embedded in thin silica layers is demonstrated using surface enhanced Raman spectroscopy (SERS), but deep analyses require the design and elaboration of dedicated plasmonic substrates giving a high enhancement factor.",M. Soumbo; A. Pugliara; A. Mlayah; M. . -C. Monje; C. Roques; B. Despax; C. Bonafos; R. Carles; K. Makasheva,,,On the application of surface enhanced Raman scattering to study the interaction of DsRed fluorescent proteins with silver nanoparticles embedded in thin silica layers,,,10.1109/NMDC.2016.7777162 ,IEEE Conferences ,,"The interaction of proteins with silver nanoparticles (AgNPs) is of primary importance to uncover silver antimicrobial efficiency and environmental hazard. This interaction can affect silver reactivity, bioavailability and, eventually, silver toxicity towards the environmental media. Detection of the interaction of DsRed fluorescent proteins with AgNPs embedded in thin silica layers is demonstrated using surface enhanced Raman spectroscopy (SERS), but deep analyses require the design and elaboration of dedicated plasmonic substrates giving a high enhancement factor.",,,978-1-5090-4352-1,1-2,IEEE , ,,,
4727,"Title:Torsadogenic drug-induced increased short-term variability of JT-area

 Increased beat-to-beat variability of repolarization (BVR) has been suggested to indicate increased susceptibility to drug-induced arrhythmia. This study aimed to characterize BVR in patients before and after administration of sotalol, a torsadogenic antiarrhythmic drug, in the search for new biomarkers of proarrhythmic risk. ECG Recordings pre and post sotalol injection in two groups of patients (with and without history of drug-induced torsades de pointes) were obtained from THEW. ECG wave detection and delineation were performed via dyadic wavelet transform. BVR was evaluated by short-term variability (STV) of QTc interval and JT area. In both groups, sotalol resulted in significant increase in STV of JT area, while no significant change occurred in STV of QTc interval. Thus, STV of JT area, as a measure of BVR, has the potential to be a biomarker for drug toxicity.",X. Jie; B. Rodriguez; E. Pueyo,,,Torsadogenic drug-induced increased short-term variability of JT-area,,, ,IEEE Conferences ,,"Increased beat-to-beat variability of repolarization (BVR) has been suggested to indicate increased susceptibility to drug-induced arrhythmia. This study aimed to characterize BVR in patients before and after administration of sotalol, a torsadogenic antiarrhythmic drug, in the search for new biomarkers of proarrhythmic risk. ECG Recordings pre and post sotalol injection in two groups of patients (with and without history of drug-induced torsades de pointes) were obtained from THEW. ECG wave detection and delineation were performed via dyadic wavelet transform. BVR was evaluated by short-term variability (STV) of QTc interval and JT area. In both groups, sotalol resulted in significant increase in STV of JT area, while no significant change occurred in STV of QTc interval. Thus, STV of JT area, as a measure of BVR, has the potential to be a biomarker for drug toxicity.",2325-8853,,978-1-4244-7319-9,353-356,IEEE , ,Electrocardiography;Drugs;Biomarkers;History;Lead;Cardiology;Dogs,,
4728,"Title:Determination of Trace Arsenic in the Qin River by Paper Absorption Spectrophotometry

 Arsenic compounds are highly toxic and the toxicity of trivalent arsenic compounds is more powerful than others. There are many ways of its determination. This article describes the determination of trace Arsenic in Qin River by Paper Absorption Spectrophotometry. The result indicate that the limit of detection of this method is 0.001 mg/L, the standard deviation is 0.0007 mg/L and the mark-on recovery ranged from 95.0%~105.6%. Meanwhile, several problems needing attention about experiment process are posed in this paper.",J. -h. Zhou; J. -g. Zhao; P. Li,,,Determination of Trace Arsenic in the Qin River by Paper Absorption Spectrophotometry,1,,10.1109/CESCE.2010.27 ,IEEE Conferences ,,"Arsenic compounds are highly toxic and the toxicity of trivalent arsenic compounds is more powerful than others. There are many ways of its determination. This article describes the determination of trace Arsenic in Qin River by Paper Absorption Spectrophotometry. The result indicate that the limit of detection of this method is 0.001 mg/L, the standard deviation is 0.0007 mg/L and the mark-on recovery ranged from 95.0%~105.6%. Meanwhile, several problems needing attention about experiment process are posed in this paper.",,,978-1-4244-5924-7,312-314,IEEE , ,Rivers;Absorption;Testing;Optical filters;Cotton;Monitoring;Lead;Humans;Silver;Spectroscopy,,
4729,"Title:In vivo molecular sensing for image-guided surgery

 Today image-guided surgery has undergone a great expansion as recent advances of imaging have allowed surgeons to perform more complex procedures with increased safety. A set of preoperative or intraoperative images such as CT or MRI are acquired to build the patient-specific 3D models of anatomy. Unfortunately, however, these instruments are not adequate for molecular imaging. Recent developments in optical and fluorophore technologies have enabled us to visualize functional molecules not only in animals but also in human. In spite of the limitations, such as poor light penetration into the deeper area, laser toxicity, and undesirable staining, the in vivo optical imaging technique appears to be an extremely valuable tool for the precise detection of malignant and ischemic lesions. Here, I will demonstrate novel two optical techniques using 5-ALA fluorescence and spontaneous Raman spectroscopy for biomedical applications.",T. Takamatsu,,,In vivo molecular sensing for image-guided surgery,,,10.1109/ICSJ.2016.7801297 ,IEEE Conferences ,,"Today image-guided surgery has undergone a great expansion as recent advances of imaging have allowed surgeons to perform more complex procedures with increased safety. A set of preoperative or intraoperative images such as CT or MRI are acquired to build the patient-specific 3D models of anatomy. Unfortunately, however, these instruments are not adequate for molecular imaging. Recent developments in optical and fluorophore technologies have enabled us to visualize functional molecules not only in animals but also in human. In spite of the limitations, such as poor light penetration into the deeper area, laser toxicity, and undesirable staining, the in vivo optical imaging technique appears to be an extremely valuable tool for the precise detection of malignant and ischemic lesions. Here, I will demonstrate novel two optical techniques using 5-ALA fluorescence and spontaneous Raman spectroscopy for biomedical applications.",,,978-1-5090-2037-9,93-94,IEEE , ,Surgery;Fluorescence;Raman scattering;Cancer;Lymph nodes;Biomedical imaging,,
4730,"Title:Optical sensor for nanoparticles

 In this paper we investigate a method for the detection of nanoparticles in order to reduce the risk associated with their toxicity, by taking into account the electromagnetic characteristics and the chemical analysis of the surface of a hybrid silicon photonic microresonator. Device sensing capabilities, both optical and chemical, are optimized in order to detect and size the nanoparticle. Thus, a silicon on insulator whispering gallery mode hybrid microresonator having an outer radius of 5 μm and features that are typical of both ring and disk resonators, has been modeled. Quantum electrodynamics principles have been exploited in order to derive the master equation associated with the nanoparticle-resonator interaction. To allow a complete modeling of the sensor attention has been paid to the nanoparticle treatment, with the result that tested nanoparticles need to be chemically stabilized, monodisperse and formed by noble metal nanocolloids, in which a metal core (e.g. Au, Pd, etc) is surrounded by a monolayer or sub-monolayer film of an organic capping agent.",C. Ciminelli; C. M. Campanella; R. Pilolli; N. Cioffi; M. N. Armenise,,,Optical sensor for nanoparticles,,,10.1109/ICTON.2011.5970964 ,IEEE Conferences ,,"In this paper we investigate a method for the detection of nanoparticles in order to reduce the risk associated with their toxicity, by taking into account the electromagnetic characteristics and the chemical analysis of the surface of a hybrid silicon photonic microresonator. Device sensing capabilities, both optical and chemical, are optimized in order to detect and size the nanoparticle. Thus, a silicon on insulator whispering gallery mode hybrid microresonator having an outer radius of 5 μm and features that are typical of both ring and disk resonators, has been modeled. Quantum electrodynamics principles have been exploited in order to derive the master equation associated with the nanoparticle-resonator interaction. To allow a complete modeling of the sensor attention has been paid to the nanoparticle treatment, with the result that tested nanoparticles need to be chemically stabilized, monodisperse and formed by noble metal nanocolloids, in which a metal core (e.g. Au, Pd, etc) is surrounded by a monolayer or sub-monolayer film of an organic capping agent.",2161-2064,,978-1-4577-0882-4,1-4,IEEE , ,Nanoparticles;Gold;Economic indicators;Microcavities;Photonics;Cancer,,
4731,"Title:Population dynamics and spatial distribution of phycotoxic microalgae associated with shellfish aquaculture sites in Nova Scotia

 Summary form only given. Coastal shellfish aquaculture sites are subject to seasonal blooms of toxic microalgae, which may result in restrictions on shellfish harvest due to human health risk. In southeastern Nova Scotia, such toxic episodes are uncommon, although significant numbers of putatively toxigenic phytoplankton are often found in the water column. In most coastal regions where diarrhetic shellfish poisoning (DSP) incidents have occurred, the events have been associated with blooms of species of the planktonic dinoflagellate Dinophysis. However, despite repeated attempts over several years, the authors have been unable to link the presence of DSP toxicity in Nova Scotian shellfish to the timing and magnitude of seasonal blooms of Dinophysis spp., even using sophisticated analytical techniques for toxin detection in size-fractionated planktonic material. Accordingly, the authors are now focusing on the epibenthic/epiphytic microalgal community associated with the suspended culture of bivalve shellfish in Mahone Bay, N.S., specifically blue mussels (Mytilus edulis). Loosely aggregated material (termed ""slub"") on shellfish lines was found to contain low levels of DSP toxins. Significant numbers of cells of a toxigenic epibenthic dinoflagellate, Prorocentrum lima were associated with the epiphytic macroalga Pilayella littoralis, a common fouling organism on suspended shellfish lines. Unialgal isolates of P. lima from this material were confirmed to produce DSP toxins in culture. Spirolides, a new class of biologically-active marine compounds, have also been identified within the digestive tissues of blue mussels and sea scallops from the east coast of Nova Scotia, including sites in Mahone Bay. The spatio-temporal distribution and seasonal occurrence (typically early May to July) of spirolides in shellfish strongly suggested a planktonic origin, and these compounds have been traced to specific size-fractions (predominately 20-50 /spl mu/m) of plankton from the upper water column. An unusual group of pigmented spherical cells (""golden balls""), with taxonomic affinities to certain gonyaulacoid dinoflagellates, are dominant in these fractions. To establish the role of attached and suspended particulate material surrounding shellfish aquaculture installations on phycotoxin transfer and feeding mechanisms, data were collected on standard oceanographic parameters (chlorophyll, inorganic nutrients, seston, POM/PIM, plankton composition and abundance, water column stratification). Preliminary studies with a high-resolution underwater photo-imaging system provided an extended time-series (48 h) of the vertical distribution of attached and suspended particulates (""marine snow""). The particle field immediately adjacent to the shellfish lines was clearly distinct from that of a nearby control site (30 m distant) and the phytoplankton composition was unrepresentative. This indicates a potentially serious bias in the application of conventional techniques for water column monitoring of toxigenic phytoplankton in nearshore coastal zones.",A. Cembella; A. Bauder; N. Lewis; M. Quilliam; J. Lawrence; J. Manuel; U. Lobsiger,,,Population dynamics and spatial distribution of phycotoxic microalgae associated with shellfish aquaculture sites in Nova Scotia,1,,10.1109/OCEANS.1997.634426 ,IEEE Conferences ,,"Summary form only given. Coastal shellfish aquaculture sites are subject to seasonal blooms of toxic microalgae, which may result in restrictions on shellfish harvest due to human health risk. In southeastern Nova Scotia, such toxic episodes are uncommon, although significant numbers of putatively toxigenic phytoplankton are often found in the water column. In most coastal regions where diarrhetic shellfish poisoning (DSP) incidents have occurred, the events have been associated with blooms of species of the planktonic dinoflagellate Dinophysis. However, despite repeated attempts over several years, the authors have been unable to link the presence of DSP toxicity in Nova Scotian shellfish to the timing and magnitude of seasonal blooms of Dinophysis spp., even using sophisticated analytical techniques for toxin detection in size-fractionated planktonic material. Accordingly, the authors are now focusing on the epibenthic/epiphytic microalgal community associated with the suspended culture of bivalve shellfish in Mahone Bay, N.S., specifically blue mussels (Mytilus edulis). Loosely aggregated material (termed ""slub"") on shellfish lines was found to contain low levels of DSP toxins. Significant numbers of cells of a toxigenic epibenthic dinoflagellate, Prorocentrum lima were associated with the epiphytic macroalga Pilayella littoralis, a common fouling organism on suspended shellfish lines. Unialgal isolates of P. lima from this material were confirmed to produce DSP toxins in culture. Spirolides, a new class of biologically-active marine compounds, have also been identified within the digestive tissues of blue mussels and sea scallops from the east coast of Nova Scotia, including sites in Mahone Bay. The spatio-temporal distribution and seasonal occurrence (typically early May to July) of spirolides in shellfish strongly suggested a planktonic origin, and these compounds have been traced to specific size-fractions (predominately 20-50 /spl mu/m) of plankton from the upper water column. An unusual group of pigmented spherical cells (""golden balls""), with taxonomic affinities to certain gonyaulacoid dinoflagellates, are dominant in these fractions. To establish the role of attached and suspended particulate material surrounding shellfish aquaculture installations on phycotoxin transfer and feeding mechanisms, data were collected on standard oceanographic parameters (chlorophyll, inorganic nutrients, seston, POM/PIM, plankton composition and abundance, water column stratification). Preliminary studies with a high-resolution underwater photo-imaging system provided an extended time-series (48 h) of the vertical distribution of attached and suspended particulates (""marine snow""). The particle field immediately adjacent to the shellfish lines was clearly distinct from that of a nearby control site (30 m distant) and the phytoplankton composition was unrepresentative. This indicates a potentially serious bias in the application of conventional techniques for water column monitoring of toxigenic phytoplankton in nearshore coastal zones.",,,0-7803-4108-2,,IEEE , ,Digital signal processing;Sea measurements;Aquaculture;Marine vegetation;Humans;Timing;Organisms;Biological materials;Biological tissues;Pigmentation,,
4732,"Title:Acoustic biosensors for medical and environmental purposes

 The massive use of pesticides, the persistence on the environment and the strong toxicity on animals and humans encourages the use of easy, quick and automated methods for the analysis of samples of environmental interest like water. On the same manner, there is also a need of analytical systems to accurately detect viruses and bacteria in human bodily fluids. Beyond the various analytical systems, immunosensors based on acoustic waves are of interest due to their good sensibility and their reproducibility. The aim of this presentation is to present highly sensitive and selective biosensors using the resonance frequency of quartz crystals for the monitoring of water pollutants and for the medical diagnosis. The whole architecture of the biosensor will be presented in details. Experimental results on different types of toxic compounds (such as pollutants) will be discussed and compared with other detection methods as bioluminescence approach.",R. E. Ionescu; K. Jia; T. Thoury; E. Eltzov; R. Marks,,,Acoustic biosensors for medical and environmental purposes,,,10.1109/ISAF.2011.6014153 ,IEEE Conferences ,,"The massive use of pesticides, the persistence on the environment and the strong toxicity on animals and humans encourages the use of easy, quick and automated methods for the analysis of samples of environmental interest like water. On the same manner, there is also a need of analytical systems to accurately detect viruses and bacteria in human bodily fluids. Beyond the various analytical systems, immunosensors based on acoustic waves are of interest due to their good sensibility and their reproducibility. The aim of this presentation is to present highly sensitive and selective biosensors using the resonance frequency of quartz crystals for the monitoring of water pollutants and for the medical diagnosis. The whole architecture of the biosensor will be presented in details. Experimental results on different types of toxic compounds (such as pollutants) will be discussed and compared with other detection methods as bioluminescence approach.",2375-0448,,978-1-4577-1163-3,1-4,IEEE , ,Immune system;Pollution measurement;Microorganisms;Biosensors;Artificial intelligence;Welding;Methanol,,
4733,"Title:Electrical Stimulation of ASAP1 with a Combination of Microelectrode Array and Fluorescent Techniques

 Optical noninvasive methods are modern tools in studying subcellular ion exchanges and corresponding membrane voltage alterations. In past decades, genetically encoded voltage indicators (GEVIs) received attention due to the low toxicity and enhanced detection limits. The very promising GEVI Accelerated Sensor of Action Potentials 1 (ASAP1) was expressed in HEK293 cells and extracellular stimulation was performed using a microelectrode-arrays integrated pulse generator. The results demonstrate high fluorescence response and changes, fast kinetics 1.5±0.3 ms, and enhanced amplitude of fluorescence response, even if the voltage sensor is not completely repolarized. The results bring verification of advantageous properties of ASAP1 and confirm a big potential of modern voltage sensitive dyes and their application in neural activity sensing where these properties play an important role. At the same time, our testing method showed as a very advantageous in voltage sensitivity dyes properties validation.",O. Svoboda; V. Cmiel; L. Baiazitova; I. Provaznik; Z. Fohlerova; J. Hubalek,,,Electrical Stimulation of ASAP1 with a Combination of Microelectrode Array and Fluorescent Techniques,,,10.1109/TSP.2018.8441414 ,IEEE Conferences ,,"Optical noninvasive methods are modern tools in studying subcellular ion exchanges and corresponding membrane voltage alterations. In past decades, genetically encoded voltage indicators (GEVIs) received attention due to the low toxicity and enhanced detection limits. The very promising GEVI Accelerated Sensor of Action Potentials 1 (ASAP1) was expressed in HEK293 cells and extracellular stimulation was performed using a microelectrode-arrays integrated pulse generator. The results demonstrate high fluorescence response and changes, fast kinetics 1.5±0.3 ms, and enhanced amplitude of fluorescence response, even if the voltage sensor is not completely repolarized. The results bring verification of advantageous properties of ASAP1 and confirm a big potential of modern voltage sensitive dyes and their application in neural activity sensing where these properties play an important role. At the same time, our testing method showed as a very advantageous in voltage sensitivity dyes properties validation.",,,978-1-5386-4695-3,1-5,IEEE , ,Fluorescence;Extracellular;Microelectrodes;Optical sensors;Action potentials;Kinetic theory;Optical imaging,,
4734,"Title:Biomonitoring Technologies Used in Aquatic Ecosystems: A Systematic and Trend Analysis

 Aquatic biomonitoring technologies are widely used to detect and identify hazardous chemicals and pollutants in aquatic ecosystems. With the advancement of technology, this study focuses on providing a review of current trends and challenges related to aquatic biomonitoring. In particular, the advancements made in the designs of biosensors and Biological Early Warning Systems (BEWS) were presented. This includes biosensors that utilize luminescent bacteria, algae, living and/or microbial fuel cells. For BEWS, those that use fishes, daphnids, and bivalves as sentinel organisms were discussed. It was shown that biosensors and BEWS show promising potential for monitoring water quality of aquatic ecosystems as they allow for real-time monitoring while performing comparably to traditional analytical methods. Despite the various research done, there are still some issues and challenges concerning aquatic biomonitoring. BEWS and biosensors were shown to have their advantages and disadvantages. Biosensors can quantify the tested parameters but are analyte-specific and often need to be replaced upon detection. On the other hand, BEWS allow for continuous real-time monitoring but are often site-specific and require an established baseline data of the water quality parameters. To combat the issues, this study proposes designing a BEWS using bivalves for early detection and utilizing analytical methods to confirm changes in water quality. It is also recommended that further research be done to determine levels of toxicity, capacity to meet needs, and water quality baseline data for local aquatic ecosystems.",C. L. Arroyo; M. Dionela; M. G. Ann Bautista; R. Concepcion; R. R. Vicerra; B. Duarte,,,Biomonitoring Technologies Used in Aquatic Ecosystems: A Systematic and Trend Analysis,,,10.1109/HNICEM57413.2022.10109557 ,IEEE Conferences ,,"Aquatic biomonitoring technologies are widely used to detect and identify hazardous chemicals and pollutants in aquatic ecosystems. With the advancement of technology, this study focuses on providing a review of current trends and challenges related to aquatic biomonitoring. In particular, the advancements made in the designs of biosensors and Biological Early Warning Systems (BEWS) were presented. This includes biosensors that utilize luminescent bacteria, algae, living and/or microbial fuel cells. For BEWS, those that use fishes, daphnids, and bivalves as sentinel organisms were discussed. It was shown that biosensors and BEWS show promising potential for monitoring water quality of aquatic ecosystems as they allow for real-time monitoring while performing comparably to traditional analytical methods. Despite the various research done, there are still some issues and challenges concerning aquatic biomonitoring. BEWS and biosensors were shown to have their advantages and disadvantages. Biosensors can quantify the tested parameters but are analyte-specific and often need to be replaced upon detection. On the other hand, BEWS allow for continuous real-time monitoring but are often site-specific and require an established baseline data of the water quality parameters. To combat the issues, this study proposes designing a BEWS using bivalves for early detection and utilizing analytical methods to confirm changes in water quality. It is also recommended that further research be done to determine levels of toxicity, capacity to meet needs, and water quality baseline data for local aquatic ecosystems.",2770-0682,,978-1-6654-6493-2,1-5,IEEE , ,Microorganisms;Ecosystems;Fuel cells;Algae;Water quality;Market research;Real-time systems,,
4735,"Title:GuidedTracker: Track the victims with access logs to finding malicious web pages

 Malicious web pages have become a malignant tumour for the Internet, which spread malicious code, steal people's private information, and deliver spamming advertisements. And how to distinguish them from the huge number of normal web pages effectively remains a huge challenge in the era of big data. To detect malicious pages, one needs to first collect candidate web pages that are live on the web; then filter massive legitimate pages using fast filters and finally examine the remaining pages using precisely but slow analyzer. However, there are new challenges recently for these conventional techniques, including large scale, imbalance data and the usage of cloaking techniques. To cope with these challenges, the malicious URL detection system should perform more efficiently. In this paper, we propose a system, named GuidedTracker, to search for suspicious malicious pages. GuidedTracker starts from the seed set which includes known malicious pages. Then, it automatically figures out those victims based on the seed set and the visit relation database. Finally, the access records of these victims are used to identify other malicious pages. In this way, GuidedTracker increase the percentages of malicious URLs in the input URL stream submitted to the precisely analyzer. To our best knowledge, GuidedTracker is the first to introduce visit relations to tackle the malicious URL detection problem. The introduction of visit relations limits the scope of URL inspection and enables this approach to have the ability of self-learning. Experimental results show that the overall ""toxicity"" can be improved by 6.97%-50.38% compared with full inspection of access logs.",H. Sha; Q. Liu; Z. Zhou; C. Zheng,,,GuidedTracker: Track the victims with access logs to finding malicious web pages,,,10.1109/GLOCOM.2014.7036867 ,IEEE Conferences ,,"Malicious web pages have become a malignant tumour for the Internet, which spread malicious code, steal people's private information, and deliver spamming advertisements. And how to distinguish them from the huge number of normal web pages effectively remains a huge challenge in the era of big data. To detect malicious pages, one needs to first collect candidate web pages that are live on the web; then filter massive legitimate pages using fast filters and finally examine the remaining pages using precisely but slow analyzer. However, there are new challenges recently for these conventional techniques, including large scale, imbalance data and the usage of cloaking techniques. To cope with these challenges, the malicious URL detection system should perform more efficiently. In this paper, we propose a system, named GuidedTracker, to search for suspicious malicious pages. GuidedTracker starts from the seed set which includes known malicious pages. Then, it automatically figures out those victims based on the seed set and the visit relation database. Finally, the access records of these victims are used to identify other malicious pages. In this way, GuidedTracker increase the percentages of malicious URLs in the input URL stream submitted to the precisely analyzer. To our best knowledge, GuidedTracker is the first to introduce visit relations to tackle the malicious URL detection problem. The introduction of visit relations limits the scope of URL inspection and enables this approach to have the ability of self-learning. Experimental results show that the overall ""toxicity"" can be improved by 6.97%-50.38% compared with full inspection of access logs.",1930-529X,,978-1-4799-3512-3,564-569,IEEE , ,Web pages;Uniform resource locators;Inspection;Security;Detectors;Information systems,,
4736,"Title:The direct competitive ELISA based on monoclonal antibody for detecting okadaic acid in seafood

 Okadaic acid (OA), a key diarrheic shellfish poisoning (DSP) toxin will possibly arouses DSP symptoms by consuming the contaminated shellfish. The DSP toxins are stable at high temperatures, and long-term DSP toxicity is carcinogenic. Therefore a fast and reliable analytical method for the detection of OA and analogues in shellfish is worth developing. In this paper, a direct competitive ELISA (dcELISA) for detecting OA in seafood was developed based on monoclonal antibody (McAb). The regression equation of direct competitive ELISA was y=-38.831X+130.25 with a coefficient correlation of R2=0.989 8. The linear range and the limit of detection (LOD) were 1.56-75 ng/mL and 1.09 ng/mL, respectively. The average recovery of OA-spiked sample was 86.05% with the coefficient of variation (CV) of 7.83%. The results indicated that the developed dcELISA is a fast, sensitive and convenient assay and could be used for detecting of OA in seafood.",S. -Y. Lu; C. Lin; S. Gong; L. Li; X. -L. Feng; P. Hu; R. -Y. Tian; Y. -Y. Liu,,,The direct competitive ELISA based on monoclonal antibody for detecting okadaic acid in seafood,,,10.1109/HHBE.2011.6028973 ,IEEE Conferences ,,"Okadaic acid (OA), a key diarrheic shellfish poisoning (DSP) toxin will possibly arouses DSP symptoms by consuming the contaminated shellfish. The DSP toxins are stable at high temperatures, and long-term DSP toxicity is carcinogenic. Therefore a fast and reliable analytical method for the detection of OA and analogues in shellfish is worth developing. In this paper, a direct competitive ELISA (dcELISA) for detecting OA in seafood was developed based on monoclonal antibody (McAb). The regression equation of direct competitive ELISA was y=-38.831X+130.25 with a coefficient correlation of R2=0.989 8. The linear range and the limit of detection (LOD) were 1.56-75 ng/mL and 1.09 ng/mL, respectively. The average recovery of OA-spiked sample was 86.05% with the coefficient of variation (CV) of 7.83%. The results indicated that the developed dcELISA is a fast, sensitive and convenient assay and could be used for detecting of OA in seafood.",,,978-1-61284-726-9,920-924,IEEE , ,Proteins;Immune system;Mice;Digital signal processing;Humans;Educational institutions;Calibration,,
4737,"Title:Prediction of Dioxin Emission Concentration from Municipal Solid Waste Incineration Process Based on PSO and Equispaced Interpolation

 As currently widely used municipal solid waste resource treatment method, the municipal solid waste incineration (MSWI) process emit dioxins (DXN) compounds with high toxicity and persistent pollution characteristics. It is one of the main reasons that cause incineration power plants to have a “Not in my back yard”. At present, the long-period, high-cost offline detection method used in industrial sites cannot achieve real-time monitoring of DXN emission concentration. Moreover, the number of samples used to build a DXN emission concentration prediction model is extremely scarce. Aim at the above problems, a method for predicting DXN emission concentration in MSWI process based on PSO and equispaced interpolation is proposed. At first, the domain of original small sample input and output is expanded based on the improved mega-trend-diffusion(MTD) technology. Then, the equal interval interpolation method is used to generate the virtual sample inputs, which are used to obtain the virtual sample outputs by combining the mapping model. The above results are combined with the expansion space to delete the bad virtual samples. Thirdly, the PSO algorithm is used to optimize and select the reduced virtual sample set. Finally, a mixed sample set composed of the optimized selected virtual sample set and the original small sample set is used to construct a DXN emission concentration prediction model. The effectiveness of the proposed method is verified with the actual detection data of DXN for many years in a MSWI plant.",D. Wang; J. Tang; Z. Guo; J. Qiao,,,Prediction of Dioxin Emission Concentration from Municipal Solid Waste Incineration Process Based on PSO and Equispaced Interpolation,,,10.1109/CCDC52312.2021.9601628 ,IEEE Conferences ,,"As currently widely used municipal solid waste resource treatment method, the municipal solid waste incineration (MSWI) process emit dioxins (DXN) compounds with high toxicity and persistent pollution characteristics. It is one of the main reasons that cause incineration power plants to have a “Not in my back yard”. At present, the long-period, high-cost offline detection method used in industrial sites cannot achieve real-time monitoring of DXN emission concentration. Moreover, the number of samples used to build a DXN emission concentration prediction model is extremely scarce. Aim at the above problems, a method for predicting DXN emission concentration in MSWI process based on PSO and equispaced interpolation is proposed. At first, the domain of original small sample input and output is expanded based on the improved mega-trend-diffusion(MTD) technology. Then, the equal interval interpolation method is used to generate the virtual sample inputs, which are used to obtain the virtual sample outputs by combining the mapping model. The above results are combined with the expansion space to delete the bad virtual samples. Thirdly, the PSO algorithm is used to optimize and select the reduced virtual sample set. Finally, a mixed sample set composed of the optimized selected virtual sample set and the original small sample set is used to construct a DXN emission concentration prediction model. The effectiveness of the proposed method is verified with the actual detection data of DXN for many years in a MSWI plant.",1948-9447,,978-1-6654-4089-9,2173-2178,IEEE , ,Waste management;Waste materials;Interpolation;Solid modeling;Toxicology;Incineration;Predictive models,,
4738,"Title:Engineering a High-Throughput 3-D In Vitro Glioblastoma Model

 Glioblastoma multiforme (GBM) is the most common and malignant primary brain tumor in adults because of its highly invasive behavior. The existing treatment for GBM, which involves a combination of resection, chemotherapy, and radiotherapy, has a very limited success rate with a median survival rate of <;1 year. This is mainly because of the failure of early detection and effective treatment. We designed a novel 3-D GBM cell culture model based on microwells that could mimic in vitro environment and help to bypass the lack of suitable animal models for preclinical toxicity tests. Microwells were fabricated from simple and inexpensive polyethylene glycol material for the control of in vitro 3-D culture. We applied the 3-D micropatterning system to GBM (U-87) cells using the photolithography technique to control the cell spheroids' shape, size, and thickness. Our preliminary results suggested that uniform GBM spheroids can be formed in 3-D, and the size of these GBM spheroids depends on the size of microwells. The viability of the spheroids generated in this manner was quantitatively evaluated using live/dead assay and shown to improve over 21 days. We believe that in vitro 3-D cell culture model could help to reduce the time of the preclinical brain tumor growth studies. The proposed novel platform could be useful and cost-effective for high-throughput screening of cancer drugs and assessment of treatment responses.",Y. Fan; N. G. Avci; D. T. Nguyen; A. Dragomir; Y. M. Akay; F. Xu; M. Akay,,,Engineering a High-Throughput 3-D In Vitro Glioblastoma Model,3,,10.1109/JTEHM.2015.2410277 ,IEEE Journals ,,"Glioblastoma multiforme (GBM) is the most common and malignant primary brain tumor in adults because of its highly invasive behavior. The existing treatment for GBM, which involves a combination of resection, chemotherapy, and radiotherapy, has a very limited success rate with a median survival rate of <;1 year. This is mainly because of the failure of early detection and effective treatment. We designed a novel 3-D GBM cell culture model based on microwells that could mimic in vitro environment and help to bypass the lack of suitable animal models for preclinical toxicity tests. Microwells were fabricated from simple and inexpensive polyethylene glycol material for the control of in vitro 3-D culture. We applied the 3-D micropatterning system to GBM (U-87) cells using the photolithography technique to control the cell spheroids' shape, size, and thickness. Our preliminary results suggested that uniform GBM spheroids can be formed in 3-D, and the size of these GBM spheroids depends on the size of microwells. The viability of the spheroids generated in this manner was quantitatively evaluated using live/dead assay and shown to improve over 21 days. We believe that in vitro 3-D cell culture model could help to reduce the time of the preclinical brain tumor growth studies. The proposed novel platform could be useful and cost-effective for high-throughput screening of cancer drugs and assessment of treatment responses.",2168-2372,,,1-8,IEEE , ,Glass;Cancer;Three-dimensional displays;In vitro;Fluorescence;Tumors;Solid modeling,,
4739,"Title:M-Evolve: Structural-Mapping-Based Data Augmentation for Graph Classification

 Graph classification, which aims to identify the category labels of graphs, plays a significant role in drug classification, toxicity detection, protein analysis etc. However, the limitation of scale in the benchmark datasets makes it easy for graph classification models to fall into over-fitting and undergeneralization. To improve this, we introduce data augmentation on graphs (i.e. graph augmentation) and present four methods: random mapping, vertex-similarity mapping, motif-random mapping and motif-similarity mapping, to generate more weakly labeled data for small-scale benchmark datasets via heuristic transformation of graph structures. Furthermore, we propose a generic model evolution framework, named M-Evolve, which combines graph augmentation, data filtration and model retraining to optimize pre-trained graph classifiers. Experiments on six benchmark datasets demonstrate that the proposed framework helps existing graph classification models alleviate over-fitting and undergeneralization in the training on small-scale benchmark datasets, which successfully yields an average improvement of 3-13% accuracy on graph classification tasks.",J. Zhou; J. Shen; S. Yu; G. Chen; Q. Xuan,,,M-Evolve: Structural-Mapping-Based Data Augmentation for Graph Classification,8,1,10.1109/TNSE.2020.3032950 ,IEEE Journals ,,"Graph classification, which aims to identify the category labels of graphs, plays a significant role in drug classification, toxicity detection, protein analysis etc. However, the limitation of scale in the benchmark datasets makes it easy for graph classification models to fall into over-fitting and undergeneralization. To improve this, we introduce data augmentation on graphs (i.e. graph augmentation) and present four methods: random mapping, vertex-similarity mapping, motif-random mapping and motif-similarity mapping, to generate more weakly labeled data for small-scale benchmark datasets via heuristic transformation of graph structures. Furthermore, we propose a generic model evolution framework, named M-Evolve, which combines graph augmentation, data filtration and model retraining to optimize pre-trained graph classifiers. Experiments on six benchmark datasets demonstrate that the proposed framework helps existing graph classification models alleviate over-fitting and undergeneralization in the training on small-scale benchmark datasets, which successfully yields an average improvement of 3-13% accuracy on graph classification tasks.",2327-4697,,,190-200,IEEE , ,Kernel;Data models;Benchmark testing;Brain modeling;Reliability;Training;Task analysis,,
4740,"Title:A new cross contamination aware routing method with intelligent path exploration in digital microfluidic biochips

 Digital microfluidic systems in recent years have been developed as an alternative platform for execution of multiple conventional laboratory methods simultaneously on a single planar 2D array of electrodes targeted for biochemical analysis and biomedical applications. Due to its discrete nature droplets can be manipulated through multiple reconfigurable paths derived by preprogrammed electrode actuation sequences through this planar array known as digital microfluidic biochip system. Cross contamination between heterogeneous samples turns out to be a major issue concerned with transportation of droplets and correctness of the detection results for the bioassay protocols -which is highly significant for clinical diagnostics and toxicity monitoring applications. In this paper we have proposed an intelligent route path exploration technique that attempts partially or completely to avoid the number of cross contamination depending on the fluidic constraints employed during routing. The path is further refined using intelligent detour by identifying zones of friction between two adjacent route paths that optimizes the overall route time by reducing the overall time for stalling while routing -as well as further optimization of resources to be utilized. The simulation is carried out on test benches of benchmark suite I and benchmark suite III. The results show improvement in overall as well as average route time and major reduction in the number of crossovers.",P. Roy; P. Howladar; R. Bhattacharjee; H. Rahaman; P. Dasgupta,,,A new cross contamination aware routing method with intelligent path exploration in digital microfluidic biochips,,,10.1109/DTIS.2013.6527777 ,IEEE Conferences ,,Digital microfluidic systems in recent years have been developed as an alternative platform for execution of multiple conventional laboratory methods simultaneously on a single planar 2D array of electrodes targeted for biochemical analysis and biomedical applications. Due to its discrete nature droplets can be manipulated through multiple reconfigurable paths derived by preprogrammed electrode actuation sequences through this planar array known as digital microfluidic biochip system. Cross contamination between heterogeneous samples turns out to be a major issue concerned with transportation of droplets and correctness of the detection results for the bioassay protocols -which is highly significant for clinical diagnostics and toxicity monitoring applications. In this paper we have proposed an intelligent route path exploration technique that attempts partially or completely to avoid the number of cross contamination depending on the fluidic constraints employed during routing. The path is further refined using intelligent detour by identifying zones of friction between two adjacent route paths that optimizes the overall route time by reducing the overall time for stalling while routing -as well as further optimization of resources to be utilized. The simulation is carried out on test benches of benchmark suite I and benchmark suite III. The results show improvement in overall as well as average route time and major reduction in the number of crossovers.,,,978-1-4673-6040-1,50-55,IEEE , ,Decision support systems;Nanoscale devices;Diffusion tensor imaging;Routing;Contamination;Mixers;Layout,,
4741,"Title:Web-based GIS dedicated for marine environment surveillance and monitoring

 Maritime and port areas throughout the world are exposed to many different hazards, like pollution, terrorism and natural disasters. Early detection, identification and preparation of appropriate response strategies is especially important in the case of semi-enclosed Basins like the Southern Baltic Sea, mainly due to the marine ecosystems' continuous absorption of pollutants including oil, heavy metals and chemicals. Many of those agents are characterised by great toxicity and cause devastation of the natural environment. The recent development in the information technology provides the means and possibilities for much faster and more efficient access to survey data, allowing their remote, nearly real-time management, processing and visualisation. Several approaches and techniques of measurements are available in marine environment monitoring. These consist of direct sampling, airborne and satellite imagery, hydrological measurements using CTD probes, remote sensing with the use of electromagnetic waves, acoustic methods based on the data acquired by multi-beam and side-scan sonars and single-beam echosounders. The acquisition, processing, integration and visualisation of various kinds of data constitutes an important problem in the context of development of applications supporting littoral environment management. These methods are not easily suited for monitoring threat levels for maritime Critical Infrastructures (CI) like ports and shipyards. However, this field has also been explored, using specialised modules like CARVER2trade or similar systems now easily available not only commercially. The presented system integrates data from all of the aforementioned sources as well as others, like live radar feed and oil spill spread simulation results. The data from the investigated marine region is presented in the form of multiple, time-varying layers, rendered in up to three dimensions. The system allows authenticated end users to remotely view these layers in a geographic context while also providing interactive features like oil spill spread animation and tools for layer query. The CI threat sensing element of the system is being developed in cooperation with the City of Gdansk. The system's application for monitoring water pollution as well as processing, integration and visualsation of various kinds of background and sensor data has been reported recently. The presented system consists of several modules, or subsystems, namely the Data Integration and Adaptation module, the Remotely Accessible GIS and third-party simulation engines, connected through the interface for Simulation Modules. The Data Integration and Adaptation module is developed using the Microsoft .NETplatform and the ESRI ArcGIS Engine, which is a set of GIS objects with application programming interfaces (APIs) for COM, .NET, Java, and C++. To provide a common and efficient solution for geospatial data serving via the TCP/IP protocol, the system utilises the ArcSDE application server that facilitates storing and managing spatial data (raster, vector, and survey) in an underlying database. ArcGIS Engine MapControl and GlobeControl components provide a standard set of GIS functionalities like map viewing, zooming and panning for twodimensional and three-dimensional imaging respectively. Interfaces to various external sensors were implemented during the development of the system. The Web-GIS module was developed entirely with the use of Open-Source technology. It utilizes the established GeoServer technology for serving Open Geospatial Consortium's (OGC) standard Web Map Service (WMS) layers and Apache Web Server as the HTTP proxy. Data processing is done by means of custom Java 2 Platform Standard Edition servlets running within the Tomcat Servlet Engine. The browser-independent DHTMI client is built with help of the Openlayers Javascript library. The Interface for Simulation Modules allows third-party applications to provide data directly into the Spatial data Management and Analysis element of the system. This allows for producing semi-dynamic thematic layers from otherwise incompatible data. Third-party modules, currently plugged into the system, consist of the CAROCS system oil spill spread simulation data and NI2 developed CARVER2 analysis tool for comparing dissimilar types of Critical Infrastructure using the same standards, which allows for quick and easy identification and comparison of their vulnerabilities at the local, state and national levels in order to assist government officials in the allocation of protective resources.",L. Kaminski; M. Kulawiak; W. Cizmowski; A. Chybicki; A. Stepnowski; A. Orlowski,,,Web-based GIS dedicated for marine environment surveillance and monitoring,,,10.1109/OCEANSE.2009.5278151 ,IEEE Conferences ,,"Maritime and port areas throughout the world are exposed to many different hazards, like pollution, terrorism and natural disasters. Early detection, identification and preparation of appropriate response strategies is especially important in the case of semi-enclosed Basins like the Southern Baltic Sea, mainly due to the marine ecosystems' continuous absorption of pollutants including oil, heavy metals and chemicals. Many of those agents are characterised by great toxicity and cause devastation of the natural environment. The recent development in the information technology provides the means and possibilities for much faster and more efficient access to survey data, allowing their remote, nearly real-time management, processing and visualisation. Several approaches and techniques of measurements are available in marine environment monitoring. These consist of direct sampling, airborne and satellite imagery, hydrological measurements using CTD probes, remote sensing with the use of electromagnetic waves, acoustic methods based on the data acquired by multi-beam and side-scan sonars and single-beam echosounders. The acquisition, processing, integration and visualisation of various kinds of data constitutes an important problem in the context of development of applications supporting littoral environment management. These methods are not easily suited for monitoring threat levels for maritime Critical Infrastructures (CI) like ports and shipyards. However, this field has also been explored, using specialised modules like CARVER2trade or similar systems now easily available not only commercially. The presented system integrates data from all of the aforementioned sources as well as others, like live radar feed and oil spill spread simulation results. The data from the investigated marine region is presented in the form of multiple, time-varying layers, rendered in up to three dimensions. The system allows authenticated end users to remotely view these layers in a geographic context while also providing interactive features like oil spill spread animation and tools for layer query. The CI threat sensing element of the system is being developed in cooperation with the City of Gdansk. The system's application for monitoring water pollution as well as processing, integration and visualsation of various kinds of background and sensor data has been reported recently. The presented system consists of several modules, or subsystems, namely the Data Integration and Adaptation module, the Remotely Accessible GIS and third-party simulation engines, connected through the interface for Simulation Modules. The Data Integration and Adaptation module is developed using the Microsoft .NETplatform and the ESRI ArcGIS Engine, which is a set of GIS objects with application programming interfaces (APIs) for COM, .NET, Java, and C++. To provide a common and efficient solution for geospatial data serving via the TCP/IP protocol, the system utilises the ArcSDE application server that facilitates storing and managing spatial data (raster, vector, and survey) in an underlying database. ArcGIS Engine MapControl and GlobeControl components provide a standard set of GIS functionalities like map viewing, zooming and panning for twodimensional and three-dimensional imaging respectively. Interfaces to various external sensors were implemented during the development of the system. The Web-GIS module was developed entirely with the use of Open-Source technology. It utilizes the established GeoServer technology for serving Open Geospatial Consortium's (OGC) standard Web Map Service (WMS) layers and Apache Web Server as the HTTP proxy. Data processing is done by means of custom Java 2 Platform Standard Edition servlets running within the Tomcat Servlet Engine. The browser-independent DHTMI client is built with help of the Openlayers Javascript library. The Interface for Simulation Modules allows third-party applications to provide data directly into the Spatial data Management and Analysis element of the system. This allows for producing semi-dynamic thematic layers from otherwise incompatible data. Third-party modules, currently plugged into the system, consist of the CAROCS system oil spill spread simulation data and NI2 developed CARVER2 analysis tool for comparing dissimilar types of Critical Infrastructure using the same standards, which allows for quick and easy identification and comparison of their vulnerabilities at the local, state and national levels in order to assist government officials in the allocation of protective resources.",,,978-1-4244-2522-8,1-7,IEEE , ,Geographic Information Systems;Surveillance;Engines;Petroleum;Hydrologic measurements;Remote monitoring;Java;Pollution;Data visualization;Acoustic measurements,,
4742,"Title:Incorporation of a fluoroscopic X-ray modality in a small animal imaging system

 The authors have developed a multimodality system for imaging the biodistribution of biologically interesting ligands tagged with /sup 125/I. By incorporating a small fluoroscope as an additional modality, they have enhanced their small animal nuclear imaging system to include both X-rays and images from two Hamamatsu R3292 5"" diameter position sensitive photomultiplier tubes (PSPMT) viewing pixelated scintillators with image co-registration of 1.5 mm or better. Collimators placed between the animal and the scintillators can easily be interchanged and include CuBe parallel-hole collimators with a range of resolution and sensitivity combinations. The small X-ray fluoroscope provides 5 cm diameter images, several of which can readily be combined to provide structural anatomical information from the animal under study. The system has been tested by comparing the uptake of /sup 125/I (in NaI) in control mice and mice previously fed a solution of KI (potassium iodide) designed specifically to block uptake of the radiolabeled iodine in the thyroid. This system not only provides an effective approach for the analysis of KI dose and toxicity issues but also allows for detection of individual variation in animals, an important issue in contemporary pharmacology and genomics.",M. S. Saha; E. L. Bradley; P. Brewer; K. K. Gleason; B. Kross; S. Majewski; V. Popov; J. Qian; A. Ranck; K. Smith; M. F. Smith; A. G. Weisenberger; R. Wojcik; R. E. Welsh,,,Incorporation of a fluoroscopic X-ray modality in a small animal imaging system,50,3,10.1109/TNS.2003.812438 ,IEEE Journals ,,"The authors have developed a multimodality system for imaging the biodistribution of biologically interesting ligands tagged with /sup 125/I. By incorporating a small fluoroscope as an additional modality, they have enhanced their small animal nuclear imaging system to include both X-rays and images from two Hamamatsu R3292 5"" diameter position sensitive photomultiplier tubes (PSPMT) viewing pixelated scintillators with image co-registration of 1.5 mm or better. Collimators placed between the animal and the scintillators can easily be interchanged and include CuBe parallel-hole collimators with a range of resolution and sensitivity combinations. The small X-ray fluoroscope provides 5 cm diameter images, several of which can readily be combined to provide structural anatomical information from the animal under study. The system has been tested by comparing the uptake of /sup 125/I (in NaI) in control mice and mice previously fed a solution of KI (potassium iodide) designed specifically to block uptake of the radiolabeled iodine in the thyroid. This system not only provides an effective approach for the analysis of KI dose and toxicity issues but also allows for detection of individual variation in animals, an important issue in contemporary pharmacology and genomics.",1558-1578,,,333-338,IEEE , ,X-ray imaging;Animals;Optical imaging;Collimators;Mice;Nuclear imaging;Photomultipliers;Pixel;System testing;Radio control,,
4743,"Title:Development of an automatic implanted drug infusion system for the management of cardiac arrhythmias

 Conventional management of cardiac arrythmias relies on oral drug therapy which minimizes recurrence of the arrhythmia, but risks unpleasant side effects and even long-term toxicity. The authors propose acute management instead, from an implanted drug pump which automatically senses the onset of arrhythmia, delivers a pharmacokinetically-based infusion to terminate the episode, and discontinues drug delivery until the next occurrence. A bedside system consisting of a personal computer and conventional intravenous pump has been developed and tested in five dogs and 24 patients during a catheter electrophysiologic study. After detection of the arrhythmia plasma levels of the antiarrhythmia drug rose immediately to the therapeutic range and were subsequently well-controlled for 30 to 60 minutes. In all five dogs and in seven of the eight patients in whom atrial fibrillation was induced during the study, conversion to normal rhythm occurred within fifteen minutes.<>",R. Arzbaecher; T. E. Bump,,,Development of an automatic implanted drug infusion system for the management of cardiac arrhythmias,76,9,10.1109/5.9666 ,IEEE Journals ,,"Conventional management of cardiac arrythmias relies on oral drug therapy which minimizes recurrence of the arrhythmia, but risks unpleasant side effects and even long-term toxicity. The authors propose acute management instead, from an implanted drug pump which automatically senses the onset of arrhythmia, delivers a pharmacokinetically-based infusion to terminate the episode, and discontinues drug delivery until the next occurrence. A bedside system consisting of a personal computer and conventional intravenous pump has been developed and tested in five dogs and 24 patients during a catheter electrophysiologic study. After detection of the arrhythmia plasma levels of the antiarrhythmia drug rose immediately to the therapeutic range and were subsequently well-controlled for 30 to 60 minutes. In all five dogs and in seven of the eight patients in whom atrial fibrillation was induced during the study, conversion to normal rhythm occurred within fifteen minutes.<>",1558-2256,,,1204-1209,IEEE , ,Dogs;Risk management;Medical treatment;Drug delivery;Microcomputers;System testing;Catheters;Plasmas;Atrial fibrillation;Rhythm,,
4744,"Title:Urban stormwater quality monitoring: From sampling to water quality analysis

 This paper presents the outcomes of urban stormwater quality monitoring and research including associated activities in South East Queensland (SEQ). The issues associated with urban stormwater quality monitoring, ranging from automated field sampling to laboratory analysis of chemical, toxicological and microbiological constituents present in stormwater are elaborated. A medium density residential stormwater supply catchment of 290 hectares in northern Brisbane is presented as a case study and discussed in detail. Preliminary results indicate that the occurrence and concentration of chemical pollutants in urban stormwater runoff and the associated baseline toxicity is relatively low. However, the microbiological quality of stormwater may not be as good as initially perceived with high numbers of faecal indicator bacteria (FIB) detected during wet weather events. In addition, the polymerase chain reaction (PCR) detection of pathogens indicated the presence of human sewage contamination during wet weather events which might be due to potential sewer overflow events. Further monitoring will be conducted to further assess the stormwater quality before undertaking a comprehensive environmental and public health risk assessment.",M. N. Chong; R. Aryal; J. Sidhu; J. Tang; S. Toze; T. Gardner,,,Urban stormwater quality monitoring: From sampling to water quality analysis,,,10.1109/ISSNIP.2011.6146598 ,IEEE Conferences ,,"This paper presents the outcomes of urban stormwater quality monitoring and research including associated activities in South East Queensland (SEQ). The issues associated with urban stormwater quality monitoring, ranging from automated field sampling to laboratory analysis of chemical, toxicological and microbiological constituents present in stormwater are elaborated. A medium density residential stormwater supply catchment of 290 hectares in northern Brisbane is presented as a case study and discussed in detail. Preliminary results indicate that the occurrence and concentration of chemical pollutants in urban stormwater runoff and the associated baseline toxicity is relatively low. However, the microbiological quality of stormwater may not be as good as initially perceived with high numbers of faecal indicator bacteria (FIB) detected during wet weather events. In addition, the polymerase chain reaction (PCR) detection of pathogens indicated the presence of human sewage contamination during wet weather events which might be due to potential sewer overflow events. Further monitoring will be conducted to further assess the stormwater quality before undertaking a comprehensive environmental and public health risk assessment.",,,978-1-4577-0674-5,174-179,IEEE , ,Meteorology;Water pollution;Chemicals;Pathogens;Pollution measurement;DNA;Humans,,
4745,"Title:Evaluation of Metal Leaching from End-of-Life Laptop Computers Using the TCLP and Other Standard Leaching Tests

 The proper management of discarded electronic devices (often called electronic waste) is an emerging issue for solid waste professionals throughout the world because of the large growth of the waste stream, and the content of toxic metals in them, most notably heavy metals such as lead. Laptop computers are becoming one of the components of discarded electronic devices and will continue to increase in the waste stream in the future. The objective of this study was to examine leaching potential of metals from discarded laptop computers using the scale-up toxicity characteristic leaching procedure (TCLP), other standard leaching tests such as California waste extraction test (Cal WET), and the synthetic precipitation leaching procedure (SPLP) and actual landfill leachates as leaching solution. The results showed that the scale-up TCLP resulted in relatively high lead found in the leachate with an average of 23.3 mg/L. The average level was less than those by the standard TCLP and WET (37.0 mg/L and 86.0 mg/L, respectively), but much greater than those by the SPLP and the extractions with the landfill leachates (0.55 mg/L and 1.47 mg/L, respectively). All other target metals (Ag, As, Ba, Cd, Cr, Hg, Se) were found to be either less than or close to their detection limits. The pH of the leaching solution and the ability of the organic acids in the TCLP and WET to complex with lead were identified as major factors that controlled the amount of lead leached from laptop computers",Yong-Chul Jang; T. Townsend; Hyunmyung Yoon,,,Evaluation of Metal Leaching from End-of-Life Laptop Computers Using the TCLP and Other Standard Leaching Tests,,,10.1109/ISEE.2006.1650082 ,IEEE Conferences ,,"The proper management of discarded electronic devices (often called electronic waste) is an emerging issue for solid waste professionals throughout the world because of the large growth of the waste stream, and the content of toxic metals in them, most notably heavy metals such as lead. Laptop computers are becoming one of the components of discarded electronic devices and will continue to increase in the waste stream in the future. The objective of this study was to examine leaching potential of metals from discarded laptop computers using the scale-up toxicity characteristic leaching procedure (TCLP), other standard leaching tests such as California waste extraction test (Cal WET), and the synthetic precipitation leaching procedure (SPLP) and actual landfill leachates as leaching solution. The results showed that the scale-up TCLP resulted in relatively high lead found in the leachate with an average of 23.3 mg/L. The average level was less than those by the standard TCLP and WET (37.0 mg/L and 86.0 mg/L, respectively), but much greater than those by the SPLP and the extractions with the landfill leachates (0.55 mg/L and 1.47 mg/L, respectively). All other target metals (Ag, As, Ba, Cd, Cr, Hg, Se) were found to be either less than or close to their detection limits. The pH of the leaching solution and the ability of the organic acids in the TCLP and WET to complex with lead were identified as major factors that controlled the amount of lead leached from laptop computers",2378-7260,,1-4244-0351-0,309-314,IEEE , ,Leaching;Portable computers;Testing;Lead;Content management;Waste management;Electronic waste;Solids;Chromium;Mercury (metals),,
4746,"Title:Dioxin Emission Concentration Soft Measurement Model of MSWI Process Based on Unmarked Samples and Improved Deep Belief Network

 Municipal solid waste incineration (MSWI) is a widely used domestic waste resource treatment technology. However, this process products pollution dioxins (DXN). It has high toxicity and durability. This is one of the main reasons of ""not in my backyard"" effect when constructing MSWI plant. As the long period and high cost of off-line DXN detection method, it is difficult to realize the real-time monitoring of DXN emission concentration. The massive unlabeled samples in the industrial field contain the generation mechanism of DXN, which are not fully utilized. Aim at the above problems, this paper proposes an unmarked samples and improved deep belief network (DBN) based method to construct DXN soft measurement model. Firstly, a large number of unlabeled samples are added to the training input sample set to improve the learning ability of soft measurement model at pre training phase. Then, an energy function is derived as the activation function of restricted Boltzmann machine (RBM). Finally, for the whole DBN, dropout algorithm is used to improve the robustness of the model, and the adaptive learning rate error back propagation algorithm is used to fine tune the weight iteratively at the fine tuning phase. The validity and rationality of this method are validated by DXN data set.",Z. Guo; J. Tang; J. Qiao; H. He,,,Dioxin Emission Concentration Soft Measurement Model of MSWI Process Based on Unmarked Samples and Improved Deep Belief Network,,,10.23919/CCC50068.2020.9188562 ,IEEE Conferences ,,"Municipal solid waste incineration (MSWI) is a widely used domestic waste resource treatment technology. However, this process products pollution dioxins (DXN). It has high toxicity and durability. This is one of the main reasons of ""not in my backyard"" effect when constructing MSWI plant. As the long period and high cost of off-line DXN detection method, it is difficult to realize the real-time monitoring of DXN emission concentration. The massive unlabeled samples in the industrial field contain the generation mechanism of DXN, which are not fully utilized. Aim at the above problems, this paper proposes an unmarked samples and improved deep belief network (DBN) based method to construct DXN soft measurement model. Firstly, a large number of unlabeled samples are added to the training input sample set to improve the learning ability of soft measurement model at pre training phase. Then, an energy function is derived as the activation function of restricted Boltzmann machine (RBM). Finally, for the whole DBN, dropout algorithm is used to improve the robustness of the model, and the adaptive learning rate error back propagation algorithm is used to fine tune the weight iteratively at the fine tuning phase. The validity and rationality of this method are validated by DXN data set.",1934-1768,,978-9-8815-6390-3,5784-5789,IEEE , ,Incineration;Training;Data models;Inductors;Fly ash;Pollution measurement;Solids,,
4747,"Title:Optick - A Low Cost Wearable Head up Display for Search and Rescue Operations

 Optick is a visual aid for search and rescue operators during disaster management to help save lives while protecting their own by detecting the presence of humans in low visibility environments and monitoring the toxicity of gases inhaled. There are three main aspects of this device. The first is interfacing the MQ-7 (Carbon Monoxide sensor) and the CCS811 (Carbon Dioxide and Volatile Organic Compounds sensor) with the Raspberry Pi Zero and the OLED display. The second is the detection of humans using the AMG8833 thermal sensor to capture temperature readings which are sent to a trained Deep Learning model. Finally, Optick focuses the display into the eye of the rescuer, giving them the ability to view overlaid information with no hindrance to normal vision. A 3D-printed enclosure is designed for effective use on the operator's head. Additionally, a capacitive sensor is made to detect the presence of the rescuer's hand to switch between the device's modes of operation.",A. Shenoy; M. Amencherla; R. Nagaraj; T. S. Chandar,,,Optick - A Low Cost Wearable Head up Display for Search and Rescue Operations,,,10.1109/ICCCNT49239.2020.9225266 ,IEEE Conferences ,,"Optick is a visual aid for search and rescue operators during disaster management to help save lives while protecting their own by detecting the presence of humans in low visibility environments and monitoring the toxicity of gases inhaled. There are three main aspects of this device. The first is interfacing the MQ-7 (Carbon Monoxide sensor) and the CCS811 (Carbon Dioxide and Volatile Organic Compounds sensor) with the Raspberry Pi Zero and the OLED display. The second is the detection of humans using the AMG8833 thermal sensor to capture temperature readings which are sent to a trained Deep Learning model. Finally, Optick focuses the display into the eye of the rescuer, giving them the ability to view overlaid information with no hindrance to normal vision. A 3D-printed enclosure is designed for effective use on the operator's head. Additionally, a capacitive sensor is made to detect the presence of the rescuer's hand to switch between the device's modes of operation.",,,978-1-7281-6851-7,1-7,IEEE , ,Optical sensors;Monitoring;Air quality;Temperature sensors;Optical imaging;Capacitive sensors;Prototypes,,
4748,"Title:Acute Inhalation Injury Signatures in Breathing Rate Abnormalities in Domestic Environment using RF Sensing

 Toxic gases pose different risks to human health. Exposure to these toxic gases can be through inhalation of mists, fumes, aerosols, and dust. These inhaled gases can cause injuries, including skin burns, respiratory distress, and death. Nowadays, these harmful toxic agents have become more common in domestic environments, increasing the chances of toxic inhalation in daily life. In a domestic environment, gas toxicity is detected through the odor of toxic gases, as equipment for gas sensing is not readily available and expensive, requiring technical expertise for usage. This situation demands novel methods for avoiding toxic inhalation injuries. Furthermore, most toxic gases affect the breathing rate; thus, constant detection of breathing rate may provide an early warning for toxic gas inhalation and avoid injury. This research study develops a software-defined radio (SDR) system using radio frequency (RF) sensing to monitor abnormal breathing rates continuously by observing channel state information (CSI) variations in the domestic environment. This research work can effectively detect abnormal breathing rates for multi-person in the same environment. The Fast Fourier Transform (FFT) frequency domain analysis-based method is used to detect the abnormal breathing rates of multiple individuals. This study faithfully detects normal, slow, and fast breathing rates for multiple expected cases. The developed system shows noteworthy performance even for five persons in the same environment. This research work is notable because it can be deployed in domestic and occupational settings.",N. A. A. Ali; M. Rehman; M. B. Khan; M. Hayajneh; S. A. Kobaisi,,,Acute Inhalation Injury Signatures in Breathing Rate Abnormalities in Domestic Environment using RF Sensing,,,10.1109/IWCMC58020.2023.10183305 ,IEEE Conferences ,,"Toxic gases pose different risks to human health. Exposure to these toxic gases can be through inhalation of mists, fumes, aerosols, and dust. These inhaled gases can cause injuries, including skin burns, respiratory distress, and death. Nowadays, these harmful toxic agents have become more common in domestic environments, increasing the chances of toxic inhalation in daily life. In a domestic environment, gas toxicity is detected through the odor of toxic gases, as equipment for gas sensing is not readily available and expensive, requiring technical expertise for usage. This situation demands novel methods for avoiding toxic inhalation injuries. Furthermore, most toxic gases affect the breathing rate; thus, constant detection of breathing rate may provide an early warning for toxic gas inhalation and avoid injury. This research study develops a software-defined radio (SDR) system using radio frequency (RF) sensing to monitor abnormal breathing rates continuously by observing channel state information (CSI) variations in the domestic environment. This research work can effectively detect abnormal breathing rates for multi-person in the same environment. The Fast Fourier Transform (FFT) frequency domain analysis-based method is used to detect the abnormal breathing rates of multiple individuals. This study faithfully detects normal, slow, and fast breathing rates for multiple expected cases. The developed system shows noteworthy performance even for five persons in the same environment. This research work is notable because it can be deployed in domestic and occupational settings.",2376-6506,,979-8-3503-3339-8,842-847,IEEE , ,Radio frequency;Wireless communication;Gases;Toxicology;Skin;Sensors;Injuries,,
4749,"Title:Spectroscopic Studies and Numerical Modelling on Nanoparticle based Toxic Heavy Metal Sensor for the Development of a Low-Cost Prototype in Field Use

 With the advent of technology, a sustainable solution of environmental pollution is the selective monitoring of pollutants in the environment. Herein, we report a spectroscopic detection of lead (Pb), one of the toxic heavy metal pollutants. Spectroscopic studies have been utilized to study the self-aggregation of citrate functionalized gold nanoparticles in presence of lead. The Longitudinal Surface Plasmon Resonance (LSPR) of gold nanoparticles increases as the lead concentration increases, and a new peak emerges in the red region of the EM spectrum indicative of the generation of larger aggregates. We have used quasi-static approximation based numerical modelling to determine the percentage of aggregation of the gold nanoparticles in presence of P$\mathrm{b}^{2+}$ ions. We are of the opinion that these key findings will pave the path towards the development of low-cost lead sensor for monitoring of lead pollution in the ecosystem. We have developed a prototype for the measurement of heavy metal toxicity in real world applications in a cost effective way.",N. Pan; R. Ghosh; D. Mukherjee; N. Bhattacharyya; L. Roy; A. Banerjee; S. Singh; R. T. Goswami; M. Mitra; A. Chattopadhyay; S. K. Pal,,,Spectroscopic Studies and Numerical Modelling on Nanoparticle based Toxic Heavy Metal Sensor for the Development of a Low-Cost Prototype in Field Use,,,10.1109/APSCON56343.2023.10101024 ,IEEE Conferences ,,"With the advent of technology, a sustainable solution of environmental pollution is the selective monitoring of pollutants in the environment. Herein, we report a spectroscopic detection of lead (Pb), one of the toxic heavy metal pollutants. Spectroscopic studies have been utilized to study the self-aggregation of citrate functionalized gold nanoparticles in presence of lead. The Longitudinal Surface Plasmon Resonance (LSPR) of gold nanoparticles increases as the lead concentration increases, and a new peak emerges in the red region of the EM spectrum indicative of the generation of larger aggregates. We have used quasi-static approximation based numerical modelling to determine the percentage of aggregation of the gold nanoparticles in presence of P$\mathrm{b}^{2+}$ ions. We are of the opinion that these key findings will pave the path towards the development of low-cost lead sensor for monitoring of lead pollution in the ecosystem. We have developed a prototype for the measurement of heavy metal toxicity in real world applications in a cost effective way.",,,978-1-6654-6163-4,1-6,IEEE , ,Nanoparticles;Gold;Pollution;Toxicology;Biological system modeling;Prototypes;Lead,,
4750,"Title:Dioxin Emission Concentration Soft Measuring Method Based on Selective Ensemble Least Square Support Vector Machine Algorithm

 Dioxin (DXN) is a highly toxic and persistent pollutant discharged from municipal solid waste incineration (MSWI). The first principal model of DXN is difficult to establish due to the complex physical and chemical characteristics of the incineration process. In the practical process, DXN emission concentration is off-line detected with monthly or seasonal periods. Aim at such small sample modeling problem, a soft measuring method based on selective ensemble (SEN) least square support vector machine (LSSVM) for modeling DXN emission concentration is proposed. At first, candidate training sub-samples are produced from original training samples. Then, different candidate sub-sub-models based on the same kernel parameter and regularization parameter are constructed by using LSSVM. Thirdly, ensemble sub-models are selected by using the genetic algorithm optimization tool box and prior knowledge. Finally, these ensemble sub-models are combined by using partial least squares algorithm in terms of reduction con-linearity among different prediction outputs. Simulation results show effectiveness of the proposed approach by using dataset in reference [18].",J. Tang; J. Qiao; Z. Guo; A. Yan,,,Dioxin Emission Concentration Soft Measuring Method Based on Selective Ensemble Least Square Support Vector Machine Algorithm,,,10.23919/ChiCC.2018.8483704 ,IEEE Conferences ,,"Dioxin (DXN) is a highly toxic and persistent pollutant discharged from municipal solid waste incineration (MSWI). The first principal model of DXN is difficult to establish due to the complex physical and chemical characteristics of the incineration process. In the practical process, DXN emission concentration is off-line detected with monthly or seasonal periods. Aim at such small sample modeling problem, a soft measuring method based on selective ensemble (SEN) least square support vector machine (LSSVM) for modeling DXN emission concentration is proposed. At first, candidate training sub-samples are produced from original training samples. Then, different candidate sub-sub-models based on the same kernel parameter and regularization parameter are constructed by using LSSVM. Thirdly, ensemble sub-models are selected by using the genetic algorithm optimization tool box and prior knowledge. Finally, these ensemble sub-models are combined by using partial least squares algorithm in terms of reduction con-linearity among different prediction outputs. Simulation results show effectiveness of the proposed approach by using dataset in reference [18].",1934-1768,,978-988-15639-5-8,7969-7974,IEEE , ,Training;Incineration;Predictive models;Data models;Pollution measurement;Genetic algorithms;Support vector machines,,
4751,"Title:COVID-19 impact on students' Mental Health: Explainable AI and Classifiers

 COVID-19, lockdown, and isolation have included an enormous impact on the students around the world like others. As isolation strategy with quarantine is useful to prevent transmission, students remaining at home gained nothing but illness perception, anxiety, and depression in spite of sharpening their knowledge and reflecting the thoughts. The detachment from routine life has affected the pillars of the mental health balance and isolated and suffocating lives have created toxic feelings in lives. Therefore the purpose of our paper is to predict the mental health of students in such situations. To accomplish our work, we have collected the students' mental health survey dataset from the Kaggle website later trained the data with suitable classifiers to predict mental health. In this paper, we demonstrated five different classifiers models to predict optimal accuracy, including two different Explainable AI (XAI) techniques (LIME, SHAP) as it enhances the trust in an AI system.",A. Ul Hussna; I. Immami Trisha; I. Jahan Ritun; M. G. Rabiul Alam,,,COVID-19 impact on students' Mental Health: Explainable AI and Classifiers,,,10.1109/DASA53625.2021.9682371 ,IEEE Conferences ,,"COVID-19, lockdown, and isolation have included an enormous impact on the students around the world like others. As isolation strategy with quarantine is useful to prevent transmission, students remaining at home gained nothing but illness perception, anxiety, and depression in spite of sharpening their knowledge and reflecting the thoughts. The detachment from routine life has affected the pillars of the mental health balance and isolated and suffocating lives have created toxic feelings in lives. Therefore the purpose of our paper is to predict the mental health of students in such situations. To accomplish our work, we have collected the students' mental health survey dataset from the Kaggle website later trained the data with suitable classifiers to predict mental health. In this paper, we demonstrated five different classifiers models to predict optimal accuracy, including two different Explainable AI (XAI) techniques (LIME, SHAP) as it enhances the trust in an AI system.",,,978-1-6654-1634-4,847-851,IEEE , ,COVID-19;Biological system modeling;Anxiety disorders;Education;Mental health;Machine learning;Forestry,,
4752,"Title:Comparison of Different Computer Vision Approaches for E-waste Components Detection to Automate E-waste Disassembly

 Electronic Waste (E-waste) is generated in a tremendous amount due to our increasing dependence on electronic devices and rapid upgrading in technological innovations. Environmental and health risks are posed because of e-waste toxic constituents. On the other hand, e-waste contains valuable recoverable materials that can gain economic benefits. Efficient e-waste recycling is optimally conducted when different components are separated and processed by their appropriate chemical techniques. If component separation were conducted by humans, it could put their health at risk and consume an unnecessary amount of time. Thus, Automation and robotics solutions are needed to carry out the recycling. At the heart of such solutions is a computer vision algorithm that can detect, localize and classify e-waste components. Different Computer vision approaches, both traditional and deep learning-based, were compared to know which approach will be more suitable for such a task.",A. M. Bassiouny; A. S. Farhan; S. A. Maged; M. I. Awaad,,,Comparison of Different Computer Vision Approaches for E-waste Components Detection to Automate E-waste Disassembly,,,10.1109/MIUCC52538.2021.9447637 ,IEEE Conferences ,,"Electronic Waste (E-waste) is generated in a tremendous amount due to our increasing dependence on electronic devices and rapid upgrading in technological innovations. Environmental and health risks are posed because of e-waste toxic constituents. On the other hand, e-waste contains valuable recoverable materials that can gain economic benefits. Efficient e-waste recycling is optimally conducted when different components are separated and processed by their appropriate chemical techniques. If component separation were conducted by humans, it could put their health at risk and consume an unnecessary amount of time. Thus, Automation and robotics solutions are needed to carry out the recycling. At the heart of such solutions is a computer vision algorithm that can detect, localize and classify e-waste components. Different Computer vision approaches, both traditional and deep learning-based, were compared to know which approach will be more suitable for such a task.",,,978-1-6654-1243-8,17-23,IEEE , ,Deep learning;Measurement;Computer vision;Portable computers;Computational modeling;Biological system modeling;Transfer learning,,
4753,"Title:Recycling of printed circuit boards by robot manipulator: A Deep Learning Approach

 Electronic circuit boards in mobile phones, PCs, home appliances, etc. that are no longer in use contain many useful parts such as resin and metals. In addition, there are toxic elements that need a specific treatment. Japan now depends almost entirely on foreign countries for the required metal resources. Since most electronic waste is composed of complex materials such as plastics and metals, it is difficult to isolate them and return them to a single resource. In addition, dedicated equipment is required to recover resources, and sensors are often used, which is a factor in increasing costs. In this paper we develop a system for recycling of PCB boards through classification, recovery and management of electronic parts. In our method, the PCBs are divided in small pieces which moves in a belt conveyer. For component recognition, we trained and compared the performance of two Convolution Neural Networks (CNN). The camera detects each PCB component and classify it. In our implementation we classified the components in five classes. Based on the camera information and the conveyer speed the robot manipulator motion is generated and the classified parts are sorted in separate containers. In addition, we investigated the shape and material of the gripper for easy grasping of PCBs components.",K. Naito; A. Shirai; S. -i. Kaneko; G. Capi,,,Recycling of printed circuit boards by robot manipulator: A Deep Learning Approach,,,10.1109/ROSE52750.2021.9611773 ,IEEE Conferences ,,"Electronic circuit boards in mobile phones, PCs, home appliances, etc. that are no longer in use contain many useful parts such as resin and metals. In addition, there are toxic elements that need a specific treatment. Japan now depends almost entirely on foreign countries for the required metal resources. Since most electronic waste is composed of complex materials such as plastics and metals, it is difficult to isolate them and return them to a single resource. In addition, dedicated equipment is required to recover resources, and sensors are often used, which is a factor in increasing costs. In this paper we develop a system for recycling of PCB boards through classification, recovery and management of electronic parts. In our method, the PCBs are divided in small pieces which moves in a belt conveyer. For component recognition, we trained and compared the performance of two Convolution Neural Networks (CNN). The camera detects each PCB component and classify it. In our implementation we classified the components in five classes. Based on the camera information and the conveyer speed the robot manipulator motion is generated and the classified parts are sorted in separate containers. In addition, we investigated the shape and material of the gripper for easy grasping of PCBs components.",,,978-1-6654-4062-2,1-5,IEEE , ,Deep learning;Robot vision systems;Metals;Manipulators;Cameras;Belts;Recycling,,
4754,"Title:Randomly Under Sampled Boosted Tree for Predicting Sepsis From Intensive Care Unit Databases

 Bacterial infection can result in sepsis; a toxic immune response by the body. Although the rate of mortality due to sepsis has fallen within the UK, overall rates remain higher than in Europe. Early detection of sepsis has been linked to elevated successful outcomes. This work focuses on the use of a Random Under Sample (RUS) Boosted Tree for classifying sepsis from intensive care unit databases.Full training set (40,336 subjects) achieved sensitivity and specificity of 53.4% and 83.6% respectively (AUC:77.79%) with 5 fold cross-validation. In the unofficial phase of the challenge the model achieved a normalized utility score of 0.267. The model did not achieve a score on the full test set (team name B-Secur).The results show that the model is capable of detecting sepsis in patients. However, there is more work to be done in order to improve performance. Future work will investigate the use of fixed time windows rather than individual hourly measurements to increase prediction performance.",P. Doggart; M. Rutherford,,,Randomly Under Sampled Boosted Tree for Predicting Sepsis From Intensive Care Unit Databases,,,10.22489/CinC.2019.362 ,IEEE Conferences ,,"Bacterial infection can result in sepsis; a toxic immune response by the body. Although the rate of mortality due to sepsis has fallen within the UK, overall rates remain higher than in Europe. Early detection of sepsis has been linked to elevated successful outcomes. This work focuses on the use of a Random Under Sample (RUS) Boosted Tree for classifying sepsis from intensive care unit databases.Full training set (40,336 subjects) achieved sensitivity and specificity of 53.4% and 83.6% respectively (AUC:77.79%) with 5 fold cross-validation. In the unofficial phase of the challenge the model achieved a normalized utility score of 0.267. The model did not achieve a score on the full test set (team name B-Secur).The results show that the model is capable of detecting sepsis in patients. However, there is more work to be done in order to improve performance. Future work will investigate the use of fixed time windows rather than individual hourly measurements to increase prediction performance.",2325-887X,,978-1-7281-6936-1,Page 1-Page 4,IEEE , ,Training data;Time measurement;Current measurement;Heart rate;Data models;Filling;Blood pressure,,
4755,"Title:Skin Diseases Classification using Deep Convolutional Neural Network

 Dermatological diseases are considered as the fourth cause of the problem of non-toxic diseases in recent years. These skin abnormalities are not affected by the physical human body as they also affect mental health. The tremendous development in medical technology has great potential in diagnosing skin diseases more quickly and accurately, but the cost of this diagnosis is still limited and expensive in addition to the high rate of diagnosis error for some types of the skin diseases. This study proposes a method that is based on the Convolution Neural Network( to detect and classify ten types of the skin diseases. The proposed CNN architecture in general nine convolution layers and two fully connected layers. The contribution of the current method is its ability to detect many visual similar diseases and some of them aren’t detected by computerized programs previously. Nine diseases are detected by a certain program while most of the previous works work on a few diseases. All the parameters of this proposed CNN are determined experimentally. The total accuracy of the proposed model is 91.07%. This proposed model works well with many issues of the detection and classification of the skin diseases. It is an encouraging method compared with other methods.",Z. H. R. Naji; N. K. El Abbadi,,,Skin Diseases Classification using Deep Convolutional Neural Network,,,10.1109/IICCIT55816.2022.10010658 ,IEEE Conferences ,,"Dermatological diseases are considered as the fourth cause of the problem of non-toxic diseases in recent years. These skin abnormalities are not affected by the physical human body as they also affect mental health. The tremendous development in medical technology has great potential in diagnosing skin diseases more quickly and accurately, but the cost of this diagnosis is still limited and expensive in addition to the high rate of diagnosis error for some types of the skin diseases. This study proposes a method that is based on the Convolution Neural Network( to detect and classify ten types of the skin diseases. The proposed CNN architecture in general nine convolution layers and two fully connected layers. The contribution of the current method is its ability to detect many visual similar diseases and some of them aren’t detected by computerized programs previously. Nine diseases are detected by a certain program while most of the previous works work on a few diseases. All the parameters of this proposed CNN are determined experimentally. The total accuracy of the proposed model is 91.07%. This proposed model works well with many issues of the detection and classification of the skin diseases. It is an encouraging method compared with other methods.",,,978-1-6654-7220-3,309-315,IEEE , ,Training;Visualization;Convolution;Computational modeling;Neural networks;Skin;Mobile applications,,
4756,"Title:Expert System for Breast Cancer Prediction using Ensemble Learning

 Breast cancer (BC) is the most frequent life-threatening illness in women, as well as the main cause of cancer mortality. Over the last two decades, BC research has made significant advances in our understanding of the disease, resulting in more effective and less toxic medicines. However, precise BC prediction is always crucial for effective therapy. Ensemble learning techniques have been used for accurate prediction of BC since the last few years. This paper also proposes an Expert System for Breast Cancer Detection (ESBCD) for better prediction of BC with machine learning analytics. The ESBCD preprocesses the BC data to impute the missing values and to remove the outliers, and then uses ensemble learning technique for classification.",R. Paul; S. K. Biswas; A. N. Boruah; A. K. Das; S. Reshmi; B. Purkayastha,,,Expert System for Breast Cancer Prediction using Ensemble Learning,1,,10.1109/COM-IT-CON54601.2022.9850678 ,IEEE Conferences ,,"Breast cancer (BC) is the most frequent life-threatening illness in women, as well as the main cause of cancer mortality. Over the last two decades, BC research has made significant advances in our understanding of the disease, resulting in more effective and less toxic medicines. However, precise BC prediction is always crucial for effective therapy. Ensemble learning techniques have been used for accurate prediction of BC since the last few years. This paper also proposes an Expert System for Breast Cancer Detection (ESBCD) for better prediction of BC with machine learning analytics. The ESBCD preprocesses the BC data to impute the missing values and to remove the outliers, and then uses ensemble learning technique for classification.",,,978-1-6654-9602-5,113-118,IEEE , ,Computational modeling;Medical treatment;Forestry;Parallel processing;Feature extraction;Breast cancer;Stability analysis,,
4757,"Title:A Survey Paper on an IoT-based Machine Learning Model to Predict Air Pollution Levels

 In today’s quickly developing world, air pollution is a major worry. As pollution rises in the earth’s atmosphere every day, so do its rates. The problem is typically caused by toxic fumes released into the air as a result of a broad range of human activities. It is necessary for the current generation to understand the risks posed by these circumstances and to take effective measures to minimize them before the ecosystem is destroyed. This study examines studies of machine learning approaches (MLAs or MLTs) and Internet of Things in predicting air quality, as well as forecasting air pollution levels so individuals can take action to reduce pollution.",S. B. Kasetty; S. Nagini,,,A Survey Paper on an IoT-based Machine Learning Model to Predict Air Pollution Levels,,,10.1109/ICAC3N56670.2022.10074555 ,IEEE Conferences ,,"In today’s quickly developing world, air pollution is a major worry. As pollution rises in the earth’s atmosphere every day, so do its rates. The problem is typically caused by toxic fumes released into the air as a result of a broad range of human activities. It is necessary for the current generation to understand the risks posed by these circumstances and to take effective measures to minimize them before the ecosystem is destroyed. This study examines studies of machine learning approaches (MLAs or MLTs) and Internet of Things in predicting air quality, as well as forecasting air pollution levels so individuals can take action to reduce pollution.",,,978-1-6654-7436-8,1408-1412,IEEE , ,Machine learning algorithms;Atmospheric measurements;Terrestrial atmosphere;Machine learning;Predictive models;Air pollution;Prediction algorithms,,
4758,"Title:Combining Pre-Trained Language Models and Features for Offensive Language Detection

 Nowadays, people often express their abusive and offensive thoughts to others on social media easier. The abusive and toxic comments hurt others seriously. Therefore those abusive and toxic comments should be detected properly through natural language processing. In this paper, we focus on two types of features in offensive language: word-level and sentence-level fea-tures. We use lexicon-based and standard bag-of-words features as the word level. We introduce BERT-based and DeepMoji-based features as the sentence level. We apply the four features to a machine learning approach: support vector machines. We evaluate the method using the combinations of four features with a dataset, Curious Cat. The best F1 score was generated by the method with all features. This result shows the effectiveness of our proposed method. In addition, the experimental result indicates that DeepMoji generated from Twitter data is better than BERT which is generated from written language, for an offensive language detection task about social media data.",Z. Li; K. Shimada,,,Combining Pre-Trained Language Models and Features for Offensive Language Detection,,,10.1109/IIAI-AAI-Winter58034.2022.00012 ,IEEE Conferences ,,"Nowadays, people often express their abusive and offensive thoughts to others on social media easier. The abusive and toxic comments hurt others seriously. Therefore those abusive and toxic comments should be detected properly through natural language processing. In this paper, we focus on two types of features in offensive language: word-level and sentence-level fea-tures. We use lexicon-based and standard bag-of-words features as the word level. We introduce BERT-based and DeepMoji-based features as the sentence level. We apply the four features to a machine learning approach: support vector machines. We evaluate the method using the combinations of four features with a dataset, Curious Cat. The best F1 score was generated by the method with all features. This result shows the effectiveness of our proposed method. In addition, the experimental result indicates that DeepMoji generated from Twitter data is better than BERT which is generated from written language, for an offensive language detection task about social media data.",,,979-8-3503-0992-8,5-10,IEEE , ,Support vector machines;Dictionaries;Social networking (online);Bit error rate;Machine learning;Media;Feature extraction,,
4759,"Title:SmokePose: End-to-End Smoke Keypoint Detection

 Smoke detection has been a research focus due to its application value in fire and toxic gas leakage alarms. Here we formulate a novel research paradigm for in-depth smoke analysis: modeling the smoke plume in an image with two semantic keypoints, i.e., the start-point (where the smoke comes from) and the end-point (where the smoke spreads), and localizing the keypoints through a heatmap-based detection method. A specialized dataset is developed for smoke keypoint detection, collecting images online and manually annotating the keypoints. Based on the dataset, we propose a Transformer-based model called SmokePose that employs a hierarchical Transformer encoder and a pure Transformer decoder to detect smoke keypoints in an end-to-end manner. We demonstrated the performance of the proposed SmokePose with comparative experiments and ablation studies. A further discussion on the visualization of the attention maps helps to understand the mechanism of SmokePose and to reveal essential image clues for smoke keypoint detection.",T. Jing; M. Zeng; Q. -H. Meng,,,SmokePose: End-to-End Smoke Keypoint Detection,33,10,10.1109/TCSVT.2023.3258527 ,IEEE Journals ,,"Smoke detection has been a research focus due to its application value in fire and toxic gas leakage alarms. Here we formulate a novel research paradigm for in-depth smoke analysis: modeling the smoke plume in an image with two semantic keypoints, i.e., the start-point (where the smoke comes from) and the end-point (where the smoke spreads), and localizing the keypoints through a heatmap-based detection method. A specialized dataset is developed for smoke keypoint detection, collecting images online and manually annotating the keypoints. Based on the dataset, we propose a Transformer-based model called SmokePose that employs a hierarchical Transformer encoder and a pure Transformer decoder to detect smoke keypoints in an end-to-end manner. We demonstrated the performance of the proposed SmokePose with comparative experiments and ablation studies. A further discussion on the visualization of the attention maps helps to understand the mechanism of SmokePose and to reveal essential image clues for smoke keypoint detection.",1558-2205,,,5778-5789,IEEE , ,Feature extraction;Semantics;Dispersion;Transformers;Task analysis;Heating systems;Visualization,,
4760,"Title:Challenges and Approaches of Code-mixed Hate Speech Detection

 The online platform and social media are very eye catchy for internet users. Platforms like YouTube, Twitter, Instagram, etc., are higher in demand due to their brilliant services. Users of these sights frequently comment on others' posts which may contain toxic speech. Some platforms also raise concerns about emerging of this activity. As the increase of hate speech is just next to impossible to control, the need to detect these contents through automated hate speech detection technologies arises. In this work, we focused on multi-lingual issues, especially Indo-European code-mixed languages. At first, we identified some issues related to code-mixed Indian languages. Then, we focused on the available solutions to this problem. We have gone through the works performed on machine learning and deep learning techniques and identified the limitations of those works. We have analyzed the present solutions and gone through the comparative studies of those. Our implementation is conducted on code-mixed twitter datasets providing several perceptions on hate speech. We have performed the experimental work on HASOC 2021 dataset. Our work contributes to the field of hate speech detection by comparing feature extraction and classifier algorithms (Machine Learning and Deep Learning). More specifically, the proposed work aimed at distinguishing Hate and Non-Hate speech from normal text.",S. S. Dash; N. B. Kar,,,Challenges and Approaches of Code-mixed Hate Speech Detection,,,10.1109/MLCSS57186.2022.00060 ,IEEE Conferences ,,"The online platform and social media are very eye catchy for internet users. Platforms like YouTube, Twitter, Instagram, etc., are higher in demand due to their brilliant services. Users of these sights frequently comment on others' posts which may contain toxic speech. Some platforms also raise concerns about emerging of this activity. As the increase of hate speech is just next to impossible to control, the need to detect these contents through automated hate speech detection technologies arises. In this work, we focused on multi-lingual issues, especially Indo-European code-mixed languages. At first, we identified some issues related to code-mixed Indian languages. Then, we focused on the available solutions to this problem. We have gone through the works performed on machine learning and deep learning techniques and identified the limitations of those works. We have analyzed the present solutions and gone through the comparative studies of those. Our implementation is conducted on code-mixed twitter datasets providing several perceptions on hate speech. We have performed the experimental work on HASOC 2021 dataset. Our work contributes to the field of hate speech detection by comparing feature extraction and classifier algorithms (Machine Learning and Deep Learning). More specifically, the proposed work aimed at distinguishing Hate and Non-Hate speech from normal text.",,,978-1-6654-5493-3,290-295,IEEE , ,Deep learning;Video on demand;Machine learning algorithms;Social networking (online);Hate speech;Blogs;Multimedia Web sites,,
4761,"Title:Air quality based optimal path search model for spatio-temporal data set

 The proliferation of GIS and GPS technology provide huge amount of geo-data in the form of spatio-temporal dataset. With the increased use of mobile devices, end users tend to avail location based services in various contexts. This requires frequent updation of the database and also the development of fast search and optimization techniques. The increasing vehicular traffic in urban sectors leads to the emission of toxic gases thereby increasing air pollution levels. Ambient air quality can be monitored dynamically using vehicular network called VANET, which senses the ambient air pollutant levels with reference to GPS points and stores them in the central GIS database server. Our proposed approach returns the optimal and the safest route when enquired for the route between a source and a destination considering acceptable pollution level limits enroute. The existing models for pointal queries provide the shortest path between source and destination consuming more disk space, construction time and execution time. They support only distance based optimization, whereas our proposed optimal path search model is based on the ambient air quality. The investigation shows that our proposed model reduces searching and execution time.",K. Karuppanan; A. Manickam; E. Karthikeyan; M. Narayanan,,,Air quality based optimal path search model for spatio-temporal data set,,,10.1109/ICACCI.2013.6637149 ,IEEE Conferences ,,"The proliferation of GIS and GPS technology provide huge amount of geo-data in the form of spatio-temporal dataset. With the increased use of mobile devices, end users tend to avail location based services in various contexts. This requires frequent updation of the database and also the development of fast search and optimization techniques. The increasing vehicular traffic in urban sectors leads to the emission of toxic gases thereby increasing air pollution levels. Ambient air quality can be monitored dynamically using vehicular network called VANET, which senses the ambient air pollutant levels with reference to GPS points and stores them in the central GIS database server. Our proposed approach returns the optimal and the safest route when enquired for the route between a source and a destination considering acceptable pollution level limits enroute. The existing models for pointal queries provide the shortest path between source and destination consuming more disk space, construction time and execution time. They support only distance based optimization, whereas our proposed optimal path search model is based on the ambient air quality. The investigation shows that our proposed model reduces searching and execution time.",,,978-1-4673-6217-7,73-78,IEEE , ,Optimization;Air pollution;Databases;Atmospheric modeling;Gases;Algorithm design and analysis,,
4762,"Title:Multi-task CNN for Abusive Language Detection

 Abusive language detection serves to ensure a compelling user experience via high-quality content. Different sub-categories of abusive language are closely related, with most aggressive comments containing personal attacks and toxic content and vice versa. We set a multi-task learning framework to detect different types of abusive content in a mental health forum to address this feature. Each classification task is treated as a subclass in a multi-class classification problem, with shared knowledge used for three related tasks: attack, aggression, and toxicity. Experimental results on three sub-types of Wikipedia abusive language datasets show that our framework can improve the net F1-score by 7.1%, 5.6%, and 2.7% in the attack, aggressive, and toxicity detection. Our experiments identified multi tasking framework act as an effective method in abusive language detection.",Q. Zhao; Y. Xiao; Y. Long,,,Multi-task CNN for Abusive Language Detection,,,10.1109/PRML52754.2021.9520387 ,IEEE Conferences ,,"Abusive language detection serves to ensure a compelling user experience via high-quality content. Different sub-categories of abusive language are closely related, with most aggressive comments containing personal attacks and toxic content and vice versa. We set a multi-task learning framework to detect different types of abusive content in a mental health forum to address this feature. Each classification task is treated as a subclass in a multi-class classification problem, with shared knowledge used for three related tasks: attack, aggression, and toxicity. Experimental results on three sub-types of Wikipedia abusive language datasets show that our framework can improve the net F1-score by 7.1%, 5.6%, and 2.7% in the attack, aggressive, and toxicity detection. Our experiments identified multi tasking framework act as an effective method in abusive language detection.",,,978-1-6654-4383-8,286-291,IEEE , ,Toxicology;Natural languages;Mental health;Machine learning;Encyclopedias;Feature extraction;User experience,,
4763,"Title:Deep Transfer Learning for Nucleus and Micronucleus Recognition

 Nucleus is the main component in a human cell. Excellent nucleus shape observation methods help endorse scientific research in medical and biological fields. Nucleus shape observation methods are performed manually by humans through medical labs. Abnormal nucleus (Micronucleus) is caused by drugs and other toxical factors. Current methods are only confined in detecting and segmenting nucleuses images from different human tissues. None of the these methods has tackled the problem of automating the nucleus and micronucleus recognition. In this paper, first, we apply a deep transfer learning to automate the recognition of nucleus and micronucleus from microscopy images. Second, we introduce our dataset which consists of manually collected nucleus and micronucleus image examples to train and evaluate the performance of the proposed method. The examples are manually curated by domain of experts in the biology. The nucleus and micronucleus images are used as an input to feed several pre-trained Convolutional Neural Network (CNN) models. The models performance is measured using 2-fold cross validation. Our experimental evaluation shows that GoogLeNet pre-trained model performs better than other models with an 80.06 % of average classification accuracy.",T. Alafif; S. Qari; A. Albassam; A. Alrefaei,,,Deep Transfer Learning for Nucleus and Micronucleus Recognition,,,10.1109/SMART-TECH49988.2020.00022 ,IEEE Conferences ,,"Nucleus is the main component in a human cell. Excellent nucleus shape observation methods help endorse scientific research in medical and biological fields. Nucleus shape observation methods are performed manually by humans through medical labs. Abnormal nucleus (Micronucleus) is caused by drugs and other toxical factors. Current methods are only confined in detecting and segmenting nucleuses images from different human tissues. None of the these methods has tackled the problem of automating the nucleus and micronucleus recognition. In this paper, first, we apply a deep transfer learning to automate the recognition of nucleus and micronucleus from microscopy images. Second, we introduce our dataset which consists of manually collected nucleus and micronucleus image examples to train and evaluate the performance of the proposed method. The examples are manually curated by domain of experts in the biology. The nucleus and micronucleus images are used as an input to feed several pre-trained Convolutional Neural Network (CNN) models. The models performance is measured using 2-fold cross validation. Our experimental evaluation shows that GoogLeNet pre-trained model performs better than other models with an 80.06 % of average classification accuracy.",,,978-1-7281-7407-5,21-27,IEEE , ,Image recognition;Shape;Biological system modeling;Microscopy;Convolutional neural networks;Feeds;Biomedical imaging,,
4764,"Title:Robotic Sorting of Batteries Using Visual Few-shot Learning and Fusion with Depth Data

 Recycling electronic waste becomes more and more important to recover precious materials. Batteries in particular contain significant amounts of rare-earth elements. These can be extracted in specialized recycling methods provided that the batteries are pre-sorted. Toxic substances released during the sorting process can expose human workers to health risks. Therefore, we propose an automated sorting line with an industrial robot for batteries based on visual and depth sensors, whereas other approaches predominantly only use monomodal sensor input. We use few-shot learning methods for visual detection to not rely on large datasets. Additionally, the visual predictions are verified based on the processed depth data using expert knowledge. The expert knowledge is integrated using rules regarding the spatial dimensions of each category of batteries. We evaluate our application in a realistic test scenario. We find that the combination of deep learning and depth data processing ensures high accuracy for sorting applications with a reduced number of training samples.",P. Keller; J. Mangler; N. Hügel; M. G. Besselmann; A. Rönnau; R. Dillmann,,,Robotic Sorting of Batteries Using Visual Few-shot Learning and Fusion with Depth Data,,,10.1109/ICECCME57830.2023.10253347 ,IEEE Conferences ,,"Recycling electronic waste becomes more and more important to recover precious materials. Batteries in particular contain significant amounts of rare-earth elements. These can be extracted in specialized recycling methods provided that the batteries are pre-sorted. Toxic substances released during the sorting process can expose human workers to health risks. Therefore, we propose an automated sorting line with an industrial robot for batteries based on visual and depth sensors, whereas other approaches predominantly only use monomodal sensor input. We use few-shot learning methods for visual detection to not rely on large datasets. Additionally, the visual predictions are verified based on the processed depth data using expert knowledge. The expert knowledge is integrated using rules regarding the spatial dimensions of each category of batteries. We evaluate our application in a realistic test scenario. We find that the combination of deep learning and depth data processing ensures high accuracy for sorting applications with a reduced number of training samples.",,,979-8-3503-2297-2,1-7,IEEE , ,Deep learning;Training;Visualization;Robot vision systems;Robustness;Batteries;Recycling,,
4765,"Title:An experimental approach to compare various deep learning architectures for sentiment analysis

 This paper aims to study the efficiency of various seq2seq deep learning architectures for the solution of toxic speech classification and performing efficient sentiment analysis using unilingual publicly available dataset. Numerical examples are presented along with various validation metrics and graphs to indicate the efficiency of the various NLP techniques and confirm the experimental findings of the paper. We also compare and contrast between traditionally used natural language processing models and state of the art model like Bidirectional Encoder Representations from Transformers or BERT.",P. Ghorpade; A. Lende; L. Chavan; R. Shaikh; N. Shaikh; A. Chavan,,,An experimental approach to compare various deep learning architectures for sentiment analysis,,,10.1109/ICCCA49541.2020.9250785 ,IEEE Conferences ,,This paper aims to study the efficiency of various seq2seq deep learning architectures for the solution of toxic speech classification and performing efficient sentiment analysis using unilingual publicly available dataset. Numerical examples are presented along with various validation metrics and graphs to indicate the efficiency of the various NLP techniques and confirm the experimental findings of the paper. We also compare and contrast between traditionally used natural language processing models and state of the art model like Bidirectional Encoder Representations from Transformers or BERT.,2642-7354,,978-1-7281-6324-6,548-553,IEEE , ,Deep learning;Sentiment analysis;Analytical models;Computational modeling;Computer architecture;Classification algorithms;Numerical models,,
4766,"Title:Animal Healthcare and Farm Animal Disease Prediction Using Machine Learning

 Veterinary care is an extremely important part of animal care. The focus of the Veterinary doctor or practitioner is to supervise the overall health and clinical care of the animals. A veterinary doctor is responsible for observing and promoting the well-being of the animal at all phases of the animal's life span. In the inaccessible remote locations of India, access to Veterinary services is difficult. Farmers or livestock owners have to travel long distances from their villages when they require treatment for their animals. This has adversely affected eutherian mammal farming in rural regions that square measure usually set in remote locations. A website to connect Veterinarians with Livestock owners can turn out to be a valuable solution. Farm Animals represent a valuable quality of nutritional products such as dairy products they also are a great resource of the economy for the owners. The production of dairy and other nutritional products is being challenged due to the toxic use of pests and malady infestation resulting in poor productivity. Death of the animals can also be expected in such cases, massive economic losses to livestock owners and the nation. Such issues must be addressed timely before the situation gets out of hand, this is only possible by making Veterinary services available to every part of the nation, be it via online mode or by providing Veterinary practitioners to rural areas. Livestock production in the farm sector acts as an important source of nutrition to India, it provides economic support to many farmers and contributes to the economy of India.",A. Nadar; A. Sane; G. Muga; E. Masih; S. Rukhande,,,Animal Healthcare and Farm Animal Disease Prediction Using Machine Learning,,,10.1109/ICNTE56631.2023.10146635 ,IEEE Conferences ,,"Veterinary care is an extremely important part of animal care. The focus of the Veterinary doctor or practitioner is to supervise the overall health and clinical care of the animals. A veterinary doctor is responsible for observing and promoting the well-being of the animal at all phases of the animal's life span. In the inaccessible remote locations of India, access to Veterinary services is difficult. Farmers or livestock owners have to travel long distances from their villages when they require treatment for their animals. This has adversely affected eutherian mammal farming in rural regions that square measure usually set in remote locations. A website to connect Veterinarians with Livestock owners can turn out to be a valuable solution. Farm Animals represent a valuable quality of nutritional products such as dairy products they also are a great resource of the economy for the owners. The production of dairy and other nutritional products is being challenged due to the toxic use of pests and malady infestation resulting in poor productivity. Death of the animals can also be expected in such cases, massive economic losses to livestock owners and the nation. Such issues must be addressed timely before the situation gets out of hand, this is only possible by making Veterinary services available to every part of the nation, be it via online mode or by providing Veterinary practitioners to rural areas. Livestock production in the farm sector acts as an important source of nutrition to India, it provides economic support to many farmers and contributes to the economy of India.",,,978-1-6654-6504-5,1-6,IEEE , ,Economics;Productivity;Schedules;Animals;Rural areas;Medical services;Predictive models,,
4767,"Title:Image De-hazing techniques for Vision based applications - A survey

 Haze is defined as a poor condition described by an iridescent atmospheric appearance that reduces clarity and visibility. The main reason for this is lot of toxic elements like dust particles, smoke in the atmosphere scattering and absorbing sun light. This poor intelligibility causes various computer vision applications to fail, including intelligent transportation, video surveillance, element recognition, and in a method to perform operations on image to get better image. There is a problem in domain of image processing wherein image recovery by various degradations is a challenge. Pictures and videos taken in outdoor environments usually suffer from reduced contrast, faded colors and with reduced visibility due to airborne particles, which directly affect image quality. This can lead to problems recognizing objects captured in blurry or still images. Several images clean up techniques have been developed to solve this problem, each with their own strengths and weaknesses, but effective image recovery is daunting task. Recently, many learning-based methods (predictive analytics and natural language processing) have tried to overcome the shortcomings of mechanical representation of properties and alleviated the challenge of efficiently reconstructing images by spending with reduce cost and comparatively reduced time. This overview delves into latest techniques for imaging with no-fog. In addition, hardware execution of many real time dehaze methods have been methodically outlined by this paper. The study done in this paper paves a way for researches in image dehazing domain as-well-as will direct them for doing further enhancement on the basis of achievements done currently.",S. Krishna B V; B. Rajalakshmi; U. Dhammini; M. K. Monika; C. Nethra; K. Ashok,,,Image De-hazing techniques for Vision based applications - A survey,,,10.1109/ICONAT57137.2023.10080156 ,IEEE Conferences ,,"Haze is defined as a poor condition described by an iridescent atmospheric appearance that reduces clarity and visibility. The main reason for this is lot of toxic elements like dust particles, smoke in the atmosphere scattering and absorbing sun light. This poor intelligibility causes various computer vision applications to fail, including intelligent transportation, video surveillance, element recognition, and in a method to perform operations on image to get better image. There is a problem in domain of image processing wherein image recovery by various degradations is a challenge. Pictures and videos taken in outdoor environments usually suffer from reduced contrast, faded colors and with reduced visibility due to airborne particles, which directly affect image quality. This can lead to problems recognizing objects captured in blurry or still images. Several images clean up techniques have been developed to solve this problem, each with their own strengths and weaknesses, but effective image recovery is daunting task. Recently, many learning-based methods (predictive analytics and natural language processing) have tried to overcome the shortcomings of mechanical representation of properties and alleviated the challenge of efficiently reconstructing images by spending with reduce cost and comparatively reduced time. This overview delves into latest techniques for imaging with no-fog. In addition, hardware execution of many real time dehaze methods have been methodically outlined by this paper. The study done in this paper paves a way for researches in image dehazing domain as-well-as will direct them for doing further enhancement on the basis of achievements done currently.",,,978-1-6654-7517-4,1-5,IEEE , ,Visualization;Image recognition;Image color analysis;Transportation;Scattering;Video surveillance;Real-time systems,,
4768,"Title:A Parsimonious and Practical Approach to Detecting Offensive Speech

 With the proliferation of hateful and offensive speech on social media platforms such as Twitter, machine learning approaches to detect such toxic content have gained prominence. Despite these advances, real-time detection of such speech, while it is being shared on these platforms, remains a challenge for two reasons. First, these approaches train complex models on a plethora of features, which calls into question their computational efficiency for real-time deployment. Moreover, they require sizeable, manually annotated data sets from the same context, and annotating large data sets is extremely time-consuming, error-prone and cumbersome. This paper proposes a parsimonious and practical approach for the detection of offensive speech that alleviates these challenges. The approach is parsimonious because through a comprehensive evaluation of commonly used machine learning models (Logistic Regression, Random Forest, Neural Networks) on two public domain data sets it demonstrates that a simple Logistic Regression model trained on unigrams with frequency counts can detect hate speech with high accuracy of over 90%. It is practical because it demonstrates how an existing labeled training data set can be used to train models that can detect offensive content from a completely unknown data set with moderate accuracy. Based on these findings, the paper offers guidance on the characteristics that may be desirable in benchmark training data sets for offensive speech detection.",H. Khan; F. Yu; A. Sinha; S. S. Gokhale,,,A Parsimonious and Practical Approach to Detecting Offensive Speech,,,10.1109/ICCCIS51004.2021.9397140 ,IEEE Conferences ,,"With the proliferation of hateful and offensive speech on social media platforms such as Twitter, machine learning approaches to detect such toxic content have gained prominence. Despite these advances, real-time detection of such speech, while it is being shared on these platforms, remains a challenge for two reasons. First, these approaches train complex models on a plethora of features, which calls into question their computational efficiency for real-time deployment. Moreover, they require sizeable, manually annotated data sets from the same context, and annotating large data sets is extremely time-consuming, error-prone and cumbersome. This paper proposes a parsimonious and practical approach for the detection of offensive speech that alleviates these challenges. The approach is parsimonious because through a comprehensive evaluation of commonly used machine learning models (Logistic Regression, Random Forest, Neural Networks) on two public domain data sets it demonstrates that a simple Logistic Regression model trained on unigrams with frequency counts can detect hate speech with high accuracy of over 90%. It is practical because it demonstrates how an existing labeled training data set can be used to train models that can detect offensive content from a completely unknown data set with moderate accuracy. Based on these findings, the paper offers guidance on the characteristics that may be desirable in benchmark training data sets for offensive speech detection.",,,978-1-7281-8529-3,688-695,IEEE , ,Voice activity detection;Social networking (online);Training data;Data models;Real-time systems;Random forests;Logistics,,
4769,"Title:Analyzing Employee Attrition Using Machine Learning: the New AI Approach

 Employee attrition has indeed been recognized as a critical concern for organizations due to the adverse effects, it has on workplace productivity as well as long-term growth plans. Organizations are using machine learning (a subset of AI) techniques to predict employee turnover to address this issue. In this paper, an attempt is made to develop a model that can predict employee turnover rates by utilizing HR analytics data provided by the Kaggle website. Random Forest and the AdaBoost classifier are used to make predictions. This paper also introduces the factors that influence employee attrition inside any organization and will provide a clear perspective to top management in making key decisions regarding the retention of most of the workforce in the organization. In future research, the analysis can be improved by considering other factors like no feedback and recognition, bad hiring procedures, toxic culture, etc which impacts employee attrition rate positively.",S. Krishna; S. Sidharth,,,Analyzing Employee Attrition Using Machine Learning: the New AI Approach,,,10.1109/I2CT54291.2022.9825342 ,IEEE Conferences ,,"Employee attrition has indeed been recognized as a critical concern for organizations due to the adverse effects, it has on workplace productivity as well as long-term growth plans. Organizations are using machine learning (a subset of AI) techniques to predict employee turnover to address this issue. In this paper, an attempt is made to develop a model that can predict employee turnover rates by utilizing HR analytics data provided by the Kaggle website. Random Forest and the AdaBoost classifier are used to make predictions. This paper also introduces the factors that influence employee attrition inside any organization and will provide a clear perspective to top management in making key decisions regarding the retention of most of the workforce in the organization. In future research, the analysis can be improved by considering other factors like no feedback and recognition, bad hiring procedures, toxic culture, etc which impacts employee attrition rate positively.",,,978-1-6654-2168-3,1-14,IEEE , ,Training;Productivity;Analytical models;Companies;Predictive models;Prediction algorithms;Data models,,
4770,"Title:Lightweight Privacy and Security Computing for Blockchained Federated Learning in IoT

 The development of Internet of Things (IoT) makes human life more intelligent, and the interconnection of all things has become a reality. However, the surge in the number of devices and centralized management brings severe challenges to IoT, such as single point of failure, poor security, privacy leakage, and low reliability. Due to the decentralization, verifiability, and privacy protection of blockchain federated learning (BFL), some BFL schemes have been proposed to solve these problems, but bring new challenges, such as device privacy leakage and heavy security computing load. In this article, we propose a new decentralized, secure and verifiable consortium BFL privacy protection scheme, named LPBFL, which realizes lightweight computing while ensuring the privacy of the local model and data set of the device. To achieve lightweight privacy protection, LPBFL adopts the Paillier encryption and the newly designed lightweight digital signature and batch verification algorithm. Additionally, considering that devices upload invalid or even toxic local models intentionally or unintentionally, we design a device reputation selection mechanism to make BFL more efficient. Finally, the theoretical analysis proves the security of LPBFL and verifies the unforgeability of the proposed digital signature. Comprehensive comparisons and extensive experiments demonstrate that our LPBFL has significant advantages in multiple aspects.",M. Fan; K. Ji; Z. Zhang; H. Yu; G. Sun,,,Lightweight Privacy and Security Computing for Blockchained Federated Learning in IoT,10,18,10.1109/JIOT.2023.3267112 ,IEEE Journals ,,"The development of Internet of Things (IoT) makes human life more intelligent, and the interconnection of all things has become a reality. However, the surge in the number of devices and centralized management brings severe challenges to IoT, such as single point of failure, poor security, privacy leakage, and low reliability. Due to the decentralization, verifiability, and privacy protection of blockchain federated learning (BFL), some BFL schemes have been proposed to solve these problems, but bring new challenges, such as device privacy leakage and heavy security computing load. In this article, we propose a new decentralized, secure and verifiable consortium BFL privacy protection scheme, named LPBFL, which realizes lightweight computing while ensuring the privacy of the local model and data set of the device. To achieve lightweight privacy protection, LPBFL adopts the Paillier encryption and the newly designed lightweight digital signature and batch verification algorithm. Additionally, considering that devices upload invalid or even toxic local models intentionally or unintentionally, we design a device reputation selection mechanism to make BFL more efficient. Finally, the theoretical analysis proves the security of LPBFL and verifies the unforgeability of the proposed digital signature. Comprehensive comparisons and extensive experiments demonstrate that our LPBFL has significant advantages in multiple aspects.",2327-4662,,,16048-16060,IEEE , ,Privacy;Internet of Things;Computational modeling;Security;Blockchains;Training;Differential privacy,,
4771,"Title:An Exploratory Analysis of Delhi Air Quality Using Statistics and Machine Learning Models

 Air pollution is one of the most significant concerns of the present era, which has severe and alarming effects on human health and the environment, thereby escalating the climate change issue. Hence, in-depth analysis of air pollution data and accurate air quality forecasting is crucial in controlling the growing pollution levels. It also aids in designing appropriate policies to prevent exposure to toxic pollutants and taking necessary precautionary measures. Air quality in Delhi, the capital of India, is inferior compared to other major cities in the world. In this study, daily and hourly concentrations of air pollutants in the Delhi region were collected and analyzed using various methods. A comparative analysis is performed based on months, seasons, and the topography of different stations. The effect of the Covid-19 lockdown on the reduction of pollutant levels is also studied. A correlation analysis is performed on the available data to show the relationships and dependencies among different pollutants, their relationship with weather parameters, and the correlations between the stations. Various machine learning models were used for air quality forecasting, like Linear Regression, Vector Auto Regression, Gradient Boosting Machine, Random Forest, and Decision Tree Regression. The performance of these models was compared using RMSE, MAE, and MAPE metrics. This study is focused on the dire state of air pollution in Delhi, the primary reasons behind it, and the efficacy of calculated lockdowns in bringing down pollution levels. It also highlights the potential of Linear Regression and Decision Tree Regression models in predicting the air quality for different time intervals.",A. Chakravarty; S. S. S; S. S,,,An Exploratory Analysis of Delhi Air Quality Using Statistics and Machine Learning Models,,,10.1109/IATMSI56455.2022.10119423 ,IEEE Conferences ,,"Air pollution is one of the most significant concerns of the present era, which has severe and alarming effects on human health and the environment, thereby escalating the climate change issue. Hence, in-depth analysis of air pollution data and accurate air quality forecasting is crucial in controlling the growing pollution levels. It also aids in designing appropriate policies to prevent exposure to toxic pollutants and taking necessary precautionary measures. Air quality in Delhi, the capital of India, is inferior compared to other major cities in the world. In this study, daily and hourly concentrations of air pollutants in the Delhi region were collected and analyzed using various methods. A comparative analysis is performed based on months, seasons, and the topography of different stations. The effect of the Covid-19 lockdown on the reduction of pollutant levels is also studied. A correlation analysis is performed on the available data to show the relationships and dependencies among different pollutants, their relationship with weather parameters, and the correlations between the stations. Various machine learning models were used for air quality forecasting, like Linear Regression, Vector Auto Regression, Gradient Boosting Machine, Random Forest, and Decision Tree Regression. The performance of these models was compared using RMSE, MAE, and MAPE metrics. This study is focused on the dire state of air pollution in Delhi, the primary reasons behind it, and the efficacy of calculated lockdowns in bringing down pollution levels. It also highlights the potential of Linear Regression and Decision Tree Regression models in predicting the air quality for different time intervals.",,,978-1-6654-7719-2,1-6,IEEE , ,Correlation;Atmospheric measurements;Atmospheric modeling;Linear regression;Urban areas;Predictive models;Air pollution,,
4772,"Title:Classification of Organic and Recyclable Waste for Sustainable Development using Resnet50 Model

 With a sharp rise in population, there are several issues related to landfills. These emit potentially toxic vapors that are bad for human health. The primary problem is the collection, handling, and classification of home solid waste. Studies show that in America, approximately 75% of garbage can be recycled, but because there isn’t a comprehensive real-time waste-segregating system in place, only 30% of waste is now recycled. We require a clever waste management and classification system if we are to preserve a clean and green environment. To tackle this highlighted issue, this paper proposes a model which can give us the better accuracy and help us in an efficient way. The major focus has been on organic waste and recycling waste. In this paper, we contrast models like CNN, ResNet50 and VGG16. Our tests demonstrate that the ResNet50 model outperforms the others.",J. Bhadra; A. Lawrence DLima,,,Classification of Organic and Recyclable Waste for Sustainable Development using Resnet50 Model,,,10.1109/ICAECIS58353.2023.10170501 ,IEEE Conferences ,,"With a sharp rise in population, there are several issues related to landfills. These emit potentially toxic vapors that are bad for human health. The primary problem is the collection, handling, and classification of home solid waste. Studies show that in America, approximately 75% of garbage can be recycled, but because there isn’t a comprehensive real-time waste-segregating system in place, only 30% of waste is now recycled. We require a clever waste management and classification system if we are to preserve a clean and green environment. To tackle this highlighted issue, this paper proposes a model which can give us the better accuracy and help us in an efficient way. The major focus has been on organic waste and recycling waste. In this paper, we contrast models like CNN, ResNet50 and VGG16. Our tests demonstrate that the ResNet50 model outperforms the others.",,,979-8-3503-4805-7,78-83,IEEE , ,Waste management;Waste materials;Sociology;Real-time systems;Telecommunication computing;Recycling;Internet,,
4773,"Title:Bespoke Approximation of Multiplication-Accumulation and Activation Targeting Printed Multilayer Perceptrons

 Printed Electronics (PE) feature distinct and remarkable characteristics that make them a prominent technology for achieving true ubiquitous computing. This is particularly relevant in application domains that require conformal and ultra-low cost solutions, which have experienced limited penetration of computing until now. Unlike silicon-based technologies, PE offer unparalleled features such as non-recurring engineering costs, ultra-low manufacturing cost, and on-demand fabrication of conformal, flexible, non-toxic, and stretchable hardware. However, PE face certain limitations due to their large feature sizes, that impede the realization of complex circuits, such as machine learning classifiers. In this work, we address these limitations by leveraging the principles of Approximate Computing and Bespoke (fully-customized) design. We propose an automated framework for designing ultra-low power Multilayer Perceptron (MLP) classifiers which employs, for the first time, a holistic approach to approximate all functions of the MLP's neurons: multiplication, accumulation, and activation. Through comprehensive evaluation across various MLPs of varying size, our framework demonstrates the ability to enable battery-powered operation of even the most intricate MLP architecture examined, significantly surpassing the current state of the art.",F. Afentaki; G. Saglam; A. Kokkinis; K. Siozios; G. Zervakis; M. B. Tahoori,,,Bespoke Approximation of Multiplication-Accumulation and Activation Targeting Printed Multilayer Perceptrons,,,10.1109/ICCAD57390.2023.10323613 ,IEEE Conferences ,,"Printed Electronics (PE) feature distinct and remarkable characteristics that make them a prominent technology for achieving true ubiquitous computing. This is particularly relevant in application domains that require conformal and ultra-low cost solutions, which have experienced limited penetration of computing until now. Unlike silicon-based technologies, PE offer unparalleled features such as non-recurring engineering costs, ultra-low manufacturing cost, and on-demand fabrication of conformal, flexible, non-toxic, and stretchable hardware. However, PE face certain limitations due to their large feature sizes, that impede the realization of complex circuits, such as machine learning classifiers. In this work, we address these limitations by leveraging the principles of Approximate Computing and Bespoke (fully-customized) design. We propose an automated framework for designing ultra-low power Multilayer Perceptron (MLP) classifiers which employs, for the first time, a holistic approach to approximate all functions of the MLP's neurons: multiplication, accumulation, and activation. Through comprehensive evaluation across various MLPs of varying size, our framework demonstrates the ability to enable battery-powered operation of even the most intricate MLP architecture examined, significantly surpassing the current state of the art.",1558-2434,,979-8-3503-2225-5,1-9,IEEE , ,Fabrication;Costs;Neurons;Medical services;Machine learning;Multilayer perceptrons;Ubiquitous computing,,
4774,"Title:Classification of Abusive Comments in Social Media using Deep Learning

 Social media has provided everyone to express views and communicate to masses, but it also becomes a place for hateful behavior, abusive language, cyber-bullying and personal attacks. However, determining comment or a post is abusive or not is still difficult and time consuming, most of the social media platforms still searching for more efficient ways for efficient moderate solution. Automating this will help in identifying abusive comments, and save the websites and increase user safety and improve discussions online. In this paper, Kaggle’s toxic comment dataset is used to train deep learning model and classifying the comments in following categories: toxic, severe toxic, obscene, threat, insult, and identity hate. The dataset is trained with various deep learning techniques and analyze which deep learning model is better in the comment classification. The deep learning techniques such as long short term memory cell (LSTM) with and without word GloVe embeddings, a Convolution neural network (CNN) with or without GloVe are used, and GloVe pretrained model is used for classification",M. Anand; R. Eswari,,,Classification of Abusive Comments in Social Media using Deep Learning,,,10.1109/ICCMC.2019.8819734 ,IEEE Conferences ,,"Social media has provided everyone to express views and communicate to masses, but it also becomes a place for hateful behavior, abusive language, cyber-bullying and personal attacks. However, determining comment or a post is abusive or not is still difficult and time consuming, most of the social media platforms still searching for more efficient ways for efficient moderate solution. Automating this will help in identifying abusive comments, and save the websites and increase user safety and improve discussions online. In this paper, Kaggle’s toxic comment dataset is used to train deep learning model and classifying the comments in following categories: toxic, severe toxic, obscene, threat, insult, and identity hate. The dataset is trained with various deep learning techniques and analyze which deep learning model is better in the comment classification. The deep learning techniques such as long short term memory cell (LSTM) with and without word GloVe embeddings, a Convolution neural network (CNN) with or without GloVe are used, and GloVe pretrained model is used for classification",,,978-1-5386-7808-4,974-977,IEEE , ,Testing;Training;Social networking (online);Deep learning;Convolution,,
4775,"Title:Mushroom Classification by Physical Characteristics by Technique of k-Nearest Neighbor

 This paper proposed the principles of data analysis in order to present the prototype of mushroom classification based on physical characteristics. We created a model of mushroom classification by using Machine Learning (ML) with the mushroom dataset, comprising a total of 800 samples from the physical data of 22 attributes and it divide into two class as a toxic and non-toxic. The investigators designed the experiment in which 200 samples were randomly assigned to the mushroom population, consisting of 200 equally toxic and nontoxic mushrooms. For the quality, many ML were comparison such as Naive Bayes Updateable, Naive Bayes, SGD Text, LWL and K-Nearest Neighbor (k-NN). The results showed that K-NN gave the highest classification accuracy rate of100%.",N. Chumuang; K. Sukkanchana; M. Ketcham; W. Yimyam; J. Chalermdit; N. Wittayakhom; P. Pramkeaw,,,Mushroom Classification by Physical Characteristics by Technique of k-Nearest Neighbor,,,10.1109/iSAI-NLP51646.2020.9376820 ,IEEE Conferences ,,"This paper proposed the principles of data analysis in order to present the prototype of mushroom classification based on physical characteristics. We created a model of mushroom classification by using Machine Learning (ML) with the mushroom dataset, comprising a total of 800 samples from the physical data of 22 attributes and it divide into two class as a toxic and non-toxic. The investigators designed the experiment in which 200 samples were randomly assigned to the mushroom population, consisting of 200 equally toxic and nontoxic mushrooms. For the quality, many ML were comparison such as Naive Bayes Updateable, Naive Bayes, SGD Text, LWL and K-Nearest Neighbor (k-NN). The results showed that K-NN gave the highest classification accuracy rate of100%.",,,978-1-6654-1554-5,1-6,IEEE , ,Training;Sociology;Prototypes;Tools;Statistics;Standards;Testing,,
4776,"Title:Abusive Language Detection on Social Media using Bidirectional Long-Short Term Memory

 Social media has allowed anybody to share their opinions and engage with the general public, but it has also become a platform for harsh language, cruel conduct, personal assaults, and cyberbullying. However, determining whether a comment or a post is violent or not remains difficult and time-consuming, and most social media businesses are always seeking better ways to do so. This may be automated to assist in detecting nasty comments, promote user safety, preserve websites, and enhance online dialogue. The toxic comment dataset is utilized in this research to train a deep learning model that categorizes comments into the following categories: severe toxic, toxic, threat, obscene, insult, and identity hatred. To categorize comments, use a bidirectional long short-term memory cell (Bi-LSTM).",A. Salehgohari; M. Mirhosseini; H. Tabrizchi; A. V. Koczy,,,Abusive Language Detection on Social Media using Bidirectional Long-Short Term Memory,,,10.1109/INES56734.2022.9922628 ,IEEE Conferences ,,"Social media has allowed anybody to share their opinions and engage with the general public, but it has also become a platform for harsh language, cruel conduct, personal assaults, and cyberbullying. However, determining whether a comment or a post is violent or not remains difficult and time-consuming, and most social media businesses are always seeking better ways to do so. This may be automated to assist in detecting nasty comments, promote user safety, preserve websites, and enhance online dialogue. The toxic comment dataset is utilized in this research to train a deep learning model that categorizes comments into the following categories: severe toxic, toxic, threat, obscene, insult, and identity hatred. To categorize comments, use a bidirectional long short-term memory cell (Bi-LSTM).",1543-9259,,978-1-6654-9209-6,000243-000248,IEEE , ,Deep learning;Training;Toxicology;Text categorization;Neural networks;Cyberbullying;Data models,,
4777,"Title:Comparison of Deep Learning Techniques for Semantic Classification of Ramps in Search and Rescue Arenas

 Search and rescue activities should be carried out in indoor environments, after disasters such as earthquakes, floods, fire, and toxic substance spread. Since these activities are dangerous for humans and animals, the studies that address employing robots to the activities have been increased in recent years. However, robots must have capabilities such as autonomous navigation and situation awareness to operate in dangerous search and rescue environments. The National Institute of Standards and Technology presents reference test arenas to measure mobile robots' autonomous navigation capability. The main motivation of this study is to compare PointNet, DGCNN, PointNet++, and PointCNN deep learning architectures for semantic classification of ramps that are placed in reference test arenas. Besides, the terrain and walls are considered since they carry essential information for navigation. To compare the architectures, the ESOGU RAMPS dataset was constructed and the architectures were trained and tested with the point cloud data that are situated in the dataset. The metric and visual test results were presented to analyze the positive and negative aspects of the architectures.",K. Turgut; B. Kaleci,,,Comparison of Deep Learning Techniques for Semantic Classification of Ramps in Search and Rescue Arenas,,,10.1109/ASYU50717.2020.9259851 ,IEEE Conferences ,,"Search and rescue activities should be carried out in indoor environments, after disasters such as earthquakes, floods, fire, and toxic substance spread. Since these activities are dangerous for humans and animals, the studies that address employing robots to the activities have been increased in recent years. However, robots must have capabilities such as autonomous navigation and situation awareness to operate in dangerous search and rescue environments. The National Institute of Standards and Technology presents reference test arenas to measure mobile robots' autonomous navigation capability. The main motivation of this study is to compare PointNet, DGCNN, PointNet++, and PointCNN deep learning architectures for semantic classification of ramps that are placed in reference test arenas. Besides, the terrain and walls are considered since they carry essential information for navigation. To compare the architectures, the ESOGU RAMPS dataset was constructed and the architectures were trained and tested with the point cloud data that are situated in the dataset. The metric and visual test results were presented to analyze the positive and negative aspects of the architectures.",,,978-1-7281-9136-2,1-6,IEEE , ,Robots;NIST;Deep learning;Three-dimensional displays;Standards;Semantics;Recurrent neural networks,,
4778,"Title:Semantic sentiment analysis based on a combination of CNN and LSTM model

 With the development of social media, there are more and more platforms for people to express their opinions and ideas openly, so there are more and more comments on the same thing and event from different angles on the Internet. Therefore, in order to clean up the internet environment, it is important to root out the source of toxic comments in each other’s anonymous web surfing. In this paper, we proposed a model which combines convolutional neural network (CNN) and long and short-term memory network (LSTM). We used a dataset from Kaggle Toxic comment challenge for model training and testing. Finally, the experimental results that ROC AUC is 0.98 which outperforms CNN and LSTM individually used as a classifier for the task.",W. Zhang; Y. Wu,,,Semantic sentiment analysis based on a combination of CNN and LSTM model,,,10.1109/MLKE55170.2022.00041 ,IEEE Conferences ,,"With the development of social media, there are more and more platforms for people to express their opinions and ideas openly, so there are more and more comments on the same thing and event from different angles on the Internet. Therefore, in order to clean up the internet environment, it is important to root out the source of toxic comments in each other’s anonymous web surfing. In this paper, we proposed a model which combines convolutional neural network (CNN) and long and short-term memory network (LSTM). We used a dataset from Kaggle Toxic comment challenge for model training and testing. Finally, the experimental results that ROC AUC is 0.98 which outperforms CNN and LSTM individually used as a classifier for the task.",,,978-1-6654-9567-7,177-180,IEEE , ,Training;Knowledge engineering;Analytical models;Sentiment analysis;Social networking (online);Semantics;Machine learning,,
4779,"Title:System observability and nonlinear parameter identification of nonylphenol biodegradation kinetics

 Addition of surfactants, detergents and emulsifiers has been successfully applied for cleanup of petroleum-contaminated sites. However, a certain group of widely used alkylphenolethoxylates (APEs) surfactants was recently banned in Europe because scientists discovered that APE breakdown products are estrogenic and highly toxic to aquatic organisms. Nonylphenol is one of the very toxic breakdown products. The process of nonylphenol biodegradation is very important to many scientists because of its potential effectiveness as a treatment tool for pollution. However, very little information is available on the biodegradation kinetics of nonylphenol. Kinetic information is necessary for predicting the fate of pollutants. We start with Monod's model for nonylphenol biodegradation which is based on a coupled system of nonlinear differential equations. We prove that the states of the system and the parameters of Monod's model are locally observable. This enables us to perform a meaningful parameter estimation analysis. By using nonlinear least-squares optimization, we obtain the biodegradation kinetics and verify physical feasibility on independent datasets.",V. Shah; A. Chaubal; R. R. Ramachandran; R. Ordonez; K. Jahan,,,System observability and nonlinear parameter identification of nonylphenol biodegradation kinetics,3,,10.1109/ISCAS.2003.1204946 ,IEEE Conferences ,,"Addition of surfactants, detergents and emulsifiers has been successfully applied for cleanup of petroleum-contaminated sites. However, a certain group of widely used alkylphenolethoxylates (APEs) surfactants was recently banned in Europe because scientists discovered that APE breakdown products are estrogenic and highly toxic to aquatic organisms. Nonylphenol is one of the very toxic breakdown products. The process of nonylphenol biodegradation is very important to many scientists because of its potential effectiveness as a treatment tool for pollution. However, very little information is available on the biodegradation kinetics of nonylphenol. Kinetic information is necessary for predicting the fate of pollutants. We start with Monod's model for nonylphenol biodegradation which is based on a coupled system of nonlinear differential equations. We prove that the states of the system and the parameters of Monod's model are locally observable. This enables us to perform a meaningful parameter estimation analysis. By using nonlinear least-squares optimization, we obtain the biodegradation kinetics and verify physical feasibility on independent datasets.",,,0-7803-7761-3,III-III,IEEE , ,Observability;Parameter estimation;Biodegradation;Kinetic theory;Electric breakdown;Pollution;Europe;Organisms;Couplings;Differential equations,,
4780,"Title:ScrapNet: An Efficient Approach to Trash Classification

 As people have become more aware of their actions and how they affect their surroundings, they have realized the dire state of the environment. As a result, the recycling movement has gained momentum as a measure to save it. Contemporarily, the recycling industry has not seen a major shift and the problems that existed decades earlier persist. Trash classification is at the core of these problems, because if you can’t classify it, obviously you can’t recycle it. Manual classification often leads to misclassification as humans classify or judge things based on their experiences, knowledge, and not just absolute facts. Additionally, if the waste to be sorted is toxic, being in direct contact may be physically harmful to the people involved. Until a solution is found for this problem, the recycling industry won’t be on par with the rise in recycling culture. Thus, this is the problem we have set out to solve; this paper proposes a Deep Learning model based on EfficientNet Architecture that can classify different kinds of trash with an accuracy high enough to make it a viable solution for the industry while using a comparatively lower number of parameters than existing methods. We achieved an accuracy of 98% on the TrashNet dataset, the standard data for Trash classification, and outperformed all existing models. Additionally, as no large dataset with a varied set of trash images was present, we created a new dataset of 8135 images by combining various datasets and standardized them, achieving a classification accuracy of 92.87% with EfficientNet B3.",A. Masand; S. Chauhan; M. Jangid; R. Kumar; S. Roy,,,ScrapNet: An Efficient Approach to Trash Classification,9,,10.1109/ACCESS.2021.3111230 ,IEEE Journals ,,"As people have become more aware of their actions and how they affect their surroundings, they have realized the dire state of the environment. As a result, the recycling movement has gained momentum as a measure to save it. Contemporarily, the recycling industry has not seen a major shift and the problems that existed decades earlier persist. Trash classification is at the core of these problems, because if you can’t classify it, obviously you can’t recycle it. Manual classification often leads to misclassification as humans classify or judge things based on their experiences, knowledge, and not just absolute facts. Additionally, if the waste to be sorted is toxic, being in direct contact may be physically harmful to the people involved. Until a solution is found for this problem, the recycling industry won’t be on par with the rise in recycling culture. Thus, this is the problem we have set out to solve; this paper proposes a Deep Learning model based on EfficientNet Architecture that can classify different kinds of trash with an accuracy high enough to make it a viable solution for the industry while using a comparatively lower number of parameters than existing methods. We achieved an accuracy of 98% on the TrashNet dataset, the standard data for Trash classification, and outperformed all existing models. Additionally, as no large dataset with a varied set of trash images was present, we created a new dataset of 8135 images by combining various datasets and standardized them, achieving a classification accuracy of 92.87% with EfficientNet B3.",2169-3536,,,130947-130958,IEEE , ,Recycling;Deep learning;Plastics;Industries;Waste management;Glass;Feature extraction,,
4781,"Title:Computational prediction of toxicity

 As the number of new chemicals developed and being used keep adding every year, having the toxic profiles of each chemical becomes a daunting challenge. To meet this information gap, EPA suggested that certain in vitro assays and computational methods, which predict toxicity related information in much lesser time and cost than traditional in vivo methods, may be used. In this paper, we use computational techniques to use results from certain in vitro assays applied on 309 chemicals (whose toxicity profile is readily available) along with the molecular descriptors and other computed physical-chemical properties of the chemicals to predict the toxicity caused by chemical at a particular endpoint. The dataset is available from EPA TOXCAST group online. We show that Random Forest and Naïve Bayes have a good performance on this dataset. We also show that using small and related trees in random forest help to further improve the performance.",M. Mishra; H. Fei; J. Huan,,,Computational prediction of toxicity,,,10.1109/BIBM.2010.5706653 ,IEEE Conferences ,,"As the number of new chemicals developed and being used keep adding every year, having the toxic profiles of each chemical becomes a daunting challenge. To meet this information gap, EPA suggested that certain in vitro assays and computational methods, which predict toxicity related information in much lesser time and cost than traditional in vivo methods, may be used. In this paper, we use computational techniques to use results from certain in vitro assays applied on 309 chemicals (whose toxicity profile is readily available) along with the molecular descriptors and other computed physical-chemical properties of the chemicals to predict the toxicity caused by chemical at a particular endpoint. The dataset is available from EPA TOXCAST group online. We show that Random Forest and Naïve Bayes have a good performance on this dataset. We also show that using small and related trees in random forest help to further improve the performance.",,,978-1-4244-8307-5,686-691,IEEE , ,Chemicals;Accuracy;Classification algorithms;In vitro;Prediction algorithms;In vivo;Boosting,,
4782,"Title:Multi-label Bengali Abusive Comments Classification using Problem Transformation Method

 Sentiment analysis on the Bengali language is limited to binary and multi-class classifications. This paper focuses on the multi-label classification of the Bengali abusive social media comments dataset having 10220 rows of different social media negative comments using the problem transformation method. The texts are categorized into five labels: toxic, threat, obscene, insult, and racism. Three different multi-label approaches: Binary Relevance, Label Powerset, and Classifier Chain combined with three popular machine learning algorithms: Multinomial Naive Bayes, Random Forest, and Logistic Regression are implemented in this research. This study evaluates the performance of these models by applying them to various classification scenarios, considering five-label, four-label, three-label, and two-label classifications independently. Our research outcomes are evaluated with some performance indicators: Accuracy, Precision, Recall, F1-Scores, Confusion matrix, Macro-average, and Hamming score. The combination of Label Powerset and Logistic Regression outperformed the other two classifier-model combinations because of their quick adaptation to the dataset with an accuracy of 88.07% for five label classifications, 90.12% for four label classifications, 90.56% considering three label classifications and 92.67% for two label classification individually. With 88.07% accuracy, the Label Powerset with Logistic Regression approach can be applied to classify five types of sentiment in a single text.",T. T. Khan; A. Hassan; M. F. Ahamed; S. Islam,,,Multi-label Bengali Abusive Comments Classification using Problem Transformation Method,,,10.1109/CCE60043.2023.10332847 ,IEEE Conferences ,,"Sentiment analysis on the Bengali language is limited to binary and multi-class classifications. This paper focuses on the multi-label classification of the Bengali abusive social media comments dataset having 10220 rows of different social media negative comments using the problem transformation method. The texts are categorized into five labels: toxic, threat, obscene, insult, and racism. Three different multi-label approaches: Binary Relevance, Label Powerset, and Classifier Chain combined with three popular machine learning algorithms: Multinomial Naive Bayes, Random Forest, and Logistic Regression are implemented in this research. This study evaluates the performance of these models by applying them to various classification scenarios, considering five-label, four-label, three-label, and two-label classifications independently. Our research outcomes are evaluated with some performance indicators: Accuracy, Precision, Recall, F1-Scores, Confusion matrix, Macro-average, and Hamming score. The combination of Label Powerset and Logistic Regression outperformed the other two classifier-model combinations because of their quick adaptation to the dataset with an accuracy of 88.07% for five label classifications, 90.12% for four label classifications, 90.56% considering three label classifications and 92.67% for two label classification individually. With 88.07% accuracy, the Label Powerset with Logistic Regression approach can be applied to classify five types of sentiment in a single text.",2642-3766,,979-8-3503-0676-7,1-6,IEEE , ,Sentiment analysis;Logistic regression;Machine learning algorithms;Social networking (online);Electrical engineering computing;Feature extraction;Task analysis,,
4783,"Title:Forecasting the Emission of Greenhouse Gases from the Waste using SARIMA Model

 Every day the human population contributes to the generation of a huge amount of waste. The solid waste usually ends up in landfills which get decomposed and release toxic greenhouse gases into the environment. Greenhouse gases (GHG) are the major sources of global warming and climate change. Climate change is the greatest threat to both human health and society. In this study, the emission rate of GHGs from waste was prognosticated for India and China. Eight different machine learning models were utilized for prediction. Out of eight regression techniques employed, the SARIMA model performed the best for both datasets. The R2, MAPE, MAE, and RMSE obtained by the model with the India dataset were as follows 0.271, 2.418, 1.953, and 2.433. Similarly, for the China dataset, the R2, MAPE, MAE and RMSE values were −0.718, 8.455, 15.538, and 18.758.",V. Jayaraman; S. Parthasarathy; A. R. Lakshminarayanan,,,Forecasting the Emission of Greenhouse Gases from the Waste using SARIMA Model,,,10.1109/ICOEI53556.2022.9777119 ,IEEE Conferences ,,"Every day the human population contributes to the generation of a huge amount of waste. The solid waste usually ends up in landfills which get decomposed and release toxic greenhouse gases into the environment. Greenhouse gases (GHG) are the major sources of global warming and climate change. Climate change is the greatest threat to both human health and society. In this study, the emission rate of GHGs from waste was prognosticated for India and China. Eight different machine learning models were utilized for prediction. Out of eight regression techniques employed, the SARIMA model performed the best for both datasets. The R2, MAPE, MAE, and RMSE obtained by the model with the India dataset were as follows 0.271, 2.418, 1.953, and 2.433. Similarly, for the China dataset, the R2, MAPE, MAE and RMSE values were −0.718, 8.455, 15.538, and 18.758.",,,978-1-6654-8328-5,99-106,IEEE , ,Waste materials;Greenhouse effect;Sociology;Machine learning;Predictive models;Market research;Global warming;Climate change,,
4784,"Title:Mining Multi-Level Associations with Fuzzy Hierarchies

 In this paper we investigate application of fuzzy concept hierarchies to mining multi-level knowledge from large datasets via a well-known attribute-oriented induction approach (Han and Kamber, 2000). We analyze in detail the original process of fuzzy hierarchical induction and extend it with two new characteristics which improve applicability of the original approach to scientific data mining. These are a consistency of our fuzzy induction model, and an approximate drilling-down technique allowing a user to retrieve estimated explanations of the generated abstract concept. An application to discovery of multi-level association rules from environmental data stored in a toxic release inventory is presented",R. A. Angryk; F. E. Petry,,,Mining Multi-Level Associations with Fuzzy Hierarchies,,,10.1109/FUZZY.2005.1452494 ,IEEE Conferences ,,"In this paper we investigate application of fuzzy concept hierarchies to mining multi-level knowledge from large datasets via a well-known attribute-oriented induction approach (Han and Kamber, 2000). We analyze in detail the original process of fuzzy hierarchical induction and extend it with two new characteristics which improve applicability of the original approach to scientific data mining. These are a consistency of our fuzzy induction model, and an approximate drilling-down technique allowing a user to retrieve estimated explanations of the generated abstract concept. An application to discovery of multi-level association rules from environmental data stored in a toxic release inventory is presented",1098-7584,,0-7803-9159-4,785-790,IEEE , ,Data mining;Data analysis;Transaction databases;Information analysis;Computer science;Application software;Induction generators;Association rules;Global Positioning System;NASA,,
4785,"Title:K-Means Clustering Analysing Abrupt Changes in Air Quality

 The sum of air pollutants are identified in the existing capitals/towns of pronounced significance to help in preserving air quality, which is a vital issue for a good life, expressly in urban surroundings. Air Pollution has been reflected as one of the sternest ecological concerns. Air pollution upsets living body tissues and human organisms in adding to the atmosphere. IoT based air pollution observing comprises wireless sensor nodes mounted at different points of location, computer server as well database to pile the monitored data. The K-Means algorithm is one of the frequently used assembling means in data-mining for immense datasets. In the present article, the K-Means one of the ML clustering algorithms is used to analyze the frequent changes that occur in air pollution of Southampton city's data. The environment in the Air Quality Index (AQI) have pm2.5 value which is calculated then compared to determine the ups and downs in air pollution layer in a specific place before and after fire outbreak map into a set of five and three distinct qualitative pm2.5 classes which are required to analyze the quality of air at the city level. K-Means clustering algorithm's experimental outcomes showcase that the quick changes that occur in air quality from the lowermost level reach the highest toxic level of the same place due to the fire pollutant in just a few hours.",J. Shafi; A. Waheed,,,K-Means Clustering Analysing Abrupt Changes in Air Quality,,,10.1109/ICECA49313.2020.9297493 ,IEEE Conferences ,,"The sum of air pollutants are identified in the existing capitals/towns of pronounced significance to help in preserving air quality, which is a vital issue for a good life, expressly in urban surroundings. Air Pollution has been reflected as one of the sternest ecological concerns. Air pollution upsets living body tissues and human organisms in adding to the atmosphere. IoT based air pollution observing comprises wireless sensor nodes mounted at different points of location, computer server as well database to pile the monitored data. The K-Means algorithm is one of the frequently used assembling means in data-mining for immense datasets. In the present article, the K-Means one of the ML clustering algorithms is used to analyze the frequent changes that occur in air pollution of Southampton city's data. The environment in the Air Quality Index (AQI) have pm2.5 value which is calculated then compared to determine the ups and downs in air pollution layer in a specific place before and after fire outbreak map into a set of five and three distinct qualitative pm2.5 classes which are required to analyze the quality of air at the city level. K-Means clustering algorithm's experimental outcomes showcase that the quick changes that occur in air quality from the lowermost level reach the highest toxic level of the same place due to the fire pollutant in just a few hours.",,,978-1-7281-6387-1,26-30,IEEE , ,Clustering algorithms;Air pollution;Pollution;Monitoring;Data mining;Wireless sensor networks;Machine learning algorithms,,
4786,"Title:An Approach for Asbestos-related Pleural Plaque Detection

 Asbestos is a toxic ore widely used in construction and commercial products. Asbestos tends to dissolve into fibers and after years inhaling them, these fibers calcify and form plaques on the pleura. Despite being benign, pleural plaques may indicate an immunologic deficiency or dysfunctional lung areas. We propose a pipeline for asbestos-related pleural plaque detection in CT images of the human thorax based on the following operations: lung segmentation, 3D patch selection along the pleura, a convolutional neural network (CNN) for feature extraction, and classification by support vector machines (SVM). Due to the scarcity of publicly available and annotated datasets of pleural plaques, the proposed CNN relies on architecture learning with random weights obtained by a PCA-based approach instead of using traditional filter learning by backpropagation. Experiments show that the proposed CNN can outperform its counterparts based on backpropagation for small training sets.",A. M. Sousa; C. Castelo-Fernández; D. Osaku; E. Bagatin; F. Reis; A. X. Falcão,,,An Approach for Asbestos-related Pleural Plaque Detection,,,10.1109/EMBC44109.2020.9176605 ,IEEE Conferences ,,"Asbestos is a toxic ore widely used in construction and commercial products. Asbestos tends to dissolve into fibers and after years inhaling them, these fibers calcify and form plaques on the pleura. Despite being benign, pleural plaques may indicate an immunologic deficiency or dysfunctional lung areas. We propose a pipeline for asbestos-related pleural plaque detection in CT images of the human thorax based on the following operations: lung segmentation, 3D patch selection along the pleura, a convolutional neural network (CNN) for feature extraction, and classification by support vector machines (SVM). Due to the scarcity of publicly available and annotated datasets of pleural plaques, the proposed CNN relies on architecture learning with random weights obtained by a PCA-based approach instead of using traditional filter learning by backpropagation. Experiments show that the proposed CNN can outperform its counterparts based on backpropagation for small training sets.",2694-0604,,978-1-7281-1990-8,1343-1346,IEEE , ,Lung;Support vector machines;Training;Kernel;Computed tomography;Image segmentation;Three-dimensional displays,,
4787,"Title:Predictive modeling of nanomaterial biological effects

 Nanomaterial environmental impact (NEI) modeling is critical for industry and policymakers to assess the unintended biological effects (e.g. mortality, malformation, growth inhibition) resulting from the application of engineered nanomaterials. The scope of NEI modeling covers nanomaterial physical, chemical and manufacturing properties, exposure and study scenarios, environmental and ecosystem responses, biological responses, and their interactions. In this paper, we introduce a data mining approach to modeling the biological effects of nanomaterials. Data mining techniques can assist analysts in developing risk assessment models for nanomaterials. Using an experimental dataset on the toxicity of nanomaterials to embryonic zebrafish, we conducted case studies on modeling the overall effect/impact of nanomaterials and the specific toxic end-points such as mortality, delayed development, and morpholigcal malformations and behavioral abnormalities. The results show that different biological effects have different modeling accuracy given the same set of algorithms and data. The results also show that the weighting scheme for different biological effects has a significant influence on modeling the overall biological effect. These results provide insights into the understanding and modeling of nanomaterial biological effects.",X. Liu; K. Tang; S. Harper; B. Harper; J. A. Steevens; R. Xu,,,Predictive modeling of nanomaterial biological effects,,,10.1109/BIBMW.2012.6470254 ,IEEE Conferences ,,"Nanomaterial environmental impact (NEI) modeling is critical for industry and policymakers to assess the unintended biological effects (e.g. mortality, malformation, growth inhibition) resulting from the application of engineered nanomaterials. The scope of NEI modeling covers nanomaterial physical, chemical and manufacturing properties, exposure and study scenarios, environmental and ecosystem responses, biological responses, and their interactions. In this paper, we introduce a data mining approach to modeling the biological effects of nanomaterials. Data mining techniques can assist analysts in developing risk assessment models for nanomaterials. Using an experimental dataset on the toxicity of nanomaterials to embryonic zebrafish, we conducted case studies on modeling the overall effect/impact of nanomaterials and the specific toxic end-points such as mortality, delayed development, and morpholigcal malformations and behavioral abnormalities. The results show that different biological effects have different modeling accuracy given the same set of algorithms and data. The results also show that the weighting scheme for different biological effects has a significant influence on modeling the overall biological effect. These results provide insights into the understanding and modeling of nanomaterial biological effects.",,,978-1-4673-2747-3,859-863,IEEE , ,Data models;Nanomaterials;Predictive models;Biological system modeling;Measurement;Prediction algorithms,,
4788,"Title:An imaging method for automated detection of acrylamide in potato chips

 Neurotoxin substance acrylamide is commonly formed in starchy food stuffs like potato during deep frying. This is a problem especially for small manufacturers. Conventionally identification of acrylamide is done by chemical based LC-MS analysis which is destructive, expensive procedure and may need expert manpower. Automated and non-destructive detection of such toxic substances like acrylamide in food stuffs is of great significance. The proposed work presents non-destructive imaging system for objective estimation of acrylamide in potato chips, which can be processed by most current smartphones. To find out discrimination between healthy and acrylamide affected potato chips, the area of chip (ROI) is automatically segmented from input image followed by feature analysis for machine learning. Statistical features were extracted from different components of ROI segmented color chip images. Extracted prominent features were subjected to artificial intelligence classifier for classification of healthy and acrylamide affected potato chip samples. The proposed imaging system is tested on a comprehensive dataset consisting of 84 samples and achieved 99% area under curve which is encouraging.",A. Singh; M. Mishra; M. K. Dutta; R. Burget,,,An imaging method for automated detection of acrylamide in potato chips,,,10.1109/UPCON.2017.8251097 ,IEEE Conferences ,,"Neurotoxin substance acrylamide is commonly formed in starchy food stuffs like potato during deep frying. This is a problem especially for small manufacturers. Conventionally identification of acrylamide is done by chemical based LC-MS analysis which is destructive, expensive procedure and may need expert manpower. Automated and non-destructive detection of such toxic substances like acrylamide in food stuffs is of great significance. The proposed work presents non-destructive imaging system for objective estimation of acrylamide in potato chips, which can be processed by most current smartphones. To find out discrimination between healthy and acrylamide affected potato chips, the area of chip (ROI) is automatically segmented from input image followed by feature analysis for machine learning. Statistical features were extracted from different components of ROI segmented color chip images. Extracted prominent features were subjected to artificial intelligence classifier for classification of healthy and acrylamide affected potato chip samples. The proposed imaging system is tested on a comprehensive dataset consisting of 84 samples and achieved 99% area under curve which is encouraging.",,,978-1-5386-3004-4,487-490,IEEE , ,Image segmentation;Feature extraction;Imaging;Image color analysis;Artificial neural networks;Color,,
4789,"Title:Detection Welding Performance of Industrial Robot Using Machine Learning

 Automated welding robots have become an essential component in manufacturing industries due to their precision and increased productivity. Furthermore, they eliminate the need for human workers to be exposed to toxic fumes and bright light during welding processes, ensuring worker safety. However, any failure in welding robots can lead to poor product quality and impact a company's credibility. Therefore, it is critical to predict the welding performance of these machines to maintain product quality. This study proposes the use of spectrogram image classification to classify the quality of welding products. Using a TM-1400 WGIII welding robot, 180 welding datasets were collected to determine the conditions of the welding robot based on different welding wire lengths. Current and voltage signals of the welding robot were studied to identify suitable input parameters and machine learning algorithms were utilized to improve the accuracy of the predictive welding quality. The experiment resulted in an accuracy of 89% based on a 70% training sets and 30% testing sets of data, indicating that spectrogram image classification is an effective technique to monitor the condition of welding robots, improve welding quality, and increase product quality control. This method can be beneficial for both small- and large-scale industries such as automotive, energy, and construction.",O. Duongthipthewa; K. Meesublak; A. Takahashi; C. Mitsantisuk,,,Detection Welding Performance of Industrial Robot Using Machine Learning,,,10.1109/ITC-CSCC58803.2023.10212676 ,IEEE Conferences ,,"Automated welding robots have become an essential component in manufacturing industries due to their precision and increased productivity. Furthermore, they eliminate the need for human workers to be exposed to toxic fumes and bright light during welding processes, ensuring worker safety. However, any failure in welding robots can lead to poor product quality and impact a company's credibility. Therefore, it is critical to predict the welding performance of these machines to maintain product quality. This study proposes the use of spectrogram image classification to classify the quality of welding products. Using a TM-1400 WGIII welding robot, 180 welding datasets were collected to determine the conditions of the welding robot based on different welding wire lengths. Current and voltage signals of the welding robot were studied to identify suitable input parameters and machine learning algorithms were utilized to improve the accuracy of the predictive welding quality. The experiment resulted in an accuracy of 89% based on a 70% training sets and 30% testing sets of data, indicating that spectrogram image classification is an effective technique to monitor the condition of welding robots, improve welding quality, and increase product quality control. This method can be beneficial for both small- and large-scale industries such as automotive, energy, and construction.",,,979-8-3503-2641-3,1-6,IEEE , ,Training;Service robots;Welding;Wires;Product design;Quality assessment;Robots,,
4790,"Title:Adaptive resonance theory (ARTMAP) for Analysis and Prediction of Survival rate of Patient after Liver Transplantion

 In both industrialized and developing nations, chronic liver disease affects a significant number of individuals (CLD). Excessive drinking, exposure to toxic gases, and the eating of polluted food all contribute to a rise in the number of liver disease sufferers. Doctors have several challenges in treating patients with liver disease since it affects so many vital bodily systems. A liver transplant is a gruelling procedure with a high likelihood of complications after the procedure. The donor and recipient's compatibility is critical to the transplant's success. If a huge patient and donor database could be utilised to precisely match a donor recipient pair, the post-transplant mortality rate might be considerably reduced. Automated medical diagnostic systems often employ classification algorithms. Artificial neural networks (ANNs), a powerful technology, may aid in the discovery of patterns. It ranges from medicine to the arts that they work in. ANN-based dermatological tools and software may be useful in medicine, according to the conclusions of this study. It was used to analyse and study the Artificial Neural Networks, Radial Basis Function and ARTMAP. ILPD was obtained from the UCI machine learning library. It was possible to evaluate the outcomes using these several methods in order to determine if one method was more accurate than another in terms of precision, accuracy, mean absolute error, and other metrics (root MAE). The best method was found to be a multilayer perceptron (MLP) artificial neural network, which had a success rate of 98.9708 percent after a 10-fold cross validation. Other nations, such as the United States, have done more study on this area than India has. According to previous US dataset analyses, MLP was the best. Finally, we'll go through the procedure used to find out whether someone has Chronic Liver Disease. Long-term therapy for cancer may be predicted using artificial neural networks (ANN). With neural networks like ARTMAP, we want to develop a viable way for estimating patient survival following liver transplantation. Accuracy in ARTMAP calculations based on the evaluation of the degree of accuracy among the three models used in this study was found to be 58.2 percent.",G. Soni,,,Adaptive resonance theory (ARTMAP) for Analysis and Prediction of Survival rate of Patient after Liver Transplantion,,,10.1109/CONECCT55679.2022.9865752 ,IEEE Conferences ,,"In both industrialized and developing nations, chronic liver disease affects a significant number of individuals (CLD). Excessive drinking, exposure to toxic gases, and the eating of polluted food all contribute to a rise in the number of liver disease sufferers. Doctors have several challenges in treating patients with liver disease since it affects so many vital bodily systems. A liver transplant is a gruelling procedure with a high likelihood of complications after the procedure. The donor and recipient's compatibility is critical to the transplant's success. If a huge patient and donor database could be utilised to precisely match a donor recipient pair, the post-transplant mortality rate might be considerably reduced. Automated medical diagnostic systems often employ classification algorithms. Artificial neural networks (ANNs), a powerful technology, may aid in the discovery of patterns. It ranges from medicine to the arts that they work in. ANN-based dermatological tools and software may be useful in medicine, according to the conclusions of this study. It was used to analyse and study the Artificial Neural Networks, Radial Basis Function and ARTMAP. ILPD was obtained from the UCI machine learning library. It was possible to evaluate the outcomes using these several methods in order to determine if one method was more accurate than another in terms of precision, accuracy, mean absolute error, and other metrics (root MAE). The best method was found to be a multilayer perceptron (MLP) artificial neural network, which had a success rate of 98.9708 percent after a 10-fold cross validation. Other nations, such as the United States, have done more study on this area than India has. According to previous US dataset analyses, MLP was the best. Finally, we'll go through the procedure used to find out whether someone has Chronic Liver Disease. Long-term therapy for cancer may be predicted using artificial neural networks (ANN). With neural networks like ARTMAP, we want to develop a viable way for estimating patient survival following liver transplantation. Accuracy in ARTMAP calculations based on the evaluation of the degree of accuracy among the three models used in this study was found to be 58.2 percent.",2766-2101,,978-1-6654-9781-7,1-6,IEEE , ,Training;Liver diseases;Databases;Medical treatment;Artificial neural networks;Multilayer perceptrons;Software,,
4791,"Title:Epileptic Seizure Classification Using Adaptive Sine Cosine Algorithm-Whale Optimization Algorithm Optimized Learning Machine Model

 Epileptic seizure leads to the unconsciousness of the brain due to the lack of sleep, toxic consumption mainly. Now a days the death rate becomes high due to the negligence of the people who suffered from the seizure. The diagnosis of epileptic seizure at the early stage is essential. The manual diagnosis of detection and classification of seizure is difficult for radiologists. Several researchers have proposed automatic detection and classification of seizure, but somehow failed in detecting and classifying seizures related the computational time and accuracy. We are proposing a novel hybrid using Adaptive Sine cosine Algorithm-Whale Optimization Algorithm optimized Extreme Learning Machine (ASCA-WOA-ELM) model for classification of epileptic seizure. The hybrid ASCA-WOA technique is proposed to optimize the weights of the ELM model to improve the performance of the conventional ELM model. The EEG signals from University of Bonn dataset are considered for the research. First, the statistical features are extracted from the EEG signals using wavelet transform. The ASCA-WOA-ELM is fed with features for classification. The proposed ASCA-WOA method's uniqueness is shown by optimizing benchmark functions. The performance measure parameters such sensitivity, specificity and accuracy are evaluated from the proposed ASCA-WOA-ELM model. The ASCA-WOA-ELM model achieved 99.42% accuracy, 99.47% specificity, and 99.53% sensitivity. Further, the computational time of 21.2841 seconds achieved by the proposed ASCA-WOA-ELM model. The comparison results with other optimized models such as SCA-ELM, WOA-ELM, ASCA-ELM, WOA-ELM, along with the proposed ASCA-WOA-ELM model are presented",S. Panda; S. Mishra; M. N. Mohanty; S. Satapathy,,,Epileptic Seizure Classification Using Adaptive Sine Cosine Algorithm-Whale Optimization Algorithm Optimized Learning Machine Model,,,10.1109/APSIT58554.2023.10201747 ,IEEE Conferences ,,"Epileptic seizure leads to the unconsciousness of the brain due to the lack of sleep, toxic consumption mainly. Now a days the death rate becomes high due to the negligence of the people who suffered from the seizure. The diagnosis of epileptic seizure at the early stage is essential. The manual diagnosis of detection and classification of seizure is difficult for radiologists. Several researchers have proposed automatic detection and classification of seizure, but somehow failed in detecting and classifying seizures related the computational time and accuracy. We are proposing a novel hybrid using Adaptive Sine cosine Algorithm-Whale Optimization Algorithm optimized Extreme Learning Machine (ASCA-WOA-ELM) model for classification of epileptic seizure. The hybrid ASCA-WOA technique is proposed to optimize the weights of the ELM model to improve the performance of the conventional ELM model. The EEG signals from University of Bonn dataset are considered for the research. First, the statistical features are extracted from the EEG signals using wavelet transform. The ASCA-WOA-ELM is fed with features for classification. The proposed ASCA-WOA method's uniqueness is shown by optimizing benchmark functions. The performance measure parameters such sensitivity, specificity and accuracy are evaluated from the proposed ASCA-WOA-ELM model. The ASCA-WOA-ELM model achieved 99.42% accuracy, 99.47% specificity, and 99.53% sensitivity. Further, the computational time of 21.2841 seconds achieved by the proposed ASCA-WOA-ELM model. The comparison results with other optimized models such as SCA-ELM, WOA-ELM, ASCA-ELM, WOA-ELM, along with the proposed ASCA-WOA-ELM model are presented",,,979-8-3503-3936-9,1-5,IEEE , ,Wavelet transforms;Training;Adaptation models;Sensitivity;Machine learning algorithms;Computational modeling;Brain modeling,,
4792,"Title:Integration of cloud with AI to predict crop diseases

 In the meantime, technology is reaching every domain. In the software industry, Automobiles, Education, Sports, Cinema technology is molding as a backbone to solve problems quickly and effectively. Technology is even used in the medical field. In pandemic situations, online medication is playing a crucial role. Technology can even be used in the agriculture field to identify crop diseases, which is a major problem for farmers. Even it spoils the environment to a great extent. Due to these, farmers are suffering huge losses. There are many reasons for this like the usage of more pesticides as these are very toxic and dangerous. If the diseases are predicted before, then these crop diseases can be removed or killed at the starting stage without causing much crop damage. Some people like experts can determine the disease by looking at the crop, that is by seeing external symptoms. But farmers don't have the connection with the experts. Our project deals with overcoming this problem by using concepts of artificial intelligence and cloud computing. The project goal is to predict crop disease. Farmers can use this project to predict crop disease at an earlier stage and get steps to remove the disease. We will develop an android app and a website that takes the cropped photo as input. Farmers should upload the affected crop images in the app, so those experts will observe the symptoms and predict the diseases. Here, the project interacts with experts and gets the required solutions. In the absence of experts, an Artificial Intelligence model is trained with the algorithm. This AI model learns from the images uploaded and the expert's instructions to predict the output with more accuracy. Here the cloud is used to save images uploaded by users. AI models are subjected to a large number of datasets that contain disease data and predict the output. The output is then validated by experts to evaluate the correctness of the output.",K. Manikanta Vamsi; C. Abhinav Chandu; S. Santosh; S. Shitharth,,,Integration of cloud with AI to predict crop diseases,2021,,10.1049/icp.2022.0403 ,IET Conferences ,,"In the meantime, technology is reaching every domain. In the software industry, Automobiles, Education, Sports, Cinema technology is molding as a backbone to solve problems quickly and effectively. Technology is even used in the medical field. In pandemic situations, online medication is playing a crucial role. Technology can even be used in the agriculture field to identify crop diseases, which is a major problem for farmers. Even it spoils the environment to a great extent. Due to these, farmers are suffering huge losses. There are many reasons for this like the usage of more pesticides as these are very toxic and dangerous. If the diseases are predicted before, then these crop diseases can be removed or killed at the starting stage without causing much crop damage. Some people like experts can determine the disease by looking at the crop, that is by seeing external symptoms. But farmers don't have the connection with the experts. Our project deals with overcoming this problem by using concepts of artificial intelligence and cloud computing. The project goal is to predict crop disease. Farmers can use this project to predict crop disease at an earlier stage and get steps to remove the disease. We will develop an android app and a website that takes the cropped photo as input. Farmers should upload the affected crop images in the app, so those experts will observe the symptoms and predict the diseases. Here, the project interacts with experts and gets the required solutions. In the absence of experts, an Artificial Intelligence model is trained with the algorithm. This AI model learns from the images uploaded and the expert's instructions to predict the output with more accuracy. Here the cloud is used to save images uploaded by users. AI models are subjected to a large number of datasets that contain disease data and predict the output. The output is then validated by experts to evaluate the correctness of the output.",,,978-1-83953-658-8,285-289,IET , ,,,
4793,"Title:Water Quality Assessment in the Lam Pa Thao Dam, Chaiyaphum, Thailand with K-Means Clustering Algorithm

 Water resource management is one of the biggest challenges that are being faced, such as a warming climate, arid land, and toxic chemicals in the water. It is essential to deal with water resource management urgently. In this article, researchers mainly focus on monitoring the water quality in the Lam Pa Thao dam, Chaiyaphum, Thailand. The farmer in that area directly affected by the water quality in the dam because they raise fish in floating fish cages. To prevent losses from fish farming, they should have the ability to monitor and control the factors that affect the water quality. As a result, the farmer can monitor the water quality and the monitor system can report to the farmer in time. In this case, to monitor the water quality, researchers designed the buoys, which is the internet of things device, to collect data from the Lam Pa Thao dam. researchers collected the water quality data from January - March 2021, including 13,608 instances. The five important parameters were obtained, including dissolved oxygen, temperature, pH, total dissolved solids, and electric conductivity. Due to the number of parameters, researchers decided not to apply dimension reduction. In these experiments, researchers proposed using K-means clustering algorithms to group the water data into appropriate clusters. For the K-Means algorithm, we calculated the silhouette coefficient to analyze the effectiveness of cluster separation. The best cluster that was grouped using the K-means algorithm achieved the silhouette score of 0.6839. Furthermore, researchers evaluated the K-means algorithm on Charles river and Fitzroy river datasets. It obtained the silhouette score of 0.5489 and 0.6589, respectively.",P. Ardarsa; O. Surinta,,,"Water Quality Assessment in the Lam Pa Thao Dam, Chaiyaphum, Thailand with K-Means Clustering Algorithm",,,10.1109/RI2C51727.2021.9559811 ,IEEE Conferences ,,"Water resource management is one of the biggest challenges that are being faced, such as a warming climate, arid land, and toxic chemicals in the water. It is essential to deal with water resource management urgently. In this article, researchers mainly focus on monitoring the water quality in the Lam Pa Thao dam, Chaiyaphum, Thailand. The farmer in that area directly affected by the water quality in the dam because they raise fish in floating fish cages. To prevent losses from fish farming, they should have the ability to monitor and control the factors that affect the water quality. As a result, the farmer can monitor the water quality and the monitor system can report to the farmer in time. In this case, to monitor the water quality, researchers designed the buoys, which is the internet of things device, to collect data from the Lam Pa Thao dam. researchers collected the water quality data from January - March 2021, including 13,608 instances. The five important parameters were obtained, including dissolved oxygen, temperature, pH, total dissolved solids, and electric conductivity. Due to the number of parameters, researchers decided not to apply dimension reduction. In these experiments, researchers proposed using K-means clustering algorithms to group the water data into appropriate clusters. For the K-Means algorithm, we calculated the silhouette coefficient to analyze the effectiveness of cluster separation. The best cluster that was grouped using the K-means algorithm achieved the silhouette score of 0.6839. Furthermore, researchers evaluated the K-means algorithm on Charles river and Fitzroy river datasets. It obtained the silhouette score of 0.5489 and 0.6589, respectively.",,,978-1-6654-0300-9,35-39,IEEE , ,Temperature measurement;Temperature sensors;Technological innovation;Dams;Clustering algorithms;Water quality;Fish,,
4794,"Title:Visual Cues for Disrespectful Conversation Analysis

 Toxic, abusive, or disrespectful behavior analysis is a non-trivial problem previously addressed mostly from the language perspective. In this paper, we present a novel video dataset containing disrespect and non-disrespect labels, and introduce such behavior analysis by using visual cues. The dataset is collected from YouTube news show videos of two-party conversations, in which a host and a guest interact through teleconferencing. Each video is labeled by three trained raters to identify disrespect expressed through face and gesture, voice, and language. By resolving confounding factors, we generate the corresponding pairwise samples of non-disrespect. To particularly show the influence of visual cues in disrespectful interactions, we present 222 labeled clips (duration=974.41(s), mean duration=4.39(s)). We extract and analyze the facial action units (AVs) prevalent in disrespectful behavior. Our result shows statistically significant differences after Bonferroni correction for Inner Brow raise (AV01), Lip Corner Depressor (AV15), and Chin Raiser (AV17). For prediction, we build two classifiers using logistic regression and linear Support Vector Machine with 62.61 % and 61.48 % accuracy, respectively. For an in-depth analysis of overall face and gesture features, we conduct a qualitative analysis using theme extraction. Our qualitative analysis provides further insights on leveraging synchronous and asynchronous features, along with combining text and audio data with visual cues to better detect disrespect.",S. Samrose; W. Chu; C. He; Y. Gao; S. S. Shahrin; Z. Bai; M. E. Hoque,,,Visual Cues for Disrespectful Conversation Analysis,,,10.1109/ACII.2019.8925440 ,IEEE Conferences ,,"Toxic, abusive, or disrespectful behavior analysis is a non-trivial problem previously addressed mostly from the language perspective. In this paper, we present a novel video dataset containing disrespect and non-disrespect labels, and introduce such behavior analysis by using visual cues. The dataset is collected from YouTube news show videos of two-party conversations, in which a host and a guest interact through teleconferencing. Each video is labeled by three trained raters to identify disrespect expressed through face and gesture, voice, and language. By resolving confounding factors, we generate the corresponding pairwise samples of non-disrespect. To particularly show the influence of visual cues in disrespectful interactions, we present 222 labeled clips (duration=974.41(s), mean duration=4.39(s)). We extract and analyze the facial action units (AVs) prevalent in disrespectful behavior. Our result shows statistically significant differences after Bonferroni correction for Inner Brow raise (AV01), Lip Corner Depressor (AV15), and Chin Raiser (AV17). For prediction, we build two classifiers using logistic regression and linear Support Vector Machine with 62.61 % and 61.48 % accuracy, respectively. For an in-depth analysis of overall face and gesture features, we conduct a qualitative analysis using theme extraction. Our qualitative analysis provides further insights on leveraging synchronous and asynchronous features, along with combining text and audio data with visual cues to better detect disrespect.",2156-8111,,978-1-7281-3888-6,580-586,IEEE , ,Visualization;Face;YouTube;Feature extraction;Labeling;Teleconferencing;Standards,,
4795,"Title:HSDH: Detection of Hate Speech on social media with an effective deep neural network for code-mixed Hinglish data

 The phenomenal rise of social media platforms like Twitter, Facebook, Instagram, and Reddit has led to the blending of native languages or regional tongues with English for the purpose of improving communication in linguistically open geographic regions around the world. There are many ways in which Holocaust denial can lead to an increase in violence, from direct assault to purging out of compassion. Online, people are very hostile to one another. Distinguishing between language that incites hatred and language that is disparaging is a fundamental challenge in the categorization and tracking of extremely toxic lexical features. Our research focuses on identifying harmful tweets composed in Hinglish, a fusion of Hindi and the Roman alphabet. We propose a system in this paper for classifying tweets as either abusive, neutral, or offensive. The help of Hindi-English offensive tweet dataset is comprised of tweets written in the code-transferred language of Hindi and is further subdivided into three groups: neutral, abusive, and hateful. We studied the abusive and hate speech dataset with transfer learning and pre-trained the proposed model on Hinglish-processed English tweets. With our proposed model, we were able to improve accuracy to 98.54 percent.",R. Kumar Kaliyar; A. Goswami; U. Sharma; K. Kanojia; M. Agrawal,,,HSDH: Detection of Hate Speech on social media with an effective deep neural network for code-mixed Hinglish data,,,10.1109/ICCCNT56998.2023.10306709 ,IEEE Conferences ,,"The phenomenal rise of social media platforms like Twitter, Facebook, Instagram, and Reddit has led to the blending of native languages or regional tongues with English for the purpose of improving communication in linguistically open geographic regions around the world. There are many ways in which Holocaust denial can lead to an increase in violence, from direct assault to purging out of compassion. Online, people are very hostile to one another. Distinguishing between language that incites hatred and language that is disparaging is a fundamental challenge in the categorization and tracking of extremely toxic lexical features. Our research focuses on identifying harmful tweets composed in Hinglish, a fusion of Hindi and the Roman alphabet. We propose a system in this paper for classifying tweets as either abusive, neutral, or offensive. The help of Hindi-English offensive tweet dataset is comprised of tweets written in the code-transferred language of Hindi and is further subdivided into three groups: neutral, abusive, and hateful. We studied the abusive and hate speech dataset with transfer learning and pre-trained the proposed model on Hinglish-processed English tweets. With our proposed model, we were able to improve accuracy to 98.54 percent.",2473-7674,,979-8-3503-3509-5,1-6,IEEE , ,Social networking (online);Computational modeling;Hate speech;Transfer learning;Multimedia Web sites;Blogs;Artificial neural networks,,
4796,"Title:Liver Disease Prediction Model Using SVM and Logistic Regression

 Because of causes including excessive alcohol use, breathing toxic fumes, and ingesting tainted food, pickles, and medications, liver illnesses are growing more and more dangerous in many nations. To help alleviate the burden on doctors, liver patient datasets have been analyzed to develop classification models that can predict liver disease. A patient's liver is completely examined using machine learning algorithms to look for a chronic liver condition that lasts longer than six months. When a training dataset is provided, various classification strategies have been proposed to enhance classification performance. In this study, SVM and Logistic Regression are proposed as machine learning algorithms for identifying liver disease. Several performance measures were used to assess the performance of each model.",M. Shabbeer; M. Pravalika; K. G. Leena; M. Likhitha; K. Sheshikanth; R. Pitchai,,,Liver Disease Prediction Model Using SVM and Logistic Regression,,,10.1109/ICECAA58104.2023.10212203 ,IEEE Conferences ,,"Because of causes including excessive alcohol use, breathing toxic fumes, and ingesting tainted food, pickles, and medications, liver illnesses are growing more and more dangerous in many nations. To help alleviate the burden on doctors, liver patient datasets have been analyzed to develop classification models that can predict liver disease. A patient's liver is completely examined using machine learning algorithms to look for a chronic liver condition that lasts longer than six months. When a training dataset is provided, various classification strategies have been proposed to enhance classification performance. In this study, SVM and Logistic Regression are proposed as machine learning algorithms for identifying liver disease. Several performance measures were used to assess the performance of each model.",,,979-8-3503-4757-9,403-408,IEEE , ,Support vector machines;Training;Measurement;Logistic regression;Machine learning algorithms;Liver diseases;Medical services,,
4797,"Title:Detection of Brick Kilns Using Multi-Spectral Bands of Sentinel-2 Imagery

 The burning of bricks affects air quality and human health, and the toxic pollutants released into the air seriously impact the surrounding areas. In order to curb the pollution caused by these brick kilns, it is very important to identify them. As part of this study, an analysis in the Delhi- NCR region is performed. An approach for mapping brick kiln locations by using various Machine Learning (ML) algorithms is presented in this work. The Sentinel-2 imagery with 10m resolution was used to create four classes, namely, built up, field, water, and brick kiln. It is possible to distinguish brick kilns from other classes by using the said dataset due to its unique spectral and geometric features. Several ML classifiers have been trained on the sentinel-2 dataset, including the Random Forest Classifier and four built-in classifiers of Google Earth Engine, such as Smile Random Forest, Smile CART (Classification and Regression Trees), Smile Gradient Tree Boost, and Smile Naive Bayes Classifier. In order to train the model based on different classifiers, 70% of data points are used for training and 30% for validation purposes. Among the machine learning classifiers, Smile Random Forest achieved the maximum accuracy of 96.4%. As a result of this study, an ML model has been proposed for the classification of brick kilns from Sentinel-2 imagery, and a comparative analysis has been done between the various ML models. The proposed ML model can classify brick kilns from Sentinel-2 images with an accuracy of 96.4%, precision of 0.88, and recall of 0.73. The functionality of the classification model lies in its utilization by local authorities and various pollution control bodies, so that proper action can be initiated. Hence contributing to a greener environment and battling serious issues like climate change and global warming.",S. Imaduddin; Y. A. Khan; K. Mirza; B. K. Bhadra,,,Detection of Brick Kilns Using Multi-Spectral Bands of Sentinel-2 Imagery,,,10.1109/AISC56616.2023.10085085 ,IEEE Conferences ,,"The burning of bricks affects air quality and human health, and the toxic pollutants released into the air seriously impact the surrounding areas. In order to curb the pollution caused by these brick kilns, it is very important to identify them. As part of this study, an analysis in the Delhi- NCR region is performed. An approach for mapping brick kiln locations by using various Machine Learning (ML) algorithms is presented in this work. The Sentinel-2 imagery with 10m resolution was used to create four classes, namely, built up, field, water, and brick kiln. It is possible to distinguish brick kilns from other classes by using the said dataset due to its unique spectral and geometric features. Several ML classifiers have been trained on the sentinel-2 dataset, including the Random Forest Classifier and four built-in classifiers of Google Earth Engine, such as Smile Random Forest, Smile CART (Classification and Regression Trees), Smile Gradient Tree Boost, and Smile Naive Bayes Classifier. In order to train the model based on different classifiers, 70% of data points are used for training and 30% for validation purposes. Among the machine learning classifiers, Smile Random Forest achieved the maximum accuracy of 96.4%. As a result of this study, an ML model has been proposed for the classification of brick kilns from Sentinel-2 imagery, and a comparative analysis has been done between the various ML models. The proposed ML model can classify brick kilns from Sentinel-2 images with an accuracy of 96.4%, precision of 0.88, and recall of 0.73. The functionality of the classification model lies in its utilization by local authorities and various pollution control bodies, so that proper action can be initiated. Hence contributing to a greener environment and battling serious issues like climate change and global warming.",,,979-8-3503-2230-9,496-503,IEEE , ,Earth;Training;Kilns;Analytical models;Machine learning algorithms;Pollution control;Sensors,,
4798,"Title:Cyberbullying Detection: An Ensemble Based Machine Learning Approach

 Research on cyberbullying detection is gaining increasing attention in recent years as both individual victims and societies are greatly affected by it. Moreover, ease of access to social media platforms such as Facebook, Instagram, Twitter, etc. has led to an exponential increase in the mistreatment of people in the form of hateful messages, bullying, sexism, racism, aggressive content, harassment, toxic comment etc. Thus there is an extensive need to identify, control and reduce the bullying contents spread over social media sites, which has motivated us to conduct this research to automate the detection process of offensive language or cyberbullying. Our main aim is to build single and double ensemble-based voting model to classify the contents into two groups: `offensive' or `non-offensive'. For this purpose, we have chosen four machine learning classifiers and three ensemble models with two different feature extraction techniques combined with various n-gram analysis on a dataset extracted from Twitter. In our work, Logistic Regression and Bagging ensemble model classifier have performed individually best in detecting cyberbullying which has been outperformed by our proposed SLE and DLE voting classifiers. Our proposed SLE and DLE models yield the best performance of 96% when TF-IDF (Unigram) feature extraction is applied with K-Fold cross-validation.",K. S. Alam; S. Bhowmik; P. R. K. Prosun,,,Cyberbullying Detection: An Ensemble Based Machine Learning Approach,,,10.1109/ICICV50876.2021.9388499 ,IEEE Conferences ,,"Research on cyberbullying detection is gaining increasing attention in recent years as both individual victims and societies are greatly affected by it. Moreover, ease of access to social media platforms such as Facebook, Instagram, Twitter, etc. has led to an exponential increase in the mistreatment of people in the form of hateful messages, bullying, sexism, racism, aggressive content, harassment, toxic comment etc. Thus there is an extensive need to identify, control and reduce the bullying contents spread over social media sites, which has motivated us to conduct this research to automate the detection process of offensive language or cyberbullying. Our main aim is to build single and double ensemble-based voting model to classify the contents into two groups: `offensive' or `non-offensive'. For this purpose, we have chosen four machine learning classifiers and three ensemble models with two different feature extraction techniques combined with various n-gram analysis on a dataset extracted from Twitter. In our work, Logistic Regression and Bagging ensemble model classifier have performed individually best in detecting cyberbullying which has been outperformed by our proposed SLE and DLE voting classifiers. Our proposed SLE and DLE models yield the best performance of 96% when TF-IDF (Unigram) feature extraction is applied with K-Fold cross-validation.",,,978-1-6654-1960-4,710-715,IEEE , ,Social networking (online);Blogs;Multimedia Web sites;Process control;Machine learning;Feature extraction;Logistics,,
4799,"Title:A Hidden Markov Model for 3D Catheter Tip Tracking With 2D X-ray Catheterization Sequence and 3D Rotational Angiography

 In minimal invasive image guided catheterization procedures, physicians require information of the catheter position with respect to the patient's vasculature. However, in fluoroscopic images, visualization of the vasculature requires toxic contrast agent. Static vasculature roadmapping, which can reduce the usage of iodine contrast, is hampered by the breathing motion in abdominal catheterization. In this paper, we propose a method to track the catheter tip inside the patient's 3D vessel tree using intra-operative single-plane 2D X-ray image sequences and a peri-operative 3D rotational angiography (3DRA). The method is based on a hidden Markov model (HMM) where states of the model are the possible positions of the catheter tip inside the 3D vessel tree. The transitions from state to state model the probabilities for the catheter tip to move from one position to another. The HMM is updated following the observation scores, based on the registration between the 2D catheter centerline extracted from the 2D X-ray image, and the 2D projection of 3D vessel tree centerline extracted from the 3DRA. The method is extensively evaluated on simulated and clinical datasets acquired during liver abdominal catheterization. The evaluations show a median 3D tip tracking error of 2.3 mm with optimal settings in simulated data. The registered vessels close to the tip have a median distance error of 4.7 mm with angiographic data and optimal settings. Such accuracy is sufficient to help the physicians with an up-to-date roadmapping. The method tracks in real-time the catheter tip and enables roadmapping during catheterization procedures.",P. Ambrosini; I. Smal; D. Ruijters; W. J. Niessen; A. Moelker; T. Van Walsum,,,A Hidden Markov Model for 3D Catheter Tip Tracking With 2D X-ray Catheterization Sequence and 3D Rotational Angiography,36,3,10.1109/TMI.2016.2625811 ,IEEE Journals ,,"In minimal invasive image guided catheterization procedures, physicians require information of the catheter position with respect to the patient's vasculature. However, in fluoroscopic images, visualization of the vasculature requires toxic contrast agent. Static vasculature roadmapping, which can reduce the usage of iodine contrast, is hampered by the breathing motion in abdominal catheterization. In this paper, we propose a method to track the catheter tip inside the patient's 3D vessel tree using intra-operative single-plane 2D X-ray image sequences and a peri-operative 3D rotational angiography (3DRA). The method is based on a hidden Markov model (HMM) where states of the model are the possible positions of the catheter tip inside the 3D vessel tree. The transitions from state to state model the probabilities for the catheter tip to move from one position to another. The HMM is updated following the observation scores, based on the registration between the 2D catheter centerline extracted from the 2D X-ray image, and the 2D projection of 3D vessel tree centerline extracted from the 3DRA. The method is extensively evaluated on simulated and clinical datasets acquired during liver abdominal catheterization. The evaluations show a median 3D tip tracking error of 2.3 mm with optimal settings in simulated data. The registered vessels close to the tip have a median distance error of 4.7 mm with angiographic data and optimal settings. Such accuracy is sufficient to help the physicians with an up-to-date roadmapping. The method tracks in real-time the catheter tip and enables roadmapping during catheterization procedures.",1558-254X,,,757-768,IEEE , ,Three-dimensional displays;Catheters;Hidden Markov models;Two dimensional displays;X-ray imaging;Catheterization,,
4800,"Title:Performance Analysis of Machine Learning Algorithms for Prediction of Liver Disease

 Liver diseases like fatty liver disease, chronic active hepatitis, and cirrhosis are the major cause of mortality in India. Alcohol consumption, inhalation of harmful toxic gases, improper consumption of contaminated pickles, drugs, and foods are the major cause of diseases in the liver. Diagnosis of liver disease needs high accuracy and precise results for predicting whether a person is suffering from liver disease or not. Major disastrous repercussions can be the result of minor errors in the diagnosis of liver diseases. The major goal of this paper is for the detection of liver disease at right time and helping the doctors and combating the increasing number of cases. In this paper, we implemented various machine learning techniques like logistic regression, KNN, XG-Boost, SVM, Gaussian NB, Random forest, Decision tree, Gradient Boosting, CatBoost, AdaBoost, and LightGBM on selected features from the dataset for predicting liver disease and it was found that Random Forest performed best among all the technique and gained high accuracy and performed outstandingly in all metric evaluations.",V. Singh; M. K. Gourisaria; H. Das,,,Performance Analysis of Machine Learning Algorithms for Prediction of Liver Disease,,,10.1109/GUCON50781.2021.9573803 ,IEEE Conferences ,,"Liver diseases like fatty liver disease, chronic active hepatitis, and cirrhosis are the major cause of mortality in India. Alcohol consumption, inhalation of harmful toxic gases, improper consumption of contaminated pickles, drugs, and foods are the major cause of diseases in the liver. Diagnosis of liver disease needs high accuracy and precise results for predicting whether a person is suffering from liver disease or not. Major disastrous repercussions can be the result of minor errors in the diagnosis of liver diseases. The major goal of this paper is for the detection of liver disease at right time and helping the doctors and combating the increasing number of cases. In this paper, we implemented various machine learning techniques like logistic regression, KNN, XG-Boost, SVM, Gaussian NB, Random forest, Decision tree, Gradient Boosting, CatBoost, AdaBoost, and LightGBM on selected features from the dataset for predicting liver disease and it was found that Random Forest performed best among all the technique and gained high accuracy and performed outstandingly in all metric evaluations.",,,978-1-7281-9951-1,1-7,IEEE , ,Support vector machines;Measurement;Machine learning algorithms;Liver diseases;Medical services;Performance analysis;Random forests,,
4801,"Title:DRFD: Deep Learning-Based Real-time and Fast Detection of False Readings in AMI

 Smart meters, installed at customers’ apartments, frequently send their power consumption readings to the system operator in the advanced metering infrastructure (AMI) network. These readings are used for energy management, load estimation, and billing. Nonetheless, malicious customers, who aim to lower their bills illegally, launch electricity theft cyberattacks by breaching their meters and reporting lower readings. These reported false readings are toxic to the grid’s reliability and performance because they are used in energy management, and hence causing financial losses and inefficient use of resources. Existing solutions present in the literature aim at securing billing only because they are designed to detect false readings in real-time. Therefore, the SO may continue to make use of these false readings for energy management and load monitoring for a long time until the detection is done. In this paper, we propose real-time detection of false readings using deep learning. We first create malicious and benign datasets generated from a sliding window and use them to train different deep learning models. The best-performing model is then trained on various ratios of the false readings. In comparison with the existing daily and weekly electricity theft detection methodologies that require 144 and 1,008 readings, respectively, our detector can identify false readings after transmitting a few false readings (about 20).",M. J. Abdulaal; M. I. Ibrahem; M. Mahmoud; S. A. Bello; A. J. Aljohani; A. H. Milyani; A. M. Abusorrah,,,DRFD: Deep Learning-Based Real-time and Fast Detection of False Readings in AMI,,,10.1109/SoutheastCon48659.2022.9763963 ,IEEE Conferences ,,"Smart meters, installed at customers’ apartments, frequently send their power consumption readings to the system operator in the advanced metering infrastructure (AMI) network. These readings are used for energy management, load estimation, and billing. Nonetheless, malicious customers, who aim to lower their bills illegally, launch electricity theft cyberattacks by breaching their meters and reporting lower readings. These reported false readings are toxic to the grid’s reliability and performance because they are used in energy management, and hence causing financial losses and inefficient use of resources. Existing solutions present in the literature aim at securing billing only because they are designed to detect false readings in real-time. Therefore, the SO may continue to make use of these false readings for energy management and load monitoring for a long time until the detection is done. In this paper, we propose real-time detection of false readings using deep learning. We first create malicious and benign datasets generated from a sliding window and use them to train different deep learning models. The best-performing model is then trained on various ratios of the false readings. In comparison with the existing daily and weekly electricity theft detection methodologies that require 144 and 1,008 readings, respectively, our detector can identify false readings after transmitting a few false readings (about 20).",1558-058X,,978-1-6654-0652-9,682-689,IEEE , ,Deep learning;Load monitoring;Neural networks;Detectors;Real-time systems;Smart meters;Smart grids,,
4802,"Title:A Rank-Based Approach to Active Diagnosis

 The problem of active diagnosis arises in several applications such as disease diagnosis and fault diagnosis in computer networks, where the goal is to rapidly identify the binary states of a set of objects (e.g., faulty or working) by sequentially selecting, and observing, potentially noisy responses to binary valued queries. Previous work in this area chooses queries sequentially based on Information gain, and the object states are inferred by maximum a posteriori (MAP) estimation. In this work, rather than MAP estimation, we aim to rank objects according to their posterior fault probability. We propose a greedy algorithm to choose queries sequentially by maximizing the area under the ROC curve associated with the ranked list. The proposed algorithm overcomes limitations of existing work. When multiple faults may be present, the proposed algorithm does not rely on belief propagation, making it feasible for large scale networks with little loss in performance. When a single fault is present, the proposed algorithm can be implemented without knowledge of the underlying query noise distribution, making it robust to any misspecification of these noise parameters. We demonstrate the performance of the proposed algorithm through experiments on computer networks, a toxic chemical database, and synthetic datasets.",G. Bellala; J. Stanley; S. K. Bhavnani; C. Scott,,,A Rank-Based Approach to Active Diagnosis,35,9,10.1109/TPAMI.2013.30 ,IEEE Journals ,,"The problem of active diagnosis arises in several applications such as disease diagnosis and fault diagnosis in computer networks, where the goal is to rapidly identify the binary states of a set of objects (e.g., faulty or working) by sequentially selecting, and observing, potentially noisy responses to binary valued queries. Previous work in this area chooses queries sequentially based on Information gain, and the object states are inferred by maximum a posteriori (MAP) estimation. In this work, rather than MAP estimation, we aim to rank objects according to their posterior fault probability. We propose a greedy algorithm to choose queries sequentially by maximizing the area under the ROC curve associated with the ranked list. The proposed algorithm overcomes limitations of existing work. When multiple faults may be present, the proposed algorithm does not rely on belief propagation, making it feasible for large scale networks with little loss in performance. When a single fault is present, the proposed algorithm can be implemented without knowledge of the underlying query noise distribution, making it robust to any misspecification of these noise parameters. We demonstrate the performance of the proposed algorithm through experiments on computer networks, a toxic chemical database, and synthetic datasets.",1939-3539,,,2078-2090,IEEE , ,Noise;Approximation methods;Diseases;Entropy;Noise measurement;Fault diagnosis;Computer networks,,
4803,"Title:Water Pollution Monitoring and Decision Support System

 Water is a source of life and is regarded as the most essential element of natural resources. Freshwater management is one of the most important tasks since health risks may arise from the consumption of water contaminated with infectious agents and toxic chemicals. Water quality is determined by assessing three classes of parameters which are physical, chemical, and biological. In this study, these parameters are taken into account to predict the water quality and spread of water pollution. Various sample datasets from Kaggle and Goa State Pollution Control Board (GSPCB) are used and analyzed to determine the parameters which can be considered to predict water pollution. The proposed model consists of a system that uses technologies such as Internet of Things, Machine learning, Embedded Systems. The data collected from these sensors is sent to a web-based micro-controller for further processing. The processed data is stored in the database through a cloud platform and various machine learning algorithms are applied to the stored data for the prediction of water pollution. On comparison, k-Nearest Neighbors (kNN) showed better results with the least error. Further on, 1-Dimensional Saint-Venant equations are used to predict the dispersion of pollutants from the polluting source.",A. Dhumvad; S. Prabhu; S. F. Da’ Silva; S. Simu; P. Padiyar; V. Turkar; V. Salgaonkar,,,Water Pollution Monitoring and Decision Support System,,,10.1109/INCET54531.2022.9824110 ,IEEE Conferences ,,"Water is a source of life and is regarded as the most essential element of natural resources. Freshwater management is one of the most important tasks since health risks may arise from the consumption of water contaminated with infectious agents and toxic chemicals. Water quality is determined by assessing three classes of parameters which are physical, chemical, and biological. In this study, these parameters are taken into account to predict the water quality and spread of water pollution. Various sample datasets from Kaggle and Goa State Pollution Control Board (GSPCB) are used and analyzed to determine the parameters which can be considered to predict water pollution. The proposed model consists of a system that uses technologies such as Internet of Things, Machine learning, Embedded Systems. The data collected from these sensors is sent to a web-based micro-controller for further processing. The processed data is stored in the database through a cloud platform and various machine learning algorithms are applied to the stored data for the prediction of water pollution. On comparison, k-Nearest Neighbors (kNN) showed better results with the least error. Further on, 1-Dimensional Saint-Venant equations are used to predict the dispersion of pollutants from the polluting source.",,,978-1-6654-9499-1,1-6,IEEE , ,Machine learning algorithms;Microcontrollers;Software algorithms;Water quality;Predictive models;Prediction algorithms;Water pollution,,
4804,"Title:Dioxin soft measuring method in municipal solid waste incineration based on virtual sample generation

 Municipal solid waste incineration (MSWI) becomes the most popular technique to enhance environment protection. This process produces one of the most toxic chemicals in the world, i.e., polychlorinated dibenzo-p-dioxins and polychlorinated dibenzofurans (PCDD/Fs). The dioxin (DXN) production should be restricted rigidly by using operation optimization and control of MSWI process based on present industrial devices. However, it is difficult to realize the on-line real-time continuous measuring of DXN duo to the complexity formation mechanism and high-cost long-time off-line detection approach. In this paper, a soft measuring method based on virtual sample generation (VSG) is used to address this problem at the first time. A few numbers of true training samples are used to produce virtual training samples based on feasibility-based programming (FBP) model using selective ensemble kernel partial least squares (SENKPLS) and prior knowledge. Simulation result based on dataset in reference [31] for a HL MSWI process shows effectiveness of the proposed method.",J. Tang; J. Qiao; K. Gu; A. Yan,,,Dioxin soft measuring method in municipal solid waste incineration based on virtual sample generation,,,10.1109/CAC.2017.8244101 ,IEEE Conferences ,,"Municipal solid waste incineration (MSWI) becomes the most popular technique to enhance environment protection. This process produces one of the most toxic chemicals in the world, i.e., polychlorinated dibenzo-p-dioxins and polychlorinated dibenzofurans (PCDD/Fs). The dioxin (DXN) production should be restricted rigidly by using operation optimization and control of MSWI process based on present industrial devices. However, it is difficult to realize the on-line real-time continuous measuring of DXN duo to the complexity formation mechanism and high-cost long-time off-line detection approach. In this paper, a soft measuring method based on virtual sample generation (VSG) is used to address this problem at the first time. A few numbers of true training samples are used to produce virtual training samples based on feasibility-based programming (FBP) model using selective ensemble kernel partial least squares (SENKPLS) and prior knowledge. Simulation result based on dataset in reference [31] for a HL MSWI process shows effectiveness of the proposed method.",,,978-1-5386-3524-7,7323-7328,IEEE , ,Training;Kernel;Interpolation;Phase measurement;Solids;Incineration;Testing,,
4805,"Title:A Spatio-Temporal Mining Approach for Enhancing Satellite Data Availability: A Case Study on Blue Green Algae

 Satellite imagery provides geospatial data, generally terabytes in size. Due to their cost effectiveness and scalability, they are used in various large scale applications related to ecological monitoring. However, satellite data is prone to problems of data incompleteness owing to a number of issues such as cloud cover, fog, etc. In this paper, we conduct a detailed study on the 10 years of satellite data using Blue-Green Algae as a case study. Blue-Green Algae (BGA) are a toxic phytoplankton which are now a worldwide phenomena and a concern to various public authorities. We first illustrate the data incompleteness problem in our dataset with respect to BGA, and then formulate this problem using time-series spatio-temporal data mining approach that harnesses similarities among lakes with respect to BGA manifestation. We evaluate our approach through experimental studies from 99 lakes in the southeastern United States. Our experiment shows that our approach is an effective method to address data incompleteness in the BGA domain.",V. Boddula; L. Ramaswamy; D. Mishra,,,A Spatio-Temporal Mining Approach for Enhancing Satellite Data Availability: A Case Study on Blue Green Algae,,,10.1109/BigDataCongress.2017.37 ,IEEE Conferences ,,"Satellite imagery provides geospatial data, generally terabytes in size. Due to their cost effectiveness and scalability, they are used in various large scale applications related to ecological monitoring. However, satellite data is prone to problems of data incompleteness owing to a number of issues such as cloud cover, fog, etc. In this paper, we conduct a detailed study on the 10 years of satellite data using Blue-Green Algae as a case study. Blue-Green Algae (BGA) are a toxic phytoplankton which are now a worldwide phenomena and a concern to various public authorities. We first illustrate the data incompleteness problem in our dataset with respect to BGA, and then formulate this problem using time-series spatio-temporal data mining approach that harnesses similarities among lakes with respect to BGA manifestation. We evaluate our approach through experimental studies from 99 lakes in the southeastern United States. Our experiment shows that our approach is an effective method to address data incompleteness in the BGA domain.",,,978-1-5386-1996-4,216-223,IEEE , ,Satellites;Lakes;Monitoring;Clouds;Sensors;Algae;Data mining,,
4806,"Title:Impact of COVID-19 Lockdowns on Air Quality in Bangladesh: Analysis and AQI Forecasting with Support Vector Regression

 Over the past few decades, air pollution has emerged as a significant environmental hazard, causing premature deaths in Southeast Asia. The proliferation of industrialization and deforestation has resulted in an alarming increase in pollution levels. However, the COVID-19 pandemic has significantly reduced the amount of volatile organic compounds and toxic gases in the air due to the decrease in human activity caused by lockdowns and restrictions. This study aims to investigate the air quality in various geographical areas of Bangladesh, comparing the air quality index (AQI) during different lockdown periods to equivalent eight-year time spans in 10 of the country’s busiest cities. This study demonstrates a strong correlation between the rapid and widespread dispersion of COVID-19 and air pollution reduction in Bangladesh. In addition, we evaluated the performance of Support Vector Regression (SVR) in AQI forecasting using the time series dataset. The results can help improve machine learning and deep learning models for accurate AQI forecasting. This study contributes to developing effective policies and strategies for reducing air pollution in Bangladesh and other countries facing similar challenges.",M. T. Hossain; A. Hossain; S. M. Meem; M. F. Monir; M. S. Ullah Miah; T. Bin Sarwar,,,Impact of COVID-19 Lockdowns on Air Quality in Bangladesh: Analysis and AQI Forecasting with Support Vector Regression,,,10.1109/INCET57972.2023.10169997 ,IEEE Conferences ,,"Over the past few decades, air pollution has emerged as a significant environmental hazard, causing premature deaths in Southeast Asia. The proliferation of industrialization and deforestation has resulted in an alarming increase in pollution levels. However, the COVID-19 pandemic has significantly reduced the amount of volatile organic compounds and toxic gases in the air due to the decrease in human activity caused by lockdowns and restrictions. This study aims to investigate the air quality in various geographical areas of Bangladesh, comparing the air quality index (AQI) during different lockdown periods to equivalent eight-year time spans in 10 of the country’s busiest cities. This study demonstrates a strong correlation between the rapid and widespread dispersion of COVID-19 and air pollution reduction in Bangladesh. In addition, we evaluated the performance of Support Vector Regression (SVR) in AQI forecasting using the time series dataset. The results can help improve machine learning and deep learning models for accurate AQI forecasting. This study contributes to developing effective policies and strategies for reducing air pollution in Bangladesh and other countries facing similar challenges.",,,979-8-3503-3575-0,1-6,IEEE , ,COVID-19;Support vector machines;Deep learning;Volatile organic compounds;Atmospheric modeling;Urban areas;Predictive models,,
4807,"Title:Detecting Offensive Tamil Texts Using Machine Learning And Multilingual Transformer Models

 Nowadays, social media has permitted an exponential increase in the circulation of hostile and toxic content, which has resulted in an increase in the number of people exposed to it. Many members of the Natural Language Processing community have recently expressed an interest in automated identification of such harmful content as hate speech, provocative language, and abusive language as a means of addressing this problem. Machine learning and multilingual transformer models are used in this study to automatically identify Tamil language comments as either offensive or not offensive messages. The dataset is collected from YouTube and Kaggle. BERT tops the competition when it comes to offensive language identification models, with an accuracy of 82% compared to the others.",M. Subramanian; G. J. Adhithiya; S. Gowthamkrishnan; R. Deepti,,,Detecting Offensive Tamil Texts Using Machine Learning And Multilingual Transformer Models,,,10.1109/ICSTSN53084.2022.9761335 ,IEEE Conferences ,,"Nowadays, social media has permitted an exponential increase in the circulation of hostile and toxic content, which has resulted in an increase in the number of people exposed to it. Many members of the Natural Language Processing community have recently expressed an interest in automated identification of such harmful content as hate speech, provocative language, and abusive language as a means of addressing this problem. Machine learning and multilingual transformer models are used in this study to automatically identify Tamil language comments as either offensive or not offensive messages. The dataset is collected from YouTube and Kaggle. BERT tops the competition when it comes to offensive language identification models, with an accuracy of 82% compared to the others.",,,978-1-6654-2111-9,1-6,IEEE , ,Support vector machines;Video on demand;Social networking (online);Bit error rate;Text categorization;Machine learning;Transformers,,
4808,"Title:Short-Term AQI Forecasts using Machine/Deep Learning Models for San Francisco, CA

 The city of San Francisco, CA is highly susceptible to severe air pollutants and often experiences a poor Air Quality Index (AQI). Some primary pollutants include Carbon Dioxide (CO2), Carbon Monoxide (CO), Nitrogen Oxide (NOx), Particulate Matter (PM), and Sulphur Dioxide (SO2). This paper estimates short-term AQI indices for the city of San Francisco, CA. Ten years of historical AQI datasets were explored for trends, levels, cyclicity, and seasonality to predict for the next 7-day and 30-day window periods. Multiple Machine/Deep Learning models such as Random Forest (RF), Support Vector Regression (SVR), XGBoost (XGB), Neural Network (NN), and Long Short-Term Memory (LSTM) were deployed. The performance of these models are assessed using Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) metrics. The preliminary results indicate that the XGBoost outperforms over other models with MAE scores of 7.991 (7-day) and 8.126 (30-day), respectively. We also remind readers that for forecasting real-time AQIs, multiple factors such as smoke pollutants from wildfires, toxic spills from train derailments, and distributed energy resources (DERs) contributors such as electric vehicle, wind, and solar fleets must be taken into consideration for robust accuracy.",B. S. Chandar; P. Rajagopalan; P. Ranganathan,,,"Short-Term AQI Forecasts using Machine/Deep Learning Models for San Francisco, CA",,,10.1109/CCWC57344.2023.10099064 ,IEEE Conferences ,,"The city of San Francisco, CA is highly susceptible to severe air pollutants and often experiences a poor Air Quality Index (AQI). Some primary pollutants include Carbon Dioxide (CO2), Carbon Monoxide (CO), Nitrogen Oxide (NOx), Particulate Matter (PM), and Sulphur Dioxide (SO2). This paper estimates short-term AQI indices for the city of San Francisco, CA. Ten years of historical AQI datasets were explored for trends, levels, cyclicity, and seasonality to predict for the next 7-day and 30-day window periods. Multiple Machine/Deep Learning models such as Random Forest (RF), Support Vector Regression (SVR), XGBoost (XGB), Neural Network (NN), and Long Short-Term Memory (LSTM) were deployed. The performance of these models are assessed using Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) metrics. The preliminary results indicate that the XGBoost outperforms over other models with MAE scores of 7.991 (7-day) and 8.126 (30-day), respectively. We also remind readers that for forecasting real-time AQIs, multiple factors such as smoke pollutants from wildfires, toxic spills from train derailments, and distributed energy resources (DERs) contributors such as electric vehicle, wind, and solar fleets must be taken into consideration for robust accuracy.",,,979-8-3503-3286-5,0402-0411,IEEE , ,Degradation;Atmospheric modeling;Railway accidents;Urban areas;Fires;Predictive models;Air quality,,
4809,"Title:An Offensive Language Identification Based on Deep Semantic Feature Fusion

 Various forms of social interactions are often char-acterized by toxic or offensive words that can be collectively referred to as offensive languages, which has become a unique linguistic phenomenon in social media platforms. How to detect and identify these offensive languages in social media platforms has become one of the important research in the field of natural language processing. Existing methods utilize machine learning algorithms or text representation models based on deep learning to learn the features of offensive languages and identify them, which have achieved good performances. However, traditional machine learning-based methods mainly rely on keyword identi-fication and blocking, deep learning-based methods do not ade-quately explore the fused deep semantic features of the content by combining word-level embeddings and sentence-level deep semantic feature representations of sentences, which cannot ef-fectively identify offensive languages that do not contain common offensive words but indicate offensive meanings. In this research, we propose a novel offensive language identification model based on deep semantic feature fusion, which uses the pre-trained model Bert to obtain word-level embedding representations of offensive languages, and then integrates the RCNN that combines with the attention mechanism to extract the fused deep semantic feature representations of offensive languages, and label encoder and offensive predictor to improve the identification accuracy and generalization ability of the model so that the performances of the model do not rely on the offensive language lexicon entirely and can identify offensive languages that do not contain common offensive words but indicate offensive meanings. Experimental results on Wikipedia and Twitter comment datasets show that our proposed model can better understand the context and discover potential offensive meanings, and outperforms existing methods.",X. Li; Z. Zeng; M. Wu; Z. Huang; Y. Sha; L. Shi,,,An Offensive Language Identification Based on Deep Semantic Feature Fusion,,,10.1109/ICCC56324.2022.10066011 ,IEEE Conferences ,,"Various forms of social interactions are often char-acterized by toxic or offensive words that can be collectively referred to as offensive languages, which has become a unique linguistic phenomenon in social media platforms. How to detect and identify these offensive languages in social media platforms has become one of the important research in the field of natural language processing. Existing methods utilize machine learning algorithms or text representation models based on deep learning to learn the features of offensive languages and identify them, which have achieved good performances. However, traditional machine learning-based methods mainly rely on keyword identi-fication and blocking, deep learning-based methods do not ade-quately explore the fused deep semantic features of the content by combining word-level embeddings and sentence-level deep semantic feature representations of sentences, which cannot ef-fectively identify offensive languages that do not contain common offensive words but indicate offensive meanings. In this research, we propose a novel offensive language identification model based on deep semantic feature fusion, which uses the pre-trained model Bert to obtain word-level embedding representations of offensive languages, and then integrates the RCNN that combines with the attention mechanism to extract the fused deep semantic feature representations of offensive languages, and label encoder and offensive predictor to improve the identification accuracy and generalization ability of the model so that the performances of the model do not rely on the offensive language lexicon entirely and can identify offensive languages that do not contain common offensive words but indicate offensive meanings. Experimental results on Wikipedia and Twitter comment datasets show that our proposed model can better understand the context and discover potential offensive meanings, and outperforms existing methods.",,,978-1-6654-5051-5,1477-1483,IEEE , ,Learning systems;Social networking (online);Computational modeling;Semantics;Blogs;Encyclopedias;Predictive models,,
4810,"Title:Late and Early Blight Diseases Identification of Potatoes with a Light Weight Hybrid Transfer Learning Model

 Potatoes are one of the world’s most important commodities, and leaf maladies such as early and late blight can substantially reduce their yield and quality. Hence, both farmers and researchers must prioritize quick and precise illness diagnosis. In our research, we propose a strategy based on transfer learning for classifying toxic and diseased potato leaf tissue. We specifically used our dataset of potato leaf photos to fine-tune the Mobile-Net model, which was a pre-trained convolutional neural network. To enhance the model’s functionality, we also added a few more layers. Our study found that, in comparison to other state-of-the-art methods, our methodology outperformed them all by achieving a multi-class classification accuracy of 99%. Our method can be used to detect and monitor potato leaf maladies in real-world situations, which could eventually contribute to enhancing potato productivity and food security.",A. Z. Bin Siddique; S. Das; P. Tabassum; A. M. Tasir; S. Roy; M. S. Rahman; M. F. Mridha; A. Islam,,,Late and Early Blight Diseases Identification of Potatoes with a Light Weight Hybrid Transfer Learning Model,,,10.1109/AIIoT58121.2023.10174429 ,IEEE Conferences ,,"Potatoes are one of the world’s most important commodities, and leaf maladies such as early and late blight can substantially reduce their yield and quality. Hence, both farmers and researchers must prioritize quick and precise illness diagnosis. In our research, we propose a strategy based on transfer learning for classifying toxic and diseased potato leaf tissue. We specifically used our dataset of potato leaf photos to fine-tune the Mobile-Net model, which was a pre-trained convolutional neural network. To enhance the model’s functionality, we also added a few more layers. Our study found that, in comparison to other state-of-the-art methods, our methodology outperformed them all by achieving a multi-class classification accuracy of 99%. Our method can be used to detect and monitor potato leaf maladies in real-world situations, which could eventually contribute to enhancing potato productivity and food security.",,,979-8-3503-3761-7,0105-0111,IEEE , ,Productivity;Transfer learning;Training data;Food security;Predictive models;Data augmentation;Data models,,
4811,"Title:Multi-Class Stress Detection Through Heart Rate Variability: A Deep Neural Network Based Study

 Stress is a natural human reaction to demands or pressure, usually when perceived as harmful or/and toxic. When stress becomes constantly overwhelmed and prolonged, it increases the risk of mental health and physiological uneasiness. Furthermore, chronic stress raises the likelihood of mental health plagues such as anxiety, depression, and sleep disorder. Although measuring stress using physiological parameters such as heart rate variability (HRV) is a common approach, how to achieve ultra-high accuracy based on HRV measurements remains as a challenging task. HRV is not equivalent to heart rate. While heart rate is the average value of heartbeats per minute, HRV represents the variation of the time interval between successive heartbeats. The HRV measurements are related to the variance of RR intervals which stand for the time between successive R peaks. In this study, we investigate the role of HRV features as stress detection bio-markers and develop a machine learning-based model for multi-class stress detection. More specifically, a convolution neural network (CNN) based model is developed to detect multi-class stress, namely, no stress, interruption stress, and time pressure stress, based on both time- and frequency-domain features of HRV. Validated through a publicly available dataset, SWELL–KW, the achieved accuracy score of our model has reached 99.9% (Precision = 1, Recall = 1,  $F1-$  score = 1, and MCC = 0.99), thus outperforming the existing methods in the literature. In addition, this study demonstrates the effectiveness of essential HRV features for stress detection using a feature extraction technique, i.e., analysis of variance.",J. A. Mortensen; M. E. Mollov; A. Chatterjee; D. Ghose; F. Y. Li,,,Multi-Class Stress Detection Through Heart Rate Variability: A Deep Neural Network Based Study,11,,10.1109/ACCESS.2023.3274478 ,IEEE Journals ,,"Stress is a natural human reaction to demands or pressure, usually when perceived as harmful or/and toxic. When stress becomes constantly overwhelmed and prolonged, it increases the risk of mental health and physiological uneasiness. Furthermore, chronic stress raises the likelihood of mental health plagues such as anxiety, depression, and sleep disorder. Although measuring stress using physiological parameters such as heart rate variability (HRV) is a common approach, how to achieve ultra-high accuracy based on HRV measurements remains as a challenging task. HRV is not equivalent to heart rate. While heart rate is the average value of heartbeats per minute, HRV represents the variation of the time interval between successive heartbeats. The HRV measurements are related to the variance of RR intervals which stand for the time between successive R peaks. In this study, we investigate the role of HRV features as stress detection bio-markers and develop a machine learning-based model for multi-class stress detection. More specifically, a convolution neural network (CNN) based model is developed to detect multi-class stress, namely, no stress, interruption stress, and time pressure stress, based on both time- and frequency-domain features of HRV. Validated through a publicly available dataset, SWELL–KW, the achieved accuracy score of our model has reached 99.9% (Precision = 1, Recall = 1,  $F1-$  score = 1, and MCC = 0.99), thus outperforming the existing methods in the literature. In addition, this study demonstrates the effectiveness of essential HRV features for stress detection using a feature extraction technique, i.e., analysis of variance.",2169-3536,,,57470-57480,IEEE , ,Heart rate variability;Stress;Human factors;Feature extraction;Classification algorithms;Electrocardiography;Convolutional neural networks,,
4812,"Title:Toward a Machine Learning Approach to Predict the CO2 Rating of Fuel-Consuming Vehicles in Canada

 Global warming is becoming a major concern for almost all countries nowadays. Burning fossil fuels, most of which by vehicles is the main cause of increasing toxic CO2 in the air we breathe. Along with other factors, the emission of CO2 from vehicles in the environment plays a major role in raising the temperature worldwide. Infrared energy of sunlight by the earth’s surface is absorbed by CO2 and then re-emitted in all directions causing the greenhouse effect. So, it is very important to take necessary actions to identify high as well as low CO2 emitting vehicles. The main aim of this work is to predict the CO2 rating of the vehicle based on various key factors and identify the vehicle with CO2 emissions beyond the ideal range. For that purpose, the last five years (2017-2021) fuel consumption rating dataset of Canada which is publicly available has been collected and analyzed first. Then, eight machine learning techniques were applied to predict the CO2 rating based on the key features. From our investigation, we have found that the highest accuracy of 96% is achieved by the random forest algorithm. We hope that this work will contribute to the field of identifying and designing low CO2-emitting vehicles.",S. D. Bappon; A. Dey; S. M. Sabuj; A. Das,,,Toward a Machine Learning Approach to Predict the CO2 Rating of Fuel-Consuming Vehicles in Canada,,,10.1109/ICCIT57492.2022.10054732 ,IEEE Conferences ,,"Global warming is becoming a major concern for almost all countries nowadays. Burning fossil fuels, most of which by vehicles is the main cause of increasing toxic CO2 in the air we breathe. Along with other factors, the emission of CO2 from vehicles in the environment plays a major role in raising the temperature worldwide. Infrared energy of sunlight by the earth’s surface is absorbed by CO2 and then re-emitted in all directions causing the greenhouse effect. So, it is very important to take necessary actions to identify high as well as low CO2 emitting vehicles. The main aim of this work is to predict the CO2 rating of the vehicle based on various key factors and identify the vehicle with CO2 emissions beyond the ideal range. For that purpose, the last five years (2017-2021) fuel consumption rating dataset of Canada which is publicly available has been collected and analyzed first. Then, eight machine learning techniques were applied to predict the CO2 rating based on the key features. From our investigation, we have found that the highest accuracy of 96% is achieved by the random forest algorithm. We hope that this work will contribute to the field of identifying and designing low CO2-emitting vehicles.",,,979-8-3503-4602-2,384-389,IEEE , ,Temperature;Machine learning algorithms;Greenhouse effect;Prediction algorithms;Global warming;Fossil fuels;Information technology,,
4813,"Title:HAB detection within Aquaculture Industry: A Case Study in the Atlantic Area*

 Fisheries and aquaculture industries notably contribute to animal-source protein production worldwide. Climate change is creating environmental conditions suitable for harmful algal blooms (HAB) on a global scale. Some phytoplankton species can also release toxins, which may cause large-scale marine mortality with knock-on effects on coastal economies. Reliable phytoplankton monitoring and early HAB detection are also essential in climate-resilient solutions for aquaculture applications. Currently, phytoplankton monitoring is primarily based on traditional microscopy. However, it is time-consuming and requires an experienced taxonomist. There is a need to expedite and automate phytoplankton monitoring to support aquaculture industries. Analytical instruments based on microscopy coupled with artificial intelligence (AI) models may be vital to monitoring applications. Digital plankton data sets are usually imbalanced and reflect natural environmental differences. The lack of data to represent minority species/genera prevents AI models from understanding some taxa completely. It compromises system reliability for HAB monitoring applications. The present study investigates state-of-the-art models for class imbalance problems tailored for HAB monitoring within multi-trophic aquaculture farms from Brazil, South Africa, and Scotland. A unified benchmark database covering publicly available microscopic image-based datasets supported phytoplankton modelling. AI deep collaborative models and threshold moving techniques provided the best results compared to standard architectures. It prevailed, especially for low-abundant yet toxic organisms.",B. Guterres; K. Sbrissa; A. Mendes; L. Meireles; L. Novoveska; F. Vermeulen; J. Martinez; A. Garcia; L. Lain; M. Smith; P. Drews; N. Duarte; V. Oliveira; M. Pias; S. Botelho; R. Machado,,,HAB detection within Aquaculture Industry: A Case Study in the Atlantic Area*,,,10.1109/INDIN51400.2023.10218124 ,IEEE Conferences ,,"Fisheries and aquaculture industries notably contribute to animal-source protein production worldwide. Climate change is creating environmental conditions suitable for harmful algal blooms (HAB) on a global scale. Some phytoplankton species can also release toxins, which may cause large-scale marine mortality with knock-on effects on coastal economies. Reliable phytoplankton monitoring and early HAB detection are also essential in climate-resilient solutions for aquaculture applications. Currently, phytoplankton monitoring is primarily based on traditional microscopy. However, it is time-consuming and requires an experienced taxonomist. There is a need to expedite and automate phytoplankton monitoring to support aquaculture industries. Analytical instruments based on microscopy coupled with artificial intelligence (AI) models may be vital to monitoring applications. Digital plankton data sets are usually imbalanced and reflect natural environmental differences. The lack of data to represent minority species/genera prevents AI models from understanding some taxa completely. It compromises system reliability for HAB monitoring applications. The present study investigates state-of-the-art models for class imbalance problems tailored for HAB monitoring within multi-trophic aquaculture farms from Brazil, South Africa, and Scotland. A unified benchmark database covering publicly available microscopic image-based datasets supported phytoplankton modelling. AI deep collaborative models and threshold moving techniques provided the best results compared to standard architectures. It prevailed, especially for low-abundant yet toxic organisms.",2378-363X,,978-1-6654-9313-0,1-6,IEEE , ,Industries;Biological system modeling;Microscopy;Collaboration;Throughput;Reliability;Artificial intelligence,,
4814,"Title:Real-time dosimetry of ultrahigh dose-rate x-ray beams using scintillation detectors

 FLASH radiation therapy using an ultrahigh dose-rate beam is found to eradicate tumours whilst significantly reducing radiation-induced tissue toxicity. A real-time dosimetry system is required for the technique to be implemented clinically and for further preclinical studies. This study aimed to optimize the design of scintillating detectors using inorganic materials for real-time dosimetry in ultrahigh dose-rate radiation applications. Inorganic scintillator detectors were fabricated using phosphor-based scintillating materials (Gd2O2S:Tb, La2O2S:Tb, and La2O2S:Eu) coupled with optical fibers. The initial results in ultrahigh dose-rate x-ray irradiation showed excellent linearity with signal independent of the dose rate and dose delivered. A hyperspectral approach is adopted in this study to account for the stem effect that occurs within the high energy typically used in radiotherapy.",S. Shaharuddin; A. Hart; D. D. Cecchi; M. Bazalova-Carter; M. Foley,,,Real-time dosimetry of ultrahigh dose-rate x-ray beams using scintillation detectors,,,10.1109/SENSORS47087.2021.9639825 ,IEEE Conferences ,,"FLASH radiation therapy using an ultrahigh dose-rate beam is found to eradicate tumours whilst significantly reducing radiation-induced tissue toxicity. A real-time dosimetry system is required for the technique to be implemented clinically and for further preclinical studies. This study aimed to optimize the design of scintillating detectors using inorganic materials for real-time dosimetry in ultrahigh dose-rate radiation applications. Inorganic scintillator detectors were fabricated using phosphor-based scintillating materials (Gd2O2S:Tb, La2O2S:Tb, and La2O2S:Eu) coupled with optical fibers. The initial results in ultrahigh dose-rate x-ray irradiation showed excellent linearity with signal independent of the dose rate and dose delivered. A hyperspectral approach is adopted in this study to account for the stem effect that occurs within the high energy typically used in radiotherapy.",2168-9229,,978-1-7281-9501-8,1-4,IEEE , ,Optical fibers;Scintillators;Toxicology;Powders;Linearity;Detectors;Real-time systems,,
4815,"Title:Rectal Toxicity Prediction in Prostate Cancer Radiation Therapy Using CT Radiomic and 3D Dose Distribution Dosomic Features

 Radiomics and dosiomics are new and upcoming areas of medical imaging that require extracting numerous quantitative features from medical images and radiation dose data. In this study, we investigated rectum toxicity prediction in prostate cancer by using 3D dose distribution (DD) dosomic and computed tomography (CT) radiomic features. Our study consisted of 60 patients with prostate cancer with CT and DD images. An experienced radiation oncologist segmented the rectum, and radiomic and dosomic features were extracted from CT and DD images. Four different feature selections (FS) and five classifiers were applied to the training dataset and evaluated on the testing dataset. The performance of the model was evaluated with Area Under Curve (AUC), accuracy (ACC), sensitivity (SEN), and specificity (SPE). In DD dosiomics features, the XGB classifier with the MRMR algorithm had the highest performance with ACC=0.84, SEN=0.79, and SPE=0.86. In CT radiomic features, the RF classifier with the ANOVA algorithm is another best-performance model with ACC=0.85, SEN=0.65, and SPE=0.92. Finally, in combining radiomic and dosomic features, the MLP classifier with ANOVA had ACC=0.75, SEN=0.62, and SPE=0.79. The dosiomics and radiomics approach applied to 3D DD and CT images could predict rectal toxicity in prostate cancer.",E. Sadati; B. Hashemi; S. R. Mahdavi; A. Nikoufar; B. Mofid; H. Abdollahi; G. Hajianfar; I. Shiri; H. Zaidi,,,Rectal Toxicity Prediction in Prostate Cancer Radiation Therapy Using CT Radiomic and 3D Dose Distribution Dosomic Features,,,10.1109/NSSMICRTSD49126.2023.10338418 ,IEEE Conferences ,,"Radiomics and dosiomics are new and upcoming areas of medical imaging that require extracting numerous quantitative features from medical images and radiation dose data. In this study, we investigated rectum toxicity prediction in prostate cancer by using 3D dose distribution (DD) dosomic and computed tomography (CT) radiomic features. Our study consisted of 60 patients with prostate cancer with CT and DD images. An experienced radiation oncologist segmented the rectum, and radiomic and dosomic features were extracted from CT and DD images. Four different feature selections (FS) and five classifiers were applied to the training dataset and evaluated on the testing dataset. The performance of the model was evaluated with Area Under Curve (AUC), accuracy (ACC), sensitivity (SEN), and specificity (SPE). In DD dosiomics features, the XGB classifier with the MRMR algorithm had the highest performance with ACC=0.84, SEN=0.79, and SPE=0.86. In CT radiomic features, the RF classifier with the ANOVA algorithm is another best-performance model with ACC=0.85, SEN=0.65, and SPE=0.92. Finally, in combining radiomic and dosomic features, the MLP classifier with ANOVA had ACC=0.75, SEN=0.62, and SPE=0.79. The dosiomics and radiomics approach applied to 3D DD and CT images could predict rectal toxicity in prostate cancer.",2577-0829,,979-8-3503-3866-9,1-1,IEEE , ,Training;Toxicology;Three-dimensional displays;Computed tomography;Feature extraction;Classification algorithms;Prostate cancer,,
4816,"Title:Study of the Coincidence Time Resolution of New Perovskite Bulk Crystals

 Compared to scintillator based PET detectors, semiconductor detectors tend to provide excellent energy and spatial resolution. However, due to the relatively slow charge carrier collection time limited by the carrier drift velocity, semiconductor based detectors have poor time resolution in the range of several nanoseconds or greater. Possibilities exist to collect prompt photons emitted from certain semiconductor materials in order to greatly improve the timing capability. In this work, we studied the prompt photon emission property and fast timing capability of two new perovskite semiconductor materials, CsPbCl3 and CsPbBr3, and compared them with TlBr, which has been previously studied for its Cerenkov emission property. The coincidence time resolution (CTR) acquired between a 3 × 3 × 3 mm3 semiconductor sample crystal and a 3 × 3 × 3 mm3 reference LYSO crystal are 238 ± 16 ps, 468 ± 55 ps and 384 ± 31 ps for CsPbCl3, CsPbBr3, and TlBr respectively, when the LYSO crystal was only triggered on photoelectric events. When we lowered the trigger level and allowed the LYSO crystal to be triggered on all events including Compton scattering, we acquired CTR of 281 ± 17ps, 499 ± 77ps and 422 ± 46ps for CsPbCt3, CsPbBr3, and TlBr respectively. Combined with the easily scalable crystal growth process, relatively low cost, low toxicity, and high energy resolution (around 3.8% at 662keV), we conclude that CsPbCl3 and CsPbBr3 could be exceptional next generation candidates as semiconductor PET detector materials.",L. Tao; Y. He; M. G. Kanatzidis; C. S. Levin,,,Study of the Coincidence Time Resolution of New Perovskite Bulk Crystals,,,10.1109/NSS/MIC42101.2019.9059716 ,IEEE Conferences ,,"Compared to scintillator based PET detectors, semiconductor detectors tend to provide excellent energy and spatial resolution. However, due to the relatively slow charge carrier collection time limited by the carrier drift velocity, semiconductor based detectors have poor time resolution in the range of several nanoseconds or greater. Possibilities exist to collect prompt photons emitted from certain semiconductor materials in order to greatly improve the timing capability. In this work, we studied the prompt photon emission property and fast timing capability of two new perovskite semiconductor materials, CsPbCl3 and CsPbBr3, and compared them with TlBr, which has been previously studied for its Cerenkov emission property. The coincidence time resolution (CTR) acquired between a 3 × 3 × 3 mm3 semiconductor sample crystal and a 3 × 3 × 3 mm3 reference LYSO crystal are 238 ± 16 ps, 468 ± 55 ps and 384 ± 31 ps for CsPbCl3, CsPbBr3, and TlBr respectively, when the LYSO crystal was only triggered on photoelectric events. When we lowered the trigger level and allowed the LYSO crystal to be triggered on all events including Compton scattering, we acquired CTR of 281 ± 17ps, 499 ± 77ps and 422 ± 46ps for CsPbCt3, CsPbBr3, and TlBr respectively. Combined with the easily scalable crystal growth process, relatively low cost, low toxicity, and high energy resolution (around 3.8% at 662keV), we conclude that CsPbCl3 and CsPbBr3 could be exceptional next generation candidates as semiconductor PET detector materials.",2577-0829,,978-1-7281-4164-0,1-3,IEEE , ,Crystals;Detectors;Timing;Photonics;Energy resolution;Semiconductor device measurement;Spatial resolution,,
4817,"Title:Fiber-coupled GAGG scintillators for real-time small-field dosimetry in FLASH proton therapy

 FLASH radiation therapy (RT) has been recently proposed as a novel modality that features reduced toxicity to healthy tissue while maintaining the same antitumor efficacy as conventional radiotherapy. FLASH-RT is characterized by the delivery of ultra-high dose rates (> 40 Gy/s) in sub-second treatment times. Real-time beam monitoring and dosimetry for FLASH are challenging and new approaches have been proposed to address this issue. Along this line, novel detectors based on fiber-coupled scintillators are under development at the University of Bern. This work reports on the characterization of a detector prototype made of a sample of Cerium-doped Gadolinium Aluminum Gallium Garnet (Ce:GAGG) of size (0.5×0.5×2) mm3 coupled to an optical fiber. The scintillation light pulses are driven to a single photon detector and to a multi-channel scaler operated at 10 kHz sampling rate. Functional tests have been performed at the Francis H. Burr Proton Therapy Center at the Massachusetts General Hospital (Boston, MA) with 227.5 MeV proton beams. The detector response was found to be linear in the range 4-120 Gy/s (maximum dose rate available). We compared the GAGG depth dose curve with that of a reference ion chamber and of a rectifier diode. We observed a reduction of the GAGG signal which is likely due to quenching effects and loss of in-scattering contribution in the sub-millimeter volume of the scintillator, and is currently under investigation. Overall, the proposed system has been found to be suitable for real-time ultra-high dose rate small field dosimetry and it is promising for quality assurance, beam monitoring and in-vivo dosimetry for FLASH therapy.",P. Casolaro; K. P. Nesteruk; E. Cascio; B. Clasie; G. Dellepiane; A. Gottstein; I. Mateu; P. Scampoli; J. Schuemann; S. Braccini,,,Fiber-coupled GAGG scintillators for real-time small-field dosimetry in FLASH proton therapy,,,10.1109/NSSMICRTSD49126.2023.10338316 ,IEEE Conferences ,,"FLASH radiation therapy (RT) has been recently proposed as a novel modality that features reduced toxicity to healthy tissue while maintaining the same antitumor efficacy as conventional radiotherapy. FLASH-RT is characterized by the delivery of ultra-high dose rates (> 40 Gy/s) in sub-second treatment times. Real-time beam monitoring and dosimetry for FLASH are challenging and new approaches have been proposed to address this issue. Along this line, novel detectors based on fiber-coupled scintillators are under development at the University of Bern. This work reports on the characterization of a detector prototype made of a sample of Cerium-doped Gadolinium Aluminum Gallium Garnet (Ce:GAGG) of size (0.5×0.5×2) mm3 coupled to an optical fiber. The scintillation light pulses are driven to a single photon detector and to a multi-channel scaler operated at 10 kHz sampling rate. Functional tests have been performed at the Francis H. Burr Proton Therapy Center at the Massachusetts General Hospital (Boston, MA) with 227.5 MeV proton beams. The detector response was found to be linear in the range 4-120 Gy/s (maximum dose rate available). We compared the GAGG depth dose curve with that of a reference ion chamber and of a rectifier diode. We observed a reduction of the GAGG signal which is likely due to quenching effects and loss of in-scattering contribution in the sub-millimeter volume of the scintillator, and is currently under investigation. Overall, the proposed system has been found to be suitable for real-time ultra-high dose rate small field dosimetry and it is promising for quality assurance, beam monitoring and in-vivo dosimetry for FLASH therapy.",2577-0829,,979-8-3503-3866-9,1-2,IEEE , ,Optical fibers;Particle beams;Scintillators;Toxicology;Real-time systems;Dosimetry;Radiation therapy,,
4818,"Title:Broadband toxicity sensing for rapid surveys of drinking water storage facilities

 Nekton Research has developed a novel, broad-band water toxicity detector and sampler for use on the Nekton Ranger AUV. This system can quickly survey drinking water reservoirs, in 3D, and provide early warning of toxic contamination. The novel element of the detector is an array of live clams that function as ""canaries in a coal mine"". When these highly sensitive filter feeders encounter water they deem toxic, they snap their shells shut and close down their feeding activities - a rapid reaction that can be utilized to trigger AUV response. Initial field trials and sensor characterization will be described as well as homeland security applications",R. Moody,,,Broadband toxicity sensing for rapid surveys of drinking water storage facilities,,,10.1109/OCEANS.2005.1639959 ,IEEE Conferences ,,"Nekton Research has developed a novel, broad-band water toxicity detector and sampler for use on the Nekton Ranger AUV. This system can quickly survey drinking water reservoirs, in 3D, and provide early warning of toxic contamination. The novel element of the detector is an array of live clams that function as ""canaries in a coal mine"". When these highly sensitive filter feeders encounter water they deem toxic, they snap their shells shut and close down their feeding activities - a rapid reaction that can be utilized to trigger AUV response. Initial field trials and sensor characterization will be described as well as homeland security applications",0197-7385,,0-933957-34-3,1448-1454 Vol. 2,IEEE , ,Water storage;Water pollution;Detectors;Water resources;Reservoirs;Contamination;Sensor arrays;Filters;Sensor phenomena and characterization;Terrorism,,
4819,"Title:Alpha-SPECT-mini: A Preclinical SPECT system Using Ultrahigh Energy Resolution CdTe detectors for Low-Dose Alpha Emitter Radiopharmaceutical Therapy Imaging

 In this work, we have developed the CdTe detector-based alpha-SPECT-mini system for preclinical studies. The system is designed to have ultrahigh energy resolution <3keV on average and sensitivity to accommodate the low dose of the targeted alpha therapy applications in mice studies. Machine learning charge sharing reconstruction algorithms are used to achieve the best energy resolution and sensitivity simultaneously. We have performed the Derenzo resolution and Image Quality phantom studies with Tc-99m to evaluate the intrinsic resolution <0.75mm and with Ac-225 to evaluate the multi-isotope imaging capabilities (Ac-225, Fr-221, Bi-213, Tl-209) of the system. Soon, we will also perform the in vivo mice imaging study to further evaluate the system performance for low dose imaging and to study the biological reaction of mice to Ac-225 and toxicity effects on surrounding healthy tissues.",C. Yang; E. M. Zannoni; L. Cai; M. D. Wilson; R. Bastiaannet; Y. Du; G. Sgouros; E. Frey; L. J. Meng,,,Alpha-SPECT-mini: A Preclinical SPECT system Using Ultrahigh Energy Resolution CdTe detectors for Low-Dose Alpha Emitter Radiopharmaceutical Therapy Imaging,,,10.1109/NSSMICRTSD49126.2023.10338639 ,IEEE Conferences ,,"In this work, we have developed the CdTe detector-based alpha-SPECT-mini system for preclinical studies. The system is designed to have ultrahigh energy resolution <3keV on average and sensitivity to accommodate the low dose of the targeted alpha therapy applications in mice studies. Machine learning charge sharing reconstruction algorithms are used to achieve the best energy resolution and sensitivity simultaneously. We have performed the Derenzo resolution and Image Quality phantom studies with Tc-99m to evaluate the intrinsic resolution <0.75mm and with Ac-225 to evaluate the multi-isotope imaging capabilities (Ac-225, Fr-221, Bi-213, Tl-209) of the system. Soon, we will also perform the in vivo mice imaging study to further evaluate the system performance for low dose imaging and to study the biological reaction of mice to Ac-225 and toxicity effects on surrounding healthy tissues.",2577-0829,,979-8-3503-3866-9,1-1,IEEE , ,Sensitivity;Image resolution;Toxicology;II-VI semiconductor materials;System performance;Energy resolution;Medical treatment,,
4820,"Title:Potential Toxicity of Chronic Creatine Supplementation in Mice

 Creatine is alleged to be a popular nutrition to enhance sports performance. It can be metabolized to methylamine, which is further converted to formaldehyde, hydrogen peroxide and ammonium by semicarbazied-sensitive amine oxidases (SSAO). Until now, there is no scientific available data for demonstration the long-term health risks of chronic creatine ingestion. In this study, we demonstrated that after chronic oral administration of creatine to mice, the level of methylamine and formaldehyde in urine were increased, SSAO activity of serum and tissue were increased simultaneously. SSAO inhibitor (2-bromoethylamine hydrobromide) could substantially increase the methylamine level and decrease the formaldehyde content respectively. A novel high-performance liquid chromatography (HPLC) and electrospray ionization (ESI) mass spectrometry method for the determination of SSAO activity was developed for the first time. Potential toxicity after chronic creatine administration was discussed according to the increase of toxic products content and SSAO activity. To our knowledge, this is the first report on the research of relationship between SSAO and creatine.",Lin Wang; Shengyuan Xiao; Yujuan Li; Lu Wang; Baoquan Che; Xuan Zhao; Yulin Deng,,,Potential Toxicity of Chronic Creatine Supplementation in Mice,,,10.1109/ICBBE.2009.5163209 ,IEEE Conferences ,,"Creatine is alleged to be a popular nutrition to enhance sports performance. It can be metabolized to methylamine, which is further converted to formaldehyde, hydrogen peroxide and ammonium by semicarbazied-sensitive amine oxidases (SSAO). Until now, there is no scientific available data for demonstration the long-term health risks of chronic creatine ingestion. In this study, we demonstrated that after chronic oral administration of creatine to mice, the level of methylamine and formaldehyde in urine were increased, SSAO activity of serum and tissue were increased simultaneously. SSAO inhibitor (2-bromoethylamine hydrobromide) could substantially increase the methylamine level and decrease the formaldehyde content respectively. A novel high-performance liquid chromatography (HPLC) and electrospray ionization (ESI) mass spectrometry method for the determination of SSAO activity was developed for the first time. Potential toxicity after chronic creatine administration was discussed according to the increase of toxic products content and SSAO activity. To our knowledge, this is the first report on the research of relationship between SSAO and creatine.",2151-7622,,978-1-4244-2901-1,1-4,IEEE , ,Mice;Biochemistry;Animals;Detectors;Inhibitors;Heart;Blood;Impurities;Chemical analysis;Analysis of variance,,
4821,"Title:Investigation of electron multiplication effect in optical property modulation-based radiation detection method for PET

 In this paper, we further explore the optical property modulation-based method for ionizing radiation photon detection in PET as a potential new direction to dramatically improve the coincidence time resolution. We compare the performance of three detector crystals for this method including two types of cadmium telluride (CdTe) crystals and one bismuth silicon oxide (BSO) crystal under high bias voltages up to 3500V. We first show that the induced current flow in the detector crystal determines the strength of the optical property modulation signal due to ionization. A larger resistivity is favorable for reducing the dark current (noise) in the crystal and facilitates the detection of weak optical property modulation signals. In addition, we show that BSO is a potential candidate detector material. When biased at 3500 V, it has comparable modulation signal sensitivity as CdTe biased at 1000V, but with higher resistivity (lower noise), larger 511 keV photon attenuation coefficient, lower price, better crystal surface finish quality, and less toxicity. By studying the dependence of modulation signal amplitude on crystal bias voltage, we show that the modulation signal amplitude (induced by both UV laser diode and Ge-68 source) is linearly proportional to crystal bias voltage with a linear fit R factor of around 0.95. The modulation signal amplitude induced by UV laser diode irradiation increases from 0% to 2% (normalized to the average signal level) for both CdTe and BSO under crystal bias voltage from 0V to 3500V. The modulation signal amplitude induced by Ge-68 irradiation increases from 0% to 12% for CdTe under crystal bias voltage from 0V to 1500 V, and increases from 0% to 10% for BSO under crystal bias voltage from 0V to 3500 V. Therefore the electron multiplication effect (with high crystal bias) shows promise to significantly boost the modulation signal amplitude with the ultimate goal to achieve single 511 keV photon detection.",L. Tao; H. M. Daghighian; C. S. Levin,,,Investigation of electron multiplication effect in optical property modulation-based radiation detection method for PET,,,10.1109/NSSMIC.2016.8069554 ,IEEE Conferences ,,"In this paper, we further explore the optical property modulation-based method for ionizing radiation photon detection in PET as a potential new direction to dramatically improve the coincidence time resolution. We compare the performance of three detector crystals for this method including two types of cadmium telluride (CdTe) crystals and one bismuth silicon oxide (BSO) crystal under high bias voltages up to 3500V. We first show that the induced current flow in the detector crystal determines the strength of the optical property modulation signal due to ionization. A larger resistivity is favorable for reducing the dark current (noise) in the crystal and facilitates the detection of weak optical property modulation signals. In addition, we show that BSO is a potential candidate detector material. When biased at 3500 V, it has comparable modulation signal sensitivity as CdTe biased at 1000V, but with higher resistivity (lower noise), larger 511 keV photon attenuation coefficient, lower price, better crystal surface finish quality, and less toxicity. By studying the dependence of modulation signal amplitude on crystal bias voltage, we show that the modulation signal amplitude (induced by both UV laser diode and Ge-68 source) is linearly proportional to crystal bias voltage with a linear fit R factor of around 0.95. The modulation signal amplitude induced by UV laser diode irradiation increases from 0% to 2% (normalized to the average signal level) for both CdTe and BSO under crystal bias voltage from 0V to 3500V. The modulation signal amplitude induced by Ge-68 irradiation increases from 0% to 12% for CdTe under crystal bias voltage from 0V to 1500 V, and increases from 0% to 10% for BSO under crystal bias voltage from 0V to 3500 V. Therefore the electron multiplication effect (with high crystal bias) shows promise to significantly boost the modulation signal amplitude with the ultimate goal to achieve single 511 keV photon detection.",,,978-1-5090-1642-6,1-3,IEEE , ,Crystals;Optical modulation;Optical sensors;Conductivity;Detectors;Photonics,,
4822,"Title:3D Volume Micro-scale 225Ac Dosimetry in Preclinical Prostate Cancer Models

 Radiopharmaceutical therapy with alpha particle emitters (αRPT) offers an advantage in the treatment of refractory or metastatic cancers, such as metastatic castration-resistant prostate cancer (mCRPC), by using a precise targeting strategy to exploit the high therapeutic specificity of short-range (40-80 μm) cytotoxic alpha particles. 225Ac-based radiopharmaceuticals have shown high efficacy in several clinical trials, but off-target toxicity suggests that improvements are needed in radiochemistry and progeny radionuclide management. However, the limited availability of data and technologies that quantify dose distribution on spatial scales relevant to the alpha particle range impairs accurate characterization of novel αRPT agents. Here, we demonstrate that 2D digital autoradiography with an ionizing-radiation quantum imaging detector (iQID) can facilitate 3D volumetric dosimetry of targeted and non-targeted tissues. A series of 10-μm cryosections extracted every 200 μm spanning the organ or tumor is measured with the device. These activity maps are used in a previously developed Monte Carlo dose kernel convolution procedure to obtain dose-rate images, which we digitally register into a 3D volume via intensity-maximization rigid-body transformations. The resulting dose-rate organ or tumor volume has an effective voxel size of 39 x 39 x 210 μm. To permit the measurement of only one slice at each position, we validate a digital duplication approximation with a secondary experiment measuring 10 consecutive 10-μmslices in each tissue. We use this technique to sample dose-rate measurements across whole tumors and kidneys from a murine study of 225Ac-MACROPA-YS5, a novel αRPT agent with specificity to CD46-positive tumors. Renal cortical dose rate is over twice that of the medullary region, which suggests that free progeny 213Bi, which is known to collect in the renal cortex, is the source of nephrotoxicity in 225Ac αRPT.",R. Peter; A. P. Bidkar; K. N. Bobba; B. Liu; B. W. Miller; K. Vetter; R. R. Flavell; Y. Seo,,,3D Volume Micro-scale 225Ac Dosimetry in Preclinical Prostate Cancer Models,,,10.1109/NSSMICRTSD49126.2023.10337919 ,IEEE Conferences ,,"Radiopharmaceutical therapy with alpha particle emitters (αRPT) offers an advantage in the treatment of refractory or metastatic cancers, such as metastatic castration-resistant prostate cancer (mCRPC), by using a precise targeting strategy to exploit the high therapeutic specificity of short-range (40-80 μm) cytotoxic alpha particles. 225Ac-based radiopharmaceuticals have shown high efficacy in several clinical trials, but off-target toxicity suggests that improvements are needed in radiochemistry and progeny radionuclide management. However, the limited availability of data and technologies that quantify dose distribution on spatial scales relevant to the alpha particle range impairs accurate characterization of novel αRPT agents. Here, we demonstrate that 2D digital autoradiography with an ionizing-radiation quantum imaging detector (iQID) can facilitate 3D volumetric dosimetry of targeted and non-targeted tissues. A series of 10-μm cryosections extracted every 200 μm spanning the organ or tumor is measured with the device. These activity maps are used in a previously developed Monte Carlo dose kernel convolution procedure to obtain dose-rate images, which we digitally register into a 3D volume via intensity-maximization rigid-body transformations. The resulting dose-rate organ or tumor volume has an effective voxel size of 39 x 39 x 210 μm. To permit the measurement of only one slice at each position, we validate a digital duplication approximation with a secondary experiment measuring 10 consecutive 10-μmslices in each tissue. We use this technique to sample dose-rate measurements across whole tumors and kidneys from a murine study of 225Ac-MACROPA-YS5, a novel αRPT agent with specificity to CD46-positive tumors. Renal cortical dose rate is over twice that of the medullary region, which suggests that free progeny 213Bi, which is known to collect in the renal cortex, is the source of nephrotoxicity in 225Ac αRPT.",2577-0829,,979-8-3503-3866-9,1-2,IEEE , ,Semiconductor device measurement;Solid modeling;Three-dimensional displays;Toxicology;Semiconductor detectors;Alpha particles;Position measurement,,
4823,"Title:Ultralow Dose Small Animal SPECT reconstruction for Alpha-Emitter Radiopharmaceutical Therapy

 Alpha-emitter radiopharmaceutical therapy (αRPT) becomes a promising cancer treatment, which harnesses the high linear energy transfer (LET) and short range of α-particles to deliver targeted destruction of cancer cells. However, the application of alpha-emitters in Targeted Alpha Therapies (TATs) may lead to the release of daughter products, which can migrate away from the tumor site and cause toxicity in nearby tissues and organs. To identify the biodistribution of primary α-emitters and their daughters, SPECT scanner with superior energy resolution is crucial to differentiate specific gamma-rays from different isotopes and distinguish the primary signal from scattering noise events. Because TAT imaging typically utilizes very low concentrations of alpha-particle emitters less than 1 μCi, the image reconstruction with denoising is necessary. Recently, we have developed an innovative preclinical SPECT system at UIUC featuring smallpixel CdTe detectors, which provides ultra-high energy resolution and exceptional spatial resolution for small-animal αRPT imaging applications. In this study, we focused on low count SPECT reconstruction, which involves 1) constructing a system matrix using voxel-driven forward/backward projectors, and 2) implementing a penalized SPECT reconstruction method utilizing the forward-backward splitting approach. We evaluated our approach using a resolution phantom filled with diagnostic isotope Tc-99m (1.5 mCi). Our results demonstrate that our system achieved a spatial resolution of approximately 0.75 mm and was capable of detecting and imaging low-activity sources with reduced artifact. In our future studies, the imaging of a mouse with sub 1-μCi Ac-225 will be particularly challenging.",K. Kim; C. Yang; L. J. Meng; Q. Li,,,Ultralow Dose Small Animal SPECT reconstruction for Alpha-Emitter Radiopharmaceutical Therapy,,,10.1109/NSSMICRTSD49126.2023.10337984 ,IEEE Conferences ,,"Alpha-emitter radiopharmaceutical therapy (αRPT) becomes a promising cancer treatment, which harnesses the high linear energy transfer (LET) and short range of α-particles to deliver targeted destruction of cancer cells. However, the application of alpha-emitters in Targeted Alpha Therapies (TATs) may lead to the release of daughter products, which can migrate away from the tumor site and cause toxicity in nearby tissues and organs. To identify the biodistribution of primary α-emitters and their daughters, SPECT scanner with superior energy resolution is crucial to differentiate specific gamma-rays from different isotopes and distinguish the primary signal from scattering noise events. Because TAT imaging typically utilizes very low concentrations of alpha-particle emitters less than 1 μCi, the image reconstruction with denoising is necessary. Recently, we have developed an innovative preclinical SPECT system at UIUC featuring smallpixel CdTe detectors, which provides ultra-high energy resolution and exceptional spatial resolution for small-animal αRPT imaging applications. In this study, we focused on low count SPECT reconstruction, which involves 1) constructing a system matrix using voxel-driven forward/backward projectors, and 2) implementing a penalized SPECT reconstruction method utilizing the forward-backward splitting approach. We evaluated our approach using a resolution phantom filled with diagnostic isotope Tc-99m (1.5 mCi). Our results demonstrate that our system achieved a spatial resolution of approximately 0.75 mm and was capable of detecting and imaging low-activity sources with reduced artifact. In our future studies, the imaging of a mouse with sub 1-μCi Ac-225 will be particularly challenging.",2577-0829,,979-8-3503-3866-9,1-1,IEEE , ,Toxicology;Semiconductor detectors;Energy resolution;Scattering;Reconstruction algorithms;Single photon emission computed tomography;Spatial resolution,,
4824,"Title:Polycrystalline diamond detectors compared with silicon X-ray dosimeters for clinical use

 Physical and metering characteristics of three room temperature X-ray dosimeters used in clinical applications, PTW diamond, Thompson MOSFET and Scanditronix silicon diode are compared with polycrystalline diamond X-ray detectors. Development of dosimeters based on natural diamond carried out by PTW have provided superior characteristics with respect to other solid state silicon devices such diodes or MOSFETs. Radiation hardness, soft tissue equivalence, lack of toxicity, negligible energy dependence and optimal sensitivity and reproducibility, have made PTW the ideal metering device for clinical dosimetry. However general use of natural dosimeters have been hindered by their rarity, very high cost and unpredictable electronic behavior due to lack of control on impurity content and crystal defects. Therefore, there have been a growing use of silicon dosimeters especially for on line configuration and in vivo dosimetry. However, both MOSFET and silicon diode do not appear to be ideal for such application for their short lifetime. Detectors based on polycrystalline diamonds seem to be the best candidate for future dosimetry since they have most of the characteristics of natural diamonds at potentially much lower cost. In this context, the performances of a laboratory made polycrystalline diamond device are compared to those of the three, PTW, Scanditronix and Thomson commercial dosimeters.",I. Ciancaglioni; R. Consorti; M. C. Rossi; G. Conte,,,Polycrystalline diamond detectors compared with silicon X-ray dosimeters for clinical use,7,,10.1109/NSSMIC.2004.1466871 ,IEEE Conferences ,,"Physical and metering characteristics of three room temperature X-ray dosimeters used in clinical applications, PTW diamond, Thompson MOSFET and Scanditronix silicon diode are compared with polycrystalline diamond X-ray detectors. Development of dosimeters based on natural diamond carried out by PTW have provided superior characteristics with respect to other solid state silicon devices such diodes or MOSFETs. Radiation hardness, soft tissue equivalence, lack of toxicity, negligible energy dependence and optimal sensitivity and reproducibility, have made PTW the ideal metering device for clinical dosimetry. However general use of natural dosimeters have been hindered by their rarity, very high cost and unpredictable electronic behavior due to lack of control on impurity content and crystal defects. Therefore, there have been a growing use of silicon dosimeters especially for on line configuration and in vivo dosimetry. However, both MOSFET and silicon diode do not appear to be ideal for such application for their short lifetime. Detectors based on polycrystalline diamonds seem to be the best candidate for future dosimetry since they have most of the characteristics of natural diamonds at potentially much lower cost. In this context, the performances of a laboratory made polycrystalline diamond device are compared to those of the three, PTW, Scanditronix and Thomson commercial dosimeters.",1082-3654,,0-7803-8701-5,4445-4447,IEEE , ,X-ray detection;X-ray detectors;Diodes;Dosimetry;MOSFET circuits;Costs;Temperature;Solid state circuits;Silicon devices;Biological tissues,,
4825,"Title:Pharmacokinetic and dosimetry modeling of Radiopharmaceutical Therapy using Spatial Transcriptomics in microenvironment

 The efficacy of radiopharmaceutical therapy (RPT) relies on the ability to deliver cytotoxic radiation to cancer cells or the surrounding tumor microenvironment (TME) while minimizing normal tissue toxicity. Therefore, dosimetry is essential to understand the factors that influence treatment. The spatial transcriptomics (ST) technique may offer a breakthrough in investigating RPT dosimetry as it enables to spatially profile the diverse gene transcripts that are associated with TME. In this study, we propose a novel approach to combine the pharmacokinetics and dosimetry of RPT with ST maps to elucidate the heterogeneity of RPT dosimetry and its effects. For proof of concept, we focused on modeling 177Lu-and 225Ac-prostate-specific membrane antigen (PSMA), which emit beta and alpha particles, respectively. Specifically, we solved partial differential equations (PDE) of the pharmacokinetic model and applied the dose-voxel kernel (DVK) method using various ST maps. Additionally, assuming hypoxia as one of the influencing factors in RPT, we utilized hypoxia ST to measure the cell survival probability of each 177Lu-and 225Ac- RPT.",J. Hong; S. Bae; L. Cavinato; K. Erlandsson; H. Choi; K. Shi,,,Pharmacokinetic and dosimetry modeling of Radiopharmaceutical Therapy using Spatial Transcriptomics in microenvironment,,,10.1109/NSSMICRTSD49126.2023.10338027 ,IEEE Conferences ,,"The efficacy of radiopharmaceutical therapy (RPT) relies on the ability to deliver cytotoxic radiation to cancer cells or the surrounding tumor microenvironment (TME) while minimizing normal tissue toxicity. Therefore, dosimetry is essential to understand the factors that influence treatment. The spatial transcriptomics (ST) technique may offer a breakthrough in investigating RPT dosimetry as it enables to spatially profile the diverse gene transcripts that are associated with TME. In this study, we propose a novel approach to combine the pharmacokinetics and dosimetry of RPT with ST maps to elucidate the heterogeneity of RPT dosimetry and its effects. For proof of concept, we focused on modeling 177Lu-and 225Ac-prostate-specific membrane antigen (PSMA), which emit beta and alpha particles, respectively. Specifically, we solved partial differential equations (PDE) of the pharmacokinetic model and applied the dose-voxel kernel (DVK) method using various ST maps. Additionally, assuming hypoxia as one of the influencing factors in RPT, we utilized hypoxia ST to measure the cell survival probability of each 177Lu-and 225Ac- RPT.",2577-0829,,979-8-3503-3866-9,1-1,IEEE , ,Semiconductor device measurement;Toxicology;Semiconductor detectors;Transcriptomics;Medical treatment;Hypoxia;Mathematical models,,
4826,"Title:Personalized PBPK modeling can reduce uncertainty of the dose prediction in radiopharmaceutical therapy (RPT): a simulation study

 Physiologically based pharmacokinetic modeling plays a crucial role in optimizing dosimetry estimates for radiopharmaceutical therapy (RPT) on cancer patients. Presently, PBPK applications in RPT predominantly depend on population-level parameters, leading to large uncertainties on the dose prediction. These uncertainties can result in sub-optimal therapeutic effects, increase toxicity, and compromise treatment planning. In this study, we developed a whole body PBPK model, incorporating a Tumor compartment, to predict the dose in different organs. By personalizing certain anatomical and physiological parameters that could be potentially derived from pre-treatment PET/CT and blood test, we observed a substantial decrease in the uncertainty of dose prediction when utilizing personalized PBPK modeling.",R. Hu; J. Luo; B. Saboury; P. Heidari; Q. Li; H. Liu; N. Guo,,,Personalized PBPK modeling can reduce uncertainty of the dose prediction in radiopharmaceutical therapy (RPT): a simulation study,,,10.1109/NSSMICRTSD49126.2023.10338122 ,IEEE Conferences ,,"Physiologically based pharmacokinetic modeling plays a crucial role in optimizing dosimetry estimates for radiopharmaceutical therapy (RPT) on cancer patients. Presently, PBPK applications in RPT predominantly depend on population-level parameters, leading to large uncertainties on the dose prediction. These uncertainties can result in sub-optimal therapeutic effects, increase toxicity, and compromise treatment planning. In this study, we developed a whole body PBPK model, incorporating a Tumor compartment, to predict the dose in different organs. By personalizing certain anatomical and physiological parameters that could be potentially derived from pre-treatment PET/CT and blood test, we observed a substantial decrease in the uncertainty of dose prediction when utilizing personalized PBPK modeling.",2577-0829,,979-8-3503-3866-9,1-1,IEEE , ,Microwave integrated circuits;Uncertainty;Toxicology;Semiconductor detectors;Medical treatment;Predictive models;Physiology,,
4827,"Title:A multiclass multivariate group comparison test: Application to drug safety

 Hypothesis tests are used to compare and show the efficiency of drugs. However, usual tests do not perform properly whenever the number of variables is greater than, or of the same order of magnitude as, the number of observations. In this paper, we propose an alternative to usual multiclass multivariate group comparison tests such as MANOVA or Wilcoxon tests. We present a pattern recognition approach to compare drugs in high dimensional spaces. Our test is based on the classification probability of error of a classifier. The decision statistics is obtained using the leave one out procedure. The statistics power density function has been experimentally shown independent from the data distribution under the null hypothesis, that allows to determine the threshold, or the p-values, of our test. This test has been applied on clinical data registered to ensure the safety side and tolerability of drugs tested.",M. Tohmé; R. Lengellé; V. Freytag,,,A multiclass multivariate group comparison test: Application to drug safety,,,10.1109/IEMBS.2010.5626384 ,IEEE Conferences ,,"Hypothesis tests are used to compare and show the efficiency of drugs. However, usual tests do not perform properly whenever the number of variables is greater than, or of the same order of magnitude as, the number of observations. In this paper, we propose an alternative to usual multiclass multivariate group comparison tests such as MANOVA or Wilcoxon tests. We present a pattern recognition approach to compare drugs in high dimensional spaces. Our test is based on the classification probability of error of a classifier. The decision statistics is obtained using the leave one out procedure. The statistics power density function has been experimentally shown independent from the data distribution under the null hypothesis, that allows to determine the threshold, or the p-values, of our test. This test has been applied on clinical data registered to ensure the safety side and tolerability of drugs tested.",1558-4615,,978-1-4244-4123-5,4711-4714,IEEE , ,Drugs;Pattern recognition;Safety;Detectors;Stability analysis;Probability density function;Covariance matrix,,
4828,"Title:Investigation of the Microstructure of Mn-doped Tin-Silver-Copper Solder Alloys Solidified with Different Cooling Rates

 Due to the moderate price and the non-toxicity, manganese is considered as an ideal dopant for the SAC (SnAgCu) solder alloys. Manganese refines the grain of solder joints, yielding better thermomechanical properties. In present research, the microstructure of the manganese-doped alloys solidified with different technological parameters had been investigated. Sn/Ag0.3/Cu0.7 based solder alloy with three different Mn content (0.1, 0.4, 0.7% wt%= were reflowed on a copper substrate with tempered hot plate. They were solidified with different cooling rates from 0.3 to 4.5 K/s. Cross-sections have been prepared from the solder samples and the metallographic properties of the solder samples was investigated with optical and scanning electron microscopes. The characteristic features of the samples have been compared to conventionally used SAC305 (Sn/Ag3/Cu0.5= solder alloys, solidified with the same rates of cooling. Results showed that besides the grain refinement, the Mn content might also have effect on the evolution of intermetallic layer between the substrate and the solder alloy. The IMC grains of the layer were more elongated and more spalled grains had been observed close to the layer. However, independently of the cooling rate, the microstructure of the Mn containing solder alloys remained the same. This suggests that the macroscopic properties are also expected to be less sensitive to the cooling rate of the solidification.",T. Hurtony; O. Krammer; B. Illés; P. Gordon,,,Investigation of the Microstructure of Mn-doped Tin-Silver-Copper Solder Alloys Solidified with Different Cooling Rates,,,10.23919/EMPC44848.2019.8951866 ,IEEE Conferences ,,"Due to the moderate price and the non-toxicity, manganese is considered as an ideal dopant for the SAC (SnAgCu) solder alloys. Manganese refines the grain of solder joints, yielding better thermomechanical properties. In present research, the microstructure of the manganese-doped alloys solidified with different technological parameters had been investigated. Sn/Ag0.3/Cu0.7 based solder alloy with three different Mn content (0.1, 0.4, 0.7% wt%= were reflowed on a copper substrate with tempered hot plate. They were solidified with different cooling rates from 0.3 to 4.5 K/s. Cross-sections have been prepared from the solder samples and the metallographic properties of the solder samples was investigated with optical and scanning electron microscopes. The characteristic features of the samples have been compared to conventionally used SAC305 (Sn/Ag3/Cu0.5= solder alloys, solidified with the same rates of cooling. Results showed that besides the grain refinement, the Mn content might also have effect on the evolution of intermetallic layer between the substrate and the solder alloy. The IMC grains of the layer were more elongated and more spalled grains had been observed close to the layer. However, independently of the cooling rate, the microstructure of the Mn containing solder alloys remained the same. This suggests that the macroscopic properties are also expected to be less sensitive to the cooling rate of the solidification.",,,978-0-9568086-6-0,1-5,IEEE , ,,,
4829,"Title:CuFeSe2 Quantum-Dot Based Infrared Photodetectors with Functionality in the Ambient

 Applications such as infrared cameras and detectors have driven efforts to discover novel infrared materials. Quantum dots have been demonstrated as sensitive and tunable infrared absorbers. Most successful quantum dots are prepared from heavier II-VI materials based on mercury and therefore pose toxicity hazards. Here we investigate CuFeSe2 quantum dots as a potential solution processed, minimally hazardous photodetector material for the fabrication of devices with functionality in the ambient. Following characterization of the nanocrystals through Transmission Electron Microscopy (TEM) and their absorption spectrum with infrared spectroscopy, we demonstrate infrared and visible light detection with two device architectures. A Metal-Semiconductor-Metal (MSM) photoconductor shows optoelectronic response with infrared light, and a p-n heterojunction shows the characteristic I-V curve with a broadband visible-infrared light source. We thus demonstrate the application of CuFeSe2 quantum dots as an infrared active material, and its heterojunction with silicon as a promising photodetector device.",T. Kumar; A. Sugathan; K. L. Narasimhan; A. Pandey; S. Avasthi,,,CuFeSe2 Quantum-Dot Based Infrared Photodetectors with Functionality in the Ambient,,,10.1109/SENSORS47087.2021.9639657 ,IEEE Conferences ,,"Applications such as infrared cameras and detectors have driven efforts to discover novel infrared materials. Quantum dots have been demonstrated as sensitive and tunable infrared absorbers. Most successful quantum dots are prepared from heavier II-VI materials based on mercury and therefore pose toxicity hazards. Here we investigate CuFeSe2 quantum dots as a potential solution processed, minimally hazardous photodetector material for the fabrication of devices with functionality in the ambient. Following characterization of the nanocrystals through Transmission Electron Microscopy (TEM) and their absorption spectrum with infrared spectroscopy, we demonstrate infrared and visible light detection with two device architectures. A Metal-Semiconductor-Metal (MSM) photoconductor shows optoelectronic response with infrared light, and a p-n heterojunction shows the characteristic I-V curve with a broadband visible-infrared light source. We thus demonstrate the application of CuFeSe2 quantum dots as an infrared active material, and its heterojunction with silicon as a promising photodetector device.",2168-9229,,978-1-7281-9501-8,1-4,IEEE , ,Spectroscopy;Toxicology;Absorption;Transmission electron microscopy;Quantum dots;Heterojunctions;Sensor phenomena and characterization,,
4830,"Title:Low overdrive voltage and low current compact comparator for a diamond dosimeter ASIC

 The dosimeters for radiotherapy must comply to strict requirements in terms of sensitivity, toxicity, tissue equivalence and radiation hardness. At present time both silicon and diamond dosimeters are used as solid state devices and in recent years, monocrystalline diamond sensors have been grown with CVD techniques. Due to the low current signals, the sensor readout is made by electrometers connected to the device with multi wire shielded cables. This measurement setup may be a serious limitation for practical application of these sensors, and makes impossible the use of matrix sensors. We present some functional block design for an ASIC that could replace the electrometer and the cabling for the measurements. The system will be realized by an hybrid assembly with the detector, or the detector matrix, very closely placed and wire bonded to the readout ASIC. The device is designed in 180 nm UMC technology with dual power supply, 3.3 V for the analog front end, in order to extend the signal dynamic, and 1.8 V for the control logic.",F. Petulla; F. de Notaristefani; V. O. Cencelli; E. D'Abramo; A. Fabbri; D. Riondino; M. Marinelli; G. Verona-Rinati,,,Low overdrive voltage and low current compact comparator for a diamond dosimeter ASIC,,,10.1109/NSSMIC.2008.4774859 ,IEEE Conferences ,,"The dosimeters for radiotherapy must comply to strict requirements in terms of sensitivity, toxicity, tissue equivalence and radiation hardness. At present time both silicon and diamond dosimeters are used as solid state devices and in recent years, monocrystalline diamond sensors have been grown with CVD techniques. Due to the low current signals, the sensor readout is made by electrometers connected to the device with multi wire shielded cables. This measurement setup may be a serious limitation for practical application of these sensors, and makes impossible the use of matrix sensors. We present some functional block design for an ASIC that could replace the electrometer and the cabling for the measurements. The system will be realized by an hybrid assembly with the detector, or the detector matrix, very closely placed and wire bonded to the readout ASIC. The device is designed in 180 nm UMC technology with dual power supply, 3.3 V for the analog front end, in order to extend the signal dynamic, and 1.8 V for the control logic.",1082-3654,,978-1-4244-2714-7,2043-2047,IEEE , ,Low voltage;Application specific integrated circuits;Wire;Cable shielding;Detectors;Silicon;Solid state circuits;Assembly systems;Bonding;Signal design,,
4831,"Title:Novel Smoke-Aware Individual Evacuation and Congestion-Aware Group Evacuation Algorithms in IoT-Enabled Multi-Story Multi-Exit Buildings

 Because of toxic gases and fast propagation speed, smoke causes the major injuries and deaths than burns in the fire. Deploying IoT enabled smoke sensors not only help to sense, collect, and transmit the smoke data to the control station, but also enable a dynamic and real-time evacuation approach to increase the evacuation success probability. In this paper, two smoke-aware evacuation approaches are proposed. The individual evacuation mathematical model and the associated SIEP algorithm are first devised to identify a fastest smoke toxic safe evacuation path for an evacuee. Next, the group evacuation mathematical model and the associated SGEP algorithm are devised to evacuate as many evacuees as possible in considering the smoke toxicity and flow congestion along the evacuation routes. SGEP circumvents the congestion problem by scheduling the evacuation sequence according to evacuee’s accumulated smoke toxicity value, where higher accumulated smoke toxicity value has higher evacuation priority to prevent incapacitation at evacuation. The FDS simulations based on the real layout of Taipei 101 mall are performed to compare the evacuation success probability between SIEP and SGEP at methane fire and PVC fire. The simulation results show that smoke from PVC fire is more toxic than that of methane fire. In addition, enabling sprinklers can reduce the percentage of toxic nodes up to 41% at methane fire and up to 10% at PCV fire, as compared to not enabling them. These results indicate that it is more challenging to evacuate at PVC fire than at methane fire. The simulation results in SGEP and SIEP justify the above conclusions where the success evacuation probability differences between methane fire and PVC fire are up to 39% (i.e., 100% and 61%) and 52.5% (i.e., 82.5% and 30%) for SGEP and SIEP, respectively. The simulation results also show that SGEP outperforms SIEP in terms of evacuation success probability at all simulation settings, especially when large number of evacuees are to be evacuated. At methane fire, the largest evacuation success probability difference between SGEP and SIEP is 68.1% at 1000 evacuees, 0.3 FED threshold and without sprinklers. At PVC fire, the largest difference is 50% at 1000 evacuees, 0.5 FED threshold and with sprinklers. These significant differences in evacuation success probability come from the evacuation congestion in SIEP. The evacuation scheduling approach based on accumulated smoke toxicity policy enables SGEP to circumvent the evacuation congestion, and to get better evacuation success probability. Besides identifying safe evacuation route and evacuation scheduling policy during congestion to evacuate more evacuees, another contribution of this paper is to identify the critical percentage of toxic nodes for safe fire evacuation and rescue operations.",H. -H. Yen; C. -H. Lin; H. -W. Tsao,,,Novel Smoke-Aware Individual Evacuation and Congestion-Aware Group Evacuation Algorithms in IoT-Enabled Multi-Story Multi-Exit Buildings,10,,10.1109/ACCESS.2022.3221757 ,IEEE Journals ,,"Because of toxic gases and fast propagation speed, smoke causes the major injuries and deaths than burns in the fire. Deploying IoT enabled smoke sensors not only help to sense, collect, and transmit the smoke data to the control station, but also enable a dynamic and real-time evacuation approach to increase the evacuation success probability. In this paper, two smoke-aware evacuation approaches are proposed. The individual evacuation mathematical model and the associated SIEP algorithm are first devised to identify a fastest smoke toxic safe evacuation path for an evacuee. Next, the group evacuation mathematical model and the associated SGEP algorithm are devised to evacuate as many evacuees as possible in considering the smoke toxicity and flow congestion along the evacuation routes. SGEP circumvents the congestion problem by scheduling the evacuation sequence according to evacuee’s accumulated smoke toxicity value, where higher accumulated smoke toxicity value has higher evacuation priority to prevent incapacitation at evacuation. The FDS simulations based on the real layout of Taipei 101 mall are performed to compare the evacuation success probability between SIEP and SGEP at methane fire and PVC fire. The simulation results show that smoke from PVC fire is more toxic than that of methane fire. In addition, enabling sprinklers can reduce the percentage of toxic nodes up to 41% at methane fire and up to 10% at PCV fire, as compared to not enabling them. These results indicate that it is more challenging to evacuate at PVC fire than at methane fire. The simulation results in SGEP and SIEP justify the above conclusions where the success evacuation probability differences between methane fire and PVC fire are up to 39% (i.e., 100% and 61%) and 52.5% (i.e., 82.5% and 30%) for SGEP and SIEP, respectively. The simulation results also show that SGEP outperforms SIEP in terms of evacuation success probability at all simulation settings, especially when large number of evacuees are to be evacuated. At methane fire, the largest evacuation success probability difference between SGEP and SIEP is 68.1% at 1000 evacuees, 0.3 FED threshold and without sprinklers. At PVC fire, the largest difference is 50% at 1000 evacuees, 0.5 FED threshold and with sprinklers. These significant differences in evacuation success probability come from the evacuation congestion in SIEP. The evacuation scheduling approach based on accumulated smoke toxicity policy enables SGEP to circumvent the evacuation congestion, and to get better evacuation success probability. Besides identifying safe evacuation route and evacuation scheduling policy during congestion to evacuate more evacuees, another contribution of this paper is to identify the critical percentage of toxic nodes for safe fire evacuation and rescue operations.",2169-3536,,,119402-119418,IEEE , ,Fires;Temperature sensors;Heating systems;Gases;Toxicology;Escalators;Methane;Mathematical models;Heuristic algorithms;Real-time systems;Hazardous areas;Emergency services;Smoke detectors;Safety,,
4832,"Title:Soil treatment using ozone and nitric monoxide produced by pulsed discharge

 Summary form only given. Usage of methyl bromide (CH3Br) for soil sterilization in the agricultural fields was forbidden due to its green house effect. Development of alternative soil sterilization techniques has been an urgent subject. We have proposed a soil treatment using ozone and nitric monoxide (NO) gas. Sterilization of soil using ozone gas seems attractive due to its strong sterilization and no residual toxicity properties. Ozone of high concentration was produced by pulsed RF discharge with high yield, and optimal condition was surveyed under various electrode configurations, applied voltages and duty ratios. NO gas was generated using pulsed arc discharges in the air. Effects of ozone and NO gas on the soil properties such as pH, electrical conductivity (EC), oxidation reduction potential (Eh), and temperature was examined using various sensors. Ozone injected into soil decreased pH and increased EC and temperature of the soil due to oxidization. It was also found ozone sterilized some kinds of bacteria in the soil",T. Ikegami; K. Ogata; K. Ebihara; K. Nagira; T. Kai,,,Soil treatment using ozone and nitric monoxide produced by pulsed discharge,,,10.1109/PLASMA.2006.1707078 ,IEEE Conferences ,,"Summary form only given. Usage of methyl bromide (CH3Br) for soil sterilization in the agricultural fields was forbidden due to its green house effect. Development of alternative soil sterilization techniques has been an urgent subject. We have proposed a soil treatment using ozone and nitric monoxide (NO) gas. Sterilization of soil using ozone gas seems attractive due to its strong sterilization and no residual toxicity properties. Ozone of high concentration was produced by pulsed RF discharge with high yield, and optimal condition was surveyed under various electrode configurations, applied voltages and duty ratios. NO gas was generated using pulsed arc discharges in the air. Effects of ozone and NO gas on the soil properties such as pH, electrical conductivity (EC), oxidation reduction potential (Eh), and temperature was examined using various sensors. Ozone injected into soil decreased pH and increased EC and temperature of the soil due to oxidization. It was also found ozone sterilized some kinds of bacteria in the soil",0730-9244,,1-4244-0125-9,206-206,IEEE , ,Temperature sensors;Radio frequency;Electrodes;Voltage;Pulse generation;Arc discharges;Soil properties;Conductivity;Oxidation;Gas detectors,,
4833,"Title:Low cost and optical detection from fluorescence of Ochratoxin A

 Ochratoxin A (OTA) is one of the most abundant food-contaminating mycotoxins, is detected worldwide in various food and feed sources and its toxicity in animals is more potent than other metabolites. Detected by the analytical methods, in spite of their high sensitivity, these methods are not suitable for analysis in-situ. Hence, this work consists to develop a low cost and portable system to quantify the concentrations of OTA through ownership of fluorescence. That occurs when it is excited with ultraviolet light (UV) at 375nm. First, an UV emitter and a silicon photodiodes were used; the limit of detection (LOD) was 250 ng/mL, a battery as source and an acquisition system with LabVIEW to process the information in a computer. To detect lower levels, a camera and red, blue and green (RGB) components were employed. The LOD was 5 μg/L. The camera detected the fluorescence in the sample when this was excited with UV light, the variation in the intensity of the color is measured and it has relation with the concentration of the sample.",D. Bueno; R. Munoz; J. L. Marty,,,Low cost and optical detection from fluorescence of Ochratoxin A,,,10.1109/GMEPE-PAHCE.2017.7972087 ,IEEE Conferences ,,"Ochratoxin A (OTA) is one of the most abundant food-contaminating mycotoxins, is detected worldwide in various food and feed sources and its toxicity in animals is more potent than other metabolites. Detected by the analytical methods, in spite of their high sensitivity, these methods are not suitable for analysis in-situ. Hence, this work consists to develop a low cost and portable system to quantify the concentrations of OTA through ownership of fluorescence. That occurs when it is excited with ultraviolet light (UV) at 375nm. First, an UV emitter and a silicon photodiodes were used; the limit of detection (LOD) was 250 ng/mL, a battery as source and an acquisition system with LabVIEW to process the information in a computer. To detect lower levels, a camera and red, blue and green (RGB) components were employed. The LOD was 5 μg/L. The camera detected the fluorescence in the sample when this was excited with UV light, the variation in the intensity of the color is measured and it has relation with the concentration of the sample.",2327-817X,,978-1-5386-1520-1,1-4,IEEE , ,Fluorescence;Sensor arrays;Detectors;Optical sensors;Light emitting diodes;Photodetectors;Biomedical optical imaging,,
4834,"Title:Revealing the structural details of huntingtin fibrils using small-angle neutron scattering

 Huntington's disease (HD) involves an abnormally expanded polyglutamine sequence in huntingtin (Htt) protein that makes it highly susceptible to aggregate. A current challenge is to map out the aggregation pathway by identifying the various precursor structures and establishing their roles in the disease. While it is highly suspected that the early oligomer species are responsible for toxicity, characterizing the end-state fibril structure is also a necessary step toward discovering the underlying mechanisms of early aggregate formation. We are actively investigating Htt structural kinetics and the resulting fibrils using small-angle neutron scattering (SANS). Here, we report on the characterization of fibrils from Htt-exon1-Q40 - a disease relevant Htt peptide as it contains a pathologically expanded glutamine repeat sequence and a proline-rich region. SANS on the end-state fibrils revealed structural similarities to the Perutz β-helixhollow cylinder model as opposed to the more commonly observed steric zipper structure found for many other amyloid fibrils. The structural details we have identified contribute toward elucidating the mechanism of pathological Htt assembly.",C. Stanley; H. P. McWilliams-Koeppen; T. Perevozchikova; E. L. Rowe; V. Berthelier,,,Revealing the structural details of huntingtin fibrils using small-angle neutron scattering,,,10.1109/BSEC.2014.6867753 ,IEEE Conferences ,,"Huntington's disease (HD) involves an abnormally expanded polyglutamine sequence in huntingtin (Htt) protein that makes it highly susceptible to aggregate. A current challenge is to map out the aggregation pathway by identifying the various precursor structures and establishing their roles in the disease. While it is highly suspected that the early oligomer species are responsible for toxicity, characterizing the end-state fibril structure is also a necessary step toward discovering the underlying mechanisms of early aggregate formation. We are actively investigating Htt structural kinetics and the resulting fibrils using small-angle neutron scattering (SANS). Here, we report on the characterization of fibrils from Htt-exon1-Q40 - a disease relevant Htt peptide as it contains a pathologically expanded glutamine repeat sequence and a proline-rich region. SANS on the end-state fibrils revealed structural similarities to the Perutz β-helixhollow cylinder model as opposed to the more commonly observed steric zipper structure found for many other amyloid fibrils. The structural details we have identified contribute toward elucidating the mechanism of pathological Htt assembly.",,,978-1-4799-4159-9,1-4,IEEE , ,Storage area networks;Scattering;Peptides;Diseases;Proteins;Aggregates;Detectors,,
4835,"Title:Hydrogen Sulfide (H2S) Gas Sensor: A Review

 This paper reviews the most important sensor-based methods that are commonly utilized for detecting and measuring hydrogen sulfide (H2S) gas. It identifies a quite comprehensive overview related to the toxicity and hazardous effects of H2S gas from an individual and environmental health protection perspective. Furthermore, the description, classification, and comparison of the H2S gas sensing technologies are exhibited according to many criteria, such as sensing material, working principle, limit of detection, response time, operating range of gas concentrations, sensor stability, sensitivity, and selectivity toward H2S. Finally, it identifies the limitations of these sensors, suggests the most probably successful future technologies, and highlights the most promising approaches that have been developed for achieving inexpensive hydrogen sulfide gas sensors which could be employed in widespread miniaturized detectors in the real-world applications.",F. I. M. Ali; F. Awwad; Y. E. Greish; S. T. Mahmoud,,,Hydrogen Sulfide (H2S) Gas Sensor: A Review,19,7,10.1109/JSEN.2018.2886131 ,IEEE Journals ,,"This paper reviews the most important sensor-based methods that are commonly utilized for detecting and measuring hydrogen sulfide (H2S) gas. It identifies a quite comprehensive overview related to the toxicity and hazardous effects of H2S gas from an individual and environmental health protection perspective. Furthermore, the description, classification, and comparison of the H2S gas sensing technologies are exhibited according to many criteria, such as sensing material, working principle, limit of detection, response time, operating range of gas concentrations, sensor stability, sensitivity, and selectivity toward H2S. Finally, it identifies the limitations of these sensors, suggests the most probably successful future technologies, and highlights the most promising approaches that have been developed for achieving inexpensive hydrogen sulfide gas sensors which could be employed in widespread miniaturized detectors in the real-world applications.",1558-1748,,,2394-2407,IEEE , ,Gas detectors;Hydrogen;Temperature sensors;Electrolytes;Optical fiber sensors,,
4836,"Title:Lead-Free CsCu2I3 Perovskite Nanostructured Networks Gas Sensor for Selective Detection of Trace Nitrogen Dioxide at Room Temperature

 The development of low power consumption sensing devices for detecting trace toxic gases is imperative for a wide variety of applications. Recently, hybrid organic–inorganic lead perovskite-based sensors have been fabricated to demonstrate their potential for gas sensing application. However, the poor repeatability and toxicity of lead halide perovskites severely restrict their further practical applications. Here, the lead-free all-inorganic cesium copper iodide (CsCu2I3) perovskite nanostructured networks are deposited onto interdigital electrodes patterned substrate as the gas sensitive layer via simply spin coating the precursors. The sensor exhibites excellent room temperature NO2 sensing properties, including ultra-low limit of detection, excellent repeatability, and good selectivity. Dynamic testing displays the good cycling repeatability of the sensor for ppb level NO2. The ultra-sensitive NO2 sensing behavior of the CsCu2I3 nanostructure networks are mainly attributed to the unique nanoneedle clusters network structure and large amount of cation vacancies on the perovskite surface. In conclusion, the high sensitivity and environmentally friendly CsCu2I3 sensor shows great potential for trace indoor pollutants detection and breathe analysis for disease diagnosis.",X. Sun; J. Yang; Z. Wu; G. Meng; X. Guo; D. Kuang; L. Xiong; W. Qu; X. Fang; X. Yang; X. Tang; Y. He,,,Lead-Free CsCu2I3 Perovskite Nanostructured Networks Gas Sensor for Selective Detection of Trace Nitrogen Dioxide at Room Temperature,21,13,10.1109/JSEN.2021.3071744 ,IEEE Journals ,,"The development of low power consumption sensing devices for detecting trace toxic gases is imperative for a wide variety of applications. Recently, hybrid organic–inorganic lead perovskite-based sensors have been fabricated to demonstrate their potential for gas sensing application. However, the poor repeatability and toxicity of lead halide perovskites severely restrict their further practical applications. Here, the lead-free all-inorganic cesium copper iodide (CsCu2I3) perovskite nanostructured networks are deposited onto interdigital electrodes patterned substrate as the gas sensitive layer via simply spin coating the precursors. The sensor exhibites excellent room temperature NO2 sensing properties, including ultra-low limit of detection, excellent repeatability, and good selectivity. Dynamic testing displays the good cycling repeatability of the sensor for ppb level NO2. The ultra-sensitive NO2 sensing behavior of the CsCu2I3 nanostructure networks are mainly attributed to the unique nanoneedle clusters network structure and large amount of cation vacancies on the perovskite surface. In conclusion, the high sensitivity and environmentally friendly CsCu2I3 sensor shows great potential for trace indoor pollutants detection and breathe analysis for disease diagnosis.",1558-1748,,,14677-14684,IEEE , ,Sensors;Gas detectors;Lead;Temperature sensors;Substrates;Crystals;Solvents,,
4837,"Title:Contaminant flux measurements across the sediment-water interface in San Diego Bay

 Marine sediments often serve as important sinks for anthropogenic contaminants from the overlying water column. In certain cases the sediments may also serve as contaminant sources, releasing contaminants later when water column and/or pore water conditions change. Variations in sediment chemical and physical properties make it impossible to rely on bulk sediment contaminant concentrations alone to predict contaminant flux, bioavailability, and therefore toxicity. In situ measurements of contaminant fluxes across the sediment-water interface provide important information for addressing these concerns. The Navy has recently developed the Benthic Flux Sampling Device (BFSD) to assess contaminant fluxes across the sediment-water interface. The BFSD has recently undergone several modifications to allow improved operation. The oxygen regulation system has been modified to allow better control of chamber oxygen levels. Some deployments have utilized real-time sensors that allow monitoring of BFSD operations and offer the potential to serve as field-screening tools to evaluate contaminant mobility. These real-time sensor techniques include potentiometric stripping analysis (PSA) for metals and laser-induced fluorescence (LIF) for hydrocarbon contaminants. As part of the Navy's ongoing program to monitor environmental conditions in San Diego Bay, this study used multiple deployments of the BFSD to assess contaminant fluxes across the sediment-water interface. In coastal areas, directly measured BFSD fluxes are often preferable to model-dependent fluxes obtained from pore water profiles. Target contaminants in this study included the trace metals Cd, Cu, Ni, Pb, and Zn. Initial results indicate fluxes occur both into and out of the sediments depending on contaminant type and site location. The metals that showed the most consistent flux out of the sediments included Zn and Mn.",J. M. Leather; D. B. Chadwick; G. H. Koon,,,Contaminant flux measurements across the sediment-water interface in San Diego Bay,3,,10.1109/OCEANS.1995.528740 ,IEEE Conferences ,,"Marine sediments often serve as important sinks for anthropogenic contaminants from the overlying water column. In certain cases the sediments may also serve as contaminant sources, releasing contaminants later when water column and/or pore water conditions change. Variations in sediment chemical and physical properties make it impossible to rely on bulk sediment contaminant concentrations alone to predict contaminant flux, bioavailability, and therefore toxicity. In situ measurements of contaminant fluxes across the sediment-water interface provide important information for addressing these concerns. The Navy has recently developed the Benthic Flux Sampling Device (BFSD) to assess contaminant fluxes across the sediment-water interface. The BFSD has recently undergone several modifications to allow improved operation. The oxygen regulation system has been modified to allow better control of chamber oxygen levels. Some deployments have utilized real-time sensors that allow monitoring of BFSD operations and offer the potential to serve as field-screening tools to evaluate contaminant mobility. These real-time sensor techniques include potentiometric stripping analysis (PSA) for metals and laser-induced fluorescence (LIF) for hydrocarbon contaminants. As part of the Navy's ongoing program to monitor environmental conditions in San Diego Bay, this study used multiple deployments of the BFSD to assess contaminant fluxes across the sediment-water interface. In coastal areas, directly measured BFSD fluxes are often preferable to model-dependent fluxes obtained from pore water profiles. Target contaminants in this study included the trace metals Cd, Cu, Ni, Pb, and Zn. Initial results indicate fluxes occur both into and out of the sediments depending on contaminant type and site location. The metals that showed the most consistent flux out of the sediments included Zn and Mn.",,,0-933957-14-9,1700-1713 vol.3,IEEE , ,Pollution measurement;Sediments;Water resources;Zinc;Toxic chemicals;Sampling methods;Control systems;Gas detectors;Laser modes;Fluorescence,,
4838,"Title:Design and Development of Fuzzy Logic Based Car Cabin Pollution Monitoring System

 This paper presents the development of air quality monitoring system based on internet of things, IOT application to control the concentration of carbon dioxide gas and carbon monoxide gas in car cabin. Carbon monoxide is one most dangerous gas and nowadays there were many fatal cases happen caused by the gas leakage, while increasing of the concentration carbon dioxide will reduce oxygen level in the air, thus can cause the driver to be fatigue, and sleepiness. Moreover, gas detector usually not installed in nowadays car. To develop smart air quality monitoring system, Arduino MKR 1010, CJMCU 811(carbon dioxide sensor), MQ-7(carbon monoxide sensor), Adafruit io application, IFTTT, Webhooks, Telegram, and MATLAB fuzzy logic toolbox were used. Furthermore, Fuzzy Logic Controller (FLC) was used to analyze the input and produce the system's output decisions on the level of gas toxicities. The five levels of gas toxicities are very safe, safe, warning, high, and very high. The decision of gas level will be sent to IOT application which is Adafruit and then triggered the three types of LED indicator, power window motor, buzzer, and signal to webhook to send the Telegram. Besides, Adafruit IO also act as the platform to present the data of gases graph pattern. In addition, MATLAB fuzzy logic toolbox was used to make comparison between the result of Arduino analysis with the value of simulation. Furthermore, Telegram messenger also act as a medium to notify the users. Based on the system evaluation, this system has performed well in analysing the gas concentrating inputs and show stable IOT interactions in triggering related warning and safety devices.",M. Z. Bin Kamal Abdul; B. A. Nayan; S. Z. Yahaya; R. Boudville; K. A. Ahmad; N. I. B. Husin,,,Design and Development of Fuzzy Logic Based Car Cabin Pollution Monitoring System,,,10.1109/ICCSCE54767.2022.9935658 ,IEEE Conferences ,,"This paper presents the development of air quality monitoring system based on internet of things, IOT application to control the concentration of carbon dioxide gas and carbon monoxide gas in car cabin. Carbon monoxide is one most dangerous gas and nowadays there were many fatal cases happen caused by the gas leakage, while increasing of the concentration carbon dioxide will reduce oxygen level in the air, thus can cause the driver to be fatigue, and sleepiness. Moreover, gas detector usually not installed in nowadays car. To develop smart air quality monitoring system, Arduino MKR 1010, CJMCU 811(carbon dioxide sensor), MQ-7(carbon monoxide sensor), Adafruit io application, IFTTT, Webhooks, Telegram, and MATLAB fuzzy logic toolbox were used. Furthermore, Fuzzy Logic Controller (FLC) was used to analyze the input and produce the system's output decisions on the level of gas toxicities. The five levels of gas toxicities are very safe, safe, warning, high, and very high. The decision of gas level will be sent to IOT application which is Adafruit and then triggered the three types of LED indicator, power window motor, buzzer, and signal to webhook to send the Telegram. Besides, Adafruit IO also act as the platform to present the data of gases graph pattern. In addition, MATLAB fuzzy logic toolbox was used to make comparison between the result of Arduino analysis with the value of simulation. Furthermore, Telegram messenger also act as a medium to notify the users. Based on the system evaluation, this system has performed well in analysing the gas concentrating inputs and show stable IOT interactions in triggering related warning and safety devices.",,,978-1-6654-8339-1,191-196,IEEE , ,Fuzzy logic;Toxicology;Carbon dioxide;Air quality;Carbon monoxide;Internet of Things;Automobiles,,
4839,"Title:Impact of brominated flame retardants on embryo development of Atlantic Cod (Gadus Morhua) during early life stages

 Brominated flame retardants (BFRs) are ubiquitous industrial chemicals likely to persistently exist in the environment, bioaccumulate in food chains, and even may cause adverse health effects in human. Borgundfjorden fjord system, an important spawning ground for the Norwegian coastal cod (Gadus morhua) stock, was contaminated by significant levels of pollutants such as BFRs, due to the local previous industrial activities. In this study, we demonstrated high level of the BFRs polybrominated biphenyl ethers (PBDEs) and polychlorinated biphenyls (PCBs) in cod liver and gonad samples from Borgundfjorden using mass spectroscopy (MS) detectors by Norwegian National Institute of Nutrition and Seafood Research (NIFES). Acute embryo toxicity test was further conducted using fertilized cod eggs. The eggs were short-term exposed to serial dilutions of five BFRs mixtures, BDE-47, or PCB mixture Aroclor 1254. At a concentration 10 times that detected in cod liver, the mixture of the five BFRs significantly reduced the embryo survival rate (p <; 0.01). Correspondingly, at 224 μg/L, which was around 10 times of that detected in cod liver, BDE-47 exhibited obvious cod embryo toxicity (p <; 0.01). As a positive control, Aroclor 1254 significantly reduced the embryo survival rate at 400 and 1600 μg/L (p <;0.001). This experiment has laid the foundation for further research on environmentally hazardous impact on the reproductive capacity of aquatic organisms, which will directly influence the fish stocks growing potential and thereby the Norwegian fishery activity.",Y. Cao; S. Anne; Y. Harald; E. Kommisrud,,,Impact of brominated flame retardants on embryo development of Atlantic Cod (Gadus Morhua) during early life stages,,,10.1109/OCEANSAP.2016.7485615 ,IEEE Conferences ,,"Brominated flame retardants (BFRs) are ubiquitous industrial chemicals likely to persistently exist in the environment, bioaccumulate in food chains, and even may cause adverse health effects in human. Borgundfjorden fjord system, an important spawning ground for the Norwegian coastal cod (Gadus morhua) stock, was contaminated by significant levels of pollutants such as BFRs, due to the local previous industrial activities. In this study, we demonstrated high level of the BFRs polybrominated biphenyl ethers (PBDEs) and polychlorinated biphenyls (PCBs) in cod liver and gonad samples from Borgundfjorden using mass spectroscopy (MS) detectors by Norwegian National Institute of Nutrition and Seafood Research (NIFES). Acute embryo toxicity test was further conducted using fertilized cod eggs. The eggs were short-term exposed to serial dilutions of five BFRs mixtures, BDE-47, or PCB mixture Aroclor 1254. At a concentration 10 times that detected in cod liver, the mixture of the five BFRs significantly reduced the embryo survival rate (p <; 0.01). Correspondingly, at 224 μg/L, which was around 10 times of that detected in cod liver, BDE-47 exhibited obvious cod embryo toxicity (p <; 0.01). As a positive control, Aroclor 1254 significantly reduced the embryo survival rate at 400 and 1600 μg/L (p <;0.001). This experiment has laid the foundation for further research on environmentally hazardous impact on the reproductive capacity of aquatic organisms, which will directly influence the fish stocks growing potential and thereby the Norwegian fishery activity.",,,978-1-4673-9724-7,1-7,IEEE , ,Embryo;Liver;Chemicals;Fish;Aquaculture;Flame retardants;Sea measurements,,
4840,"Title:Analysis of smoke during prescribed fires

 This work consist in sampling and analyzing smoke released by typical Mediterranean vegetation during a fire. To proceed we used an experimental apparatus made of an air sampling pump with a cartridge filled with Tenaxreg TA. The sampling device was situated in a fixed place corresponding to the position of a fireman for the four studied stations. Analyses were performed at the laboratory by gas chromatography one day after the field experiment. Samples were Thermally Desorbed from the cartridges in the Gas Chromatography column coupled to a detector by Mass Spectrometry. We aim to characterize the risks related to the toxicity of smoke in actual conditions. Benzene, Toluene and Xylene (BTX) are highly toxic compounds that we propose to quantify in the smoke sampled during the fire.",T. Barboni; N. Chiaramonti; E. Leoni; J. -M. Desjobert; P. -A. Santoni,,,Analysis of smoke during prescribed fires,,,10.1109/ISEIMA.2006.345041 ,IEEE Conferences ,,"This work consist in sampling and analyzing smoke released by typical Mediterranean vegetation during a fire. To proceed we used an experimental apparatus made of an air sampling pump with a cartridge filled with Tenaxreg TA. The sampling device was situated in a fixed place corresponding to the position of a fireman for the four studied stations. Analyses were performed at the laboratory by gas chromatography one day after the field experiment. Samples were Thermally Desorbed from the cartridges in the Gas Chromatography column coupled to a detector by Mass Spectrometry. We aim to characterize the risks related to the toxicity of smoke in actual conditions. Benzene, Toluene and Xylene (BTX) are highly toxic compounds that we propose to quantify in the smoke sampled during the fire.",,,1-4244-0231-X,18-23,IEEE , ,Fires;Sampling methods;Cities and towns;Vegetation mapping;Performance analysis;Combustion;Fuels;Sea measurements;Gas chromatography;Blood,,
4841,"Title:A Toxic Content Detection Technique in Sentimental Analysis with Convolution Neural Networks

 In the recent time, the usage of various social media platforms has drastically increased which involves the positive or negative impact on human lives. One of the aspects is directly associated with comment/opinion which individual user/person passes through different social networking sites. This paper provides the discussion on different approaches to analyze classification and modelling techniques for detecting toxic comments using convolution neural networks (CNN). It also specifies algorithm based on outlier detection on given data stream that can evaluate the posted material on social platforms and check its positive and negative impact on the society.",V. Mishra; M. Tripathi,,,A Toxic Content Detection Technique in Sentimental Analysis with Convolution Neural Networks,,,10.1109/CSNT54456.2022.9787588 ,IEEE Conferences ,,"In the recent time, the usage of various social media platforms has drastically increased which involves the positive or negative impact on human lives. One of the aspects is directly associated with comment/opinion which individual user/person passes through different social networking sites. This paper provides the discussion on different approaches to analyze classification and modelling techniques for detecting toxic comments using convolution neural networks (CNN). It also specifies algorithm based on outlier detection on given data stream that can evaluate the posted material on social platforms and check its positive and negative impact on the society.",2329-7182,,978-1-6654-8038-3,398-402,IEEE , ,Analytical models;Social networking (online);Convolution;Communication systems;Conferences;Neural networks;Companies,,
4842,"Title:Automatic Detection of Toxic South African Tweets Using Support Vector Machines with N-Gram Features

 Toxic South African corpus is not available to detect toxic tweets such as offensive, hate, bullying and violent tweets. But there are some offensive and hate speech corpora, mostly in English, which have been used to detect toxic tweets. This paper focuses on automatic detection of toxic South African tweets using a reliable English corpus. The review of text classification models has shown that Support Vector Machines have very often outperformed other classic machine learning algorithms, while word and character n-gram features have performed well with varying prediction performances in different contexts. This paper therefore evaluated the performance of different parameter settings of Support Vector Machines and n-gram features for detection of toxic South African tweets, with a view to hybridize the best among the classifiers. Different combinations of word and character n- gram features were used for the classification. The results show that the Support Vector Machine classifier with set of unigram and bigram as well as set of character n-gram with length sizes from 3 to 7 perform best. By combining the classifiers, the accuracy and F-measure improve from the initial highest Accuracy and F-Measure scores of 0.9085 and 0.94, respectively to 0.9095 and 0.95. The comparison of our results with the performance of previous work on the English corpus shows that our model is reliable.",O. Oriola; E. Kotzé,,,Automatic Detection of Toxic South African Tweets Using Support Vector Machines with N-Gram Features,,,10.1109/ISCMI47871.2019.9004298 ,IEEE Conferences ,,"Toxic South African corpus is not available to detect toxic tweets such as offensive, hate, bullying and violent tweets. But there are some offensive and hate speech corpora, mostly in English, which have been used to detect toxic tweets. This paper focuses on automatic detection of toxic South African tweets using a reliable English corpus. The review of text classification models has shown that Support Vector Machines have very often outperformed other classic machine learning algorithms, while word and character n-gram features have performed well with varying prediction performances in different contexts. This paper therefore evaluated the performance of different parameter settings of Support Vector Machines and n-gram features for detection of toxic South African tweets, with a view to hybridize the best among the classifiers. Different combinations of word and character n- gram features were used for the classification. The results show that the Support Vector Machine classifier with set of unigram and bigram as well as set of character n-gram with length sizes from 3 to 7 perform best. By combining the classifiers, the accuracy and F-measure improve from the initial highest Accuracy and F-Measure scores of 0.9085 and 0.94, respectively to 0.9095 and 0.95. The comparison of our results with the performance of previous work on the English corpus shows that our model is reliable.",2640-0146,,978-1-7281-4577-8,126-130,IEEE , ,Support vector machines;Training;Feature extraction;Standards;Testing;Twitter;Logistics,,
4843,"Title:Toxic Comment Classification For French Online Comments

 In this paper, we propose a supervised approach for toxic comment classification for French language. We choose a set of features proposed for toxic comment detection for English and use it for French toxic comment detection. Our approach is based on N-gram features, linguistic features and a dictionary of insulting words and expressions. We obtain a F1-score of 78% with N-grams, linguistic and lexicon features, a precision of 87% with N-gram features and a recall of 83% with N-gram, linguistic and lexicon features. Classifier used are linear SVM and decision tree.",N. Boudjani; Y. Haralambous; I. Lyubareva,,,Toxic Comment Classification For French Online Comments,,,10.1109/ICMLA51294.2020.00164 ,IEEE Conferences ,,"In this paper, we propose a supervised approach for toxic comment classification for French language. We choose a set of features proposed for toxic comment detection for English and use it for French toxic comment detection. Our approach is based on N-gram features, linguistic features and a dictionary of insulting words and expressions. We obtain a F1-score of 78% with N-grams, linguistic and lexicon features, a precision of 87% with N-gram features and a recall of 83% with N-gram, linguistic and lexicon features. Classifier used are linear SVM and decision tree.",,,978-1-7281-8470-8,1010-1014,IEEE , ,Support vector machines;Dictionaries;Conferences;Machine learning;Linguistics;Feature extraction;Decision trees,,
4844,"Title:Toxic Speech Classification using Machine Learning Algorithms

 In today's era of online social media platforms, there has been a massive surge in the propagation of toxic content speech. They provide many betterments. However, persons with considerable differences in their viewpoints have contributed to an increase in lethality of people in internet posts and debates.. With the outbreak of the pandemic, corporations, educational institutions, students, and the general public have all increased their usage in web sites. For a long time, the growing popularity of internet platforms like Twitter and Facebook has been a major cause of anxiety. These platforms not only allow for improved communication, but they also allow the users to express their thoughts, which are quickly shared with the rest of the world. Furthermore, given the diversity of these platforms' users' histories, beliefs, race, and customs, many of them choose to use disparaging, abusive, and antagonistic language while interacting with those who do not share their background. This online toxicity has been increasing exponentially by advancements provided by these social media platforms in this emerging world under the cloud of anonymity. Unlike manually, this problem can be solved using Machine Learning. Phrases like “Obscene”,”Toxic”, “Severe Toxic”,”Threat”, “Insult”,”Identity Hate” are used mutually and hence have been incorporated under “Toxic” speech content. As a result, it is vital to recognise and eliminate toxic speech from internet - based social media networks naturally. The numerous varieties of Machine Learning approaches, such as traditional Machine Learning, ensemble approach are explored in this paper. We use a corpus collected from online platform twitter to do binary and multi-class classification and investigate two techniques.: (a) a method which consists in extracting of word embeddings and then generating the model; (b)Improving the existing models- RF, DT, VC, LR, KNN. Any other sort of social media comment can be analyzed using the proposed methods. By this, we developed a model that can classify given comments into different categories of toxicity with greater precision, recall, and accuracy score.",P. Sumanth; S. Samiuddin; K. Jamal; S. Domakonda; P. Shivani,,,Toxic Speech Classification using Machine Learning Algorithms,,,10.1109/ICESIC53714.2022.9783475 ,IEEE Conferences ,,"In today's era of online social media platforms, there has been a massive surge in the propagation of toxic content speech. They provide many betterments. However, persons with considerable differences in their viewpoints have contributed to an increase in lethality of people in internet posts and debates.. With the outbreak of the pandemic, corporations, educational institutions, students, and the general public have all increased their usage in web sites. For a long time, the growing popularity of internet platforms like Twitter and Facebook has been a major cause of anxiety. These platforms not only allow for improved communication, but they also allow the users to express their thoughts, which are quickly shared with the rest of the world. Furthermore, given the diversity of these platforms' users' histories, beliefs, race, and customs, many of them choose to use disparaging, abusive, and antagonistic language while interacting with those who do not share their background. This online toxicity has been increasing exponentially by advancements provided by these social media platforms in this emerging world under the cloud of anonymity. Unlike manually, this problem can be solved using Machine Learning. Phrases like “Obscene”,”Toxic”, “Severe Toxic”,”Threat”, “Insult”,”Identity Hate” are used mutually and hence have been incorporated under “Toxic” speech content. As a result, it is vital to recognise and eliminate toxic speech from internet - based social media networks naturally. The numerous varieties of Machine Learning approaches, such as traditional Machine Learning, ensemble approach are explored in this paper. We use a corpus collected from online platform twitter to do binary and multi-class classification and investigate two techniques.: (a) a method which consists in extracting of word embeddings and then generating the model; (b)Improving the existing models- RF, DT, VC, LR, KNN. Any other sort of social media comment can be analyzed using the proposed methods. By this, we developed a model that can classify given comments into different categories of toxicity with greater precision, recall, and accuracy score.",,,978-1-6654-8385-8,257-263,IEEE , ,Machine learning algorithms;Social networking (online);Blogs;Machine learning;Content management;Information integrity;Behavioral sciences;Fake news;Cultural diferences,,
4845,"Title:Toxic Speech Detection using Traditional Machine Learning Models and BERT and fastText Embedding with Deep Neural Networks

 The introduction of social media brought about a revolution in the world of digitalization and communication. These platforms were initially developed with a purpose of connecting people across the global boundaries while allowing them to express their views and opinions and learn from others' ideas. With the incoming of the pandemic, the usage of these sites has risen significantly be it by the businesses, educational institutions, students or general public. The increasing ubiquity of social media platforms like Twitter and Facebook has been an issue of major concern since a long time. Along with providing a way for enhanced communication, these platforms also allow internet users to voice their opinions which get circulated among the masses within seconds. Moreover, given the different backgrounds, believes, ethnicity and cultures that the users on these platforms come from, many of them tend to use mean, aggressive and hateful content during their discussions with people not hailing from a background similar to theirs. The amount of hate speech and offensive content has been increasing exponentially. Terms like ""profane"", ""hate"", and ""offensive"" are used interchangeably, and hence these have been classified under a broader category of ""Toxic"" content. A major part of our dataset focuses on conversations prevailing among the youth. After the preprocessing of this dataset using NLP and embeddings (Bert and fastText), a bunch of Machine Learning (LR, SVM, DT, RF, XGBoost) and Deep Learning algorithms (CNN, MLP, LSTM) have been performed, with CNN giving the best results.",P. Malik; A. Aggrawal; D. K. Vishwakarma,,,Toxic Speech Detection using Traditional Machine Learning Models and BERT and fastText Embedding with Deep Neural Networks,,,10.1109/ICCMC51019.2021.9418395 ,IEEE Conferences ,,"The introduction of social media brought about a revolution in the world of digitalization and communication. These platforms were initially developed with a purpose of connecting people across the global boundaries while allowing them to express their views and opinions and learn from others' ideas. With the incoming of the pandemic, the usage of these sites has risen significantly be it by the businesses, educational institutions, students or general public. The increasing ubiquity of social media platforms like Twitter and Facebook has been an issue of major concern since a long time. Along with providing a way for enhanced communication, these platforms also allow internet users to voice their opinions which get circulated among the masses within seconds. Moreover, given the different backgrounds, believes, ethnicity and cultures that the users on these platforms come from, many of them tend to use mean, aggressive and hateful content during their discussions with people not hailing from a background similar to theirs. The amount of hate speech and offensive content has been increasing exponentially. Terms like ""profane"", ""hate"", and ""offensive"" are used interchangeably, and hence these have been classified under a broader category of ""Toxic"" content. A major part of our dataset focuses on conversations prevailing among the youth. After the preprocessing of this dataset using NLP and embeddings (Bert and fastText), a bunch of Machine Learning (LR, SVM, DT, RF, XGBoost) and Deep Learning algorithms (CNN, MLP, LSTM) have been performed, with CNN giving the best results.",,,978-1-6654-0360-3,1254-1259,IEEE , ,Voice activity detection;Support vector machines;Radio frequency;Deep learning;Machine learning algorithms;Social networking (online);Pandemics,,
4846,"Title:Bangla Toxic Comment Classification and Severity Measure Using Deep Learning

 Online users nowadays leave a lot of comments on various social networks, news websites, and forums. Certain comments are harmful or abusive. Since it is impractical to manually monitor so many comments, the majority of systems employ some form of a machine learning model to automatically identify harmful content. Much of the work has been done for the English language. However, only a few approaches have been taken to classify toxic comments in the Bangla language. A multi-label classification technique for Bangla comments is offered in the study that follows to classify the numerous toxic comments into six categories: toxic, severe toxic, obscene, threat, insult, and identity hate, and also measure the severity of these comments. For the experiment, we compiled a dataset of 12634 comments from TikTok and other sources. By incorporating knowledge from earlier proposed studies, the proposed classification model was developed utilizing deep learning techniques, specifically Long Short-Term Memory (LSTM) and Long Short-Term Memory-Convolutional Neural Networks (LSTM-CNNs), as well as word embeddings and obtained a maximum accuracy of 83.66% and 1.61 MSE loss for the severity measure.11https://github.com/imbodrulalam/Toxic-Comment-Detection-BN",N. Haque; M. B. Alam; A. A. Towfiq; M. Hossain,,,Bangla Toxic Comment Classification and Severity Measure Using Deep Learning,,,10.1109/ICRPSET57982.2022.10188551 ,IEEE Conferences ,,"Online users nowadays leave a lot of comments on various social networks, news websites, and forums. Certain comments are harmful or abusive. Since it is impractical to manually monitor so many comments, the majority of systems employ some form of a machine learning model to automatically identify harmful content. Much of the work has been done for the English language. However, only a few approaches have been taken to classify toxic comments in the Bangla language. A multi-label classification technique for Bangla comments is offered in the study that follows to classify the numerous toxic comments into six categories: toxic, severe toxic, obscene, threat, insult, and identity hate, and also measure the severity of these comments. For the experiment, we compiled a dataset of 12634 comments from TikTok and other sources. By incorporating knowledge from earlier proposed studies, the proposed classification model was developed utilizing deep learning techniques, specifically Long Short-Term Memory (LSTM) and Long Short-Term Memory-Convolutional Neural Networks (LSTM-CNNs), as well as word embeddings and obtained a maximum accuracy of 83.66% and 1.61 MSE loss for the severity measure.11https://github.com/imbodrulalam/Toxic-Comment-Detection-BN",,,979-8-3503-3270-4,1-5,IEEE , ,Deep learning;Resistance;Knowledge engineering;Social networking (online);Neural networks;Loss measurement;Electrical resistance measurement,,
4847,"Title:A Survey on Continuous Object Tracking and Boundary Detection Schemes in IoT Assisted Wireless Sensor Networks

 With the new age of data innovation, the Internet of Things (IoT) proliferation has drawn enormous thought and has applied to help applications in different fields i.e., natural assurance, military observing, and industrial applications. WSNs are the essential segment of IoT for monitoring as well as tracking. The most preeminent applications provide confinement and identification of continuous objects i.e. wildfire, toxic gas, bio synthetics concoctions, and so forth. In the case of continuous objects such as fire and toxic gases are detected to identify the boundary of damage and alert teams for rescue efforts. It is also helpful in identifying safe paths for rescue. We have investigated various existing surveys that carried out different concepts associated with continuous object tracking and find out the deficit of boundary detection of object. In order to replete the present cleft of analysis, we have inspected various current state-of-the-art works on boundary detection of a continuous object that has yet not been added to the current writing. This paper presents an extensive overview of different continuous object tracking schemes which involve energy efficiency, boundary detection, communication, data aggregation, and network structural design in literature with the aid of featuring taxonomy. We summarized, compared, and classified these schemes along with their analysis and performance. Moreover, for further evaluation mechanism, strengths and weaknesses of these schemes are presented. Finally, various state-of-the-art open research challenges are identified. Moreover, there is a need to overcome these challenges through novel and reliable arrangements by the researchers.",A. Ullah; N. Ishaq; M. Azeem; H. Ashraf; N. Z. Jhanjhi; M. Humayun; T. A. Tabbakh; Z. A. Almusaylim,,,A Survey on Continuous Object Tracking and Boundary Detection Schemes in IoT Assisted Wireless Sensor Networks,9,,10.1109/ACCESS.2021.3110203 ,IEEE Journals ,,"With the new age of data innovation, the Internet of Things (IoT) proliferation has drawn enormous thought and has applied to help applications in different fields i.e., natural assurance, military observing, and industrial applications. WSNs are the essential segment of IoT for monitoring as well as tracking. The most preeminent applications provide confinement and identification of continuous objects i.e. wildfire, toxic gas, bio synthetics concoctions, and so forth. In the case of continuous objects such as fire and toxic gases are detected to identify the boundary of damage and alert teams for rescue efforts. It is also helpful in identifying safe paths for rescue. We have investigated various existing surveys that carried out different concepts associated with continuous object tracking and find out the deficit of boundary detection of object. In order to replete the present cleft of analysis, we have inspected various current state-of-the-art works on boundary detection of a continuous object that has yet not been added to the current writing. This paper presents an extensive overview of different continuous object tracking schemes which involve energy efficiency, boundary detection, communication, data aggregation, and network structural design in literature with the aid of featuring taxonomy. We summarized, compared, and classified these schemes along with their analysis and performance. Moreover, for further evaluation mechanism, strengths and weaknesses of these schemes are presented. Finally, various state-of-the-art open research challenges are identified. Moreover, there is a need to overcome these challenges through novel and reliable arrangements by the researchers.",2169-3536,,,126324-126336,IEEE , ,Target tracking;Object tracking;Wireless sensor networks;Sensors;Monitoring;Energy efficiency;Object detection,,
4848,"Title:Arabic hate speech detection system based on AraBERT

 Tunisia has entered a phase freedom of speech with access to social media since the Jasmine Revolution in 2011. Toxic contents such as abusive and hateful speeches have become omnipresent on Tunisian social media. Considering the side effects of these toxic contents on the psychology of users, it is necessary to detect them automatically. The dialect of Tunisian is underrepresented. As a consequence, there is not enough data set. In this paper, we present the data collection process with the aim of having a Tunisian reference dataset, to evaluate different models of hate speech and abuse detection. We also present our neural network model based on AraBERT. Our experimental results on our dataset shows that the AraBERT model performs better with an F1 score of 0.99.",P. O. Salomon; Z. Kechaou; A. Wali,,,Arabic hate speech detection system based on AraBERT,,,10.1109/ICCICC57084.2022.10101577 ,IEEE Conferences ,,"Tunisia has entered a phase freedom of speech with access to social media since the Jasmine Revolution in 2011. Toxic contents such as abusive and hateful speeches have become omnipresent on Tunisian social media. Considering the side effects of these toxic contents on the psychology of users, it is necessary to detect them automatically. The dialect of Tunisian is underrepresented. As a consequence, there is not enough data set. In this paper, we present the data collection process with the aim of having a Tunisian reference dataset, to evaluate different models of hate speech and abuse detection. We also present our neural network model based on AraBERT. Our experimental results on our dataset shows that the AraBERT model performs better with an F1 score of 0.99.",,,978-1-6654-9084-9,208-213,IEEE , ,Social networking (online);Computational modeling;Hate speech;Neural networks;Psychology;Data collection;Data models,,
4849,"Title:BERT and fastText Embeddings for Automatic Detection of Toxic Speech

 With the expansion of Internet usage, catering to the dissemination of thoughts and expressions of an individual, there has been an immense increase in the spread of online hate speech. Social media, community forums, discussion platforms are few examples of common playground of online discussions where people are freely allowed to communicate. However, the freedom of speech may be misused by some people by arguing aggressively, offending others and spreading verbal violence. As there is no clear distinction between the terms offensive, abusive, hate and toxic speech, in this paper we consider the above mentioned terms as toxic speech. In many countries, online toxic speech is punishable by the law. Thus, it is important to automatically detect and remove toxic speech from online medias. Through this work, we propose automatic classification of toxic speech using embedding representations of words and deep-learning techniques. We perform binary and multi-class classification using a Twitter corpus and study two approaches: (a) a method which consists in extracting of word embeddings and then using a DNN classifier; (b) fine-tuning the pre-trained BERT model. We observed that BERT fine-tuning performed much better. Proposed methodology can be used for any other type of social media comments.",A. G. D'Sa; I. Illina; D. Fohr,,,BERT and fastText Embeddings for Automatic Detection of Toxic Speech,,,10.1109/OCTA49274.2020.9151853 ,IEEE Conferences ,,"With the expansion of Internet usage, catering to the dissemination of thoughts and expressions of an individual, there has been an immense increase in the spread of online hate speech. Social media, community forums, discussion platforms are few examples of common playground of online discussions where people are freely allowed to communicate. However, the freedom of speech may be misused by some people by arguing aggressively, offending others and spreading verbal violence. As there is no clear distinction between the terms offensive, abusive, hate and toxic speech, in this paper we consider the above mentioned terms as toxic speech. In many countries, online toxic speech is punishable by the law. Thus, it is important to automatically detect and remove toxic speech from online medias. Through this work, we propose automatic classification of toxic speech using embedding representations of words and deep-learning techniques. We perform binary and multi-class classification using a Twitter corpus and study two approaches: (a) a method which consists in extracting of word embeddings and then using a DNN classifier; (b) fine-tuning the pre-trained BERT model. We observed that BERT fine-tuning performed much better. Proposed methodology can be used for any other type of social media comments.",,,978-1-7281-6403-8,1-5,IEEE , ,Bit error rate;Task analysis;Adaptation models;Data models;Twitter;Natural language processing,,
4850,"Title:Separating Hate Speech from Abusive Language on Indonesian Twitter

 Social media is an effective tool for connecting with people and distributing information. However, many people often use social media to spread hate speech and abusive languages. In contrast to hate speech, abusive languages are frequently used as jokes with no purpose of offending individuals or groups, even though they may contain profanities. As a result, the distinction between hate speech and abusive language is often blurred. In many cases, individuals who spread hate speech may be prosecuted as it has legal implications. Previous research has focused on binary classification of hate speech and normal tweets. This study aims to classify hate speech, abusive language, and normal messages on Indonesian Twitter. Several machine learning models, such as logistic regression and BERT models, are utilized to accomplish text classification tasks. The model's performance is assessed using the F1-Score evaluation metric. The results show that BERT models outperform other models in terms of F1-Score, with the BERT-indobenchmark model, which was pretrained on social media text data, achieving the highest F1-Score of 85.59. This also demonstrates that pretraining the BERT model using social media data improves the classification model significantly. Developing such classification model that can distinguish between hate speech and abusive language would help individuals in preventing the spread of hate speech that has legal implications.",M. A. Ibrahim; N. Tri Maretta Sagala; S. Arifin; R. Nariswari; N. P. Murnaka; P. W. Prasetyo,,,Separating Hate Speech from Abusive Language on Indonesian Twitter,,,10.1109/ICoDSA55874.2022.9862850 ,IEEE Conferences ,,"Social media is an effective tool for connecting with people and distributing information. However, many people often use social media to spread hate speech and abusive languages. In contrast to hate speech, abusive languages are frequently used as jokes with no purpose of offending individuals or groups, even though they may contain profanities. As a result, the distinction between hate speech and abusive language is often blurred. In many cases, individuals who spread hate speech may be prosecuted as it has legal implications. Previous research has focused on binary classification of hate speech and normal tweets. This study aims to classify hate speech, abusive language, and normal messages on Indonesian Twitter. Several machine learning models, such as logistic regression and BERT models, are utilized to accomplish text classification tasks. The model's performance is assessed using the F1-Score evaluation metric. The results show that BERT models outperform other models in terms of F1-Score, with the BERT-indobenchmark model, which was pretrained on social media text data, achieving the highest F1-Score of 85.59. This also demonstrates that pretraining the BERT model using social media data improves the classification model significantly. Developing such classification model that can distinguish between hate speech and abusive language would help individuals in preventing the spread of hate speech that has legal implications.",,,978-1-6654-8665-1,187-191,IEEE , ,Social networking (online);Law;Hate speech;Blogs;Bit error rate;Text categorization;Machine learning,,
4851,"Title:Machine Learning Technology Using Thick Film Gas Sensor Toxic Liquid Detection For Industrial IOT Application

 Right now proposed paper has been made to investigate the affectability, reaction of SnO2 based Pd-doped thick gas sensor for hazardous liquid as for example Vodka, LPG and Whisky identification. 1"" × 1"" alumina matrix material was exploited prevarication of thick film gas sensor. It comprises of a gas touchy layer SnO2 doped with 1% Pd, a conjoin of electrodes underneath the gas detecting layer filling in as a contact cushion for the sensor. Likewise, a radiator component is additionally planned on the posterior of the substrate The affectability of the sensor has been learned at various Pd-doped concentration (1 % Pd doped) at a constants temperature 3000C upon exposure Vodka, LPG & Whisky. In this paper, experimental results simulate in Anaconda software with the Spyder tool (Spyder 3) tool using the python programming language. Python programming is written in machine learning clustering techniques and simulated results match the experimental results with different temperatures. Industrial internet of things predominantly exploited in the frame of reference for industry 4.0. In the proposed paper, IIoT was exploited for identifying hazardous liquid.",A. Gupta; V. Ravi Kumar,,,Machine Learning Technology Using Thick Film Gas Sensor Toxic Liquid Detection For Industrial IOT Application,,,10.1109/CONECCT50063.2020.9198535 ,IEEE Conferences ,,"Right now proposed paper has been made to investigate the affectability, reaction of SnO2 based Pd-doped thick gas sensor for hazardous liquid as for example Vodka, LPG and Whisky identification. 1"" × 1"" alumina matrix material was exploited prevarication of thick film gas sensor. It comprises of a gas touchy layer SnO2 doped with 1% Pd, a conjoin of electrodes underneath the gas detecting layer filling in as a contact cushion for the sensor. Likewise, a radiator component is additionally planned on the posterior of the substrate The affectability of the sensor has been learned at various Pd-doped concentration (1 % Pd doped) at a constants temperature 3000C upon exposure Vodka, LPG & Whisky. In this paper, experimental results simulate in Anaconda software with the Spyder tool (Spyder 3) tool using the python programming language. Python programming is written in machine learning clustering techniques and simulated results match the experimental results with different temperatures. Industrial internet of things predominantly exploited in the frame of reference for industry 4.0. In the proposed paper, IIoT was exploited for identifying hazardous liquid.",,,978-1-7281-6828-9,1-6,IEEE , ,Sensitivity;Gas detectors;Temperature sensors;Thick films;Temperature measurement;Monitoring;Artificial intelligence,,
4852,"Title:Automated NER, Sentiment Analysis and Toxic Comment Classification for a Goal-Oriented Chatbot

 This paper focuses on improving the conversational ability of a robo receptionist. In particular, we seek to improve the ability to retrieve information specific to an organization through the design of a named-entity-recognition module. We accentuate the chatbot's sensitivity to a user's comment and the tone of a conversation through designing a fine-grained sentiment analysis module. And, finally, we have ensured the output of the self-learning chatbot is positive and pleasant through a toxic-comment classifier that improves upon a dictionary-based profanity detection module. Improving the core components of the chatbot, viz., the named entity recognition, sentiment analysis and toxic comment classification modules, reflect as an improvement in the performance of the chatbot. The performance of these modules in comparison with predecessor approaches and the code to reproduce the results have also been included to facilitate further improvements in these directions.",S. R. Murali; S. Rangreji; S. Vinay; G. Srinivasa,,,"Automated NER, Sentiment Analysis and Toxic Comment Classification for a Goal-Oriented Chatbot",,,10.1109/ICDS50568.2020.9268680 ,IEEE Conferences ,,"This paper focuses on improving the conversational ability of a robo receptionist. In particular, we seek to improve the ability to retrieve information specific to an organization through the design of a named-entity-recognition module. We accentuate the chatbot's sensitivity to a user's comment and the tone of a conversation through designing a fine-grained sentiment analysis module. And, finally, we have ensured the output of the self-learning chatbot is positive and pleasant through a toxic-comment classifier that improves upon a dictionary-based profanity detection module. Improving the core components of the chatbot, viz., the named entity recognition, sentiment analysis and toxic comment classification modules, reflect as an improvement in the performance of the chatbot. The performance of these modules in comparison with predecessor approaches and the code to reproduce the results have also been included to facilitate further improvements in these directions.",,,978-1-7281-8084-7,1-7,IEEE , ,Training;Sentiment analysis;Sensitivity;Computational modeling;Organizations;Chatbot;Data models,,
4853,"Title:Quora Based Insincere Content Classification & Detection for Social Media using Machine Learning

 Internet, being a source of infinite amount of information that people use and exchange daily, is not protected from the abusive, inappropriate and toxic content. Sometimes people deteriorate the content on social media which negatively impacts the society and it may have awful results. Regarding this toxic content over social media we examined the data set of Quora, which is a question answer website, to filter the inappropriate questions which not only affects the society but also degrade the quality and the standard of such websites. This paper analysed tokenization and vectorization which are considered to be some of the best technique in natural language processing and machine learning algorithms such as Naive Bayes, Logistic Regression, Support Vector Machine and Random Forest. On the basis of accuracy, F1-score and confusion matrix we evaluated that SVM performs best result followed by Logistic Regression. The count vectorizer techniques resulted better than other text vectorizer techniques. The experimental results showed that SVM worked better by achieving an accuracy of 0.899 for the best case.",R. Kumar; A. Kumar; M. Gupta; B. Chauhan,,,Quora Based Insincere Content Classification & Detection for Social Media using Machine Learning,,,10.1109/ICAC3N53548.2021.9725450 ,IEEE Conferences ,,"Internet, being a source of infinite amount of information that people use and exchange daily, is not protected from the abusive, inappropriate and toxic content. Sometimes people deteriorate the content on social media which negatively impacts the society and it may have awful results. Regarding this toxic content over social media we examined the data set of Quora, which is a question answer website, to filter the inappropriate questions which not only affects the society but also degrade the quality and the standard of such websites. This paper analysed tokenization and vectorization which are considered to be some of the best technique in natural language processing and machine learning algorithms such as Naive Bayes, Logistic Regression, Support Vector Machine and Random Forest. On the basis of accuracy, F1-score and confusion matrix we evaluated that SVM performs best result followed by Logistic Regression. The count vectorizer techniques resulted better than other text vectorizer techniques. The experimental results showed that SVM worked better by achieving an accuracy of 0.899 for the best case.",,,978-1-6654-3811-7,294-299,IEEE , ,Support vector machines;Machine learning algorithms;Social networking (online);Process control;Information filters;Tokenization;Internet,,
4854,"Title:Linguistic-based Data Augmentation Approach for Offensive Language Detection

 The massive amount of data generated by social media possess a great deal of toxic content that lead to serious content filtering problems including hate speech, cyberbullying and insulting. Offensive content even without profanity may result in psychological and physical harms to, particularly children and sensitive people. As of 2022, Turkey houses 7th largest Twitter community among all countries in terms of the active user size exceeding 16 million users, which represents a high diversity of people considering its population. That said, there is a growing need for a comprehensive and high-quality dataset in Turkish that can be utilized in development of NLP models for robust detection of offensive language usage in social media. Related studies in literature have mostly focused on small, synthetic and label-imbalanced datasets. Machine learning models trained on such datasets tend to favor majority class for accuracy and possess generalizability issues. However, it is challenging to create an unbiased dataset containing hate speech without offensive words, and build an accurate detection model to identify the actual hate speech Tweets. The models may lack sufficient context due to the absence of swear words. Therefore, we propose a data augmentation approach based on data mining methods utilizing the linguistic features of Turkish that can help enhance the generalizability of machine learning models without further human interaction. Furthermore, we evaluated the impact of our comprehensive dataset in detection of offensive language in social media. The NLP models training using the augmented dataset improved the macro average detection accuracy by 7.60% in comparison to the baseline approach.",T. Tanyel; B. Alkurdi; S. Ayvaz,,,Linguistic-based Data Augmentation Approach for Offensive Language Detection,,,10.1109/UBMK55850.2022.9919562 ,IEEE Conferences ,,"The massive amount of data generated by social media possess a great deal of toxic content that lead to serious content filtering problems including hate speech, cyberbullying and insulting. Offensive content even without profanity may result in psychological and physical harms to, particularly children and sensitive people. As of 2022, Turkey houses 7th largest Twitter community among all countries in terms of the active user size exceeding 16 million users, which represents a high diversity of people considering its population. That said, there is a growing need for a comprehensive and high-quality dataset in Turkish that can be utilized in development of NLP models for robust detection of offensive language usage in social media. Related studies in literature have mostly focused on small, synthetic and label-imbalanced datasets. Machine learning models trained on such datasets tend to favor majority class for accuracy and possess generalizability issues. However, it is challenging to create an unbiased dataset containing hate speech without offensive words, and build an accurate detection model to identify the actual hate speech Tweets. The models may lack sufficient context due to the absence of swear words. Therefore, we propose a data augmentation approach based on data mining methods utilizing the linguistic features of Turkish that can help enhance the generalizability of machine learning models without further human interaction. Furthermore, we evaluated the impact of our comprehensive dataset in detection of offensive language in social media. The NLP models training using the augmented dataset improved the macro average detection accuracy by 7.60% in comparison to the baseline approach.",2521-1641,,978-1-6654-7010-0,1-6,IEEE , ,Training;Filtering;Computational modeling;Hate speech;Sociology;Psychology;Machine learning,,
4855,"Title:Clustering Method Response and Recovery Time Analysis with Different Temperature for different Toxic Gas

 Nitrogen Dioxide sensors supported Zinc Stannate films were manufactured utilizing the splattering-pyrolysis technique. The impact of parent material pyrexia on Nitrogen Dioxide reaction was investigated. The sheets deposited at 400 °C dominate flakes like geomorphology that the blanks put forward within the superficial increase the roughness. The zinc Stannate sensor demonstrated maximum sensor reaction 29.3 at comparatively low (300 °C) functioning pyrexia regarding 40 ppm Nitrogen Dioxide concentration. The new Zinc Stannate films demonstrate excellent gas sensing characteristics and evidence extraordinary reaction and rehabilitation dynamics with no superficial variation by element or surface-active agent. The proposed work follows the use of anaconda software over spider tool (spyder-3) operation with python programming language. The Python scripts in machine learning with applied clustering techniques have valued toxic liquids. The results are close to real-time results with simulated ones at divergent functional temperatures.",A. Gupta; A. V. N. Rao; B. Raghavaiah; S. K. Dargar,,,Clustering Method Response and Recovery Time Analysis with Different Temperature for different Toxic Gas,2,,10.1109/ICIPTM54933.2022.9754047 ,IEEE Conferences ,,Nitrogen Dioxide sensors supported Zinc Stannate films were manufactured utilizing the splattering-pyrolysis technique. The impact of parent material pyrexia on Nitrogen Dioxide reaction was investigated. The sheets deposited at 400 °C dominate flakes like geomorphology that the blanks put forward within the superficial increase the roughness. The zinc Stannate sensor demonstrated maximum sensor reaction 29.3 at comparatively low (300 °C) functioning pyrexia regarding 40 ppm Nitrogen Dioxide concentration. The new Zinc Stannate films demonstrate excellent gas sensing characteristics and evidence extraordinary reaction and rehabilitation dynamics with no superficial variation by element or surface-active agent. The proposed work follows the use of anaconda software over spider tool (spyder-3) operation with python programming language. The Python scripts in machine learning with applied clustering techniques have valued toxic liquids. The results are close to real-time results with simulated ones at divergent functional temperatures.,,,978-1-6654-6643-1,79-83,IEEE , ,Temperature measurement;Temperature sensors;Films;Sensor phenomena and characterization;Surface roughness;Software;Nitrogen,,
4856,"Title:A Review of Spam Detection in Social Media

 With significant usage of social media to socialize in virtual environments, bad actors are now able to use these platforms to spread their malicious activities such as hate speech, spam, and even phishing to very large crowds. Especially, Twitter is suitable for these types of activities because it is one of the most common social media platforms for microblogging with millions of active users. Moreover, since the end of 2019, Covid-19 has changed the lives of individuals in many ways. While it increased social media usage due to free time, the number of cyber-attacks soared too. To prevent these activities, detection is a very crucial phase. Thus, the main goal of this study is to review the state-of-art in the detection of malicious content and the contribution of AI algorithms for detecting spam and scams effectively in social media.",İ. Yurtseven; S. Bagriyanik; S. Ayvaz,,,A Review of Spam Detection in Social Media,,,10.1109/UBMK52708.2021.9558993 ,IEEE Conferences ,,"With significant usage of social media to socialize in virtual environments, bad actors are now able to use these platforms to spread their malicious activities such as hate speech, spam, and even phishing to very large crowds. Especially, Twitter is suitable for these types of activities because it is one of the most common social media platforms for microblogging with millions of active users. Moreover, since the end of 2019, Covid-19 has changed the lives of individuals in many ways. While it increased social media usage due to free time, the number of cyber-attacks soared too. To prevent these activities, detection is a very crucial phase. Thus, the main goal of this study is to review the state-of-art in the detection of malicious content and the contribution of AI algorithms for detecting spam and scams effectively in social media.",2521-1641,,978-1-6654-2908-5,383-388,IEEE , ,Computer science;COVID-19;Social networking (online);Phishing;Blogs;Virtual environments;Artificial intelligence,,
4857,"Title:Toxic Comment Detection using LSTM

 While online communication media acts as a platform for people to connect, collaborate and discuss, overcoming the barriers for communication, some take it as a medium to direct hateful and abusive comments that may prejudice an individual's emotional and mental well being. Explosion of online communication makes it virtually impossible for filtering out the hateful tweets manually, and hence there is a need for a method to filter out the hate-speech and make social media cleaner and safer to use. The paper aims to achieve the same by text mining and making use of deep learning models constructed using LSTM neural networks that can near accurately identify and classify hate-speech and filter it out for us. The model that we have developed is able to classify given comments as toxic or nontoxic with 94.49% precision, 92.79% recall and 94.94% Accuracy score.",K. Dubey; R. Nair; M. U. Khan; P. S. Shaikh,,,Toxic Comment Detection using LSTM,,,10.1109/ICAECC50550.2020.9339521 ,IEEE Conferences ,,"While online communication media acts as a platform for people to connect, collaborate and discuss, overcoming the barriers for communication, some take it as a medium to direct hateful and abusive comments that may prejudice an individual's emotional and mental well being. Explosion of online communication makes it virtually impossible for filtering out the hateful tweets manually, and hence there is a need for a method to filter out the hate-speech and make social media cleaner and safer to use. The paper aims to achieve the same by text mining and making use of deep learning models constructed using LSTM neural networks that can near accurately identify and classify hate-speech and filter it out for us. The model that we have developed is able to classify given comments as toxic or nontoxic with 94.49% precision, 92.79% recall and 94.94% Accuracy score.",2642-6595,,978-1-7281-9183-6,1-8,IEEE , ,Training;Text mining;Toxicology;Computational modeling;Neural networks;Text categorization;Data models,,
4858,"Title:A Transfer Learning Method for Hate Speech Detection

 In this work we explore the possibilities of using transfer learning techniques to enhance performance of hate speech detection models by relying on similar linguistic problems (e.g. toxic language detection). Multiple algorithms are trained for similar linguistic tasks on larger datasets, and the obtained models are used for getting predictions on the ETHOS dataset, which we chose as the target dataset of our work. The obtained predictions are used as sole or additional features in the subsequently performed experiments. Multiple algorithms are evaluated, including Logistic Regression, SVM, RidgeClassifier, Decision Tree, Random Forest, AdaBoost, GradBoost, Bagging. Furthermore, multiple textual representations are taken into account including Tf-Idf, Bert embeddings and BERT embeddings combined with the aforementioned additional features. Transformer-based models BERT and DistilBERT are introduced and fine-tuned on ETHOS dataset. All the obtained models are evaluated and the resulting performance metrics are compared to results obtained by the authors of the ETHOS dataset. In order to explore the remaining underlying issues, model-agnostic method LIME is used to obtain explanations for incorrect predictions.",E. Šmuc; G. Delač; M. Šilić; K. Vladimir,,,A Transfer Learning Method for Hate Speech Detection,,,10.23919/MIPRO57284.2023.10159777 ,IEEE Conferences ,,"In this work we explore the possibilities of using transfer learning techniques to enhance performance of hate speech detection models by relying on similar linguistic problems (e.g. toxic language detection). Multiple algorithms are trained for similar linguistic tasks on larger datasets, and the obtained models are used for getting predictions on the ETHOS dataset, which we chose as the target dataset of our work. The obtained predictions are used as sole or additional features in the subsequently performed experiments. Multiple algorithms are evaluated, including Logistic Regression, SVM, RidgeClassifier, Decision Tree, Random Forest, AdaBoost, GradBoost, Bagging. Furthermore, multiple textual representations are taken into account including Tf-Idf, Bert embeddings and BERT embeddings combined with the aforementioned additional features. Transformer-based models BERT and DistilBERT are introduced and fine-tuned on ETHOS dataset. All the obtained models are evaluated and the resulting performance metrics are compared to results obtained by the authors of the ETHOS dataset. In order to explore the remaining underlying issues, model-agnostic method LIME is used to obtain explanations for incorrect predictions.",2623-8764,,978-953-233-104-2,953-958,IEEE , ,Training;Support vector machines;Hate speech;Transfer learning;Bit error rate;Predictive models;Linguistics,,
4859,"Title:Multi-Label Classification of Hate Speech Severity on Social Media using BERT Model

 Detection of offensive and hate speeches on social media using multi-label classification technique is a relatively new fine-grained solution to classification problems. This paper investigates intelligent learning models based on the BERT model for multi-label classification of hate speech. The approach utilized a semi-supervised pseudo-labeling technique to automatically label a newly created multi-social media data which was then augmented and balanced using AugLy and GPT-2 libraries before being used to train the BERT model. Alpha evaluation of the model returned a score of 0.948695 for toxic, 0.946662 for severe toxic, 0.944483 for obscene, 0.946159 for threat, 0.909272 for insult and 0.734659 for identity hate respectively. Examples were ranked and one among such ranked examples gave a probability score of 96%, 89.91% and 80.21% for the top three likely labels. The results compared well with that of the human-annotated severity ranking.",B. D. Dirting; G. A. Chukwudebe; E. C. Nwokorie; I. I. Ayogu,,,Multi-Label Classification of Hate Speech Severity on Social Media using BERT Model,,,10.1109/NIGERCON54645.2022.9803164 ,IEEE Conferences ,,"Detection of offensive and hate speeches on social media using multi-label classification technique is a relatively new fine-grained solution to classification problems. This paper investigates intelligent learning models based on the BERT model for multi-label classification of hate speech. The approach utilized a semi-supervised pseudo-labeling technique to automatically label a newly created multi-social media data which was then augmented and balanced using AugLy and GPT-2 libraries before being used to train the BERT model. Alpha evaluation of the model returned a score of 0.948695 for toxic, 0.946662 for severe toxic, 0.944483 for obscene, 0.946159 for threat, 0.909272 for insult and 0.734659 for identity hate respectively. Examples were ranked and one among such ranked examples gave a probability score of 96%, 89.91% and 80.21% for the top three likely labels. The results compared well with that of the human-annotated severity ranking.",2377-2697,,978-1-6654-7978-3,1-5,IEEE , ,Social networking (online);Conferences;Hate speech;Bit error rate;Media;Data models;Real-time systems,,
4860,"Title:Cyber-Security for IoT Applications based on ANN Algorithm

 Actually, Internet of Things (IoT) applications have greatly been applied in several domains such as smart home, smart building, smart agriculture, etc. However, IoT applications suffer from different form of cyber-attacks. Cyber-attacks may block the whole functionality of IoT applications. In this paper, the vulnerabilities and security of smart agriculture application is considered using artificial intelligence (AI) especially deep learning algorithms. Among the parameters monitored in the prototype of smart agriculture application temperature/humidity, water level, oxygen and toxic gas. Then, the security weakness and attacks of IoT environment for smart application have been handled and analyzed. Hence, an intrusion detection system (IDS) has been performed to detect cyber-attacks and alert sensor nodes about them. The IDS implemented in this work is based on Artificial Neural Network (ANN). The IDS may allow the detection of suspicious and abnormal activities and triggers alarm in the event of an intrusion.",A. Zrelli; C. Nakkach; T. Ezzedine,,,Cyber-Security for IoT Applications based on ANN Algorithm,,,10.1109/ISNCC55209.2022.9851715 ,IEEE Conferences ,,"Actually, Internet of Things (IoT) applications have greatly been applied in several domains such as smart home, smart building, smart agriculture, etc. However, IoT applications suffer from different form of cyber-attacks. Cyber-attacks may block the whole functionality of IoT applications. In this paper, the vulnerabilities and security of smart agriculture application is considered using artificial intelligence (AI) especially deep learning algorithms. Among the parameters monitored in the prototype of smart agriculture application temperature/humidity, water level, oxygen and toxic gas. Then, the security weakness and attacks of IoT environment for smart application have been handled and analyzed. Hence, an intrusion detection system (IDS) has been performed to detect cyber-attacks and alert sensor nodes about them. The IDS implemented in this work is based on Artificial Neural Network (ANN). The IDS may allow the detection of suspicious and abnormal activities and triggers alarm in the event of an intrusion.",,,978-1-6654-8544-9,1-5,IEEE , ,Smart agriculture;Temperature sensors;Temperature measurement;Smart buildings;Prototypes;Artificial neural networks;Smart homes,,
4861,"Title:Intelligent Transmitter : Analysis of Effective parameters on Sensor Response of Gas Transmitter to Enhancement Measurment Accuracy by Intelligent Corrective Model Based on Artificial Neural Network

 As we may know, H2S is a toxic and dangerous gas that mainly can be found in oil fields, drilling rigs, gas separators, petrochemicals etc. It is so dangerous that if it exceeds a specified amount, it will cause physical and respiratory complications or death in some cases. For the time being, a transmitter is used to detect and measure the concentration of H2S gas which the most significant part of it, is the gas sensor. We used an electrochemical sensor to construct the transmitter. Neural networks have been used to investigate the effect of environmental parameters such as temperature and humidity. The network consists of an input layer, a hidden layer and an output layer. The results show that the output of the neural network is well able to follow the actual output. Therefore, changes in temperature and humidity affect the response of the hydrogen sulfide gas transmitter, and this change reduces the accuracy measured by the device. Furthermore, high-precision hydrogen sulfide detection sensors are generally expensive. This finding has important implications for developing robust gas sensors. By using the achieved relationship and considering the effect of temperature and humidity changes, the accuracy of the low-cos sensors can be greatly increased and the cost of producing a hydrogen sulfide transmitter can be greatly reduced.",M. M. Ahad; T. Hamoule,,,Intelligent Transmitter : Analysis of Effective parameters on Sensor Response of Gas Transmitter to Enhancement Measurment Accuracy by Intelligent Corrective Model Based on Artificial Neural Network,,,10.1109/CFIS54774.2022.9756483 ,IEEE Conferences ,,"As we may know, H2S is a toxic and dangerous gas that mainly can be found in oil fields, drilling rigs, gas separators, petrochemicals etc. It is so dangerous that if it exceeds a specified amount, it will cause physical and respiratory complications or death in some cases. For the time being, a transmitter is used to detect and measure the concentration of H2S gas which the most significant part of it, is the gas sensor. We used an electrochemical sensor to construct the transmitter. Neural networks have been used to investigate the effect of environmental parameters such as temperature and humidity. The network consists of an input layer, a hidden layer and an output layer. The results show that the output of the neural network is well able to follow the actual output. Therefore, changes in temperature and humidity affect the response of the hydrogen sulfide gas transmitter, and this change reduces the accuracy measured by the device. Furthermore, high-precision hydrogen sulfide detection sensors are generally expensive. This finding has important implications for developing robust gas sensors. By using the achieved relationship and considering the effect of temperature and humidity changes, the accuracy of the low-cos sensors can be greatly increased and the cost of producing a hydrogen sulfide transmitter can be greatly reduced.",2771-1374,,978-1-6654-7872-4,1-7,IEEE , ,Temperature measurement;Temperature sensors;Temperature;Costs;Transmitters;Hydrogen;Humidity measurement,,
4862,"Title:Automatic System for Monitoring Landfills SAM-01

 Uncontrolled storage of problematic and toxic waste, respectively, has led in many places to the emergence of areas that pose a danger to the environment and natural resources, as well as to human health. Basically, all over the world countries are dealing with these environmental issues, therefore we have focused our attention on this mandatory objective for contemporary society and for staff working in the field of technical and engineering sciences. Our system, i.e. SAM-01, ensures the monitoring of the gases emitted by waste or household waste left in the arranged or unarranged locations as well as the monitoring of the soil pH in order to prevent the infestation of groundwater with harmful substances. The temperature inside the waste mass is monitored in order to prevent the phenomenon of self-combustion; the soil moisture is also monitored in the possible direction of leakage of harmful substances emanating from the landfill. Both the hardware and software supports of our system are presented in this paper together with further development of SAM-01.",C. Ciufudean; C. Buzduga,,,Automatic System for Monitoring Landfills SAM-01,,,10.1109/ICCCA52192.2021.9666282 ,IEEE Conferences ,,"Uncontrolled storage of problematic and toxic waste, respectively, has led in many places to the emergence of areas that pose a danger to the environment and natural resources, as well as to human health. Basically, all over the world countries are dealing with these environmental issues, therefore we have focused our attention on this mandatory objective for contemporary society and for staff working in the field of technical and engineering sciences. Our system, i.e. SAM-01, ensures the monitoring of the gases emitted by waste or household waste left in the arranged or unarranged locations as well as the monitoring of the soil pH in order to prevent the infestation of groundwater with harmful substances. The temperature inside the waste mass is monitored in order to prevent the phenomenon of self-combustion; the soil moisture is also monitored in the possible direction of leakage of harmful substances emanating from the landfill. Both the hardware and software supports of our system are presented in this paper together with further development of SAM-01.",2642-7354,,978-1-6654-1473-9,362-366,IEEE , ,Temperature sensors;Temperature measurement;Wires;Soil moisture;Software;Sensors;Servers,,
4863,"Title:Implementation of Adaboost for the detection of the toxic response behaviour of zebrafish (Danio Rerio)

 The movement behaviour of zebrafish (Danio rerio) schools was observed in response to treatment with copper at a 24 h half-lethal concentration. The behavioural characteristic parameters, which were continuously recorded into a SQL (Structured Query Language) Server database by a digital image processing system both before and after the treatment, had significant changes. Subsequently, the Adaboost algorithm was implemented to solve the data vector classification problem in normal and abnormal water. Furthermore, to evaluate the accuracy and timeliness of the classifiers, Adaboost was compared with a back-propagation neural network (BPNN) and support vector machine (SVM). The results clearly demonstrated that the prediction accuracy of the Gentle Adaboost and Real Adaboost algorithms were over 93%, which was better than the Modest Adaboost, the BPNN and the SVM. In addition, the time requirement was also acceptable. In conclusion, Adaboost is a useful computational method for the classification of water quality.",Q. Du; J. Xu; Y. Ge; C. Wang,,,Implementation of Adaboost for the detection of the toxic response behaviour of zebrafish (Danio Rerio),,,10.1109/ISSPIT.2015.7394381 ,IEEE Conferences ,,"The movement behaviour of zebrafish (Danio rerio) schools was observed in response to treatment with copper at a 24 h half-lethal concentration. The behavioural characteristic parameters, which were continuously recorded into a SQL (Structured Query Language) Server database by a digital image processing system both before and after the treatment, had significant changes. Subsequently, the Adaboost algorithm was implemented to solve the data vector classification problem in normal and abnormal water. Furthermore, to evaluate the accuracy and timeliness of the classifiers, Adaboost was compared with a back-propagation neural network (BPNN) and support vector machine (SVM). The results clearly demonstrated that the prediction accuracy of the Gentle Adaboost and Real Adaboost algorithms were over 93%, which was better than the Modest Adaboost, the BPNN and the SVM. In addition, the time requirement was also acceptable. In conclusion, Adaboost is a useful computational method for the classification of water quality.",,,978-1-5090-0481-2,466-471,IEEE , ,Signal processing;Information technology,,
4864,"Title:Detecting Hate Speech in Tweets Using Different Deep Neural Network Architectures

 One of the major problems, apparent in online social media, is the toxic online content. This has continued unabated, as people from diverse cultural backgrounds access the Internet, concealing their identity under the cloud of anonymity. Deep neural networks have been employed to detect hate speech from online content. This paper describes three different Deep Neural Network (DNN) Architectures for detection of hate words in Twitter - Gated Recurrent Unit (GRU), useful in capturing sequence orders, Convolution Neural Network (CNN), good for feature extraction, and Universal Language Model Fine-tuning (ULMFiT) model, which is based on transfer learning technique. ULMFiT model uses the DNN Architecture called Average-SGD Weight-Dropped Long Short Term Memory (AWD-LSTM). AWD -LSTM model was pre-trained using WikiText103 dataset. This method significantly outperformed the other Architectures.",B. R. Amrutha; K. R. Bindu,,,Detecting Hate Speech in Tweets Using Different Deep Neural Network Architectures,,,10.1109/ICCS45141.2019.9065763 ,IEEE Conferences ,,"One of the major problems, apparent in online social media, is the toxic online content. This has continued unabated, as people from diverse cultural backgrounds access the Internet, concealing their identity under the cloud of anonymity. Deep neural networks have been employed to detect hate speech from online content. This paper describes three different Deep Neural Network (DNN) Architectures for detection of hate words in Twitter - Gated Recurrent Unit (GRU), useful in capturing sequence orders, Convolution Neural Network (CNN), good for feature extraction, and Universal Language Model Fine-tuning (ULMFiT) model, which is based on transfer learning technique. ULMFiT model uses the DNN Architecture called Average-SGD Weight-Dropped Long Short Term Memory (AWD-LSTM). AWD -LSTM model was pre-trained using WikiText103 dataset. This method significantly outperformed the other Architectures.",,,978-1-5386-8113-8,923-926,IEEE , ,Computational modeling;Neural networks;Conferences;Computer architecture;Voice activity detection;Convolution;Feature extraction,,
4865,"Title:Social Media's Toxic Comments Detection Using Artificial Intelligence Techniques

 Cyberbullying takes its place in social media and has increased throughout the past few years. The damage that cyberbullying has on the users is undeniable they get attacked either on their appearances, ethnicities, religions, and even their thoughts and personal opinion. The attack causes these users anxiety, depression, low self-esteem, and in the worst scenarios suicide. These harmful actions toward the users drive researchers to identify and detect cyberbullying to fight it. Unfortunately, most of the previous approaches were on English texts, hardly any on other languages. This paper presents a cyberbullying detection system in the Moroccan dialect on an Instagram-collected dataset. The experiment results gave accuracies of around 77% to 91% from both the ML and DL algorithms. The LSTM model gave the best outcome by 91.24% outperforming the ML models.",R. Rachidi; M. A. Ouassil; M. Errami; B. Cherradi; S. Hamida; H. Silkan,,,Social Media's Toxic Comments Detection Using Artificial Intelligence Techniques,,,10.1109/IRASET57153.2023.10153015 ,IEEE Conferences ,,"Cyberbullying takes its place in social media and has increased throughout the past few years. The damage that cyberbullying has on the users is undeniable they get attacked either on their appearances, ethnicities, religions, and even their thoughts and personal opinion. The attack causes these users anxiety, depression, low self-esteem, and in the worst scenarios suicide. These harmful actions toward the users drive researchers to identify and detect cyberbullying to fight it. Unfortunately, most of the previous approaches were on English texts, hardly any on other languages. This paper presents a cyberbullying detection system in the Moroccan dialect on an Instagram-collected dataset. The experiment results gave accuracies of around 77% to 91% from both the ML and DL algorithms. The LSTM model gave the best outcome by 91.24% outperforming the ML models.",,,979-8-3503-9836-6,1-6,IEEE , ,Anxiety disorders;Cyberbullying;Depression;Artificial intelligence,,
4866,"Title:Arduino Based Bluetooth Voice-Controlled Robot Car and Obstacle Detector

 A machine is required when humans would like to work in different environmental conditions, such as toxic material, remote handling of bombs, health conditions, and sewage treatment. The paper aims to build a robot car that monitors the human voice's movement and senses distant objects. The L298N board, HC-05, Arduino Uno microcontroller, ultrasonic sensor, battery, and jumping wires are included in this system. The robot movement and control system is used by the speaker to allow the robot to react to any speaker command that gives any verbal instruction that produces sound frequencies of the human voice. Through the software application, the user of a robotic car will choose the route or path to control the movement of the car. The user can monitor the robot's movements on his own smart device and allow the car to drive in his own way. In this method, a microcontroller with android devices is linked through a bluetooth module to receive desired voice commands. The robot then escapes obstacles and detects distant objects. The android application that is used to convert a voice to a text command and then transmit data to a microcontroller moves the robot via a voice application according to the user's command. After receiving the command, the robot moves in left, right, forward, and backward directions. This device tried to alert workers to the possibility of a terrorist attack in a military camp.",R. Sissodia; M. S. Rauthan; V. Barthwal,,,Arduino Based Bluetooth Voice-Controlled Robot Car and Obstacle Detector,,,10.1109/SCEECS57921.2023.10063092 ,IEEE Conferences ,,"A machine is required when humans would like to work in different environmental conditions, such as toxic material, remote handling of bombs, health conditions, and sewage treatment. The paper aims to build a robot car that monitors the human voice's movement and senses distant objects. The L298N board, HC-05, Arduino Uno microcontroller, ultrasonic sensor, battery, and jumping wires are included in this system. The robot movement and control system is used by the speaker to allow the robot to react to any speaker command that gives any verbal instruction that produces sound frequencies of the human voice. Through the software application, the user of a robotic car will choose the route or path to control the movement of the car. The user can monitor the robot's movements on his own smart device and allow the car to drive in his own way. In this method, a microcontroller with android devices is linked through a bluetooth module to receive desired voice commands. The robot then escapes obstacles and detects distant objects. The android application that is used to convert a voice to a text command and then transmit data to a microcontroller moves the robot via a voice application according to the user's command. After receiving the command, the robot moves in left, right, forward, and backward directions. This device tried to alert workers to the possibility of a terrorist attack in a military camp.",2688-0288,,979-8-3503-9874-8,1-5,IEEE , ,Bluetooth;Microcontrollers;Wires;Robot sensing systems;Software;Acoustics;Autonomous automobiles,,
4867,"Title:Injurious Comment Detection and Removal utilizing Neural Network

 There are a lot of ways to communicate in this cyber world. With this increasingly growing era there is also much obstruction in a safe and secure environment. There has been an exponential growth in cyber bullying and abusing. Deep learning methods have recently begun to be used to detect abusive comments made in online forums. Detecting, and classifying, online abusive language is a non-trivial NLP challenge because online comments are made in a wide variety of contexts, and contain words from many different formal and informal lexicons. For this to overcome we design a model that detects the level of toxicity in a message and replaces it with another phrase. It uses a Deep Neural network model that takes a message/comment as an input and checks for various parameters such as Toxic, Severe Toxic, Identity hate, threat, etc. And the application finally then replaces the portion with another word/phrase. Examining things, you care about can be troublesome. The danger of misuse and provocation online implies that numerous individuals quit communicating and offer up on looking for changed thoughts. Stages battle to adequately encourage discussions, driving numerous networks to restrict or totally shut down client remarks.",A. Wadhwani; P. Jain; S. Sahu,,,Injurious Comment Detection and Removal utilizing Neural Network,,,10.1109/ICIPTM52218.2021.9388331 ,IEEE Conferences ,,"There are a lot of ways to communicate in this cyber world. With this increasingly growing era there is also much obstruction in a safe and secure environment. There has been an exponential growth in cyber bullying and abusing. Deep learning methods have recently begun to be used to detect abusive comments made in online forums. Detecting, and classifying, online abusive language is a non-trivial NLP challenge because online comments are made in a wide variety of contexts, and contain words from many different formal and informal lexicons. For this to overcome we design a model that detects the level of toxicity in a message and replaces it with another phrase. It uses a Deep Neural network model that takes a message/comment as an input and checks for various parameters such as Toxic, Severe Toxic, Identity hate, threat, etc. And the application finally then replaces the portion with another word/phrase. Examining things, you care about can be troublesome. The danger of misuse and provocation online implies that numerous individuals quit communicating and offer up on looking for changed thoughts. Stages battle to adequately encourage discussions, driving numerous networks to restrict or totally shut down client remarks.",,,978-1-6654-2530-8,165-168,IEEE , ,Deep learning;Toxicology;Neural networks;Graphical user interfaces,,
4868,"Title:Deep Neural Networks based Detection and Analysis of Fake Tweets

 Social networking is a wedge for interchanging thoughts, individual perspectives and views but without adversely affecting the sentimental, religious, or maybe private thoughts of the group. Furthermore, the spread of fake news flashes continues to be a pattern on social networking. This paper discusses a hybrid method used towards the control over this kind of ill intentions by developing a method that analysis and also detects posts, toxic comments, or fake news inside any multimedia or text format. This particular paper will help to identify the precision of fake news utilizing Deep Neural Networks. News articles extracted from Twitter is represented as embedding vectors. The hybridized Convolutional Neural Network and LSTM (Long-Short Term Memory) framework is built to learn the contextual dependencies between the words present in news articles. We compare many methods for detecting fake news. The Natural Language Interference (NLI) designs may also be qualified. The information compilation, interpretation, and then tests procedure are clarified completely along with existing different study analyses in the identity of linguistic variants to come down with truthful and false information. Next, we check as well as train a pair of learning breakthroughs to produce exact fake information detectors.",G. Mareeswari; E. V. Dinesh,,,Deep Neural Networks based Detection and Analysis of Fake Tweets,,,10.1109/ICSPC57692.2023.10125815 ,IEEE Conferences ,,"Social networking is a wedge for interchanging thoughts, individual perspectives and views but without adversely affecting the sentimental, religious, or maybe private thoughts of the group. Furthermore, the spread of fake news flashes continues to be a pattern on social networking. This paper discusses a hybrid method used towards the control over this kind of ill intentions by developing a method that analysis and also detects posts, toxic comments, or fake news inside any multimedia or text format. This particular paper will help to identify the precision of fake news utilizing Deep Neural Networks. News articles extracted from Twitter is represented as embedding vectors. The hybridized Convolutional Neural Network and LSTM (Long-Short Term Memory) framework is built to learn the contextual dependencies between the words present in news articles. We compare many methods for detecting fake news. The Natural Language Interference (NLI) designs may also be qualified. The information compilation, interpretation, and then tests procedure are clarified completely along with existing different study analyses in the identity of linguistic variants to come down with truthful and false information. Next, we check as well as train a pair of learning breakthroughs to produce exact fake information detectors.",,,979-8-3503-0077-2,56-61,IEEE , ,Deep learning;Support vector machines;Radio frequency;Social networking (online);Neural networks;Signal processing algorithms;Feature extraction,,
4869,"Title:Bullyproof Sentinel: Fortifying Online Spaces Against Bullying using Machine Learning

 In the current social media landscape, cyberbullying and online harassment remain pressing issues. Therefore, we planned a cyberbullying detection system for social media platforms. It can protect online communities from toxic behaviors and make a global impact by fostering a safer and more constructive online environment. We are mainly focused on developing an improved technique to detect bot profiles on social media, developing a mechanism to detect abusive content and sarcasm, developing a mechanism to detect defamatory comments on social media, and developing an effective method for detecting offensive and abusive content in image-format reviews on social media using machine learning algorithms.",D. M.M.T.; V. T.; W. W.A.S.D.; J. V.; A. Senarathne; A. Gunasinghe,,,Bullyproof Sentinel: Fortifying Online Spaces Against Bullying using Machine Learning,,,10.1109/I-SMAC58438.2023.10290419 ,IEEE Conferences ,,"In the current social media landscape, cyberbullying and online harassment remain pressing issues. Therefore, we planned a cyberbullying detection system for social media platforms. It can protect online communities from toxic behaviors and make a global impact by fostering a safer and more constructive online environment. We are mainly focused on developing an improved technique to detect bot profiles on social media, developing a mechanism to detect abusive content and sarcasm, developing a mechanism to detect defamatory comments on social media, and developing an effective method for detecting offensive and abusive content in image-format reviews on social media using machine learning algorithms.",2768-0673,,979-8-3503-4148-5,825-830,IEEE , ,Machine learning algorithms;Cyberbullying;Pressing;Machine learning;Chatbots;Behavioral sciences,,
4870,"Title:Multilabeling Indonesian Toxic Comments Classification Using The Bidirectional Encoder Representations of Transformers Model

 The main goal of this study is to create a language model to identify and classify multi-label on toxic comments that exist in social media. However, toxic comments classification faces a problem: one single toxic comment can have more than one class or label. Therefore, traditional algorithms such as Naive Bayes, SVM, or else cannot handle this type of classification efficiently because to analyze toxic comments, a model needs to understand language context. For that reason, we use BERT (Bidirectional Encoder Representation from Transformers), which can learn language bidirectionally. Two models (bert-base-multilingual-uncased and indobert-base-p1) will be trained and compared. The data used in this study is acquired from Twitter and will go through a pre-processing phase that includes case folding, data cleaning, normalization, and non-alphanumeric removal before it is used to train BERT. The model's hyperparameters are three epochs, 2e-5 learning rate, and a batch size of 32. The best test accuracy scores acquired from the two models in this paper are toxic: 92%, severe toxic: 92%, obscene: 91%, insult: 85%, threat: 93%, dan identity hate: 90%.",R. Rivaldo; A. Amalia; D. Gunawan,,,Multilabeling Indonesian Toxic Comments Classification Using The Bidirectional Encoder Representations of Transformers Model,,,10.1109/DATABIA53375.2021.9650126 ,IEEE Conferences ,,"The main goal of this study is to create a language model to identify and classify multi-label on toxic comments that exist in social media. However, toxic comments classification faces a problem: one single toxic comment can have more than one class or label. Therefore, traditional algorithms such as Naive Bayes, SVM, or else cannot handle this type of classification efficiently because to analyze toxic comments, a model needs to understand language context. For that reason, we use BERT (Bidirectional Encoder Representation from Transformers), which can learn language bidirectionally. Two models (bert-base-multilingual-uncased and indobert-base-p1) will be trained and compared. The data used in this study is acquired from Twitter and will go through a pre-processing phase that includes case folding, data cleaning, normalization, and non-alphanumeric removal before it is used to train BERT. The model's hyperparameters are three epochs, 2e-5 learning rate, and a batch size of 32. The best test accuracy scores acquired from the two models in this paper are toxic: 92%, severe toxic: 92%, obscene: 91%, insult: 85%, threat: 93%, dan identity hate: 90%.",,,978-1-6654-2680-0,22-26,IEEE , ,Support vector machines;Analytical models;Social networking (online);Bit error rate;Data science;Transformers;Data models,,
4871,"Title:Multilingual Toxic Comment Classifier

 This research study’s primary goal is to identify all the toxic comments on social media including hate, abusive, obscene, threat and insulting comments in a dataset where the entries are stored in more than one language. In the dataset with more than one language there are many problems faced in writing the pseudo-code of the Deep learning algorithms as the first part for each and every algorithm was to detect the language and then search/detect the word as to a toxic or a non-toxic comment.",A. S. Kapse; A. Dubey; H. Bisen; K. Kumar; M. Tamheed,,,Multilingual Toxic Comment Classifier,,,10.1109/ICICCS56967.2023.10142540 ,IEEE Conferences ,,"This research study’s primary goal is to identify all the toxic comments on social media including hate, abusive, obscene, threat and insulting comments in a dataset where the entries are stored in more than one language. In the dataset with more than one language there are many problems faced in writing the pseudo-code of the Deep learning algorithms as the first part for each and every algorithm was to detect the language and then search/detect the word as to a toxic or a non-toxic comment.",2768-5330,,979-8-3503-9725-3,1223-1228,IEEE , ,Deep learning;Social networking (online);Computational modeling;Writing;Search problems;Control systems;Classification algorithms,,
4872,"Title:Design of Monitoring and Early Warning System for Sewage Discharge from Oil Pool in Transformer Accident

 Transformer waste oil contains toluene and other toxic substances. In order to prevent excessive oil content in the sewage discharge at the sewage outlet of the accident oil pool, the waste oil content in the sewage discharge is rapidly monitored online. Based on UV-fluorescence method, transformer waste oil was taken as the main research object, and controlled experiments were carried out in tap water, tap water containing gravel and tap water containing soil. Firstly, the fluorescence signal sent by the molecule was received by the water oil sensor, and then transmitted to the RS485 interface. Finally, the Modbus protocol was used to read the data. With STM32 MCU as the experimental hardware platform, LCD screen display test results and buzzer as early warning, a set of real-time monitoring and high sensitivity detection system is built. The test shows that the system is accurate and stable in detecting oil content in water based on UV-fluorescence method.",H. Liu; K. Du; F. Xiang; Y. Zhou; Y. Gao; G. Wei,,,Design of Monitoring and Early Warning System for Sewage Discharge from Oil Pool in Transformer Accident,,,10.1109/ACPEE56931.2023.10135779 ,IEEE Conferences ,,"Transformer waste oil contains toluene and other toxic substances. In order to prevent excessive oil content in the sewage discharge at the sewage outlet of the accident oil pool, the waste oil content in the sewage discharge is rapidly monitored online. Based on UV-fluorescence method, transformer waste oil was taken as the main research object, and controlled experiments were carried out in tap water, tap water containing gravel and tap water containing soil. Firstly, the fluorescence signal sent by the molecule was received by the water oil sensor, and then transmitted to the RS485 interface. Finally, the Modbus protocol was used to read the data. With STM32 MCU as the experimental hardware platform, LCD screen display test results and buzzer as early warning, a set of real-time monitoring and high sensitivity detection system is built. The test shows that the system is accurate and stable in detecting oil content in water based on UV-fluorescence method.",,,979-8-3503-4552-0,2207-2211,IEEE , ,Sensitivity;Protocols;Oils;Laboratories;Oil insulation;Soil;Transformers,,
4873,"Title:Toxic Comment Identification and Classification using BERT and SVM

 Bullying cases like toxic comments on many social media platforms cause a negative impact that occurs in every age circles. From those cases, we would like to make a system that can identify and classify toxic words from a comment before it is sent and seen by others. By utilizing a Machine Learning application, hopefully, the produced system can be useful in reducing bullying cases that are many in social media. Lot of experiments have been done to find the settlement for this problem, but various algorithms and models are used. In this research, we will be doing a comparison of two models, the BERT (Bidirectional Encoder Representations from Transformers) model which is usually used to solve NLP (Natural Language Processing) tasks, and SVM (Support Vector Machine) model which is great at classifying. Both models will be compared to find out which model is better in identifying and classifying toxic comments. The result that is gotten shows that BERT model is said to be superior compared to SVM model, with an accuracy of 98.3% including other metric evaluation scores that show a significant result compared to the result achieved by SVM model.",I. Gladwin; E. V. Renjiro; B. Valerian; I. S. Edbert; D. Suhartono,,,Toxic Comment Identification and Classification using BERT and SVM,1,,10.1109/ICST56971.2022.10136295 ,IEEE Conferences ,,"Bullying cases like toxic comments on many social media platforms cause a negative impact that occurs in every age circles. From those cases, we would like to make a system that can identify and classify toxic words from a comment before it is sent and seen by others. By utilizing a Machine Learning application, hopefully, the produced system can be useful in reducing bullying cases that are many in social media. Lot of experiments have been done to find the settlement for this problem, but various algorithms and models are used. In this research, we will be doing a comparison of two models, the BERT (Bidirectional Encoder Representations from Transformers) model which is usually used to solve NLP (Natural Language Processing) tasks, and SVM (Support Vector Machine) model which is great at classifying. Both models will be compared to find out which model is better in identifying and classifying toxic comments. The result that is gotten shows that BERT model is said to be superior compared to SVM model, with an accuracy of 98.3% including other metric evaluation scores that show a significant result compared to the result achieved by SVM model.",,,978-1-6654-5622-7,1-6,IEEE , ,Support vector machines;Measurement;Machine learning algorithms;Social networking (online);Bit error rate;Transformers;Natural language processing,,
4874,"Title:Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning

 This paper presents a deep learning-based pipeline for categorizing Bengali toxic comments, in which at first a binary classification model is used to determine whether a comment is toxic or not, and then a multi-label classifier is employed to determine which toxicity type the comment belongs to. For this purpose, we have prepared a manually labeled dataset consisting of 16,073 instances among which 8,488 are Toxic and any toxic comment may correspond to one or more of the six toxic categories - vulgar, hate, religious, threat, troll, and insult simulta-neously. Long Short Term Memory (LSTM) with BERT Embedding achieved 89.42% accuracy for the binary classification task while as a multi-label classifier, a combination of Convolutional Neural Network and Bi-directional Long Short Term Memory (CNN-BiLSTM) with attention mechanism achieved 78.92% accuracy and 0.86 as weighted F1-score. To explain the predictions and interpret the word feature importance during classification by the proposed models, we utilized Local Interpretable Model-Agnostic Explanations (LIME) framework. We have made our dataset public and can be accessed at - https://github.com/deepu099cse/Multi-Labeled-Bengali-Toxic-Comments-Classification",T. A. Belal; G. M. Shahariar; M. H. Kabir,,,Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning,,,10.1109/ECCE57851.2023.10101588 ,IEEE Conferences ,,"This paper presents a deep learning-based pipeline for categorizing Bengali toxic comments, in which at first a binary classification model is used to determine whether a comment is toxic or not, and then a multi-label classifier is employed to determine which toxicity type the comment belongs to. For this purpose, we have prepared a manually labeled dataset consisting of 16,073 instances among which 8,488 are Toxic and any toxic comment may correspond to one or more of the six toxic categories - vulgar, hate, religious, threat, troll, and insult simulta-neously. Long Short Term Memory (LSTM) with BERT Embedding achieved 89.42% accuracy for the binary classification task while as a multi-label classifier, a combination of Convolutional Neural Network and Bi-directional Long Short Term Memory (CNN-BiLSTM) with attention mechanism achieved 78.92% accuracy and 0.86 as weighted F1-score. To explain the predictions and interpret the word feature importance during classification by the proposed models, we utilized Local Interpretable Model-Agnostic Explanations (LIME) framework. We have made our dataset public and can be accessed at - https://github.com/deepu099cse/Multi-Labeled-Bengali-Toxic-Comments-Classification",,,979-8-3503-4536-0,1-6,IEEE , ,Deep learning;Toxicology;Pipelines;Transfer learning;Predictive models;Transformers;Natural language processing,,
4875,"Title:A Comparative Study and Analysis on Toxic Comment Classification

 It is the task of identifying and categorizing comments that contain harmful or offensive content, such as hate speech, cyberbullying, or harassment. This task is crucial for maintaining a safe and respectful online community, but it poses several challenges due to the complexity and ambiguity of natural language, as well as the constantly evolving nature of toxic language. Recent techniques for toxic comment classification include deep learning models such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformer-based models like BERT and GPT. These models have achieved impressive performance on benchmark datasets, but it still faces several challenges. One challenge is the lack of diversity in training data, which can lead to biased models that perform poorly on real-world data. Another challenge is the difficulty of detecting and classifying subtle forms of toxic language, such as sarcasm, irony, and euphemisms. The proposed objective of this study is to develop a more robust and accurate toxic comment classification system that addresses these challenges. Specifically, this research study aims to improve the model’s ability to detect and classify subtle forms of toxic language by incorporating additional contextual information and leveraging techniques such as adversarial training and data augmentation to increase the diversity of training data. This study also plans to evaluate the model’s performance on a range of real-world datasets to ensure its effectiveness in practical settings.",Ashish; A. Rani; H. Shyan,,,A Comparative Study and Analysis on Toxic Comment Classification,,,10.1109/ICSCSS57650.2023.10169771 ,IEEE Conferences ,,"It is the task of identifying and categorizing comments that contain harmful or offensive content, such as hate speech, cyberbullying, or harassment. This task is crucial for maintaining a safe and respectful online community, but it poses several challenges due to the complexity and ambiguity of natural language, as well as the constantly evolving nature of toxic language. Recent techniques for toxic comment classification include deep learning models such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformer-based models like BERT and GPT. These models have achieved impressive performance on benchmark datasets, but it still faces several challenges. One challenge is the lack of diversity in training data, which can lead to biased models that perform poorly on real-world data. Another challenge is the difficulty of detecting and classifying subtle forms of toxic language, such as sarcasm, irony, and euphemisms. The proposed objective of this study is to develop a more robust and accurate toxic comment classification system that addresses these challenges. Specifically, this research study aims to improve the model’s ability to detect and classify subtle forms of toxic language by incorporating additional contextual information and leveraging techniques such as adversarial training and data augmentation to increase the diversity of training data. This study also plans to evaluate the model’s performance on a range of real-world datasets to ensure its effectiveness in practical settings.",,,979-8-3503-3360-2,783-787,IEEE , ,Training;Recurrent neural networks;Natural languages;Hate speech;Training data;Transformers;Rendering (computer graphics),,
4876,"Title:Optimal sizing of solar energy transformers using natural ester fluid

 As a result of the increasing number of nation-states that are adopting aggressive Renewable & Alternative Energy Portfolios, the solar energy market is nearly doubling year over year. With this aggressive growth comes even greater scrutiny when sizing solar farms. There is often great incentive to get the most utilization out of the equipment. An often over looked piece of equipment on these farms is the liquid filled AC padmount transformer. Given the green nature of the solar market, every Cooper Power Systems Envirotran™ Solar transformer contains the non-toxic, biodegradable Envirotemp™ FR3™ fluid, made from renewable seed oils. Equal in importance to its biodegradability, this natural ester fluid substantially extends the life of the cellulosic insulation in the transformer, while allowing periods of overloading of the transformer. The high fire point of natural ester fluid provides a safer transformer for solar applications compared to mineral oil, especially during periods of high ambient temperature and unit overloading. This work presents how using the inherent properties of natural ester fluid in conjunction with defined inverter load profile and site environmental conditions can help optimize transformers for Solar PV applications.",D. A. Trevas; A. Peterson; K. J. Rapp; J. Luksich,,,Optimal sizing of solar energy transformers using natural ester fluid,,,10.1109/EEEIC.2012.6221525 ,IEEE Conferences ,,"As a result of the increasing number of nation-states that are adopting aggressive Renewable & Alternative Energy Portfolios, the solar energy market is nearly doubling year over year. With this aggressive growth comes even greater scrutiny when sizing solar farms. There is often great incentive to get the most utilization out of the equipment. An often over looked piece of equipment on these farms is the liquid filled AC padmount transformer. Given the green nature of the solar market, every Cooper Power Systems Envirotran™ Solar transformer contains the non-toxic, biodegradable Envirotemp™ FR3™ fluid, made from renewable seed oils. Equal in importance to its biodegradability, this natural ester fluid substantially extends the life of the cellulosic insulation in the transformer, while allowing periods of overloading of the transformer. The high fire point of natural ester fluid provides a safer transformer for solar applications compared to mineral oil, especially during periods of high ambient temperature and unit overloading. This work presents how using the inherent properties of natural ester fluid in conjunction with defined inverter load profile and site environmental conditions can help optimize transformers for Solar PV applications.",,,978-1-4577-1829-8,1006-1010,IEEE , ,Power transformer insulation;Oil insulation;Fluids;Minerals;Inverters;Aging,,
4877,"Title:Advantages for Indonesia to Process Coconut Oil as Power Transformer Insulation and its Cooling System

 By 2017, the capacity of the Indonesian power system is 56,333.08 MW. A conventional power transformer is an oil-filled transformer, which is mineral oil. It uses mineral oil as insulation and cooling media, which is toxic and nonenvironmentally friendly. Reducing the usage of mineral oil has a lot of advantages and a great deal. In the other hand, Indonesia and Philippines were the two top coconut suppliers in the entire world in 2011-2015. With this capability, Indonesia should utilize conventional coconut oil to become insulation media, especially for power transformer. An alternative insulation media must have similar dielectric characteristics at least as mineral oil. Conventional mineral oil has high dielectric strength, good heat conductivity, a low specific gravity, a low viscosity, a low pour point, a high flash point, safe for the transformer material, and stable. On the other side, coconut oil has dielectric characteristics too. Its characteristic has some similar standard with mineral oil for power transformer. In some researches, half processed of coconut oil has been tested based on the standard. The researchers obtained five parameters. Good result for flashpoint, viscosity at 40°C, and neutralization value of total acidity but not good for breakdown voltage and pour point. It because of the tested coconut oil is commercially available or unrefined coconut oil and researchers needs more test for other parameters. In order to fulfil the standard, Indonesia should process crude coconut oil domestically as insulating media. It will provide a job for seekers, the world's alternative for liquid insulation media, and prosper the coconut gardener. Of course, coconut oil is more environmentally friendly than mineral oil.",H. Erwantono; B. Permadi; P. Basuki,,,Advantages for Indonesia to Process Coconut Oil as Power Transformer Insulation and its Cooling System,,,10.1109/ICT-PEP50916.2020.9249946 ,IEEE Conferences ,,"By 2017, the capacity of the Indonesian power system is 56,333.08 MW. A conventional power transformer is an oil-filled transformer, which is mineral oil. It uses mineral oil as insulation and cooling media, which is toxic and nonenvironmentally friendly. Reducing the usage of mineral oil has a lot of advantages and a great deal. In the other hand, Indonesia and Philippines were the two top coconut suppliers in the entire world in 2011-2015. With this capability, Indonesia should utilize conventional coconut oil to become insulation media, especially for power transformer. An alternative insulation media must have similar dielectric characteristics at least as mineral oil. Conventional mineral oil has high dielectric strength, good heat conductivity, a low specific gravity, a low viscosity, a low pour point, a high flash point, safe for the transformer material, and stable. On the other side, coconut oil has dielectric characteristics too. Its characteristic has some similar standard with mineral oil for power transformer. In some researches, half processed of coconut oil has been tested based on the standard. The researchers obtained five parameters. Good result for flashpoint, viscosity at 40°C, and neutralization value of total acidity but not good for breakdown voltage and pour point. It because of the tested coconut oil is commercially available or unrefined coconut oil and researchers needs more test for other parameters. In order to fulfil the standard, Indonesia should process crude coconut oil domestically as insulating media. It will provide a job for seekers, the world's alternative for liquid insulation media, and prosper the coconut gardener. Of course, coconut oil is more environmentally friendly than mineral oil.",,,978-1-7281-8835-5,152-155,IEEE , ,Oils;Media;Oil insulation;Minerals;Dielectrics;Standards;Power transformer insulation,,
4878,"Title:Evaluating the Effectiveness of Capsule Neural Network in Toxic Comment Classification Using Pre-Trained BERT Embeddings

 Large language models (LLMs) have attracted considerable interest in the fields of natural language understanding (NLU) and natural language generation (NLG) since their introduction. In contrast, the legacy of Capsule Neural Networks (CapsNet) appears to have been largely forgotten amidst all of this excitement. This project's objective is to reignite interest in CapsNet by reopening the previously closed studies and conducting a new research into CapsNet's potential. We present a study where CapsNet is used to classify toxic text by leveraging pre-trained BERT embed dings (bert-base-uncased) on a large multilingual dataset. In this experiment, CapsNet was tasked with categorizing toxic text. By comparing the performance of CapsNet to that of other architectures, such as DistilBERT, Vanilla Neural Networks (VNN), and Convolutional Neural Networks (CNN), we were able to achieve an accuracy of 90.44 %. This result highlights the benefits of CapsNet over text data and suggests new ways to enhance their performance so that it is comparable to DistilBERT and other reduced architectures.",H. Rahman Sifat; N. H. Nuri Sabab; T. Ahmed,,,Evaluating the Effectiveness of Capsule Neural Network in Toxic Comment Classification Using Pre-Trained BERT Embeddings,,,10.1109/TENCON58879.2023.10322429 ,IEEE Conferences ,,"Large language models (LLMs) have attracted considerable interest in the fields of natural language understanding (NLU) and natural language generation (NLG) since their introduction. In contrast, the legacy of Capsule Neural Networks (CapsNet) appears to have been largely forgotten amidst all of this excitement. This project's objective is to reignite interest in CapsNet by reopening the previously closed studies and conducting a new research into CapsNet's potential. We present a study where CapsNet is used to classify toxic text by leveraging pre-trained BERT embed dings (bert-base-uncased) on a large multilingual dataset. In this experiment, CapsNet was tasked with categorizing toxic text. By comparing the performance of CapsNet to that of other architectures, such as DistilBERT, Vanilla Neural Networks (VNN), and Convolutional Neural Networks (CNN), we were able to achieve an accuracy of 90.44 %. This result highlights the benefits of CapsNet over text data and suggests new ways to enhance their performance so that it is comparable to DistilBERT and other reduced architectures.",2159-3450,,979-8-3503-0219-6,42-46,IEEE , ,Neural networks;Text categorization;Natural language processing;Convolutional neural networks;Task analysis;IEEE Regions,,
4879,"Title:Class H insulation and its use in dry type station auxiliary & substation transformers

 Industrial and utility engineers are becoming more demanding for fire and explosion resistant transformers for use in large generating stations, unit substations, and in network applications. Fire insurance companies are threatening and are raising rates for insurance protection on transformers installed in buildings or in industrial plants where human life is endangered. Oil-filled transformers are not approved by Underwriters for such indoor usage. Askarel-filled transformers, although approved, have been known to liberate toxic gases under certain conditions. And besides, some 500 gallons of such liquid, which is now almost impossible to procure, is required per 1000 KVA of transformer rating.",M. L. Manning,,,Class H insulation and its use in dry type station auxiliary & substation transformers,,,10.1109/EIC.1951.7533296 ,IEEE Conferences ,,"Industrial and utility engineers are becoming more demanding for fire and explosion resistant transformers for use in large generating stations, unit substations, and in network applications. Fire insurance companies are threatening and are raising rates for insurance protection on transformers installed in buildings or in industrial plants where human life is endangered. Oil-filled transformers are not approved by Underwriters for such indoor usage. Askarel-filled transformers, although approved, have been known to liberate toxic gases under certain conditions. And besides, some 500 gallons of such liquid, which is now almost impossible to procure, is required per 1000 KVA of transformer rating.",,,978-1-5090-3128-3,14-17,IEEE , ,Power transformer insulation;Oil insulation;Temperature;Rubber;Resistance;Aging,,
4880,"Title:Progress report on natural esters for distribution and power transformers

 Natural ester seed oil based dielectric fluid is an environmentally advantaged fluid that is increasingly being used as a replacement for mineral oil and for high temperature flashpoint liquids, including silicone and R-TEMP. This report updates experience with use of the fluid over the last two years. Considerable studies have been conducted to investigate heat aging performance of cellulose, electrical contact thermal stability, dielectric strength, moisture sensitivity, and cold temperature performance. A series of reports presents a summary of work that has been completed to date and examines customer experience with the use of natural esters in real transformers. The work contains both new transformers and retro-fills in distribution and power transformers as well as step voltage regulators and switchgear.",P. Hopkinson; L. Dix; C. P. McShane; H. R. Moore; S. Moore; J. Murphy; T. Prevost; B. Beaster,,,Progress report on natural esters for distribution and power transformers,,,10.1109/PES.2009.5275850 ,IEEE Conferences ,,"Natural ester seed oil based dielectric fluid is an environmentally advantaged fluid that is increasingly being used as a replacement for mineral oil and for high temperature flashpoint liquids, including silicone and R-TEMP. This report updates experience with use of the fluid over the last two years. Considerable studies have been conducted to investigate heat aging performance of cellulose, electrical contact thermal stability, dielectric strength, moisture sensitivity, and cold temperature performance. A series of reports presents a summary of work that has been completed to date and examines customer experience with the use of natural esters in real transformers. The work contains both new transformers and retro-fills in distribution and power transformers as well as step voltage regulators and switchgear.",1932-5517,,978-1-4244-4241-6,1-3,IEEE , ,Power transformers;Petroleum;Temperature sensors;Dielectric liquids;Minerals;Resistance heating;Aging;Contacts;Thermal conductivity;Thermal stability,,
4881,"Title:When to replace aging transformers

 Transformers play critical roles in delivering power to distribution equipment for homes, commercial establishments and industrial facilities. Sudden failure of a transformer can have many serious repercussions leading to loss of power for a few minutes to hours. There are instances an outage could last for weeks because of system configuration, such as a simple radial system or the transformer was the single point failure. In industrial complexes an outage lasting a few minutes could lead to loss opportunities as well as millions of dollars in lost production and start up costs. Many older transformers have been in operation for more than 80 years without failure or major problems. Although there have been recent failures of units producing fires and explosions resulting in the release of toxic and combustible gases as well as smoke into the atmosphere; also OSHA has levied fines because of the type of incident. Many transformers in the petrochemical industry now fall under OSHA 1910.119, Mechanical Integrity regulations due to probability of catastrophic failure during power loss, resulting in release of highly hazardous chemicals. Transformers tanks containing more than 10,000 pounds of aggregates in some cases fall underneath the 1910.119 as well as 1910.269 regulations. Mineral oil in transformers is used as a media for cooling and insulating parts within close proximity. Mineral oil has a NFPA flammability rating of 1, indicating it is slightly flammable with a health rating of 1 as well, indicating a slight health hazard. However, during fault conditions mineral oil can be hazardous to your health and the environment. The purpose of this paper is to provide information and insight related to repair or outright replacement of aging transformers containing mineral oil under fault conditions such as the production of combustible gases. This paper will explain how oil sampling, gas analyses, internal inspection and testing were used to determine which required replacing or simple repairs. It will explain the use of standards such as IEEE C57 guidelines, to determine loading, hours of operation, degradation and other tests used to evaluate conditions and suitability for future operation of transformers. It will discuss the use of insulation power factor, Furan and other tests to help predict remaining life in transformers. It will discuss life cycles and vintage of transformer produced in the 1950's versus those manufactured for our facility after 1990. There will be discussions about methods, local repair shops employed to test and evaluate transformer incoming conditions and suitability for future service.",F. L. Dixon; D. Steward; J. Hoffmeister,,,When to replace aging transformers,,,10.1109/PCIC.2010.5666818 ,IEEE Conferences ,,"Transformers play critical roles in delivering power to distribution equipment for homes, commercial establishments and industrial facilities. Sudden failure of a transformer can have many serious repercussions leading to loss of power for a few minutes to hours. There are instances an outage could last for weeks because of system configuration, such as a simple radial system or the transformer was the single point failure. In industrial complexes an outage lasting a few minutes could lead to loss opportunities as well as millions of dollars in lost production and start up costs. Many older transformers have been in operation for more than 80 years without failure or major problems. Although there have been recent failures of units producing fires and explosions resulting in the release of toxic and combustible gases as well as smoke into the atmosphere; also OSHA has levied fines because of the type of incident. Many transformers in the petrochemical industry now fall under OSHA 1910.119, Mechanical Integrity regulations due to probability of catastrophic failure during power loss, resulting in release of highly hazardous chemicals. Transformers tanks containing more than 10,000 pounds of aggregates in some cases fall underneath the 1910.119 as well as 1910.269 regulations. Mineral oil in transformers is used as a media for cooling and insulating parts within close proximity. Mineral oil has a NFPA flammability rating of 1, indicating it is slightly flammable with a health rating of 1 as well, indicating a slight health hazard. However, during fault conditions mineral oil can be hazardous to your health and the environment. The purpose of this paper is to provide information and insight related to repair or outright replacement of aging transformers containing mineral oil under fault conditions such as the production of combustible gases. This paper will explain how oil sampling, gas analyses, internal inspection and testing were used to determine which required replacing or simple repairs. It will explain the use of standards such as IEEE C57 guidelines, to determine loading, hours of operation, degradation and other tests used to evaluate conditions and suitability for future operation of transformers. It will discuss the use of insulation power factor, Furan and other tests to help predict remaining life in transformers. It will discuss life cycles and vintage of transformer produced in the 1950's versus those manufactured for our facility after 1990. There will be discussions about methods, local repair shops employed to test and evaluate transformer incoming conditions and suitability for future service.",2161-8127,,978-1-4244-6801-0,1-14,IEEE , ,Oil insulation;Power transformer insulation;Petroleum;Gases;Maintenance engineering,,
4882,"Title:Multilingual Obnoxious Message Classification using Bidirectional Encoder Representation from Transformers (BERT)

 Everyday we witness incidents of social media bullying, harassment and various other toxic remarks. It has now become the part and parcel of social networking. Promotion of violence and hate speech, etc involve toxic comments in various forms on social media. The proposed model in this paper helps with the identification of all the obnoxious and questionable content on the internet by classifying the online comments as toxic or clean to tackle this problem. This is realised by using a pre-trained model - BERT. To enhance the performance, this model used RoBERTa (Robustly Optimized BERT Pre Training Approach), which has basically been formed by altering some hyperparameters which are tuned during the pre-training of BERT.",N. Banka; S. Narang; M. Gupta; A. Sharma; D. Upadhyay,,,Multilingual Obnoxious Message Classification using Bidirectional Encoder Representation from Transformers (BERT),,,10.1109/IC2E357697.2023.10262469 ,IEEE Conferences ,,"Everyday we witness incidents of social media bullying, harassment and various other toxic remarks. It has now become the part and parcel of social networking. Promotion of violence and hate speech, etc involve toxic comments in various forms on social media. The proposed model in this paper helps with the identification of all the obnoxious and questionable content on the internet by classifying the online comments as toxic or clean to tackle this problem. This is realised by using a pre-trained model - BERT. To enhance the performance, this model used RoBERTa (Robustly Optimized BERT Pre Training Approach), which has basically been formed by altering some hyperparameters which are tuned during the pre-training of BERT.",,,979-8-3503-3800-3,1-6,IEEE , ,Training;Social networking (online);Hate speech;Bidirectional control;Transformers;Encoding;Long short term memory,,
4883,"Title:Natural esters distribution transformers: A solution for environmental and fire risk prevention

 The electrical transformers insulated and cooled with mineral oils remain, still today, the most widespread and effective solution for converting electrical energy. Mineral oils are used for their excellent dielectric and thermal properties, but have a low flash/fire points and biodegradability and these factors may negatively contribute in cases of fire and toxic release with contamination of soil and surface water and groundwater. For these reasons, innovative insulating fluids, such as natural esters (vegetable oils), have been suggested worldwide.",M. Pompili; L. Calcara; A. Sturchio; F. Catanzaro,,,Natural esters distribution transformers: A solution for environmental and fire risk prevention,,,10.23919/AEIT.2016.7892754 ,IEEE Conferences ,,"The electrical transformers insulated and cooled with mineral oils remain, still today, the most widespread and effective solution for converting electrical energy. Mineral oils are used for their excellent dielectric and thermal properties, but have a low flash/fire points and biodegradability and these factors may negatively contribute in cases of fire and toxic release with contamination of soil and surface water and groundwater. For these reasons, innovative insulating fluids, such as natural esters (vegetable oils), have been suggested worldwide.",,,978-8-8872-3730-6,1-5,IEEE , ,Oils;Fires;Minerals;Power transformer insulation;Oil insulation;Contamination;Europe,,
4884,"Title:Multilingual Toxic Text Classification Model Based On Deep Learning

 The nature of comments usually has an important impact on the network environment. Polite and gentle comments can not only promote communication between users, but also maintain the stability of the network platform. On the contrary, rude and toxic comments will make the communication environment unacceptable. Therefore, we need to impose certain restrictions on comments. This article is based on the XLM-RoBERTa model to achieve the classification of multilingual toxic comments. We first use training and verification data to train and optimize the model, and then use the test data to get the final classification results. In addition, our model is compared with models such as LSTM and RNN. Experiments show that the model proposed in this paper has better classification performance.",W. Li; A. Li; T. Tang; Y. Wang; Z. Fang,,,Multilingual Toxic Text Classification Model Based On Deep Learning,,,10.1109/ICBAIE56435.2022.9985930 ,IEEE Conferences ,,"The nature of comments usually has an important impact on the network environment. Polite and gentle comments can not only promote communication between users, but also maintain the stability of the network platform. On the contrary, rude and toxic comments will make the communication environment unacceptable. Therefore, we need to impose certain restrictions on comments. This article is based on the XLM-RoBERTa model to achieve the classification of multilingual toxic comments. We first use training and verification data to train and optimize the model, and then use the test data to get the final classification results. In addition, our model is compared with models such as LSTM and RNN. Experiments show that the model proposed in this paper has better classification performance.",,,978-1-6654-5160-4,726-729,IEEE , ,Training;Deep learning;Text categorization;Big Data;Transformers;Data models;Stability analysis,,
4885,"Title:Frequency Response Analysis for Accounting the Changes in Permittivity of Natural Ester Oil with Mineral Oil

 Recently, ester based insulating oils including both natural ester and synthetic ester are being considered as potential alternatives to petroleum based mineral oil due to their better environmental friendly, higher fire safety, non-toxic and continuous overloading benefits. Ester oil has higher permittivity than mineral oil due to chemical compositions. Hence, the higher permittivity of ester oil affects electrical stress distribution in insulation system of transformer and it can also affects frequency response analysis of transformer during sweep frequency response analysis (SFRA). In this paper, to evaluate the differences in permittivity of natural ester and mineral oil, SFRA are performed for a given same winding geometry and insulation arrangement. The mineral oil transformer frequency responses are considered as a reference response and its results are compared with natural ester oil transformer. The frequency domain responses are evaluated using graphical analysis and commonly used numerical indicators of correlation coefficient, standard deviation, absolute sum of logarithmic error, mean square error and Max-min ratio.",A. Jain; A. Garg; J. Velandy; C. S. Narasimhan,,,Frequency Response Analysis for Accounting the Changes in Permittivity of Natural Ester Oil with Mineral Oil,,,10.1109/PIICON49524.2020.9113057 ,IEEE Conferences ,,"Recently, ester based insulating oils including both natural ester and synthetic ester are being considered as potential alternatives to petroleum based mineral oil due to their better environmental friendly, higher fire safety, non-toxic and continuous overloading benefits. Ester oil has higher permittivity than mineral oil due to chemical compositions. Hence, the higher permittivity of ester oil affects electrical stress distribution in insulation system of transformer and it can also affects frequency response analysis of transformer during sweep frequency response analysis (SFRA). In this paper, to evaluate the differences in permittivity of natural ester and mineral oil, SFRA are performed for a given same winding geometry and insulation arrangement. The mineral oil transformer frequency responses are considered as a reference response and its results are compared with natural ester oil transformer. The frequency domain responses are evaluated using graphical analysis and commonly used numerical indicators of correlation coefficient, standard deviation, absolute sum of logarithmic error, mean square error and Max-min ratio.",2642-5289,,978-1-7281-6664-3,1-5,IEEE , ,Temperature measurement;Oils;Frequency-domain analysis;Windings;Resonant frequency;Oil insulation;Frequency response,,
4886,"Title:Study on the Ageing Characteristics of Persea Americana Oil as an Alternative Transformer Insulation oil

 Mineral insulation oils have been used as a liquid insulation in electrical equipment for several decades. However, mineral oil is non-biodegradable and non-renewable. It has been predicted that they may run out in the near future. There is thus an urgent need to find their alternatives. Natural, plant based insulating oils are the solution. They are non-toxic, and possess higher fire points and excellent biodegradability characteristics. Therefore, to improve fire safety of transformers and to decrease the harmful environmental impact, there is an increasing demand for these insulating liquids as transformer insulating oils. Persea americana ester (PAE), a plant based oil has high biodegradability and is renewable. PAE has shown through experiments, a likelihood of being an alternative to mineral insulation oil (MIO) because of its good physico-chemical and electrical properties, so far investigated. Since insulating oil for transformers is used over several years, it is imperative to study the ageing characteristics of proposed new insulation oils. Accelerated ageing using open beaker method with copper catalyst was carried out to predict the reliability of Persea americana oil when in operation. The ageing test was based on accelerated thermal ageing to induce the ageing mechanisms within a short period (96 and 164 hours). Results obtained for Specific Resistivity at 27°C and 90°C, Dielectric dissipation factor, Total acidity and sludge for PAE; suggest that PAE could be a potential transformer insulating liquid. For comparison, the corresponding properties of mineral insulation oil (MIO) in the same experimental conditions were also measured. The results obtained as per the IEC and ASTM specifications gives hope for new natural liquid insulation oil.",B. M. Makaa; G. K. Irungu; D. K. Murage,,,Study on the Ageing Characteristics of Persea Americana Oil as an Alternative Transformer Insulation oil,,,10.1109/EIC43217.2019.9046615 ,IEEE Conferences ,,"Mineral insulation oils have been used as a liquid insulation in electrical equipment for several decades. However, mineral oil is non-biodegradable and non-renewable. It has been predicted that they may run out in the near future. There is thus an urgent need to find their alternatives. Natural, plant based insulating oils are the solution. They are non-toxic, and possess higher fire points and excellent biodegradability characteristics. Therefore, to improve fire safety of transformers and to decrease the harmful environmental impact, there is an increasing demand for these insulating liquids as transformer insulating oils. Persea americana ester (PAE), a plant based oil has high biodegradability and is renewable. PAE has shown through experiments, a likelihood of being an alternative to mineral insulation oil (MIO) because of its good physico-chemical and electrical properties, so far investigated. Since insulating oil for transformers is used over several years, it is imperative to study the ageing characteristics of proposed new insulation oils. Accelerated ageing using open beaker method with copper catalyst was carried out to predict the reliability of Persea americana oil when in operation. The ageing test was based on accelerated thermal ageing to induce the ageing mechanisms within a short period (96 and 164 hours). Results obtained for Specific Resistivity at 27°C and 90°C, Dielectric dissipation factor, Total acidity and sludge for PAE; suggest that PAE could be a potential transformer insulating liquid. For comparison, the corresponding properties of mineral insulation oil (MIO) in the same experimental conditions were also measured. The results obtained as per the IEC and ASTM specifications gives hope for new natural liquid insulation oil.",2576-6791,,978-1-5386-7624-0,287-290,IEEE , ,Vegetable oils;Oxidation;Accelerated aging;Oil insulation,,
4887,"Title:Inhibition Effect of TiO2 on Sulfur Corrosion in Transformer Insulation Oil

 The destructive effect of sulfide on the insulation performance of transformer should not be ignored. Therefore, reducing the destructive effects of sulfide has become an important research topic. As a kind of cheap and non-toxic material with excellent chemical stability and wide sources, TiO2 has good adsorption performance. In this paper, based on the molecular dynamics simulation method, the adsorption properties of different mass fractions of TiO2 in mineral insulating oil to DBDS, n-hexetylmercaptan represented by large molecular sulfide and hydrogen sulfide represented by small molecular sulfide. The results show that the addition of TiO2 can reduce the chance of forming hydrogen bond between sulfide molecules and insulating paper and copper windings, and inhibit the corrosion of sulfide molecules on transformer insulation system. This paper provides reference value for the study of preventive measures of sulfide.",J. Chen; L. Zhang; H. Li; C. Tang,,,Inhibition Effect of TiO2 on Sulfur Corrosion in Transformer Insulation Oil,,,10.1109/PandaFPE57779.2023.10140197 ,IEEE Conferences ,,"The destructive effect of sulfide on the insulation performance of transformer should not be ignored. Therefore, reducing the destructive effects of sulfide has become an important research topic. As a kind of cheap and non-toxic material with excellent chemical stability and wide sources, TiO2 has good adsorption performance. In this paper, based on the molecular dynamics simulation method, the adsorption properties of different mass fractions of TiO2 in mineral insulating oil to DBDS, n-hexetylmercaptan represented by large molecular sulfide and hydrogen sulfide represented by small molecular sulfide. The results show that the addition of TiO2 can reduce the chance of forming hydrogen bond between sulfide molecules and insulating paper and copper windings, and inhibit the corrosion of sulfide molecules on transformer insulation system. This paper provides reference value for the study of preventive measures of sulfide.",,,979-8-3503-2117-3,1213-1217,IEEE , ,Oils;Corrosion;Adsorption;Hydrogen;Windings;Oil insulation;Minerals,,
4888,"Title:Indian transformer industry gearing up for next-gen green liquids

 Transformer mineral oil has proved its suitability with transformer as an insulating medium, a coolant and a diagnostic tool over the past 100 years. Mineral oil is an environmental hazard which is not only toxic for human health, but also non-biodegradable and fast depleting (being a petroleum product). Also, this is not fire safe due to low flash & fire points. Transformer industry therefore, is seeing synthetic esters and natural esters liquids produced from various crop seeds (sunflower, soya bean etc.) as a substitute to mineral oil. The paper deals with challenges in designing, manufacturing, processing and operation of ester immersed transformers. It also discusses different tests carried out on natural ester liquid in factory received condition. The Paper also discusses the current status of Indian Transformer Industry in developing the ester immersed transformers for Indian utilities and development of Indian Standards on Green liquids.",D. Mehta; P. Kundu; A. Chowdhury,,,Indian transformer industry gearing up for next-gen green liquids,,,10.1109/NUICONE.2015.7449605 ,IEEE Conferences ,,"Transformer mineral oil has proved its suitability with transformer as an insulating medium, a coolant and a diagnostic tool over the past 100 years. Mineral oil is an environmental hazard which is not only toxic for human health, but also non-biodegradable and fast depleting (being a petroleum product). Also, this is not fire safe due to low flash & fire points. Transformer industry therefore, is seeing synthetic esters and natural esters liquids produced from various crop seeds (sunflower, soya bean etc.) as a substitute to mineral oil. The paper deals with challenges in designing, manufacturing, processing and operation of ester immersed transformers. It also discusses different tests carried out on natural ester liquid in factory received condition. The Paper also discusses the current status of Indian Transformer Industry in developing the ester immersed transformers for Indian utilities and development of Indian Standards on Green liquids.",,,978-1-4799-9991-0,1-4,IEEE , ,Liquids;Power transformer insulation;Oil insulation;Minerals;Dielectric liquids,,
4889,"Title:Gelling behaviour of natural ester transformer liquid under thermal ageing

 There have been increasing interests on natural esters as potential substitutes to conventional mineral oils in transformers, due to their less-flammable, non-toxic and environmentally friendly properties. The application has been successful in traction and distribution transformers with sealed type. But the susceptibility to oxidation and hence the suspected gelling behaviour prevent the application of natural esters in free-breathing transformers. This paper presents an experimental study of gelling/oxidation behaviour of thin films of a natural ester under thermal ageing. Ageing experiments were carried out with presence of air at different temperatures of 120 °C and 20 °C and durations up to 2 years. The gelling/oxidation behaviour of natural ester was evaluated in terms of changes in viscosity and acidity. Results showed that both viscosity and acidity can be used to assess gelling/oxidation behaviour of natural ester from initial liquid phase to eventually gelled form. In addition to temperature, the thickness of the thin film samples has a significant effect on the gelling speed, i.e. the thinner of the film, the faster of the gelling speed.",W. Lu; Q. Liu; Z. D. Wang,,,Gelling behaviour of natural ester transformer liquid under thermal ageing,,,10.1109/ICHVE.2012.6357101 ,IEEE Conferences ,,"There have been increasing interests on natural esters as potential substitutes to conventional mineral oils in transformers, due to their less-flammable, non-toxic and environmentally friendly properties. The application has been successful in traction and distribution transformers with sealed type. But the susceptibility to oxidation and hence the suspected gelling behaviour prevent the application of natural esters in free-breathing transformers. This paper presents an experimental study of gelling/oxidation behaviour of thin films of a natural ester under thermal ageing. Ageing experiments were carried out with presence of air at different temperatures of 120 °C and 20 °C and durations up to 2 years. The gelling/oxidation behaviour of natural ester was evaluated in terms of changes in viscosity and acidity. Results showed that both viscosity and acidity can be used to assess gelling/oxidation behaviour of natural ester from initial liquid phase to eventually gelled form. In addition to temperature, the thickness of the thin film samples has a significant effect on the gelling speed, i.e. the thinner of the film, the faster of the gelling speed.",,,978-1-4673-4746-4,643-647,IEEE , ,Aging;Viscosity;Films;Oxidation;Temperature measurement;Liquids;Power transformers,,
4890,"Title:Investigation of Persea Americana Oil as an Alternative Transformer Insulation Oil

 Mineral insulating fluids have conventionally been used as insulating liquids in electrical equipment for over a century. These fluids serve as dielectrics and coolants. They are however known to be environmentally toxic and are highly flammable. Hence, they require costly fire protection schemes and deluge systems. Increasing awareness of environmental protection and fire safety is leading to accelerating trend of looking for plant based oil alternatives that are environmentally friendly. Increase in power rating of electrical equipment also calls for high temperature performance insulating oils. Plant based dielectric fluids have been found to defeat mineral oils in many of these aspects. They are nontoxic, possess better thermal properties and have excellent biodegradability. In order to reduce the adverse environmental impact and to improve the fire safety of transformers, there is an increasing demand for plant based insulating liquids as transformer insulating oils. This paper presents results of series of experiments that were performed to investigate the electrical, chemical, physical and thermal properties of food grade Persea americana ester (PAE) for possible use as insulation oil. For comparison, the corresponding properties of mineral insulation oil (MIO) in the same experimental conditions were also measured and compared with those of PAE. In this investigation, two different types of Persea americana oil samples consisting of extra virgin and refined PAE were tested. The obtained results show that the average electrical, chemical, physical and thermal properties of PAE meet the IEC and IEEE specifications for new natural liquid insulation oils. This may suggest that Persea americana oil can be tried as an alternative transformer liquid insulation.",B. M. Makaa; G. K. Irungu; D. K. Murage,,,Investigation of Persea Americana Oil as an Alternative Transformer Insulation Oil,,,10.1109/EIC43217.2019.9046539 ,IEEE Conferences ,,"Mineral insulating fluids have conventionally been used as insulating liquids in electrical equipment for over a century. These fluids serve as dielectrics and coolants. They are however known to be environmentally toxic and are highly flammable. Hence, they require costly fire protection schemes and deluge systems. Increasing awareness of environmental protection and fire safety is leading to accelerating trend of looking for plant based oil alternatives that are environmentally friendly. Increase in power rating of electrical equipment also calls for high temperature performance insulating oils. Plant based dielectric fluids have been found to defeat mineral oils in many of these aspects. They are nontoxic, possess better thermal properties and have excellent biodegradability. In order to reduce the adverse environmental impact and to improve the fire safety of transformers, there is an increasing demand for plant based insulating liquids as transformer insulating oils. This paper presents results of series of experiments that were performed to investigate the electrical, chemical, physical and thermal properties of food grade Persea americana ester (PAE) for possible use as insulation oil. For comparison, the corresponding properties of mineral insulation oil (MIO) in the same experimental conditions were also measured and compared with those of PAE. In this investigation, two different types of Persea americana oil samples consisting of extra virgin and refined PAE were tested. The obtained results show that the average electrical, chemical, physical and thermal properties of PAE meet the IEC and IEEE specifications for new natural liquid insulation oils. This may suggest that Persea americana oil can be tried as an alternative transformer liquid insulation.",2576-6791,,978-1-5386-7624-0,197-200,IEEE , ,Oils;Dielectric liquids;Standards;Power transformer insulation;Oil insulation,,
4891,"Title:Silicone oil as replacement fluid for PCBs in transformers

 A brief critical review of the electrical, thermal and flammability properties of silicone oil for transformers is presented in comparison to the same properties for polychlorinated biphenyl fluids (PCB) and mineral oil. It is deduced that silicone oil is an acceptable substitute for PCBs. Despite a significantly lower fire resistance, silicone oil is not toxic and is compatible with traces of PCBs and mineral oil. It is therefore perfectly suited for the retrofilling of PCB contaminated transformers.",J. Crine,,,Silicone oil as replacement fluid for PCBs in transformers,11,3,10.1109/CEEJ.1986.6594046 ,IEEE Journals ,,"A brief critical review of the electrical, thermal and flammability properties of silicone oil for transformers is presented in comparison to the same properties for polychlorinated biphenyl fluids (PCB) and mineral oil. It is deduced that silicone oil is an acceptable substitute for PCBs. Despite a significantly lower fire resistance, silicone oil is not toxic and is compatible with traces of PCBs and mineral oil. It is therefore perfectly suited for the retrofilling of PCB contaminated transformers.",0700-9216,,,110-113,IEEE , ,Oil insulation;Minerals;Thermal stability;Liquids;Power transformers;Chemicals,,
4892,"Title:The research of Power Electronic Transformer (PET) in Smart distribution network

 The transformers have been widely used in traditional power system, the primary functions of which are voltage-transformation, isolation and energy-transfer. Now with the development of Smart-Grid, power system requires an increasing penetration of the renewable energy resources and other distributed generations around loads, and an active role for DSOs in controlling the network stability, optimizing central and security. Owing to the bulky iron cores, heavy copper windings and simple functions, the traditional transformer can't satisfy the requirements of SG. Power Electronic Transformer which has been developed for years, can adjust to the development of SG, and improve the performance of distribution system. This paper presents a new topology of PET based on three-level converter, which is used in active medium-voltage distribution network, and supplies a possible solution for bi-directional energy flow of generated loads, and the stability of PS. With the high-performance control strategies-SVM, PET not only realized the all functions of old transformers, but also permitted the distributed power to inject into network. Additionally, the proposed PET performs typical functions and has advantages such as power factor correction, voltage regulation, voltage sag and swell elimination, voltage flicker reduction and protection capability in fault situations. In addition, it has other benefits such as light weight, low volume and no toxic dielectric coolants. First the paper introduced the fundamentals of PET, and studied on the mathematical model of the new topology. In order to verify the validity of this device, we used MATLAB/PST software to simulate the PET model. As a result of divided DC bus with H-bridge converter and connecting of DGs, the neural point's voltage of DC-Bus is unbalanced, the paper proposed an arithmetic to overcome this problem and suppress the effect of ripple voltage on common DC-bus. Eventually simulations results validate the feasibility of the new topology and the control strategies.",Zhibing Wang; Kunshan Yu,,,The research of Power Electronic Transformer (PET) in Smart distribution network,,,10.1109/POWERCON.2010.5666398 ,IEEE Conferences ,,"The transformers have been widely used in traditional power system, the primary functions of which are voltage-transformation, isolation and energy-transfer. Now with the development of Smart-Grid, power system requires an increasing penetration of the renewable energy resources and other distributed generations around loads, and an active role for DSOs in controlling the network stability, optimizing central and security. Owing to the bulky iron cores, heavy copper windings and simple functions, the traditional transformer can't satisfy the requirements of SG. Power Electronic Transformer which has been developed for years, can adjust to the development of SG, and improve the performance of distribution system. This paper presents a new topology of PET based on three-level converter, which is used in active medium-voltage distribution network, and supplies a possible solution for bi-directional energy flow of generated loads, and the stability of PS. With the high-performance control strategies-SVM, PET not only realized the all functions of old transformers, but also permitted the distributed power to inject into network. Additionally, the proposed PET performs typical functions and has advantages such as power factor correction, voltage regulation, voltage sag and swell elimination, voltage flicker reduction and protection capability in fault situations. In addition, it has other benefits such as light weight, low volume and no toxic dielectric coolants. First the paper introduced the fundamentals of PET, and studied on the mathematical model of the new topology. In order to verify the validity of this device, we used MATLAB/PST software to simulate the PET model. As a result of divided DC bus with H-bridge converter and connecting of DGs, the neural point's voltage of DC-Bus is unbalanced, the paper proposed an arithmetic to overcome this problem and suppress the effect of ripple voltage on common DC-bus. Eventually simulations results validate the feasibility of the new topology and the control strategies.",,,978-1-4244-5940-7,1-7,IEEE , ,Modulation;Silicon;Neodymium;Nickel,,
4893,"Title:Dielectric performance of solid dielectric immersed in vegetable oil with antioxidant

 Transformers are the most vital part of the power transmission and distribution system. Protecting them from all possible abnormalities is of very high priority. The insulation levels in the transformers need to be of very high grade as the power and voltage levels of a transformer are very high. Transformers are generally filled with petroleum based mineral oil as an insulator and also as a coolant inside them. These oils are highly inflammable and also highly toxic. They are also non-biodegradable, causing major harm to the environment. Vegetable oils which are abundant in nature unlike the mineral oil is being studied as a suitable substitute for mineral oils as transformer oil. The availability of vegetable oils differ from place to place. The work here focusses on the commercially available vegetable oils in India. Seven different samples of oil are tested for their dielectric properties and viscosity and the best one among them is tested with a solid dielectric (epoxy) immersed within it in order to simulate more appropriate conditions of a practical transformer. The tests are conducted based on Indian Standards (IS6792).",M. George; P. Manikandan,,,Dielectric performance of solid dielectric immersed in vegetable oil with antioxidant,,,10.1109/ICCPCT.2016.7530260 ,IEEE Conferences ,,"Transformers are the most vital part of the power transmission and distribution system. Protecting them from all possible abnormalities is of very high priority. The insulation levels in the transformers need to be of very high grade as the power and voltage levels of a transformer are very high. Transformers are generally filled with petroleum based mineral oil as an insulator and also as a coolant inside them. These oils are highly inflammable and also highly toxic. They are also non-biodegradable, causing major harm to the environment. Vegetable oils which are abundant in nature unlike the mineral oil is being studied as a suitable substitute for mineral oils as transformer oil. The availability of vegetable oils differ from place to place. The work here focusses on the commercially available vegetable oils in India. Seven different samples of oil are tested for their dielectric properties and viscosity and the best one among them is tested with a solid dielectric (epoxy) immersed within it in order to simulate more appropriate conditions of a practical transformer. The tests are conducted based on Indian Standards (IS6792).",,,978-1-5090-1277-0,1-7,IEEE , ,Vegetable oils;Oil insulation;Power transformer insulation;Minerals;Viscosity;Dielectrics,,
4894,"Title:An Air Pyrolysis Study of Cast Bisphenol a Epoxy Transformer Coils

 This study experimentally determines the products of combustion of Bisphenol A epoxy in air and considers a worst case situation to arrive at a calculation ation of the maximum toxic vapor concentration for the combustion products. Comparisons to the concentrations of the products of combustion for common transformer insulating ulating fluids and several types of construction wood are made in this study.",F. S. Brugner; A. J. Jonnatti,,,An Air Pyrolysis Study of Cast Bisphenol a Epoxy Transformer Coils,PAS-102,7,10.1109/TPAS.1983.318208 ,IEEE Journals ,,This study experimentally determines the products of combustion of Bisphenol A epoxy in air and considers a worst case situation to arrive at a calculation ation of the maximum toxic vapor concentration for the combustion products. Comparisons to the concentrations of the products of combustion for common transformer insulating ulating fluids and several types of construction wood are made in this study.,0018-9510,,,2203-2207,IEEE , ,Coils;Power transformer insulation;Combustion;Oil insulation;Resins;Humans;Pollution measurement;Solids;Electrical equipment industry;Temperature,,
4895,"Title:Use of Peltier Modules for Liquid Cooling

 This paper deals with the use of Peltier modules for liquid cooling. The aim is to use a two-circuit device that uses Peltier modules to cool the flowing liquid, which serves as a cooling medium for the accumulation of cold in the tank. This tank also serves as an exchanger that transfers heat between the primary and secondary circuits of the device. This configuration is especially useful when dealing with radiation, toxic substances or on the contrary compliance with cleanliness standards in the food industry. The paper describes the overall efficiency of the device in comparison with traditional cooling methods as well as other pros and cons of such a solution.",R. Guráš; M. Mahdal,,,Use of Peltier Modules for Liquid Cooling,,,10.1109/ICCC51557.2021.9454645 ,IEEE Conferences ,,"This paper deals with the use of Peltier modules for liquid cooling. The aim is to use a two-circuit device that uses Peltier modules to cool the flowing liquid, which serves as a cooling medium for the accumulation of cold in the tank. This tank also serves as an exchanger that transfers heat between the primary and secondary circuits of the device. This configuration is especially useful when dealing with radiation, toxic substances or on the contrary compliance with cleanliness standards in the food industry. The paper describes the overall efficiency of the device in comparison with traditional cooling methods as well as other pros and cons of such a solution.",,,978-1-7281-8609-2,1-4,IEEE , ,Vibrations;Heating systems;Liquid cooling;Food industry;Reservoirs;Steady-state;Standards,,
4896,"Title:The Making Processes of Natural Ester from Palm Oil through Transesterification Reaction for Transformer Application

 It has been more than a hundred year since mineral oil was used as liquid insulation for high voltage transformer. Mineral oil is obtained from petroleum through distillation processes. Petroleum is known as non-renewable resources and non-biodegradable. The flash point of mineral oil is around 150°C, thus it creates a problem for high temperature condition. Based on those facts, a new formula of liquid insulation is needed to replace mineral oil. Natural ester oil is derived from vegetable oil. It is biodegradable, non-toxic, non-flammable, and has a higher breakdown voltage. However, the viscosity of vegetable oil is high so that further treatment is needed in order to reduce the viscosity of the oil. This paper reports a sequential procedure in making natural ester oil through transesterification processes using palm oil for transformer application. The alkyl ester can be obtained from the reaction of triglycerides, alcohol and strong base as a catalyst. The by-product, which is glycerol, is then separated from the oil by using gravitational method as its density is higher than the natural ester oil. In this research, methanol is used as a reactant in transesterification reaction due to its cheap price and its fast reactivity. Potassium hydroxide also has a big role in transesterification, its used as a catalyst to make the process easier.",S. Suwarno; Y. E. Sari; T. I. D. K. Dewi,,,The Making Processes of Natural Ester from Palm Oil through Transesterification Reaction for Transformer Application,,,10.1109/ICHVEPS47643.2019.9011068 ,IEEE Conferences ,,"It has been more than a hundred year since mineral oil was used as liquid insulation for high voltage transformer. Mineral oil is obtained from petroleum through distillation processes. Petroleum is known as non-renewable resources and non-biodegradable. The flash point of mineral oil is around 150°C, thus it creates a problem for high temperature condition. Based on those facts, a new formula of liquid insulation is needed to replace mineral oil. Natural ester oil is derived from vegetable oil. It is biodegradable, non-toxic, non-flammable, and has a higher breakdown voltage. However, the viscosity of vegetable oil is high so that further treatment is needed in order to reduce the viscosity of the oil. This paper reports a sequential procedure in making natural ester oil through transesterification processes using palm oil for transformer application. The alkyl ester can be obtained from the reaction of triglycerides, alcohol and strong base as a catalyst. The by-product, which is glycerol, is then separated from the oil by using gravitational method as its density is higher than the natural ester oil. In this research, methanol is used as a reactant in transesterification reaction due to its cheap price and its fast reactivity. Potassium hydroxide also has a big role in transesterification, its used as a catalyst to make the process easier.",,,978-1-7281-2669-2,24-028,IEEE , ,Vegetable oils;Carbon;Methanol;Production;Silicon compounds;Biofuels,,
4897,"Title:DC power flow control in DC networks through DC/DC zero sequence blocking transformer

 World is moving to adopt the renewable energy sources to overcome the power issues with zero toxic emission. The key problem is to inject huge power to the grid, generating from renewable energy sources with traditional electrical equipment and grid infrastructure. Currently, work on DC networks is achieving great attention in distributed power generation system, which arise the problem related to the significance of DC power flow control in DC networks. Interline power flow controller (IPFC) are used to control of power flow in the multi-lines and parallel transmission lines. In this paper, a new topology for Interline DC Power Flow Controller (IDCPFC) based on the Zero Sequence Blocking Transformer (ZSBT) has been proposed and analyzed. In the proposed model, the buck converter works as a variable transformer and its current is regulated through the duty cycle of converter. In Comparison with pervious topologies the control algorithm is simple. To validate the topology, simulation results of proposed topology are investigated in this paper. Large-scale network has the characteristics of complex system, and its survivability is different from simple network. The current network survivability studies usually only aim for a specific network level or type, and seldom investigate survivability from a system perspective. In this paper, the concept of large-scale network survivability is defined from the perspective of complex system, the survivability association is analyzed based upon the correlation characteristics of complex system, and the structural model of large-scale network survivability association is established and its properties are analyzed. On the basis of survivability association properties, the survivability association function is defined based upon set pair analysis theory, which is utilized to characterize the survivability association degree among subsystems in large-scale network. Finally, the effectiveness of the model proposed in this paper is validated through case study.",M. Q. Khan; M. M. Khan; J. Huawei; Z. Yi,,,DC power flow control in DC networks through DC/DC zero sequence blocking transformer,,,10.1109/IAEAC.2017.8054193 ,IEEE Conferences ,,"World is moving to adopt the renewable energy sources to overcome the power issues with zero toxic emission. The key problem is to inject huge power to the grid, generating from renewable energy sources with traditional electrical equipment and grid infrastructure. Currently, work on DC networks is achieving great attention in distributed power generation system, which arise the problem related to the significance of DC power flow control in DC networks. Interline power flow controller (IPFC) are used to control of power flow in the multi-lines and parallel transmission lines. In this paper, a new topology for Interline DC Power Flow Controller (IDCPFC) based on the Zero Sequence Blocking Transformer (ZSBT) has been proposed and analyzed. In the proposed model, the buck converter works as a variable transformer and its current is regulated through the duty cycle of converter. In Comparison with pervious topologies the control algorithm is simple. To validate the topology, simulation results of proposed topology are investigated in this paper. Large-scale network has the characteristics of complex system, and its survivability is different from simple network. The current network survivability studies usually only aim for a specific network level or type, and seldom investigate survivability from a system perspective. In this paper, the concept of large-scale network survivability is defined from the perspective of complex system, the survivability association is analyzed based upon the correlation characteristics of complex system, and the structural model of large-scale network survivability association is established and its properties are analyzed. On the basis of survivability association properties, the survivability association function is defined based upon set pair analysis theory, which is utilized to characterize the survivability association degree among subsystems in large-scale network. Finally, the effectiveness of the model proposed in this paper is validated through case study.",,,978-1-4673-8979-2,1149-1153,IEEE , ,Load flow;Topology;Network topology;Power conversion;Power transmission lines;Voltage control,,
4898,"Title:Comparative Study of Liquid Insulating Materials for High Voltage Transformer

 In recent years, the latest technology, Gas-to-liquid (GTL) has been developed as an alternative to mineral oil. Natural ester oil is derived from vegetable oil. It is biodegradable, non-toxic, non-flammable, and has a higher breakdown voltage. Compared to conventional mineral oils and natural ester oils, GTL based oils are designed with a high level of composition and consistent performance, high purity, excellent resistance to degradation and are essentially sulfur free. In this study, GTL oil, mineral oil and natural ester oil will be compared in performance. Tests carried out for GTL oil, mineral oil and natural ester oil are tests of color scale and appearance, acid content, viscosity, moisture or water content, dielectric losses, breakdown voltage, and Dissolved Gas Analysis (DGA). Increased contaminants and free radicals cause an increase in dielectric losses and a decrease in oil resistivity. In addition, a strong correlation was found between the relative water content of oil and the breakdown voltage.",A. D. Sorimuda Ritonga; Y. Erina Sari; S. Suwarno,,,Comparative Study of Liquid Insulating Materials for High Voltage Transformer,,,10.1109/ICHVEPS47643.2019.9011143 ,IEEE Conferences ,,"In recent years, the latest technology, Gas-to-liquid (GTL) has been developed as an alternative to mineral oil. Natural ester oil is derived from vegetable oil. It is biodegradable, non-toxic, non-flammable, and has a higher breakdown voltage. Compared to conventional mineral oils and natural ester oils, GTL based oils are designed with a high level of composition and consistent performance, high purity, excellent resistance to degradation and are essentially sulfur free. In this study, GTL oil, mineral oil and natural ester oil will be compared in performance. Tests carried out for GTL oil, mineral oil and natural ester oil are tests of color scale and appearance, acid content, viscosity, moisture or water content, dielectric losses, breakdown voltage, and Dissolved Gas Analysis (DGA). Increased contaminants and free radicals cause an increase in dielectric losses and a decrease in oil resistivity. In addition, a strong correlation was found between the relative water content of oil and the breakdown voltage.",,,978-1-7281-2669-2,1-5,IEEE , ,Vegetable oils;Minerals;Moisture;Pollution measurement;Dielectrics;Viscosity,,
4899,"Title:Gaseous insulation for high-voltage transformers

 SULFUR HEXAFLUORIDE in high-voltage apparatus fulfills these requirements of a gaseous dielectric: 1. dielectric strength should be high at a low-gauge pressure; 2. temperature of condensation should be equal to or lower than that at which the apparatus is operated; 3. the gas itself and its products of decomposition should not be toxic or of readily controllable toxicity. Similarly, the gas should not corrode materials of construction; 4. the gas should be chemically inert and thermally stable; 5. it should have a high heat transfer coefficient.",G. Camilli; G. S. Gordon; R. E. Plump,,,Gaseous insulation for high-voltage transformers,71,6,10.1109/EE.1952.6437531 ,IEEE Journals ,,"SULFUR HEXAFLUORIDE in high-voltage apparatus fulfills these requirements of a gaseous dielectric: 1. dielectric strength should be high at a low-gauge pressure; 2. temperature of condensation should be equal to or lower than that at which the apparatus is operated; 3. the gas itself and its products of decomposition should not be toxic or of readily controllable toxicity. Similarly, the gas should not corrode materials of construction; 4. the gas should be chemically inert and thermally stable; 5. it should have a high heat transfer coefficient.",2376-7804,,,513-513,IEEE , ,Sulfur hexafluoride;Power transformer insulation;Dielectric breakdown;Heat transfer;Oil insulation;Thermal stability,,
4900,"Title:A new synthetic ester fluid for transformers

 A synthetic ester fluid Midel, is described which has exceptional tolerance to moisture, high thermal stability and good resistance to fire. This fluid has been developed to replace the highly toxic Polychlorobiphenols (PCB's) it has good electrical properties such as high breakdown strength, high resistivity and resistance to arcing.",F. B. Waddington,,,A new synthetic ester fluid for transformers,,,10.1109/EIC.1979.7461123 ,IEEE Conferences ,,"A synthetic ester fluid Midel, is described which has exceptional tolerance to moisture, high thermal stability and good resistance to fire. This fluid has been developed to replace the highly toxic Polychlorobiphenols (PCB's) it has good electrical properties such as high breakdown strength, high resistivity and resistance to arcing.",,,978-1-5090-3113-9,211-213,IEEE , ,Fluids;Oil insulation;Moisture;Thermal stability;Power transformer insulation;Fires;Dielectrics,,
4901,"Title:Biodegradable dielectric liquids for transformer applications

 Summary form only given. Mineral oil, which is a derivative of petroleum crude, is used in transformers, capacitors, switchgears and in circuit breaker from the beginning. The Polychlorinated biphenyls were introduced as non-flammable, high chemical stability synthetic liquids for transformers, capacitors, and for switchgear. The worldwide depletion of petroleum crudes and alternative to Polychlorinated biphenyls has stimulated the pattern of research and evaluation of hydrocarbons, esters both natural and synthetic in respect of characteristics to suit electrical applications. A number of synthetic dielectric liquids such as silicone oil, organic esters and aromatic hydrocarbons in place of PCB's were developed and are being used in a variety of electrical applications because of their fire-resistance, thermal stability & high dielectric behavior. It is very essential to use such biodegradable, non-toxic dielectric fluids for transformer applications. Not only it is important for a dielectric fluid to be biodegradable, but also it should not pollute the ecosystem by giving out any hazardous materials. When transformers located close proximity to the rivers, canals, sewage treatment work spots, high rise buildings, hospitals and educational institutions, risk is minimized my using fire resistant, biodegradable, non-toxic dielectric fluids. This ensures that the ecosystem is clean, free from toxic contaminant for the better life. CPRI has undertaken research work on these areas to cater to the needs for the Indian systems.",P. Thomas,,,Biodegradable dielectric liquids for transformer applications,1,,10.1109/ISEIM.2005.193350 ,IEEE Conferences ,,"Summary form only given. Mineral oil, which is a derivative of petroleum crude, is used in transformers, capacitors, switchgears and in circuit breaker from the beginning. The Polychlorinated biphenyls were introduced as non-flammable, high chemical stability synthetic liquids for transformers, capacitors, and for switchgear. The worldwide depletion of petroleum crudes and alternative to Polychlorinated biphenyls has stimulated the pattern of research and evaluation of hydrocarbons, esters both natural and synthetic in respect of characteristics to suit electrical applications. A number of synthetic dielectric liquids such as silicone oil, organic esters and aromatic hydrocarbons in place of PCB's were developed and are being used in a variety of electrical applications because of their fire-resistance, thermal stability & high dielectric behavior. It is very essential to use such biodegradable, non-toxic dielectric fluids for transformer applications. Not only it is important for a dielectric fluid to be biodegradable, but also it should not pollute the ecosystem by giving out any hazardous materials. When transformers located close proximity to the rivers, canals, sewage treatment work spots, high rise buildings, hospitals and educational institutions, risk is minimized my using fire resistant, biodegradable, non-toxic dielectric fluids. This ensures that the ecosystem is clean, free from toxic contaminant for the better life. CPRI has undertaken research work on these areas to cater to the needs for the Indian systems.",,,4-88686-063-X,135-136 Vol. 1,IEEE , ,Biodegradable materials;Dielectric liquids;Oil insulation;Petroleum;Hydrocarbons;Ecosystems;Minerals;Switched capacitor circuits;Switching circuits;Circuit breakers,,
4902,"Title:Distribution utility experience with natural ester dielectric coolants

 Natural ester seed oil is a biodegradable fluid that is increasingly being used as a replacement for mineral oil and for high temperature flashpoint liquids, including silicone and R-TEMP. This paper updates work that was presented in 2006. Experience to date continues to be positive.",J. R. Murphy; J. Graham,,,Distribution utility experience with natural ester dielectric coolants,,,10.1109/PES.2009.5275170 ,IEEE Conferences ,,"Natural ester seed oil is a biodegradable fluid that is increasingly being used as a replacement for mineral oil and for high temperature flashpoint liquids, including silicone and R-TEMP. This paper updates work that was presented in 2006. Experience to date continues to be positive.",1932-5517,,978-1-4244-4241-6,1-3,IEEE , ,Dielectrics;Coolants;Transformers;Petroleum;Fires;Minerals;Biodegradable materials;Safety;Aging;Substations,,
4903,"Title:Design and Modelling of Multilevel Inverter for Micro Wind Energy Generation System

 Renewable energy sources are used extensively in a wide variety of applications as it is available in abundance, and also pollution free. This paper discusses the wind energy system connected to the micro grid system used for small scale operations. Wind Energy Systems are connected to the grid through a conventional two level inverter which results in high value of THD and harmonics in current. This problem can be overcome by multilevel converter with different switching strategies. The simulation is done in MATLAB tool and comparison is made to prove the results with hybrid multilevel inverter provide low value of THD. Distribution of Reusable Energy based power generation plants, their incorporation into the already existing utility grid will result to the concept of Micro grid and Smart grid system which can be obtained from the Simulation and investigation of a standalone DC Micro grid System. Proposed system utilizes wind Energy system as the main source of the grid and battery as the Energy Storage System (ESS). Usage of renewable energy sources for electrical application will meaningfully lower the fuel consumption for the generation of electrical power that in turn automatically reduces the emissions of greenhouse toxic gas. Along with wind energy system, this paper proposes a design that joins the doubly taken care of enlistment generator (DFIG) based breeze turbine and Solid State Transformer activity. Because of the breeze power being a wild asset, different issues in regards to control quality and security issues are created. The Solid State Transformer (SST) has been discovered to be helpful in mix of various dispersed fuel sources just as wind power in the appropriation matrix with different functionalities.",R. Revathy; R. Priya; S. Priyanka,,,Design and Modelling of Multilevel Inverter for Micro Wind Energy Generation System,,,10.1109/ICSCAN53069.2021.9526375 ,IEEE Conferences ,,"Renewable energy sources are used extensively in a wide variety of applications as it is available in abundance, and also pollution free. This paper discusses the wind energy system connected to the micro grid system used for small scale operations. Wind Energy Systems are connected to the grid through a conventional two level inverter which results in high value of THD and harmonics in current. This problem can be overcome by multilevel converter with different switching strategies. The simulation is done in MATLAB tool and comparison is made to prove the results with hybrid multilevel inverter provide low value of THD. Distribution of Reusable Energy based power generation plants, their incorporation into the already existing utility grid will result to the concept of Micro grid and Smart grid system which can be obtained from the Simulation and investigation of a standalone DC Micro grid System. Proposed system utilizes wind Energy system as the main source of the grid and battery as the Energy Storage System (ESS). Usage of renewable energy sources for electrical application will meaningfully lower the fuel consumption for the generation of electrical power that in turn automatically reduces the emissions of greenhouse toxic gas. Along with wind energy system, this paper proposes a design that joins the doubly taken care of enlistment generator (DFIG) based breeze turbine and Solid State Transformer activity. Because of the breeze power being a wild asset, different issues in regards to control quality and security issues are created. The Solid State Transformer (SST) has been discovered to be helpful in mix of various dispersed fuel sources just as wind power in the appropriation matrix with different functionalities.",,,978-1-6654-3986-2,1-6,IEEE , ,Wind energy generation;Renewable energy sources;Switches;Tools;Systems modeling;Multilevel inverters;Wind turbines,,
4904,"Title:Silicone Transformer Liquid: Use, Maintenance, and Safety

 Silicone transformer liquid has been in use in over 10 000 small and medium power transformers in the United States since 1972. In this time, the reliability and performance of silicone liquid has been proven. Silicone liquid is chemically inert and thermally stable. These characteristics will allow for a long and useful life and ease of reclaiming contaminated liquid. Similar procedures are used to process and test silicone liquid and mineral oil. Transformer designs have been modified in only minor ways to accommodate the differences between silicone, mineral oil, and askarel. The coefficient of expansion, the heat transfer characteristics, and the dielectric properties have all been thoroughly investigated. Silicone fluid has been used in new and retrofilled transformers without any unusual or premium design features. In a monitoring program, no water contamination, leaking, overheating or any other operational problem were experienced in over three million documented hours of service in all kinds of environments. The safety of silicone liquid has been established through thorough testing and field experience. The very low heat release rates and unique burning characteristics combine to make silicone a very safe material for use in power transformers. In addition, silicone liquids are among the least toxic of all commercial chemicals. This, and their ecological compatibility, make silicone a safe environmental choice in replacing askarel.",R. E. Miller,,,"Silicone Transformer Liquid: Use, Maintenance, and Safety",IA-17,5,10.1109/TIA.1981.4503983 ,IEEE Journals ,,"Silicone transformer liquid has been in use in over 10 000 small and medium power transformers in the United States since 1972. In this time, the reliability and performance of silicone liquid has been proven. Silicone liquid is chemically inert and thermally stable. These characteristics will allow for a long and useful life and ease of reclaiming contaminated liquid. Similar procedures are used to process and test silicone liquid and mineral oil. Transformer designs have been modified in only minor ways to accommodate the differences between silicone, mineral oil, and askarel. The coefficient of expansion, the heat transfer characteristics, and the dielectric properties have all been thoroughly investigated. Silicone fluid has been used in new and retrofilled transformers without any unusual or premium design features. In a monitoring program, no water contamination, leaking, overheating or any other operational problem were experienced in over three million documented hours of service in all kinds of environments. The safety of silicone liquid has been established through thorough testing and field experience. The very low heat release rates and unique burning characteristics combine to make silicone a very safe material for use in power transformers. In addition, silicone liquids are among the least toxic of all commercial chemicals. This, and their ecological compatibility, make silicone a safe environmental choice in replacing askarel.",1939-9367,,,463-468,IEEE , ,Safety;Power transformers;Oil insulation;Testing;Minerals;Petroleum;Maintenance;Chemicals;Heat transfer;Dielectrics,,
4905,"Title:Soil ecotoxicity of natural ester transformer liquids

 Mineral oils have been used for decades as transformer fluids because of their excellent dielectric properties and availability. In the last decade natural ester transformer liquids have been introduced in the market. Natural ester transformer liquids are readily biodegradable fluids and induce very low toxicity levels against aquatic organisms like fish, algae or daphnia. On the other hand, the behavior of natural esters at the end of their life it is not fully understood because in service transformers containing natural esters have not reached that stage yet. Moreover, the interaction of natural esters with aquatic organisms has been thoroughly studied but that is not the case regarding soil organisms. This work presents the study of the behavior of natural esters, at the beginning and at the end of their life, in contact with water and soil organisms. The natural ester transformer liquid has been aged under severe oxidative conditions in order to obtain samples representing the state of the liquid well beyond the end of its life. Samples of non-aged and aged liquid have been tested according to OECD 207 and OECD 208 standards. OECD 207 standard defines the method for testing toxicity of chemicals to earthworms in an artificial soil test. OECD 208 test assesses effects on seedling emergence and early growth of higher plants following exposure to the test substance in the soil. The tests results demonstrate that the fluids are not classified as toxic for terrestrial organisms. The vegetable transformer fluid described in this work does not contain added antioxidants, including synthetic antioxidants, therefore enhancing the biodegradability and toxicity properties of the final product.",E. I. Diestre Redondo; F. S. Pérez; M. Á. VÁzquez Cantero; J. Izcara Zurro; J. A. Rojas Cerdeño; J. N. Nuñez,,,Soil ecotoxicity of natural ester transformer liquids,,,10.1109/ICDL.2014.6893088 ,IEEE Conferences ,,"Mineral oils have been used for decades as transformer fluids because of their excellent dielectric properties and availability. In the last decade natural ester transformer liquids have been introduced in the market. Natural ester transformer liquids are readily biodegradable fluids and induce very low toxicity levels against aquatic organisms like fish, algae or daphnia. On the other hand, the behavior of natural esters at the end of their life it is not fully understood because in service transformers containing natural esters have not reached that stage yet. Moreover, the interaction of natural esters with aquatic organisms has been thoroughly studied but that is not the case regarding soil organisms. This work presents the study of the behavior of natural esters, at the beginning and at the end of their life, in contact with water and soil organisms. The natural ester transformer liquid has been aged under severe oxidative conditions in order to obtain samples representing the state of the liquid well beyond the end of its life. Samples of non-aged and aged liquid have been tested according to OECD 207 and OECD 208 standards. OECD 207 standard defines the method for testing toxicity of chemicals to earthworms in an artificial soil test. OECD 208 test assesses effects on seedling emergence and early growth of higher plants following exposure to the test substance in the soil. The tests results demonstrate that the fluids are not classified as toxic for terrestrial organisms. The vegetable transformer fluid described in this work does not contain added antioxidants, including synthetic antioxidants, therefore enhancing the biodegradability and toxicity properties of the final product.",2153-3733,,978-1-4799-2063-1,1-4,IEEE , ,Fluids;Oil insulation;Testing;Aging;Europe,,
4906,"Title:Gas sensing properties of ZnO-SnO2 nanostructures towards CO in transformer oil

 Power transformer is an important equipment to transport and deliver the electric energy in the power system. It will result in huge damage of national economy while the transformers break down. On-line monitoring the dissolved gases in oil is one of the effective methods to improve the security and reliability of the power system. CO is the one of main failure characteristic gases in the transformer oil. It's significant to monitor on-line and analyze CO gas for the power transformer's safe operation. The key of on-line monitoring is the gas sensor technology. One-dimensional (1D) semiconductor metal oxide nanostructures have attracted increasing attention in electrochemistry, optics, magnetic, and gas sensing fields for the good properties. N-type low dimensional semiconducting oxides such as SnO2 and ZnO have been known for the detection of inflammable or toxic gases. In this paper, we fabricated the ZnO-SnO2 and SnO2 nanoparticles by hydrothermal synthesis. Microstructure characterization was performed using X-ray diffraction (XRD) and surface morphologies for both the pristine and doped samples were observed using field emission scanning electron microscope (FESEM), transmission electron microscopy (TEM) and high resolution transmission electron microscopy (HRTEM). Then we made thin film gas sensor to study the gas sensing properties of ZnO-SnO2 and SnO2 gas sensor to CO. A systematic comparison study reveals an enhanced gas sensing performance for the sensor made of SnO2 and ZnO towards CO over that of the commonly applied undecorated SnO2 nanoparticles. The improved gas sensing properties are attributed to the size of grains and pronounced electron transfer between the compound nanostructures and the absorbed oxygen species as well as to the heterojunctions of the ZnO nanoparticles to the SnO2 nanoparticles, which provide additional reaction rooms. The results represent an advance of compound nanostructures in further enhancing the functionality of gas sensors, and this facile method could be applicable to many sensing materials, offering a new avenue and direction to detect gases of interest based on composite tin oxide nanoparticles.",Q. Z. Li; W. G. Chen; T. Y. Gao; H. L. Gan,,,Gas sensing properties of ZnO-SnO2 nanostructures towards CO in transformer oil,,,10.1109/ICHVE.2014.7035461 ,IEEE Conferences ,,"Power transformer is an important equipment to transport and deliver the electric energy in the power system. It will result in huge damage of national economy while the transformers break down. On-line monitoring the dissolved gases in oil is one of the effective methods to improve the security and reliability of the power system. CO is the one of main failure characteristic gases in the transformer oil. It's significant to monitor on-line and analyze CO gas for the power transformer's safe operation. The key of on-line monitoring is the gas sensor technology. One-dimensional (1D) semiconductor metal oxide nanostructures have attracted increasing attention in electrochemistry, optics, magnetic, and gas sensing fields for the good properties. N-type low dimensional semiconducting oxides such as SnO2 and ZnO have been known for the detection of inflammable or toxic gases. In this paper, we fabricated the ZnO-SnO2 and SnO2 nanoparticles by hydrothermal synthesis. Microstructure characterization was performed using X-ray diffraction (XRD) and surface morphologies for both the pristine and doped samples were observed using field emission scanning electron microscope (FESEM), transmission electron microscopy (TEM) and high resolution transmission electron microscopy (HRTEM). Then we made thin film gas sensor to study the gas sensing properties of ZnO-SnO2 and SnO2 gas sensor to CO. A systematic comparison study reveals an enhanced gas sensing performance for the sensor made of SnO2 and ZnO towards CO over that of the commonly applied undecorated SnO2 nanoparticles. The improved gas sensing properties are attributed to the size of grains and pronounced electron transfer between the compound nanostructures and the absorbed oxygen species as well as to the heterojunctions of the ZnO nanoparticles to the SnO2 nanoparticles, which provide additional reaction rooms. The results represent an advance of compound nanostructures in further enhancing the functionality of gas sensors, and this facile method could be applicable to many sensing materials, offering a new avenue and direction to detect gases of interest based on composite tin oxide nanoparticles.",,,978-1-4799-6613-4,1-4,IEEE , ,Zinc oxide;Materials reliability;Reliability engineering;Monitoring;Ceramics;Heating,,
4907,"Title:Luminescent Lanthanide-Based Sensor for H2O Detection in Aprotic Solvents and D2O

 Applied methods for detecting water impurities in organic solvents, such as Fischer titration, include wayward equipment and toxic reagents. This method is inapplicable for detecting H2O in D2O, but suitable techniques like NMR-, IR-, and mass-spectrometry are costly. We report a low-cost, novel luminescent sensor material based on terbium-europium 3D MOF compound developed for facile, portable, and disposable monitoring of water quantities. Our sensor is able to determine water traces in D2O and aprotic organic solvents. Treating the material to solvent leads to the change in intensities ratio of terbium and europium bands in emission spectra depending of water content and nature of solvent. For D2O calibrating plot  $\text{I}_{\mathrm {Eu}}/\text{I}_{\mathrm {Tb}}$ –%H2O is linear whereas for dioxane and acetonitrile the dependence becomes linear in the coordinates  $\text{I}_{\mathrm {Eu}}/\text{I}_{\mathrm {Tb}}$ -ln(%H2O). The results reveal the potential application of developed sensor for ratiometric quantitation of H2O admixtures in D2O, organic solvents, transformer oil, etc.",V. E. Gontcharenko; A. M. Lunev; I. V. Taydakov; V. M. Korshunov; A. A. Drozdov; Y. A. Belousov,,,Luminescent Lanthanide-Based Sensor for H2O Detection in Aprotic Solvents and D2O,19,17,10.1109/JSEN.2019.2916498 ,IEEE Journals ,,"Applied methods for detecting water impurities in organic solvents, such as Fischer titration, include wayward equipment and toxic reagents. This method is inapplicable for detecting H2O in D2O, but suitable techniques like NMR-, IR-, and mass-spectrometry are costly. We report a low-cost, novel luminescent sensor material based on terbium-europium 3D MOF compound developed for facile, portable, and disposable monitoring of water quantities. Our sensor is able to determine water traces in D2O and aprotic organic solvents. Treating the material to solvent leads to the change in intensities ratio of terbium and europium bands in emission spectra depending of water content and nature of solvent. For D2O calibrating plot  $\text{I}_{\mathrm {Eu}}/\text{I}_{\mathrm {Tb}}$ –%H2O is linear whereas for dioxane and acetonitrile the dependence becomes linear in the coordinates  $\text{I}_{\mathrm {Eu}}/\text{I}_{\mathrm {Tb}}$ -ln(%H2O). The results reveal the potential application of developed sensor for ratiometric quantitation of H2O admixtures in D2O, organic solvents, transformer oil, etc.",1558-1748,,,7365-7372,IEEE , ,Sensors;Compounds;Water;Solvents;Luminescence;Europium,,
4908,"Title:Design of Power Electronic Transformer based on Cascaded H-bridge Multilevel Converter

 One key component of the future automation in electrical network is the replacement of conventional distribution transformers by an all-solid-state (power- electronic) alternative. In this paper, the optimum design of a power electronic transformer (PET) based on state of the art cascaded H-bridge multilevel converter is investigated. In the design process, a new and simple control method for balancing the cascaded H-bridge DC buses has been introduced. The proposed PET is extremely modular and can be extended for different voltage and power levels. It performs typical functions and has advantages such as power factor correction, elimination of voltage sag and swell, and reduction of voltage flicker in load side. Also in comparison to conventional transformers, it has lower weight, lower volume and eliminates necessity for toxic dielectric coolants.",H. Iman-Eini; S. Farhangi; J. -L. Schanen; J. Aime,,,Design of Power Electronic Transformer based on Cascaded H-bridge Multilevel Converter,,,10.1109/ISIE.2007.4374713 ,IEEE Conferences ,,"One key component of the future automation in electrical network is the replacement of conventional distribution transformers by an all-solid-state (power- electronic) alternative. In this paper, the optimum design of a power electronic transformer (PET) based on state of the art cascaded H-bridge multilevel converter is investigated. In the design process, a new and simple control method for balancing the cascaded H-bridge DC buses has been introduced. The proposed PET is extremely modular and can be extended for different voltage and power levels. It performs typical functions and has advantages such as power factor correction, elimination of voltage sag and swell, and reduction of voltage flicker in load side. Also in comparison to conventional transformers, it has lower weight, lower volume and eliminates necessity for toxic dielectric coolants.",2163-5145,,978-1-4244-0754-5,877-882,IEEE , ,Power electronics;Oil insulation;Positron emission tomography;Power quality;Power factor correction;Voltage fluctuations;Topology;Power system reliability;Power system protection;Buck converters,,
4909,"Title:An Experimental Research of the Release Characteristics of the Transformer Oil in Workplace

 Transformer oil emitted at the workplace can impose great risks to the workers. 1, 1-Diphenylethane and 4-Methyldiphenylmethane are the main substances released. The workers feel awful during the working time. Gas chromatography (GC) equipped with FID was used to measure the indoor concentration of the above toxic chemical substances in this work. Results show that the concentration of 1, 1-Diphenylethane and 4-Methyldiphenylmethane is up to 70.478 and 8.844mg/m3, respectively, and the concentration of the Diphenylethane is ten times higher than the limit values of Benzene and a part of its derivatives. Further observation indicated that the air change rate is only one time per hour in the workshop and the air distribution may not satisfactory.",Y. Fan; R. Gong,,,An Experimental Research of the Release Characteristics of the Transformer Oil in Workplace,,,10.1109/icbbe.2011.5781264 ,IEEE Conferences ,,"Transformer oil emitted at the workplace can impose great risks to the workers. 1, 1-Diphenylethane and 4-Methyldiphenylmethane are the main substances released. The workers feel awful during the working time. Gas chromatography (GC) equipped with FID was used to measure the indoor concentration of the above toxic chemical substances in this work. Results show that the concentration of 1, 1-Diphenylethane and 4-Methyldiphenylmethane is up to 70.478 and 8.844mg/m3, respectively, and the concentration of the Diphenylethane is ten times higher than the limit values of Benzene and a part of its derivatives. Further observation indicated that the air change rate is only one time per hour in the workshop and the air distribution may not satisfactory.",2151-7622,,978-1-4244-5089-3,1-3,IEEE , ,Ventilation;Conferences;Oil insulation;Exhaust systems;Employment;Materials;Temperature sensors,,
4910,"Title:Under-Voltage Monitoring System for Integrated Wind Turbine Microgrid, Utility Grid, and AC Load During Fault Conditions

 Civilisations have relied heavily on fossil fuels such as coal, nuclear, etc., to produce electricity over the past decades. This has contributed to climate change owing to the emission of toxic gases, where humans are growing ail because of the contaminated atmosphere. Renewable Energy Systems (RESs) are progressively regarded as power consumers' backbone. This is because the energy generated from RESs does not pose a risk to the ecosystem. Another driving force is that the larger the power system, the higher the power demand and the higher the cost. As a result, there will be an acute shortage of coal for power generation in the coming years. Therefore, the grid will be compromised due to an inability to match load requirements, possibly leading to load shedding. RESs are used as a supplement to an existing power grid or as an islanded mode configuration for a load proportional to the output voltage of the microgrid (MG). Innovative solutions must ensure that the load connected is continuously energised under normal conditions. An under-voltage monitor for a power system design that integrates a utility grid, a wind turbine MG system, and a load is presented. Novelty, results of this work indicate that the presented algorithm is reliable and is efficient however suffers from 3rd harmonics due to the motors and transformers. Therefore, the authors emphasise the need of designing an algorithm that will support transformers and motors designed for 50 Hz applications.",M. K. Ngwenyama; P. F. Le Roux,,,"Under-Voltage Monitoring System for Integrated Wind Turbine Microgrid, Utility Grid, and AC Load During Fault Conditions",,,10.1109/INCET54531.2022.9824493 ,IEEE Conferences ,,"Civilisations have relied heavily on fossil fuels such as coal, nuclear, etc., to produce electricity over the past decades. This has contributed to climate change owing to the emission of toxic gases, where humans are growing ail because of the contaminated atmosphere. Renewable Energy Systems (RESs) are progressively regarded as power consumers' backbone. This is because the energy generated from RESs does not pose a risk to the ecosystem. Another driving force is that the larger the power system, the higher the power demand and the higher the cost. As a result, there will be an acute shortage of coal for power generation in the coming years. Therefore, the grid will be compromised due to an inability to match load requirements, possibly leading to load shedding. RESs are used as a supplement to an existing power grid or as an islanded mode configuration for a load proportional to the output voltage of the microgrid (MG). Innovative solutions must ensure that the load connected is continuously energised under normal conditions. An under-voltage monitor for a power system design that integrates a utility grid, a wind turbine MG system, and a load is presented. Novelty, results of this work indicate that the presented algorithm is reliable and is efficient however suffers from 3rd harmonics due to the motors and transformers. Therefore, the authors emphasise the need of designing an algorithm that will support transformers and motors designed for 50 Hz applications.",,,978-1-6654-9499-1,1-7,IEEE , ,Energy management;Microgrids;Power system harmonics;Transformers;Threshold voltage;Wind turbines;Power system reliability;Climate change;Renewable energy sources;Voltage control,,
4911,"Title:Health status evaluation method of smart distribution station based on operation trajectory information matrix

 In order to solve the problem of real-time perception and evaluation of health status of smart distribution station, a health status evaluation method of smart distribution station based on operation trajectory information matrix is proposed. Firstly, the operation trajectory information matrix model of distribution station is established to record the development and change of environmental information and abnormal electrical quantity information in the distribution station for a certain period of time. Then, the development process of equipment state is divided into three stages: health state, sub-health state and disease state. The distribution station operation trajectory logic matrix is proposed, and the logic quantization of the distribution station operation trajectory information matrix is carried out. Finally, the distribution station operation trajectory logic diagram is established. The healthy development process of distribution station is discussed through the change of graphic area and volume. The health status of the distribution station is quantitatively evaluated through the distribution station sub-item health status evaluation matrix and the distribution station comprehensive health status evaluation index. Through the example analysis, it can be seen that the method is simple and fast, the abnormal and defective conditions of the equipment in the distribution station can be found in time, and the safe and economic operation of the distribution network can be ensured.",H. Liu; G. Su; X. You; P. Zhang; S. Li; M. Huang,,,Health status evaluation method of smart distribution station based on operation trajectory information matrix,,,10.1109/IAECST57965.2022.10061907 ,IEEE Conferences ,,"In order to solve the problem of real-time perception and evaluation of health status of smart distribution station, a health status evaluation method of smart distribution station based on operation trajectory information matrix is proposed. Firstly, the operation trajectory information matrix model of distribution station is established to record the development and change of environmental information and abnormal electrical quantity information in the distribution station for a certain period of time. Then, the development process of equipment state is divided into three stages: health state, sub-health state and disease state. The distribution station operation trajectory logic matrix is proposed, and the logic quantization of the distribution station operation trajectory information matrix is carried out. Finally, the distribution station operation trajectory logic diagram is established. The healthy development process of distribution station is discussed through the change of graphic area and volume. The health status of the distribution station is quantitatively evaluated through the distribution station sub-item health status evaluation matrix and the distribution station comprehensive health status evaluation index. Through the example analysis, it can be seen that the method is simple and fast, the abnormal and defective conditions of the equipment in the distribution station can be found in time, and the safe and economic operation of the distribution network can be ensured.",,,979-8-3503-2000-8,333-338,IEEE , ,Graphics;Temperature distribution;Technological innovation;Quantization (signal);Distribution networks;Maintenance engineering;Real-time systems,,
4912,"Title:Electronic waste disposal in District Sarajevo

 This paper analyses the disposal problem of electronic waste in District Sarajevo (DS), Bosnia and Herzegovina (B&H). It provides a brief overview of electronics development including analysis of the quantity of electronics presented in the present market. This analysis is specially focused on explaining how far the electronic development has come and how far is it supposed to go, in the future. It is a fact that electronic devices are overflowing the everyday life of an average citizen and because of the speed of their production and development their numbers are reaching critical figures. Materials found in electronic waste can be divided into two categories: material suited for recycling and material harmful for its surroundings. This paper explains several methods of electronic waste recycling. The recycling itself is explained from various points of view: legislatives, technological procedures, economical parameters, ecological goals and the most important one, the conscientiousness of the community involving the problem of recycling and preserving our natural habitat. This paper presents the analysis of the state of the disposal system concerning electronic waste in the DS, B&H. This district has around 400.000 citizens and it represents a good candidate for this type of analysis. Research shows that amount of electronic waste is concerning, and numbers describing the amount keep increasing. The legislatives concerning this problem, together with the technology used, are not sufficient to resolve this constantly evolving problem. The biggest problem is that the community awareness of this issue is nearly nonexistent.",A. Aksamovic; E. Huseinović,,,Electronic waste disposal in District Sarajevo,,,10.23919/MIPRO.2018.8400134 ,IEEE Conferences ,,"This paper analyses the disposal problem of electronic waste in District Sarajevo (DS), Bosnia and Herzegovina (B&H). It provides a brief overview of electronics development including analysis of the quantity of electronics presented in the present market. This analysis is specially focused on explaining how far the electronic development has come and how far is it supposed to go, in the future. It is a fact that electronic devices are overflowing the everyday life of an average citizen and because of the speed of their production and development their numbers are reaching critical figures. Materials found in electronic waste can be divided into two categories: material suited for recycling and material harmful for its surroundings. This paper explains several methods of electronic waste recycling. The recycling itself is explained from various points of view: legislatives, technological procedures, economical parameters, ecological goals and the most important one, the conscientiousness of the community involving the problem of recycling and preserving our natural habitat. This paper presents the analysis of the state of the disposal system concerning electronic waste in the DS, B&H. This district has around 400.000 citizens and it represents a good candidate for this type of analysis. Research shows that amount of electronic waste is concerning, and numbers describing the amount keep increasing. The legislatives concerning this problem, together with the technology used, are not sufficient to resolve this constantly evolving problem. The biggest problem is that the community awareness of this issue is nearly nonexistent.",,,978-953-233-095-3,720-0725,IEEE , ,Recycling;Consumer electronics;Electronic waste;TV;Metals;Integrated circuits;Plastics,,
4913,"Title:Electrolysis - Inevitable energy transformer in a world of sustainable energy

 The standard of living of a country is now judged by the energy it consumes, since the energy is the basic input to sustain the economic growth by providing the basic amenities of life for the entire population of the country. Nuclear energy, solar energy, wind energy, geothermal energy and tidal energy are some of the sources from which energy can be obtained. However, transport of the energy is not possible using these new unconventional energy sources and more than that some of them are available intermittently. In this context many scientists and engineers believe that the hydrogen energy system will be the best in view of the advantages over its chief-rivals - electricity and methanol. Hydrogen has all the favorable properties for transport, distribution and generation of heat and electricity. As for as the safety point of view, it is neither toxic nor radioactive and so does not cause any damage. Even though the hydrogen/oxidizer mixtures have a wide ignition range, tending to rapid deflagration, because of lightness it will diffuse upwards quite fast or burn away quickly. The availability of hydrogen as an energy carrier in economically significant amounts will be in the near future and its cost will be comparable when the fossil resources become scarce. Energy from the later is likely to become costlier if the firm adherence of environmental regulations is closely followed. Hydrogen can be manufactured by a variety of processes and this review paper mainly focuses on hydrogen generation by water electrolysis.",S. Vasudevan,,,Electrolysis - Inevitable energy transformer in a world of sustainable energy,,,10.1109/ICEETS.2013.6533400 ,IEEE Conferences ,,"The standard of living of a country is now judged by the energy it consumes, since the energy is the basic input to sustain the economic growth by providing the basic amenities of life for the entire population of the country. Nuclear energy, solar energy, wind energy, geothermal energy and tidal energy are some of the sources from which energy can be obtained. However, transport of the energy is not possible using these new unconventional energy sources and more than that some of them are available intermittently. In this context many scientists and engineers believe that the hydrogen energy system will be the best in view of the advantages over its chief-rivals - electricity and methanol. Hydrogen has all the favorable properties for transport, distribution and generation of heat and electricity. As for as the safety point of view, it is neither toxic nor radioactive and so does not cause any damage. Even though the hydrogen/oxidizer mixtures have a wide ignition range, tending to rapid deflagration, because of lightness it will diffuse upwards quite fast or burn away quickly. The availability of hydrogen as an energy carrier in economically significant amounts will be in the near future and its cost will be comparable when the fossil resources become scarce. Energy from the later is likely to become costlier if the firm adherence of environmental regulations is closely followed. Hydrogen can be manufactured by a variety of processes and this review paper mainly focuses on hydrogen generation by water electrolysis.",,,978-1-4673-6150-7,306-311,IEEE , ,Corrosion;Standards;Electrochemical processes;Bottling;Coatings;Hydrogen,,
4914,"Title:Solvent Decontamination of PCB Electrical Equipment

 Polychlorinated biphenyls (PCB's) which are used as dielectric fluids in transformers and capacitors, are toxic relatively inert materials which are persistent and widespread in the environment and biomagnified in the food chain. Disposal of contaminated electrical equipment requires removal of the majority of PCB's. Various solvent cleaning techniques have been investigated for decontamination of intact transformers and shredded capacitors. The PCB content of transformers which originally contained 180-270 kg PCB was reduced by 99.72-99.96 percent. The relatively small amount of retained PCB resides primarily in the interstices and absorbent material of the core and coil assembly. Shredded power factor correction capacitors were decontaminated using trichlorethylene in a multistage concurrent batch extraction process. The PCB content was reduced by 99.9 percent, leaving a residual PCB content of 0.01 kg per capacitor.",S. H. Hawthorne,,,Solvent Decontamination of PCB Electrical Equipment,IA-18,6,10.1109/TIA.1982.4504119 ,IEEE Journals ,,"Polychlorinated biphenyls (PCB's) which are used as dielectric fluids in transformers and capacitors, are toxic relatively inert materials which are persistent and widespread in the environment and biomagnified in the food chain. Disposal of contaminated electrical equipment requires removal of the majority of PCB's. Various solvent cleaning techniques have been investigated for decontamination of intact transformers and shredded capacitors. The PCB content of transformers which originally contained 180-270 kg PCB was reduced by 99.72-99.96 percent. The relatively small amount of retained PCB resides primarily in the interstices and absorbent material of the core and coil assembly. Shredded power factor correction capacitors were decontaminated using trichlorethylene in a multistage concurrent batch extraction process. The PCB content was reduced by 99.9 percent, leaving a residual PCB content of 0.01 kg per capacitor.",1939-9367,,,626-631,IEEE , ,Solvents;Decontamination;Capacitors;Biological materials;Dielectric materials;Cleaning;Transformer cores;Coils;Assembly;Power factor correction,,
4915,"Title:Development of Security System for Ready Made Garments (RMG) Industry in Bangladesh

 Employees in the poor world have no access to numerous simple, technologically driven resources and comforts, that are often taken for granted in affluent countries. The incredible expansion of the clothing industry has given people in Bangladesh with work during the past two decades. However, this industry is subject to a lack of safety measurements for garment workers and those relating to the garment industries. However, certain minor safety measures can make the overall safety of this industry effective and much needed improvement. This article discusses an easy and inexpensive design and implementation of a secure system that makes the greatest use of available resources. The suggested system is easy to build and can be utilized by those who are only minimally aware of basic understanding of its usage and without the requirement of expensive resources. The technique of development of safety used will be of particular benefit to the owners of the textile industry and other industries in which employees' safety is a requirement. The program seeks to ensure that safe and secure working spaces are a rule, not the exception, for all men and women in the readymade Bangladeshi clothing sector. It has been working together to create sustainable solutions.",S. S. Arman; M. A. Bari; M. M. Khan,,,Development of Security System for Ready Made Garments (RMG) Industry in Bangladesh,,,10.1109/UEMCON53757.2021.9666612 ,IEEE Conferences ,,"Employees in the poor world have no access to numerous simple, technologically driven resources and comforts, that are often taken for granted in affluent countries. The incredible expansion of the clothing industry has given people in Bangladesh with work during the past two decades. However, this industry is subject to a lack of safety measurements for garment workers and those relating to the garment industries. However, certain minor safety measures can make the overall safety of this industry effective and much needed improvement. This article discusses an easy and inexpensive design and implementation of a secure system that makes the greatest use of available resources. The suggested system is easy to build and can be utilized by those who are only minimally aware of basic understanding of its usage and without the requirement of expensive resources. The technique of development of safety used will be of particular benefit to the owners of the textile industry and other industries in which employees' safety is a requirement. The program seeks to ensure that safe and secure working spaces are a rule, not the exception, for all men and women in the readymade Bangladeshi clothing sector. It has been working together to create sustainable solutions.",,,978-1-6654-0690-1,810-0816,IEEE , ,Industries;Clothing;Legislation;Clothing industry;Regulation;Safety;Security,,
4916,"Title:Development of palm-based neopentyl glycol diester as dielectric fluid and its thermal aging performance

 The potential of palm-based neopentyl glycol diester as dielectric insulating fluid was investigated. The details of the transesterification of high oleic palm oil methyl ester (POME) with neopentyl glycol (NPG) with the final product yield of more than 90 wt% of NPG diester were discussed. The thermal aging performance of NPG diester was compared with conventional mineral insulating oil at 90, 110 and 130 °C. This paper focused mainly in the effects of aging to chemical, physical and electrical properties of NPG diester. Apart from being fully biodegradable and non-toxic, the synthesized diesters exhibited high flashpoint and the breakdown voltage was comparable to mineral oil. The result indicated that throughout the aging period, NPG diester exhibited lower acid value than mineral oil and no significant change in viscosity was observed. The study on mechanical properties of insulating paper aged in NPG diester shows higher tensile strength than paper aged in mineral oil. The synthesized esters have shown great potential to be used as transformer oil.",N. A. Raof; U. Rashid; R. Yunus; N. Azis; Z. Yaakub,,,Development of palm-based neopentyl glycol diester as dielectric fluid and its thermal aging performance,23,4,10.1109/TDEI.2016.7556478 ,IEEE Journals ,,"The potential of palm-based neopentyl glycol diester as dielectric insulating fluid was investigated. The details of the transesterification of high oleic palm oil methyl ester (POME) with neopentyl glycol (NPG) with the final product yield of more than 90 wt% of NPG diester were discussed. The thermal aging performance of NPG diester was compared with conventional mineral insulating oil at 90, 110 and 130 °C. This paper focused mainly in the effects of aging to chemical, physical and electrical properties of NPG diester. Apart from being fully biodegradable and non-toxic, the synthesized diesters exhibited high flashpoint and the breakdown voltage was comparable to mineral oil. The result indicated that throughout the aging period, NPG diester exhibited lower acid value than mineral oil and no significant change in viscosity was observed. The study on mechanical properties of insulating paper aged in NPG diester shows higher tensile strength than paper aged in mineral oil. The synthesized esters have shown great potential to be used as transformer oil.",1558-4135,,,2051-2058,IEEE , ,Vegetable oils;Aging;Power transformer insulation;Oil insulation;Minerals;Moisture,,
4917,"Title:Experimental Study on monitoring of SF6 degradation by Raman Spectroscopy

 As important and widely used electrical equipment, GIS (gas insulated switchgear)greatly affects the stability and safety of the entire power grid due to its working state and performance. When a partial discharge or local overheating occurs inside the GIS, SF6will decompose and produce various by-products (including SO2, SO2F2, COS, H2S, SOF2 and etc) that are toxic and corrosive. The reduction of SF6 gas concentration and the generation of corrosive gases will lead to a decrease in the internal insulation strength of GIS. By monitoring the concentration of SF6in GIS, it can help us to judge the operating status of GIS and prevent fault. In this paper, we build a gas Raman spectroscopy gas detection platform. The light source of the detection platform is a solid-state laser with a wavelength of 532nm and a laser power of 1.5W. A self-designed gas cell is used to contain the gas to be measured. A spectrometer and CCD are used to collect Raman signals. Based on this Raman spectroscopy gas detection platform, a Raman spectroscopy study of SF6was carried out. Under 1 atmosphere pressure, Based on the built Raman detection platform, Raman spectroscopy of SF6with a concentration of 99.99% was obtained. By analyzing the Raman spectroscopy obtained, the characteristic Raman spectral lines of SF6was determined as 774cm-1. And the Raman spectroscopy of SF6 under the pressure of gradient distribution was obtained. The Raman spectra of SF6with gradient pressure, laser power were obtained. By analyzing the Raman spectroscopy of SF6obtained under different pressure and laser power, it is found that the characteristic peak intensity of Raman of SF6is highly linear with pressure and laser power. The highly linear relationship between the Raman peak intensity of SF6and various conditions shows that Raman spectroscopy has great advantages in the quantitative analysis of SF6. This research laid the foundation for Raman spectroscopy to monitor the decomposition of SF6, indicating that Raman spectroscopy has great potential in this field.",G. Qian; Q. Peng; H. Peng; J. Hu; J. Wang,,,Experimental Study on monitoring of SF6 degradation by Raman Spectroscopy,,,10.1109/ICHVE49031.2020.9279422 ,IEEE Conferences ,,"As important and widely used electrical equipment, GIS (gas insulated switchgear)greatly affects the stability and safety of the entire power grid due to its working state and performance. When a partial discharge or local overheating occurs inside the GIS, SF6will decompose and produce various by-products (including SO2, SO2F2, COS, H2S, SOF2 and etc) that are toxic and corrosive. The reduction of SF6 gas concentration and the generation of corrosive gases will lead to a decrease in the internal insulation strength of GIS. By monitoring the concentration of SF6in GIS, it can help us to judge the operating status of GIS and prevent fault. In this paper, we build a gas Raman spectroscopy gas detection platform. The light source of the detection platform is a solid-state laser with a wavelength of 532nm and a laser power of 1.5W. A self-designed gas cell is used to contain the gas to be measured. A spectrometer and CCD are used to collect Raman signals. Based on this Raman spectroscopy gas detection platform, a Raman spectroscopy study of SF6was carried out. Under 1 atmosphere pressure, Based on the built Raman detection platform, Raman spectroscopy of SF6with a concentration of 99.99% was obtained. By analyzing the Raman spectroscopy obtained, the characteristic Raman spectral lines of SF6was determined as 774cm-1. And the Raman spectroscopy of SF6 under the pressure of gradient distribution was obtained. The Raman spectra of SF6with gradient pressure, laser power were obtained. By analyzing the Raman spectroscopy of SF6obtained under different pressure and laser power, it is found that the characteristic peak intensity of Raman of SF6is highly linear with pressure and laser power. The highly linear relationship between the Raman peak intensity of SF6and various conditions shows that Raman spectroscopy has great advantages in the quantitative analysis of SF6. This research laid the foundation for Raman spectroscopy to monitor the decomposition of SF6, indicating that Raman spectroscopy has great potential in this field.",2474-3852,,978-1-7281-5511-1,1-4,IEEE , ,Raman scattering;Gas lasers;Power lasers;Sulfur hexafluoride;Monitoring;Measurement by laser beam;Vibrations,,
4918,"Title:A high-power versatile wireless power transfer for biomedical implants

 Implantable biomedical actuators are highly desired in modern medicine. However, how to power up these biomedical implants remains a challenge since most of them need more than several hundreds mW of power. The air-core based radio-frequency transformer (two face-to-face inductive coils) has been the only non-toxic and non-invasive power source for implants for the last three decades [1]. For various technical constraints, the maximum delivered power is limited by this approach. The highest delivered power reported is 275 mW over 1 cm distance [2]. Also, the delivered power is highly vulnerable to the coils' geometrical arrangement and the electrical property of the medium around them. In this paper, a novel rotating-magnets based wireless power transfer that can deliver ∼10 W over 1 cm is demonstrated. The delivered power is significantly higher than the existing start-of-art. Further, the new method is versatile since there is no need to have the impedance matching networks that are highly susceptible to the operating frequency, the coil arrangement and the environment.",H. Jiang; J. M. Zhang; S. S. Liou; R. Fechter; S. Hirose; M. Harrison; S. Roy,,,A high-power versatile wireless power transfer for biomedical implants,,,10.1109/IEMBS.2010.5627329 ,IEEE Conferences ,,"Implantable biomedical actuators are highly desired in modern medicine. However, how to power up these biomedical implants remains a challenge since most of them need more than several hundreds mW of power. The air-core based radio-frequency transformer (two face-to-face inductive coils) has been the only non-toxic and non-invasive power source for implants for the last three decades [1]. For various technical constraints, the maximum delivered power is limited by this approach. The highest delivered power reported is 275 mW over 1 cm distance [2]. Also, the delivered power is highly vulnerable to the coils' geometrical arrangement and the electrical property of the medium around them. In this paper, a novel rotating-magnets based wireless power transfer that can deliver ∼10 W over 1 cm is demonstrated. The delivered power is significantly higher than the existing start-of-art. Further, the new method is versatile since there is no need to have the impedance matching networks that are highly susceptible to the operating frequency, the coil arrangement and the environment.",1558-4615,,978-1-4244-4123-5,6437-6440,IEEE , ,Coils;Steel;Wireless communication;Transformer cores;Rotors;Radio frequency,,
4919,"Title:Hybrid Renewable Energy System Design and Optimization for Developing Countries Using HOMER Pro: Case of Rwanda

 HOMER (Hybrid Optimization Model for Electric Renewables) is a tool invented by the National Renewable Energy Laboratory (NREL) used in renewable power systems optimization. This tool is utilized by researchers to design and model various power system and hybrid system configuration. HOMER has different built-in component and devices such as hydro turbines, PV modules, generators, batteries, converters, utility loads transformers and many more. Researchers are able to simulates different power systems designed by HOMER and also find the most optimized power system configurations considering the operating cost, the net present cost, the carbon oxide emission and comparison of economic viability. Currently the energy demand is highly increasing worldwide therefore the design and implementation of new renewable energy systems with zero gas emission is needed for the future energy forecasting and pollution free energy systems implementation to reduce the dependence on conventional energies. This work modeled a hybrid system for Gicumbi district in Rukomo village in which the designed system deals with solar, wind and converters to decrease amount of electricity paid to the national grid. This work evaluates the power generated, emitted gases, net present cost and the cost of electricity. The work presents various optimized system simulated results. The proposed hybrid wind-PV system scheme is generalized to the most economic comparing to other systems considering the operating cost, the NPC and the toxic gases emission.",E. Niringiyimana; S. Wanquan; G. Dushimimana; J. b. Niyigena,,,Hybrid Renewable Energy System Design and Optimization for Developing Countries Using HOMER Pro: Case of Rwanda,,,10.1109/ICGEA57077.2023.10125739 ,IEEE Conferences ,,"HOMER (Hybrid Optimization Model for Electric Renewables) is a tool invented by the National Renewable Energy Laboratory (NREL) used in renewable power systems optimization. This tool is utilized by researchers to design and model various power system and hybrid system configuration. HOMER has different built-in component and devices such as hydro turbines, PV modules, generators, batteries, converters, utility loads transformers and many more. Researchers are able to simulates different power systems designed by HOMER and also find the most optimized power system configurations considering the operating cost, the net present cost, the carbon oxide emission and comparison of economic viability. Currently the energy demand is highly increasing worldwide therefore the design and implementation of new renewable energy systems with zero gas emission is needed for the future energy forecasting and pollution free energy systems implementation to reduce the dependence on conventional energies. This work modeled a hybrid system for Gicumbi district in Rukomo village in which the designed system deals with solar, wind and converters to decrease amount of electricity paid to the national grid. This work evaluates the power generated, emitted gases, net present cost and the cost of electricity. The work presents various optimized system simulated results. The proposed hybrid wind-PV system scheme is generalized to the most economic comparing to other systems considering the operating cost, the NPC and the toxic gases emission.",,,978-1-6654-5609-8,72-76,IEEE , ,Renewable energy sources;Gases;Costs;Pollution;Production;Transformers;Hybrid power systems,,
4920,"Title:A power electronic based transformer for feeding sensitive loads

 In this paper a modular power electronic transformer (PET) for feeding sensitive loads is presented. The proposed PET can be directly connected to the medium voltage levels and provide a low-voltage and highly-stable interface with the consumer applications. At the input side, cascaded H-bridge rectifier serves as an active-front-end (AFE) rectifier to ensure sinusoidal input current, while converting AC input voltage to distinct DC buses. The isolated DC/DC converters are connected to the individual DC buses and reduce the AC voltage level through series-input and parallel-output configuration of the H-bridge cells. The proposed PET can compensate both the active and reactive powers, and remove the power quality disturbances such as sag, swell, under voltage, over voltage and voltage flicker. In comparison to the conventional transformers, it has low weight, compact volume, extended functionality, and eliminates the necessity for toxic dielectric coolants. The proposed topology and the principle of operation are explained and the validity of the design is verified using the simulation and experimental results.",H. Iman-Eini; J. Schanen; S. Farhangi; J. Barbaroux; J. Keradec,,,A power electronic based transformer for feeding sensitive loads,,,10.1109/PESC.2008.4592324 ,IEEE Conferences ,,"In this paper a modular power electronic transformer (PET) for feeding sensitive loads is presented. The proposed PET can be directly connected to the medium voltage levels and provide a low-voltage and highly-stable interface with the consumer applications. At the input side, cascaded H-bridge rectifier serves as an active-front-end (AFE) rectifier to ensure sinusoidal input current, while converting AC input voltage to distinct DC buses. The isolated DC/DC converters are connected to the individual DC buses and reduce the AC voltage level through series-input and parallel-output configuration of the H-bridge cells. The proposed PET can compensate both the active and reactive powers, and remove the power quality disturbances such as sag, swell, under voltage, over voltage and voltage flicker. In comparison to the conventional transformers, it has low weight, compact volume, extended functionality, and eliminates the necessity for toxic dielectric coolants. The proposed topology and the principle of operation are explained and the validity of the design is verified using the simulation and experimental results.",2377-6617,,978-1-4244-1667-7,2549-2555,IEEE , ,Converters;Voltage control;Positron emission tomography;Rectifiers;Power electronics;Pulse width modulation;Voltage fluctuations,,
4921,"Title:Unifying Converters of Inductive Sensors Parameters for Devices Measuring the Parameters of Electrophysical Properties of Substances

 Inductive sensors can be used in devices for measuring the composition of liquid media, the moisture content of bulk and solid materials, while they provide several advantages over the more common conductometric sensors, for example, they allow more accurate measurements of moving materials or ampoules of aggressive and toxic environments. Inductive sensors are less widely used due to the complexity of the design and the appearance of resonant effects in combination with the capacity of inductive sensors. The article discusses: equivalent circuits of inductive sensors represented by a multi-element equivalent circuit; options for constructing unifying single and multichannel converters of electrophysical properties parameters of substances based on an inductive sensor, their construction features, drawbacks, errors, the choice of an informative parameter, ways to increase the invariance of measurements. To process the obtained analog results from the outputs of the unifying converters, it is proposed to use digital post-processing in the microcontroller. This construction simplifies the scheme and allows you to create stand-alone mobile devices without the use of processing measurement results on a personal computer and without the use of specialized expensive software. The advantages of such a construction are its wide functionality and correction of additional errors.",A. V. Grachev; P. P. Churakov; A. Y. Tychkov; A. K. Alimuradov,,,Unifying Converters of Inductive Sensors Parameters for Devices Measuring the Parameters of Electrophysical Properties of Substances,,,10.1109/MWENT47943.2020.9067423 ,IEEE Conferences ,,"Inductive sensors can be used in devices for measuring the composition of liquid media, the moisture content of bulk and solid materials, while they provide several advantages over the more common conductometric sensors, for example, they allow more accurate measurements of moving materials or ampoules of aggressive and toxic environments. Inductive sensors are less widely used due to the complexity of the design and the appearance of resonant effects in combination with the capacity of inductive sensors. The article discusses: equivalent circuits of inductive sensors represented by a multi-element equivalent circuit; options for constructing unifying single and multichannel converters of electrophysical properties parameters of substances based on an inductive sensor, their construction features, drawbacks, errors, the choice of an informative parameter, ways to increase the invariance of measurements. To process the obtained analog results from the outputs of the unifying converters, it is proposed to use digital post-processing in the microcontroller. This construction simplifies the scheme and allows you to create stand-alone mobile devices without the use of processing measurement results on a personal computer and without the use of specialized expensive software. The advantages of such a construction are its wide functionality and correction of additional errors.",,,978-1-7281-2572-5,1-5,IEEE , ,Resistance;Capacitance;Equivalent circuits;Inductance;RLC circuits;Capacitive sensors,,
4922,"Title:Dechlorination And Reclamation Of PCB-Contaminated Insulating Fluids

 A process was developed by Ontario Hydro Research to dechlorinate PCBs in contaminated insulating fluids and reclaim the insulating fluids after treatment, thus alleviating a growing environmental hazard. The contaminated fluids, containing up to several thousand milligrams of PCB per kilogram (ppm) are contacted with metallic sodium at moderate temperatures, resulting in virtual (<2 mg/kg) disappearance of any PCB. Results are presented for a variety of new and aged insulating oils contaminated with either PCB or PCB-containing askarel at concentrations up to 100 000 mg/kg. Details are presented on reaction conditions, type of PCB molecule and insulating oil and oil reclamation processes. Successful operation of the process is described at the laboratory (1 L) as well as the pilot plant (120 L) scale. All process streams were found, free of toxic by- products while after conventional clay treatment the regenerated oils-were suitable for reuse.",W. J. Janis; J. S. Ferrie; J. M. Braun,,,Dechlorination And Reclamation Of PCB-Contaminated Insulating Fluids,PAS-102,12,10.1109/TPAS.1983.317932 ,IEEE Journals ,,"A process was developed by Ontario Hydro Research to dechlorinate PCBs in contaminated insulating fluids and reclaim the insulating fluids after treatment, thus alleviating a growing environmental hazard. The contaminated fluids, containing up to several thousand milligrams of PCB per kilogram (ppm) are contacted with metallic sodium at moderate temperatures, resulting in virtual (<2 mg/kg) disappearance of any PCB. Results are presented for a variety of new and aged insulating oils contaminated with either PCB or PCB-containing askarel at concentrations up to 100 000 mg/kg. Details are presented on reaction conditions, type of PCB molecule and insulating oil and oil reclamation processes. Successful operation of the process is described at the laboratory (1 L) as well as the pilot plant (120 L) scale. All process streams were found, free of toxic by- products while after conventional clay treatment the regenerated oils-were suitable for reuse.",0018-9510,,,3928-3932,IEEE , ,Petroleum;Oil insulation;Power transformer insulation;Laboratories;Dielectric liquids;Solvents;Hazards;Temperature;Aging;Roads,,
4923,"Title:Sulfur hexafluoride SF6

 This article deals with the sulfur hexafluoride in high voltage applications for electrical insulation and electrical arc distinguishing when circuit breakers, ground switches, and disconnectors are operated. Sulfur hexafluoride (SF6) is a colorless, odorless, non-toxic and non flammable gas. It is an extremely stable gas with high dielectric strength and excellent arc quenching properties making it an ideal for use in gas insulated substations (GIS). Virtually all substations being built today use SF6for circuit breakers and every GIS station relies on SF6 for insulation. At the same time, SF6 has been identified as a potent greenhouse gas, 22,500 times more effective at trapping infra-red radiation than an equivalent amount of CO2. There are no statutory requirements in the U.S. limiting the usage of SF6, but there are voluntary governments and private corporate program initiatives to better manage SF6 with the aim of reducing emissions.",M. Etter; H. Koch,,,Sulfur hexafluoride SF6,,,10.1109/PES.2008.4596619 ,IEEE Conferences ,,"This article deals with the sulfur hexafluoride in high voltage applications for electrical insulation and electrical arc distinguishing when circuit breakers, ground switches, and disconnectors are operated. Sulfur hexafluoride (SF6) is a colorless, odorless, non-toxic and non flammable gas. It is an extremely stable gas with high dielectric strength and excellent arc quenching properties making it an ideal for use in gas insulated substations (GIS). Virtually all substations being built today use SF6for circuit breakers and every GIS station relies on SF6 for insulation. At the same time, SF6 has been identified as a potent greenhouse gas, 22,500 times more effective at trapping infra-red radiation than an equivalent amount of CO2. There are no statutory requirements in the U.S. limiting the usage of SF6, but there are voluntary governments and private corporate program initiatives to better manage SF6 with the aim of reducing emissions.",1932-5517,,978-1-4244-1905-0,1-4,IEEE , ,Sulfur hexafluoride;Substations;Geographic information systems;Greenhouses;Switchgear;Power systems;Power transformer insulation,,
4924,"Title:The Characteristics of Natural Organic Matter by High Voltage Pulse Discharge Plasma

 High voltage pulse discharge plasma can remove natural organic matter (NOM) and produce no production of toxic by-products. Fulvic acid solution was treated by high voltage pulse discharge plasma in this paper. It was shown that because of the thermolysis and oxidation, with the increase of peak voltage and fulvic acid solution concentration, the pH and ORP of solution decreased gradually, meanwhile the temperature and turbidity of solution increased gradually. Adding hydrochlorid acid in the treatment could amplify the effect of plasma. As the surrogate parameter of NOM concentration, UV254 increased slowly by the effect of plasma, while the degradation of TOC was first-order reaction. The removal rate of TOC increased from 22.6% to 33.4% by high voltage pulse electrical field of 35 kv, and from 25.6% to 36.7% with the addition of hydrochlorid acid. This paper may provide some basis for the scale-up design of water treatment process by high voltage pulse discharge plasma with other technologies.",F. Song; Y. Guo,,,The Characteristics of Natural Organic Matter by High Voltage Pulse Discharge Plasma,,,10.1109/ICBBE.2010.5515935 ,IEEE Conferences ,,"High voltage pulse discharge plasma can remove natural organic matter (NOM) and produce no production of toxic by-products. Fulvic acid solution was treated by high voltage pulse discharge plasma in this paper. It was shown that because of the thermolysis and oxidation, with the increase of peak voltage and fulvic acid solution concentration, the pH and ORP of solution decreased gradually, meanwhile the temperature and turbidity of solution increased gradually. Adding hydrochlorid acid in the treatment could amplify the effect of plasma. As the surrogate parameter of NOM concentration, UV254 increased slowly by the effect of plasma, while the degradation of TOC was first-order reaction. The removal rate of TOC increased from 22.6% to 33.4% by high voltage pulse electrical field of 35 kv, and from 25.6% to 36.7% with the addition of hydrochlorid acid. This paper may provide some basis for the scale-up design of water treatment process by high voltage pulse discharge plasma with other technologies.",2151-7622,,978-1-4244-4712-1,1-4,IEEE , ,Voltage;Plasma properties;Plasma temperature;Electrodes;Inductors;Oxidation;Plasma materials processing;Water resources;Pulse transformers;Needles,,
4925,"Title:Design and Implementation of an Automatic Gas and Smoke Detector

 Every home and work environment are expected to be free of highly combustible gas leaks, which might lead to a fire outbreak and the loss of lives and property, as well as toxic fumes in the form of smoke, which are extremely harmful to human health, particularly the lungs. As a result, a system that aids in the extraction of toxic gases or toxins in the form of smoke, as well as the maintenance of a habitable working environment through ventilation is required. When combustible gases like butane and methane leak in an unventilated environment, the air became supercharged with gas molecules which will result in a fire with a little spark. This paper proposed an enhanced designed that will reduce the risk of gas-related fires and environmental pollutions using an embedded system and a gas and smoke sensor.",Y. Uthman; D. Watsai; D. Nwude; G. Oletu,,,Design and Implementation of an Automatic Gas and Smoke Detector,,,10.1109/ISNCC55209.2022.9851795 ,IEEE Conferences ,,"Every home and work environment are expected to be free of highly combustible gas leaks, which might lead to a fire outbreak and the loss of lives and property, as well as toxic fumes in the form of smoke, which are extremely harmful to human health, particularly the lungs. As a result, a system that aids in the extraction of toxic gases or toxins in the form of smoke, as well as the maintenance of a habitable working environment through ventilation is required. When combustible gases like butane and methane leak in an unventilated environment, the air became supercharged with gas molecules which will result in a fire with a little spark. This paper proposed an enhanced designed that will reduce the risk of gas-related fires and environmental pollutions using an embedded system and a gas and smoke sensor.",,,978-1-6654-8544-9,1-4,IEEE , ,Methane;Gases;Pollution;Microcontrollers;Lung;Maintenance engineering;Ventilation,,
4926,"Title:Comparative Study of Accelerated Thermal Aging of Papers in Mineral Oil, Natural Ester, and Gas-to-Liquid

 Mineral oil has long been used as an insulating liquid in transformers. Natural ester-based oil is an alternative due to its non-toxic and biodegradable characteristics. Then this study compared the rate of degradation of accelerated thermal aging paper impregnated in natural ester oil (NE) with mineral oil (MO) and Gas-to-Liquid (GTL). Sealed glass bottles containing thermally upgraded kraft paper (TUK), kraft paper (KP), pressboard (PB), and oil in an atmospheric environment were aged in an oven at 150 °C within 1344 hours. Observations were made at intervals of 336 hours during the aging. The rate of degradation of the paper was observed through the Degree of Polymerization (DP) test of kraft paper, while the chemical structure of the paper was observed through the Fourier Transform Infrared (FTIR) test of the paper. In addition, acid and moisture tests were also carried out to observe the oil-paper interaction during aging. The depolymerization rate of paper in natural ester oil is smaller compared to other oils. This indicates that NE has better thermal stability and can extend life of the transformer paper. The paper aging rate in MO is similar to GTL Oil because they both are hydrocarbons-based.",I. Daris; M. Ahmad; H. R. Nurhakim; Suwarno,,,"Comparative Study of Accelerated Thermal Aging of Papers in Mineral Oil, Natural Ester, and Gas-to-Liquid",,,10.1109/ICHVEPS53178.2021.9601014 ,IEEE Conferences ,,"Mineral oil has long been used as an insulating liquid in transformers. Natural ester-based oil is an alternative due to its non-toxic and biodegradable characteristics. Then this study compared the rate of degradation of accelerated thermal aging paper impregnated in natural ester oil (NE) with mineral oil (MO) and Gas-to-Liquid (GTL). Sealed glass bottles containing thermally upgraded kraft paper (TUK), kraft paper (KP), pressboard (PB), and oil in an atmospheric environment were aged in an oven at 150 °C within 1344 hours. Observations were made at intervals of 336 hours during the aging. The rate of degradation of the paper was observed through the Degree of Polymerization (DP) test of kraft paper, while the chemical structure of the paper was observed through the Fourier Transform Infrared (FTIR) test of the paper. In addition, acid and moisture tests were also carried out to observe the oil-paper interaction during aging. The depolymerization rate of paper in natural ester oil is smaller compared to other oils. This indicates that NE has better thermal stability and can extend life of the transformer paper. The paper aging rate in MO is similar to GTL Oil because they both are hydrocarbons-based.",,,978-1-6654-4354-8,323-328,IEEE , ,Degradation;Oils;Moisture;Power system stability;Oil insulation;Minerals;Polymers,,
4927,"Title:Wild mushroom classification based on improved MobileViT_v2

 Accidental ingestion of toxic or inedible wild mushrooms is very dangerous. Because identifying their species is a fine-grained classification problem, it is difficult to directly apply general deep learning classification methods to obtain excellent fine-grained classification results. For mobile application scenarios, MobileViT_v2 with characteristics of convolutional ViT blocks is selected as the basic network. In addition, lightweight coordinate attention (CA) blocks are inserted to enhance the ability of filtering local foreground areas and feature channels of the network. After the shallow local fine-grained features processed by SoftPool, skipping connections are introduced between blocks to achieve fusion with global semantic features of deep layers to help achieve fine-grained classification that pays more attention to local detail features. Experimental results show that the improved method can improve the classification accuracy of Top1 from 96.83% to 97.39%, and reduce the loss by about 10%, indicating stronger generalization ability. Moreover, our improved network outperforms typical lightweight and heavyweight ones (MobileNet_v3, ShuffleNet_v2, ResNet50 and ResNeXt50-32×4d etc.).",C. Long; P. Yu; H. Li; H. Li,,,Wild mushroom classification based on improved MobileViT_v2,3,,10.1109/ICIBA56860.2023.10165212 ,IEEE Conferences ,,"Accidental ingestion of toxic or inedible wild mushrooms is very dangerous. Because identifying their species is a fine-grained classification problem, it is difficult to directly apply general deep learning classification methods to obtain excellent fine-grained classification results. For mobile application scenarios, MobileViT_v2 with characteristics of convolutional ViT blocks is selected as the basic network. In addition, lightweight coordinate attention (CA) blocks are inserted to enhance the ability of filtering local foreground areas and feature channels of the network. After the shallow local fine-grained features processed by SoftPool, skipping connections are introduced between blocks to achieve fusion with global semantic features of deep layers to help achieve fine-grained classification that pays more attention to local detail features. Experimental results show that the improved method can improve the classification accuracy of Top1 from 96.83% to 97.39%, and reduce the loss by about 10%, indicating stronger generalization ability. Moreover, our improved network outperforms typical lightweight and heavyweight ones (MobileNet_v3, ShuffleNet_v2, ResNet50 and ResNeXt50-32×4d etc.).",,,978-1-6654-9079-5,12-18,IEEE , ,Deep learning;Filtering;Semantics;Learning (artificial intelligence);Interference;Big Data;Mobile applications,,
4928,"Title:Software and Hardware Solution of a Complex Tumor Visualization System for Use in a Medical Institution of an Industrial Enterprise

 Currently, workers of oil and gas enterprises, working in areas with toxic volatile substances, have an increased probability of the appearance of tumors of various nature. In order to carry out a high-quality surgical intervention, minimize health risks, as well as reduce the postoperative recovery time of a highly qualified staff, a preoperative planning technique is used, based on modeling the tumor and forming a plan for its step-by-step removal. In order to increase the accuracy of reproduction of tumor surface models, this article analyzes current software tools for modeling tumors based on data obtained during magnetic resonance imaging, and devices for outputting these data to printed surface. It is proposed to use an improved method of reproducing 3D tumor models, based on additional processing of tomographic images. The improved method provides for several ways of processing and analyzing the slices: cutting the boundaries of the slices to sizes close to the structures to be selected; linear contrast of slices; optional positive-negative conversion; gamma correction of slices; brightness correction; contrast correction; control of brightness levels and their distribution according to the histogram; threshold processing of slices; spatial median filtering. The proposed slice processing improvements are modeled in the computer algebra system Mathcad, and in the LabView development environment these improvements are implemented in a virtual device for rendering 3D tumor models. The article also presents an improved method of displaying medical information using tablet graph plotter. In the course of the work, the structural and circuit diagrams of such a device were designed, as well as its physical model was built. Working with the graph plotter model, the selected processed slice was converted into a set of commands for the model to reproduce its outline. The test drawings were digitized and compared with the digital standard.",A. Perekrest; D. Kukharenko; M. Kushch-Zhyrko; K. Vadurin,,,Software and Hardware Solution of a Complex Tumor Visualization System for Use in a Medical Institution of an Industrial Enterprise,,,10.1109/MEES58014.2022.10005779 ,IEEE Conferences ,,"Currently, workers of oil and gas enterprises, working in areas with toxic volatile substances, have an increased probability of the appearance of tumors of various nature. In order to carry out a high-quality surgical intervention, minimize health risks, as well as reduce the postoperative recovery time of a highly qualified staff, a preoperative planning technique is used, based on modeling the tumor and forming a plan for its step-by-step removal. In order to increase the accuracy of reproduction of tumor surface models, this article analyzes current software tools for modeling tumors based on data obtained during magnetic resonance imaging, and devices for outputting these data to printed surface. It is proposed to use an improved method of reproducing 3D tumor models, based on additional processing of tomographic images. The improved method provides for several ways of processing and analyzing the slices: cutting the boundaries of the slices to sizes close to the structures to be selected; linear contrast of slices; optional positive-negative conversion; gamma correction of slices; brightness correction; contrast correction; control of brightness levels and their distribution according to the histogram; threshold processing of slices; spatial median filtering. The proposed slice processing improvements are modeled in the computer algebra system Mathcad, and in the LabView development environment these improvements are implemented in a virtual device for rendering 3D tumor models. The article also presents an improved method of displaying medical information using tablet graph plotter. In the course of the work, the structural and circuit diagrams of such a device were designed, as well as its physical model was built. Working with the graph plotter model, the selected processed slice was converted into a set of commands for the model to reproduce its outline. The test drawings were digitized and compared with the digital standard.",,,979-8-3503-4683-1,1-6,IEEE , ,Solid modeling;Analytical models;Three-dimensional displays;Brightness;Process control;Hardware;Integrated circuit modeling,,
4929,"Title:The Safe Disposal of Polychlorinated Biphenyls

 The degradation of polychlorinated biphenyls (PCBs) is reviewed in terms of the methods available and the reaction products generated. The origin of the PCB ""problem"" is discussed with reference to the toxic components of askarels. The paper is organized into two sections (1) the disposal of askarel liquids and (2) the disposal of PCB contaminated liquid. (1) PCBs require a very large energy input to cause decomposition and therefore, the methods in use are typically large energy sources. The most widely used method of disposal of pure PCBs, and that preferred by the EPA, is high temperature incineration. However, other methods discussed here include chemical methods and the use of a microwave plasma. (2) In the case of liquids which are contaminated by PCBs, the first two disposal choices involve either destruction, by a combustion method or disposal in a chemical waste landfill. However, it is sometimes possible to reclaim the liquid for re-use. This paper discusses the numerous alternative chemical methods of PCB destruction as well as the physical separation of PCBs to yield uncontaminated liquids.",D. Pilgrim; M. A. Thompson; I. Webber,,,The Safe Disposal of Polychlorinated Biphenyls,,, ,IEEE Conferences ,,"The degradation of polychlorinated biphenyls (PCBs) is reviewed in terms of the methods available and the reaction products generated. The origin of the PCB ""problem"" is discussed with reference to the toxic components of askarels. The paper is organized into two sections (1) the disposal of askarel liquids and (2) the disposal of PCB contaminated liquid. (1) PCBs require a very large energy input to cause decomposition and therefore, the methods in use are typically large energy sources. The most widely used method of disposal of pure PCBs, and that preferred by the EPA, is high temperature incineration. However, other methods discussed here include chemical methods and the use of a microwave plasma. (2) In the case of liquids which are contaminated by PCBs, the first two disposal choices involve either destruction, by a combustion method or disposal in a chemical waste landfill. However, it is sometimes possible to reclaim the liquid for re-use. This paper discusses the numerous alternative chemical methods of PCB destruction as well as the physical separation of PCBs to yield uncontaminated liquids.",2576-702X,,978-1-5090-3187-0,336-343,IEEE , ,Costs;Chemicals;Transformers;Liquids;Incineration;Sodium;Solids,,
4930,"Title:Study on enhanced H2 gas sensing characteristics of CuO-SnO2 nanostructures

 In the past decades, the application of nanostructures and nanotechnology has attracted intensive attention in many fields from electronic devices to chemical sensors. The monitoring of toxic or inflammable gases has been increasingly important for humans, environment and various areas. In the power system field, power transformers are important equipment of electricity transmission and distribution, and its operation condition is associated with the safety of power system. If the power transformers break down, there will be a huge lose in national economic. Hydrogen (H2) is one of the main fault characteristic gases dissolved in transformer oil, which can indicate the high energy discharge, spark discharge, partial discharge and partial oil overheating. The gas sensor technology is the key of on-line monitoring trace amount of gases. This paper made a research on the detection characteristics of CuO-SnO2 gas sensor to the H2 gas dissolved in transformer oil. In this study, a facile hydrothermal method was adopted to fabricate SnO2 and CuO-SnO2 nanoparticles. The CuO content was chosen as 5mol-% (sample 1), 10mol-% (sample 2) and 15mol-% (sample 3). Microstructures and surface morphologies for all samples were characterised by X-ray diffraction (XRD), field emission scanning electron microscopy (FESEM), transmission electron microscopy (TEM) and high-resolution transmission electron microscopy (HRTEM). Then the gas sensing mechanism of gas sensor was analyzed. The results proved that: A lot of p-n heterojunction would form which change the gas sensing properties of composite SnO2-based gas sensor to hydrogen; compared with the SnO2 gas sensor, the CuO-SnO2 performed better sensitivity and quicker response to the H2,and also kept a good linearity and stability. The results offer a new thought to study the application of composite SnO2-based gas sensor on detecting the gases dissolved in transformer oil on line and represent an advance of heterojuction nanostructures in further enhancing the functionality of gas sensors towards H2.",W. G. Chen; T. Y. Gao; Q. Z. Li; H. L. Gan,,,Study on enhanced H2 gas sensing characteristics of CuO-SnO2 nanostructures,,,10.1109/ICHVE.2014.7035507 ,IEEE Conferences ,,"In the past decades, the application of nanostructures and nanotechnology has attracted intensive attention in many fields from electronic devices to chemical sensors. The monitoring of toxic or inflammable gases has been increasingly important for humans, environment and various areas. In the power system field, power transformers are important equipment of electricity transmission and distribution, and its operation condition is associated with the safety of power system. If the power transformers break down, there will be a huge lose in national economic. Hydrogen (H2) is one of the main fault characteristic gases dissolved in transformer oil, which can indicate the high energy discharge, spark discharge, partial discharge and partial oil overheating. The gas sensor technology is the key of on-line monitoring trace amount of gases. This paper made a research on the detection characteristics of CuO-SnO2 gas sensor to the H2 gas dissolved in transformer oil. In this study, a facile hydrothermal method was adopted to fabricate SnO2 and CuO-SnO2 nanoparticles. The CuO content was chosen as 5mol-% (sample 1), 10mol-% (sample 2) and 15mol-% (sample 3). Microstructures and surface morphologies for all samples were characterised by X-ray diffraction (XRD), field emission scanning electron microscopy (FESEM), transmission electron microscopy (TEM) and high-resolution transmission electron microscopy (HRTEM). Then the gas sensing mechanism of gas sensor was analyzed. The results proved that: A lot of p-n heterojunction would form which change the gas sensing properties of composite SnO2-based gas sensor to hydrogen; compared with the SnO2 gas sensor, the CuO-SnO2 performed better sensitivity and quicker response to the H2,and also kept a good linearity and stability. The results offer a new thought to study the application of composite SnO2-based gas sensor on detecting the gases dissolved in transformer oil on line and represent an advance of heterojuction nanostructures in further enhancing the functionality of gas sensors towards H2.",,,978-1-4799-6613-4,1-4,IEEE , ,Heating;Chemicals;X-ray scattering;Sensors;Junctions,,
4931,"Title:AC breakdown performance of natural esters combined with different biodegradable antioxidants under accelerated thermal ageing

 Natural esters derived from natural plants are being considered as potential substitutes to conventional mineral oils, due to their less-flammable, non-toxic and environmentally friendly properties. To date, natural esters have been successfully applied in sealed distribution, traction transformers and even a few cases in power transformers. But the fact of being susceptible to oxidation presents it still an engineering challenge of replacing mineral oil by natural esters in those free-breathing transformers. At present, the most commonly used antioxidant in natural esters is BHT, but its non-degradability also brings a big problem. In this paper, different biodegradable antioxidants were added into natural esters and liquid samples filled into specially designed test cells with a volume/surface ratio of 20 mm. The liquid samples in the test cell were aged in an air-circulating oven at 120°C. AC breakdown strength (kV/mm) of the liquid samples was measured periodically during the accelerated ageing experiment. Acid value of the liquid samples was also measured to provide additional information. The results show that the natural ester with biodegradable antioxidants can not only meet the aging property, but also have good breakdown property, which is an ideal substitute for BHT.",W. Peng; M. Xiong; X. Deng; Z. Peng; W. Lu; W. Zhao; H. Zhang,,,AC breakdown performance of natural esters combined with different biodegradable antioxidants under accelerated thermal ageing,2021,,10.1049/icp.2022.0273 ,IET Conferences ,,"Natural esters derived from natural plants are being considered as potential substitutes to conventional mineral oils, due to their less-flammable, non-toxic and environmentally friendly properties. To date, natural esters have been successfully applied in sealed distribution, traction transformers and even a few cases in power transformers. But the fact of being susceptible to oxidation presents it still an engineering challenge of replacing mineral oil by natural esters in those free-breathing transformers. At present, the most commonly used antioxidant in natural esters is BHT, but its non-degradability also brings a big problem. In this paper, different biodegradable antioxidants were added into natural esters and liquid samples filled into specially designed test cells with a volume/surface ratio of 20 mm. The liquid samples in the test cell were aged in an air-circulating oven at 120°C. AC breakdown strength (kV/mm) of the liquid samples was measured periodically during the accelerated ageing experiment. Acid value of the liquid samples was also measured to provide additional information. The results show that the natural ester with biodegradable antioxidants can not only meet the aging property, but also have good breakdown property, which is an ideal substitute for BHT.",,,978-1-83953-605-2,1571-1575,IET , ,,,
4932,"Title:Indian Experience in commissioning of World’s first 420kV shunt Reactor with Natural Ester

 Mineral oil from petroleum crude has been used in Transformers and Reactors since 1890s. Since inception, manufacturing of mineral oil has gone through several stages of improvement during past 130 years. Further, gas to liquid technology has also been evolved in recent times for mineral oils. Despite the improvement in production technology, Transformer mineral oil suffers from two major disadvantages: lower biodegradability and less fire safety, causing consequential damages during catastrophic failure of Transformers. Further, there are major concerns on the toxic effects of oil spills to nearby environment. Ester based alternate fluids viz. synthetic esters and natural esters mitigate the disadvantages of conventional mineral oil in terms of higher biodegradability and better fire safety. Use of Ester fluids results in less water migration to insulating paper during equilibrium, thereby promoting better insulation dryness and higher equipment life. The experience in India on using alternate environment friendly fluid was till now limited to distribution and medium voltage rating 66 kV class Transformers. Recently, Power Grid Corporation of India Limited (POWERGRID), a major Transmission utility in India took a pilot project to commission world’s first Natural Ester filled 420kV Shunt Reactor to gain field experience.",D. N. Jha; P. Ghosh; R. K. Jain; P. R. S. Yadav; A. K. Gupta,,,Indian Experience in commissioning of World’s first 420kV shunt Reactor with Natural Ester,,,10.1109/EIC51169.2022.10122616 ,IEEE Conferences ,,"Mineral oil from petroleum crude has been used in Transformers and Reactors since 1890s. Since inception, manufacturing of mineral oil has gone through several stages of improvement during past 130 years. Further, gas to liquid technology has also been evolved in recent times for mineral oils. Despite the improvement in production technology, Transformer mineral oil suffers from two major disadvantages: lower biodegradability and less fire safety, causing consequential damages during catastrophic failure of Transformers. Further, there are major concerns on the toxic effects of oil spills to nearby environment. Ester based alternate fluids viz. synthetic esters and natural esters mitigate the disadvantages of conventional mineral oil in terms of higher biodegradability and better fire safety. Use of Ester fluids results in less water migration to insulating paper during equilibrium, thereby promoting better insulation dryness and higher equipment life. The experience in India on using alternate environment friendly fluid was till now limited to distribution and medium voltage rating 66 kV class Transformers. Recently, Power Grid Corporation of India Limited (POWERGRID), a major Transmission utility in India took a pilot project to commission world’s first Natural Ester filled 420kV Shunt Reactor to gain field experience.",2576-6791,,978-1-6654-8023-9,372-378,IEEE , ,Viscosity;Shunts (electrical);Fluids;Oils;Oil insulation;Minerals;Inductors,,
4933,"Title:Bioinformatics Analyses of Deinococcus Radiodurans in Order to Waste Clean Up

 Environmental pollutants have become a major global concern. The waste generated from the development of products and processes are of concern to the environmentalist. One of the major issues in recent times is the threat to the human life caused due to the progressive deterioration of the environment. The waste generated from the development of products and processes are of concern to the environmentalist. Heavy metals are also reported persisting into the environment causing toxicity to living organisms through bioaccumulation, adsorption and biotransformation. A number of microorganisms, as a result of their versatility, adaptability and diversity in the environment, are considered to be the best candidates among all living organisms to remediate most of the environmental contaminants into the natural biogeochemical cycle. These natural forces of biodegradation can reduce waste and cleanup some types of environmental contaminants. Compositing can accelerate natural biodegradation and convert organic wastes to valuable resources. Deinococcus radiodurans is known as the world's toughest bacteria and it is the most radiation resistant organism known. Scientists are interested in this organism because of its potential usefulness in cleaning up waste sites that contain radiation and toxic chemicals. It can tolerate radiation levels at 1000 times the levels that would kill a human and it was originally isolated in 1956 from a can of meat that had been irradiated with X-rays. The bacterium can tolerate high levels of chemical, oxidative, UV, and ionizing radiation-induced damage to the cell's DNA, which it efficiently repairs. The resistance to radiation may reflect its resistance to dessication, which also causes DNA damage. This organism may be of use in cleaning up toxic metals found at nuclear weapons production sites due to the radiation resistance. Deinococcus has been genetically engineered for use in bioremediation to consume and digest solvents and heavy metals, even in a highly radioactive site. For example, the bacterial mercuric reductase gene has been cloned from Escherichia coli into Deinococcus to detoxify the ionic mercury residue frequently found in radioactive waste generated from nuclear weapons manufacture. This bacterium is also a highly efficient transformer, and can readily take up exogenous DNA from the environment, which may also aid DNA repair. Bioinformatics offers many interesting possibilities for bioremediation from environment protection point of view. Genomic and bioinformatic data provide a wealth of information that would be greatly enhanced by structural characterisation of some of these proteins in them. It can be extended to follow the leads provided by collaborating bioinformatics experts and proteomics studies. This may ultimately result not only in a more complete understanding of the radiation resistance of this bacterium, but also to the discovery of novel DNA repair systems, applicable to an understanding of the mechanisms of higher organisms such as man. Analysis of paralogs in Deinococcus has revealed several unique protein families. In addition, specific expansions of several other families including phosphatases, proteases, acyltransferases, and Nudix family pyrophosphohydrolases were detected. Genes that potentially affect DNA repair and stress responses and recombination were investigated in this article. These observations suggest that several different biological mechanisms contribute to the multiple DNA repair-dependent phenotypes of this organism. Then D.radiodurans as a bioremediation agent, can remove heavy metals and organic solvents such that the subsequent radionuclide isolation is safer and easier. This analysis is a single substantiation of function of Nudix protein family with is taken from D.radiodurans R1, for the purpose of waste clean up.",M. Sadraeian; Z. Molaee,,,Bioinformatics Analyses of Deinococcus Radiodurans in Order to Waste Clean Up,,,10.1109/ICECS.2009.36 ,IEEE Conferences ,,"Environmental pollutants have become a major global concern. The waste generated from the development of products and processes are of concern to the environmentalist. One of the major issues in recent times is the threat to the human life caused due to the progressive deterioration of the environment. The waste generated from the development of products and processes are of concern to the environmentalist. Heavy metals are also reported persisting into the environment causing toxicity to living organisms through bioaccumulation, adsorption and biotransformation. A number of microorganisms, as a result of their versatility, adaptability and diversity in the environment, are considered to be the best candidates among all living organisms to remediate most of the environmental contaminants into the natural biogeochemical cycle. These natural forces of biodegradation can reduce waste and cleanup some types of environmental contaminants. Compositing can accelerate natural biodegradation and convert organic wastes to valuable resources. Deinococcus radiodurans is known as the world's toughest bacteria and it is the most radiation resistant organism known. Scientists are interested in this organism because of its potential usefulness in cleaning up waste sites that contain radiation and toxic chemicals. It can tolerate radiation levels at 1000 times the levels that would kill a human and it was originally isolated in 1956 from a can of meat that had been irradiated with X-rays. The bacterium can tolerate high levels of chemical, oxidative, UV, and ionizing radiation-induced damage to the cell's DNA, which it efficiently repairs. The resistance to radiation may reflect its resistance to dessication, which also causes DNA damage. This organism may be of use in cleaning up toxic metals found at nuclear weapons production sites due to the radiation resistance. Deinococcus has been genetically engineered for use in bioremediation to consume and digest solvents and heavy metals, even in a highly radioactive site. For example, the bacterial mercuric reductase gene has been cloned from Escherichia coli into Deinococcus to detoxify the ionic mercury residue frequently found in radioactive waste generated from nuclear weapons manufacture. This bacterium is also a highly efficient transformer, and can readily take up exogenous DNA from the environment, which may also aid DNA repair. Bioinformatics offers many interesting possibilities for bioremediation from environment protection point of view. Genomic and bioinformatic data provide a wealth of information that would be greatly enhanced by structural characterisation of some of these proteins in them. It can be extended to follow the leads provided by collaborating bioinformatics experts and proteomics studies. This may ultimately result not only in a more complete understanding of the radiation resistance of this bacterium, but also to the discovery of novel DNA repair systems, applicable to an understanding of the mechanisms of higher organisms such as man. Analysis of paralogs in Deinococcus has revealed several unique protein families. In addition, specific expansions of several other families including phosphatases, proteases, acyltransferases, and Nudix family pyrophosphohydrolases were detected. Genes that potentially affect DNA repair and stress responses and recombination were investigated in this article. These observations suggest that several different biological mechanisms contribute to the multiple DNA repair-dependent phenotypes of this organism. Then D.radiodurans as a bioremediation agent, can remove heavy metals and organic solvents such that the subsequent radionuclide isolation is safer and easier. This analysis is a single substantiation of function of Nudix protein family with is taken from D.radiodurans R1, for the purpose of waste clean up.",,,978-1-4244-5591-1,254-258,IEEE , ,Bioinformatics;Organisms;DNA;Immune system;Microorganisms;Proteins;Humans;Biodegradation;Cleaning;Nuclear weapons,,
4934,"Title:Evaluation of several techniques and additives to de-moisturise vegetable oils and bench mark the moisture content level of vegetable oil-based dielectric fluids

 Highly biodegradable and renewable seed-based oils can be an alternative source of dielectric fluids to replace the non-friendly mineral oil-based dielectric fluids. However, the high moisture content of vegetable oils is not suitable for a viable dielectric fluid formulation for safe, economic and trouble free operation of power and distribution transformers. The reduction of the moisture level of vegetable oils to an acceptable and safe working level is one of the major steps of development of a highly biodegradable and environment friendly dielectric fluid. This paper describes an analytical method to bench mark the moisture content level of vegetable oil-based dielectric fluids and evaluates several techniques and products for lowering the moisture content level of vegetable oils below the bench marked level for safe operation of power and distribution transformers. The paper also presents the acute toxicity and biodegradation characteristics of the processed vegetable oil-based base fluid to demonstrate its environmental compliance. Experimental results of de-moisturisation using some absorbing materials indicate that the moisture level of vegetable oils can be reduced below the bench marked level to ensure the functional behaviour of vegetable oil-based dielectric fluids. The acute toxicity and biodegradation tests of the base fluid indicate virtually non-toxic and readily biodegradable characteristics for dielectric fluid that can be formulated using the base fluid.",M. Amanullah; S. M. Islam; S. Chami; G. Ienco,,,Evaluation of several techniques and additives to de-moisturise vegetable oils and bench mark the moisture content level of vegetable oil-based dielectric fluids,,,10.1109/ICDL.2008.4622460 ,IEEE Conferences ,,"Highly biodegradable and renewable seed-based oils can be an alternative source of dielectric fluids to replace the non-friendly mineral oil-based dielectric fluids. However, the high moisture content of vegetable oils is not suitable for a viable dielectric fluid formulation for safe, economic and trouble free operation of power and distribution transformers. The reduction of the moisture level of vegetable oils to an acceptable and safe working level is one of the major steps of development of a highly biodegradable and environment friendly dielectric fluid. This paper describes an analytical method to bench mark the moisture content level of vegetable oil-based dielectric fluids and evaluates several techniques and products for lowering the moisture content level of vegetable oils below the bench marked level for safe operation of power and distribution transformers. The paper also presents the acute toxicity and biodegradation characteristics of the processed vegetable oil-based base fluid to demonstrate its environmental compliance. Experimental results of de-moisturisation using some absorbing materials indicate that the moisture level of vegetable oils can be reduced below the bench marked level to ensure the functional behaviour of vegetable oil-based dielectric fluids. The acute toxicity and biodegradation tests of the base fluid indicate virtually non-toxic and readily biodegradable characteristics for dielectric fluid that can be formulated using the base fluid.",2153-3733,,978-1-4244-1585-4,1-4,IEEE , ,Fluids;Dielectrics;Moisture;Vegetable oils;Petroleum;Biodegradation;Oils,,
4935,"Title:High-Rise Building Decontamination after a Furan Incident

 A fire involving a polychlorinated biphenyl (PCB) filled transformer in an underground vault forced the closure of a high-rise office building due to contamination by PCBs and toxic combustion by-products. This paper describes the incident and the steps taken to reopen the building.",R. Maslowski; V. Rose,,,High-Rise Building Decontamination after a Furan Incident,1,1,10.1109/TPWRD.1986.4307914 ,IEEE Journals ,,A fire involving a polychlorinated biphenyl (PCB) filled transformer in an underground vault forced the closure of a high-rise office building due to contamination by PCBs and toxic combustion by-products. This paper describes the incident and the steps taken to reopen the building.,1937-4208,,,239-244,IEEE , ,Decontamination;Fires;Buildings;Poles and towers;Oil insulation;Circuit faults;Contamination;Cables;Substation protection;Cities and towns,,
4936,"Title:Comparison of Machine Learning Algorithms and Oversampling Techniques for Urinary Toxicity Prediction After Prostate Cancer Radiotherapy

 Prostate cancer radiotherapy unavoidably involves the irradiation not only of the target volume, but also of healthy organs-at-risk, neighboring the prostate, likely causing adverse, toxicity-related side-effects. Specifically, in the case of urinary toxicity, these side effects might be associated with a variety of dosimetric, clinical and genetic factors, making its prediction particularly challenging. Given the inconsistency of available data concerning radiation-induced toxicity, it is crucial to develop robust models with superior predictive performance in order to perform tailored treatments. Machine Learning techniques emerge as appealing in this context, nevertheless without any consensus on the best algorithms to be used. This work proposes a comparison of several machine-learning strategies together with different minority class oversampling techniques for prediction of urinary toxicity following prostate cancer radiotherapy using dosimetric and clinical data. The performance of these classifiers was evaluated on the original dataset and using four different synthetic oversampling techniques. The area under the ROC curve (AUC) and the F-measure were employed to evaluate their performance. Results suggest that, regardless of the technique, oversampling always increases the prediction performance of the models (p=0.004). Overall, oversampling with Synthetic Minority Oversampling Technique (SMOTE) followed by Edited Nearest Neighbour algorithm (ENN) together with Regularized Discriminant Analysis (RDA) classifier provide the best performance (AUC=0.71).",E. Mylona; C. Lebreton; P. Fontaine; S. Supiot; N. Magne; G. Crehange; R. de Crevoisier; O. Acosta,,,Comparison of Machine Learning Algorithms and Oversampling Techniques for Urinary Toxicity Prediction After Prostate Cancer Radiotherapy,,,10.1109/BIBE.2019.00180 ,IEEE Conferences ,,"Prostate cancer radiotherapy unavoidably involves the irradiation not only of the target volume, but also of healthy organs-at-risk, neighboring the prostate, likely causing adverse, toxicity-related side-effects. Specifically, in the case of urinary toxicity, these side effects might be associated with a variety of dosimetric, clinical and genetic factors, making its prediction particularly challenging. Given the inconsistency of available data concerning radiation-induced toxicity, it is crucial to develop robust models with superior predictive performance in order to perform tailored treatments. Machine Learning techniques emerge as appealing in this context, nevertheless without any consensus on the best algorithms to be used. This work proposes a comparison of several machine-learning strategies together with different minority class oversampling techniques for prediction of urinary toxicity following prostate cancer radiotherapy using dosimetric and clinical data. The performance of these classifiers was evaluated on the original dataset and using four different synthetic oversampling techniques. The area under the ROC curve (AUC) and the F-measure were employed to evaluate their performance. Results suggest that, regardless of the technique, oversampling always increases the prediction performance of the models (p=0.004). Overall, oversampling with Synthetic Minority Oversampling Technique (SMOTE) followed by Edited Nearest Neighbour algorithm (ENN) together with Regularized Discriminant Analysis (RDA) classifier provide the best performance (AUC=0.71).",2471-7819,,978-1-7281-4617-1,964-971,IEEE , ,Toxicology;Machine learning;Prostate cancer;Predictive models;Training;Decision trees,,
4937,"Title:Implementation of the Grey Wolf Algorithm in Optimization of Artificial Neural Network Method for Fingerprint-Based Toxicity Prediction

 Medicine is a primary need that is used to heal various diseases in living things. When consuming the drug alone, it may cause symptoms of toxicity. Therefore, it is very necessary to predict toxicity in chemical compounds that can be tolerated by the body. Regarding toxicity prediction, an alternative method is needed to replace High-Throughput Screening (HTS), because the method requires a lot of time and money. One of the alternative methods is using the machine learning method, such as Artificial Neural Network (ANN). This study aims to predict the toxicity of chemical compounds with feature-based fingerprints using the ANN method optimized by the grey wolf algorithm. The dataset was retrieved from Tox21 Data Challenge repository. According to the result, we obtained the best model from ANN with 2 hidden layers, tanh activation function, and adam optimizer, getting F1-score results and accuracy on test data with values of 0.590 and 0.887 respectively.",M. F. Aditya; A. Aditsania; I. Kurniawan,,,Implementation of the Grey Wolf Algorithm in Optimization of Artificial Neural Network Method for Fingerprint-Based Toxicity Prediction,,,10.1109/IC2IE60547.2023.10331599 ,IEEE Conferences ,,"Medicine is a primary need that is used to heal various diseases in living things. When consuming the drug alone, it may cause symptoms of toxicity. Therefore, it is very necessary to predict toxicity in chemical compounds that can be tolerated by the body. Regarding toxicity prediction, an alternative method is needed to replace High-Throughput Screening (HTS), because the method requires a lot of time and money. One of the alternative methods is using the machine learning method, such as Artificial Neural Network (ANN). This study aims to predict the toxicity of chemical compounds with feature-based fingerprints using the ANN method optimized by the grey wolf algorithm. The dataset was retrieved from Tox21 Data Challenge repository. According to the result, we obtained the best model from ANN with 2 hidden layers, tanh activation function, and adam optimizer, getting F1-score results and accuracy on test data with values of 0.590 and 0.887 respectively.",,,979-8-3503-4516-2,109-114,IEEE , ,Drugs;Toxicology;Machine learning algorithms;Metaheuristics;Artificial neural networks;Computer architecture;Fingerprint recognition,,
4938,"Title:Toxicity Prediction in Pelvic Radiotherapy Using Multiple Instance Learning and Cascaded Attention Layers

 Modern radiotherapy delivers treatment plans optimised on an individual patient level, using CT-based 3D models of patient anatomy. This optimisation is fundamentally based on simple assumptions about the relationship between radiation dose delivered to the cancer (increased dose will increase cancer control) and normal tissue (increased dose will increase rate of side effects). The details of these relationships are still not well understood, especially for radiation-induced toxicity. We propose a convolutional neural network based on multiple instance learning to analyse toxicity relationships for patients receiving pelvic radiotherapy. A dataset comprising of 315 patients were included in this study; with 3D dose distributions, pre-treatment CT scans with annotated abdominal structures, and patient-reported toxicity scores provided for each participant. In addition, we propose a novel mechanism for segregating the attentions over space and dose/imaging features independently for a better understanding of the anatomical distribution of toxicity. Quantitative and qualitative experiments were performed to evaluate the network performance. The proposed network could predict toxicity with 80% accuracy. Attention analysis over space demonstrated that there was a significant association between radiation dose to the anterior and right iliac of the abdomen and patient-reported toxicity. Experimental results showed that the proposed network had outstanding performance for toxicity prediction, localisation and explanation with the ability of generalisation for an unseen dataset.",B. Elhaminia; A. Gilbert; J. Lilley; M. Abdar; A. F. Frangi; A. Scarsbrook; A. Appelt; A. Gooya,,,Toxicity Prediction in Pelvic Radiotherapy Using Multiple Instance Learning and Cascaded Attention Layers,27,4,10.1109/JBHI.2023.3238825 ,IEEE Journals ,,"Modern radiotherapy delivers treatment plans optimised on an individual patient level, using CT-based 3D models of patient anatomy. This optimisation is fundamentally based on simple assumptions about the relationship between radiation dose delivered to the cancer (increased dose will increase cancer control) and normal tissue (increased dose will increase rate of side effects). The details of these relationships are still not well understood, especially for radiation-induced toxicity. We propose a convolutional neural network based on multiple instance learning to analyse toxicity relationships for patients receiving pelvic radiotherapy. A dataset comprising of 315 patients were included in this study; with 3D dose distributions, pre-treatment CT scans with annotated abdominal structures, and patient-reported toxicity scores provided for each participant. In addition, we propose a novel mechanism for segregating the attentions over space and dose/imaging features independently for a better understanding of the anatomical distribution of toxicity. Quantitative and qualitative experiments were performed to evaluate the network performance. The proposed network could predict toxicity with 80% accuracy. Attention analysis over space demonstrated that there was a significant association between radiation dose to the anterior and right iliac of the abdomen and patient-reported toxicity. Experimental results showed that the proposed network had outstanding performance for toxicity prediction, localisation and explanation with the ability of generalisation for an unseen dataset.",2168-2208,,,1958-1966,IEEE , ,Toxicology;Three-dimensional displays;Computed tomography;Radiation therapy;Cancer;Biomedical imaging;Convolutional neural networks,,
4939,"Title:Feature Selection on Imbalanced Data and Its Application on Toxicity Prediction

 The principle of computational toxicity prediction is that chemicals with similar molecular structures may possess similar toxicological pathways and effects. There have been many methods that represented each chemical by a set of descriptors, which are identified by experts as promising properties for predicting biological activity or toxicity. These chemical descriptors play a critical role in computational methods, that task correlated descriptors are favorable to achieve high prediction performance. However, there are few work compare the effectiveness of chemical descriptors and evaluate their performance in toxicity prediction. In this paper, we propose a novel ensemble feature selection method based on random under-sampling to analysis the effectiveness of chemical descriptors adopted in toxicity prediction application. The proposed method is efficient and can relief the imbalanced data problem of toxicity. Experiment results on the tox21 toxicity prediction dataset show that ""molecular property"", ""connectivity"" and ""topological"" descriptor are the three most important descriptors for toxicity prediction tasks among the 12 popular descriptors adopted in toxicity prediction applications. The results of this study can be used as a guide to propose new descriptors for chemical toxicity prediction.",J. -C. LI,,,Feature Selection on Imbalanced Data and Its Application on Toxicity Prediction,,,10.1109/ICMLC51923.2020.9469564 ,IEEE Conferences ,,"The principle of computational toxicity prediction is that chemicals with similar molecular structures may possess similar toxicological pathways and effects. There have been many methods that represented each chemical by a set of descriptors, which are identified by experts as promising properties for predicting biological activity or toxicity. These chemical descriptors play a critical role in computational methods, that task correlated descriptors are favorable to achieve high prediction performance. However, there are few work compare the effectiveness of chemical descriptors and evaluate their performance in toxicity prediction. In this paper, we propose a novel ensemble feature selection method based on random under-sampling to analysis the effectiveness of chemical descriptors adopted in toxicity prediction application. The proposed method is efficient and can relief the imbalanced data problem of toxicity. Experiment results on the tox21 toxicity prediction dataset show that ""molecular property"", ""connectivity"" and ""topological"" descriptor are the three most important descriptors for toxicity prediction tasks among the 12 popular descriptors adopted in toxicity prediction applications. The results of this study can be used as a guide to propose new descriptors for chemical toxicity prediction.",2160-1348,,978-1-6654-1943-7,151-157,IEEE , ,Toxicology;Correlation;Feature extraction;Biology;Task analysis;Chemicals;Random forests,,
4940,"Title:TOP: Towards Better Toxicity Prediction by Deep Molecular Representation Learning

 At the early stages of the drug discovery, molecule toxicity prediction is crucial to excluding drug candidates that are likely to fail in clinical trials. In this paper, we presented a novel molecular representation method and developed a corresponding deep learning-based framework called TOP (the abbreviation of TOxicity Prediction). TOP integrated a serial special data processing methods, a bidirectional gated recurrent unit-based RNN (BiGRU) and a fully connected neural network for end-to-end molecular representation learning and chemical toxicity prediction. TOP can automatically learn a mixed molecular representation from not only SMILES contextual information that describes the molecule structure, but also physiochemical properties. Therefore, TOP can overcome the drawbacks of existing methods that use either of them, thus greatly promotes toxicity prediction. We conducted extensive experiments over 14 classic toxicity prediction tasks on three different benchmark datasets, including balanced and imbalanced ones. The results show that, with the help of the novel molecular representation method, TOP significantly outperforms not only three baseline machine learning methods, but also five state-of-the-art methods.",Y. Peng; Z. Zhang; Q. Jiang; J. Guan; S. Zhou,,,TOP: Towards Better Toxicity Prediction by Deep Molecular Representation Learning,,,10.1109/BIBM47256.2019.8983340 ,IEEE Conferences ,,"At the early stages of the drug discovery, molecule toxicity prediction is crucial to excluding drug candidates that are likely to fail in clinical trials. In this paper, we presented a novel molecular representation method and developed a corresponding deep learning-based framework called TOP (the abbreviation of TOxicity Prediction). TOP integrated a serial special data processing methods, a bidirectional gated recurrent unit-based RNN (BiGRU) and a fully connected neural network for end-to-end molecular representation learning and chemical toxicity prediction. TOP can automatically learn a mixed molecular representation from not only SMILES contextual information that describes the molecule structure, but also physiochemical properties. Therefore, TOP can overcome the drawbacks of existing methods that use either of them, thus greatly promotes toxicity prediction. We conducted extensive experiments over 14 classic toxicity prediction tasks on three different benchmark datasets, including balanced and imbalanced ones. The results show that, with the help of the novel molecular representation method, TOP significantly outperforms not only three baseline machine learning methods, but also five state-of-the-art methods.",,,978-1-7281-1867-3,318-325,IEEE , ,,,
4941,"Title:Analysis of Multiple Toxicities Using ML Algorithms to Detect Toxic Comments

 Toxic Comment Classification is a classification problem that needs to be addressed these days. People can expresstheir thoughts on the internet via social media platforms. Hence itis important to set up some guidelines, which address the kind of information that is allowed to be posted. Hence The study of comments and their classification is necessary. The main aim of the following project is to understand whether the followingcomment falls under the toxic or nontoxic category by using multiple machine learning techniques. The following study uses 6 different traits, with the help of □ vectorization a dictionary will be created out of known vocabulary(Dataset) to train the ML model. Since Multiple Traits are presentthe ML model has to get trained multiple times against each trait.This helps us to identify, which algorithm performs best in identifying multiple types of toxicities. It was identified that the Random Forest algorithm performed well against all types of traitswhich gave us a good accuracy of 85% with a precision of 91%. During the preliminary research, it was concluded that most of theresearch which was revolving around the topic was limited to Demographic/local Languages. We tried identifying a classifier for the English language.",K. A. Kumar; B. Kanisha,,,Analysis of Multiple Toxicities Using ML Algorithms to Detect Toxic Comments,,,10.1109/ICACITE53722.2022.9823822 ,IEEE Conferences ,,"Toxic Comment Classification is a classification problem that needs to be addressed these days. People can expresstheir thoughts on the internet via social media platforms. Hence itis important to set up some guidelines, which address the kind of information that is allowed to be posted. Hence The study of comments and their classification is necessary. The main aim of the following project is to understand whether the followingcomment falls under the toxic or nontoxic category by using multiple machine learning techniques. The following study uses 6 different traits, with the help of □ vectorization a dictionary will be created out of known vocabulary(Dataset) to train the ML model. Since Multiple Traits are presentthe ML model has to get trained multiple times against each trait.This helps us to identify, which algorithm performs best in identifying multiple types of toxicities. It was identified that the Random Forest algorithm performed well against all types of traitswhich gave us a good accuracy of 85% with a precision of 91%. During the preliminary research, it was concluded that most of theresearch which was revolving around the topic was limited to Demographic/local Languages. We tried identifying a classifier for the English language.",,,978-1-6654-3789-9,1561-1566,IEEE , ,Toxicology;Dictionaries;Social networking (online);Forestry;Classification algorithms;Regression tree analysis;Random forests,,
4942,"Title:Toxicity Prediction Using Pre-trained Autoencoder

 Toxicology in the 21st Century (Tox21) is a collaborative initiative whose purpose is to investigate and develop efficient testing approaches to predict the impact chemical compounds have on Humans. In this paper we investigate how a pre-trained auto-encoder can be used to build classifiers capable of predicting the toxicity property of chemical compounds. Using a Deep Learning approach, we performed experiments to deter-mine if chemical compound fingerprints can be used to predict active and inactive compounds based on simplified molecular-input line-entry system (SMILES) in twelve selected assays. We conducted these experiments using data from ChEMBL and Tox21 to investigate how the latent layer produced by an auto-encoder can be used to train a classifier. All experimental results are compared against the winning teams of the Tox21 challenge, where positives and limitations of the proposed approaches are discussed.",M. Galushka; F. Browne; M. Mulvenna; R. Bond; G. Lightbody,,,Toxicity Prediction Using Pre-trained Autoencoder,,,10.1109/BIBM.2018.8621421 ,IEEE Conferences ,,"Toxicology in the 21st Century (Tox21) is a collaborative initiative whose purpose is to investigate and develop efficient testing approaches to predict the impact chemical compounds have on Humans. In this paper we investigate how a pre-trained auto-encoder can be used to build classifiers capable of predicting the toxicity property of chemical compounds. Using a Deep Learning approach, we performed experiments to deter-mine if chemical compound fingerprints can be used to predict active and inactive compounds based on simplified molecular-input line-entry system (SMILES) in twelve selected assays. We conducted these experiments using data from ChEMBL and Tox21 to investigate how the latent layer produced by an auto-encoder can be used to train a classifier. All experimental results are compared against the winning teams of the Tox21 challenge, where positives and limitations of the proposed approaches are discussed.",,,978-1-5386-5488-0,299-304,IEEE , ,Compounds;Chemical compounds;Training;Chemicals;Neural networks;Decoding;Testing,,
4943,"Title:An Efficient Technique of Predicting Toxicity on Music Lyrics Machine Learning

 It is widely accepted that music is humanity's universal language since it can spread happiness and excitement throughout people's lives. Music is a form of art that is highly regarded worldwide. There are many ways that music lyrics affect our daily lives. In the music industry, it is crucial to prevent the reproduction of songs whose lyrics are toxic or unsuitable for children. Our mood might be impacted by listening to particularly toxic or non-toxic music. The listener's experience might be enhanced if the recommendation method eliminates toxicity. In this study, we use machine learning (ML) algorithms to classify lyrics from various musical genres and performers as toxic or non-toxic. Utilizing the Detoxify model, the toxicity score was generated and labelled the songs as toxic and non-toxic based on the scores. The study demonstrates that the configuration using the lyric data set along with TF-IDF vectorization and Ensemble of Logistic Regression, Support Vector Machine and Decision Tree as an algorithm surpasses all other designs with 94% accuracy. This classification will help the authority and policymakers of music industries to categorize the song based on the label and mention in the song description which is not appropriate for the children and set guidelines to prevent toxicity via songs.",N. Bin Noor; I. Ahmed,,,An Efficient Technique of Predicting Toxicity on Music Lyrics Machine Learning,,,10.1109/ECCE57851.2023.10101658 ,IEEE Conferences ,,"It is widely accepted that music is humanity's universal language since it can spread happiness and excitement throughout people's lives. Music is a form of art that is highly regarded worldwide. There are many ways that music lyrics affect our daily lives. In the music industry, it is crucial to prevent the reproduction of songs whose lyrics are toxic or unsuitable for children. Our mood might be impacted by listening to particularly toxic or non-toxic music. The listener's experience might be enhanced if the recommendation method eliminates toxicity. In this study, we use machine learning (ML) algorithms to classify lyrics from various musical genres and performers as toxic or non-toxic. Utilizing the Detoxify model, the toxicity score was generated and labelled the songs as toxic and non-toxic based on the scores. The study demonstrates that the configuration using the lyric data set along with TF-IDF vectorization and Ensemble of Logistic Regression, Support Vector Machine and Decision Tree as an algorithm surpasses all other designs with 94% accuracy. This classification will help the authority and policymakers of music industries to categorize the song based on the label and mention in the song description which is not appropriate for the children and set guidelines to prevent toxicity via songs.",,,979-8-3503-4536-0,1-5,IEEE , ,Industries;Support vector machines;Toxicology;Machine learning algorithms;Computational modeling;Music;Organizations,,
4944,"Title:Toxicity risk assessment from heterogeneous uncertain data with possibility-probability distribution

 Due to the advance of modern computing technology, decisions can be made based on all the existing related data instances scattered across multiple data storages, such that available information has been entirely taken into consideration. Particularly in the predictive toxicology domain, because of the heterogeneity of data sources, multiple data instances with respect to the same endpoint are usually inconsistent, and the quality (or reliability) of the data instances is typically different. Also, the quantity of data instances is often not sufficient to conduct a study using conventional statistics-based methods. This paper presents a novel risk analysis approach for chemical toxicity assessment which considers all the available heterogeneous data instances in the same time, assisted by their quality (or reliability) values. The system is developed on the basis of possibility-probability distribution, where the uncertainty of the approximated probability values based on traditional statistics methods is represented by possibility. The uncertainty considered herein is led not only by the statistics on limited small number of data instances, but also by the poor quality (or reliability) of data instances. The possibility-probability distribution is automatically computed from available data instances by employing a modified diffused-interior-outer-set model (where the reliability of data is considered) based on information diffusion theory. Toxicity value for a given chemical compound is then estimated as the fuzzy expected value based on the resulted possibility-probability distribution. Toxicity risk with respect to regulatory threshold is also introduced, in order to evaluate the probability of which the toxicity may be classified into a certain regulatory range. The proposed approach is applied to a real-world dataset to illustrate the utility and the potential of the approach in risk assessment of chemical toxicity.",L. Yang; D. Neagu,,,Toxicity risk assessment from heterogeneous uncertain data with possibility-probability distribution,,,10.1109/FUZZ-IEEE.2013.6622304 ,IEEE Conferences ,,"Due to the advance of modern computing technology, decisions can be made based on all the existing related data instances scattered across multiple data storages, such that available information has been entirely taken into consideration. Particularly in the predictive toxicology domain, because of the heterogeneity of data sources, multiple data instances with respect to the same endpoint are usually inconsistent, and the quality (or reliability) of the data instances is typically different. Also, the quantity of data instances is often not sufficient to conduct a study using conventional statistics-based methods. This paper presents a novel risk analysis approach for chemical toxicity assessment which considers all the available heterogeneous data instances in the same time, assisted by their quality (or reliability) values. The system is developed on the basis of possibility-probability distribution, where the uncertainty of the approximated probability values based on traditional statistics methods is represented by possibility. The uncertainty considered herein is led not only by the statistics on limited small number of data instances, but also by the poor quality (or reliability) of data instances. The possibility-probability distribution is automatically computed from available data instances by employing a modified diffused-interior-outer-set model (where the reliability of data is considered) based on information diffusion theory. Toxicity value for a given chemical compound is then estimated as the fuzzy expected value based on the resulted possibility-probability distribution. Toxicity risk with respect to regulatory threshold is also introduced, in order to evaluate the probability of which the toxicity may be classified into a certain regulatory range. The proposed approach is applied to a real-world dataset to illustrate the utility and the potential of the approach in risk assessment of chemical toxicity.",1098-7584,,978-1-4799-0022-0,1-8,IEEE , ,Reliability;Mathematical model;Equations;Uncertainty;Chemicals;Chemical compounds,,
4945,"Title:A new ECG biomarker for drug toxicity: A combined signal processing and computational modeling study

 QT prolongation is the only clinically proven, yet insufficient, electrocardiogram (ECG) biomarker for drug-induced cardiac toxicity. The goal of this study is to evaluate whether JT area, i.e., total area of the T-wave, can serve as an ECG biomarker for drug-induced cardiac toxicity using both signal processing and computational modeling approaches. An ECG dataset that contained recordings from patients under control and sotalol condition was analyzed. In order to relate sotalol-induced ECG changes to its effect on ion channel level, i.e., blockade of the rapid component of the delayed rectifier potassium channel (IKr), varied degrees of IKr blockade were simulated in a slab of ventricular tissue. The mean JT area increased by 36.5% following the administration of sotalol in patients. Simulations in the slab tissue showed that sotalol increased action potential duration preferentially in the midmyocardium, which led to increased transmural dispersion of repolarization and JT area. In conclusion, JT area reflects the transmural dispersion of repolarization and may be a potentially useful surrogate/supplemental ECG biomarker to assess drug safety.",X. Jie; B. Rodriguez; E. Pueyo,,,A new ECG biomarker for drug toxicity: A combined signal processing and computational modeling study,,,10.1109/IEMBS.2010.5626864 ,IEEE Conferences ,,"QT prolongation is the only clinically proven, yet insufficient, electrocardiogram (ECG) biomarker for drug-induced cardiac toxicity. The goal of this study is to evaluate whether JT area, i.e., total area of the T-wave, can serve as an ECG biomarker for drug-induced cardiac toxicity using both signal processing and computational modeling approaches. An ECG dataset that contained recordings from patients under control and sotalol condition was analyzed. In order to relate sotalol-induced ECG changes to its effect on ion channel level, i.e., blockade of the rapid component of the delayed rectifier potassium channel (IKr), varied degrees of IKr blockade were simulated in a slab of ventricular tissue. The mean JT area increased by 36.5% following the administration of sotalol in patients. Simulations in the slab tissue showed that sotalol increased action potential duration preferentially in the midmyocardium, which led to increased transmural dispersion of repolarization and JT area. In conclusion, JT area reflects the transmural dispersion of repolarization and may be a potentially useful surrogate/supplemental ECG biomarker to assess drug safety.",1558-4615,,978-1-4244-4123-5,2565-2568,IEEE , ,Electrocardiography;Computational modeling;Drugs;Dispersion;Slabs;Lead,,
4946,"Title:The Combination of Clinical, Dose-Related and Imaging Features Helps Predict Radiation-Induced Normal-Tissue Toxicity in Lung-cancer Patients -- An in-silico Trial Using Machine Learning Techniques

 The amount of delivered radiation dose to the tumor in non-small cell lung cancer (NSCLC) patients is limited by the negative side effects on normal tissues. The most dose-limiting factor in radiotherapy is the radiation-induced lung toxicity (RILT). RILT is generally measured semi-quantitatively, by a dyspnea, or shortness-of-breath, score. In general, about 20-30% of patients develop RILT several months after treatment, and in about 70% of the patients the delivered dose is insufficient to control the tumor growth. Ideally, if the RILT score would be known in advance, then the dose treatment plan for the low-toxicity-risk patients could be adjusted so that higher dose is delivered to the tumor to better control it. A number of possible predictors of RILT have been proposed in the literature, including dose-related and clinical/demographic patient characteristics available prior to radiotherapy. In addition, the use of imaging features -- which are noninvasive in nature - has been gaining momentum. Thus, anatomic as well as functional/metabolic information from CT and PET scanner images respectively are used in daily clinical practice, which provide further information about the status of a patient. In this study we assessed whether machine learning techniques can successfully be applied to predict post-radiation lung damage, proxied by dyspnea score, based on clinical, dose-related (dosimetric) and image features. Our dataset included 78 NSCLC patients. The patients were divided into two groups: no-deterioration-of-dyspnea, and deterioration-of-dyspnea patients. Several machine-learning binary classifiers were applied to discriminate the two groups. The results, evaluated using the area under the ROC curve in a cross-validation procedure, are highly promising. This outcome could open the possibility to deliver better, individualized dose-treatment plans for lung cancer patients and help the overall clinical decision making (treatment) process.",G. Nalbantov; A. Dekker; D. De Ruysscher; P. Lambin; E. N. Smirnov,,,"The Combination of Clinical, Dose-Related and Imaging Features Helps Predict Radiation-Induced Normal-Tissue Toxicity in Lung-cancer Patients -- An in-silico Trial Using Machine Learning Techniques",2,,10.1109/ICMLA.2011.139 ,IEEE Conferences ,,"The amount of delivered radiation dose to the tumor in non-small cell lung cancer (NSCLC) patients is limited by the negative side effects on normal tissues. The most dose-limiting factor in radiotherapy is the radiation-induced lung toxicity (RILT). RILT is generally measured semi-quantitatively, by a dyspnea, or shortness-of-breath, score. In general, about 20-30% of patients develop RILT several months after treatment, and in about 70% of the patients the delivered dose is insufficient to control the tumor growth. Ideally, if the RILT score would be known in advance, then the dose treatment plan for the low-toxicity-risk patients could be adjusted so that higher dose is delivered to the tumor to better control it. A number of possible predictors of RILT have been proposed in the literature, including dose-related and clinical/demographic patient characteristics available prior to radiotherapy. In addition, the use of imaging features -- which are noninvasive in nature - has been gaining momentum. Thus, anatomic as well as functional/metabolic information from CT and PET scanner images respectively are used in daily clinical practice, which provide further information about the status of a patient. In this study we assessed whether machine learning techniques can successfully be applied to predict post-radiation lung damage, proxied by dyspnea score, based on clinical, dose-related (dosimetric) and image features. Our dataset included 78 NSCLC patients. The patients were divided into two groups: no-deterioration-of-dyspnea, and deterioration-of-dyspnea patients. Several machine-learning binary classifiers were applied to discriminate the two groups. The results, evaluated using the area under the ROC curve in a cross-validation procedure, are highly promising. This outcome could open the possibility to deliver better, individualized dose-treatment plans for lung cancer patients and help the overall clinical decision making (treatment) process.",,,978-1-4577-2134-2,220-224,IEEE , ,Lungs;Computed tomography;Positron emission tomography;Cancer;Tumors;Three dimensional displays;Machine learning,,
4947,"Title:3D echocardiographic quantification of ejection fraction and cardio-toxicity onset

 The aim of this study was to evaluate if variability in EF estimate from echocardiographic data acquired with two dimensional (2DE) and three-dimensional (3DE) systems and analyzed using different software packages could affect cardio-toxicity assessment. We analyzed 2DE and 3DE datasets in 94 patients treated for breast cancer with anthracycline and trastuzumab. EF was computed from 2DE and 3DE data using two software packages (EchoPAC, GE Healthcare and TomTec 4D LV analysis). Corresponding estimates were compared. In addition, in a subgroup of 20 patients 3DE data were re-analyzed and intra-observer and inter-observer variability by three investigators were computed, using both software packages. As expected 2DE-based estimates significantly underestimated 3DE-based estimates. Intra-observer and inter-observer variability using both analysis packages showed a huge variability, due to significant differences in end systolic volume and EF. Following clinical definition of cardio-toxicity onset, these variability results could be a confounding factor since variations in EF measurement are in the range of EF decrease due to cardiac adverse effects from cancer therapeutic drugs.",C. Lorenzini; M. Aquilina; C. Lamberti; C. Corsi,,,3D echocardiographic quantification of ejection fraction and cardio-toxicity onset,,, ,IEEE Conferences ,,"The aim of this study was to evaluate if variability in EF estimate from echocardiographic data acquired with two dimensional (2DE) and three-dimensional (3DE) systems and analyzed using different software packages could affect cardio-toxicity assessment. We analyzed 2DE and 3DE datasets in 94 patients treated for breast cancer with anthracycline and trastuzumab. EF was computed from 2DE and 3DE data using two software packages (EchoPAC, GE Healthcare and TomTec 4D LV analysis). Corresponding estimates were compared. In addition, in a subgroup of 20 patients 3DE data were re-analyzed and intra-observer and inter-observer variability by three investigators were computed, using both software packages. As expected 2DE-based estimates significantly underestimated 3DE-based estimates. Intra-observer and inter-observer variability using both analysis packages showed a huge variability, due to significant differences in end systolic volume and EF. Following clinical definition of cardio-toxicity onset, these variability results could be a confounding factor since variations in EF measurement are in the range of EF decrease due to cardiac adverse effects from cancer therapeutic drugs.",2325-8853,,978-1-4799-4347-0,709-712,IEEE , ,Abstracts;Software;Collaboration;Monitoring;Biomedical monitoring,,
4948,"Title:Altered GABAA receptor expression as biomarker of mercury toxicity in embryonic neurogenesis

 Mouse brain microarray dataset (GDS2702) on embryonic days 14.5 (E14.5), 16.5 (E16.5) and 18.5 (E18.5) was investigated for gene expression patterns of GABA receptors. Gabbr1, Gabra2, Gabrb3 and Gabrg2 were the only four GABA receptor genes expressed at stage E14.5 and E16.5. However, at stage E18.5, four additional genes (Gabra1, Gabra3, Gabrg1 and Gabrg3) were expressed. Gabbr1 had the highest intensity in all the three embryonic days. Gabra6, Gabrb2, Gabrd, Gabrr1 and Gabrr2 were not expressed in all the 3 samples analyzed. It is proposed that Gabra6 receptor is a potential biomarker for neuronal toxicity that can arise from maternal exposures to low doses of mercury through diet, water and air pollutions.",W. K. Ayensu; R. D. Isokpehi; H. H. Cohly; J. M. Murray; D. J. Webb; P. B. Tchounwou,,,Altered GABAA receptor expression as biomarker of mercury toxicity in embryonic neurogenesis,,,10.1109/BSEC.2009.5090491 ,IEEE Conferences ,,"Mouse brain microarray dataset (GDS2702) on embryonic days 14.5 (E14.5), 16.5 (E16.5) and 18.5 (E18.5) was investigated for gene expression patterns of GABA receptors. Gabbr1, Gabra2, Gabrb3 and Gabrg2 were the only four GABA receptor genes expressed at stage E14.5 and E16.5. However, at stage E18.5, four additional genes (Gabra1, Gabra3, Gabrg1 and Gabrg3) were expressed. Gabbr1 had the highest intensity in all the three embryonic days. Gabra6, Gabrb2, Gabrd, Gabrr1 and Gabrr2 were not expressed in all the 3 samples analyzed. It is proposed that Gabra6 receptor is a potential biomarker for neuronal toxicity that can arise from maternal exposures to low doses of mercury through diet, water and air pollutions.",,,978-1-4244-3837-2,1-3,IEEE , ,Biomarkers;Embryo;Computational biology;Gene expression;Neurotransmitters;Pediatrics;Bioinformatics;Chemicals;Mice;Organisms,,
4949,"Title:Generalisation of Cyberbullying Detection

 Filtering out Cyberbullying of communities has proven to be a challenge, and efforts have led to the creation of many different datasets to train classifiers. Through these datasets, we will explore the variety of definitions of cyberbullying behaviors and the impact of these differences on the portability of one classifier to another community. We also gain insight on the generalization power of these classifiers. A study of ensemble models combining these classifiers will help us understand how they interact with each other.",M. -A. Larochelle; R. Khoury,,,Generalisation of Cyberbullying Detection,,,10.1109/ASONAM49781.2020.9381476 ,IEEE Conferences ,,"Filtering out Cyberbullying of communities has proven to be a challenge, and efforts have led to the creation of many different datasets to train classifiers. Through these datasets, we will explore the variety of definitions of cyberbullying behaviors and the impact of these differences on the portability of one classifier to another community. We also gain insight on the generalization power of these classifiers. A study of ensemble models combining these classifiers will help us understand how they interact with each other.",2473-991X,,978-1-7281-1056-1,296-300,IEEE , ,Knowledge engineering;Vocabulary;Social networking (online);Filtering;Neural networks;Natural languages,,
4950,"Title:Toxic Comment Analysis for Online Learning

 Due to recent circumstances of the pandemic, online platforms are becoming more and more essential for communication in many sectors. But because of this, a lot of negativity and toxic comments are surfacing, resulting in degradation and online abuse. Educational systems and Institutions heavily rely on such platforms for e-learning leading to unrestricted attacks of toxic and negative comments towards teachers and students. Due to this work, issues of constant bullying and online abuse will be reduced. The comments classified are according to the parameters from our self-prepared dataset combined with Kaggle's toxic comment dataset, named as toxic, severely toxic, obscene, threat, insult, and identity hate. Machine Learning algorithms such as Logistic Regression, Random Forest, and Multinomial Naive Bayes are used. For data evaluation, ROC and Hamming scores are used. The output will be shown as the rate of each category in percentile and in a graphical format. This work will help reduce the online bullying and harassment faced by teachers and students and help create a non-toxic learning environment. In this way, the main focus will be on studying and not getting de-motivated and discouraged by hateful comments and people commenting toxic comments will also get reduced.",M. Vichare; S. Thorat; C. S. Uberoi; S. Khedekar; S. Jaikar,,,Toxic Comment Analysis for Online Learning,,,10.1109/ACCESS51619.2021.9563344 ,IEEE Conferences ,,"Due to recent circumstances of the pandemic, online platforms are becoming more and more essential for communication in many sectors. But because of this, a lot of negativity and toxic comments are surfacing, resulting in degradation and online abuse. Educational systems and Institutions heavily rely on such platforms for e-learning leading to unrestricted attacks of toxic and negative comments towards teachers and students. Due to this work, issues of constant bullying and online abuse will be reduced. The comments classified are according to the parameters from our self-prepared dataset combined with Kaggle's toxic comment dataset, named as toxic, severely toxic, obscene, threat, insult, and identity hate. Machine Learning algorithms such as Logistic Regression, Random Forest, and Multinomial Naive Bayes are used. For data evaluation, ROC and Hamming scores are used. The output will be shown as the rate of each category in percentile and in a graphical format. This work will help reduce the online bullying and harassment faced by teachers and students and help create a non-toxic learning environment. In this way, the main focus will be on studying and not getting de-motivated and discouraged by hateful comments and people commenting toxic comments will also get reduced.",,,978-1-7281-7136-4,130-135,IEEE , ,Seminars;Analytical models;Electronic learning;Computational modeling;Training data;Data models;Classification algorithms,,
4951,"Title:Impact of SMOTE on Imbalanced Text Features for Toxic Comments Classification Using RVVC Model

 Social media platforms and microblogging websites have gained accelerated popularity during the past few years. These platforms are used for expressing views and opinions about products, personalities, and events. Often during discussions and debates, fights take place on social media platforms which involves using rude, disrespectful, and hateful comments called toxic comments. The identification of toxic comments has been regarded as an essential element for social media platforms. This study introduces an ensemble approach, called regression vector voting classifier (RVVC), to identify the toxic comments on social media platforms. The ensemble merges the logistic regression and support vector classifier under soft voting criteria. Several experiments are performed on the imbalanced and balanced dataset to analyze the performance of the proposed approach. For data balance, the synthetic minority oversampling technique (SMOTE) is used on the imbalanced dataset. Furthermore, two feature extraction approaches are utilized to investigate their suitability such as term frequency-inverse document frequency (TF-IDF) and bag-of-words (BoW). The performance of the proposed approach is compared with several machine learning classifiers using accuracy, precision, recall, and F1-score. Results suggest that RVVC outperforms all other individual models when TF-IDF features are used with SMOTE balanced dataset and achieves an accuracy of 0.97.",V. Rupapara; F. Rustam; H. F. Shahzad; A. Mehmood; I. Ashraf; G. S. Choi,,,Impact of SMOTE on Imbalanced Text Features for Toxic Comments Classification Using RVVC Model,9,,10.1109/ACCESS.2021.3083638 ,IEEE Journals ,,"Social media platforms and microblogging websites have gained accelerated popularity during the past few years. These platforms are used for expressing views and opinions about products, personalities, and events. Often during discussions and debates, fights take place on social media platforms which involves using rude, disrespectful, and hateful comments called toxic comments. The identification of toxic comments has been regarded as an essential element for social media platforms. This study introduces an ensemble approach, called regression vector voting classifier (RVVC), to identify the toxic comments on social media platforms. The ensemble merges the logistic regression and support vector classifier under soft voting criteria. Several experiments are performed on the imbalanced and balanced dataset to analyze the performance of the proposed approach. For data balance, the synthetic minority oversampling technique (SMOTE) is used on the imbalanced dataset. Furthermore, two feature extraction approaches are utilized to investigate their suitability such as term frequency-inverse document frequency (TF-IDF) and bag-of-words (BoW). The performance of the proposed approach is compared with several machine learning classifiers using accuracy, precision, recall, and F1-score. Results suggest that RVVC outperforms all other individual models when TF-IDF features are used with SMOTE balanced dataset and achieves an accuracy of 0.97.",2169-3536,,,78621-78634,IEEE , ,Social networking (online);Support vector machines;Blogs;Feature extraction;Deep learning;Machine learning;Logistics,,
4952,"Title:Image Classification of Edible Wild Plants in the Philippines using Deep Convolutional Neural Network on Mobile Platform

 Edible wild plants are an important source of food in many regions of the world, including in the Philippines, and their recognition is a key skill for survival in the wild. In this study, we propose a mobile platform for image recognition of edible wild plants using deep convolutional neural networks (CNNs). The proposed system is designed to be lightweight and easily deployable on mobile devices, allowing for real-time recognition of edible plants in the field. To develop the system, we first collected a dataset of images of various edible wild plants. The dataset was preprocessed and augmented for better generalization. We then trained a CNN model using transfer learning techniques on a custom specific dataset of edible wild plant images endemic to the Philippines to recognize the different species of edible plants. The trained model was then optimized for deployment on mobile devices, and the resulting mobile application was tested on a variety of wild plants. The results showed that the proposed system achieved high accuracy in identifying edible wild plants, with an average accuracy of 96.98%. The proposed system has many potential applications, including in the field of outdoor education, potential solutions to address food scarcity, and survival training. It can also be used by foragers and hikers to identify edible plants in the wild, helping to prevent the consumption of toxic plants. Additionally, it can be used by researchers to gather data on the distribution and abundance of edible plants in different regions. The proposed mobile platform for image recognition of edible wild plants using CNNs is a promising tool for enhancing the safety and sustainability of foraging and outdoor activities.",V. Calinao; P. J. Go; M. Cabatuan; E. Sybingco,,,Image Classification of Edible Wild Plants in the Philippines using Deep Convolutional Neural Network on Mobile Platform,,,10.1109/TENCON58879.2023.10322310 ,IEEE Conferences ,,"Edible wild plants are an important source of food in many regions of the world, including in the Philippines, and their recognition is a key skill for survival in the wild. In this study, we propose a mobile platform for image recognition of edible wild plants using deep convolutional neural networks (CNNs). The proposed system is designed to be lightweight and easily deployable on mobile devices, allowing for real-time recognition of edible plants in the field. To develop the system, we first collected a dataset of images of various edible wild plants. The dataset was preprocessed and augmented for better generalization. We then trained a CNN model using transfer learning techniques on a custom specific dataset of edible wild plant images endemic to the Philippines to recognize the different species of edible plants. The trained model was then optimized for deployment on mobile devices, and the resulting mobile application was tested on a variety of wild plants. The results showed that the proposed system achieved high accuracy in identifying edible wild plants, with an average accuracy of 96.98%. The proposed system has many potential applications, including in the field of outdoor education, potential solutions to address food scarcity, and survival training. It can also be used by foragers and hikers to identify edible plants in the wild, helping to prevent the consumption of toxic plants. Additionally, it can be used by researchers to gather data on the distribution and abundance of edible plants in different regions. The proposed mobile platform for image recognition of edible wild plants using CNNs is a promising tool for enhancing the safety and sustainability of foraging and outdoor activities.",2159-3450,,979-8-3503-0219-6,1163-1168,IEEE , ,Deep learning;Training;Image recognition;Transfer learning;Real-time systems;Safety;Mobile applications,,
4953,"Title:Identification of Cancer Cell Population Dynamics Leveraging the Effect of Pre-Treatment for Drug Schedule Design

 Sequences of different drugs have shown potential to improve treatment strategies for cancer. Typical switched system approaches model the population dynamics of each drug independently, not rigorously considering the effects of pretreatment or drug-drug interactions. In this paper, a general model family incorporating pre-treatment effects and biological domain knowledge is proposed, and a model from this family is identified by using a novel experimental data set of two-drug sequences. Leveraging the data, a simulator for the cell population dynamics under sequences of up to nine drugs is developed and used to empirically evaluate the performance of a set of closed-loop drug scheduling controllers. We used the controllers to identifying promising drug schedules in silico and evaluated them in vitro. The experiments validated the effectiveness of the identified schedules in reducing the number of living cells to less than 10% of the initial. While only treating with certain toxic drugs achieves similar effectiveness, the schedules use toxic drugs for significantly shorter times which likely reduces toxicity to non-cancer cells.",M. Wiggert; M. Turnidge; Z. Cohen; E. M. Langer; R. C. Sears; M. P. Chapman; C. J. Tomlin,,,Identification of Cancer Cell Population Dynamics Leveraging the Effect of Pre-Treatment for Drug Schedule Design,,,10.23919/ACC50511.2021.9482989 ,IEEE Conferences ,,"Sequences of different drugs have shown potential to improve treatment strategies for cancer. Typical switched system approaches model the population dynamics of each drug independently, not rigorously considering the effects of pretreatment or drug-drug interactions. In this paper, a general model family incorporating pre-treatment effects and biological domain knowledge is proposed, and a model from this family is identified by using a novel experimental data set of two-drug sequences. Leveraging the data, a simulator for the cell population dynamics under sequences of up to nine drugs is developed and used to empirically evaluate the performance of a set of closed-loop drug scheduling controllers. We used the controllers to identifying promising drug schedules in silico and evaluated them in vitro. The experiments validated the effectiveness of the identified schedules in reducing the number of living cells to less than 10% of the initial. While only treating with certain toxic drugs achieves similar effectiveness, the schedules use toxic drugs for significantly shorter times which likely reduces toxicity to non-cancer cells.",2378-5861,,978-1-6654-4197-1,1909-1916,IEEE , ,Drugs;Switched systems;Schedules;Toxicology;Biological system modeling;Sociology;Dynamic scheduling,,
4954,"Title:Active Genetic Learning with Evidential Uncertainty for Identifying Mushroom Toxicity

 Mushroom's classification as edible or poisonous is an important problem that can have a direct impact on hu-man life. However, most of the existing works do not in-clude model uncertainty in their analysis and suffer from over-confidence issue. To solve this problem, we propose a learning framework, called deep active genetic with evi-dential uncertainty (DAG-EU), to model the uncertainty of the class probability to classify mushrooms. The framework selects the data points with high uncertainty and the most influencing features by using genetic algorithms. The ex-perimental results on the mushrooms dataset demonstrate that the proposed framework can improve the model classi-fication accuracy by 2.3% compared to the methods in the same domain. Moreover, it outperforms the other models from literature by 3.6%.",O. M. Aranay; P. K. Atrey,,,Active Genetic Learning with Evidential Uncertainty for Identifying Mushroom Toxicity,,,10.1109/MIPR54900.2022.00078 ,IEEE Conferences ,,"Mushroom's classification as edible or poisonous is an important problem that can have a direct impact on hu-man life. However, most of the existing works do not in-clude model uncertainty in their analysis and suffer from over-confidence issue. To solve this problem, we propose a learning framework, called deep active genetic with evi-dential uncertainty (DAG-EU), to model the uncertainty of the class probability to classify mushrooms. The framework selects the data points with high uncertainty and the most influencing features by using genetic algorithms. The ex-perimental results on the mushrooms dataset demonstrate that the proposed framework can improve the model classi-fication accuracy by 2.3% compared to the methods in the same domain. Moreover, it outperforms the other models from literature by 3.6%.",2770-4319,,978-1-6654-9548-6,395-400,IEEE , ,Analytical models;Uncertainty;Toxicology;Computational modeling;Training data;Information processing;Genetics,,
4955,"Title:Imbalanced Toxic Comments Classification Using Data Augmentation and Deep Learning

 Recently cyber-bullying and online harassment have become two of the most serious issues in many public online communities. In this paper, we use data from Wikipedia talk page edits to train multi-label classifier that detects different types of toxicity in online user-generated content. We present different data augmentation techniques to overcome the data imbalance problem in the Wikipedia dataset. The proposed solution is an ensemble of three models: convolutional neural network (CNN), bidirectional long short-term memory (LSTM) and bidirectional gated recurrent units (GRU). We divide the classification problem into two steps, first we determine whether or not the input is toxic then we find the types of toxicity present in the toxic content. The evaluation results show that the proposed ensemble approach provides the highest accuracy among all considered algorithms. It achieves 0.828 F1-score for toxic/non-toxic classification and 0.872 for toxicity types prediction.",M. Ibrahim; M. Torki; N. El-Makky,,,Imbalanced Toxic Comments Classification Using Data Augmentation and Deep Learning,,,10.1109/ICMLA.2018.00141 ,IEEE Conferences ,,"Recently cyber-bullying and online harassment have become two of the most serious issues in many public online communities. In this paper, we use data from Wikipedia talk page edits to train multi-label classifier that detects different types of toxicity in online user-generated content. We present different data augmentation techniques to overcome the data imbalance problem in the Wikipedia dataset. The proposed solution is an ensemble of three models: convolutional neural network (CNN), bidirectional long short-term memory (LSTM) and bidirectional gated recurrent units (GRU). We divide the classification problem into two steps, first we determine whether or not the input is toxic then we find the types of toxicity present in the toxic content. The evaluation results show that the proposed ensemble approach provides the highest accuracy among all considered algorithms. It achieves 0.828 F1-score for toxic/non-toxic classification and 0.872 for toxicity types prediction.",,,978-1-5386-6805-4,875-878,IEEE , ,Data models;Training;Kernel;Encyclopedias;Electronic publishing;Internet,,
4956,"Title:Integration strategies for toxicity data from an empirical perspective

 The recent development of information techniques, especially the state-of-the-art “big data” solutions, enables the extracting, gathering, and processing large amount of toxicity information from multiple sources. Facilitated by this technology advance, a framework named integrated testing strategies (ITS) has been proposed in the predictive toxicology domain, in an effort to intelligently jointly use multiple heterogeneous toxicity data records (through data fusion, grouping, interpolation/extrapolation etc.) for toxicity assessment. This will ultimately contribute to accelerating the development cycle of chemical products, reducing animal use, and decreasing development costs. Most of the current study in ITS is based on a group of consensus processes, termed weight of evidence (WoE), which quantitatively integrate all the relevant data instances towards the same endpoint into an integrated decision supported by data quality. Several WoE implementations for the particular case of toxicity data fusion have been presented in the literature, which are collectively studied in this paper. Noting that these uncertainty handling methodologies are usually not simply developed from conventional probability theory due to the unavailability of big datasets, this paper first investigates the mathematical foundations of these approaches. Then, the investigated data integration models are applied to a representative case in the predictive toxicology domain, with the experimental results compared and analysed.",L. Yang; D. Neagu,,,Integration strategies for toxicity data from an empirical perspective,,,10.1109/UKCI.2014.6930153 ,IEEE Conferences ,,"The recent development of information techniques, especially the state-of-the-art “big data” solutions, enables the extracting, gathering, and processing large amount of toxicity information from multiple sources. Facilitated by this technology advance, a framework named integrated testing strategies (ITS) has been proposed in the predictive toxicology domain, in an effort to intelligently jointly use multiple heterogeneous toxicity data records (through data fusion, grouping, interpolation/extrapolation etc.) for toxicity assessment. This will ultimately contribute to accelerating the development cycle of chemical products, reducing animal use, and decreasing development costs. Most of the current study in ITS is based on a group of consensus processes, termed weight of evidence (WoE), which quantitatively integrate all the relevant data instances towards the same endpoint into an integrated decision supported by data quality. Several WoE implementations for the particular case of toxicity data fusion have been presented in the literature, which are collectively studied in this paper. Noting that these uncertainty handling methodologies are usually not simply developed from conventional probability theory due to the unavailability of big datasets, this paper first investigates the mathematical foundations of these approaches. Then, the investigated data integration models are applied to a representative case in the predictive toxicology domain, with the experimental results compared and analysed.",2162-7657,,978-1-4799-5538-1,1-8,IEEE , ,Reliability;Mathematical model;Data integration;Bayes methods;Equations;Uncertainty,,
4957,"Title:The Drug-Like Molecule Pre-Training Strategy for Drug Discovery

 Recent advances in artificial intelligence (AI) have led to the development of transformer-based models that have shown success in identifying potential drug molecules for therapeutic purposes. However, for a molecule to be considered a viable drug candidate, it must exhibit certain desirable properties such as low toxicity, high druggability, and synthesizability. To address this, we propose an approach that incorporates prior knowledge about these properties during the model training process. In this study, we utilized the PubChem database, which contains 100 million molecules, to filter drug-like molecules based on the quantity of drug-likeliness (QED) score and the Pfizer rule. We then used this filtered dataset of drug-like molecules to train both molecular representation (ChemBERTa) and molecular generation models (MolGPT). To assess the performance of the molecular representation model, we fine-tuned the results on the MoleculeNet benchmark datasets. Meanwhile, we evaluated the performance of the molecular generation model based on the generated samples comprising 10,000 molecules. Despite the limited diversity of the pre-training dataset, the models for molecular representation were able to retain at least 90% of their original performance on benchmark datasets, with an additional improvement of 6% in predicting clinical toxicology. In the domain of molecular generation, the model pre-trained on drug-like molecules exhibited a high rate of desirable molecule properties in the unconditionally generated outputs. Additionally, the diversity of generated structures demonstrated notable performance compared to the conditional generation approach. Moreover, the drug-like molecule pre-training strategy is not limited to a specific model or training method, making it a flexible approach that can be easily modified based on the research interests and criteria of interest.",J. Lee; I. -S. Myeong; Y. Kim,,,The Drug-Like Molecule Pre-Training Strategy for Drug Discovery,11,,10.1109/ACCESS.2023.3285811 ,IEEE Journals ,,"Recent advances in artificial intelligence (AI) have led to the development of transformer-based models that have shown success in identifying potential drug molecules for therapeutic purposes. However, for a molecule to be considered a viable drug candidate, it must exhibit certain desirable properties such as low toxicity, high druggability, and synthesizability. To address this, we propose an approach that incorporates prior knowledge about these properties during the model training process. In this study, we utilized the PubChem database, which contains 100 million molecules, to filter drug-like molecules based on the quantity of drug-likeliness (QED) score and the Pfizer rule. We then used this filtered dataset of drug-like molecules to train both molecular representation (ChemBERTa) and molecular generation models (MolGPT). To assess the performance of the molecular representation model, we fine-tuned the results on the MoleculeNet benchmark datasets. Meanwhile, we evaluated the performance of the molecular generation model based on the generated samples comprising 10,000 molecules. Despite the limited diversity of the pre-training dataset, the models for molecular representation were able to retain at least 90% of their original performance on benchmark datasets, with an additional improvement of 6% in predicting clinical toxicology. In the domain of molecular generation, the model pre-trained on drug-like molecules exhibited a high rate of desirable molecule properties in the unconditionally generated outputs. Additionally, the diversity of generated structures demonstrated notable performance compared to the conditional generation approach. Moreover, the drug-like molecule pre-training strategy is not limited to a specific model or training method, making it a flexible approach that can be easily modified based on the research interests and criteria of interest.",2169-3536,,,61680-61687,IEEE , ,Artificial intelligence;Companies;Transformers;Benchmark testing;Drug delivery;Databases;Toxicology,,
4958,"Title:Mercury bioindicators across the Mediterranean basin: evidence from a dataset on Mytilus galloprovincialis

 Samples of Mytilus galloprovincialis across the Mediterranean Sea have been considered with a focus on the areas and periods where the mussels recorded high concentrations of mercury. In this regard, some critical areas have been found specifically around Portoscuso (Sardinia) and Livorno harbour (Tuscany), in the Tyrrhenian Sea, as well as Trieste Gulf (Friuli) and Kaštela Bay (Croatia), in the Adriatic one. For these identified hot-spot areas, findings about mercury trends in M. galloprovincialis, have been obtained through an analysis that might be useful to investigate the effectiveness of international regulatory actions for ultimately reducing the mercury exposure, in humans and wildlife.",D. E. Bruno; F. D’Amore; F. D. Simone; M. Bencardino; A. Lay-Ekuakille; S. Cinnirella; F. Sprovieri; N. Pirrone,,,Mercury bioindicators across the Mediterranean basin: evidence from a dataset on Mytilus galloprovincialis,,,10.1109/MetroSea52177.2021.9611602 ,IEEE Conferences ,,"Samples of Mytilus galloprovincialis across the Mediterranean Sea have been considered with a focus on the areas and periods where the mussels recorded high concentrations of mercury. In this regard, some critical areas have been found specifically around Portoscuso (Sardinia) and Livorno harbour (Tuscany), in the Tyrrhenian Sea, as well as Trieste Gulf (Friuli) and Kaštela Bay (Croatia), in the Adriatic one. For these identified hot-spot areas, findings about mercury trends in M. galloprovincialis, have been obtained through an analysis that might be useful to investigate the effectiveness of international regulatory actions for ultimately reducing the mercury exposure, in humans and wildlife.",,,978-1-6654-1458-6,209-214,IEEE , ,Geology;Wildlife;Ecosystems;Sea measurements;Metrology;Market research;Sediments,,
4959,"Title:Drug ADMET Prediction Method Based on Improved Graph Convolution Neural Network

 To improve the performance of the determination model for evaluating drug absorption, distribution, metabolism, exclusion, and toxicity (ADMET), a drug ADMET prediction model based on graph convolution network is proposed from the two chemical properties of drug solubility and toxicity. At the same time, a multilayer perceptron and an attention mechanism are introduced to improve the model by using special information such as features in molecular bonds and the difference in interaction strength between adjacent atoms. The error of the improved model is reduced by about 24% and 25% on average on two public data sets of drug solubility, and the accuracy of three public data sets of drug toxicity is increased by about 7.8% on average and 9.6 % at most. Experiments show that the good performance of this method can be used for early drug ADMET prediction, thus providing a reference for computer-aided drug design.",H. Xiao; X. Chen,,,Drug ADMET Prediction Method Based on Improved Graph Convolution Neural Network,,,10.1109/ICRCV55858.2022.9953254 ,IEEE Conferences ,,"To improve the performance of the determination model for evaluating drug absorption, distribution, metabolism, exclusion, and toxicity (ADMET), a drug ADMET prediction model based on graph convolution network is proposed from the two chemical properties of drug solubility and toxicity. At the same time, a multilayer perceptron and an attention mechanism are introduced to improve the model by using special information such as features in molecular bonds and the difference in interaction strength between adjacent atoms. The error of the improved model is reduced by about 24% and 25% on average on two public data sets of drug solubility, and the accuracy of three public data sets of drug toxicity is increased by about 7.8% on average and 9.6 % at most. Experiments show that the good performance of this method can be used for early drug ADMET prediction, thus providing a reference for computer-aided drug design.",,,978-1-6654-8170-0,266-271,IEEE , ,Drugs;Toxicology;Machine learning algorithms;Convolution;Computational modeling;Biological system modeling;Neural networks,,
4960,"Title:Explicate Toxicity By eXplainable Artificial Intelligence

 Chemical exposure can cause formative neurotoxicity, which requires fast and exact testing techniques. Current methods, notably in vivo research on animal models and assessments of primary cell cultures derived from animal and humans, have difficulties in terms of time, expense, and application to human physiology. For example, in vivo animal studies may take years to complete. In this study, eXplainable Artificial Intelligence (XAI) was combined with XGBoost machine learning (ML) models that were prepared to utilize binary classification as a potent mix of datasets to identify genes that may be associated with neurotoxicity. Significant genes were found and connected to the progression of neurotoxicity after SHAP values were effectively integrated into the ML models.",N. Tanwar; J. Meena; Y. Hasija,,,Explicate Toxicity By eXplainable Artificial Intelligence,,,10.1109/I4Tech55392.2022.9952865 ,IEEE Conferences ,,"Chemical exposure can cause formative neurotoxicity, which requires fast and exact testing techniques. Current methods, notably in vivo research on animal models and assessments of primary cell cultures derived from animal and humans, have difficulties in terms of time, expense, and application to human physiology. For example, in vivo animal studies may take years to complete. In this study, eXplainable Artificial Intelligence (XAI) was combined with XGBoost machine learning (ML) models that were prepared to utilize binary classification as a potent mix of datasets to identify genes that may be associated with neurotoxicity. Significant genes were found and connected to the progression of neurotoxicity after SHAP values were effectively integrated into the ML models.",,,978-1-6654-7196-1,1-6,IEEE , ,In vivo;Toxicology;Animals;Machine learning;Physiology;Fourth Industrial Revolution;Chemicals,,
4961,"Title:Occurrence features and leaching migration of chloroform in shallow groundwater

 Through the testing, research and analysis of the 390 samples of shallow groundwater in Hutuo alluvial plain, this paper illustrates the pollution characteristics of high Chloroform detection rate and wide distribution, through analysis obtains the conclusion that the main pollution sources are industrial enterprises and sewage drainage rivers and channels, determines the distribution of pollution sources and makes clear that the direct cause affecting the halogenated hydrocarbon pollution in the region is the lithology of the unsaturated zone. In addition, the GUS value of Chloroform is calculated through EPI Suit, and the leaching migration is preliminarily discussed.",Y. -s. Li; Z. -j. Zhang; Y. -h. Fei; Z. Wang; Y. Qian; J. -s. Chen; F. -e. Zhang,,,Occurrence features and leaching migration of chloroform in shallow groundwater,1,,10.1109/ISWREP.2011.5892938 ,IEEE Conferences ,,"Through the testing, research and analysis of the 390 samples of shallow groundwater in Hutuo alluvial plain, this paper illustrates the pollution characteristics of high Chloroform detection rate and wide distribution, through analysis obtains the conclusion that the main pollution sources are industrial enterprises and sewage drainage rivers and channels, determines the distribution of pollution sources and makes clear that the direct cause affecting the halogenated hydrocarbon pollution in the region is the lithology of the unsaturated zone. In addition, the GUS value of Chloroform is calculated through EPI Suit, and the leaching migration is preliminarily discussed.",,,978-1-61284-340-7,31-34,IEEE , ,Water pollution;Hydrocarbons;Rivers;Soil;Environmentally friendly manufacturing techniques;Leaching,,
4962,"Title:26.4 A Cell-Capacitance-Insensitive CMOS Sample-and-Hold Chronoamperometric Sensor for Real-Time Measurement of Small Molecule Drugs in Whole Blood

 The capability of adjusting a drug-dosing profile in real time based on personalized pharmacokinetics plays a crucial role in achieving optimal therapeutic outcomes at minimal toxicity [1]. Achieving this requires biosensors that can continuously measure drug concentrations at sub-minute temporal resolution. Today, the gold standard methods such as immunoassays and liquid chromatography are not able to achieve this because they require long assay times (typically hours). Recently, structure-switching aptamers have drawn great attention for in vivo realtime monitoring [2]-[4]. As shown in Fig. 26.4.1, aptamers are single-stranded DNA molecules whose sequences are selected to bind target molecules with high affinity [2]. To achieve electrochemical detection, redox reporters (such as methylene blue, MB) are conjugated to these aptamers such that conformation changes in the aptamer caused by target binding leads to a direct electrical readout in proportional to the target concentration. Such a reagent-free capability has been demonstrated using microfluidics and implanted probes measuring chemotherapeutics and aminoglycoside antibiotics [2]-[4]. To generalize the technology for ambulatory patients, [5] presents a system integrating an aptamer-interfacing electrochemical circuit with wireless powering and telemetry.",J. -C. Chien; H. T. Soh; A. Arbabian,,,26.4 A Cell-Capacitance-Insensitive CMOS Sample-and-Hold Chronoamperometric Sensor for Real-Time Measurement of Small Molecule Drugs in Whole Blood,,,10.1109/ISSCC19947.2020.9063036 ,IEEE Conferences ,,"The capability of adjusting a drug-dosing profile in real time based on personalized pharmacokinetics plays a crucial role in achieving optimal therapeutic outcomes at minimal toxicity [1]. Achieving this requires biosensors that can continuously measure drug concentrations at sub-minute temporal resolution. Today, the gold standard methods such as immunoassays and liquid chromatography are not able to achieve this because they require long assay times (typically hours). Recently, structure-switching aptamers have drawn great attention for in vivo realtime monitoring [2]-[4]. As shown in Fig. 26.4.1, aptamers are single-stranded DNA molecules whose sequences are selected to bind target molecules with high affinity [2]. To achieve electrochemical detection, redox reporters (such as methylene blue, MB) are conjugated to these aptamers such that conformation changes in the aptamer caused by target binding leads to a direct electrical readout in proportional to the target concentration. Such a reagent-free capability has been demonstrated using microfluidics and implanted probes measuring chemotherapeutics and aminoglycoside antibiotics [2]-[4]. To generalize the technology for ambulatory patients, [5] presents a system integrating an aptamer-interfacing electrochemical circuit with wireless powering and telemetry.",2376-8606,,978-1-7281-3205-1,406-408,IEEE , ,Current measurement;Biomedical measurement;Monitoring;Real-time systems;Drugs;Electric potential;Sensors,,
4963,"Title:Microplastics and Mercury Detection on Anchovy from Alor and Balikpapan Harbors, Indonesia

 Microplastics contamination has become a severe environmental problem. Several studies reported that microplastics carried another contamination and increasing the toxicity effect. Research on microplastics meets on human health risk regarding possibilities of microplastics exposure, which causes the issue more concern to be studied. On this research, we investigated the total of microplastics contaminant from a seafood product, the anchovies (Stolephorus spp.) from Alor and Balikpapan harbors. The digestive tract of anchovies are isolated and measured as length (cm±SD) and dry weight (g±SD). The anchovies digestive tracts (±1 g) were added with 30 mL (1 M) NaOH together with 15 mL 0.5% dissolved Sodium Lauryl Sulphate (technical grade) and kept at room temperature within a week. Microplastics is observed with microscope Leica and confirmed by Fourier-Transform Infrared (FTIR) analysis. The results reveal that the anchovies from Alor carried out 302±1.0 particles microplastic/individual, followed by 130±1.73 particles microplastic/individual from Balikpapan' anchovies. The most shape and size found on a sample from Alor were 95% microfiber with 50-500 μm, while from Balikpapan sample were 43.83% microfilm with 20-50 μm, The mercury contamination is also tested. The results showed that mercury are not detected from the Alor sample and a little bit from Balikpapan sample (39.49 ug/L or 0.04 mg/Kg). Although mercury is present from Balikpapan sample, the amount is under the maximum level (0.06 mg/Kg) based on BPOM RI standard. To better understand the microplastics and mercury contamination on the anchovies product originate from Indonesia Sea, the future study which provides more sampling location is needed.",E. W. Ningrum; M. P. Patria,,,"Microplastics and Mercury Detection on Anchovy from Alor and Balikpapan Harbors, Indonesia",,,10.1109/R10-HTC47129.2019.9042436 ,IEEE Conferences ,,"Microplastics contamination has become a severe environmental problem. Several studies reported that microplastics carried another contamination and increasing the toxicity effect. Research on microplastics meets on human health risk regarding possibilities of microplastics exposure, which causes the issue more concern to be studied. On this research, we investigated the total of microplastics contaminant from a seafood product, the anchovies (Stolephorus spp.) from Alor and Balikpapan harbors. The digestive tract of anchovies are isolated and measured as length (cm±SD) and dry weight (g±SD). The anchovies digestive tracts (±1 g) were added with 30 mL (1 M) NaOH together with 15 mL 0.5% dissolved Sodium Lauryl Sulphate (technical grade) and kept at room temperature within a week. Microplastics is observed with microscope Leica and confirmed by Fourier-Transform Infrared (FTIR) analysis. The results reveal that the anchovies from Alor carried out 302±1.0 particles microplastic/individual, followed by 130±1.73 particles microplastic/individual from Balikpapan' anchovies. The most shape and size found on a sample from Alor were 95% microfiber with 50-500 μm, while from Balikpapan sample were 43.83% microfilm with 20-50 μm, The mercury contamination is also tested. The results showed that mercury are not detected from the Alor sample and a little bit from Balikpapan sample (39.49 ug/L or 0.04 mg/Kg). Although mercury is present from Balikpapan sample, the amount is under the maximum level (0.06 mg/Kg) based on BPOM RI standard. To better understand the microplastics and mercury contamination on the anchovies product originate from Indonesia Sea, the future study which provides more sampling location is needed.",2572-7621,,978-1-7281-0834-6,254-257,IEEE , ,Contamination;Shape;Pollution measurement;Standards;Chemicals;Water pollution,,
4964,"Title:A Molecular Communication Detection Method for the Deformability of Erythrocyte Membrane in Blood Vessels

 Molecular communication (MC) inspired drug delivery holds considerable promise as a new design for targeted therapy with high efficiency and minimal toxicity. The process of drug delivery can be modelled in a blood flow-based MC system, where nanoparticles (NPs) carry therapeutic agents through the blood vessel channels to the targeted diseased tissue. Most previous studies in the flow-based MC consider a Newtonian fluid with a laminar flow, which ignores the influence of red blood cells (RBCs). However, the nature of blood flow is a complex and non-Newtonian fluid composed of proteins, platelets, plasma and deformable cells, especially RBCs. The ability to change their shapes is essential to the proper functioning of RBCs in the microvasculature. Different shapes of RBCs have a great impact on the performance of blood flow. Changes in the properties and shapes of RBCs are often associated with different diseases, such as sickle cell anemia, diabetes, and malaria. Thus, it is highly important to establish a more realistic blood flow MC model considering the deformable cells. According to our previous study, the motion and adhesion of individual NPs are modelled through the Brownian adhesion dynamics. Subsequently, this paper establishes a particle-cell hybrid model in the flow-based MC, which focuses on the RBC deformation, aggregation, and dispersion in the blood suspension. Based on the state of the RBC deformation and aggregation in the vessels with different flow rates, this paper proposes a novel methodology for detecting the deformability of the cells. The blood state in terms of RBC deformability is determined by the difference in NPs’ concentration at the receiving end., this paper sheds some light on the influence of RBCs on the motion of NPs, which provides new insights on the design of targeted drug delivery and the detection of vascular diseases.",Y. Sun; R. Zhang; Y. Chen,,,A Molecular Communication Detection Method for the Deformability of Erythrocyte Membrane in Blood Vessels,20,4,10.1109/TNB.2021.3064194 ,IEEE Journals ,,"Molecular communication (MC) inspired drug delivery holds considerable promise as a new design for targeted therapy with high efficiency and minimal toxicity. The process of drug delivery can be modelled in a blood flow-based MC system, where nanoparticles (NPs) carry therapeutic agents through the blood vessel channels to the targeted diseased tissue. Most previous studies in the flow-based MC consider a Newtonian fluid with a laminar flow, which ignores the influence of red blood cells (RBCs). However, the nature of blood flow is a complex and non-Newtonian fluid composed of proteins, platelets, plasma and deformable cells, especially RBCs. The ability to change their shapes is essential to the proper functioning of RBCs in the microvasculature. Different shapes of RBCs have a great impact on the performance of blood flow. Changes in the properties and shapes of RBCs are often associated with different diseases, such as sickle cell anemia, diabetes, and malaria. Thus, it is highly important to establish a more realistic blood flow MC model considering the deformable cells. According to our previous study, the motion and adhesion of individual NPs are modelled through the Brownian adhesion dynamics. Subsequently, this paper establishes a particle-cell hybrid model in the flow-based MC, which focuses on the RBC deformation, aggregation, and dispersion in the blood suspension. Based on the state of the RBC deformation and aggregation in the vessels with different flow rates, this paper proposes a novel methodology for detecting the deformability of the cells. The blood state in terms of RBC deformability is determined by the difference in NPs’ concentration at the receiving end., this paper sheds some light on the influence of RBCs on the motion of NPs, which provides new insights on the design of targeted drug delivery and the detection of vascular diseases.",1558-2639,,,387-395,IEEE , ,Red blood cells;Molecular communication (telecommunication);Cells (biology);Blood vessels;Viscosity;Nanoparticles,,
4965,"Title:In-Situ Detection Method of Jellyfish Based on Improved Faster R-CNN and FP16

 In recent years, large numbers of jellyfish have congregated in marine areas, leading to a decline in other plankton and fisheries. Jellyfish themselves have a certain toxicity and aggression, which have a serious impact on the safety of human life. In order to detect the quantity and distribution of underwater jellyfish, and to be more proactive in the prevention and control of Aurelia outbreaks, this study proposed a method for in-situ detection of underwater jellyfish based on the improved Faster R-CNN network model. Firstly, the real data sets of three species of jellyfish in the Qinhuangdao sea area were established by using underwater high-definition camera. The Multi Scale Retinex with Colour Restoration (MSRCR) algorithm was used to improve the brightness and contrast of the underwater images. Secondly, the residual network Resnet50 was integrated into the backbone network for better feature extraction; then the semi-precision floating-point number FP16 was added to improve the training speed. Finally, comparative experiments were conducted to verify the improved network. The F1 value, the P-R curve, the Loss curve and the AP value of the three detection models were evaluated and compared. The experimental results showed that compared to Vgg16 network and YOLO V3 network, the training speed was improved from 1.85bit/s to 7.35bit/s, and the accuracy was also improved to over 0.98. The experimental results were good, and the research results provided a more accurate and faster method for the in-situ detection of underwater jellyfish.",B. Weihong; J. Yun; L. Jiaxin; S. Lingling; F. Guangwei; J. Wa,,,In-Situ Detection Method of Jellyfish Based on Improved Faster R-CNN and FP16,11,,10.1109/ACCESS.2023.3300655 ,IEEE Journals ,,"In recent years, large numbers of jellyfish have congregated in marine areas, leading to a decline in other plankton and fisheries. Jellyfish themselves have a certain toxicity and aggression, which have a serious impact on the safety of human life. In order to detect the quantity and distribution of underwater jellyfish, and to be more proactive in the prevention and control of Aurelia outbreaks, this study proposed a method for in-situ detection of underwater jellyfish based on the improved Faster R-CNN network model. Firstly, the real data sets of three species of jellyfish in the Qinhuangdao sea area were established by using underwater high-definition camera. The Multi Scale Retinex with Colour Restoration (MSRCR) algorithm was used to improve the brightness and contrast of the underwater images. Secondly, the residual network Resnet50 was integrated into the backbone network for better feature extraction; then the semi-precision floating-point number FP16 was added to improve the training speed. Finally, comparative experiments were conducted to verify the improved network. The F1 value, the P-R curve, the Loss curve and the AP value of the three detection models were evaluated and compared. The experimental results showed that compared to Vgg16 network and YOLO V3 network, the training speed was improved from 1.85bit/s to 7.35bit/s, and the accuracy was also improved to over 0.98. The experimental results were good, and the research results provided a more accurate and faster method for the in-situ detection of underwater jellyfish.",2169-3536,,,81803-81814,IEEE , ,Training;Residual neural networks;Monitoring;Feature extraction;Software;Sea surface;Sea measurements;Convolutional neural networks;Jellyfish;Aquaculture;Toxicology,,
4966,"Title:Deep Learning for Multi-Labeled Cyberbully Detection: Enhancing Online Safety

 Social media platforms offer undeniable benefits, but the preservation of anonymity has led to the emergence of cyberbullying, a concerning social problem. This form of online harassment creates a negative and hostile environment, resulting in decreased user engagement and psychological harm to victims. According to ResearchGate and ScienceDaily, cyberbullying victims in the United States are 1.9 times more likely to commit suicide, highlighting the severity of the issue. However, the current research on cyberbullying detection has been limited to binary/multi-class text classification due to the lack of comprehensive datasets for training and evaluation. To address this gap, we developed a DL-based multi-labeled cyberbully detection system using a dataset of 95,608 social media comments. These comments were categorized into five distinct multi-labeled classes, allowing for a more comprehensive understanding of the different dimensions of cyberbullying. We utilized DL architectures, such as LSTM, BiLSTM, CLSTM, and BiGRU, to develop advanced cyberbully detection systems. By comparing the performance of these DL models with the ML models, we were able to assess the effectiveness and superiority of DL approaches in accurately identifying instances of cyberbullying contents. The CLSTM model, outperformed the others with an exceptional binary accuracy of 87.8% and a macro f1-score of 88.3%. CLSTM's ability to integrate both local and sequential information, coupled with its capacity to capture complex patterns and long-term dependencies, contributes to its superior performance in identifying and classifying cyberbullying instances. By successfully identifying and preventing cyberbullying, our study can contribute to creating a safer and more positive online environment, ultimately enhancing user engagement and satisfaction.",N. Islam; R. Haque; P. K. Pareek; M. B. Islam; I. H. Sajeeb; M. H. Ratul,,,Deep Learning for Multi-Labeled Cyberbully Detection: Enhancing Online Safety,,,10.1109/ICDSNS58469.2023.10245135 ,IEEE Conferences ,,"Social media platforms offer undeniable benefits, but the preservation of anonymity has led to the emergence of cyberbullying, a concerning social problem. This form of online harassment creates a negative and hostile environment, resulting in decreased user engagement and psychological harm to victims. According to ResearchGate and ScienceDaily, cyberbullying victims in the United States are 1.9 times more likely to commit suicide, highlighting the severity of the issue. However, the current research on cyberbullying detection has been limited to binary/multi-class text classification due to the lack of comprehensive datasets for training and evaluation. To address this gap, we developed a DL-based multi-labeled cyberbully detection system using a dataset of 95,608 social media comments. These comments were categorized into five distinct multi-labeled classes, allowing for a more comprehensive understanding of the different dimensions of cyberbullying. We utilized DL architectures, such as LSTM, BiLSTM, CLSTM, and BiGRU, to develop advanced cyberbully detection systems. By comparing the performance of these DL models with the ML models, we were able to assess the effectiveness and superiority of DL approaches in accurately identifying instances of cyberbullying contents. The CLSTM model, outperformed the others with an exceptional binary accuracy of 87.8% and a macro f1-score of 88.3%. CLSTM's ability to integrate both local and sequential information, coupled with its capacity to capture complex patterns and long-term dependencies, contributes to its superior performance in identifying and classifying cyberbullying instances. By successfully identifying and preventing cyberbullying, our study can contribute to creating a safer and more positive online environment, ultimately enhancing user engagement and satisfaction.",,,979-8-3503-0159-5,1-6,IEEE , ,Training;Adaptation models;Text categorization;Transfer learning;Cyberbullying;Predictive models;Network security,,
4967,"Title:Incorporating a Novel Hexaazatriphenylene Derivative to a Flexible Screen-Printed Electrochemical Sensor for Copper Ion Detection in Water Samples

 A novel hexaazatriphenylene derivative, 6,7,16, 17,26,27-hexahydronaphtho[2,3-h]naphtho[2',3':7,8] quinoxalino[2,3-a]naphtho[2',3':7,8] quinoxalino[2,3-c]phenazine-5, 10,15,20,25,30-hexaone (HNQP), was successfully synthesized to selectively detect copper (Cu2+) ions over other metal ions in aqueous solutions. A flexible and planar electrochemical sensor with silver, carbon and silver/silver chloride as counter, working and reference electrodes, respectively was fabricated on a polyimide substrate using an additive screen printing process. The HNQP was drop casted on the electrochemical sensor and its capability to selectively detect Cu2+ ions was investigated by performing differential pulse voltammetry (DPV). A wide peak domain with average currents increasing from 0.16 μA to 17.97 μA was observed as the concentration of Cu2+ ions was increased from 0 μM to 100 μM, respectively, at reduction potential ~0.05V. A sensitivity of 135 μA/mM and a correlation coefficient of 0.99 was calculated for the HNQP drop casted electrochemical sensor. Further tests revealed selective detection of Cu2+ ions over other interfering metal ions including Co2+, Zn2+, Ni2+, Fe2+, Li1+, Pb2+, Hg2+ and Ag1+ using the HNQP drop casted electrochemical sensor. In addition, a limit of detection (LOD) and limit of quantification (LOQ) of 142 nM and 430 nM, respectively, was calculated for the sensor which is lower than the specified toxicity levels of Cu2+ ions in drinking water (20 - 30 μM) set by the U.S. environmental protection agency (EPA) and world health organization (WHO).",D. Maddipatla; T. S. Saeed; B. B. Narakathu; S. O. Obare; M. Z. Atashbar,,,Incorporating a Novel Hexaazatriphenylene Derivative to a Flexible Screen-Printed Electrochemical Sensor for Copper Ion Detection in Water Samples,20,21,10.1109/JSEN.2020.3002811 ,IEEE Journals ,,"A novel hexaazatriphenylene derivative, 6,7,16, 17,26,27-hexahydronaphtho[2,3-h]naphtho[2',3':7,8] quinoxalino[2,3-a]naphtho[2',3':7,8] quinoxalino[2,3-c]phenazine-5, 10,15,20,25,30-hexaone (HNQP), was successfully synthesized to selectively detect copper (Cu2+) ions over other metal ions in aqueous solutions. A flexible and planar electrochemical sensor with silver, carbon and silver/silver chloride as counter, working and reference electrodes, respectively was fabricated on a polyimide substrate using an additive screen printing process. The HNQP was drop casted on the electrochemical sensor and its capability to selectively detect Cu2+ ions was investigated by performing differential pulse voltammetry (DPV). A wide peak domain with average currents increasing from 0.16 μA to 17.97 μA was observed as the concentration of Cu2+ ions was increased from 0 μM to 100 μM, respectively, at reduction potential ~0.05V. A sensitivity of 135 μA/mM and a correlation coefficient of 0.99 was calculated for the HNQP drop casted electrochemical sensor. Further tests revealed selective detection of Cu2+ ions over other interfering metal ions including Co2+, Zn2+, Ni2+, Fe2+, Li1+, Pb2+, Hg2+ and Ag1+ using the HNQP drop casted electrochemical sensor. In addition, a limit of detection (LOD) and limit of quantification (LOQ) of 142 nM and 430 nM, respectively, was calculated for the sensor which is lower than the specified toxicity levels of Cu2+ ions in drinking water (20 - 30 μM) set by the U.S. environmental protection agency (EPA) and world health organization (WHO).",1558-1748,,,12582-12591,IEEE , ,Sensors;Ions;Electrodes;Substrates;Chemicals;Copper,,
4968,"Title:Detecting Toxic Comments Using Convolutional Neural Network Approach

 In the most significant issue now plaguing social networking platforms and online communities is toxicity identification. Therefore, it is necessary to create an automatic hazardous identification system to block and restrict individual from certain online environments. We introduce multichannel Convolutional Neural Network (CNN) approach in this paper for the detection of toxic comments in a multi-label context. With the help of pre-trained word embeddings, the suggested model produces word vectors. Also, to model input words with long-term dependency, this hybrid model extracts local characteristics using a variety of filters and kernel sizes. Then, to forecast multi-label categories, we integrate numerous channels with three layers as fully linked, normalization, and an output layer. The results of the experiments show that the suggested model performs where we are presenting the fresh modeling CNN approach to detect the toxicity of textual content present on the social media platforms and we categorized the toxicity into positive and negative impact on our society.",V. Mishra; M. Tripathi,,,Detecting Toxic Comments Using Convolutional Neural Network Approach,,,10.1109/CICN56167.2022.10008301 ,IEEE Conferences ,,"In the most significant issue now plaguing social networking platforms and online communities is toxicity identification. Therefore, it is necessary to create an automatic hazardous identification system to block and restrict individual from certain online environments. We introduce multichannel Convolutional Neural Network (CNN) approach in this paper for the detection of toxic comments in a multi-label context. With the help of pre-trained word embeddings, the suggested model produces word vectors. Also, to model input words with long-term dependency, this hybrid model extracts local characteristics using a variety of filters and kernel sizes. Then, to forecast multi-label categories, we integrate numerous channels with three layers as fully linked, normalization, and an output layer. The results of the experiments show that the suggested model performs where we are presenting the fresh modeling CNN approach to detect the toxicity of textual content present on the social media platforms and we categorized the toxicity into positive and negative impact on our society.",2472-7555,,978-1-6654-8771-9,252-255,IEEE , ,Toxicology;Social networking (online);Computational modeling;Convolutional neural networks;Communication networks;Kernel;Computational intelligence,,
4969,"Title:Optical Detection of Lead and Potassium Ions Using a Quantum-Dot-Based Aptamer Nanosensor

 Quantum-dot (QD) based nanosensors can be used to detect a wide range of molecules. This study examined a nanosensor comprised of thrombin binding aptamer (TBA) with 700NC InGaP QD on the 5 ' terminus and an Au nanoparticle quencher on the 3 ' terminus. Both K+ and Pb2+ bind to TBA, resulting in a conformational change that brings the Au quencher closer to the QD. Photoluminescence measurements indicated a decrease in fluorescence corresponding to an increase in either K+ or Pb2+ concentration. For healthy blood serum K+ concentrations (3.5-5 mM), the beacon exhibited 15-17% quenching efficiency. Pb2+ concentration of 0.48 μM, the threshold for toxicity in serum, yielded 14% quenching. The beacon's ability to detect changes in ion levels in a critical range of concentrations can make it an effective diagnostic tool.",X. Meshik; K. Xu; M. Dutta; M. A. Stroscio,,,Optical Detection of Lead and Potassium Ions Using a Quantum-Dot-Based Aptamer Nanosensor,13,2,10.1109/TNB.2014.2317315 ,IEEE Journals ,,"Quantum-dot (QD) based nanosensors can be used to detect a wide range of molecules. This study examined a nanosensor comprised of thrombin binding aptamer (TBA) with 700NC InGaP QD on the 5 ' terminus and an Au nanoparticle quencher on the 3 ' terminus. Both K+ and Pb2+ bind to TBA, resulting in a conformational change that brings the Au quencher closer to the QD. Photoluminescence measurements indicated a decrease in fluorescence corresponding to an increase in either K+ or Pb2+ concentration. For healthy blood serum K+ concentrations (3.5-5 mM), the beacon exhibited 15-17% quenching efficiency. Pb2+ concentration of 0.48 μM, the threshold for toxicity in serum, yielded 14% quenching. The beacon's ability to detect changes in ion levels in a critical range of concentrations can make it an effective diagnostic tool.",1558-2639,,,161-164,IEEE , ,Gold;Nanobioscience;Ions;Nanoparticles;Optical sensors;Fluorescence,,
4970,"Title:Proximity based Intelligent Air Pollution Alerts for Garbage Disposal Sites

 Air pollution is one of the key trending challenges faced by the public at present. The garbage disposal sites are the major contributors which emit harmful gases (CO, CO2, CH4) where toxicity is at a higher level. This research attempts to fill the lacuna by providing an intelligent proximity-based air pollution detection system that alerts and makes the public aware of the danger and risk of the garbage dumps that are located near them via a mobile application. The device is developed to detect harmful gas with MG811, MQ7, MQ4 sensors with 0.80 accuracy. The device also contains a DHT22 temperature humidity sensor with 0.80 accuracy and SD011 particulate matter sensor which has a 0.95 accuracy. The application can notify the responsible authorities regarding the possible risks of the garbage dump and the health effects that can cause. The air toxicity is calculated with an accuracy of 0.75 and visualized, using the landfill classification and pollution level prediction algorithms with an accuracy of 0.96 in a geo proximity map with 0.92 percent accuracy.",W. G. D. U. Wijerathne; M. L. M. P. Perera; R. H. C. Nuwandika; R. A. K. A. Ranasinghe; K. A. D. C. P. Kahandawaarachchi; N. D. U. Gamage,,,Proximity based Intelligent Air Pollution Alerts for Garbage Disposal Sites,1,,10.1109/ICAC51239.2020.9357286 ,IEEE Conferences ,,"Air pollution is one of the key trending challenges faced by the public at present. The garbage disposal sites are the major contributors which emit harmful gases (CO, CO2, CH4) where toxicity is at a higher level. This research attempts to fill the lacuna by providing an intelligent proximity-based air pollution detection system that alerts and makes the public aware of the danger and risk of the garbage dumps that are located near them via a mobile application. The device is developed to detect harmful gas with MG811, MQ7, MQ4 sensors with 0.80 accuracy. The device also contains a DHT22 temperature humidity sensor with 0.80 accuracy and SD011 particulate matter sensor which has a 0.95 accuracy. The application can notify the responsible authorities regarding the possible risks of the garbage dump and the health effects that can cause. The air toxicity is calculated with an accuracy of 0.75 and visualized, using the landfill classification and pollution level prediction algorithms with an accuracy of 0.96 in a geo proximity map with 0.92 percent accuracy.",,,978-1-7281-8412-8,500-505,IEEE , ,Gases;Toxicology;Prototypes;Air pollution;Hardware;Sensors;Mobile applications,,
4971,"Title:Photoinitiator Release of Photoprinted SLA Resins for Lab-on-a-chip Applications

 3D printing with SLA resins is a very useful manufacturing process to build microfluidic devices (lab-on-a-chip). These photoresin-based methods are especially interesting, as they allow to obtain quickly and accurately high precise designs. However, commercial photoresins have some limitations for cell culture due to its composition. In this sense, photoinitiators used for curing these resins are commonly cytotoxic. Although curing and cleaning protocols are used to remove these components from printed pieces, they could still remain in enough quantity to compromise cell culture on lab-on-a-chips. For this reason, a continuous phase in a solid-liquid extraction has been studied using two media (IPA and PBS) to determine the photoinitiator release of two different resins (Clear and BioMedClear) along 16 days. So, detection, identification and quantification of the released compounds were done by UV-Vis spectroscopy each two days during this period. Results show spectra of TPO and PPO photoinitiators. Additionally, curing and cleaning protocols do not fully remove these toxic compounds, but IPA provides better solvent properties to release these photoinitiator molecules than PBS. In conclusion, lab-on-a-chip applications of SLA resins require specific post-processing to minimize toxicity due to release of photoinitiators.",D. P. Caballero; J. B. P. Carrasco; V. P. G. Chacón; J. Loureiro; M. P. Ribeiro; S. Miguel; P. Coutinho; F. M. S. Margallo,,,Photoinitiator Release of Photoprinted SLA Resins for Lab-on-a-chip Applications,,,10.1109/EHB55594.2022.9991420 ,IEEE Conferences ,,"3D printing with SLA resins is a very useful manufacturing process to build microfluidic devices (lab-on-a-chip). These photoresin-based methods are especially interesting, as they allow to obtain quickly and accurately high precise designs. However, commercial photoresins have some limitations for cell culture due to its composition. In this sense, photoinitiators used for curing these resins are commonly cytotoxic. Although curing and cleaning protocols are used to remove these components from printed pieces, they could still remain in enough quantity to compromise cell culture on lab-on-a-chips. For this reason, a continuous phase in a solid-liquid extraction has been studied using two media (IPA and PBS) to determine the photoinitiator release of two different resins (Clear and BioMedClear) along 16 days. So, detection, identification and quantification of the released compounds were done by UV-Vis spectroscopy each two days during this period. Results show spectra of TPO and PPO photoinitiators. Additionally, curing and cleaning protocols do not fully remove these toxic compounds, but IPA provides better solvent properties to release these photoinitiator molecules than PBS. In conclusion, lab-on-a-chip applications of SLA resins require specific post-processing to minimize toxicity due to release of photoinitiators.",2575-5145,,978-1-6654-8557-9,1-4,IEEE , ,Solvents;Spectroscopy;Protocols;Toxicology;Curing;Lab-on-a-chip;Three-dimensional printing,,
4972,"Title:Heavy Metal Analysis in Urtica Dioica Aerial Parts Using Automatic Atomic Absorption Spectrophotometer Controlled via Computer Data System

 The present paper investigates the levels of heavy metal contamination i.e. lead, cadmium, mercury and arsenic in Urtica dioica aerial parts using automatic atomic absorption spectrophotometer (AAS) by computer plotting. The computer data system allows higher precision, higher sensitivity, and lower detection limits. The determination of heavy metals even in traces is of utmost importance as these metals are involved in biological cycles and their accumulation causes high toxicity. The paper compares the data of toxic metals with respect to permissible/acceptable limits of different countries. The level of heavy metals for Urtica dioica was found to be within the permissible limits for safe human use.",C. Singla; S. Drabu; M. Ali,,,Heavy Metal Analysis in Urtica Dioica Aerial Parts Using Automatic Atomic Absorption Spectrophotometer Controlled via Computer Data System,,,10.1109/ACCT.2012.61 ,IEEE Conferences ,,"The present paper investigates the levels of heavy metal contamination i.e. lead, cadmium, mercury and arsenic in Urtica dioica aerial parts using automatic atomic absorption spectrophotometer (AAS) by computer plotting. The computer data system allows higher precision, higher sensitivity, and lower detection limits. The determination of heavy metals even in traces is of utmost importance as these metals are involved in biological cycles and their accumulation causes high toxicity. The paper compares the data of toxic metals with respect to permissible/acceptable limits of different countries. The level of heavy metals for Urtica dioica was found to be within the permissible limits for safe human use.",2327-0659,,978-1-4673-0471-9,337-338,IEEE , ,Lead;Computers;Cadmium;Absorption;Instruments;Data systems,,
4973,"Title:An automated and high-throughput Photomotor Response platform for chemical screens

 The zebrafish (Danio rerio) is a well-established vertebrate model organism. Its embryos are used extensively in biology and medicine to perform chemical screens to identify drug candidates or to evaluate teratogenicity and embryotoxicity of substances. Behavioral readouts are increasingly used to assess the effects of compounds on the nervous system. Early stage zebrafish show characteristic behavioral features at stages between 30 and 42 hours post fertilization (hpf) when exposed to a short and bright light flash. This so-called Photomotor Response (PMR) is a reaction of the nervous system of the fish and can be used as a marker in screenings for neuroactive chemicals. To probe a broad and diverse chemical space, many different substances have to be tested and repeated observations are necessary to warrant statistical significance of the results. Although PMR-based chemical screens must use a large number of specimens, there is no sophisticated, automated high-throughput platform available which ensures minimal human intervention. Here we report a PMR platform that was developed by combining an improved automatic sample handling with a remotely controllable microscope setup and an image analysis pipeline. Using infrared illumination during automatic sample preparation, we were able to eliminate excess amounts of visible light that could potentially alter the response results. A remotely controlled microscope setup allows us to screen entire 96-well microtiter plates without human presence that could disturb the embryos. The development of custom video analysis software, including single egg detection, enables us to detect variance among treated specimens and extract easy to interpret numerical values representing the PMR motion. By testing several neuroactive compounds we validated the workflow that can be used to analyze more than one thousand zebrafish eggs on a single 96-well plate.",D. Marcato; R. Alshut; H. Breitwieser; R. Mikut; U. Strähle; C. Pylatiuk; R. Peravali,,,An automated and high-throughput Photomotor Response platform for chemical screens,,,10.1109/EMBC.2015.7320183 ,IEEE Conferences ,,"The zebrafish (Danio rerio) is a well-established vertebrate model organism. Its embryos are used extensively in biology and medicine to perform chemical screens to identify drug candidates or to evaluate teratogenicity and embryotoxicity of substances. Behavioral readouts are increasingly used to assess the effects of compounds on the nervous system. Early stage zebrafish show characteristic behavioral features at stages between 30 and 42 hours post fertilization (hpf) when exposed to a short and bright light flash. This so-called Photomotor Response (PMR) is a reaction of the nervous system of the fish and can be used as a marker in screenings for neuroactive chemicals. To probe a broad and diverse chemical space, many different substances have to be tested and repeated observations are necessary to warrant statistical significance of the results. Although PMR-based chemical screens must use a large number of specimens, there is no sophisticated, automated high-throughput platform available which ensures minimal human intervention. Here we report a PMR platform that was developed by combining an improved automatic sample handling with a remotely controllable microscope setup and an image analysis pipeline. Using infrared illumination during automatic sample preparation, we were able to eliminate excess amounts of visible light that could potentially alter the response results. A remotely controlled microscope setup allows us to screen entire 96-well microtiter plates without human presence that could disturb the embryos. The development of custom video analysis software, including single egg detection, enables us to detect variance among treated specimens and extract easy to interpret numerical values representing the PMR motion. By testing several neuroactive compounds we validated the workflow that can be used to analyze more than one thousand zebrafish eggs on a single 96-well plate.",1558-4615,,978-1-4244-9271-8,7728-7731,IEEE , ,Embryo;Microscopy;Ash;Chemicals;Lighting;Indexes;Compounds,,
4974,"Title:Toward single molecule detection in physiological buffer using planar FET biosensors

 Among a variety of sensing mechanisms and device architectures, field effect transistors (FETs) based devices are ideal biosensors that can directly convert interactions of biomolecules to electrical signals for low cost, rapid, label free, and sensitive detection. Si-based MOSFETs (planar or nanowire) have the great advantage of compatibility to the current microelectronic manufacturing processes, but suffer from current drift due to ion diffusion into the gate oxide layer, making them difficult to detect target analytes at low concentrations in physiological buffers or fluids with high ionic strengths. III-nitride semiconductors have attracted considerable interests for biosensor applications due to their unique properties, such as chemical inertness, non-toxicity, and thermal stability. Especially, III-nitrides FETs are ion-impermeable and highly stable in electrolytic solutions, making them ideal for detection at ultralow concentration in fluids with high ionic strengths. Theoretical calculations suggest that nanowire and quantum dot FETs should have higher sensitivity than planar FETs due to the large surface to volume ratio. Single molecule detection has been demonstrated using single wall carbon nanotube devices1. Previously we demonstrated pM sensitivity of streptavidin (SA) protein detection in 0.25×PBS with an ionic strength of 40 mM using an AlGaN/GaN FET biosensor with a control gate electrode when the device was biased in the sub-threshold regime2. Here we show a recessed gate AlGaN/GaN heterojunction FET (HFET, Fig. 1) for detection of proteins at a concentration of 16 aM in PBS buffer (163 mM).",Y. Wang; P. Casal; S. C. Lee; W. Lu,,,Toward single molecule detection in physiological buffer using planar FET biosensors,,,10.1109/DRC.2013.6633832 ,IEEE Conferences ,,"Among a variety of sensing mechanisms and device architectures, field effect transistors (FETs) based devices are ideal biosensors that can directly convert interactions of biomolecules to electrical signals for low cost, rapid, label free, and sensitive detection. Si-based MOSFETs (planar or nanowire) have the great advantage of compatibility to the current microelectronic manufacturing processes, but suffer from current drift due to ion diffusion into the gate oxide layer, making them difficult to detect target analytes at low concentrations in physiological buffers or fluids with high ionic strengths. III-nitride semiconductors have attracted considerable interests for biosensor applications due to their unique properties, such as chemical inertness, non-toxicity, and thermal stability. Especially, III-nitrides FETs are ion-impermeable and highly stable in electrolytic solutions, making them ideal for detection at ultralow concentration in fluids with high ionic strengths. Theoretical calculations suggest that nanowire and quantum dot FETs should have higher sensitivity than planar FETs due to the large surface to volume ratio. Single molecule detection has been demonstrated using single wall carbon nanotube devices1. Previously we demonstrated pM sensitivity of streptavidin (SA) protein detection in 0.25×PBS with an ionic strength of 40 mM using an AlGaN/GaN FET biosensor with a control gate electrode when the device was biased in the sub-threshold regime2. Here we show a recessed gate AlGaN/GaN heterojunction FET (HFET, Fig. 1) for detection of proteins at a concentration of 16 aM in PBS buffer (163 mM).",1548-3770,,978-1-4799-0814-1,139-140,IEEE , ,Logic gates;Field effect transistors;Biosensors;Gallium nitride;Signal to noise ratio;Aluminum gallium nitride,,
4975,"Title:Machine Learning Expert System for Recognizing Emotions in text “Umai Cloud Services”

 In this research, the focus is on recognizing 28 emotions in a text using the Roberta model, which is a state-of-the-art pre-trained language model that has achieved outstanding results in various natural language processing tasks. The study explores the effectiveness of the Roberta model for emotion recognition and compares it with other approaches, such as CNNs and RNNs. In addition, the research investigates the problem of toxicity detection, which involves identifying and flagging potentially harmful or offensive language in a given text. Various techniques for toxicity detection are considered, including supervised learning and deep learning methods. The study also explores the process of extracting key phrases and words from a text using machine learning algorithms. This involves applying NLP techniques such as part-of-speech tagging, named entity recognition, and text summarization. All of these methods are implemented and tested using a cloud service provided by Umai Cloud Services, a Kazakh startup company that offers machine learning and artificial intelligence solutions. The results of the study demonstrate the effectiveness of the Roberta model for emotion recognition and show promising results for toxicity detection and text summarization.",A. Tleubayeva; A. Shaikhanova; B. Ospan; A. Sultan; M. Abu; N. Darmenkyzy,,,Machine Learning Expert System for Recognizing Emotions in text “Umai Cloud Services”,,,10.1109/SIST58284.2023.10223554 ,IEEE Conferences ,,"In this research, the focus is on recognizing 28 emotions in a text using the Roberta model, which is a state-of-the-art pre-trained language model that has achieved outstanding results in various natural language processing tasks. The study explores the effectiveness of the Roberta model for emotion recognition and compares it with other approaches, such as CNNs and RNNs. In addition, the research investigates the problem of toxicity detection, which involves identifying and flagging potentially harmful or offensive language in a given text. Various techniques for toxicity detection are considered, including supervised learning and deep learning methods. The study also explores the process of extracting key phrases and words from a text using machine learning algorithms. This involves applying NLP techniques such as part-of-speech tagging, named entity recognition, and text summarization. All of these methods are implemented and tested using a cloud service provided by Umai Cloud Services, a Kazakh startup company that offers machine learning and artificial intelligence solutions. The results of the study demonstrate the effectiveness of the Roberta model for emotion recognition and show promising results for toxicity detection and text summarization.",,,979-8-3503-3504-0,293-298,IEEE , ,Emotion recognition;Toxicology;Machine learning algorithms;Text recognition;Supervised learning;Tagging;Linguistics,,
4976,"Title:An electrochemical immunosensor for ochratoxin a detection based on coplanar capacitive array

 Due to the high toxicity and wide distribution of ochratoxin A (OTA), it's essential to implement the fast and sensitive detection. In this paper, a rapid and sensitive electrochemical immunosensor based on coplanar capacitive array and DNA probes was developed for the detection of OTA. The structure and parameters of the coplanar capacitive array are studied to improve the performance of the immunosensor. The gold electrodes on the surface of the sensor are modified by DNA probes, which can specifically combine with OTA to change the gold electrode surface structure. Consequently, when OTA was detected, the output capacitance will be changed. The results show that OTA could be effectively detected by analyzing the changes of the output capacitance of the immunosensor. This work demonstrates that the capacitive immunosensor provided a simple, fast and sensitive detection of OTA. Furthermore, the immunosensor could be effectively applied in other small-molecule substance detection according to the different modification.",J. Zhang; Y. Huang,,,An electrochemical immunosensor for ochratoxin a detection based on coplanar capacitive array,,,10.1109/YAC51587.2020.9337626 ,IEEE Conferences ,,"Due to the high toxicity and wide distribution of ochratoxin A (OTA), it's essential to implement the fast and sensitive detection. In this paper, a rapid and sensitive electrochemical immunosensor based on coplanar capacitive array and DNA probes was developed for the detection of OTA. The structure and parameters of the coplanar capacitive array are studied to improve the performance of the immunosensor. The gold electrodes on the surface of the sensor are modified by DNA probes, which can specifically combine with OTA to change the gold electrode surface structure. Consequently, when OTA was detected, the output capacitance will be changed. The results show that OTA could be effectively detected by analyzing the changes of the output capacitance of the immunosensor. This work demonstrates that the capacitive immunosensor provided a simple, fast and sensitive detection of OTA. Furthermore, the immunosensor could be effectively applied in other small-molecule substance detection according to the different modification.",,,978-1-7281-7684-0,710-716,IEEE , ,Electrodes;Gold;DNA;Probes;Optimization;Immune system;Sensor arrays,,
4977,"Title:EnFVe: An Ensemble Fact Verification Pipeline

 Recent years have seen exponential growth in the volume of data generated. An undesirable consequence of this rapid expansion is the alarming rise of misinformation that is spreading throughout social networks and publishing platforms. Fact verification is the act of verifying the correctness of a particular statement. Manual fact-checkers find it increasingly difficult to keep up with the rapid proliferation of fake news in the information ecosystem. Fact verification pipelines aim at assisting the fact-checkers. These pipelines involve retrieving potentially relevant documents for a given claim, checking the reliability of the document media sources, evaluating the significance of each document, and verifying the correctness of given claims. However, there are a few limitations to these pipelines. The first limitation is that they treat fact verification as a stance detection or textual entailment task and places less emphasis on pure reasoning as the basis of fact verification. The second limitation is the robustness of the models. The fact verification models do not perform well on real-world data due to the text constructed using a myriad of complex ways. The reason for low accuracy is due to the evaluation and training of models on synthetic data that does not resemble the real-world data. In this paper, we present EnFVe, an end-to-end pipeline that integrates various components of fact verification. EnFVe pipeline improves upon the existing pipelines by integrating: (1) a Data Acquisition module that routinely scrapes data for constructing and updating the ground truth, (2) Preprocessing modules such as Coreference Resolution and Sentence Simplification that improves the robustness of the verification, (3) a Continuous Retrieval Engine module that captures the semantic context of the text, and (4) an Ensemble module that consists of various state-of-the-art fact verification models equipped with hyperparameter optimization. EnFVe achieves an accuracy of (dev/test) 79.26%/73.28%, which is better as compared to the state-of-the-art fact verification pipelines.",J. J. Kurian; D. Z. R. Menezes; A. Ronanki; G. Sharma; S. K. Prasad; A. Chouhan; A. Prabhune,,,EnFVe: An Ensemble Fact Verification Pipeline,,,10.1109/WIIAT50758.2020.00016 ,IEEE Conferences ,,"Recent years have seen exponential growth in the volume of data generated. An undesirable consequence of this rapid expansion is the alarming rise of misinformation that is spreading throughout social networks and publishing platforms. Fact verification is the act of verifying the correctness of a particular statement. Manual fact-checkers find it increasingly difficult to keep up with the rapid proliferation of fake news in the information ecosystem. Fact verification pipelines aim at assisting the fact-checkers. These pipelines involve retrieving potentially relevant documents for a given claim, checking the reliability of the document media sources, evaluating the significance of each document, and verifying the correctness of given claims. However, there are a few limitations to these pipelines. The first limitation is that they treat fact verification as a stance detection or textual entailment task and places less emphasis on pure reasoning as the basis of fact verification. The second limitation is the robustness of the models. The fact verification models do not perform well on real-world data due to the text constructed using a myriad of complex ways. The reason for low accuracy is due to the evaluation and training of models on synthetic data that does not resemble the real-world data. In this paper, we present EnFVe, an end-to-end pipeline that integrates various components of fact verification. EnFVe pipeline improves upon the existing pipelines by integrating: (1) a Data Acquisition module that routinely scrapes data for constructing and updating the ground truth, (2) Preprocessing modules such as Coreference Resolution and Sentence Simplification that improves the robustness of the verification, (3) a Continuous Retrieval Engine module that captures the semantic context of the text, and (4) an Ensemble module that consists of various state-of-the-art fact verification models equipped with hyperparameter optimization. EnFVe achieves an accuracy of (dev/test) 79.26%/73.28%, which is better as compared to the state-of-the-art fact verification pipelines.",,,978-1-6654-1924-6,80-89,IEEE , ,Electronic publishing;Biological system modeling;Pipelines;Semantics;Encyclopedias;Real-time systems;Data models,,
4978,"Title:A Comprehensive Review on Deep Learning Algorithms and its Applications

 A very active expansion of data and convenience in modern period accept to motivate extremely significant automation tasks with the advanced algorithmic models with the technologies such as Artificial Intelligence, Deep Learning (Portion belonging to Machine Learning) to overcome the challenges in speech synthesis and brain tumor analysis. This research study explores different deep learnign algorithms and its applications. This review paper investigates the incoporation of Deep Learning techniques in signal processing, communications, medical image processing, particularly the models, which manage through effective activation of Artificial Intelligence. At this moment, many researchers attempt to obtain novel solutions to several issues that occur in different domains. This investigation focuses on anticipating threats that arise in different domains, which will be clarified through Deep Learning and it unquestionably be an upcoming generation of certain issues that are valuable and may help the analysts.",P. S. Kumar; V. P. Sakthivel; M. Raju; P. D. Sathya,,,A Comprehensive Review on Deep Learning Algorithms and its Applications,,,10.1109/ICESC51422.2021.9532767 ,IEEE Conferences ,,"A very active expansion of data and convenience in modern period accept to motivate extremely significant automation tasks with the advanced algorithmic models with the technologies such as Artificial Intelligence, Deep Learning (Portion belonging to Machine Learning) to overcome the challenges in speech synthesis and brain tumor analysis. This research study explores different deep learnign algorithms and its applications. This review paper investigates the incoporation of Deep Learning techniques in signal processing, communications, medical image processing, particularly the models, which manage through effective activation of Artificial Intelligence. At this moment, many researchers attempt to obtain novel solutions to several issues that occur in different domains. This investigation focuses on anticipating threats that arise in different domains, which will be clarified through Deep Learning and it unquestionably be an upcoming generation of certain issues that are valuable and may help the analysts.",,,978-1-6654-2867-5,1378-1385,IEEE , ,Deep learning;Machine learning algorithms;Shape;Face recognition;Signal processing algorithms;Predictive models;Brain modeling,,
4979,"Title:Studies on detection of atrazine and papaverine by protein arrays

 The high toxicity of pesticides and their wide use in modern agriculture has increased public concern. People are also worried about health threats caused by deleterious materials added to food. Current detection methods for these materials have their shortcomings. Microarray technology provides a highly sensitive and precise technique for obtaining information from biological samples, with the added advantage that it can handle a large number of samples simultaneously for rapid analysis. A direct competitive immunoassay for the screening of poisonous chemical haptens is proposed. Complete antigens of atrazine and papaverine were labeled with fluorescence. The fluorescence intensity linearly increased with decreasing concentration of analytes. The detection limits of atrazine and papaverine were 0.001 /spl mu/g/ml and 0.01 /spl mu/g/ml respectively.",Zhixian Gao; Yanjun Fang; Yan Wang; Shengqi Wang; Lei Zhang,,,Studies on detection of atrazine and papaverine by protein arrays,,,10.1109/ICSENS.2004.1426296 ,IEEE Conferences ,,"The high toxicity of pesticides and their wide use in modern agriculture has increased public concern. People are also worried about health threats caused by deleterious materials added to food. Current detection methods for these materials have their shortcomings. Microarray technology provides a highly sensitive and precise technique for obtaining information from biological samples, with the added advantage that it can handle a large number of samples simultaneously for rapid analysis. A direct competitive immunoassay for the screening of poisonous chemical haptens is proposed. Complete antigens of atrazine and papaverine were labeled with fluorescence. The fluorescence intensity linearly increased with decreasing concentration of analytes. The detection limits of atrazine and papaverine were 0.001 /spl mu/g/ml and 0.01 /spl mu/g/ml respectively.",,,0-7803-8692-2,822-823 vol.2,IEEE , ,Proteins;Immune system;Glass;Conducting materials;Fluorescence;Agriculture;Biological materials;Biomedical materials;Instruments;Throughput,,
4980,"Title:Systematic Design of a Quorum Sensing-Based Biosensor for Enhanced Detection of Metal Ion in Escherichia Coli

 With the recent industrial expansion, heavy metals and other pollutants have increasingly contaminated our living surroundings. The non-degradability of heavy metals may lead to accumulation in food chains and the resulting toxicity could cause damage in organisms. Hence, detection techniques have gradually received attention. In this study, a quorum sensing (QS)-based amplifier is introduced to improve the detection performance of metal ion biosensing. The design utilizes diffusible signal molecules, which freely pass through the cell membrane into the environment to communicate with others. Bacteria cooperate via the cell-cell communication process, thereby displaying synchronous behavior, even if only a minority of the cells detect the metal ion. In order to facilitate the design, the ability of the engineered biosensor to detect metal ion is described in a steady state model. The design can be constructed according to user-oriented specifications by selecting adequate components from corresponding libraries, with the help of a genetic algorithm (GA)-based design method. The experimental results validate enhanced efficiency and detection performance of the quorum sensing-based biosensor of metal ions.",C. -Y. Hsu; B. -K. Chen; R. -H. Hu; B. -S. Chen,,,Systematic Design of a Quorum Sensing-Based Biosensor for Enhanced Detection of Metal Ion in Escherichia Coli,10,3,10.1109/TBCAS.2015.2495151 ,IEEE Journals ,,"With the recent industrial expansion, heavy metals and other pollutants have increasingly contaminated our living surroundings. The non-degradability of heavy metals may lead to accumulation in food chains and the resulting toxicity could cause damage in organisms. Hence, detection techniques have gradually received attention. In this study, a quorum sensing (QS)-based amplifier is introduced to improve the detection performance of metal ion biosensing. The design utilizes diffusible signal molecules, which freely pass through the cell membrane into the environment to communicate with others. Bacteria cooperate via the cell-cell communication process, thereby displaying synchronous behavior, even if only a minority of the cells detect the metal ion. In order to facilitate the design, the ability of the engineered biosensor to detect metal ion is described in a steady state model. The design can be constructed according to user-oriented specifications by selecting adequate components from corresponding libraries, with the help of a genetic algorithm (GA)-based design method. The experimental results validate enhanced efficiency and detection performance of the quorum sensing-based biosensor of metal ions.",1940-9990,,,593-601,IEEE , ,Metals;Proteins;Biosensors;Protein engineering;Ions;Steady-state,,
4981,"Title:Imprinted Polymer Inverse Opals for the Detection of Nanoparticles

 Because of their small size, nanoparticles present specific properties and are extensively present in our everyday life. They are used in many industrial fields (paintings, cosmetics, food industry). Toxicity and especially eco-toxicity of these particles are not well-known yet and further data on their impact on human health and on the environment are absolutely needed. Nevertheless, effects such as airway inflammation or disruption of neuronal functions have been established by experiments on animals. Consequently, the development of sensitive devices for measuring exposure to nanoparticles with selective recognition and size measurement is absolutely needed.",S. Gam-Derouich; C. Bourdillon; S. L. Chaouche; L. Coolen; A. Maître; C. Mangeney; C. Schwob,,,Imprinted Polymer Inverse Opals for the Detection of Nanoparticles,,,10.1109/CLEOE-EQEC.2019.8872947 ,IEEE Conferences ,,"Because of their small size, nanoparticles present specific properties and are extensively present in our everyday life. They are used in many industrial fields (paintings, cosmetics, food industry). Toxicity and especially eco-toxicity of these particles are not well-known yet and further data on their impact on human health and on the environment are absolutely needed. Nevertheless, effects such as airway inflammation or disruption of neuronal functions have been established by experiments on animals. Consequently, the development of sensitive devices for measuring exposure to nanoparticles with selective recognition and size measurement is absolutely needed.",,,978-1-7281-0469-0,1-1,IEEE , ,Nanoparticles;Polymers;Photonic crystals;Quantum dots;Reflection;Size measurement;Painting,,
4982,"Title:Optical Detection of Lead(II) Ions Using DNA-Based Nanosensor

 Lead (Pb) is a highly toxic metal that tends to accumulate in the body. The complexes of lead are very stable within the body and cannot be metabolized or degraded rapidly, leading to lead toxicity. Therefore, it is important to detect low levels of lead in the environment to prevent lead poisoning in humans. The detection of Pb2+ ions at the nanomolar and micromolar level is achieved using DNA aptamers and quantum dots. Pb2+ ions can be detected using a DNA aptamer known as thrombin binding aptamer (TBA), which folds into a G-quadruplex structure when lead is present. The conjugation of a quantum dot and a gold nanoparticle (AuNP) to the TBA allows for optical detection via fluorescence resonant energy transfer. In the aptamer probe discussed herein, the excited quantum dot fluoresces when the DNA is in a random coil configuration. Once the Pb2+ ion-induced folding occurs, the fluorescence is reduced through energy transfer to the AuNP. The quenching efficiency observed with the liquid assay probe and the filter paper probe at 1-ţM Pb2+ ions is 41% and 71%, respectively.",K. L. Brenneman; S. Poduri; M. A. Stroscio; M. Dutta,,,Optical Detection of Lead(II) Ions Using DNA-Based Nanosensor,13,5,10.1109/JSEN.2013.2241757 ,IEEE Journals ,,"Lead (Pb) is a highly toxic metal that tends to accumulate in the body. The complexes of lead are very stable within the body and cannot be metabolized or degraded rapidly, leading to lead toxicity. Therefore, it is important to detect low levels of lead in the environment to prevent lead poisoning in humans. The detection of Pb2+ ions at the nanomolar and micromolar level is achieved using DNA aptamers and quantum dots. Pb2+ ions can be detected using a DNA aptamer known as thrombin binding aptamer (TBA), which folds into a G-quadruplex structure when lead is present. The conjugation of a quantum dot and a gold nanoparticle (AuNP) to the TBA allows for optical detection via fluorescence resonant energy transfer. In the aptamer probe discussed herein, the excited quantum dot fluoresces when the DNA is in a random coil configuration. Once the Pb2+ ion-induced folding occurs, the fluorescence is reduced through energy transfer to the AuNP. The quenching efficiency observed with the liquid assay probe and the filter paper probe at 1-ţM Pb2+ ions is 41% and 71%, respectively.",1558-1748,,,1783-1786,IEEE , ,Ions;Probes;Fluorescence;Optical filters;DNA;Particle beam optics;Quantum dots,,
4983,"Title:Interdigital sensing system for detection of levels of creatinine from the samples

 Creatinine is a biological waste that is diffused in the blood and filtered by the kidneys to reduce blood waste content-oriented toxicity for maintaining homeostasis in the living body. In the current research, we have developed a sensing system for early detection of side effects of brain cancer chemotherapy on human kidneys by monitoring the rise in creatinine levels. High creatinine levels can lead to permanent incurable conditions such as acute kidney damage or acute kidney failure. The proposed research is related to the real-time detection of creatinine in an aqueous medium. The sensing system is able to determine concentrations within the range of 0.1 - 50 ppm. The sensitivity % curve presented aids in finding an unknown sample concentration from resistance values at a frequency of 100 Hz using the electrical impedance spectroscopy (EIS) technique. The results highlight the future possibility of modifying this system for early levels of creatinine rise for preventing life-threatening conditions and providing indications to doctors in the form of parts per million (ppm) unit results where they can change the chemotherapy medicines or reduce the total drug regiments.",S. N. Prabhu; S. C. Mukhopadhyay; C. Gooneratne; A. S. Davidson; G. Liu,,,Interdigital sensing system for detection of levels of creatinine from the samples,,,10.1109/ICST46873.2019.9047672 ,IEEE Conferences ,,"Creatinine is a biological waste that is diffused in the blood and filtered by the kidneys to reduce blood waste content-oriented toxicity for maintaining homeostasis in the living body. In the current research, we have developed a sensing system for early detection of side effects of brain cancer chemotherapy on human kidneys by monitoring the rise in creatinine levels. High creatinine levels can lead to permanent incurable conditions such as acute kidney damage or acute kidney failure. The proposed research is related to the real-time detection of creatinine in an aqueous medium. The sensing system is able to determine concentrations within the range of 0.1 - 50 ppm. The sensitivity % curve presented aids in finding an unknown sample concentration from resistance values at a frequency of 100 Hz using the electrical impedance spectroscopy (EIS) technique. The results highlight the future possibility of modifying this system for early levels of creatinine rise for preventing life-threatening conditions and providing indications to doctors in the form of parts per million (ppm) unit results where they can change the chemotherapy medicines or reduce the total drug regiments.",2156-8073,,978-1-7281-4807-6,1-6,IEEE , ,Sensors;Kidney;Resistance;Electrodes;Standards;Chemotherapy;Drugs,,
4984,"Title:Occurrence of Pharmaceuticals in WWTP Influents

 Pharmaceuticals are a class of emerging micropollutants whose detection in surface waters have been attributed to domestic effluent discharges. Although concerns over potential ecological and health impacts have been raised for certain pharmaceutical groups (e.g., antibiotics), to date there are no discharge standards for these chemicals. Given that most ecotoxicity studies for pharmaceuticals were performed in laboratory settings that may differ from environmental conditions, there is a need to establish their actual environmental concentrations. In the current study, we performed a systematic review of literature to examine the influent sewage concentrations of erythromycin (prescription antibiotic) and ibuprofen (over-the counter pain reliever) in municipal wastewater treatment plants (WWTPs). The literature search and screening procedure yielded datasets from a total of 250 WWTPs which were grouped according to plant capacity (small, <; 10 mega gallons per day, MGD; medium, 10-100 MGD; and large, > 100 MGD) and geographic location (Asia, Europe, North America). Measured erythromycin levels in the influent ranged from 10-1 μ g/L to 1 μ g/L, while ibuprofen levels ranged from 10-1 μ g/L to 102 μ g/L. Average erythromycin levels were about the same across all WWTP sizes and regions. Average ibuprofen levels were significantly higher in small WWTPs than in large WWTPs ( ). Average ibuprofen levels were highest in North America -102 times higher than in Europe and 10 times higher than in Asia. With respect to WWTP operation, research findings suggest that small WWTPs should receive the same consideration as larger WWTPs where the level of treatment (i.e., degree of removal) for pharmaceuticals is concerned. Furthermore, the summarized occurrence data presented in this study provide insights to WWTP managers in assessing if enhanced WWTP treatment or downstream risks assessment for receiving streams are needed.",A. Rojjanapinun; S. Pagsuyoin; J. Luo,,,Occurrence of Pharmaceuticals in WWTP Influents,,,10.1109/SIEDS.2019.8735622 ,IEEE Conferences ,,"Pharmaceuticals are a class of emerging micropollutants whose detection in surface waters have been attributed to domestic effluent discharges. Although concerns over potential ecological and health impacts have been raised for certain pharmaceutical groups (e.g., antibiotics), to date there are no discharge standards for these chemicals. Given that most ecotoxicity studies for pharmaceuticals were performed in laboratory settings that may differ from environmental conditions, there is a need to establish their actual environmental concentrations. In the current study, we performed a systematic review of literature to examine the influent sewage concentrations of erythromycin (prescription antibiotic) and ibuprofen (over-the counter pain reliever) in municipal wastewater treatment plants (WWTPs). The literature search and screening procedure yielded datasets from a total of 250 WWTPs which were grouped according to plant capacity (small, <; 10 mega gallons per day, MGD; medium, 10-100 MGD; and large, > 100 MGD) and geographic location (Asia, Europe, North America). Measured erythromycin levels in the influent ranged from 10-1 μ g/L to 1 μ g/L, while ibuprofen levels ranged from 10-1 μ g/L to 102 μ g/L. Average erythromycin levels were about the same across all WWTP sizes and regions. Average ibuprofen levels were significantly higher in small WWTPs than in large WWTPs ( ). Average ibuprofen levels were highest in North America -102 times higher than in Europe and 10 times higher than in Asia. With respect to WWTP operation, research findings suggest that small WWTPs should receive the same consideration as larger WWTPs where the level of treatment (i.e., degree of removal) for pharmaceuticals is concerned. Furthermore, the summarized occurrence data presented in this study provide insights to WWTP managers in assessing if enhanced WWTP treatment or downstream risks assessment for receiving streams are needed.",,,978-1-7281-0998-5,1-5,IEEE , ,Chemicals;Asia;North America;Europe;Drugs;Analysis of variance,,
4985,"Title:Hybrid optical resonator for nanostructured virus detection and sizing

 We investigate a method for the detection of influenza A virus in order to reduce the risks associated with its toxicity. Our work is based on the analysis of the optical properties of a whispering gallery mode microresonator interacting with a spherical nanoparticle modeling the virion. The microresonator shows a Q-factor quite high, of the order of 6·104. Higher is the Q-factor, higher is the perturbation that the light propagating inside the resonator experiences when interacting with a scattering center, i.e. a nanoparticle. Thus, from the transmission spectrum of the resonator-virion system, we are able to derive the size of nanoparticles having a radius in the range 30 - 100 nm, with a small error with respect to the nanoparticle nominal radius.",C. Ciminelli; C. M. Campanella; M. N. Armenise,,,Hybrid optical resonator for nanostructured virus detection and sizing,,,10.1109/MeMeA.2011.5966768 ,IEEE Conferences ,,"We investigate a method for the detection of influenza A virus in order to reduce the risks associated with its toxicity. Our work is based on the analysis of the optical properties of a whispering gallery mode microresonator interacting with a spherical nanoparticle modeling the virion. The microresonator shows a Q-factor quite high, of the order of 6·104. Higher is the Q-factor, higher is the perturbation that the light propagating inside the resonator experiences when interacting with a scattering center, i.e. a nanoparticle. Thus, from the transmission spectrum of the resonator-virion system, we are able to derive the size of nanoparticles having a radius in the range 30 - 100 nm, with a small error with respect to the nanoparticle nominal radius.",,,978-1-4244-9338-8,555-558,IEEE , ,Nanoparticles;Mathematical model;Microcavities;Influenza;Equations;Optical ring resonators,,
4986,"Title:A novel acoustofluidic device for antigen antibody interaction detection using electrochemical impedance measurement

 The advantages of an acoustofluidic biochip includes low cost, deeper penetration depth, non-toxicity, temperature resistant and the ability to stream without presence of micro bubbles. A new acoustofluidic device developed for use as a biosensor is presented. A light-driven transducer was developed to manipulate protein biomarkers by integrating an acoustic radiation force and a gravitational force. We also present results when an acoustofluidic device is incorporated to create a label-free impedance biosensor which can form an assay for protein biomarkers for disease detection. This kind of acoustic field can be used to increase the binding efficiency between antigen and antibodies and save on costs by requiring less sample concentration and amount.",T. -H. Tsai; C. -K. Lee,,,A novel acoustofluidic device for antigen antibody interaction detection using electrochemical impedance measurement,,,10.1109/ISAF.2014.6923015 ,IEEE Conferences ,,"The advantages of an acoustofluidic biochip includes low cost, deeper penetration depth, non-toxicity, temperature resistant and the ability to stream without presence of micro bubbles. A new acoustofluidic device developed for use as a biosensor is presented. A light-driven transducer was developed to manipulate protein biomarkers by integrating an acoustic radiation force and a gravitational force. We also present results when an acoustofluidic device is incorporated to create a label-free impedance biosensor which can form an assay for protein biomarkers for disease detection. This kind of acoustic field can be used to increase the binding efficiency between antigen and antibodies and save on costs by requiring less sample concentration and amount.",2375-0448,,978-1-4799-3860-5,1-4,IEEE , ,Acoustic devices;Microfluidics;Impedance;Charge carrier processes;Electrodes;Ocean temperature,,
4987,"Title:Plasmonic nanobubble theranostics: Detection and destruction of drug-resistant tumors in a single rapid procedure

 On-demand plasmonic nanobubbles combine highly sensitive detection and guided destruction of drug-resistant tumors, minimize non-specific toxicity in a rapid theranostic procedure that converts current “macro” treatments into a cancer cell level “micro” modality.",D. Lapotko,,,Plasmonic nanobubble theranostics: Detection and destruction of drug-resistant tumors in a single rapid procedure,,,10.1364/CLEO_AT.2014.ATh4P.1 ,IEEE Conferences ,,"On-demand plasmonic nanobubbles combine highly sensitive detection and guided destruction of drug-resistant tumors, minimize non-specific toxicity in a rapid theranostic procedure that converts current “macro” treatments into a cancer cell level “micro” modality.",2160-8989,,978-1-55752-999-2,1-2,IEEE , ,Tumors;Cancer;Plasmons;Animals;Gold;Lasers;Nanoparticles,,
4988,"Title:Pulse Shape Discrimination in Polysiloxane-Based Liquid Scintillator

 The time response of a recently developed polysiloxane based liquid scintillator has been analyzed for the first time: a special focus on the pulse shape discrimination capability of this material, which is characterized by low toxicity and low volatility, has been addressed. Fluorescence lifetime and scintillation pulses have been studied at different primary dye concentrations, with the aim of optimizing the neutron/gamma discrimination, connecting the results to the energy transfer and to the formation of excimers inside the scintillating solution. Pulse shape analysis performed during the irradiation of the samples with a pulsed neutron beam allowed the definition of a figure of merit as an indicative parameter for the neutron/gamma discrimination. The dependence of this parameter from radiation energy and PPO concentration has been analyzed in order to optimize the performances of the material in view of its possible use in environments with high gamma-ray radiation background.",M. Dalla Palma; T. Marchi; S. Carturan; C. Checchia; G. Collazuol; F. Gramegna; N. Daldosso; V. Paterlini; A. Quaranta; M. Cinausero; M. Degerlier,,,Pulse Shape Discrimination in Polysiloxane-Based Liquid Scintillator,63,3,10.1109/TNS.2016.2530307 ,IEEE Journals ,,"The time response of a recently developed polysiloxane based liquid scintillator has been analyzed for the first time: a special focus on the pulse shape discrimination capability of this material, which is characterized by low toxicity and low volatility, has been addressed. Fluorescence lifetime and scintillation pulses have been studied at different primary dye concentrations, with the aim of optimizing the neutron/gamma discrimination, connecting the results to the energy transfer and to the formation of excimers inside the scintillating solution. Pulse shape analysis performed during the irradiation of the samples with a pulsed neutron beam allowed the definition of a figure of merit as an indicative parameter for the neutron/gamma discrimination. The dependence of this parameter from radiation energy and PPO concentration has been analyzed in order to optimize the performances of the material in view of its possible use in environments with high gamma-ray radiation background.",1558-1578,,,1608-1615,IEEE , ,Liquids;Neutrons;Shape;Fluorescence;Particle beams;Solvents,,
4989,"Title:Comet assay based detection of SPION induced DNA damage in human lymphocytes

 Superparamagnetic iron oxide nanoparticle (SPION) coated with suitable biocompatible substances have uses in various biomedical fields, particularly in magnetic resonance imaging, tissue engineering, hyperthermia and drug delivery. In this study we have used two newly formulated SPIONs. SPIONs were coated with biodegradable polymer polylactide co glycolide (PLGA) using of the two types of surfactants-didodecyldimethylammoniumbromide (DMAB) and ±-tocopheryl glycol succinate (TPGS) for surface modification, to extend the application potential in the field of nanomedicine. The present study focuses on the evaluation of genotoxicity if any of the two types of formulated SPIONs on human lymphocyte. Human lymphocytes were exposed to SPIONs at 11.2μg/ml concentrations of Fe in each group for 3 h at 37°C. Single-dose toxicity was tested in isolated lymphocytes using MTT assay. Uncoated SPIONs were found highly toxic while the coated ones showed significantly less cell death. In vitro genotoxicity of the formulated SPIONs showed significantly lower %tail DNA than uncoated SPIONs as detected by comet assay in lymphocytes. The results show that SPION induced genotoxicity is completely dependent on its physicochemical properties. Regulation of these properties by using different coatings could decrease toxicity. Type of surface modification primarily governed the amount of DNA damage as detected by Comet assay. The results also indicate that the coatings on the SPION were biocompatible and suitable for in vivo explorations while the free SPION were found completely unsuitable for in vivo administration.",S. Ghosh; I. Ghosh; A. Mukherjee,,,Comet assay based detection of SPION induced DNA damage in human lymphocytes,,,10.1109/ICSMB.2016.7915095 ,IEEE Conferences ,,"Superparamagnetic iron oxide nanoparticle (SPION) coated with suitable biocompatible substances have uses in various biomedical fields, particularly in magnetic resonance imaging, tissue engineering, hyperthermia and drug delivery. In this study we have used two newly formulated SPIONs. SPIONs were coated with biodegradable polymer polylactide co glycolide (PLGA) using of the two types of surfactants-didodecyldimethylammoniumbromide (DMAB) and ±-tocopheryl glycol succinate (TPGS) for surface modification, to extend the application potential in the field of nanomedicine. The present study focuses on the evaluation of genotoxicity if any of the two types of formulated SPIONs on human lymphocyte. Human lymphocytes were exposed to SPIONs at 11.2μg/ml concentrations of Fe in each group for 3 h at 37°C. Single-dose toxicity was tested in isolated lymphocytes using MTT assay. Uncoated SPIONs were found highly toxic while the coated ones showed significantly less cell death. In vitro genotoxicity of the formulated SPIONs showed significantly lower %tail DNA than uncoated SPIONs as detected by comet assay in lymphocytes. The results show that SPION induced genotoxicity is completely dependent on its physicochemical properties. Regulation of these properties by using different coatings could decrease toxicity. Type of surface modification primarily governed the amount of DNA damage as detected by Comet assay. The results also indicate that the coatings on the SPION were biocompatible and suitable for in vivo explorations while the free SPION were found completely unsuitable for in vivo administration.",,,978-1-4673-7666-2,91-94,IEEE , ,DNA,,
4990,"Title:Detecting the environmental impact of nanoparticles using plant-based biosensors

 The increased manufacturing of nanoparticles for use in cosmetics, foods and clothing, necessitates the need for an effective system to evaluate the potential side-effects (e.g., toxicity) of nanoparticles to the environment. A sensitive detection system would serve as a sentinel to characterize and understand the impact, and monitor the toxicity level for any potential health or safety concerns. In this paper, we proposed a plant biosensor for characterizing, monitoring, and understanding the environmental impact of both naturally occurring and man-made nanoparticles. The health of the plant sensor was monitored using an automated camera system. A machine learning-based approach was used to train the sensor to increase accuracy and adaptability with various plant sensors. The biosensor has been tested and validated in vitro. The plant sensor was proposed because it is cost-effective, and can be easily embedded into the environment. Moreover, it can detect not only exposure of water and soil, but also air. Since environmental toxicity can be measured by monitoring the health of the plant, the plant sensor can be used to monitor any potential hazard. In this study, we have demonstrated a proof-of-concept bio-sensor system for effectively detecting environmental exposure from nanoparticles. The preliminary experimental results have demonstrated the effectiveness of the approach, and the adaptability of the proposed system.",Y. Li; S. Lenaghan; J. Burris; C. N. Stewart; L. Parker; M. Zhang,,,Detecting the environmental impact of nanoparticles using plant-based biosensors,,,10.1109/NANO.2011.6144505 ,IEEE Conferences ,,"The increased manufacturing of nanoparticles for use in cosmetics, foods and clothing, necessitates the need for an effective system to evaluate the potential side-effects (e.g., toxicity) of nanoparticles to the environment. A sensitive detection system would serve as a sentinel to characterize and understand the impact, and monitor the toxicity level for any potential health or safety concerns. In this paper, we proposed a plant biosensor for characterizing, monitoring, and understanding the environmental impact of both naturally occurring and man-made nanoparticles. The health of the plant sensor was monitored using an automated camera system. A machine learning-based approach was used to train the sensor to increase accuracy and adaptability with various plant sensors. The biosensor has been tested and validated in vitro. The plant sensor was proposed because it is cost-effective, and can be easily embedded into the environment. Moreover, it can detect not only exposure of water and soil, but also air. Since environmental toxicity can be measured by monitoring the health of the plant, the plant sensor can be used to monitor any potential hazard. In this study, we have demonstrated a proof-of-concept bio-sensor system for effectively detecting environmental exposure from nanoparticles. The preliminary experimental results have demonstrated the effectiveness of the approach, and the adaptability of the proposed system.",1944-9399,,978-1-4577-1516-7,48-52,IEEE , ,Nanoparticles;Biosensors;Monitoring;Image edge detection;Zinc oxide;Cameras;Image color analysis,,
4991,"Title:A review of early detection of cancers using breath analysis

 Authentic and accurate information is basic to any disease control initiative. More than 70% of diseases are related to life-style factors such as food and beverage practices, personal habits, infections, tobacco consumption and social customs. In addition, urbanization, industrialization and increasing life-span are also known to influence the cancer pattern globally. This necessitates proper appreciation of risk factors and other causes of cancer by the people. Various modalities for early detection through screening are being investigated. Majority of the patients have locally advanced or disseminated disease at presentation and are not candidates for surgery. Chemotherapy applied as an adjunct with radiation improves survival and the quality of life. New anticancer drugs, which have emerged during the last decade, have shown an improved efficacy toxicity ratio. This review is more about the diagnosing cancer at an early stage using invasive electronic sensors and intelligent computing methods by capturing only the breath of the human being. Strengthening the methods for early diagnosis of cancers and improved treatments will have a significant impact on cutting death rates.",D. A. P. Daniel; K. Thangavel; R. S. C. Boss,,,A review of early detection of cancers using breath analysis,,,10.1109/ICPRIME.2012.6208385 ,IEEE Conferences ,,"Authentic and accurate information is basic to any disease control initiative. More than 70% of diseases are related to life-style factors such as food and beverage practices, personal habits, infections, tobacco consumption and social customs. In addition, urbanization, industrialization and increasing life-span are also known to influence the cancer pattern globally. This necessitates proper appreciation of risk factors and other causes of cancer by the people. Various modalities for early detection through screening are being investigated. Majority of the patients have locally advanced or disseminated disease at presentation and are not candidates for surgery. Chemotherapy applied as an adjunct with radiation improves survival and the quality of life. New anticancer drugs, which have emerged during the last decade, have shown an improved efficacy toxicity ratio. This review is more about the diagnosing cancer at an early stage using invasive electronic sensors and intelligent computing methods by capturing only the breath of the human being. Strengthening the methods for early diagnosis of cancers and improved treatments will have a significant impact on cutting death rates.",,,978-1-4673-1039-0,433-438,IEEE , ,Cancer;Lungs;Biopsy;Diseases;Breast;Sensor arrays,,
4992,"Title:An Early Prognosis of Lung Cancer using Machine Intelligence

 Cancer is a disease in which the body cells start growing uncontrollably and spreads all over the body. Mostly, the cancer symptoms appear only in the advanced stages. This disease is very complex in terms of its diagnosis in the early stages which results in a high mortality rate. Thus, there is a requirement for cancer to be diagnosed at its early stages which may result in better survival chances and the patients can be treated successfully. The dose-limiting toxicity in lung cancer radiotherapy (RT) is radiation pneumonitis (RP). Cancer characteristics and treatment features are intertwined, resulting, in RP associated with a single parameter is not always possible. This study aims to determine the algorithms which are most accurate for lung cancer prediction. As per the study by WHO, it has been found that in the year 2020, a total of 2.21 million people were diseased with lung cancer resulting in 1.80 million deaths all over the globe. In India, each year almost 70,000 active cases of lung cancer are identified. Early detection plays an important role in saving lives because it can give a patient a better chance to cure and recover. In recent times, different computer technologies are used for solving the problems of cancer detection. In this work, several types of machine-learning algorithms such as Naive Bayes (accuracy 96.61%), Decision tree (accuracy 91.52%), Random forest (accuracy 93.22%), Logistic Regression (accuracy 96.61%), Multilayer perceptron (accuracy 98.30%) have been utilized for predicting lung cancer. Among all of these algorithms, multilayer perceptron is the best algorithm to diagnose lung cancer.",A. Vishwakarma; A. Saini; K. Guleria; S. Sharma,,,An Early Prognosis of Lung Cancer using Machine Intelligence,,,10.1109/ICAIA57370.2023.10169432 ,IEEE Conferences ,,"Cancer is a disease in which the body cells start growing uncontrollably and spreads all over the body. Mostly, the cancer symptoms appear only in the advanced stages. This disease is very complex in terms of its diagnosis in the early stages which results in a high mortality rate. Thus, there is a requirement for cancer to be diagnosed at its early stages which may result in better survival chances and the patients can be treated successfully. The dose-limiting toxicity in lung cancer radiotherapy (RT) is radiation pneumonitis (RP). Cancer characteristics and treatment features are intertwined, resulting, in RP associated with a single parameter is not always possible. This study aims to determine the algorithms which are most accurate for lung cancer prediction. As per the study by WHO, it has been found that in the year 2020, a total of 2.21 million people were diseased with lung cancer resulting in 1.80 million deaths all over the globe. In India, each year almost 70,000 active cases of lung cancer are identified. Early detection plays an important role in saving lives because it can give a patient a better chance to cure and recover. In recent times, different computer technologies are used for solving the problems of cancer detection. In this work, several types of machine-learning algorithms such as Naive Bayes (accuracy 96.61%), Decision tree (accuracy 91.52%), Random forest (accuracy 93.22%), Logistic Regression (accuracy 96.61%), Multilayer perceptron (accuracy 98.30%) have been utilized for predicting lung cancer. Among all of these algorithms, multilayer perceptron is the best algorithm to diagnose lung cancer.",,,978-1-6654-5627-2,1-6,IEEE , ,Training;Logistic regression;Machine learning algorithms;Toxicology;Lung cancer;Multilayer perceptrons;Prediction algorithms,,
4993,"Title:Artificial Intelligence Assisted Drug Research and Development

 Artificial Intelligence, abbreviated as AI, is described as a collection of technologies that work together to allow machines to discern, interpret, take action, and acquire knowledge with human level of intelligence. The AI domain includes technologies such as natural language processing (NLP) and machine learning (ML). Each of these is on its separate route of development and, when combined with datasets, analytics, and computerization, may assist organisations in achieving their objectives, whether it's enhancing customer service or improving supply chain. The pipeline of the development of novel drugs is quite extensive and costly apart from being complicated. On average, this entire process requires around 12 years costing approximately 2.6 billion USD. In this age of computational power, AI-based techniques are used in almost all of the steps during the process of discovering and developing drugs. AI has been able to reduce the time requirement and amount of money involved in this process thus expediting the entire procedure of new pharmaceutical inventions. In this manuscript, we have discussed some of the major applications of AI in the pharmaceutical sector. Tools that are employed to forecast the toxicity of drugs and how some of them, for example - Toxtree, ADMET, ProTox etc. have been used by researchers in the drug discovery process, have also been talked about. Further we have mentioned how AI is proving to be a powerful tool in the fight against the COVID-19 pandemic, for example, in the detection of the SARS-Co V -2 virus, development of vaccines, genomics etc. In addition to this, we have discussed about the manner in which the penetration of AI-based companies into the pharmaceutical field has resulted in some notable outcomes, for instance - prediction of the 3-dimensional structure of proteins by DeepMind's AlphaFold2, determination of new drug contender for kidney fibrosis by Insilico Medicine's Chemistry42 etc. Furthermore, we have stated the propitious future that AI is expected to bring about in the pharma world with a special focus on drug development.",K. Soni; Y. Hasija,,,Artificial Intelligence Assisted Drug Research and Development,,,10.1109/DELCON54057.2022.9753179 ,IEEE Conferences ,,"Artificial Intelligence, abbreviated as AI, is described as a collection of technologies that work together to allow machines to discern, interpret, take action, and acquire knowledge with human level of intelligence. The AI domain includes technologies such as natural language processing (NLP) and machine learning (ML). Each of these is on its separate route of development and, when combined with datasets, analytics, and computerization, may assist organisations in achieving their objectives, whether it's enhancing customer service or improving supply chain. The pipeline of the development of novel drugs is quite extensive and costly apart from being complicated. On average, this entire process requires around 12 years costing approximately 2.6 billion USD. In this age of computational power, AI-based techniques are used in almost all of the steps during the process of discovering and developing drugs. AI has been able to reduce the time requirement and amount of money involved in this process thus expediting the entire procedure of new pharmaceutical inventions. In this manuscript, we have discussed some of the major applications of AI in the pharmaceutical sector. Tools that are employed to forecast the toxicity of drugs and how some of them, for example - Toxtree, ADMET, ProTox etc. have been used by researchers in the drug discovery process, have also been talked about. Further we have mentioned how AI is proving to be a powerful tool in the fight against the COVID-19 pandemic, for example, in the detection of the SARS-Co V -2 virus, development of vaccines, genomics etc. In addition to this, we have discussed about the manner in which the penetration of AI-based companies into the pharmaceutical field has resulted in some notable outcomes, for instance - prediction of the 3-dimensional structure of proteins by DeepMind's AlphaFold2, determination of new drug contender for kidney fibrosis by Insilico Medicine's Chemistry42 etc. Furthermore, we have stated the propitious future that AI is expected to bring about in the pharma world with a special focus on drug development.",,,978-1-6654-5883-2,1-10,IEEE , ,Drugs;Proteins;Technological innovation;Toxicology;Supply chains;Pipelines;Natural language processing,,
4994,"Title:Early Detection of Amyloid β Pathology in Alzheimer’s Disease by Molecular MRI

 Alzheimer’s disease (AD) is a degenerative brain disease and the most common cause of dementia. Early stage β-amyloid oligomers (AβOs) and late stage Aβ plaques are the pathological hallmarks of AD brains. AβOs are known to be more neurotoxic and contribute to neuronal damage. Most current approaches are focused on detecting Aβ plaques, which occurs at the late stage of AD, and are limited by poor sensitivity and/or contrast agent toxicity. In previous studies, we developed a new curcumin-conjugated magnetic nanoparticle (Cur-MNPs) to target the Aβ pathologies. In this study, we investigate the in vivo feasibility of this novel Cur-MNPs to detect Aβ pathologies at the early and late stages of AD in transgenic AD mice and perform immunohistochemical examinations to validate the specific targeting of various form of Aβ pathologies.",C. M. Dong; A. S. Guo; A. To; K. W. Y. Chan; A. S. F. Chow; L. Bian; A. T. L. Leong; E. X. Wu,,,Early Detection of Amyloid β Pathology in Alzheimer’s Disease by Molecular MRI,,,10.1109/EMBC44109.2020.9176013 ,IEEE Conferences ,,"Alzheimer’s disease (AD) is a degenerative brain disease and the most common cause of dementia. Early stage β-amyloid oligomers (AβOs) and late stage Aβ plaques are the pathological hallmarks of AD brains. AβOs are known to be more neurotoxic and contribute to neuronal damage. Most current approaches are focused on detecting Aβ plaques, which occurs at the late stage of AD, and are limited by poor sensitivity and/or contrast agent toxicity. In previous studies, we developed a new curcumin-conjugated magnetic nanoparticle (Cur-MNPs) to target the Aβ pathologies. In this study, we investigate the in vivo feasibility of this novel Cur-MNPs to detect Aβ pathologies at the early and late stages of AD in transgenic AD mice and perform immunohistochemical examinations to validate the specific targeting of various form of Aβ pathologies.",2694-0604,,978-1-7281-1990-8,1100-1103,IEEE , ,Mice;Pathology;Magnetic resonance imaging;Dementia;In vivo,,
4995,"Title:Vanadium Oxide Nanoparticles For Dimethylamine Vapour Detection

 Dimethylamine -((CH3)2N) (DMA), is one of the genotoxic highly volatile chemical compound that has significant biochemical effect on human genetic cells. In addition to the role of bio-marker in determining the fish freshness, dimethylamine is also used as a pre-cursor in many applications such as in the field of pesticides, dyes, plastics, etc., Therefore, to detect DMA at its early stage in commercial areas is of great importance in protecting the atmosphere as well as human health due to its irritability, combustibility, and toxicity. The reports on DMA sensing is in scarce and few reports that have been reported are at high temperature operation. Semiconducting metal-oxides are prominent material in chemical sensing due to its high sensitivity, faster response, and better stability. Hence, in the present work, vanadium pentoxide (V2O5) chemi-resistive sensor was developed to detect DMA vapours at room temperature for the minimum concentration of about 5 ppm. V2O5 nanoparticles were synthesized using hydrothermal technique and its structural information has been obtained from X-ray diffraction and Raman spectroscopy techniques. The morphology of the synthesized nanoparticles exhibited porous structure that have been observed using scanning electron microscopy. The DMA sensing studies have been carried out in a custom-made vapour sensing chamber at ambient temperature and relative humidity (25°C and 37%) for various concentrations of DMA and its sensor response (S) was calculated. Selectivity studies have been performed for various vapours and found that the synthesized nanoparticles were highly selective towards DMA vapours.",V. Mounasamy; G. K. Mani; S. Sukumaran; D. Ponnusamy; K. Tsuchiya; A. K. Prasad; S. Madanagurusamy,,,Vanadium Oxide Nanoparticles For Dimethylamine Vapour Detection,,,10.1109/MHS.2018.8886979 ,IEEE Conferences ,,"Dimethylamine -((CH3)2N) (DMA), is one of the genotoxic highly volatile chemical compound that has significant biochemical effect on human genetic cells. In addition to the role of bio-marker in determining the fish freshness, dimethylamine is also used as a pre-cursor in many applications such as in the field of pesticides, dyes, plastics, etc., Therefore, to detect DMA at its early stage in commercial areas is of great importance in protecting the atmosphere as well as human health due to its irritability, combustibility, and toxicity. The reports on DMA sensing is in scarce and few reports that have been reported are at high temperature operation. Semiconducting metal-oxides are prominent material in chemical sensing due to its high sensitivity, faster response, and better stability. Hence, in the present work, vanadium pentoxide (V2O5) chemi-resistive sensor was developed to detect DMA vapours at room temperature for the minimum concentration of about 5 ppm. V2O5 nanoparticles were synthesized using hydrothermal technique and its structural information has been obtained from X-ray diffraction and Raman spectroscopy techniques. The morphology of the synthesized nanoparticles exhibited porous structure that have been observed using scanning electron microscopy. The DMA sensing studies have been carried out in a custom-made vapour sensing chamber at ambient temperature and relative humidity (25°C and 37%) for various concentrations of DMA and its sensor response (S) was calculated. Selectivity studies have been performed for various vapours and found that the synthesized nanoparticles were highly selective towards DMA vapours.",2474-3771,,978-1-5386-6793-4,1-5,IEEE , ,Nanoparticles;Temperature sensors;Vanadium;Resistance;Fish;Nanoscale devices,,
4996,"Title:Towards an optimized tetrapolar electrical impedance lithium detection probe for bipolar disorder: A simulation study

 Bipolar disorder is characterized as a manic-depressive syndrome with severe risks to the individual. Bipolar patients' therapy involves administration of lithium which has proven to be effective for mood stabilization. The therapeutic concentration window for lithium in blood plasma is typically between 0.6-1.5 mM and is of vital importance that concentrations do not exceed the 1.5mM as it can be toxic. Accurate monitoring of the concentration changes of Lithium in blood, down to levels of approximately 0.2mM is vital since toxicity levels are in close proximity to therapeutic levels. This paper aims to study the sensitivity of tetrapolar electrical impedance measurements when used to monitor changes in the conductivity of a solution/sample as in the case of changes in Lithium concentration in blood.",L. Constantinou; P. A. Kyriacou; I. F. Triantis,,,Towards an optimized tetrapolar electrical impedance lithium detection probe for bipolar disorder: A simulation study,,,10.1109/ICSENS.2017.8234225 ,IEEE Conferences ,,"Bipolar disorder is characterized as a manic-depressive syndrome with severe risks to the individual. Bipolar patients' therapy involves administration of lithium which has proven to be effective for mood stabilization. The therapeutic concentration window for lithium in blood plasma is typically between 0.6-1.5 mM and is of vital importance that concentrations do not exceed the 1.5mM as it can be toxic. Accurate monitoring of the concentration changes of Lithium in blood, down to levels of approximately 0.2mM is vital since toxicity levels are in close proximity to therapeutic levels. This paper aims to study the sensitivity of tetrapolar electrical impedance measurements when used to monitor changes in the conductivity of a solution/sample as in the case of changes in Lithium concentration in blood.",,,978-1-5090-1012-7,1-3,IEEE , ,Sensitivity;Conductivity;Impedance;Electrodes;Impedance measurement;Lithium;Blood,,
4997,"Title:Computerized Detection of JWH Synthetic Cannabinoids Class Membership Based on Machine Learning Algorithms and Molecular Descriptors

 An Artificial Neural Networks (ANN) model identifying JWH Synthetic Cannabinoids, that we have developed based on a combination of topological, 3D-MoRSE (Molecule Representation of Structure based on Electron diffraction) and ADMET (Absorption, Distribution, Metabolism, Excretion and Toxicity) molecular descriptors, is described and analyzed. The validation results indicate that this computerized system has a very high potential for efficiently predicting the class membership of JWH and discriminating them from a large variety of (non-JWH) substances of forensic interest.",C. M. Burlacu; M. Praisler; A. C. Burlacu,,,Computerized Detection of JWH Synthetic Cannabinoids Class Membership Based on Machine Learning Algorithms and Molecular Descriptors,,,10.1109/AQTR55203.2022.9801971 ,IEEE Conferences ,,"An Artificial Neural Networks (ANN) model identifying JWH Synthetic Cannabinoids, that we have developed based on a combination of topological, 3D-MoRSE (Molecule Representation of Structure based on Electron diffraction) and ADMET (Absorption, Distribution, Metabolism, Excretion and Toxicity) molecular descriptors, is described and analyzed. The validation results indicate that this computerized system has a very high potential for efficiently predicting the class membership of JWH and discriminating them from a large variety of (non-JWH) substances of forensic interest.",,,978-1-6654-7933-2,1-5,IEEE , ,Drugs;Electric potential;Toxicology;Machine learning algorithms;Forensics;Artificial neural networks;Compounds,,
4998,"Title:The Detection of Hydrolyzable Fluoride in SF6 Equipment by Ion Chromatography and Application in Fault Determination

 SF6 in the faulty gas insulation equipment can be resolved into low-fluoride sulfide under the effect of high energy. Some of them such as SF2, S2F2, SF4, SOF2, SOF4 are easy to take hydrolysis and alkaline reactions, and some such as SO2F2, are able to occur partially alkaline reactions, and some are almost impossible to decompose such as S2F10, S2F10O and so on. The total amount of low-fluoride sulfide which can undergo hydrolysis and alkaline reactions in SF6 could be determined by hydrolysis fluoride. Therefore, if the content of hydrolyzable fluoride is found to be significantly higher than its initial value, some internal faults may exist in the equipment. In addition, hydrolyzable fluoride in SF6 will lead to the corrosion and accelerate deterioration of equipment and solid insulation materials. The amount of hydrolyzable fluoride represents the degree of toxicity, which is one of the important indicators of the quality control of SF6. In this paper, the amount of hydrolyzable fluoride in SF6 is determined by the ion chromatography. The variation tendencies of hydrolyzable fluoride are investigated under discharge and overheating conditions and the content of hydrolyzable fluoride in SF6 in normal and failure conditions is compared. In this paper, the traditional method is improved by simplifying the absorption method of the lye absorption step and adopting mechanical oscillation absorption, which make the absorption effect is controllable, the automatic drawing by the ion chromatography workstation in the standard working curve drawing step, which makes the operation easier. In the end, a reference value related to hydrolyzable fluoride for fault diagnosis is proposed, which has a certain reference significance for judging the fault condition in SF6 equipment.",N. Qiu; G. Xie; Q. Yao; Y. Miao; F. Zeng; L. Dai,,,The Detection of Hydrolyzable Fluoride in SF6 Equipment by Ion Chromatography and Application in Fault Determination,,,10.1109/ICEMPE.2019.8727271 ,IEEE Conferences ,,"SF6 in the faulty gas insulation equipment can be resolved into low-fluoride sulfide under the effect of high energy. Some of them such as SF2, S2F2, SF4, SOF2, SOF4 are easy to take hydrolysis and alkaline reactions, and some such as SO2F2, are able to occur partially alkaline reactions, and some are almost impossible to decompose such as S2F10, S2F10O and so on. The total amount of low-fluoride sulfide which can undergo hydrolysis and alkaline reactions in SF6 could be determined by hydrolysis fluoride. Therefore, if the content of hydrolyzable fluoride is found to be significantly higher than its initial value, some internal faults may exist in the equipment. In addition, hydrolyzable fluoride in SF6 will lead to the corrosion and accelerate deterioration of equipment and solid insulation materials. The amount of hydrolyzable fluoride represents the degree of toxicity, which is one of the important indicators of the quality control of SF6. In this paper, the amount of hydrolyzable fluoride in SF6 is determined by the ion chromatography. The variation tendencies of hydrolyzable fluoride are investigated under discharge and overheating conditions and the content of hydrolyzable fluoride in SF6 in normal and failure conditions is compared. In this paper, the traditional method is improved by simplifying the absorption method of the lye absorption step and adopting mechanical oscillation absorption, which make the absorption effect is controllable, the automatic drawing by the ion chromatography workstation in the standard working curve drawing step, which makes the operation easier. In the end, a reference value related to hydrolyzable fluoride for fault diagnosis is proposed, which has a certain reference significance for judging the fault condition in SF6 equipment.",,,978-1-5386-8434-4,125-130,IEEE , ,Discharges (electric);Sulfur hexafluoride;Heating systems;Ions;Needles;Absorption;Valves,,
4999,"Title:Detection of Covid-19 Vaccination Effect Through Proteomic Approaches in Cancer Patients

 Protection through a thorough vaccination campaign has become crucial with the beginning of the second wave of COVID-19 infection globally, notably in Pakistan in March-April 2021. The effectiveness of vaccines in lowering the chance of contracting severe illnesses makes them essential weapons in the fight against COVID-19. According to the GLOBOCAN database, approximately 19.3 million new cancer cases in 2020 were recorded, which made it difficult for medical practitioners to safeguard so many ""sensitive"" people against COVID-19. The COVID-19 outbreak could only be stopped after it had begun through vaccination. Around the world, there is doubt regarding the effectiveness and safety of the current COVID-19 immunization. Investigating the adverse consequences of post-COVID-19 vaccination is the goal of this study in cancer and non-cancer subjects who received a range of vaccinations, including inactivated viral vaccines (Sinopharm and Sinovac), RNA-based vaccines (Moderna and Pfizer), and non-replicating viral vaccines (AstraZeneca and Casino bio) based on Adenovirus (Sputnik-V). This study used questionnaires and interviews to examine the concurrent side effects of various COVID-19 vaccines in populations with and without cancer. IBM-SPSS was used to analyze the data using a chi-square test and an independent sample T-test. The non-cancer category was where most of the adverse effects were documented.Patients who received the vaccine safely under the care of the medical oncology clinic reported no significant toxicity. These vaccines are safe for cancer patients and people without cancer. Based on the information available, we advise cancer patients to get the inactivated viral-based Covid-19 vaccination.",S. Ishaq; A. Y. Nadeem; A. Fatima; M. Azhar; A. Shehzad,,,Detection of Covid-19 Vaccination Effect Through Proteomic Approaches in Cancer Patients,,,10.1109/ICoDT259378.2023.10325831 ,IEEE Conferences ,,"Protection through a thorough vaccination campaign has become crucial with the beginning of the second wave of COVID-19 infection globally, notably in Pakistan in March-April 2021. The effectiveness of vaccines in lowering the chance of contracting severe illnesses makes them essential weapons in the fight against COVID-19. According to the GLOBOCAN database, approximately 19.3 million new cancer cases in 2020 were recorded, which made it difficult for medical practitioners to safeguard so many ""sensitive"" people against COVID-19. The COVID-19 outbreak could only be stopped after it had begun through vaccination. Around the world, there is doubt regarding the effectiveness and safety of the current COVID-19 immunization. Investigating the adverse consequences of post-COVID-19 vaccination is the goal of this study in cancer and non-cancer subjects who received a range of vaccinations, including inactivated viral vaccines (Sinopharm and Sinovac), RNA-based vaccines (Moderna and Pfizer), and non-replicating viral vaccines (AstraZeneca and Casino bio) based on Adenovirus (Sputnik-V). This study used questionnaires and interviews to examine the concurrent side effects of various COVID-19 vaccines in populations with and without cancer. IBM-SPSS was used to analyze the data using a chi-square test and an independent sample T-test. The non-cancer category was where most of the adverse effects were documented.Patients who received the vaccine safely under the care of the medical oncology clinic reported no significant toxicity. These vaccines are safe for cancer patients and people without cancer. Based on the information available, we advise cancer patients to get the inactivated viral-based Covid-19 vaccination.",,,979-8-3503-3081-6,1-6,IEEE , ,COVID-19;Toxicology;Databases;Weapons;Sociology;Vaccines;Safety,,
5000,"Title:Automatic and Immediate Detection of Uterine Fibroids Thermally Ablated Regions Using Diffusion-Weighted Imaging and Deep Learning

 The automatic intraoperative monitoring of the uterine fibroid ablation treatment area using the Magnetic resonance guided high intensity focused ultrasound system (MRgFUS) remains a significant issue due to time-consuming procedures and inefficient manual segmentation. Dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) is the traditional method and gold standard for evaluating ablation treatment region. But it has the disadvantages of slow imaging and the inability to perform multiple examinations due to the toxicity of the Gadolinium-based contrast agent (GBCA). After analyzing the similarity and consistency of DCE and diffusion weighted imaging (DWI) ablation treatment regions, the segmentation algorithm of the high-intensity focused ultrasound ablation region based on DWI and deep learning is developed to ensure the real-time, effectiveness and safety of ablation region monitoring. Twenty female patients with histologically confirmed uterine fibroids were selected to undergo MRgFUS treatment along with DWI and DCE examination. An end-to-end multimodal image segmentation network DWIseg-net was constructed to segment the ablation regions in DWI, and performed 5-fold cross validation, using non perfusion volume (NPV) in DCE as the gold standard. The proposed DWIseg network directly detects the ablation treatment region on intraoperative DWI, resulting in a DSC of 0.8845, which is superior to previous methods. The ablation treatment rate detected by DWIseg net showed no statistically significant difference compared to the standard NPV ($p=0.3883$). The DWIseg network proposed in this study immediately detects the treatment completion region of uterine fibroids treated by MRgFUS, which helps doctors timely adjust the treatment plan during surgery and improve the one-time success rate of surgical treatment.",M. Liu; S. Zong; G. Shen; T. Na,,,Automatic and Immediate Detection of Uterine Fibroids Thermally Ablated Regions Using Diffusion-Weighted Imaging and Deep Learning,,,10.1109/AINIT59027.2023.10212556 ,IEEE Conferences ,,"The automatic intraoperative monitoring of the uterine fibroid ablation treatment area using the Magnetic resonance guided high intensity focused ultrasound system (MRgFUS) remains a significant issue due to time-consuming procedures and inefficient manual segmentation. Dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) is the traditional method and gold standard for evaluating ablation treatment region. But it has the disadvantages of slow imaging and the inability to perform multiple examinations due to the toxicity of the Gadolinium-based contrast agent (GBCA). After analyzing the similarity and consistency of DCE and diffusion weighted imaging (DWI) ablation treatment regions, the segmentation algorithm of the high-intensity focused ultrasound ablation region based on DWI and deep learning is developed to ensure the real-time, effectiveness and safety of ablation region monitoring. Twenty female patients with histologically confirmed uterine fibroids were selected to undergo MRgFUS treatment along with DWI and DCE examination. An end-to-end multimodal image segmentation network DWIseg-net was constructed to segment the ablation regions in DWI, and performed 5-fold cross validation, using non perfusion volume (NPV) in DCE as the gold standard. The proposed DWIseg network directly detects the ablation treatment region on intraoperative DWI, resulting in a DSC of 0.8845, which is superior to previous methods. The ablation treatment rate detected by DWIseg net showed no statistically significant difference compared to the standard NPV ($p=0.3883$). The DWIseg network proposed in this study immediately detects the treatment completion region of uterine fibroids treated by MRgFUS, which helps doctors timely adjust the treatment plan during surgery and improve the one-time success rate of surgical treatment.",,,979-8-3503-1452-6,122-126,IEEE , ,Deep learning;Seminars;Image segmentation;Ultrasonic imaging;Toxicology;Surgery;Real-time systems,,
5001,"Title:Study on Rapid Detection Model of Pesticide Residues on Fruit Surface Based on Hyperspectral Imaging Technology

 It is well known that if a large number of related pesticides are used in the process of agricultural planting, pesticides will often produce certain toxicity. In the process of agricultural production, in order to pursue a good harvest, the application of pesticides is inevitable. In the actual production of vegetables and fruits, there are some problems such as immature technology and inadequate pesticide spraying management, which lead to more pesticide residues in vegetables and fruits and pose a threat to people's health. In this paper, through comparing and analyzing the routine inspection results of common fruits and vegetables sold in Weifang from 2017 to 2019, the computer has made clear the present situation and causes of pesticide residues in vegetables and fruits, and put forward countermeasures and suggestions on how to effectively strengthen the quality and safety of agricultural products and improve the quality and safety level of vegetables and fruits.",Y. Chao; S. Yan,,,Study on Rapid Detection Model of Pesticide Residues on Fruit Surface Based on Hyperspectral Imaging Technology,,,10.1109/NetCIT57419.2022.00076 ,IEEE Conferences ,,"It is well known that if a large number of related pesticides are used in the process of agricultural planting, pesticides will often produce certain toxicity. In the process of agricultural production, in order to pursue a good harvest, the application of pesticides is inevitable. In the actual production of vegetables and fruits, there are some problems such as immature technology and inadequate pesticide spraying management, which lead to more pesticide residues in vegetables and fruits and pose a threat to people's health. In this paper, through comparing and analyzing the routine inspection results of common fruits and vegetables sold in Weifang from 2017 to 2019, the computer has made clear the present situation and causes of pesticide residues in vegetables and fruits, and put forward countermeasures and suggestions on how to effectively strengthen the quality and safety of agricultural products and improve the quality and safety level of vegetables and fruits.",,,978-1-6654-9273-7,294-297,IEEE , ,Toxicology;Pollution;Spraying;Process control;Production;Quality control;Inspection,,
5002,"Title:Biomonitoring of indoor particle contamination by detection of bioluminescence reduction of marine bacterium Vibrio fischeri

 Bioassay, which detects biohazardous property of environmental contaminants, is still being an unexplored field of air quality monitoring. This study aims to develop a simple testing system of toxicity of the indoor particulate matter by detecting bioluminescence reduction of marine bacterium Vibrio fischeri. Suspended particulate matter in indoor and outdoor air was collected on a quartz fiber filter at a flow rate of 23.5 L/min. by a low volume air sampler for 7-day duration, at the terrace and living room of an apartment house in Kanagawa, Japan. Collected materials were extracted with sterilized distilled water by mild shaking. After filtration with 0.45 mum pore size filter, the extracts were subsequently mixed with a bacterium solution in a well of 24-well plate and time courses of bioluminescence intensity were measured by a luminometer. As a result, the water extracts of indoor and outdoor aerosol samples significantly reduced the bioluminescence of Vibrio fischeri and the inhibition per sampling volume increased with increasing TSP concentrations. The inhibition per unit mass of the indoor aerosols became greater than that of outdoor aerosols, when increasing in air change rate. The inhibition tended to correlate with nitrate and sulfate concentrations in the extracts. This study showed possible application of bioassay to the monitoring of indoor suspended particle contamination.",S. Ikeda; M. Oikawa; Y. Sekine,,,Biomonitoring of indoor particle contamination by detection of bioluminescence reduction of marine bacterium Vibrio fischeri,,, ,IEEE Conferences ,,"Bioassay, which detects biohazardous property of environmental contaminants, is still being an unexplored field of air quality monitoring. This study aims to develop a simple testing system of toxicity of the indoor particulate matter by detecting bioluminescence reduction of marine bacterium Vibrio fischeri. Suspended particulate matter in indoor and outdoor air was collected on a quartz fiber filter at a flow rate of 23.5 L/min. by a low volume air sampler for 7-day duration, at the terrace and living room of an apartment house in Kanagawa, Japan. Collected materials were extracted with sterilized distilled water by mild shaking. After filtration with 0.45 mum pore size filter, the extracts were subsequently mixed with a bacterium solution in a well of 24-well plate and time courses of bioluminescence intensity were measured by a luminometer. As a result, the water extracts of indoor and outdoor aerosol samples significantly reduced the bioluminescence of Vibrio fischeri and the inhibition per sampling volume increased with increasing TSP concentrations. The inhibition per unit mass of the indoor aerosols became greater than that of outdoor aerosols, when increasing in air change rate. The inhibition tended to correlate with nitrate and sulfate concentrations in the extracts. This study showed possible application of bioassay to the monitoring of indoor suspended particle contamination.",,,978-4-907764-34-0,4486-4489,IEEE , ,Contamination;Bioluminescence;Aerosols;Monitoring;Filters;System testing;Optical fiber testing;Biological materials;Filtration;Pollution measurement,,
5003,"Title:Toxic Code Snippets on Stack Overflow

 Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects.",C. Ragkhitwetsagul; J. Krinke; M. Paixao; G. Bianco; R. Oliveto,,,Toxic Code Snippets on Stack Overflow,47,3,10.1109/TSE.2019.2900307 ,IEEE Journals ,,"Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects.",1939-3520,,,560-581,IEEE , ,Cloning;Licenses;Software;Programming;Computer bugs;Security;Tutorials,,
5004,"Title:Arduino based Sensor Equipped Fire Surveillance Drone

 In this paper, a solution is proposed that tackles most of the problems in firefighting using a drone equipped with sensors. The drone would have the ability to monitor the environment caught in fire. The proposed solution will be a semi-automated drone that would generate an area map, heat map and toxicity reports of the environment. Along with it, the drone will also provide positional information about the possible presence of living beings. All the functionalities will be implemented using basic sensors like ultrasonic sensors, MPU sensor, DHT sensor, and hardware controllers like Arduino, NodeMCU & Raspberry pi 3.",R. Joseph; D. Gopalani; B. Khubnani; A. Bote; R. Devadiga,,,Arduino based Sensor Equipped Fire Surveillance Drone,,,10.1109/ICICCS48265.2020.9121043 ,IEEE Conferences ,,"In this paper, a solution is proposed that tackles most of the problems in firefighting using a drone equipped with sensors. The drone would have the ability to monitor the environment caught in fire. The proposed solution will be a semi-automated drone that would generate an area map, heat map and toxicity reports of the environment. Along with it, the drone will also provide positional information about the possible presence of living beings. All the functionalities will be implemented using basic sensors like ultrasonic sensors, MPU sensor, DHT sensor, and hardware controllers like Arduino, NodeMCU & Raspberry pi 3.",,,978-1-7281-4876-2,219-223,IEEE , ,Heating systems;Toxicology;Surveillance;Control systems;Sensor systems;Hardware;Acoustics,,
5005,"Title:A Preliminary Study on Shallow Groundwater Organic Pollution in the Alluvial Plain of Hutuo River

 Groundwater is the source of main agricultural, industrial and domestic water in the Alluvial Plain of Hutu River, the pollution degree of groundwater directly affects habitants state of health in the area. In order to explain the condition of shallow groundwater organic pollution under the influence of human activities, the Alluvial Plain of Hutuo River was selected as the main study area, and then by a large amount of groundwater sampling, analysis and test, we analyzed the characteristics of shallow groundwater organic pollution. The results show that shallow groundwater has been under threat of organic pollution in the area, the main detected organic components are halogenated hydrocarbons, polyaromatics and chlorobenzenes, among which the detection rate of trichloromethane amounts to 14.02%; Over-standard organics samples are sparse, but the over-standard concentrations are high, the main over-standard component is tetrachloromethane. Because of the high toxicity of organics, organic pollution has become unable to be neglected in the study area.",Y. Li; Z. Zhang; Y. Fei; Y. Qian; S. Meng,,,A Preliminary Study on Shallow Groundwater Organic Pollution in the Alluvial Plain of Hutuo River,,,10.1109/CDCIEM.2011.355 ,IEEE Conferences ,,"Groundwater is the source of main agricultural, industrial and domestic water in the Alluvial Plain of Hutu River, the pollution degree of groundwater directly affects habitants state of health in the area. In order to explain the condition of shallow groundwater organic pollution under the influence of human activities, the Alluvial Plain of Hutuo River was selected as the main study area, and then by a large amount of groundwater sampling, analysis and test, we analyzed the characteristics of shallow groundwater organic pollution. The results show that shallow groundwater has been under threat of organic pollution in the area, the main detected organic components are halogenated hydrocarbons, polyaromatics and chlorobenzenes, among which the detection rate of trichloromethane amounts to 14.02%; Over-standard organics samples are sparse, but the over-standard concentrations are high, the main over-standard component is tetrachloromethane. Because of the high toxicity of organics, organic pollution has become unable to be neglected in the study area.",,,978-1-61284-278-3,678-682,IEEE , ,Monitoring;Computers;Distributed control,,
5006,"Title:Cyberbullying and Cyberviolence Detection: A Triangular User-Activity-Content View

 Recent years have witnessed the increasing popularity of mobile and networking devices, as well as social networking sites, where users engage in a variety of activities in the cyberspace on a daily and real-time basis. While such systems provide tremendous convenience and enjoyment for users, malicious usages, such as bullying, cruelty, extremism, and toxicity behaviors, also grow noticeably, and impose significant threats to individuals and communities. In this paper, we review computational approaches for cyberbullying and cyberviolence detection, in order to understand two major factors: 1) What are the defining features of online bullying users, and 2) How to detect cyberbullying and cyberviolence. To achieve the goal, we propose a user-activities-content (UAC) triangular view, which defines that users in the cyberspace are centered around the UAC triangle to carry out activities and generate content. Accordingly, we categorize cyberbully features into three main categories: 1) User centered features, 2) Content centered features, and 3) Activity centered features. After that, we review methods for cyberbully detection, by taking supervised, unsupervised, transfer learning, and deep learning, etc., into consideration. The UAC centered view provides a coherent and complete summary about features and characteristics of online users (their activities), approaches to detect bullying users (and malicious content), and helps defend cyberspace from bullying and toxicity.",S. Wang; X. Zhu; W. Ding; A. A. Yengejeh,,,Cyberbullying and Cyberviolence Detection: A Triangular User-Activity-Content View,9,8,10.1109/JAS.2022.105740 ,IEEE Journals ,,"Recent years have witnessed the increasing popularity of mobile and networking devices, as well as social networking sites, where users engage in a variety of activities in the cyberspace on a daily and real-time basis. While such systems provide tremendous convenience and enjoyment for users, malicious usages, such as bullying, cruelty, extremism, and toxicity behaviors, also grow noticeably, and impose significant threats to individuals and communities. In this paper, we review computational approaches for cyberbullying and cyberviolence detection, in order to understand two major factors: 1) What are the defining features of online bullying users, and 2) How to detect cyberbullying and cyberviolence. To achieve the goal, we propose a user-activities-content (UAC) triangular view, which defines that users in the cyberspace are centered around the UAC triangle to carry out activities and generate content. Accordingly, we categorize cyberbully features into three main categories: 1) User centered features, 2) Content centered features, and 3) Activity centered features. After that, we review methods for cyberbully detection, by taking supervised, unsupervised, transfer learning, and deep learning, etc., into consideration. The UAC centered view provides a coherent and complete summary about features and characteristics of online users (their activities), approaches to detect bullying users (and malicious content), and helps defend cyberspace from bullying and toxicity.",2329-9274,,,1384-1405,IEEE , ,Deep learning;Toxicology;Transfer learning;Supervised learning;Time series analysis;Taxonomy;Cyberbullying,,
5007,"Title:Implementation of Internet of Things and Nanobiotechnology in Medical Sector

 Nanobiotechnology is broadly used in the realm of medicine as nanomedicine. There may be uses for some nanoparticles in state-of-the-art diagnostic tools, imaging and methodology, pharmaceutical items, biomedical implants, and tissue engineering. Nanobiotechnology now allows for the innovative and safer administration of high-toxicity treatments like chemotherapy for cancer. Furthermore, wearable technology can identify critical alterations in vital signs, cancer cell states and infections that are actually occurring in the body. Likewise, the Internet of Things (IoT) has also been widely used to interconnect available medical resources and offer elderly and patients with chronic illnesses reliable, efficient and smart healthcare services. This study covers nanobiotechnology applications in the medical field. The class, features and resources of nanobiotechnology for medicine are also briefed. This study also identifies the intelligentization trend and future research directions in the healthcare industry while summarizing IoT applications in that sector. The current study includes many potential Internet of Things and nanobiotechnology applications in the medical field. As a result, the study offers a brief and well-organized report on both nanobiotechnology and the Internet of Things which should be helpful to researchers, engineers and scientists for future research initiatives.",J. S. Chohan; R. Kumar; S. Singh; B. Goyal; A. Dogra,,,Implementation of Internet of Things and Nanobiotechnology in Medical Sector,,, ,IEEE Conferences ,,"Nanobiotechnology is broadly used in the realm of medicine as nanomedicine. There may be uses for some nanoparticles in state-of-the-art diagnostic tools, imaging and methodology, pharmaceutical items, biomedical implants, and tissue engineering. Nanobiotechnology now allows for the innovative and safer administration of high-toxicity treatments like chemotherapy for cancer. Furthermore, wearable technology can identify critical alterations in vital signs, cancer cell states and infections that are actually occurring in the body. Likewise, the Internet of Things (IoT) has also been widely used to interconnect available medical resources and offer elderly and patients with chronic illnesses reliable, efficient and smart healthcare services. This study covers nanobiotechnology applications in the medical field. The class, features and resources of nanobiotechnology for medicine are also briefed. This study also identifies the intelligentization trend and future research directions in the healthcare industry while summarizing IoT applications in that sector. The current study includes many potential Internet of Things and nanobiotechnology applications in the medical field. As a result, the study offers a brief and well-organized report on both nanobiotechnology and the Internet of Things which should be helpful to researchers, engineers and scientists for future research initiatives.",,,978-93-80544-47-2,1026-1030,IEEE , ,Industries;Sociology;Production;Internet of Things;Security;Nanomedicine;Statistics,,
5008,"Title:Microdroplet Based Organic Vapour Sensor on a Disposable GO-Chitosan Flexible Substrate

 With rising hazardous organic vapours in the environment, the detection of volatile organic vapour compounds (VOCs) is important for human safety. To this end, this paper presents a conductive droplet-based disposable sensor. Unlike conventional sensors, the droplet system is easily replaceable and is capable of detecting multiple vapours based on surface tension gradient. The response time for the presented sensing arrangement was found to be 3-4 seconds which is better than the solid-state counterparts. The chemiresistive sensor used in this work, is fabricated on 2.5 μm thick ultra-flexible graphene oxide-chitosan (GOC) bioresorbable substrate with Pt electrodes which are 60 μm apart. The presence of GO in the GOC substrate provides optimum hydrophobicity to the droplet for efficient operation. The electrostatic interaction and strong hydrogen bonds between GO and polysaccharide groups in chitosan provides tunable hydrophobicity and stability to the droplet. Moreover, biocompatibility, low-toxicity and bioresorbability of GOC substrate are highly desirable in the disposable sensing applications. With a conductive droplet of ~10 μL of aq. NaCl as an active sensing material, dispensed in-between the Pt electrodes, it was observed that the droplet shows 14-21% change in resistance in presence of VOCs.",M. Bhattacharjee; A. Vilouras; R. Dahiya,,,Microdroplet Based Organic Vapour Sensor on a Disposable GO-Chitosan Flexible Substrate,,,10.1109/FLEPS.2019.8792237 ,IEEE Conferences ,,"With rising hazardous organic vapours in the environment, the detection of volatile organic vapour compounds (VOCs) is important for human safety. To this end, this paper presents a conductive droplet-based disposable sensor. Unlike conventional sensors, the droplet system is easily replaceable and is capable of detecting multiple vapours based on surface tension gradient. The response time for the presented sensing arrangement was found to be 3-4 seconds which is better than the solid-state counterparts. The chemiresistive sensor used in this work, is fabricated on 2.5 μm thick ultra-flexible graphene oxide-chitosan (GOC) bioresorbable substrate with Pt electrodes which are 60 μm apart. The presence of GO in the GOC substrate provides optimum hydrophobicity to the droplet for efficient operation. The electrostatic interaction and strong hydrogen bonds between GO and polysaccharide groups in chitosan provides tunable hydrophobicity and stability to the droplet. Moreover, biocompatibility, low-toxicity and bioresorbability of GOC substrate are highly desirable in the disposable sensing applications. With a conductive droplet of ~10 μL of aq. NaCl as an active sensing material, dispensed in-between the Pt electrodes, it was observed that the droplet shows 14-21% change in resistance in presence of VOCs.",,,978-1-5386-9304-9,1-3,IEEE , ,Substrates;Electrodes;Graphene;Surface tension;Microfluidics;Biosensors,,
5009,"Title:Single-molecule Aflatoxin B1 Sensing via Pyrrole-based Molecular Quantum Dot

 We investigate through ab-initio simulations the gold-8PyrroleDiThiol-gold (Au-8PyDT) molecular quantum dot as an amperometric single-molecule sensor for the aflatoxin B1 (AFB1) detection. We study the adsorption of AFB1 onto the Au-8PyDT and we analyze the transport characteristics for the most probable adsorption configuration. We find that a significant current modulation occurs, with around 80% of current decrease in presence of AFB1. Interestingly, the investigated sensor exhibits a voltage-dependent response, that we motivate through a transmission properties analysis. Our results, considering the synthesis simplicity of PolyPyrroles and their non-toxicity, motivate future research efforts in this direction.",F. Mo; C. E. Spano; Y. Ardesi; M. R. Roch; G. Piccinini; M. Graziano,,,Single-molecule Aflatoxin B1 Sensing via Pyrrole-based Molecular Quantum Dot,,,10.1109/NANO54668.2022.9928694 ,IEEE Conferences ,,"We investigate through ab-initio simulations the gold-8PyrroleDiThiol-gold (Au-8PyDT) molecular quantum dot as an amperometric single-molecule sensor for the aflatoxin B1 (AFB1) detection. We study the adsorption of AFB1 onto the Au-8PyDT and we analyze the transport characteristics for the most probable adsorption configuration. We find that a significant current modulation occurs, with around 80% of current decrease in presence of AFB1. Interestingly, the investigated sensor exhibits a voltage-dependent response, that we motivate through a transmission properties analysis. Our results, considering the synthesis simplicity of PolyPyrroles and their non-toxicity, motivate future research efforts in this direction.",1944-9380,,978-1-6654-5225-0,153-156,IEEE , ,Electric potential;Sensitivity;Adsorption;Quantum dots;Modulation;Feature extraction;Real-time systems,,
5010,"Title:Acute Cyanide Poisoning: Identification of Prussic Acid in by Analyzing of Various Parameters in Cattle

 Cyanide is one of the most vigorous toxins which contains in plants naturally and it can affect all the animals especially in cattle. Cogitative can be easily affected by this toxic substance from consuming various kinds of natural plants like sorghum and Johnson grass. Most of the plant species contains cyanogenic glycosides and these cyanogenic glycosides are converted to hydrogen cyanide by hydrolyzation in the cattle body. After the hydrolyzation, hydrogen cyanide combine with methemoglobin is hemoglobin in the form of metalloprotein and this composite constrain the oxidative phosphorylation. As a ramification of this process the affected cogitative animals may die. This toxic cyanide can affect animals rapidly. In olden process the cyanide detection can be identified using the cherryred color change of the blood of affected cattle and in the necropsy early formation of death attendance are the cardinal symptoms of cyanide poisoning. If the treatment performed rapidly, toxin can be neutralized but in the most cases the animals die due to rapidly acting nature of the toxin. It is more important to prevent cattle from the toxic substances.",S. Sankaran; M. P. Rajasekaran; V. Govindaraj; P. Sowmiya; S. ShinyRebekka; B. Kaleeswaran,,,Acute Cyanide Poisoning: Identification of Prussic Acid in by Analyzing of Various Parameters in Cattle,,,10.1109/ICCSP48568.2020.9182090 ,IEEE Conferences ,,"Cyanide is one of the most vigorous toxins which contains in plants naturally and it can affect all the animals especially in cattle. Cogitative can be easily affected by this toxic substance from consuming various kinds of natural plants like sorghum and Johnson grass. Most of the plant species contains cyanogenic glycosides and these cyanogenic glycosides are converted to hydrogen cyanide by hydrolyzation in the cattle body. After the hydrolyzation, hydrogen cyanide combine with methemoglobin is hemoglobin in the form of metalloprotein and this composite constrain the oxidative phosphorylation. As a ramification of this process the affected cogitative animals may die. This toxic cyanide can affect animals rapidly. In olden process the cyanide detection can be identified using the cherryred color change of the blood of affected cattle and in the necropsy early formation of death attendance are the cardinal symptoms of cyanide poisoning. If the treatment performed rapidly, toxin can be neutralized but in the most cases the animals die due to rapidly acting nature of the toxin. It is more important to prevent cattle from the toxic substances.",,,978-1-7281-4988-2,561-0568,IEEE , ,Color;Cows;Blood;Fluorescence;Ions;Probes,,
5011,"Title:Better Prevent than React: Deep Stratified Learning to Predict Hate Intensity of Twitter Reply Chains

 Given a tweet, predicting the discussions that unfold around it is convoluted, to say the least. Most if not all of the discernibly benign tweets which seem innocuous may very well attract inflammatory posts (hate speech) from people who find them non-congenial. Therefore, building upon the aforementioned task and predicting if a tweet will incite hate speech is of critical importance. To stifle the dissemination of online hate speech is the need of the hour. Thus, there have been a handful of models for the detection of hate speech. Classical models work retrospectively by leveraging a reactive strategy – detection after the postage of hate speech, i.e., a backward trace after detection. Therefore, a benign post that may act as a surrogate to invoke toxicity in the near future, may not be flagged by the existing hate speech detection models. In this paper, we address this problem through a proactive strategy initiated to avert hate crime. We propose DRAGNET, a deep stratified learning framework which predicts the intensity of hatred that a root tweet can fetch through its subsequent replies. We extend the collection of social media discourse from our earlier work [1], comprising the entire reply chains up to $\sim$5k root tweets catalogued into four controversial topics Similar to [1], we notice a handful of cases where despite the root tweets being non-hateful, the succeeding replies inject an enormous amount of toxicity into the discussions. DRAGNET turns out to be highly effective, significantly outperforming six state-of-the-art baselines. It beats the best baseline with an increase of 9.4% in the Pearson correlation coefficient and a decrease of 19% in Root Mean Square Error. Further, DRAGNET’S deployment in Logically’s advanced AI platform designed to monitor real-world problematic and hateful narratives has improved the aggregated insights extracted for understanding their spread, influence and thereby offering actionable intelligence to counter them",D. Sahnan; S. Dahiya; V. Goel; A. Bandhakavi; T. Chakraborty,,,Better Prevent than React: Deep Stratified Learning to Predict Hate Intensity of Twitter Reply Chains,,,10.1109/ICDM51629.2021.00066 ,IEEE Conferences ,,"Given a tweet, predicting the discussions that unfold around it is convoluted, to say the least. Most if not all of the discernibly benign tweets which seem innocuous may very well attract inflammatory posts (hate speech) from people who find them non-congenial. Therefore, building upon the aforementioned task and predicting if a tweet will incite hate speech is of critical importance. To stifle the dissemination of online hate speech is the need of the hour. Thus, there have been a handful of models for the detection of hate speech. Classical models work retrospectively by leveraging a reactive strategy – detection after the postage of hate speech, i.e., a backward trace after detection. Therefore, a benign post that may act as a surrogate to invoke toxicity in the near future, may not be flagged by the existing hate speech detection models. In this paper, we address this problem through a proactive strategy initiated to avert hate crime. We propose DRAGNET, a deep stratified learning framework which predicts the intensity of hatred that a root tweet can fetch through its subsequent replies. We extend the collection of social media discourse from our earlier work [1], comprising the entire reply chains up to $\sim$5k root tweets catalogued into four controversial topics Similar to [1], we notice a handful of cases where despite the root tweets being non-hateful, the succeeding replies inject an enormous amount of toxicity into the discussions. DRAGNET turns out to be highly effective, significantly outperforming six state-of-the-art baselines. It beats the best baseline with an increase of 9.4% in the Pearson correlation coefficient and a decrease of 19% in Root Mean Square Error. Further, DRAGNET’S deployment in Logically’s advanced AI platform designed to monitor real-world problematic and hateful narratives has improved the aggregated insights extracted for understanding their spread, influence and thereby offering actionable intelligence to counter them",2374-8486,,978-1-6654-2398-4,549-558,IEEE , ,Toxicology;Social networking (online);Hate speech;Blogs;Semantics;Data mining;Artificial intelligence,,
5012,"Title:A Personalized Framework for Medication Treatment Management in Chronic Care

 The ongoing efforts toward continuity of care and the recent advances in information and communication technologies have led to a number of successful personal health systems for the management of chronic care. These systems are mostly focused on monitoring efficiently the patient's medical status at home. This paper aims at extending home care services delivery by introducing a novel framework for monitoring the patient's condition and safety with respect to the medication treatment administered. For this purpose, considering a body area network (BAN) with advanced sensors and a mobile base unit as the central communication hub from the one side, and the clinical environment from the other side, an architecture was developed, offering monitoring patterns definition for the detection of possible adverse drug events and the assessment of medication response, supported by mechanisms enabling bidirectional communication between the BAN and the clinical site. Particular emphasis was given on communication and information flow aspects that have been addressed by defining/adopting appropriate formal information structures as well as the service-oriented architecture paradigm. The proposed framework is illustrated via an application scenario concerning hypertension management.",V. G. Koutkias; I. Chouvarda; A. Triantafyllidis; A. Malousi; G. D. Giaglis; N. Maglaveras,,,A Personalized Framework for Medication Treatment Management in Chronic Care,14,2,10.1109/TITB.2009.2036367 ,IEEE Journals ,,"The ongoing efforts toward continuity of care and the recent advances in information and communication technologies have led to a number of successful personal health systems for the management of chronic care. These systems are mostly focused on monitoring efficiently the patient's medical status at home. This paper aims at extending home care services delivery by introducing a novel framework for monitoring the patient's condition and safety with respect to the medication treatment administered. For this purpose, considering a body area network (BAN) with advanced sensors and a mobile base unit as the central communication hub from the one side, and the clinical environment from the other side, an architecture was developed, offering monitoring patterns definition for the detection of possible adverse drug events and the assessment of medication response, supported by mechanisms enabling bidirectional communication between the BAN and the clinical site. Particular emphasis was given on communication and information flow aspects that have been addressed by defining/adopting appropriate formal information structures as well as the service-oriented architecture paradigm. The proposed framework is illustrated via an application scenario concerning hypertension management.",1558-0032,,,464-472,IEEE , ,Medical treatment;Patient monitoring;Biomedical monitoring;Body sensor networks;Communications technology;Technology management;Condition monitoring;Domestic safety;Body area networks;Mobile communication,,
5013,"Title:A Distributed, Collaborative Intelligent Agent System Approach for Proactive Postmarketing Drug Safety Surveillance

 Discovering unknown adverse drug reactions (ADRs) in postmarketing surveillance as early as possible is of great importance. The current approach to postmarketing surveillance primarily relies on spontaneous reporting. It is a passive surveillance system and limited by gross underreporting (<10% reporting rate), latency, and inconsistent reporting. We propose a novel team-based intelligent agent software system approach for proactively monitoring and detecting potential ADRs of interest using electronic patient records. We designed such a system and named it ADRMonitor. The intelligent agents, operating on computers located in different places, are capable of continuously and autonomously collaborating with each other and assisting the human users (e.g., the food and drug administration (FDA), drug safety professionals, and physicians). The agents should enhance current systems and accelerate early ADR identification. To evaluate the performance of the ADRMonitor with respect to the current spontaneous reporting approach, we conducted simulation experiments on identification of ADR signal pairs (i.e., potential links between drugs and apparent adverse reactions) under various conditions. The experiments involved over 275 000 simulated patients created on the basis of more than 1000 real patients treated by the drug cisapride that was on the market for seven years until its withdrawal by the FDA in 2000 due to serious ADRs. Healthcare professionals utilizing the spontaneous reporting approach and the ADRMonitor were separately simulated by decision-making models derived from a general cognitive decision model called fuzzy recognition-primed decision (RPD) model that we recently developed. The quantitative simulation results show that 1) the number of true ADR signal pairs detected by the ADRMonitor is 6.6 times higher than that by the spontaneous reporting strategy; 2) the ADR detection rate of the ADRMonitor agents with even moderate decision-making skills is five times higher than that of spontaneous reporting; and 3) as the number of patient cases increases, ADRs could be detected significantly earlier by the ADRMonitor.",Y. Ji; H. Ying; M. S. Farber; J. Yen; P. Dews; R. E. Miller; R. M. Massanari,,,"A Distributed, Collaborative Intelligent Agent System Approach for Proactive Postmarketing Drug Safety Surveillance",14,3,10.1109/TITB.2009.2037007 ,IEEE Journals ,,"Discovering unknown adverse drug reactions (ADRs) in postmarketing surveillance as early as possible is of great importance. The current approach to postmarketing surveillance primarily relies on spontaneous reporting. It is a passive surveillance system and limited by gross underreporting (<10% reporting rate), latency, and inconsistent reporting. We propose a novel team-based intelligent agent software system approach for proactively monitoring and detecting potential ADRs of interest using electronic patient records. We designed such a system and named it ADRMonitor. The intelligent agents, operating on computers located in different places, are capable of continuously and autonomously collaborating with each other and assisting the human users (e.g., the food and drug administration (FDA), drug safety professionals, and physicians). The agents should enhance current systems and accelerate early ADR identification. To evaluate the performance of the ADRMonitor with respect to the current spontaneous reporting approach, we conducted simulation experiments on identification of ADR signal pairs (i.e., potential links between drugs and apparent adverse reactions) under various conditions. The experiments involved over 275 000 simulated patients created on the basis of more than 1000 real patients treated by the drug cisapride that was on the market for seven years until its withdrawal by the FDA in 2000 due to serious ADRs. Healthcare professionals utilizing the spontaneous reporting approach and the ADRMonitor were separately simulated by decision-making models derived from a general cognitive decision model called fuzzy recognition-primed decision (RPD) model that we recently developed. The quantitative simulation results show that 1) the number of true ADR signal pairs detected by the ADRMonitor is 6.6 times higher than that by the spontaneous reporting strategy; 2) the ADR detection rate of the ADRMonitor agents with even moderate decision-making skills is five times higher than that of spontaneous reporting; and 3) as the number of patient cases increases, ADRs could be detected significantly earlier by the ADRMonitor.",1558-0032,,,826-837,IEEE , ,Collaboration;Intelligent agent;Drugs;Safety;Surveillance;Decision making;Delay;Software systems;Patient monitoring;Computerized monitoring,,
5014,"Title:Reusable Boron-Doped Diamond Electrodes for the Semi-Continuous Detection of Tetrabromobisphenol A

 It is of great importance to measure tetrabromobisphenol A (TBBPA) owing to its high toxicity and wide existence in the environment. In this paper, an electrochemical sensor based on boron-doped diamond (BDD) thin film was developed for the detection of TBBPA. The diamond thin film was deposited on Si substrate via filament-assisted chemical vapor deposition. Due to the great electrochemical properties, the BDD electrode could be reactivated after a pretreatment process after each measurement, which realized a continuous detection of TBBPA and solved the problem of renewal. The electrochemical pretreatment procedure was studied in order to achieve better performance. The peak current of the BDD electrode displayed a good linearity toward TBBPA concentrations ranging from 50 nM to 10 μM, and the detection limit was 27 nM (S/N = 3).",S. Gong; C. Gao; J. Wang; J. Tong; C. Bian; K. Wu; S. Xia,,,Reusable Boron-Doped Diamond Electrodes for the Semi-Continuous Detection of Tetrabromobisphenol A,18,13,10.1109/JSEN.2018.2827999 ,IEEE Journals ,,"It is of great importance to measure tetrabromobisphenol A (TBBPA) owing to its high toxicity and wide existence in the environment. In this paper, an electrochemical sensor based on boron-doped diamond (BDD) thin film was developed for the detection of TBBPA. The diamond thin film was deposited on Si substrate via filament-assisted chemical vapor deposition. Due to the great electrochemical properties, the BDD electrode could be reactivated after a pretreatment process after each measurement, which realized a continuous detection of TBBPA and solved the problem of renewal. The electrochemical pretreatment procedure was studied in order to achieve better performance. The peak current of the BDD electrode displayed a good linearity toward TBBPA concentrations ranging from 50 nM to 10 μM, and the detection limit was 27 nM (S/N = 3).",1558-1748,,,5219-5224,IEEE , ,Electrodes;Diamond;Oxidation;Substrates;Electric potential;Surface treatment;Sensors,,
5015,"Title:Precision Low Cost Phase Sensitive Optical Sensor for Detecting Carbon Nanoparticle Degradation

 Phase sensitive detection (PSD) is a powerful technique to extract low amplitude signals from noisy data. Commercially available lock-in amplifiers that employ this technique are expensive and cost-prohibitive for several applications where accuracy is desired with low cost instrumentation. In this manuscript we present a novel dual switch based phase sensitive detection scheme to distinguish the contrast of a reflecting surface. The circuit is sensitive enough to distinguish various shades of gray colored (darkness) text printed on a sheet of regular printer paper, even in presence of high intensity background light. We report the measurement of concentration of a solution of carbon nanoparticles in water, with potential application as a toxicity sensor or biosensor for various enzymes that could cause degradation of carbon nanoparticles.",R. Nandeshwar; N. Maheshwari; S. Tallur,,,Precision Low Cost Phase Sensitive Optical Sensor for Detecting Carbon Nanoparticle Degradation,,,10.1109/ICSENS.2018.8589505 ,IEEE Conferences ,,"Phase sensitive detection (PSD) is a powerful technique to extract low amplitude signals from noisy data. Commercially available lock-in amplifiers that employ this technique are expensive and cost-prohibitive for several applications where accuracy is desired with low cost instrumentation. In this manuscript we present a novel dual switch based phase sensitive detection scheme to distinguish the contrast of a reflecting surface. The circuit is sensitive enough to distinguish various shades of gray colored (darkness) text printed on a sheet of regular printer paper, even in presence of high intensity background light. We report the measurement of concentration of a solution of carbon nanoparticles in water, with potential application as a toxicity sensor or biosensor for various enzymes that could cause degradation of carbon nanoparticles.",2168-9229,,978-1-5386-4707-3,1-3,IEEE , ,Carbon;Light emitting diodes;Optical sensors;Optical filters;Noise measurement;Optical switches;Nanoparticles,,
5016,"Title:Fruit Disease and Freshness Identification By Image Processing Method Using Raspberry Pi

 This article discusses a system that uses Raspberry PI to detect and prevent the spread of fruit illnesses. The k-avg cluster algorithm is used to analyse various images. It has several advantages for use in large agricultural farms and detects disease symptoms on fruit leaves immediately. The automatic detection of disease symptoms using image processing and the k-means cluster method is useful for tracking crops in the field of fungus and is thus an important research topic in fruit pharmaceutical research. The term “disease” refers to the type of fruit toxicity. This study presents the most effective method for identifying fruit diseases using image processing and alerting the system owner about the disease's cause by displaying the disease's name on the system owner's monitor display. Automatic disease symptom identification can help farmers improve their crops. These technologies, which are entirely automatic in their design and implementation, will be extremely useful in chemical applications. It will reduce the cost of pesticides and other goods. This will result in increased agricultural productivity.",M. S; N. S. Kumar; G. Chandrasekaran; V. K; N. Priyadarshi; T. Mahajan; N. Kumar,,,Fruit Disease and Freshness Identification By Image Processing Method Using Raspberry Pi,,,10.1109/SMARTGENCON56628.2022.10083880 ,IEEE Conferences ,,"This article discusses a system that uses Raspberry PI to detect and prevent the spread of fruit illnesses. The k-avg cluster algorithm is used to analyse various images. It has several advantages for use in large agricultural farms and detects disease symptoms on fruit leaves immediately. The automatic detection of disease symptoms using image processing and the k-means cluster method is useful for tracking crops in the field of fungus and is thus an important research topic in fruit pharmaceutical research. The term “disease” refers to the type of fruit toxicity. This study presents the most effective method for identifying fruit diseases using image processing and alerting the system owner about the disease's cause by displaying the disease's name on the system owner's monitor display. Automatic disease symptom identification can help farmers improve their crops. These technologies, which are entirely automatic in their design and implementation, will be extremely useful in chemical applications. It will reduce the cost of pesticides and other goods. This will result in increased agricultural productivity.",,,978-1-6654-5499-5,1-5,IEEE , ,Productivity;Toxicology;Costs;Image processing;Computational modeling;Crops;Clustering algorithms,,
5017,"Title:The Determination of Platinum in Human Tissues with PIXE

 Platinum levels as well as trace element concentrations in samples from cis-platin treated patients have been measured using the PIXE technique. The results were verified by neutron activation analysis for some elements. Spectral interferences of the platinum Lß peak and selenium Kα have been solved by introducing a germanium layer as a selective absorber. The experiments are done in the frame work of a project on the assesment of the toxicity of cytostatic platinum compounds. Preliminary results for liver, kidney and heart tissues are shown.",T. G. M. H. Dikhoff; J. A. van der Heide; M. Prins; J. G. Mc Vie,,,The Determination of Platinum in Human Tissues with PIXE,30,2,10.1109/TNS.1983.4332523 ,IEEE Journals ,,"Platinum levels as well as trace element concentrations in samples from cis-platin treated patients have been measured using the PIXE technique. The results were verified by neutron activation analysis for some elements. Spectral interferences of the platinum Lß peak and selenium Kα have been solved by introducing a germanium layer as a selective absorber. The experiments are done in the frame work of a project on the assesment of the toxicity of cytostatic platinum compounds. Preliminary results for liver, kidney and heart tissues are shown.",1558-1578,,,1329-1331,IEEE , ,Platinum;Humans;Liver;Medical treatment;Heart;Plasma measurements;Neutrons;Activation analysis;Yttrium;X-ray detection,,
5018,"Title:Automated design of microfluidics-based biochips: connecting biochemistry to electronics CAD

 Microfluidics-based biochips are soon expected to revolutionize laboratory procedures involving molecular biology. Advances in microfluidics technology offer exciting possibilities in the realm of enzymatic analysis, DNA analysis, proteomic analysis involving proteins and peptides, immuno-assays, and environmental toxicity monitoring. Another emerging application area for microfluidics-based biochips is clinical diagnostics, especially the immediate point-of-care diagnosis of diseases. As the use of microfluidics-based biochips increases, their complexity is expected to become significant due to the need for multiple and concurrent assays on the chip. There is a need to deliver the same level of computer-aided design (CAD) support to the biochip designer that the semiconductor industry now takes for granted. These CAD tools allow designers to harness the new technology that is rapidly emerging for integrated biofluidics. This paper presents early work on CAD tools that allow biochip users to describe bioassays at a sufficiently high level of abstraction. It describes synthesis tools that can map behavioral descriptions to a droplet-based microfluidic biochip and generate an optimized schedule of bioassay operations, the binding of assay operations to functional units, and the layout and droplet flow-paths for the biochip. Cost-effective testing techniques are presented to detect faults after manufacture and during field operation. It is shown how on-line and off-line reconfiguration techniques can be used to easily bypass faults once they are detected. Thus the biochip user can concentrate on the development of the nano- and micro-scale bioassays, leaving implementation details to design automation tools",K. Chakrabarty,,,Automated design of microfluidics-based biochips: connecting biochemistry to electronics CAD,,,10.1109/DTIS.2006.1708725 ,IEEE Conferences ,,"Microfluidics-based biochips are soon expected to revolutionize laboratory procedures involving molecular biology. Advances in microfluidics technology offer exciting possibilities in the realm of enzymatic analysis, DNA analysis, proteomic analysis involving proteins and peptides, immuno-assays, and environmental toxicity monitoring. Another emerging application area for microfluidics-based biochips is clinical diagnostics, especially the immediate point-of-care diagnosis of diseases. As the use of microfluidics-based biochips increases, their complexity is expected to become significant due to the need for multiple and concurrent assays on the chip. There is a need to deliver the same level of computer-aided design (CAD) support to the biochip designer that the semiconductor industry now takes for granted. These CAD tools allow designers to harness the new technology that is rapidly emerging for integrated biofluidics. This paper presents early work on CAD tools that allow biochip users to describe bioassays at a sufficiently high level of abstraction. It describes synthesis tools that can map behavioral descriptions to a droplet-based microfluidic biochip and generate an optimized schedule of bioassay operations, the binding of assay operations to functional units, and the layout and droplet flow-paths for the biochip. Cost-effective testing techniques are presented to detect faults after manufacture and during field operation. It is shown how on-line and off-line reconfiguration techniques can be used to easily bypass faults once they are detected. Thus the biochip user can concentrate on the development of the nano- and micro-scale bioassays, leaving implementation details to design automation tools",,,0-7803-9726-6,2-2,IEEE , ,Joining processes;Biochemistry;Design automation;Microfluidics;Fault detection;Laboratories;DNA;Proteomics;Proteins;Peptides,,
5019,"Title:Validation Methods for Cell Cycle Analysis Algorithms in Confocal Fluorescence Images

 Automated analysis of live cells over extended time periods requires both novel assays and automated image analysis algorithms. Among other applications, this is necessary for studying the effect of inhibitor compounds that are designed to block the replication of cancerous cells. Due to their toxicity, fluorescent dyes that bind to the nuclear DNA cannot be used to mark nuclei, and traditional non-toxic nuclear markers do not yield information about the cell cycle phases. Instead, a non-toxic cell cycle phase marker can be used. We previously described a set of image analysis methods designed to automatically segment nuclei in such 2D time-lapse images. While the methods show promise, it is necessary to provide a validation framework for these methods. This paper introduces methods for validating the various stages of the algorithm in order to demonstrate their viability for automatic cell cycle analysis",D. Padfield; J. Rittscher; N. Thomas; B. Roysam,,,Validation Methods for Cell Cycle Analysis Algorithms in Confocal Fluorescence Images,,,10.1109/LSSA.2006.250406 ,IEEE Conferences ,,"Automated analysis of live cells over extended time periods requires both novel assays and automated image analysis algorithms. Among other applications, this is necessary for studying the effect of inhibitor compounds that are designed to block the replication of cancerous cells. Due to their toxicity, fluorescent dyes that bind to the nuclear DNA cannot be used to mark nuclei, and traditional non-toxic nuclear markers do not yield information about the cell cycle phases. Instead, a non-toxic cell cycle phase marker can be used. We previously described a set of image analysis methods designed to automatically segment nuclei in such 2D time-lapse images. While the methods show promise, it is necessary to provide a validation framework for these methods. This paper introduces methods for validating the various stages of the algorithm in order to demonstrate their viability for automatic cell cycle analysis",,,1-4244-0277-8,1-2,IEEE , ,Image analysis;Algorithm design and analysis;Fluorescence;Image segmentation;Inhibitors;DNA;Level set;Image edge detection;Cancer;Genetics,,
5020,"Title:A center location algorithm used in cells microscopic image

 Using microscopy technology to analysis human cells is an important method for pathological study, diagnostic etc. As a pioneering imaging technology, the microscopy has many advantages: reduced photo toxicity and photo bleaching as well as enhanced imaging penetration depth. There are many center location methods for cells microscopic image. However, location results of these methods cannot meet the requirements of precision analysis. In this paper, We present a novel algorithm to locate cell nucleus in microscopic image. Our method consists of the following components: Firstly, to improve robustness of the algorithm the initial segmented regions are obtained by using Otsu method. Secondly, in order to improve accuracy of location results, the random sample consensus (RANSAC) method is used to eliminate exterior point after find the minimum bounding circle of cells. Finally, an ellipse fitting method is introduced to get the location of cell nucleus. Experiments on challenging microscopic images show that the proposed algorithm performs favorably against several state-of-the-art methods.",P. Hui; J. Sun; D. Xue; C. Ding; Y. Zhang,,,A center location algorithm used in cells microscopic image,,,10.1109/ICOT.2016.8278971 ,IEEE Conferences ,,"Using microscopy technology to analysis human cells is an important method for pathological study, diagnostic etc. As a pioneering imaging technology, the microscopy has many advantages: reduced photo toxicity and photo bleaching as well as enhanced imaging penetration depth. There are many center location methods for cells microscopic image. However, location results of these methods cannot meet the requirements of precision analysis. In this paper, We present a novel algorithm to locate cell nucleus in microscopic image. Our method consists of the following components: Firstly, to improve robustness of the algorithm the initial segmented regions are obtained by using Otsu method. Secondly, in order to improve accuracy of location results, the random sample consensus (RANSAC) method is used to eliminate exterior point after find the minimum bounding circle of cells. Finally, an ellipse fitting method is introduced to get the location of cell nucleus. Experiments on challenging microscopic images show that the proposed algorithm performs favorably against several state-of-the-art methods.",,,978-1-5386-4831-5,28-31,IEEE , ,Microscopy;Fitting;Image segmentation;Mathematical model;Image edge detection;Robustness;Algorithm design and analysis,,
5021,"Title:A comparison between PLSR, SVMR and NARX network for the mint treatment day prediction based on multisensor system

 The ability to distinguish between edible aromatic plants treated with insecticides holds the attention of researchers in view of the toxicity of insecticides in human health. The malathion has a distinctive smell it an insecticide widely used to protect mint crops. In the present paper, three regression and artificial intelligence (AI)-based methods such as partial least squares (PLS) regression, support vector machine (SVM) regression, and the nonlinear autoregressive with exogenous input (NARX) were investigated to predict the mint treatment day with malathion. The data used in this work are collected using a multi-sensor system designed based on commercial gas sensors. In this case, the nonlinear autoregressive with exogenous input (NARX) was found the most effective achieving a correlation coefficient (R) of 0.99 with a very minimal mean squared error (MSE) of about 1.10288e-14. Thanks to the right choice of the appropriate algorithm, the mint treatment day could be predicted with a simple multisensor gas array.",A. Amkor; N. E. Barbri; K. Maaider,,,"A comparison between PLSR, SVMR and NARX network for the mint treatment day prediction based on multisensor system",,,10.1109/ICOA51614.2021.9442652 ,IEEE Conferences ,,"The ability to distinguish between edible aromatic plants treated with insecticides holds the attention of researchers in view of the toxicity of insecticides in human health. The malathion has a distinctive smell it an insecticide widely used to protect mint crops. In the present paper, three regression and artificial intelligence (AI)-based methods such as partial least squares (PLS) regression, support vector machine (SVM) regression, and the nonlinear autoregressive with exogenous input (NARX) were investigated to predict the mint treatment day with malathion. The data used in this work are collected using a multi-sensor system designed based on commercial gas sensors. In this case, the nonlinear autoregressive with exogenous input (NARX) was found the most effective achieving a correlation coefficient (R) of 0.99 with a very minimal mean squared error (MSE) of about 1.10288e-14. Thanks to the right choice of the appropriate algorithm, the mint treatment day could be predicted with a simple multisensor gas array.",,,978-1-6654-4103-2,1-5,IEEE , ,Support vector machines;Correlation coefficient;Toxicology;Prediction algorithms;Agriculture;Artificial intelligence;Optimization,,
5022,"Title:A Portable Ultra-low-cost Multi-Gas Sensing System-on-Module for Wireless Air Quality Monitoring Network

 Air pollution is a major problem in cities around the world. It poses a serious threat to human health and the environment. A low-cost sensing infrastructure is essential for real-time monitoring of ambient air quality. We introduce an ultra-low-cost portable sensing device that can monitor multiple air pollutants like NO2, O3 and Particulate Matter (PM). Chronic exposure to these gases causes serious health concerns. We propose to use an integrated microcontroller and a sub-1 GHz transceiver chip to significantly reduce the cost and power consumption of the sensing device. It is a portable device with a small form factor of $15 \times 11 \times 5$ cm3, costing less than US$ 250 and consuming approx 100 mW of power. The sensing devices equipped with wireless networking capabilities can form a dense network and assist in examining the toxicity of air.",A. Sharma; S. Divekar; R. Zele,,,A Portable Ultra-low-cost Multi-Gas Sensing System-on-Module for Wireless Air Quality Monitoring Network,,,10.1109/VLSID57277.2023.00062 ,IEEE Conferences ,,"Air pollution is a major problem in cities around the world. It poses a serious threat to human health and the environment. A low-cost sensing infrastructure is essential for real-time monitoring of ambient air quality. We introduce an ultra-low-cost portable sensing device that can monitor multiple air pollutants like NO2, O3 and Particulate Matter (PM). Chronic exposure to these gases causes serious health concerns. We propose to use an integrated microcontroller and a sub-1 GHz transceiver chip to significantly reduce the cost and power consumption of the sensing device. It is a portable device with a small form factor of $15 \times 11 \times 5$ cm3, costing less than US$ 250 and consuming approx 100 mW of power. The sensing devices equipped with wireless networking capabilities can form a dense network and assist in examining the toxicity of air.",2380-6923,,979-8-3503-4678-7,270-273,IEEE , ,Wireless communication;Wireless sensor networks;Costs;Power demand;Very large scale integration;Air pollution;Transceivers,,
5023,"Title:Non-Contact Photoacoustic Lipid Imaging by Remote Sensing on First Overtone of C-H Bond

 As one of the most central kind of biomolecules under interest, lipids perform versatile roles in metabolism, structural maintenance, energy conservation as well as signal transmission [1]. Many techniques are developed and employed for lipids studies, including but not limited to lipophilic dyeing, mass spectroscopy, fluorescent and Raman microscopy et al [2]. However, these examinations of lipids hinge on biopsy invasion or external labeling, which demands complex sample preparation procedures and might incur toxicity or changes in metabolic conditions. Hence, a label-free and non-invasive imaging modality is desired for biomedical lipid studies, which eliminates biosafety concerns and allows easy implementation.",G. Hu; X. Dong; Y. Zhou; J. Kang; K. K. Y. Wong,,,Non-Contact Photoacoustic Lipid Imaging by Remote Sensing on First Overtone of C-H Bond,,,10.1109/CLEO/Europe-EQEC57999.2023.10231573 ,IEEE Conferences ,,"As one of the most central kind of biomolecules under interest, lipids perform versatile roles in metabolism, structural maintenance, energy conservation as well as signal transmission [1]. Many techniques are developed and employed for lipids studies, including but not limited to lipophilic dyeing, mass spectroscopy, fluorescent and Raman microscopy et al [2]. However, these examinations of lipids hinge on biopsy invasion or external labeling, which demands complex sample preparation procedures and might incur toxicity or changes in metabolic conditions. Hence, a label-free and non-invasive imaging modality is desired for biomedical lipid studies, which eliminates biosafety concerns and allows easy implementation.",2833-1052,,979-8-3503-4599-5,1-1,IEEE , ,Toxicology;Transmission electron microscopy;Microscopy;Molecular biophysics;Maintenance engineering;Lipidomics;Mass spectroscopy,,
5024,"Title:Cloud enabled air quality detection, analysis and prediction - A smart city application for smart health

 The work proposes a cloud based air quality detection system that analyzes the data for providing atmospheric quality to the user in real time. The data, collected through various gas sensors deployed outdoors in strategic locations across the city of Manipal, Karnataka is sent to the cloud via an adaptive interface that supports 2G/3G/4G infrastructure. Also, a live feed of Closed-circuit Television (CCTV) footage of some strategic locations of Manipal's road traffic is sent to the cloud for analysing the density of pollutants in air with respect to the road traffic. In addition to this, the database from the Regional Transport Office (RTO) and the Computerized Pollution Check Centres of Manipal provide a basis for a comparative analysis of the variances in the spectrum of emissions from vehicles and sensor-based data coming from strategic locations. This combination along with the knowledge of the geographic and industrial properties of the area will help analyse the data for finding patterns in air quality in a particular time interval. The proposed model will then be able to predict the air quality for future days. A web and mobile application interface will help the users to check and understand the air quality at their current location. The mobile application will also notify the user about severe toxicity. People with respiratory problems will be able to get personalized notifications for poor conditions.",Y. Mehta; M. M. Manohara Pai; S. Mallissery; S. Singh,,,"Cloud enabled air quality detection, analysis and prediction - A smart city application for smart health",,,10.1109/ICBDSC.2016.7460380 ,IEEE Conferences ,,"The work proposes a cloud based air quality detection system that analyzes the data for providing atmospheric quality to the user in real time. The data, collected through various gas sensors deployed outdoors in strategic locations across the city of Manipal, Karnataka is sent to the cloud via an adaptive interface that supports 2G/3G/4G infrastructure. Also, a live feed of Closed-circuit Television (CCTV) footage of some strategic locations of Manipal's road traffic is sent to the cloud for analysing the density of pollutants in air with respect to the road traffic. In addition to this, the database from the Regional Transport Office (RTO) and the Computerized Pollution Check Centres of Manipal provide a basis for a comparative analysis of the variances in the spectrum of emissions from vehicles and sensor-based data coming from strategic locations. This combination along with the knowledge of the geographic and industrial properties of the area will help analyse the data for finding patterns in air quality in a particular time interval. The proposed model will then be able to predict the air quality for future days. A web and mobile application interface will help the users to check and understand the air quality at their current location. The mobile application will also notify the user about severe toxicity. People with respiratory problems will be able to get personalized notifications for poor conditions.",,,978-1-4673-9584-7,1-7,IEEE , ,Monitoring;Air pollution;Real-time systems;Wireless sensor networks;Vehicles;Cloud computing,,
5025,"Title:Insect Detection on an Unmanned Ground Rover

 Crop losses and damages caused by insects and pests negatively impact nations' economies worldwide, particularly in agricultural producing countries. Farmers struggling to maintain both the product yield and profit as well as to make ends meet often resort to the apparently easy solution of using insecticides. A health hazard, exposure to chemical pesticides, may result in acute poisoning and long-term chronic toxicity. Applying information technology to contribute to agricultural innovation, we propose an approach to detect the presence of flying insects and to monitor insect populations in an open field. Simple yet effective computer vision and image processing techniques are employed. Moving objects in the scenes are detected, then classified whether or not they are flying insects. Instead of requiring an installation of either equipment and tools or electronic sensors in and around the field, our small-sized video-camera is mounted on a remotely controlled big-rock crawler. A user only needs to specify a search area of interest and point out locations over where the rover cannot go. The system then runs a path finding algorithm to lay out a mission, which the rover is programmed to execute unmanned. In our experiment, the rover successfully followed a desired mission. Its accuracy was evaluated and the effects of terrain conditions were analyzed. The fully-integrated system has achieved an insect detection accuracy of 89.43%.",A. Srisuphab; P. Silapachote; W. Tantratorn; P. Krakornkul; P. Darote,,,Insect Detection on an Unmanned Ground Rover,,,10.1109/TENCON.2018.8650312 ,IEEE Conferences ,,"Crop losses and damages caused by insects and pests negatively impact nations' economies worldwide, particularly in agricultural producing countries. Farmers struggling to maintain both the product yield and profit as well as to make ends meet often resort to the apparently easy solution of using insecticides. A health hazard, exposure to chemical pesticides, may result in acute poisoning and long-term chronic toxicity. Applying information technology to contribute to agricultural innovation, we propose an approach to detect the presence of flying insects and to monitor insect populations in an open field. Simple yet effective computer vision and image processing techniques are employed. Moving objects in the scenes are detected, then classified whether or not they are flying insects. Instead of requiring an installation of either equipment and tools or electronic sensors in and around the field, our small-sized video-camera is mounted on a remotely controlled big-rock crawler. A user only needs to specify a search area of interest and point out locations over where the rover cannot go. The system then runs a path finding algorithm to lay out a mission, which the rover is programmed to execute unmanned. In our experiment, the rover successfully followed a desired mission. Its accuracy was evaluated and the effects of terrain conditions were analyzed. The fully-integrated system has achieved an insect detection accuracy of 89.43%.",2159-3450,,978-1-5386-5457-6,954-0959,IEEE , ,Insects;Global Positioning System;IEEE Regions;Conferences;Image processing;Sensors;Crawlers,,
5026,"Title:Estimating Conditional Probabilities for the Detection of Unfavorable Copy Number Alterations in a Targeted Therapy

 Emerging targeted therapies have shown benefits such as less toxicity and higher effectiveness in specific types of cancer treatment; however, the accessibility of these advantages may rely on correct identification of suitable patients, which remains highly immature. We assume that copy number profiles, being accessible genomic data via microarray techniques, can provide useful information regarding drug response and shed light on personalized therapy. Based on the mechanism of action (MOA) of trastuzumab in the HER2 signaling pathway, a Bayesian network model in which copy number alterations (CNAs) serve as latent parents modifying signal transduction is applied. Two model parameters M-score and R -value which stand for the qualitative and quantitative effects of CNAs on drug effectiveness and are functions of conditional probabilities (CPs), are defined. An expectation-maximization (EM) algorithm is developed for estimating CPs, M-scores, and R-values from continuous measures, such as microarray data. We show through simulations that the EM algorithm can outperform classical threshold-based methods in the estimation of CPs and thereby provide improved performance for the detection of unfavorable CNAs. Several candidates of unfavorable CNAs to the trastuzumab therapy in breast cancer are provided in a real data example.",F. -H. Hsu; E. R. Dougherty; Y. Chen; E. Serpedin,,,Estimating Conditional Probabilities for the Detection of Unfavorable Copy Number Alterations in a Targeted Therapy,60,10,10.1109/TBME.2013.2266356 ,IEEE Journals ,,"Emerging targeted therapies have shown benefits such as less toxicity and higher effectiveness in specific types of cancer treatment; however, the accessibility of these advantages may rely on correct identification of suitable patients, which remains highly immature. We assume that copy number profiles, being accessible genomic data via microarray techniques, can provide useful information regarding drug response and shed light on personalized therapy. Based on the mechanism of action (MOA) of trastuzumab in the HER2 signaling pathway, a Bayesian network model in which copy number alterations (CNAs) serve as latent parents modifying signal transduction is applied. Two model parameters M-score and R -value which stand for the qualitative and quantitative effects of CNAs on drug effectiveness and are functions of conditional probabilities (CPs), are defined. An expectation-maximization (EM) algorithm is developed for estimating CPs, M-scores, and R-values from continuous measures, such as microarray data. We show through simulations that the EM algorithm can outperform classical threshold-based methods in the estimation of CPs and thereby provide improved performance for the detection of unfavorable CNAs. Several candidates of unfavorable CNAs to the trastuzumab therapy in breast cancer are provided in a real data example.",1558-2531,,,2933-2942,IEEE , ,Drugs;Bayes methods;Gene expression;Cancer;Estimation;Tumors,,
5027,"Title:A new digital analyzer for optically detected samples in Digital Microfluidic Biochips

 Electrowetting based digital microfluidic biochips are developed recently as an alternative platform for conventional laboratory methods in advanced biochemical applications. With the advantages of portability, cost minimization, higher precision combined with better throughput - these devices are finding increasing applications in the areas of point of care diagnostics, parallel immunoassays, drug design, DNA sequencing as well as environmental toxicity monitoring and others. Advanced design automation strategies are developed to facilitate multiple bioassay operation to be enabled simultaneously on a single microfluidic biochip. On completion of these Bioassay protocols the detection is enabled at the optical detection sites within the chip area itself. In this work we have proposed a unique design of an automated droplet detection analyzer to be coupled with the targeted biochip for providing detailed analysis result based on the data acquired through optical detection. This newly proposed design not only enables the detection analysis of samples based on predefined characterized results - but also enhances the process of integration of multiple biochips to perform different set of test sequences on different biochips on the basis of these analysis results obtained in the proposed analyzer. The architecture, synthesis and simulation of the proposed droplet analyzer for signals obtained from Blood oxygen analysis, each for multiple samples in a single biochip has been displayed in this paper - and the results are found to be quite encouraging.",P. Roy; S. Chakraborty; M. Sohid; H. Rahaman; P. Dasgupta,,,A new digital analyzer for optically detected samples in Digital Microfluidic Biochips,,,10.1109/MWSCAS.2012.6292057 ,IEEE Conferences ,,"Electrowetting based digital microfluidic biochips are developed recently as an alternative platform for conventional laboratory methods in advanced biochemical applications. With the advantages of portability, cost minimization, higher precision combined with better throughput - these devices are finding increasing applications in the areas of point of care diagnostics, parallel immunoassays, drug design, DNA sequencing as well as environmental toxicity monitoring and others. Advanced design automation strategies are developed to facilitate multiple bioassay operation to be enabled simultaneously on a single microfluidic biochip. On completion of these Bioassay protocols the detection is enabled at the optical detection sites within the chip area itself. In this work we have proposed a unique design of an automated droplet detection analyzer to be coupled with the targeted biochip for providing detailed analysis result based on the data acquired through optical detection. This newly proposed design not only enables the detection analysis of samples based on predefined characterized results - but also enhances the process of integration of multiple biochips to perform different set of test sequences on different biochips on the basis of these analysis results obtained in the proposed analyzer. The architecture, synthesis and simulation of the proposed droplet analyzer for signals obtained from Blood oxygen analysis, each for multiple samples in a single biochip has been displayed in this paper - and the results are found to be quite encouraging.",1558-3899,,978-1-4673-2527-1,462-465,IEEE , ,Microfluidics;Biomedical optical imaging;Optical sensors;Computer architecture;Blood;Electrodes;Microprocessors,,
5028,"Title:Prediction of anorexic person from “thin” or “ dieting” patient via neural network: BPNN Detecting Anorexia

 Anorexia nervosa is a quiet dangerous disease that detected in an early stage may save the patient life and flushes his veins with “passion-red blood” pumping happiness and hope with every heartbeat. A study based on back propagation neural network giving machines the ability to mimic the human function to detect a “haunted person by anorexia “ from a person obsessed by “looking “wow” as a model under spot lights”. This study was based on the assessment of several factors including the concentration of several defined ions: zinc, iron, magnesium, calcium, copper and manganese (Zn, Fe, Mg, Cu, Ca, and Mn). Alteration in these ions concentration may lead to deficiency or toxicity leading to severe disease including anorexia. The intake of these ions may be appropriately pioneered by healthy diet food that is eradicated in anorexia disorder. Other factors playing a crucial role in developing this “ghost-eating disorder” are gender and age. A predictive BPNN system was developed based on these factors to help predicting an anorexic person in early stage to deter him from barring himself into his grave.",R. E. Ahdab,,,Prediction of anorexic person from “thin” or “ dieting” patient via neural network: BPNN Detecting Anorexia,,,10.1109/ICABME.2015.7323237 ,IEEE Conferences ,,"Anorexia nervosa is a quiet dangerous disease that detected in an early stage may save the patient life and flushes his veins with “passion-red blood” pumping happiness and hope with every heartbeat. A study based on back propagation neural network giving machines the ability to mimic the human function to detect a “haunted person by anorexia “ from a person obsessed by “looking “wow” as a model under spot lights”. This study was based on the assessment of several factors including the concentration of several defined ions: zinc, iron, magnesium, calcium, copper and manganese (Zn, Fe, Mg, Cu, Ca, and Mn). Alteration in these ions concentration may lead to deficiency or toxicity leading to severe disease including anorexia. The intake of these ions may be appropriately pioneered by healthy diet food that is eradicated in anorexia disorder. Other factors playing a crucial role in developing this “ghost-eating disorder” are gender and age. A predictive BPNN system was developed based on these factors to help predicting an anorexic person in early stage to deter him from barring himself into his grave.",2377-5696,,978-1-4673-6516-1,5-8,IEEE , ,Biological neural networks;Training;Diseases;Testing;Zinc;Neurons;Ions,,
5029,"Title:Forensic Determination of Toxication of Strychnos Nuxvomica

 Strychnos nux-vomica has been used as a poisonous raw material for the preparation of Chinese medicinal herb for thousands of years in China, it is required that the herb should be specially processed before being put into clinical use. Since its treatment dosage is very close to its toxic dosage, poisoning frequently take place due to misuse, brucine and its derivatives are the principal component responsible for its pharmacodynamic effect and toxicity, strychnine is main component responsible for its toxicity. Both strychnine and brucine are typical antagonists of the glycine receptors on postsynatic membrane. Its toxic effects are mainly to cause central excitation. Because of its strong toxicity, narrow safety range and cumulative effect, the use of the drug in the clinical practice tends to cause poisoning, and poisoning of the drug is associated with the large dosage, and/or the long time use. Its toxicity also varies with its origins of production or batches. The symptoms of strychnos nuxvomica poisoning vary. The autopsy findings mainly include pathological changes caused by acute disorder of blood circulation, characterized by the congestion and edema of organs or pinpoint bleeding of mucosa or serous membrane. Long-term toxicity test revealed no characteristic pathological changes of vital organs in animals. For the detection of poisonous substances, the stomach tissue or stomach contents are the best choices, and urine, intestinal contents are the next best materials. Liver, brain and spinal medulla also have high level of strychnos nuxvomica after poisioning. In the forensic identification of strychnos nuxvomica poisoning, it is important to eliminate the other death causes, than get sufficient information concerning the source of the herb (variety, batch, origin of the product), the physical condition (metabolic status) of the patients or victim, dosage, and take the symptoms, pathological changes into consideration. Because of its accumulation, the possibility of the drug being given multiple-times and in small-dose should be considered. The detection of strychnos nuxvomica and quantitative analysis is essential and most reliable in the identification of strychnos nuxvomica poisoning. Exceptionally, great care should be exercised to differentiate it from the intoxication of tetra mine, fumarin and armazide and other spasm-causing agents.",X. -j. Shu; W. Liu; S. -x. Zhu,,,Forensic Determination of Toxication of Strychnos Nuxvomica,,,10.1109/iCBEB.2012.226 ,IEEE Conferences ,,"Strychnos nux-vomica has been used as a poisonous raw material for the preparation of Chinese medicinal herb for thousands of years in China, it is required that the herb should be specially processed before being put into clinical use. Since its treatment dosage is very close to its toxic dosage, poisoning frequently take place due to misuse, brucine and its derivatives are the principal component responsible for its pharmacodynamic effect and toxicity, strychnine is main component responsible for its toxicity. Both strychnine and brucine are typical antagonists of the glycine receptors on postsynatic membrane. Its toxic effects are mainly to cause central excitation. Because of its strong toxicity, narrow safety range and cumulative effect, the use of the drug in the clinical practice tends to cause poisoning, and poisoning of the drug is associated with the large dosage, and/or the long time use. Its toxicity also varies with its origins of production or batches. The symptoms of strychnos nuxvomica poisoning vary. The autopsy findings mainly include pathological changes caused by acute disorder of blood circulation, characterized by the congestion and edema of organs or pinpoint bleeding of mucosa or serous membrane. Long-term toxicity test revealed no characteristic pathological changes of vital organs in animals. For the detection of poisonous substances, the stomach tissue or stomach contents are the best choices, and urine, intestinal contents are the next best materials. Liver, brain and spinal medulla also have high level of strychnos nuxvomica after poisioning. In the forensic identification of strychnos nuxvomica poisoning, it is important to eliminate the other death causes, than get sufficient information concerning the source of the herb (variety, batch, origin of the product), the physical condition (metabolic status) of the patients or victim, dosage, and take the symptoms, pathological changes into consideration. Because of its accumulation, the possibility of the drug being given multiple-times and in small-dose should be considered. The detection of strychnos nuxvomica and quantitative analysis is essential and most reliable in the identification of strychnos nuxvomica poisoning. Exceptionally, great care should be exercised to differentiate it from the intoxication of tetra mine, fumarin and armazide and other spasm-causing agents.",,,978-0-7695-4706-0,1482-1485,IEEE , ,Forensics;Blood;Pathology;Drugs;Muscles;Educational institutions;Raw materials,,
5030,"Title:Overview of image processing approach for nutrient deficiencies detection in Elaeis Guineensis

 The most common problems occurred in Elaeis Guineensis or widely known as oil palm are plant diseases and pest outbreaks. The diseased oil palm plants normally shows a range of symptoms such as coloured spots or streaks that will occur on the leaves, stems, and seeds of the plant. At present, in the agricultural sectors, diagnosing the type disease of plants are based on human expert, which is alongside with the conventional method applied using test device and performing laboratory test. Therefore, the needs in new approach to classify type of diseases are preferable. Hence, the aim of this paper is to focus on an innovative method based on image processing technique for classifying the lack of nutritional disease occurred in oil palm leaves by analyzing the leave surface only. The result is usable as a guide for fertilization since the trees respond rapidly to the applied fertilizers. The main important concern is to ensure the sufficient amount of fertilizer since excessive intake of fertilizers will cause toxicity to trees and indirectly increase cost of fertilizers. Images of oil palm leaves will be captured using high-end digital imaging device to analyse the leaves surface. Further, feature extraction algorithms also will develop based on shape, texture, and colour of the disease type. The feature vectors will be attained acting as inputs to fuzzy classifier. Overall, the proposed method will benefit the oil palm industries to fulfill the industry demand.",Muhammad Asraf Hairuddin; N. Md Tahir; Shah Rizam Shah Baki,,,Overview of image processing approach for nutrient deficiencies detection in Elaeis Guineensis,,,10.1109/ICSEngT.2011.5993432 ,IEEE Conferences ,,"The most common problems occurred in Elaeis Guineensis or widely known as oil palm are plant diseases and pest outbreaks. The diseased oil palm plants normally shows a range of symptoms such as coloured spots or streaks that will occur on the leaves, stems, and seeds of the plant. At present, in the agricultural sectors, diagnosing the type disease of plants are based on human expert, which is alongside with the conventional method applied using test device and performing laboratory test. Therefore, the needs in new approach to classify type of diseases are preferable. Hence, the aim of this paper is to focus on an innovative method based on image processing technique for classifying the lack of nutritional disease occurred in oil palm leaves by analyzing the leave surface only. The result is usable as a guide for fertilization since the trees respond rapidly to the applied fertilizers. The main important concern is to ensure the sufficient amount of fertilizer since excessive intake of fertilizers will cause toxicity to trees and indirectly increase cost of fertilizers. Images of oil palm leaves will be captured using high-end digital imaging device to analyse the leaves surface. Further, feature extraction algorithms also will develop based on shape, texture, and colour of the disease type. The feature vectors will be attained acting as inputs to fuzzy classifier. Overall, the proposed method will benefit the oil palm industries to fulfill the industry demand.",,,978-1-4577-1255-5,116-120,IEEE , ,Image color analysis;Nitrogen;Diseases;Fertilizers;Vegetation;Feature extraction,,
5031,"Title:Cyberbullying Detection using LSTM-CNN architecture and its applications

 In the present information age, there's been an increase in the use of social media, as a result, there have been multiple cyberbullying instances. To prevent or reduce cyberbullying, many existing approaches in the literature incorporate normal Machine Learning and Natural Language Processing text classification models without considering the sentence semantics. In this paper, we aim to target that issue. We have used word2vec to train our custom word embeddings upon which we built our LSTM - CNN architecture and finally it was trained on it. We made a comparative study of the above approaches by testing our model on Twitter posts and comments. The eminent performance achieved by our method has been observed in this study. We also created a web application that used the model to classify tweets as cyberbullying or not based on the toxicity score along with various features. The model was also implemented on Telegram Bot which is used to check and prevent cyberbullying. Two Chrome Extensions were built to redact and retract Not Safe For Work (NSFW) content and prevent cyberbullying on WhatsApp Web. We have been able to achieve excellent performance in the form of a 97% ROC AUC score for our model.",M. Gada; K. Damania; S. Sankhe,,,Cyberbullying Detection using LSTM-CNN architecture and its applications,,,10.1109/ICCCI50826.2021.9402412 ,IEEE Conferences ,,"In the present information age, there's been an increase in the use of social media, as a result, there have been multiple cyberbullying instances. To prevent or reduce cyberbullying, many existing approaches in the literature incorporate normal Machine Learning and Natural Language Processing text classification models without considering the sentence semantics. In this paper, we aim to target that issue. We have used word2vec to train our custom word embeddings upon which we built our LSTM - CNN architecture and finally it was trained on it. We made a comparative study of the above approaches by testing our model on Twitter posts and comments. The eminent performance achieved by our method has been observed in this study. We also created a web application that used the model to classify tweets as cyberbullying or not based on the toxicity score along with various features. The model was also implemented on Telegram Bot which is used to check and prevent cyberbullying. Two Chrome Extensions were built to redact and retract Not Safe For Work (NSFW) content and prevent cyberbullying on WhatsApp Web. We have been able to achieve excellent performance in the form of a 97% ROC AUC score for our model.",2329-7190,,978-1-7281-5875-4,1-6,IEEE , ,Freeware;Toxicology;Social networking (online);Blogs;Text categorization;Internet telephony;Testing,,
5032,"Title:Detection and management of side effects in patients with head and neck cancer

 Concurrent chemoradiotherapy (CCRT) is a very effective treatment for head and neck cancer, but it can cause severe acute toxicity; therefore, home patients undergoing CCRT have to be continuously monitored. To this purpose, we already developed a mobile application (app), addressed to patients, whose configuration concerning the data to be monitored can be decided by the oncologists in order to meet the specific patients' needs. The app regularly sends data to the hospital server for monitoring purposes, where they are visualized by the staff to undertake the required actions. In this paper, we propose to add a guideline-based decision support system to the architecture and we explain its components from a technical point of view. This system is able to help doctors with the app configuration and, more in general, with the prevention, diagnosis and treatment of CCRT side effects.",E. M. Zini; G. Lanzola; S. Quaglini,,,Detection and management of side effects in patients with head and neck cancer,,,10.1109/RTSI.2017.8065888 ,IEEE Conferences ,,"Concurrent chemoradiotherapy (CCRT) is a very effective treatment for head and neck cancer, but it can cause severe acute toxicity; therefore, home patients undergoing CCRT have to be continuously monitored. To this purpose, we already developed a mobile application (app), addressed to patients, whose configuration concerning the data to be monitored can be decided by the oncologists in order to meet the specific patients' needs. The app regularly sends data to the hospital server for monitoring purposes, where they are visualized by the staff to undertake the required actions. In this paper, we propose to add a guideline-based decision support system to the architecture and we explain its components from a technical point of view. This system is able to help doctors with the app configuration and, more in general, with the prevention, diagnosis and treatment of CCRT side effects.",,,978-1-5386-3906-1,1-6,IEEE , ,Guidelines;Cancer;Head;Neck;Decision support systems;Medical treatment,,
5033,"Title:Small Single Board Computers based Smart Manhole Monitoring and Detection System

 Accidents now frequently culminate from missing or broken maintenance manhole covers. In developing countries, maintenance holes receive insufficient care. Both fatalities and serious injuries may result from incidents of this nature. This research study provides a solution to this problem. Several sensors are coordinated to screen the sewage vent cap and prevent similar incidents thoroughly. This recommended solution includes a gas cover to keep track of the gas’s toxicity that the sewage systems discharge. A tilt sensor also shows whether the maintenance hole may tilt. A float sensor also alerts individuals when the water level rises too high. If any parameters cause an alert, they SMS a selected municipal corporation mobile number and upload it on the IOT website. Also, all parameters are regularly updated on the webpage. The suggested real-time, cost-effective, and low-maintenance IoT system is a maintenance hole that alerts the management station when it exceeds specific threshold values. Not only does this technology help the general population, but it also reduces the death risk for people who manually clean underground drainage.",N. Vikram; R. Raman; J. J. Babu; E. Srividhya,,,Small Single Board Computers based Smart Manhole Monitoring and Detection System,,,10.1109/ICESC57686.2023.10193117 ,IEEE Conferences ,,"Accidents now frequently culminate from missing or broken maintenance manhole covers. In developing countries, maintenance holes receive insufficient care. Both fatalities and serious injuries may result from incidents of this nature. This research study provides a solution to this problem. Several sensors are coordinated to screen the sewage vent cap and prevent similar incidents thoroughly. This recommended solution includes a gas cover to keep track of the gas’s toxicity that the sewage systems discharge. A tilt sensor also shows whether the maintenance hole may tilt. A float sensor also alerts individuals when the water level rises too high. If any parameters cause an alert, they SMS a selected municipal corporation mobile number and upload it on the IOT website. Also, all parameters are regularly updated on the webpage. The suggested real-time, cost-effective, and low-maintenance IoT system is a maintenance hole that alerts the management station when it exceeds specific threshold values. Not only does this technology help the general population, but it also reduces the death risk for people who manually clean underground drainage.",,,979-8-3503-0009-3,234-239,IEEE , ,Temperature sensors;Temperature measurement;Toxicology;Vents;Urban areas;Maintenance engineering;Real-time systems,,
5034,"Title:Predicting radiation protection and toxicity of p53 targeting radioprotectors using machine learning

 This paper explores machine learning application in the case of drug discovery. We apply extreme gradient boosting and K-nearest neighbor to biomedical data and it signiflcantly outperform former studies using feature selection and proper tuning parameters. The novel application motivated by a recent circumstance that there is a need for rapid development of radio-protectors. It mainly targets the DNA of growing cancer cells, whereas it has adverse side effects, including p53-induced apoptosis of normal tissues and cells. It considered that p53 would be a target for therapeutic and mitigated radioprotection to escape from the apoptotic fate. On the other hand, many types of compounds contain several level of toxicity, so it is important to consider not only radiation protection but also the level of toxicity of candidate compounds for radioprotectors. Compounds of radio-protectors that have low toxicity and high radiation protection are expected. It is possible to do efficiently the compounds discovery using machine learning. This study predicts compounds of radioprotectors using plural machine learning methods, Extreme Gradient Boosting, K-nearest neighbor, SVM and Random Forest. We compare these methods and suggest proper methods to predict radioprotectors.",M. Kimura; S. Aoki; H. Ohwada,,,Predicting radiation protection and toxicity of p53 targeting radioprotectors using machine learning,,,10.1109/CIBCB.2017.8058540 ,IEEE Conferences ,,"This paper explores machine learning application in the case of drug discovery. We apply extreme gradient boosting and K-nearest neighbor to biomedical data and it signiflcantly outperform former studies using feature selection and proper tuning parameters. The novel application motivated by a recent circumstance that there is a need for rapid development of radio-protectors. It mainly targets the DNA of growing cancer cells, whereas it has adverse side effects, including p53-induced apoptosis of normal tissues and cells. It considered that p53 would be a target for therapeutic and mitigated radioprotection to escape from the apoptotic fate. On the other hand, many types of compounds contain several level of toxicity, so it is important to consider not only radiation protection but also the level of toxicity of candidate compounds for radioprotectors. Compounds of radio-protectors that have low toxicity and high radiation protection are expected. It is possible to do efficiently the compounds discovery using machine learning. This study predicts compounds of radioprotectors using plural machine learning methods, Extreme Gradient Boosting, K-nearest neighbor, SVM and Random Forest. We compare these methods and suggest proper methods to predict radioprotectors.",,,978-1-4673-8988-4,1-6,IEEE , ,Compounds;Boosting;Support vector machines;Decision trees;Drugs;Cancer,,
5035,"Title:Mitigation of toxicity in marine mussels by autonomous mobile agents

 We propose an autonomous algorithm for mobile agents in multisensor fusion. Our algorithm is based on the concept of mutual information (MI) and the bounds obtained for correlated information. The bounds are obtained by our technique of Determinant Inequalities to maximize the mutual information to achieve the conditions for autonomy. We demonstrate the superiority our autonomous algorithm over the Principal Component Analysis (PCA) in mitigating the trace element toxicity present in marine mussels.",P. T. K. Kumar; P. T. Vinod; S. Madhusudana; S. S. Iyengar,,,Mitigation of toxicity in marine mussels by autonomous mobile agents,,,10.1109/ICWCSC.2010.5415880 ,IEEE Conferences ,,We propose an autonomous algorithm for mobile agents in multisensor fusion. Our algorithm is based on the concept of mutual information (MI) and the bounds obtained for correlated information. The bounds are obtained by our technique of Determinant Inequalities to maximize the mutual information to achieve the conditions for autonomy. We demonstrate the superiority our autonomous algorithm over the Principal Component Analysis (PCA) in mitigating the trace element toxicity present in marine mussels.,,,978-1-4244-5136-4,1-3,IEEE , ,Mobile agents;Mutual information;Information theory;Principal component analysis;Monitoring;Robust stability;Tellurium;Marine technology;Educational institutions;Computer science,,
5036,"Title:Factors affecting the expectation of casualties in the virtual range toxicity model

 The virtual range (VR) is an environment that integrates in a seamless fashion several models to improve complex systems visualization. A complex system is a nonlinear system of systems whose interactions bring together interesting emergent properties that are very difficult to visualize and/or study by using the traditional approach of decomposition. The VR toxicity model as described here represents the different systems that interact in the determination of the expectation of casualties (E/sub c/) resulting from the toxic effects of the gas dispersion that occurs after a disaster affecting a space shuttle within 120 seconds of liftoff. We present a detailed description of the VR and the factors affecting E/sub c/. The system helps local authorities to estimate the population at risk in order to plan for areas to evacuate and/or for the resources required to provide aid and comfort and mitigate damages in case of a disaster.",J. Sepulveda; L. Rabelo; J. Park; F. Gruber; O. Martinez,,,Factors affecting the expectation of casualties in the virtual range toxicity model,2,,10.1109/WSC.2004.1371528 ,IEEE Conferences ,,The virtual range (VR) is an environment that integrates in a seamless fashion several models to improve complex systems visualization. A complex system is a nonlinear system of systems whose interactions bring together interesting emergent properties that are very difficult to visualize and/or study by using the traditional approach of decomposition. The VR toxicity model as described here represents the different systems that interact in the determination of the expectation of casualties (E/sub c/) resulting from the toxic effects of the gas dispersion that occurs after a disaster affecting a space shuttle within 120 seconds of liftoff. We present a detailed description of the VR and the factors affecting E/sub c/. The system helps local authorities to estimate the population at risk in order to plan for areas to evacuate and/or for the resources required to provide aid and comfort and mitigate damages in case of a disaster.,,,0-7803-8786-4,1762-1769 vol.2,IEEE , ,Propellants;Virtual reality;Vehicles;Geographic Information Systems;Wind;Sensitivity analysis;Space shuttles;Pollution;Uncertainty;NASA,,
5037,"Title:Auspicious and Adverse Effects of Curcuma longa L Supplemented Diet on Total Protein and Kidney Injury Molecule-1 in Indomethacin Treated Rats

 The influences of Curcuma longa rhizome supplemented diet at different percentages on total protein concentration in serum, selected organs (heart, kidney and liver) and kidney injury molecule-1 (KIM-1) of indomethacin treated rats were investigated in this study. A total of 35 mature male Wistar rats, weighing between 110 and 160g, were divided into seven groups of five rats each at random. Rats in groups A through D were fed diets supplemented with 1%, 2%, 5%, and 10% turmeric; group E received a pre-treatment of the conventional medication omeprazole (20 mg/kg) orally; and groups F and G received a 28-day supply of regular rat meal. Animals in all groups were then given a single oral dose of indomethacin (60 mg/kg b.w.), fasted for the next day (except group G), and left for six (6) hours before being sacrificed. The effect(s) of turmeric rhizome powder on total protein concentration in serum, the selected organs mentioned above and kidney KIM-1 were determined. It was revealed from this study that there was increased serum total protein concentration of animals in F and D groups compared with animals in groups G and A-C with concomitant decrease in heart and kidney protein activities in concentration dependent manner. However, there was no concomitant decrease in the liver of animals in groups G and A-C. Furthermore, the result also showed a significant $(P < 0.05)$ increased expression of the kidney injury marker, KIM-1 in groups F and D in comparison with groups G and A-C in dose dependent wise. It can therefore be concluded that consumption of turmeric at 10% of whole recipe can enhance the damaging effect of indomethacin. Nonetheless, inclusion of turmeric powder at moderate concentration between 1-5% at most could mitigate the tissue damaging effect of indomethacin and therefore serve as tissue protective agent.",A. G. Oluwafemi; O. B. Ajayi; A. M. Amarachi; D. R. Emmanuel; B. P. Omoniwa,,,Auspicious and Adverse Effects of Curcuma longa L Supplemented Diet on Total Protein and Kidney Injury Molecule-1 in Indomethacin Treated Rats,1,,10.1109/SEB-SDG57117.2023.10124489 ,IEEE Conferences ,,"The influences of Curcuma longa rhizome supplemented diet at different percentages on total protein concentration in serum, selected organs (heart, kidney and liver) and kidney injury molecule-1 (KIM-1) of indomethacin treated rats were investigated in this study. A total of 35 mature male Wistar rats, weighing between 110 and 160g, were divided into seven groups of five rats each at random. Rats in groups A through D were fed diets supplemented with 1%, 2%, 5%, and 10% turmeric; group E received a pre-treatment of the conventional medication omeprazole (20 mg/kg) orally; and groups F and G received a 28-day supply of regular rat meal. Animals in all groups were then given a single oral dose of indomethacin (60 mg/kg b.w.), fasted for the next day (except group G), and left for six (6) hours before being sacrificed. The effect(s) of turmeric rhizome powder on total protein concentration in serum, the selected organs mentioned above and kidney KIM-1 were determined. It was revealed from this study that there was increased serum total protein concentration of animals in F and D groups compared with animals in groups G and A-C with concomitant decrease in heart and kidney protein activities in concentration dependent manner. However, there was no concomitant decrease in the liver of animals in groups G and A-C. Furthermore, the result also showed a significant $(P < 0.05)$ increased expression of the kidney injury marker, KIM-1 in groups F and D in comparison with groups G and A-C in dose dependent wise. It can therefore be concluded that consumption of turmeric at 10% of whole recipe can enhance the damaging effect of indomethacin. Nonetheless, inclusion of turmeric powder at moderate concentration between 1-5% at most could mitigate the tissue damaging effect of indomethacin and therefore serve as tissue protective agent.",,,979-8-3503-2478-5,1-5,IEEE , ,Proteins;Heart;Powders;Liver;Rats;Regulation;Gene expression,,
5038,"Title:Mitigation of whole-body gamma radiation–induced damages by Clerodendron infortunatum in mammalian organisms

 Several phytoceuticals and extracts of medicinal plants are reported to mitigate deleterious effects of ionizing radiation. The potential of hydro-alcoholic extract of Clerodendron infortunatum (CIE) for providing protection to mice exposed to gamma radiation was investigated. Oral administration of CIE bestowed a survival advantage to mice exposed to lethal doses of gamma radiation. Radiation-induced depletion of the total blood count and bone marrow cellularity were prevented by treatment with CIE. Damage to the cellular DNA (as was evident from the comet assay and the micronucleus index) was also found to be decreased upon CIE administration. Radiation-induced damages to intestinal crypt cells was also reduced by CIE. Studies on gene expression in intestinal cells revealed that there was a marked increase in the Bax/Bcl-2 ratio in mice exposed to whole-body 4 Gy gamma radiation, and that administration of CIE resulted in significant lowering of this ratio, suggestive of reduction of radiation-induced apoptosis. Also, in the intestinal tissue of irradiated animals, following CIE treatment, levels of expression of the DNA repair gene Atm were found to be elevated, and there was reduction in the expression of the inflammatory Cox-2 gene. Thus, our results suggest a beneficial use of Clerodendron infortunatum for mitigating radiation toxicity.",T. Chacko; A. Menon; T. Majeed; S. V. Nair; N. S. John; C. K. K. Nair,,,Mitigation of whole-body gamma radiation–induced damages by Clerodendron infortunatum in mammalian organisms,58,3,10.1093/jrr/rrw093 ,OUP Journals ,,"Several phytoceuticals and extracts of medicinal plants are reported to mitigate deleterious effects of ionizing radiation. The potential of hydro-alcoholic extract of Clerodendron infortunatum (CIE) for providing protection to mice exposed to gamma radiation was investigated. Oral administration of CIE bestowed a survival advantage to mice exposed to lethal doses of gamma radiation. Radiation-induced depletion of the total blood count and bone marrow cellularity were prevented by treatment with CIE. Damage to the cellular DNA (as was evident from the comet assay and the micronucleus index) was also found to be decreased upon CIE administration. Radiation-induced damages to intestinal crypt cells was also reduced by CIE. Studies on gene expression in intestinal cells revealed that there was a marked increase in the Bax/Bcl-2 ratio in mice exposed to whole-body 4 Gy gamma radiation, and that administration of CIE resulted in significant lowering of this ratio, suggestive of reduction of radiation-induced apoptosis. Also, in the intestinal tissue of irradiated animals, following CIE treatment, levels of expression of the DNA repair gene Atm were found to be elevated, and there was reduction in the expression of the inflammatory Cox-2 gene. Thus, our results suggest a beneficial use of Clerodendron infortunatum for mitigating radiation toxicity.",1349-9157,,,281-291,OUP , ,,,
5039,"Title:Defense against chemical warfare agents and toxic industrial chemicals

 Research on mitigation of toxic threats is critical to national defense, but is often hazardous. Toxicity generally arises at the molecular level via reactions between toxins and host biomolecules. This lends itself well to simulations from which one may safely derive the insight required for effective preventative or therapeutic response strategies. Thus, we have applied quantum chemical methods to address toxicity arising from both hostile (i.e., nerve agents) and inadvertent (e.g., toxic industrial chemicals) sources. Neurotoxic reactions involving inhibition of the acetylcholinesterase enzyme have been structurally and energetically characterized with mind to mitigating the process. In a complementary effort, interactions between toxins and various catalytic and filtering media have been reported with an aim of improving chemical protection devices.",M. M. Hurley; J. B. Wright; A. Balboa; G. H. Lushington,,,Defense against chemical warfare agents and toxic industrial chemicals,,,10.1109/DODUGC.2003.1253374 ,IEEE Conferences ,,"Research on mitigation of toxic threats is critical to national defense, but is often hazardous. Toxicity generally arises at the molecular level via reactions between toxins and host biomolecules. This lends itself well to simulations from which one may safely derive the insight required for effective preventative or therapeutic response strategies. Thus, we have applied quantum chemical methods to address toxicity arising from both hostile (i.e., nerve agents) and inadvertent (e.g., toxic industrial chemicals) sources. Neurotoxic reactions involving inhibition of the acetylcholinesterase enzyme have been structurally and energetically characterized with mind to mitigating the process. In a complementary effort, interactions between toxins and various catalytic and filtering media have been reported with an aim of improving chemical protection devices.",,,0-7695-1953-9,55-59,IEEE , ,Chemical industry;Toxic chemicals;Defense industry;Hydrogen;Protection;Biochemistry;Chemical hazards;Bonding;Filtration;Molecular biophysics,,
5040,"Title:Neural Interface Dynamics Following Insertion of Hydrous Iridium Oxide Microelectrode Arrays

 Studies examining traumatic brain injury have suggested a 'window of opportunity' exists for therapeutic agents to mitigate edema and cellular toxicity effectively. However, successful therapy also relies on identifying the extent of blood-brain barrier disruption, which is associated with excessive extra-cellular concentrations of ions, excitatory amino acids, and serum proteins. The following study investigates the use of pH-selective hydrous iridium oxide microelectrodes to assess trauma following insertion of a neural probe. Electrochemical activation of iridium microelectrode arrays was performed in either acidic (0.5 M H2SO4) or weak basic (0.3 M Na2HPO4, pH=8.56) solutions. Both oxides demonstrated super-Nernstian pH sensitivity (-88.5 mV/pH and -77.1 mV/pH, respectively) with little interference by other cations. Data suggest that acid-grown oxide provides better potential stability than base-grown oxide (sigma=2.8 versus 4.9 mV over 5 hours). Implantation of these electrodes into motor cortex and dorsal striatum revealed significant acidosis during and following insertion. Variability in the spatiotemporal pH profile included micro-scale inhomogeneities along the probe shank and significant differences in the averaged pH response between successive insertions using the same depth and speed. This diagnostic technology has important implications for intervention therapies in order to more effectively treat acute surgical brain trauma",M. D. Johnson; N. B. Langhals; D. R. Kipke,,,Neural Interface Dynamics Following Insertion of Hydrous Iridium Oxide Microelectrode Arrays,,,10.1109/IEMBS.2006.260521 ,IEEE Conferences ,,"Studies examining traumatic brain injury have suggested a 'window of opportunity' exists for therapeutic agents to mitigate edema and cellular toxicity effectively. However, successful therapy also relies on identifying the extent of blood-brain barrier disruption, which is associated with excessive extra-cellular concentrations of ions, excitatory amino acids, and serum proteins. The following study investigates the use of pH-selective hydrous iridium oxide microelectrodes to assess trauma following insertion of a neural probe. Electrochemical activation of iridium microelectrode arrays was performed in either acidic (0.5 M H2SO4) or weak basic (0.3 M Na2HPO4, pH=8.56) solutions. Both oxides demonstrated super-Nernstian pH sensitivity (-88.5 mV/pH and -77.1 mV/pH, respectively) with little interference by other cations. Data suggest that acid-grown oxide provides better potential stability than base-grown oxide (sigma=2.8 versus 4.9 mV over 5 hours). Implantation of these electrodes into motor cortex and dorsal striatum revealed significant acidosis during and following insertion. Variability in the spatiotemporal pH profile included micro-scale inhomogeneities along the probe shank and significant differences in the averaged pH response between successive insertions using the same depth and speed. This diagnostic technology has important implications for intervention therapies in order to more effectively treat acute surgical brain trauma",1557-170X,,1-4244-0032-5,3178-3181,IEEE , ,Microelectrodes;Medical treatment;Probes;Brain injuries;Amino acids;Proteins;Interference;Stability;Electrodes;Spatiotemporal phenomena,,
5041,"Title:Nanotechnology enabled hybrid power system suitable for batteries in hybrid electric vehicle

 Hybrid electric vehicles are playing very important key role in transportation. As atmospheric imbalance is a cause of large amount of carbon emission due to fuel used in vehicles. So to mitigate this problem use of electric vehicles is increasing day by day. Lithium-ion batteries are playing very crucial role in hybrid electric vehicles. As these batteries are very beneficial for proper functioning of hybrid electric vehicles. So Lithium-ion is the best and most promising choice at the present. Lithium-ion batteries have myriad amount of applications in the field of electric vehicles and portable electronics. The worldwide demand for a clean, low fuel-consuming road transportation system has given raises to the rapid growth of hybrid electric vehicles. Nanotechnology is playing vital role in enhancing the battery life. So use of nanostructure materials in battery design is increasing day by day. This enables battery to become effectual in many applications Lithium- ion batteries (LIBs) are the best choice as they have advantages such as high energy density, high discharge power and long service life. In large scale applications of lithium ion battery important aspects such as safety, toxicity, cost and myriad of raw materials become highly significant and also high discharge rate requirements can be fulfill by the use of nanostructure materials to achieve performance targets. This paper mainly focuses on use of nanotechnology in lithium-ion battery technology. For this purpose system can be designed which is combination of many technology and based on nanotechnology that enables to use nanostructure materials for lithium ion battery used in hybrid electric vehicles. This system is nanotechnology enabled hybrid system which can be very beneficial to ameliorates the performance of the battery that will further helps in ameliorating performance of hybrid electric vehicles. Super capacitors are used in parallel combination in the hybrid system to increases battery performance, efficiency and life of battery this system can play important role in betterment of transportation as well as in enhancing electrification of transportation. Nanostructure materials in batteries ameliorate the electrochemical performances of existing electrode materials for lithium-ion batteries, for this purpose nanotechnology based hybrid system is very beneficial.",V. S. Deshpande; M. N. Talele,,,Nanotechnology enabled hybrid power system suitable for batteries in hybrid electric vehicle,,,10.1109/AEEICB.2017.7972378 ,IEEE Conferences ,,"Hybrid electric vehicles are playing very important key role in transportation. As atmospheric imbalance is a cause of large amount of carbon emission due to fuel used in vehicles. So to mitigate this problem use of electric vehicles is increasing day by day. Lithium-ion batteries are playing very crucial role in hybrid electric vehicles. As these batteries are very beneficial for proper functioning of hybrid electric vehicles. So Lithium-ion is the best and most promising choice at the present. Lithium-ion batteries have myriad amount of applications in the field of electric vehicles and portable electronics. The worldwide demand for a clean, low fuel-consuming road transportation system has given raises to the rapid growth of hybrid electric vehicles. Nanotechnology is playing vital role in enhancing the battery life. So use of nanostructure materials in battery design is increasing day by day. This enables battery to become effectual in many applications Lithium- ion batteries (LIBs) are the best choice as they have advantages such as high energy density, high discharge power and long service life. In large scale applications of lithium ion battery important aspects such as safety, toxicity, cost and myriad of raw materials become highly significant and also high discharge rate requirements can be fulfill by the use of nanostructure materials to achieve performance targets. This paper mainly focuses on use of nanotechnology in lithium-ion battery technology. For this purpose system can be designed which is combination of many technology and based on nanotechnology that enables to use nanostructure materials for lithium ion battery used in hybrid electric vehicles. This system is nanotechnology enabled hybrid system which can be very beneficial to ameliorates the performance of the battery that will further helps in ameliorating performance of hybrid electric vehicles. Super capacitors are used in parallel combination in the hybrid system to increases battery performance, efficiency and life of battery this system can play important role in betterment of transportation as well as in enhancing electrification of transportation. Nanostructure materials in batteries ameliorate the electrochemical performances of existing electrode materials for lithium-ion batteries, for this purpose nanotechnology based hybrid system is very beneficial.",,,978-1-5090-5434-3,33-35,IEEE , ,Hybrid electric vehicles;Ions;Lithium;Nanostructured materials,,
5042,"Title:Salinity and SiO<inf>2</inf> Impact on Growth and Biochemical Responses of Basil (Ocimum Basilicum L.) Seedlings

 Silicon has the ability in ameliorating the negative effect of salinity on plants by reducing ionic toxicity and maintaining plant water balance, reducing oxidative stress. The present paper examines the effects of saline stress (50mM and 100mM NaCl) applied singular and in combination with SiO2 on basil (Ocimum basilicum L.) seedlings. Significant changes occurred in terms of shoot length, varying from 7.27 mm (50 mM NaCl) to 8.39 mm (50mM NaCl+SiNPs), and in the case of radicles, from 3.22 mm (SiNP) to 3.98 mm (100 mM NaCl), suggesting that salt treatment reduces shoot elongation, and SiO2 application could mitigate the saline stress effect. The activity of antioxidant enzymes in O. basilicum seedlings exposed to treatments, singular or in combination, was generally lower compared to the control. SiO2 supplement may contribute to the increase of salt tolerance, as reflected by the improvement of SOD and POD activity, especially in the combined treatment of 100 mM NaCl+SiO2.",L. Oprica; M. -N. Grigore; I. Bara; G. Vochita,,,Salinity and SiO<inf>2</inf> Impact on Growth and Biochemical Responses of Basil (Ocimum Basilicum L.) Seedlings,,,10.1109/EHB52898.2021.9657645 ,IEEE Conferences ,,"Silicon has the ability in ameliorating the negative effect of salinity on plants by reducing ionic toxicity and maintaining plant water balance, reducing oxidative stress. The present paper examines the effects of saline stress (50mM and 100mM NaCl) applied singular and in combination with SiO2 on basil (Ocimum basilicum L.) seedlings. Significant changes occurred in terms of shoot length, varying from 7.27 mm (50 mM NaCl) to 8.39 mm (50mM NaCl+SiNPs), and in the case of radicles, from 3.22 mm (SiNP) to 3.98 mm (100 mM NaCl), suggesting that salt treatment reduces shoot elongation, and SiO2 application could mitigate the saline stress effect. The activity of antioxidant enzymes in O. basilicum seedlings exposed to treatments, singular or in combination, was generally lower compared to the control. SiO2 supplement may contribute to the increase of salt tolerance, as reflected by the improvement of SOD and POD activity, especially in the combined treatment of 100 mM NaCl+SiO2.",2575-5145,,978-1-6654-4000-4,1-4,IEEE , ,Silicon compounds;Toxicology;Salinity (geophysical);Pigments;Silicon;Biochemistry;Stress,,
5043,"Title:A Multi-dimensional Generic Evaluation Framework for the Security of Large Language Models

 In light of the widespread adoption of large language models, their susceptibility to security vulnerabilities cannot be overlooked. As a result, it has become imperative to evaluate their proficiency in addressing issues such as toxicity, bias, and disinformation. However, current research focused on appraising and mitigating security risks has predominantly concentrated on specific facets, leading to disparities in evaluation criteria. In contrast, there has been relatively limited attention given to multidimensional and universal frameworks for security evaluation. In this context, this paper delves into the realm of generic evaluation frameworks for security that offer support for cross-language and multi-category analysis. We underscore the existing challenges associated with prominent large language models concerning security issues and develop a comprehensive test data set to furnish researchers with a tool for quantifying security aspects. Through comprehensive evaluations across three major benchmark tests, we identify distinct strengths and weaknesses exhibited by each open source large language model to varying degrees. By employing a multi-dimensional security evaluation framework, we can attain a more holistic comprehension of the performance exhibited by each model across diverse security dimensions. This approach holds significant value in advancing the domain of security research and facilitating the practical application of language models.",Z. Yu,,,A Multi-dimensional Generic Evaluation Framework for the Security of Large Language Models,,,10.1109/ICBAIE59714.2023.10281279 ,IEEE Conferences ,,"In light of the widespread adoption of large language models, their susceptibility to security vulnerabilities cannot be overlooked. As a result, it has become imperative to evaluate their proficiency in addressing issues such as toxicity, bias, and disinformation. However, current research focused on appraising and mitigating security risks has predominantly concentrated on specific facets, leading to disparities in evaluation criteria. In contrast, there has been relatively limited attention given to multidimensional and universal frameworks for security evaluation. In this context, this paper delves into the realm of generic evaluation frameworks for security that offer support for cross-language and multi-category analysis. We underscore the existing challenges associated with prominent large language models concerning security issues and develop a comprehensive test data set to furnish researchers with a tool for quantifying security aspects. Through comprehensive evaluations across three major benchmark tests, we identify distinct strengths and weaknesses exhibited by each open source large language model to varying degrees. By employing a multi-dimensional security evaluation framework, we can attain a more holistic comprehension of the performance exhibited by each model across diverse security dimensions. This approach holds significant value in advancing the domain of security research and facilitating the practical application of language models.",,,979-8-3503-4361-8,410-414,IEEE , ,Toxicology;Media;Big Data;Benchmark testing;Data models;Security;Internet of Things,,
5044,"Title:The Study of Designing for Environment on Liquid Crystal Display

 The Flat Panel Display Industry in Taiwan recently has reached a numerous export value with tens of billion US dollars. It is also a core industry for Taiwan. However, the recent environmental protection strategy and directives developed in Europe, US, and Japan have been gradually shifting from the end of pipe mindset to a more impacts preventive approach from the product designing phase, which was perceived as a new trade barrier that could have significant negative impacts on Taiwan industries. Thus, this paper categorizes the international environmental standards, relative regulations and proposes some strategies of DfE for LCD products in Taiwan. This paper also presented successful cases of DfE application in LCD Monitor, indicated significant benefits could be obtained. For this case, costs reduction around $65,000 US dollars in materials and 2,500 hours saving in labor was achieved every year, and the pollutants emission was also mitigated with rate around 20∼30% estimated. By using saving energy, low toxicity, and recycling concept into development of LCD products, it would improve these products to comply with requirements from international regulations.",Ching-Chih Lin; Mei-Hwa Chung; Zen Wang,,,The Study of Designing for Environment on Liquid Crystal Display,,,10.1109/ECODIM.2005.1619283 ,IEEE Conferences ,,"The Flat Panel Display Industry in Taiwan recently has reached a numerous export value with tens of billion US dollars. It is also a core industry for Taiwan. However, the recent environmental protection strategy and directives developed in Europe, US, and Japan have been gradually shifting from the end of pipe mindset to a more impacts preventive approach from the product designing phase, which was perceived as a new trade barrier that could have significant negative impacts on Taiwan industries. Thus, this paper categorizes the international environmental standards, relative regulations and proposes some strategies of DfE for LCD products in Taiwan. This paper also presented successful cases of DfE application in LCD Monitor, indicated significant benefits could be obtained. For this case, costs reduction around $65,000 US dollars in materials and 2,500 hours saving in labor was achieved every year, and the pollutants emission was also mitigated with rate around 20∼30% estimated. By using saving energy, low toxicity, and recycling concept into development of LCD products, it would improve these products to comply with requirements from international regulations.",,,1-4244-0081-3,523-524,IEEE , ,Liquid crystal displays;Monitoring;Batteries;Product design;Recycling;Ink;Pigments;Electronics packaging;Plastic packaging;Mercury (metals),,
5045,"Title:Design automation for biochemistry synthesis on a digital microfluidic lab-on-a-chip

 Microfluidic biochips are recently being advocated for on-chip implementation of several biochemical laboratory assays or protocols [1]. Such labs-on-a-chip (LoC) have brought a complete paradigm shift in DNA analysis, toxicity grading, in molecular biology, and in drug design and delivery. This technology offers a viable and low-cost platform for reducing healthcare cost of cardiovascular diseases, cancer, diabetes, for providing point-of-care (P-o-C) health services [2, 3], and for the management of bio-terrorism threats [4]. These chips are also immensely useful for rapid and accurate diagnosis of various diseases including malaria, human immunodeficiency virus infection (HIV), acquired immunodeficiency syndrome (AIDS), and for mitigating neglected tropical diseases (NTD) prevalent in the developing countries [5].",K. Chakrabarty; B. B. Bhattacharya; A. Banerjee,,,Design automation for biochemistry synthesis on a digital microfluidic lab-on-a-chip,,,10.1109/ICCAD.2014.7001364 ,IEEE Conferences ,,"Microfluidic biochips are recently being advocated for on-chip implementation of several biochemical laboratory assays or protocols [1]. Such labs-on-a-chip (LoC) have brought a complete paradigm shift in DNA analysis, toxicity grading, in molecular biology, and in drug design and delivery. This technology offers a viable and low-cost platform for reducing healthcare cost of cardiovascular diseases, cancer, diabetes, for providing point-of-care (P-o-C) health services [2, 3], and for the management of bio-terrorism threats [4]. These chips are also immensely useful for rapid and accurate diagnosis of various diseases including malaria, human immunodeficiency virus infection (HIV), acquired immunodeficiency syndrome (AIDS), and for mitigating neglected tropical diseases (NTD) prevalent in the developing countries [5].",1558-2434,,978-1-4799-6278-5,286-288,IEEE , ,Protocols;System-on-chip;Routing;Laboratories;Drugs;Diseases;Design automation,,
5046,"Title:A software-based predictive model for greenhouse gas mitigation: Towards environmental sustainability

 In the last years research-based programs relevant to sustainability have been developed. Some technological research programs are focused on the design of systems and processes that can be useful for mitigating greenhouse gas emissions as CO2. To diminish the negative impact caused by CO2 for global warming, its chemical transformation in Dimethyl Carbonate is a promising technology. Dimethyl Carbonate is a solvent with low toxicity and due to oxidative capacity can be used as fuel additive. In this work, the membrane reactor technology to improve the Dymethyl Carbonate production is explored from the perspective of modelling and simulation. As a result, a software-based model is implemented, in order to develop and couple different models for describing the membrane reactor. Simulation results showed that the membrane reactor, compared with conventional reactor, increase the reaction conversion and Dymethyl Carbonate production up to 67% and 78%, respectively. Finally, it can be seen that the solution obtained from software-based model allows to conclude that membrane reactor is a promising technology to mitigate CO2 emissions, allowing to achieve environmental sustainability.",S. V. Moncada; M. G. Palacio; M. Luna-delRisco; C. A. A. Orozco; J. Jair; Q. Montealegre; J. C. Imbachi; I. Diaz-Forero,,,A software-based predictive model for greenhouse gas mitigation: Towards environmental sustainability,,,10.23919/CISTI.2018.8399195 ,IEEE Conferences ,,"In the last years research-based programs relevant to sustainability have been developed. Some technological research programs are focused on the design of systems and processes that can be useful for mitigating greenhouse gas emissions as CO2. To diminish the negative impact caused by CO2 for global warming, its chemical transformation in Dimethyl Carbonate is a promising technology. Dimethyl Carbonate is a solvent with low toxicity and due to oxidative capacity can be used as fuel additive. In this work, the membrane reactor technology to improve the Dymethyl Carbonate production is explored from the perspective of modelling and simulation. As a result, a software-based model is implemented, in order to develop and couple different models for describing the membrane reactor. Simulation results showed that the membrane reactor, compared with conventional reactor, increase the reaction conversion and Dymethyl Carbonate production up to 67% and 78%, respectively. Finally, it can be seen that the solution obtained from software-based model allows to conclude that membrane reactor is a promising technology to mitigate CO2 emissions, allowing to achieve environmental sustainability.",,,978-989-98434-8-6,1-6,IEEE , ,Mathematical model;Inductors;Monte Carlo methods;Production;Numerical models;Sustainable development;Software,,
5047,"Title:A convex optimization approach to cancer treatment to address tumor heterogeneity and imperfect drug penetration in physiological compartments

 The clinical success of targeted cancer therapies is limited by the emergence of drug resistance often due to pre-existing tumor genetic heterogeneity and acquired, therapy-induced resistance. Targeted therapies have varied success in addressing metastatic disease, due to their ability to penetrate certain physiological compartments. This paper considers an evolutionary cancer model that incorporates tumor cell growth, mutation and compartmental migration and leverages recent results on the optimal control of monotone and convex systems to synthesize switching treatment strategies where a single drug or a predetermined combination of drugs is used at a given time. The need for switching is motivated by clinical considerations such as the limited effectiveness of any single targeted therapy against multiple resistance mechanisms arising in a single patient and the inability to design drug combinations at effective doses due to toxicity constraints. An optimal and clinically feasible switching therapy is obtained as the solution of a convex optimization problem that exploits the diagonally-dominant structure of the model. We demonstrate that this method yields an effective strategy in mitigating disease evolution in the presence of imperfect drug penetration in two compartments on an experimentally identified model of anaplastic lymphoma kinase (ALK)-rearranged lung carcinoma.",G. Giordano; A. Rantzer; V. D. Jonsson,,,A convex optimization approach to cancer treatment to address tumor heterogeneity and imperfect drug penetration in physiological compartments,,,10.1109/CDC.2016.7798636 ,IEEE Conferences ,,"The clinical success of targeted cancer therapies is limited by the emergence of drug resistance often due to pre-existing tumor genetic heterogeneity and acquired, therapy-induced resistance. Targeted therapies have varied success in addressing metastatic disease, due to their ability to penetrate certain physiological compartments. This paper considers an evolutionary cancer model that incorporates tumor cell growth, mutation and compartmental migration and leverages recent results on the optimal control of monotone and convex systems to synthesize switching treatment strategies where a single drug or a predetermined combination of drugs is used at a given time. The need for switching is motivated by clinical considerations such as the limited effectiveness of any single targeted therapy against multiple resistance mechanisms arising in a single patient and the inability to design drug combinations at effective doses due to toxicity constraints. An optimal and clinically feasible switching therapy is obtained as the solution of a convex optimization problem that exploits the diagonally-dominant structure of the model. We demonstrate that this method yields an effective strategy in mitigating disease evolution in the presence of imperfect drug penetration in two compartments on an experimentally identified model of anaplastic lymphoma kinase (ALK)-rearranged lung carcinoma.",,,978-1-5090-1837-6,2494-2500,IEEE , ,Drugs;Tumors;Switches;Convex functions;Optimal control;Physiology,,
5048,"Title:Latticed Channel Model of Touchable Communication Over Capillary Microcirculation Network

 Recent progress on bioresorbable and bio-compatible miniature systems provides prospects for developing novel nanorobots operating inside the human body. These nanoscale systems are expected to dissolve in vivo and cause no side effect after completing their tasks. Motivated by these advancements, we have developed the analytical framework of touchable molecular communication (TouchCom) to describe the process of direct drug targeting (DDT) using externally controllable nanorobots. Built upon our previous work, we develop a novel latticed channel model of TouchCom for an interconnected capillary network near a targeted tumor area. Specifically, we propose a two-dimensional grid to synthesize the microcirculation environment, which is used to describe the propagation process of nanorobots. Furthermore, by applying the concept of multiple-input multiple-output (MIMO) systems in wireless communications to the therapeutic window in cancer treatment, we propose a MIMO DDT strategy in the latticed channel to enhance the targeting efficiency while minimizing the adverse effect of drug toxicity. Based on the proposed model, we study the influence of blood flow direction on the efficiency of DDT, and introduce a compensation strategy with the help of an external guiding field to mitigate the misalignment between the direction of blood flow and the tumor location.",Y. Zhou; Y. Chen,,,Latticed Channel Model of Touchable Communication Over Capillary Microcirculation Network,18,4,10.1109/TNB.2019.2943671 ,IEEE Journals ,,"Recent progress on bioresorbable and bio-compatible miniature systems provides prospects for developing novel nanorobots operating inside the human body. These nanoscale systems are expected to dissolve in vivo and cause no side effect after completing their tasks. Motivated by these advancements, we have developed the analytical framework of touchable molecular communication (TouchCom) to describe the process of direct drug targeting (DDT) using externally controllable nanorobots. Built upon our previous work, we develop a novel latticed channel model of TouchCom for an interconnected capillary network near a targeted tumor area. Specifically, we propose a two-dimensional grid to synthesize the microcirculation environment, which is used to describe the propagation process of nanorobots. Furthermore, by applying the concept of multiple-input multiple-output (MIMO) systems in wireless communications to the therapeutic window in cancer treatment, we propose a MIMO DDT strategy in the latticed channel to enhance the targeting efficiency while minimizing the adverse effect of drug toxicity. Based on the proposed model, we study the influence of blood flow direction on the efficiency of DDT, and introduce a compensation strategy with the help of an external guiding field to mitigate the misalignment between the direction of blood flow and the tumor location.",1558-2639,,,669-678,IEEE , ,Tumors;Drugs;Targeted drug delivery;Channel models;Molecular communication (telecommunication),,
5049,"Title:A comparative analysis of feature selection algorithms on classification of gene microarray dataset

 Analysis of gene expression is important in many fields of biological research in order to retrieve the required information. As the time advances, the illness in general and cancer in particular have become more and more complex and complicated, in detecting, analyzing and curing. Cancer research is one of the major research areas in the medical field. Accurate prediction of different tumor types has great value in providing better treatment and toxicity minimization on the patients. To minimize it, the data mining algorithms are important tool and the most extensively used approach to classify gene expression data and plays an important role for cancer classification. One of the major challenges is to discover how to extract useful information from datasets. This research is based on recent advances in the machine learning based microarray gene expression data analysis with three feature selection algorithms.",J. Jeyachidra; M. Punithavalli,,,A comparative analysis of feature selection algorithms on classification of gene microarray dataset,,,10.1109/ICICES.2013.6508165 ,IEEE Conferences ,,"Analysis of gene expression is important in many fields of biological research in order to retrieve the required information. As the time advances, the illness in general and cancer in particular have become more and more complex and complicated, in detecting, analyzing and curing. Cancer research is one of the major research areas in the medical field. Accurate prediction of different tumor types has great value in providing better treatment and toxicity minimization on the patients. To minimize it, the data mining algorithms are important tool and the most extensively used approach to classify gene expression data and plays an important role for cancer classification. One of the major challenges is to discover how to extract useful information from datasets. This research is based on recent advances in the machine learning based microarray gene expression data analysis with three feature selection algorithms.",,,978-1-4673-5788-3,1088-1093,IEEE , ,Classification algorithms;Accuracy;Algorithm design and analysis;Cancer;Indexes;Gene expression;Error analysis,,
5050,"Title:An Effective Machine Learning Approach for Identifying the Glyphosate Poisoning Status in Rats Using Blood Routine Test

 Glyphosate, one of the most popular herbicides world-wide, is used as an active ingredient in many commercial formulations. So far, many studies have focused on reproductive toxicity on glyphosate which may trigger epigenetic changes through endocrine-mediated mechanisms. Generally, it is critical to identify the glyphosate poisoning status in order to minimize health risks. This paper proposed a machine learning approach using 110 rats' samples to identify the glyphosate poisoning status. All rats were randomly divided into 2 groups (n = 55 each) in the study. The rats in the blank control group were given 0.9% sodium chloride solution orally for 15 days, while the other groups were administered orally at the dosage of 0.5g/kg of glyphosate once per day for 15 days consecutively. Consequently, the potential of an enhanced fuzzy k nearest neighbor approach was explored through blood routine test to recognize the glyphosate poisoning condition based on the blood indices. A real-life data set was used to evaluate the effectiveness of the proposed method in terms of classification accuracy (ACC), sensitivity, specificity, and Matthews Correlation Coefficients (MCC). The results demonstrated that there were significant differences in blood routine test indices between the control and the glyphosate groups (p-value <; 0.01). It was observed in the feature selection that the most important correlated indices were white blood cell , lymphocyte , intermediate cell, and neutrophil granulocyte. A comparative study with support vector machine and artificial neural networks had shown that the proposed approach could achieve much more promising results with 95.45% ACC, 0.90 MCC, 98.89% sensitivity, and 88.89% specificity. The empirical analysis verifies that the proposed method is promising to act as a new, accurate method for identification of the glyphosate poisoning status in subjects.",J. Zhu; X. Zhao; H. Li; H. Chen; G. Wu,,,An Effective Machine Learning Approach for Identifying the Glyphosate Poisoning Status in Rats Using Blood Routine Test,6,,10.1109/ACCESS.2018.2809789 ,IEEE Journals ,,"Glyphosate, one of the most popular herbicides world-wide, is used as an active ingredient in many commercial formulations. So far, many studies have focused on reproductive toxicity on glyphosate which may trigger epigenetic changes through endocrine-mediated mechanisms. Generally, it is critical to identify the glyphosate poisoning status in order to minimize health risks. This paper proposed a machine learning approach using 110 rats' samples to identify the glyphosate poisoning status. All rats were randomly divided into 2 groups (n = 55 each) in the study. The rats in the blank control group were given 0.9% sodium chloride solution orally for 15 days, while the other groups were administered orally at the dosage of 0.5g/kg of glyphosate once per day for 15 days consecutively. Consequently, the potential of an enhanced fuzzy k nearest neighbor approach was explored through blood routine test to recognize the glyphosate poisoning condition based on the blood indices. A real-life data set was used to evaluate the effectiveness of the proposed method in terms of classification accuracy (ACC), sensitivity, specificity, and Matthews Correlation Coefficients (MCC). The results demonstrated that there were significant differences in blood routine test indices between the control and the glyphosate groups (p-value <; 0.01). It was observed in the feature selection that the most important correlated indices were white blood cell , lymphocyte , intermediate cell, and neutrophil granulocyte. A comparative study with support vector machine and artificial neural networks had shown that the proposed approach could achieve much more promising results with 95.45% ACC, 0.90 MCC, 98.89% sensitivity, and 88.89% specificity. The empirical analysis verifies that the proposed method is promising to act as a new, accurate method for identification of the glyphosate poisoning status in subjects.",2169-3536,,,15653-15662,IEEE , ,Rats;Blood;Liver;Artificial neural networks;Sensitivity;Feature extraction,,
5051,"Title:A Novel Preprocessing Technique for Toxic Comment Classification

 The threat of online abuse and harassment is increasing day by day in the cyber community. To tackle this problem, many platforms have devised policies. But these policies require prior identification of the content that is inappropriate and offensive. Furthermore, the data contains various aspects of negativity, for example, a particular piece of comment can express, disgust, disbelief, and threat at the same time. It points that even the negativity/toxicity exhibited in a comment can have various facets. Hence, the challenge is to identify what exactly is exhibited in comments so that respective policies can be formulated and applied to penalize the offender. This study makes use of two approaches to identify these underlying toxicities in the comments. The first approach is to train separate classifiers against each facet of the toxicity in comments. The second approach deals with the problem as a multi-label classification problem. Different machine learning approaches including logistic regression, Naïve Bayes, and decision tree classification are employed to carry out this study. The dataset is taken from Kaggle and 10-fold cross-validation is used to report the robustness of the model. The study uses a novel preprocessing scheme that transforms the multi-label classification problem into the multi-class classification problem. The preprocessing strategy has shown a significant improvement in the accuracies when employed for simple classification models encouraging its use for other sophisticated models as well. Experimental results show that in both the binary classification and the multi-classification, logistic regression turns out to be a better performer. This indicates the potential use of the preprocessing for the neural classification models.",M. Husnain; A. Khalid; N. Shafi,,,A Novel Preprocessing Technique for Toxic Comment Classification,,,10.1109/ICAI52203.2021.9445252 ,IEEE Conferences ,,"The threat of online abuse and harassment is increasing day by day in the cyber community. To tackle this problem, many platforms have devised policies. But these policies require prior identification of the content that is inappropriate and offensive. Furthermore, the data contains various aspects of negativity, for example, a particular piece of comment can express, disgust, disbelief, and threat at the same time. It points that even the negativity/toxicity exhibited in a comment can have various facets. Hence, the challenge is to identify what exactly is exhibited in comments so that respective policies can be formulated and applied to penalize the offender. This study makes use of two approaches to identify these underlying toxicities in the comments. The first approach is to train separate classifiers against each facet of the toxicity in comments. The second approach deals with the problem as a multi-label classification problem. Different machine learning approaches including logistic regression, Naïve Bayes, and decision tree classification are employed to carry out this study. The dataset is taken from Kaggle and 10-fold cross-validation is used to report the robustness of the model. The study uses a novel preprocessing scheme that transforms the multi-label classification problem into the multi-class classification problem. The preprocessing strategy has shown a significant improvement in the accuracies when employed for simple classification models encouraging its use for other sophisticated models as well. Experimental results show that in both the binary classification and the multi-classification, logistic regression turns out to be a better performer. This indicates the potential use of the preprocessing for the neural classification models.",,,978-1-6654-3293-1,22-27,IEEE , ,Toxicology;Recurrent neural networks;Social networking (online);Text categorization;Machine learning;Transforms;Robustness,,
5052,"Title:Prediction of Multi Class Drugs: A Perspective for Designing Drug with Many Uses

 The drug-like molecule which could treat multiple diseases is commercially more viable and can act on multiple biological pathways. Such drug candidates can also be more important in the treatment of complex diseases like cancer. Traditional methods are not focused on the development of such drugs, but computational method can be developed to predict multiple disease potential of drug-like molecules. Computational methods have been extremely successful in drug discovery through prediction of drug potential of the drug-like molecules such as toxicity, physiological effects, binding energy and binding pose with the receptor. Computational methods to predict multiple disease potential of the drug-like molecules are not worked out so far in spite of the high importance of such drugs and it can also expedite the drug repurposing. Hence, information of approved drugs used for the treatment of single and multiple diseases was included to develop the machine learning-based model for the prediction of multiple disease potential of the drug-like molecules. Molecular descriptors were used as the features and optimally selected for support vector machine-based prediction models. The fairly high accuracy of developed method justifies the importance of selected method and approach. The developed method is expected to expedite the drug discovery process through the prediction of multi-drug potential of drug-like molecules.",P. Vaidya; S. Chauhan; V. Jaiswal,,,Prediction of Multi Class Drugs: A Perspective for Designing Drug with Many Uses,,,10.1109/AISP53593.2022.9760640 ,IEEE Conferences ,,"The drug-like molecule which could treat multiple diseases is commercially more viable and can act on multiple biological pathways. Such drug candidates can also be more important in the treatment of complex diseases like cancer. Traditional methods are not focused on the development of such drugs, but computational method can be developed to predict multiple disease potential of drug-like molecules. Computational methods have been extremely successful in drug discovery through prediction of drug potential of the drug-like molecules such as toxicity, physiological effects, binding energy and binding pose with the receptor. Computational methods to predict multiple disease potential of the drug-like molecules are not worked out so far in spite of the high importance of such drugs and it can also expedite the drug repurposing. Hence, information of approved drugs used for the treatment of single and multiple diseases was included to develop the machine learning-based model for the prediction of multiple disease potential of the drug-like molecules. Molecular descriptors were used as the features and optimally selected for support vector machine-based prediction models. The fairly high accuracy of developed method justifies the importance of selected method and approach. The developed method is expected to expedite the drug discovery process through the prediction of multi-drug potential of drug-like molecules.",2640-5768,,978-1-6654-4290-9,1-7,IEEE , ,Drugs;Training;Support vector machines;Toxicology;Three-dimensional displays;Predictive models;Signal processing,,
5053,"Title:Investigating the Use of Machine Learning Models to Understand the Drugs Permeability Across Placenta

 Owing to limited drug testing possibilities in pregnant population, the development of computational algorithms is crucial to predict the fate of drugs in the placental barrier; it could serve as an alternative to animal testing. The ability of a molecule to effectively cross the placental barrier and reach the fetus determines the drug’s toxicological effects on the fetus. In this regard, our study aims to predict the permeability of molecules across the placental barrier. Based on publicly available datasets, several machine learning models are comprehensively analysed across different fingerprints and toolkits to find the best suitable models. Several dataset analysis models are utilised to study the data diversity. Further, this study demonstrates the application of neural network-based models to effectively predict the permeability. K-nearest neighbour (KNN), standard vector classifier (SVC) and Multi-layer perceptron (MLP) are found to be the best-performing models with a prediction percentage of 82%, 86.4% and 90.8%, respectively. Different models are compared to predict the chosen set of drugs, drugs like Aliskiren, some insulin secretagogues and glucocorticoids are found to be negative while predicting the permeability.",V. Chandrasekar; M. Y. Ansari; A. V. Singh; S. Uddin; K. S. Prabhu; S. Dash; S. A. Khodor; A. Terranegra; M. Avella; S. P. Dakua,,,Investigating the Use of Machine Learning Models to Understand the Drugs Permeability Across Placenta,11,,10.1109/ACCESS.2023.3272987 ,IEEE Journals ,,"Owing to limited drug testing possibilities in pregnant population, the development of computational algorithms is crucial to predict the fate of drugs in the placental barrier; it could serve as an alternative to animal testing. The ability of a molecule to effectively cross the placental barrier and reach the fetus determines the drug’s toxicological effects on the fetus. In this regard, our study aims to predict the permeability of molecules across the placental barrier. Based on publicly available datasets, several machine learning models are comprehensively analysed across different fingerprints and toolkits to find the best suitable models. Several dataset analysis models are utilised to study the data diversity. Further, this study demonstrates the application of neural network-based models to effectively predict the permeability. K-nearest neighbour (KNN), standard vector classifier (SVC) and Multi-layer perceptron (MLP) are found to be the best-performing models with a prediction percentage of 82%, 86.4% and 90.8%, respectively. Different models are compared to predict the chosen set of drugs, drugs like Aliskiren, some insulin secretagogues and glucocorticoids are found to be negative while predicting the permeability.",2169-3536,,,52726-52739,IEEE , ,Drugs;Permeability;Predictive models;Pregnancy;Fingerprint recognition;Machine learning;Computational modeling,,
5054,"Title:Data-based prediction of the correction roll intermesh in industrial hot-dip galvanizing lines

 In the continuous hot-dip galvanizing process, the final zinc coating thickness is heavily influenced by the distance between the strip surface and the gas wiping dies which blow off excess zinc. To this end, establishing a flat, non-curved strip is a key prerequisite to minimize coating thickness deviations and inhomogeneities. A common way to influence the lateral strip profile is to introduce a controlled plastic deformation of the strip at the guiding rolls in the zinc bath. This motivates a data-based study of the optimal roll intermesh value of the zinc bath rolls to achieve a flat (zero-crossbow) strip profile during the galvanizing process. Based on this analysis, a data-based algorithm for the online prediction of the optimal roll intermesh value at the head end of each strip is developed and implemented in an industrial processing line. The prediction results from 1045 strips demonstrate the feasibility and accuracy of the proposed prediction algorithm.",L. Marko; A. Kugi; A. Steinboeck,,,Data-based prediction of the correction roll intermesh in industrial hot-dip galvanizing lines,,,10.1109/CCTA54093.2023.10253412 ,IEEE Conferences ,,"In the continuous hot-dip galvanizing process, the final zinc coating thickness is heavily influenced by the distance between the strip surface and the gas wiping dies which blow off excess zinc. To this end, establishing a flat, non-curved strip is a key prerequisite to minimize coating thickness deviations and inhomogeneities. A common way to influence the lateral strip profile is to introduce a controlled plastic deformation of the strip at the guiding rolls in the zinc bath. This motivates a data-based study of the optimal roll intermesh value of the zinc bath rolls to achieve a flat (zero-crossbow) strip profile during the galvanizing process. Based on this analysis, a data-based algorithm for the online prediction of the optimal roll intermesh value at the head end of each strip is developed and implemented in an industrial processing line. The prediction results from 1045 strips demonstrate the feasibility and accuracy of the proposed prediction algorithm.",2768-0770,,979-8-3503-3544-6,898-904,IEEE , ,Strips;Deformation;Prediction algorithms;Nonhomogeneous media;Coatings;Plastics;Galvanizing,,
5055,"Title:Joint Biomedical Entity and Relation Extraction Based on Feature Filter Table Labeling

 Joint biomedical entity and relation extraction is essential in biomedical text mining. It automatically identifies entities and uncovers the relation between them from biomedical texts. However, due to the relatively complex semantics of biomedical texts, the current methods are unable to effectively leverage the interaction between the two subtasks. In this work, in order to use the interaction between the subtasks, we propose to model entity labels and relation labels with table-filling. We assume that the table structure facilitates the information exchange between entities and relations. Additionally, a feature filtering module is designed in the model to enhance this interaction. After passing through the feature filtering module, the table was constructed based on the selected global features. Our model was evaluated on two tasks, the task of extracting adverse drug events between drug and disease entities, and the task of extracting interaction between drug entities. Compared with the state-of-the-art systems in these tasks, our model improved the F1 scores of the first task by 0.97% in entity recognition and 1.43% in relation extraction, and that of the second task by 1.14% in relation extraction.",Z. Sun; L. Xing; L. Zhang; H. Cai; M. Guo,,,Joint Biomedical Entity and Relation Extraction Based on Feature Filter Table Labeling,11,,10.1109/ACCESS.2023.3331504 ,IEEE Journals ,,"Joint biomedical entity and relation extraction is essential in biomedical text mining. It automatically identifies entities and uncovers the relation between them from biomedical texts. However, due to the relatively complex semantics of biomedical texts, the current methods are unable to effectively leverage the interaction between the two subtasks. In this work, in order to use the interaction between the subtasks, we propose to model entity labels and relation labels with table-filling. We assume that the table structure facilitates the information exchange between entities and relations. Additionally, a feature filtering module is designed in the model to enhance this interaction. After passing through the feature filtering module, the table was constructed based on the selected global features. Our model was evaluated on two tasks, the task of extracting adverse drug events between drug and disease entities, and the task of extracting interaction between drug entities. Compared with the state-of-the-art systems in these tasks, our model improved the F1 scores of the first task by 0.97% in entity recognition and 1.43% in relation extraction, and that of the second task by 1.14% in relation extraction.",2169-3536,,,127422-127430,IEEE , ,Task analysis;Feature extraction;Biological system modeling;Information filters;Semantics;Data mining;Neurons,,
5056,"Title:DeepDrug: Applying AI for the Advancement of Drug Discovery

 To address the issues of multidrug-resistance and newly emerging pathogens DeepDrug is developing computer aided drug design software utilizing Artificial Intelligence (AI)-based techniques that access very large datasets and, in turn, creates an improved method for identify new compounds rapidly thereby dramatically shortening the developmental time line and the cost to have a new drug accepted. The software the DeepDrug team has developed is collectively referred to as DeepDrug which is comprised of the lead program eSynth (creates new molecules for a researcher's use) together with eMolFrag (decomposes organic compounds into non-redundant fragments) and eToxPred (predicts the possible side effects.). eDrugRes, an AI based module allows the examination of the genomes of pathogens, etc. to aid in developing new compounds.",S. Mukhopadhyay; M. Brylinski; A. Bess; F. Berglind; C. Galliano; P. F. McGrew,,,DeepDrug: Applying AI for the Advancement of Drug Discovery,,,10.1109/COMSNETS53615.2022.9668586 ,IEEE Conferences ,,"To address the issues of multidrug-resistance and newly emerging pathogens DeepDrug is developing computer aided drug design software utilizing Artificial Intelligence (AI)-based techniques that access very large datasets and, in turn, creates an improved method for identify new compounds rapidly thereby dramatically shortening the developmental time line and the cost to have a new drug accepted. The software the DeepDrug team has developed is collectively referred to as DeepDrug which is comprised of the lead program eSynth (creates new molecules for a researcher's use) together with eMolFrag (decomposes organic compounds into non-redundant fragments) and eToxPred (predicts the possible side effects.). eDrugRes, an AI based module allows the examination of the genomes of pathogens, etc. to aid in developing new compounds.",2155-2509,,978-1-6654-2104-1,667-674,IEEE , ,Drugs;Industries;Pathogens;Costs;Software;Vaccines;Artificial intelligence,,
5057,"Title:Model Poisoning Attack In Federated Learning Via Adversarial Examples

 The emergence of federated learning framework sets protects user privacy and has solved the Isolated Data Island problem. However, existing federation attack methods mostly use label flipping for data poisoning attacks, while federated backdoor attacks require patching the target samples. The attacker can also arrange other generative networks at local nodes but has limited data reconstruction capability. Thus, this paper proposes a new poisoning attack method named adversarial example poisoning attack (AEP A). The attacker uses the distributed global model to create adversarial examples and uses the original clean label for federation training and attacks against the specific target class in the dataset. In the evaluation process, we conducted extensive experiments on the CfF AR-l 0 dataset. We also explored the toxicity of the adversarial examples under different generation methods, compared our method with the label-flipping attack, and finally showed the effectiveness of AEPA.",L. Yuan; H. Hu,,,Model Poisoning Attack In Federated Learning Via Adversarial Examples,,,10.1109/SCSET58950.2023.00021 ,IEEE Conferences ,,"The emergence of federated learning framework sets protects user privacy and has solved the Isolated Data Island problem. However, existing federation attack methods mostly use label flipping for data poisoning attacks, while federated backdoor attacks require patching the target samples. The attacker can also arrange other generative networks at local nodes but has limited data reconstruction capability. Thus, this paper proposes a new poisoning attack method named adversarial example poisoning attack (AEP A). The attacker uses the distributed global model to create adversarial examples and uses the original clean label for federation training and attacks against the specific target class in the dataset. In the evaluation process, we conducted extensive experiments on the CfF AR-l 0 dataset. We also explored the toxicity of the adversarial examples under different generation methods, compared our method with the label-flipping attack, and finally showed the effectiveness of AEPA.",,,979-8-3503-0147-2,52-55,IEEE , ,Training;Seminars;Computer science;Data privacy;Toxicology;Federated learning,,
5058,"Title:Attribute Selection and Visualization for Classification for Small Molecules

 The process of drug discovery using in silico methods often produces datasets with a very large number of attributes (fields) per instance (record). Automated classification of such data on properties such as toxicity provides significant benefits for drug design but must cope effectively with the large number of attributes and the relatively small number of instances. This paper studies this problem in the context of a dataset, from prior work, used to discover promising small molecules for controlling circadian rhythm in humans. By identifying a suitable small subset of the attributes that are effective for this classification task, experimental results indicate accuracies that compare very favorably with prior work on the same data.",S. S. Chawathe,,,Attribute Selection and Visualization for Classification for Small Molecules,,,10.1109/UEMCON54665.2022.9965654 ,IEEE Conferences ,,"The process of drug discovery using in silico methods often produces datasets with a very large number of attributes (fields) per instance (record). Automated classification of such data on properties such as toxicity provides significant benefits for drug design but must cope effectively with the large number of attributes and the relatively small number of instances. This paper studies this problem in the context of a dataset, from prior work, used to discover promising small molecules for controlling circadian rhythm in humans. By identifying a suitable small subset of the attributes that are effective for this classification task, experimental results indicate accuracies that compare very favorably with prior work on the same data.",,,978-1-6654-9299-7,456-462,IEEE , ,Drugs;Self-organizing feature maps;Measurement;Toxicology;Prototypes;Focusing;Data visualization,,
5059,"Title:Deep Reinforcement Learning for Medicine Recommendation

 Medicine recommendation is denoted as the task of predicting drug combinations for patients' therapies with complex diseases (i.e., cancer, diabetes, etc.). These patients often follow a treatment that consists of multiple drugs simultaneously, focusing at different human targets such as genes, proteins, etc. Previous research has already integrated the patients' Electronic Health Records (EHRs) with an adversarial Drug-Drug Interaction (DDI) knowledge graph to predict the next drug combination for a patient's therapy and minimize the drug side effects. However, they miss to consider additional valuable information that comes from synergistic Drug-Drug interaction knowledge graphs. In this paper, we integrate an EHR graph, which incorporates the patient, the disease, the therapy, and the drug information, with a Synergistic and/or an Adversarial DDI knowledge graph to recommend both accurate and safe medication. By identifying those drugs which can act synergistically and/or adversely, we are able to improve either the efficacy of the patient's therapy or minimize the toxicity and drug side effects. We have run experiments with two real-life medical data sets. Our results show that we can assist doctors to prescribe effective and safe medication for the patients' treatment.",P. Symeonidis; S. Chairistanidis; M. Zanker,,,Deep Reinforcement Learning for Medicine Recommendation,,,10.1109/BIBE55377.2022.00026 ,IEEE Conferences ,,"Medicine recommendation is denoted as the task of predicting drug combinations for patients' therapies with complex diseases (i.e., cancer, diabetes, etc.). These patients often follow a treatment that consists of multiple drugs simultaneously, focusing at different human targets such as genes, proteins, etc. Previous research has already integrated the patients' Electronic Health Records (EHRs) with an adversarial Drug-Drug Interaction (DDI) knowledge graph to predict the next drug combination for a patient's therapy and minimize the drug side effects. However, they miss to consider additional valuable information that comes from synergistic Drug-Drug interaction knowledge graphs. In this paper, we integrate an EHR graph, which incorporates the patient, the disease, the therapy, and the drug information, with a Synergistic and/or an Adversarial DDI knowledge graph to recommend both accurate and safe medication. By identifying those drugs which can act synergistically and/or adversely, we are able to improve either the efficacy of the patient's therapy or minimize the toxicity and drug side effects. We have run experiments with two real-life medical data sets. Our results show that we can assist doctors to prescribe effective and safe medication for the patients' treatment.",2471-7819,,978-1-6654-8487-9,85-90,IEEE , ,Drugs;Proteins;Deep learning;Toxicology;Medical treatment;Focusing;Reinforcement learning,,
5060,"Title:Comparing Clustering Techniques for Real Microarray Data

 The clustering of genes detected as significant or differentially expressed provides useful information to biologists about functions and functional relationship of genes. There are variant types of clustering methods that can be applied in genomic data. These are mainly divided into the two groups, namely, hierarchical and partitional methods. In this paper, as the novelty, we perform a detailed clustering analysis for the recently collected boron micro array dataset to investigate biologically more interesting results and to construct a basis for the selection of the most effective method in the analysis of different micro array datum. In the calculation, we implement the agglomerative hierarchical clustering among hierarchical techniques and use the k-means and the PAMSAM methods within partitional clustering approaches, and finally use a recently improved method, called HIPAM, which is not only a hierarchical but also partitional approach. In the assessment, we compare and discuss the significant genes of the boron data whose estimated signals are found by the FGX normalization method.",V. P. Gazi; E. Kayis,,,Comparing Clustering Techniques for Real Microarray Data,,,10.1109/ASONAM.2012.143 ,IEEE Conferences ,,"The clustering of genes detected as significant or differentially expressed provides useful information to biologists about functions and functional relationship of genes. There are variant types of clustering methods that can be applied in genomic data. These are mainly divided into the two groups, namely, hierarchical and partitional methods. In this paper, as the novelty, we perform a detailed clustering analysis for the recently collected boron micro array dataset to investigate biologically more interesting results and to construct a basis for the selection of the most effective method in the analysis of different micro array datum. In the calculation, we implement the agglomerative hierarchical clustering among hierarchical techniques and use the k-means and the PAMSAM methods within partitional clustering approaches, and finally use a recently improved method, called HIPAM, which is not only a hierarchical but also partitional approach. In the assessment, we compare and discuss the significant genes of the boron data whose estimated signals are found by the FGX normalization method.",,,978-1-4673-2497-7,788-791,IEEE , ,Boron;Clustering methods;Gene expression;RNA;Clustering algorithms;Arrays,,
5061,"Title:Comparison of radiomics approaches to predict resistance to 1st line chemotherapy in liver metastatic colorectal cancer

 Colorectal cancer (CRC) has the second-highest tumor incidence and is a leading cause of death by cancer. Nearly 20% of patients with CRC will have metastases (mts) at the time of diagnosis, and more than 50% of patients with CRC develop metastases during their disease. Unfortunately, only 45% of patients after a chemotherapy will respond to treatment. The aim of this study is to develop and validate a machine learning algorithm to predict response of individual liver mts, using CT scans. Understanding which mts will respond or not will help clinicians in providing a more efficient per-lesion treatment based on patient specific response and not only following a standard treatment. A group of 92 patients was enrolled from two Italian institutions. CT scans were collected, and the portal venous phase was manually segmented by an expert radiologist. Then, 75 radiomics features were extracted both from 7x7 ROIs that moved across the image and from the whole 3D mts. Feature selection was performed using a genetic algorithm. Results are presented as a comparison of the two different approaches of features extraction and different classification algorithms. Accuracy (ACC), sensitivity (SE), specificity (SP), negative and positive predictive values (NPV and PPV) were evaluated for all lesions (per-lesion analysis) and patients (per-patient analysis) in the construction and validation sets. Best results were obtained in the per-lesion analysis from the 3D approach using a Support Vector Machine as classifier. We reached on the training set an ACC of 81%, while on test set, we obtained SE of 76%, SP of 67%, PPV of 69% and NPV of 75%. On the validation set a SE of 61%, SP of 60%, PPV of 57% and NPV of 64% were reached. The promising results obtained in the validation dataset should be extended to a larger cohort of patient to further validate our method.Clinical Relevance— to develop a radiomics signatures predicting single liver mts response to therapy. A personalized mts approach is important to avoid unnecessary toxicity offering more suitable treatments and a better quality of life to oncological patients.",A. Defeudis; L. Cefaloni; G. Giannetto; G. Cappello; F. Rizzetto; J. Panic; D. Barra; G. Nicoletti; S. Mazzetti; A. Vanzulli; D. Regge; V. Giannini,,,Comparison of radiomics approaches to predict resistance to 1st line chemotherapy in liver metastatic colorectal cancer,,,10.1109/EMBC46164.2021.9630316 ,IEEE Conferences ,,"Colorectal cancer (CRC) has the second-highest tumor incidence and is a leading cause of death by cancer. Nearly 20% of patients with CRC will have metastases (mts) at the time of diagnosis, and more than 50% of patients with CRC develop metastases during their disease. Unfortunately, only 45% of patients after a chemotherapy will respond to treatment. The aim of this study is to develop and validate a machine learning algorithm to predict response of individual liver mts, using CT scans. Understanding which mts will respond or not will help clinicians in providing a more efficient per-lesion treatment based on patient specific response and not only following a standard treatment. A group of 92 patients was enrolled from two Italian institutions. CT scans were collected, and the portal venous phase was manually segmented by an expert radiologist. Then, 75 radiomics features were extracted both from 7x7 ROIs that moved across the image and from the whole 3D mts. Feature selection was performed using a genetic algorithm. Results are presented as a comparison of the two different approaches of features extraction and different classification algorithms. Accuracy (ACC), sensitivity (SE), specificity (SP), negative and positive predictive values (NPV and PPV) were evaluated for all lesions (per-lesion analysis) and patients (per-patient analysis) in the construction and validation sets. Best results were obtained in the per-lesion analysis from the 3D approach using a Support Vector Machine as classifier. We reached on the training set an ACC of 81%, while on test set, we obtained SE of 76%, SP of 67%, PPV of 69% and NPV of 75%. On the validation set a SE of 61%, SP of 60%, PPV of 57% and NPV of 64% were reached. The promising results obtained in the validation dataset should be extended to a larger cohort of patient to further validate our method.Clinical Relevance— to develop a radiomics signatures predicting single liver mts response to therapy. A personalized mts approach is important to avoid unnecessary toxicity offering more suitable treatments and a better quality of life to oncological patients.",2694-0604,,978-1-7281-1179-7,3305-3308,IEEE , ,Training;Support vector machines;Three-dimensional displays;Chemotherapy;Toxicology;Computed tomography;Liver,,
5062,"Title:User Feedback Severity Level Identification and Classification through Deeper Analysis of Text

 Now a days world is look right on digitalized. Social media is captivating in this digital age through the accessibility of consumer's feedback. The recent work in the field of classification based on comments on social media is gaining appeal on a global scale. Unfortunately, the study does not offer better accuracy in terms of toxic comments. On social media platforms, hateful and abusive language has a detrimental effect on users' mental health and involvement from people from all diverse backgrounds. Automatic methods is most commonly used datasets with categorical labels to detect foul language. The level of offensiveness of comments varies. In NLP we use binary classification like either a comment is offensive or not and leave continues classification. In continues classification one can identify the severity level of comments, can set a threshold, and by using Deep Learning and modeling techniques can directly identify the severity level of comments by considering context. The review of related literature shows that identification of toxicity of user comments can be improved by pre-processing methods, such as deleting null values and anomies from the dataset, to refine the dataset and increase its accuracy by applying different algorithm techniques to make feature more valuables. This research provides analysis of user comments datasets and study's user comments toxicity with different machine learning approaches. First, we need to do pre-processing steps including punctuations, stop words, null entries, and duplicate removal to remove anomalies. After that we need to apply different methods like count vectorizer and bag of words to extract features. After that, we MCPL algorithm applied on these datasets to predicts results. By applying MCPL model on user comments dataset 88.5% accuracy were founded.",M. Umair; S. Aun Irtaza; S. Salim,,,User Feedback Severity Level Identification and Classification through Deeper Analysis of Text,,,10.1109/iCoMET57998.2023.10099177 ,IEEE Conferences ,,"Now a days world is look right on digitalized. Social media is captivating in this digital age through the accessibility of consumer's feedback. The recent work in the field of classification based on comments on social media is gaining appeal on a global scale. Unfortunately, the study does not offer better accuracy in terms of toxic comments. On social media platforms, hateful and abusive language has a detrimental effect on users' mental health and involvement from people from all diverse backgrounds. Automatic methods is most commonly used datasets with categorical labels to detect foul language. The level of offensiveness of comments varies. In NLP we use binary classification like either a comment is offensive or not and leave continues classification. In continues classification one can identify the severity level of comments, can set a threshold, and by using Deep Learning and modeling techniques can directly identify the severity level of comments by considering context. The review of related literature shows that identification of toxicity of user comments can be improved by pre-processing methods, such as deleting null values and anomies from the dataset, to refine the dataset and increase its accuracy by applying different algorithm techniques to make feature more valuables. This research provides analysis of user comments datasets and study's user comments toxicity with different machine learning approaches. First, we need to do pre-processing steps including punctuations, stop words, null entries, and duplicate removal to remove anomalies. After that we need to apply different methods like count vectorizer and bag of words to extract features. After that, we MCPL algorithm applied on these datasets to predicts results. By applying MCPL model on user comments dataset 88.5% accuracy were founded.",,,979-8-3503-3531-6,1-7,IEEE , ,Deep learning;Toxicology;Machine learning algorithms;Social networking (online);Null value;Mental health;Feature extraction,,
5063,"Title:Reliably Filter Drug-Induced Liver Injury Literature With Natural Language Processing and Conformal Prediction

 Drug-induced liver injury describes the adverse effects of drugs that damage the liver. Life-threatening results were also reported in severe cases. Therefore, liver toxicity is an important assessment for new drug candidates. These reports are documented in research papers that contain preliminary in vitro and in vivo experiments. Conventionally, data extraction from publications relies on resource-demanding manual labeling, which restricts the efficiency of the information extraction. The development of natural language processing techniques enables the automatic processing of biomedical texts. Herein, based on around 28,000 papers (titles and abstracts) provided by the Critical Assessment of Massive Data Analysis challenge, this study benchmarked model performances on filtering liver-damage-related literature. Among five text embedding techniques, the model using term frequency-inverse document frequency (TF-IDF) and logistic regression outperformed others with an accuracy of 0.957 on the validation set. Furthermore, an ensemble model with similar overall performances was developed with a logistic regression model on the predicted probability given by separate models with different vectorization techniques. The ensemble model achieved a high accuracy of 0.954 and an F1 score of 0.955 in the hold-out validation data in the challenge. Moreover, important words in positive/negative predictions were identified via model interpretation. The prediction reliability was quantified with conformal prediction, which provides users with a control over the prediction uncertainty. Overall, the ensemble model and TF-IDF model reached satisfactory classification results, which can be used by researchers to rapidly filter literature that describes events related to liver injury induced by medications.",X. Zhan; F. Wang; O. Gevaert,,,Reliably Filter Drug-Induced Liver Injury Literature With Natural Language Processing and Conformal Prediction,26,10,10.1109/JBHI.2022.3193365 ,IEEE Journals ,,"Drug-induced liver injury describes the adverse effects of drugs that damage the liver. Life-threatening results were also reported in severe cases. Therefore, liver toxicity is an important assessment for new drug candidates. These reports are documented in research papers that contain preliminary in vitro and in vivo experiments. Conventionally, data extraction from publications relies on resource-demanding manual labeling, which restricts the efficiency of the information extraction. The development of natural language processing techniques enables the automatic processing of biomedical texts. Herein, based on around 28,000 papers (titles and abstracts) provided by the Critical Assessment of Massive Data Analysis challenge, this study benchmarked model performances on filtering liver-damage-related literature. Among five text embedding techniques, the model using term frequency-inverse document frequency (TF-IDF) and logistic regression outperformed others with an accuracy of 0.957 on the validation set. Furthermore, an ensemble model with similar overall performances was developed with a logistic regression model on the predicted probability given by separate models with different vectorization techniques. The ensemble model achieved a high accuracy of 0.954 and an F1 score of 0.955 in the hold-out validation data in the challenge. Moreover, important words in positive/negative predictions were identified via model interpretation. The prediction reliability was quantified with conformal prediction, which provides users with a control over the prediction uncertainty. Overall, the ensemble model and TF-IDF model reached satisfactory classification results, which can be used by researchers to rapidly filter literature that describes events related to liver injury induced by medications.",2168-2208,,,5033-5041,IEEE , ,Liver;Predictive models;Drugs;Data models;Training;Bioinformatics;Injuries,,
5064,"Title:Inter-Rater Agreement for Social Computing Studies

 Different agreement scores are widely used in social computing studies to evaluate the reliability of crowdsourced ratings. In this research, we argue that the concept of agreement is problematic for many rating tasks in computational social science because they are characterized by subjectivity. We demonstrate this claim by analyzing four social computing datasets that are rated by crowd workers, showing that the agreement ratings are low despite deploying proper instructions and platform settings. Findings indicate that the more subjective the rating task, the lower the agreement, suggesting that tasks differ by their inherent subjectivity and that measuring the agreement of social computing tasks might not be the optimal way to ensure data quality. When creating subjective tasks, the use of agreement metrics potentially gives a false picture of the consistency of crowd workers, as they over-simplify the reality of obtaining quality labels. We also provide empirical evidence on the stability of crowd ratings with a different number of raters, items, and categories, finding that the reliability scores are most sensitive to the number categories, somewhat less sensitive to the number of raters, and the least sensitive to the number of items. Our findings have implications for computational social scientists using crowdsourcing for data collection.",J. O. Salminen; H. A. Al-Merekhi; P. Dey; B. J. Jansen,,,Inter-Rater Agreement for Social Computing Studies,,,10.1109/SNAMS.2018.8554744 ,IEEE Conferences ,,"Different agreement scores are widely used in social computing studies to evaluate the reliability of crowdsourced ratings. In this research, we argue that the concept of agreement is problematic for many rating tasks in computational social science because they are characterized by subjectivity. We demonstrate this claim by analyzing four social computing datasets that are rated by crowd workers, showing that the agreement ratings are low despite deploying proper instructions and platform settings. Findings indicate that the more subjective the rating task, the lower the agreement, suggesting that tasks differ by their inherent subjectivity and that measuring the agreement of social computing tasks might not be the optimal way to ensure data quality. When creating subjective tasks, the use of agreement metrics potentially gives a false picture of the consistency of crowd workers, as they over-simplify the reality of obtaining quality labels. We also provide empirical evidence on the stability of crowd ratings with a different number of raters, items, and categories, finding that the reliability scores are most sensitive to the number categories, somewhat less sensitive to the number of raters, and the least sensitive to the number of items. Our findings have implications for computational social scientists using crowdsourcing for data collection.",,,978-1-5386-9588-3,80-87,IEEE , ,Social computing;Reliability;Task analysis;Measurement;Social network services;Training data;Mathematical model,,
5065,"Title:The Michigan Data Science Team: A Data Science Education Program with Significant Social Impact

 One role of universities is to provide students with the practical knowledge necessary to address broad societal needs. The growing field of data science has the potential to address many of these needs, primarily due to recent efforts to collect large amounts of data related to social, environmental, and political issues. A challenge is that there exists a disconnect between these real-world issues and the course materials taught to university students. This gap is due in part to a lack of engagement between universities and their local communities, leaving students with few opportunities to work with datasets relevant to real-world problems. To address this disconnect, the authors have implemented a novel data science education and outreach program in which students acquire new knowledge and skills while creating positive social impact through community service. In this work, we outline this outreach program, the Michigan Data Science Team, and provide empirical evidence of positive educational and social impact.",A. Farahi; J. C. Stroud,,,The Michigan Data Science Team: A Data Science Education Program with Significant Social Impact,,,10.1109/DSW.2018.8439915 ,IEEE Conferences ,,"One role of universities is to provide students with the practical knowledge necessary to address broad societal needs. The growing field of data science has the potential to address many of these needs, primarily due to recent efforts to collect large amounts of data related to social, environmental, and political issues. A challenge is that there exists a disconnect between these real-world issues and the course materials taught to university students. This gap is due in part to a lack of engagement between universities and their local communities, leaving students with few opportunities to work with datasets relevant to real-world problems. To address this disconnect, the authors have implemented a novel data science education and outreach program in which students acquire new knowledge and skills while creating positive social impact through community service. In this work, we outline this outreach program, the Michigan Data Science Team, and provide empirical evidence of positive educational and social impact.",,,978-1-5386-4410-2,120-124,IEEE , ,Data science;Tutorials;Collaboration;Mentoring;Organizations;Encoding,,
5066,"Title:Environmental Assessment of a New Developed Camera System for Automotive Application

 Embedding technology is an advanced electronic packaging method which allows assembling electronic components not only on the surface but also inside the volume of the printed circuit board material. The resulting higher packing density of assemblies leads to drastic miniaturisation of the package and reduces the expenditure on materials. This work compares the environmental performance of a conventional and a new developed rear camera system for automotive application. The life cycle assessment method is ReCiPe Midpoint (H), 2014, based on the ecoinvent 3.3 database. The considered characterisation categories are Climate change (CC), Human toxicity (HT), and Terrestrial ecotoxicity (TE). The new demonstrator camera shows in all characterisation categories a reduction of the environmental impact between 55 % and 60 % within the defined system boundaries, compared to the traditional multilayer PCB assembly, and a mass reduction of 31 %.",M. Franz; M. Unger; G. Schmid; J. Nicolics,,,Environmental Assessment of a New Developed Camera System for Automotive Application,,,10.1109/ISSE.2018.8443694 ,IEEE Conferences ,,"Embedding technology is an advanced electronic packaging method which allows assembling electronic components not only on the surface but also inside the volume of the printed circuit board material. The resulting higher packing density of assemblies leads to drastic miniaturisation of the package and reduces the expenditure on materials. This work compares the environmental performance of a conventional and a new developed rear camera system for automotive application. The life cycle assessment method is ReCiPe Midpoint (H), 2014, based on the ecoinvent 3.3 database. The considered characterisation categories are Climate change (CC), Human toxicity (HT), and Terrestrial ecotoxicity (TE). The new demonstrator camera shows in all characterisation categories a reduction of the environmental impact between 55 % and 60 % within the defined system boundaries, compared to the traditional multilayer PCB assembly, and a mass reduction of 31 %.",2161-2536,,978-1-5386-5731-7,1-8,IEEE , ,Cameras;Production;Climate change;Environmental factors;Automotive engineering,,
5067,"Title:Molecule Classification Using Visualization and Convolutional Neural Network

 In this paper, we propose a procedure that provides solid performance regarding molecule classification. Our solution can predict with high accuracy the toxicity and activity of different unknown molecules based on their compounds and structural information. As for the methodological contribution, our approach takes the commonly used SMILES strings and generates the three dimensional model of the investigated molecule. After that, we project this model to the two-dimensional plane from different points of view and a pre-trained convolutional neural network classifies all of these generated 2D images. The final class label is derived as an ensemble of these classification outputs. For the ensemble of class labels and the applied visualization method, we have reached 90.66% classification accuracy with ROC-AUC 0.9629.",I. Lakatos; A. Hajdu; B. Harangi,,,Molecule Classification Using Visualization and Convolutional Neural Network,,,10.1109/ISBI48211.2021.9433953 ,IEEE Conferences ,,"In this paper, we propose a procedure that provides solid performance regarding molecule classification. Our solution can predict with high accuracy the toxicity and activity of different unknown molecules based on their compounds and structural information. As for the methodological contribution, our approach takes the commonly used SMILES strings and generates the three dimensional model of the investigated molecule. After that, we project this model to the two-dimensional plane from different points of view and a pre-trained convolutional neural network classifies all of these generated 2D images. The final class label is derived as an ensemble of these classification outputs. For the ensemble of class labels and the applied visualization method, we have reached 90.66% classification accuracy with ROC-AUC 0.9629.",1945-8452,,978-1-6654-1246-9,1695-1698,IEEE , ,Training;Visualization;Solid modeling;Toxicology;Three-dimensional displays;Two dimensional displays;Image representation,,
5068,"Title:Development of Deep Learning approaches to predict relationships between chemical structures and sweetness

 The non-caloric sweeteners market is catching up with the market of conventionally used sugars due to the benefits of preventing obesity, tooth decay and other health problems. Developing strategies for designing easier-to-produce novel molecules with a sweet taste and less toxicity are up-to-date motivations for the food industry. In this sense, Machine Learning (ML) approaches have been reported as cutting-edge technologies to guide the design of new molecules towards specific objectives, including sweet taste. The largest known dataset of sweet molecules is here provided. The dataset contains fully integrated 9541 sweeteners and 1141 bitterants from FooDB, FlavorDB and literature. This robust dataset allowed the development of standard Machine and Deep Learning pipelines towards conceiving Structure-Activity Relationships (SAR) between molecules and sweetness. In this work, we showcase that Textual Convolutional Neural Networks (TextCNN), Graph Convolutional Networks (GCN), and Deep Neural Networks (DNNs) outperformed most of traditional “shallow” learning approaches. These Deep Learning (DL) models produced platforms to guide the design of new sweeteners and repurposing existing compounds. Sixty million compounds from PubChem were evaluated using these models. Herein, we deliver a dataset of 67724 compounds that present high probabilities of being sweet. Quick searches in literature allowed us to find 13 molecules reported as potent sweetening agents, revealing that our approach is suitable for finding new sweeteners, valuable to expand food chemistry databases, repurposing existing chemicals and designing novel molecules with a sweet taste.",J. Capela; J. Correia; V. Pereira; M. Rocha,,,Development of Deep Learning approaches to predict relationships between chemical structures and sweetness,,,10.1109/IJCNN55064.2022.9891992 ,IEEE Conferences ,,"The non-caloric sweeteners market is catching up with the market of conventionally used sugars due to the benefits of preventing obesity, tooth decay and other health problems. Developing strategies for designing easier-to-produce novel molecules with a sweet taste and less toxicity are up-to-date motivations for the food industry. In this sense, Machine Learning (ML) approaches have been reported as cutting-edge technologies to guide the design of new molecules towards specific objectives, including sweet taste. The largest known dataset of sweet molecules is here provided. The dataset contains fully integrated 9541 sweeteners and 1141 bitterants from FooDB, FlavorDB and literature. This robust dataset allowed the development of standard Machine and Deep Learning pipelines towards conceiving Structure-Activity Relationships (SAR) between molecules and sweetness. In this work, we showcase that Textual Convolutional Neural Networks (TextCNN), Graph Convolutional Networks (GCN), and Deep Neural Networks (DNNs) outperformed most of traditional “shallow” learning approaches. These Deep Learning (DL) models produced platforms to guide the design of new sweeteners and repurposing existing compounds. Sixty million compounds from PubChem were evaluated using these models. Herein, we deliver a dataset of 67724 compounds that present high probabilities of being sweet. Quick searches in literature allowed us to find 13 molecules reported as potent sweetening agents, revealing that our approach is suitable for finding new sweeteners, valuable to expand food chemistry databases, repurposing existing chemicals and designing novel molecules with a sweet taste.",2161-4407,,978-1-7281-8671-9,1-8,IEEE , ,Deep learning;Toxicology;Pipelines;Neural networks;Predictive models;Data models;Sugar industry,,
5069,"Title:Enhanced Graph Isomorphism Network for Molecular ADMET Properties Prediction

 The evaluation of absorption, distribution, metabolism, exclusion, and toxicity (ADMET) properties plays a key role in a variety of domains including industrial chemicals, agrochemicals, cosmetics, environmental science, food chemistry, and particularly drug development. Since molecules are often intrinsically described as molecular graphs, graph neural networks have recently been studied to improve the prediction of ADMET properties. Among many graph neural networks published in recent years, Graph Isomorphism Network (GIN) is a relatively recent and very promising one. In this paper, we propose an enhanced GIN, called MolGIN, via exploiting the bond features and differences influence of the atom neighbors to end-to-end predict ADMET properties. Based on GIN, MolGIN concatenates the bond feature together with node feature in the feature aggregator and applies a gate unit to adjust the atomic neighborhood weights to map the differences in the interaction strength between the central atom and its neighbors, such that more meaningful structural patterns of molecules can be explored toward better molecular modeling. Extensive experiments were conducted on seven public datasets to evaluate MolGIN against four baseline models with benchmark metrics. Experimental results of MolGIN were also compared with state-of-the-art results published in the last three years on each dataset. Experimental results in terms of RMSE and AUC show that MolGIN significantly boosts the prediction performance of GIN and markedly outperforms the baseline models, and achieves comparable or superior performance to state-of-the-art results.",Y. Peng; Y. Lin; X. -Y. Jing; H. Zhang; Y. Huang; G. S. Luo,,,Enhanced Graph Isomorphism Network for Molecular ADMET Properties Prediction,8,,10.1109/ACCESS.2020.3022850 ,IEEE Journals ,,"The evaluation of absorption, distribution, metabolism, exclusion, and toxicity (ADMET) properties plays a key role in a variety of domains including industrial chemicals, agrochemicals, cosmetics, environmental science, food chemistry, and particularly drug development. Since molecules are often intrinsically described as molecular graphs, graph neural networks have recently been studied to improve the prediction of ADMET properties. Among many graph neural networks published in recent years, Graph Isomorphism Network (GIN) is a relatively recent and very promising one. In this paper, we propose an enhanced GIN, called MolGIN, via exploiting the bond features and differences influence of the atom neighbors to end-to-end predict ADMET properties. Based on GIN, MolGIN concatenates the bond feature together with node feature in the feature aggregator and applies a gate unit to adjust the atomic neighborhood weights to map the differences in the interaction strength between the central atom and its neighbors, such that more meaningful structural patterns of molecules can be explored toward better molecular modeling. Extensive experiments were conducted on seven public datasets to evaluate MolGIN against four baseline models with benchmark metrics. Experimental results of MolGIN were also compared with state-of-the-art results published in the last three years on each dataset. Experimental results in terms of RMSE and AUC show that MolGIN significantly boosts the prediction performance of GIN and markedly outperforms the baseline models, and achieves comparable or superior performance to state-of-the-art results.",2169-3536,,,168344-168360,IEEE , ,Predictive models;Drugs;Neural networks;Compounds;Machine learning;Chemicals;Logic gates,,
5070,"Title:Online Hate Interpretation Varies by Country, But More by Individual: A Statistical Analysis Using Crowdsourced Ratings

 Hate is prevalent in online social media. This has resulted in a considerable amount of research in detecting and scoring it. Most computational efforts involve machine learning with crowdsourced ratings as training data. A prominent example of this is the Perspective API., a tool by Google to score toxicity of online comments. However., a major issue in the existing approaches is the lack of consideration for the subjective nature of online hate. While there is research that shows the intensity of hate varies and the hate depends on the context., there is no research that systematically investigates how hate interpretation varies by country or individual. In this exploratory research, we undertake this challenge. We sample crowd workers from 50 countries, have them score the same social media comments for toxicity and then evaluate the differences in the scores., altogether 18.,125 ratings. We find that the interpretation score differences among countries are highly significant. However., the hate interpretations vary more by the individual raters than by countries. These findings suggest that hate scoring systems should consider user-level features when scoring and automating the processing of online hate.",J. Salminen; F. Veronesi; H. Almerekhi; S. -G. Jung; B. J. Jansen,,,"Online Hate Interpretation Varies by Country, But More by Individual: A Statistical Analysis Using Crowdsourced Ratings",,,10.1109/SNAMS.2018.8554954 ,IEEE Conferences ,,"Hate is prevalent in online social media. This has resulted in a considerable amount of research in detecting and scoring it. Most computational efforts involve machine learning with crowdsourced ratings as training data. A prominent example of this is the Perspective API., a tool by Google to score toxicity of online comments. However., a major issue in the existing approaches is the lack of consideration for the subjective nature of online hate. While there is research that shows the intensity of hate varies and the hate depends on the context., there is no research that systematically investigates how hate interpretation varies by country or individual. In this exploratory research, we undertake this challenge. We sample crowd workers from 50 countries, have them score the same social media comments for toxicity and then evaluate the differences in the scores., altogether 18.,125 ratings. We find that the interpretation score differences among countries are highly significant. However., the hate interpretations vary more by the individual raters than by countries. These findings suggest that hate scoring systems should consider user-level features when scoring and automating the processing of online hate.",,,978-1-5386-9588-3,88-94,IEEE , ,Dictionaries;Facebook;YouTube;Media;Task analysis;Security,,
5071,"Title:An Efficient Computer Vision Approach for Rapid Recognition of Poisonous Plants by Classifying Leaf Images using Transfer Learning

 Livestock poisoning by several kinds of poisonous plants causes grievous economic losses to the livestock industry. Poisonous plants are also a fatal threat to humans, ingesting these plants can cause several side effects in the body because of their toxicity. Hence, it is essential to develop a rapid approach to recognize poisonous plants efficiently. This paper addresses a recognition approach for eighteen poisonous plants using poisonous plants leaf (PPL) dataset which has been generated using image augmentation techniques that contains 54000 training, 27000 validation, and 9000 testing images. Six different state-of-the-art deep learning models have been used in this study such as Xception, ResNet152V2, InceptionResNetV2, MobileNetV2, DenseNet201, and NASNetLarge for classifying leaf images of poisonous plants. Xception has shown more significant performance than other models, achieved 99.71% training and 99.37% testing accuracy. NASNetLarge and InceptionResNetV2 have achieved 96.89% and 95.18% test accuracy, respectively, and MobileNetV2 achieved the lowest test accuracy.",R. H. Hridoy; F. Akter; M. Afroz,,,An Efficient Computer Vision Approach for Rapid Recognition of Poisonous Plants by Classifying Leaf Images using Transfer Learning,,,10.1109/ICCCNT51525.2021.9580011 ,IEEE Conferences ,,"Livestock poisoning by several kinds of poisonous plants causes grievous economic losses to the livestock industry. Poisonous plants are also a fatal threat to humans, ingesting these plants can cause several side effects in the body because of their toxicity. Hence, it is essential to develop a rapid approach to recognize poisonous plants efficiently. This paper addresses a recognition approach for eighteen poisonous plants using poisonous plants leaf (PPL) dataset which has been generated using image augmentation techniques that contains 54000 training, 27000 validation, and 9000 testing images. Six different state-of-the-art deep learning models have been used in this study such as Xception, ResNet152V2, InceptionResNetV2, MobileNetV2, DenseNet201, and NASNetLarge for classifying leaf images of poisonous plants. Xception has shown more significant performance than other models, achieved 99.71% training and 99.37% testing accuracy. NASNetLarge and InceptionResNetV2 have achieved 96.89% and 95.18% test accuracy, respectively, and MobileNetV2 achieved the lowest test accuracy.",,,978-1-7281-8595-8,1-7,IEEE , ,Training;Deep learning;Computer vision;Image recognition;Biological system modeling;Computational modeling;Transfer learning,,
5072,"Title:Predicting Physiological Effects of Chemical Substances Using Natural Language Processing

 In this paper, we apply natural language processing methods to develop models for predicting physiological effects of chemical substances based on their molecular structures. Using string representations of structure as a starting point, we vectorize molecules using two different approaches resulting in sparse and dense vector representations, respectively. We use these representations to train predictive models for a variety of physiological effects such as toxicity, cell cycle arrest and proliferation. Using standard chemical datasets, we empirically demonstrate that such models can achieve high predictive accu-racy.",S. Mukherjee; J. Ben-Joseph; M. Campos; P. Malla; H. Nguyen; A. Pham; T. Oates; V. Janarthanan,,,Predicting Physiological Effects of Chemical Substances Using Natural Language Processing,,,10.1109/CCECE53047.2021.9569202 ,IEEE Conferences ,,"In this paper, we apply natural language processing methods to develop models for predicting physiological effects of chemical substances based on their molecular structures. Using string representations of structure as a starting point, we vectorize molecules using two different approaches resulting in sparse and dense vector representations, respectively. We use these representations to train predictive models for a variety of physiological effects such as toxicity, cell cycle arrest and proliferation. Using standard chemical datasets, we empirically demonstrate that such models can achieve high predictive accu-racy.",2576-7046,,978-1-6654-4864-2,1-6,IEEE , ,Drugs;Toxicology;Machine learning algorithms;Costs;Predictive models;Feature extraction;Physiology,,
5073,"Title:Neural grammar networks for toxicology

 In this paper we compare two methods for toxicity prediction: a novel method called a neural grammar network (NGN) and a more conventional Quantitative Structure Activity Relation (QSAR) approach based on a feed forward artificial neural network (ANN). Focusing each round of training and prediction on target organisms and specific organ systems sufficiently narrows down the parameters for us to do useful toxicity prediction. We represent the molecules in the dataset two ways. Simplified Molecular Input Line Entry Specification (SMILES) are input to the NGN while Feature vectors (or chemical descriptors) are input to the ANN. We perform training and testing on a regression-type problem wherein we predict the Lethal Dose for 50% (LD50) of the population of a given organism for the molecules in each dataset. The results of the experiment indicates that the SMILES-NGN method outperformed the ANN method in QSAR. The SMILES-NGN estimates were closer to their targets for 87% of the trials on randomized training data (as described in Section II.B) and 62% on grouped data when compared to ANN. The results also showed less variance in 87% of cases for NGN-SMILES estimates compared to ANN. Using a toxicity prediction method such as the one presented here allows the prediction of toxicity without the need for costly lab experiment (and which are, by definition, lethal to the test subjects).",C. J. F. Cameron; E. Y. T. Ma; S. C. Kremer,,,Neural grammar networks for toxicology,,,10.1109/CIBCB.2010.5510322 ,IEEE Conferences ,,"In this paper we compare two methods for toxicity prediction: a novel method called a neural grammar network (NGN) and a more conventional Quantitative Structure Activity Relation (QSAR) approach based on a feed forward artificial neural network (ANN). Focusing each round of training and prediction on target organisms and specific organ systems sufficiently narrows down the parameters for us to do useful toxicity prediction. We represent the molecules in the dataset two ways. Simplified Molecular Input Line Entry Specification (SMILES) are input to the NGN while Feature vectors (or chemical descriptors) are input to the ANN. We perform training and testing on a regression-type problem wherein we predict the Lethal Dose for 50% (LD50) of the population of a given organism for the molecules in each dataset. The results of the experiment indicates that the SMILES-NGN method outperformed the ANN method in QSAR. The SMILES-NGN estimates were closer to their targets for 87% of the trials on randomized training data (as described in Section II.B) and 62% on grouped data when compared to ANN. The results also showed less variance in 87% of cases for NGN-SMILES estimates compared to ANN. Using a toxicity prediction method such as the one presented here allows the prediction of toxicity without the need for costly lab experiment (and which are, by definition, lethal to the test subjects).",,,978-1-4244-6766-2,1-8,IEEE , ,Toxicology;Artificial neural networks;Next generation networking;Organisms;Testing;Feeds;Chemicals;Performance evaluation;Training data;Prediction methods,,
5074,"Title:Rating the Severity of Toxic Comments Using BERT-Based Deep Learning Method

 With the integration of Internet and smartphones into people’s lives, toxic comments become ubiquitous on various online social media. These comments hinder seriously the construction of a safe and healthy network environment, leading to a great demand for automated methods which can effectively identify such harmful information and deal with it in a timely manner. To address this challenge, we propose a BERT-based deep learning method in this paper to rate the severity of toxic comments. On the basis of the text dataset provided by Jigsaw, BERT-based backbones (RoBERTa and DeBERTa) are trained to extract contextualized embeddings from sentences. After that, corresponding severity scores of comments are calculated by the subsequent head layers, where the head is chosen from the multilayer perceptron, convolutional neural network, and attention structure. After applying the K-Fold cross validation and an average ensemble of different models, our method achieves a rank 28/2301 (top 1.2%) in the leaderboard of Jigsaw Rate Severity of Toxic Comments Kaggle competition. This result can get a silver medal in this competition, and proves that our model can be an effective approach to rate precisely the severity of a toxic comment. This work can remarkably reduce the workload of manual review of Internet content and help build a more harmonious online community environment.",Z. Zhai,,,Rating the Severity of Toxic Comments Using BERT-Based Deep Learning Method,,,10.1109/ICET55676.2022.9825384 ,IEEE Conferences ,,"With the integration of Internet and smartphones into people’s lives, toxic comments become ubiquitous on various online social media. These comments hinder seriously the construction of a safe and healthy network environment, leading to a great demand for automated methods which can effectively identify such harmful information and deal with it in a timely manner. To address this challenge, we propose a BERT-based deep learning method in this paper to rate the severity of toxic comments. On the basis of the text dataset provided by Jigsaw, BERT-based backbones (RoBERTa and DeBERTa) are trained to extract contextualized embeddings from sentences. After that, corresponding severity scores of comments are calculated by the subsequent head layers, where the head is chosen from the multilayer perceptron, convolutional neural network, and attention structure. After applying the K-Fold cross validation and an average ensemble of different models, our method achieves a rank 28/2301 (top 1.2%) in the leaderboard of Jigsaw Rate Severity of Toxic Comments Kaggle competition. This result can get a silver medal in this competition, and proves that our model can be an effective approach to rate precisely the severity of a toxic comment. This work can remarkably reduce the workload of manual review of Internet content and help build a more harmonious online community environment.",2768-6515,,978-1-6654-8508-1,1283-1288,IEEE , ,Deep learning;Silver;Gold;Social networking (online);Manuals;Multilayer perceptrons;Internet,,
5075,"Title:PCA-AdaBoost Method for a Low Bias and Low Dimension Toxic Comment Classification.

 Toxic comment classification can be a solution to reduce the impact of one of these forms of online harassment, where the term frequency-inverse document frequency (TF-IDF) vectoring method can do feature extraction on comment text datasets. However, TF-IDF vectoring can result in a curse of dimensionality, which increases the computational cost exponentially. In addition, imbalanced data can also reduce classification performance. This study proposes the PCA-AdaBoost method for toxic comment classification with low dimension and low bias. We use the Jigsaw toxic comment classification dataset from Kaggle and apply AFINN’s lexicon for labeling toxic comments. DT and RF are two methods to benchmark the performance of our proposed classification method. The performance test applies several methods such as K-fold cross-validation, receiver operating characteristic (ROC) curve, the area under curve (AUC) value, confusion matrix, Accuracy, Precision, Recall, and F1-Score. The test results show that the application of PCA produces a Dimension Reduction that equals 7.3%, where 275 new features from dimension reduction have a Total Explained Variance of 96.6%. In addition, the results of the cross-validation test show that PCA can provide improved performance and a more robust classification model. Then the proposed PCAAdaBoost has the best Accuracy, Precision, Recall, and F1-Score compared to benchmark methods, namely, 0.86, 0.89, 0.82, and 0.85 respectively.",M. N. Fauzan; A. G. Putrada; N. Alamsyah; S. F. Pane,,,PCA-AdaBoost Method for a Low Bias and Low Dimension Toxic Comment Classification.,,,10.1109/ICACNIS57039.2022.10055017 ,IEEE Conferences ,,"Toxic comment classification can be a solution to reduce the impact of one of these forms of online harassment, where the term frequency-inverse document frequency (TF-IDF) vectoring method can do feature extraction on comment text datasets. However, TF-IDF vectoring can result in a curse of dimensionality, which increases the computational cost exponentially. In addition, imbalanced data can also reduce classification performance. This study proposes the PCA-AdaBoost method for toxic comment classification with low dimension and low bias. We use the Jigsaw toxic comment classification dataset from Kaggle and apply AFINN’s lexicon for labeling toxic comments. DT and RF are two methods to benchmark the performance of our proposed classification method. The performance test applies several methods such as K-fold cross-validation, receiver operating characteristic (ROC) curve, the area under curve (AUC) value, confusion matrix, Accuracy, Precision, Recall, and F1-Score. The test results show that the application of PCA produces a Dimension Reduction that equals 7.3%, where 275 new features from dimension reduction have a Total Explained Variance of 96.6%. In addition, the results of the cross-validation test show that PCA can provide improved performance and a more robust classification model. Then the proposed PCAAdaBoost has the best Accuracy, Precision, Recall, and F1-Score compared to benchmark methods, namely, 0.86, 0.89, 0.82, and 0.85 respectively.",,,979-8-3503-3444-9,1-6,IEEE , ,Dimensionality reduction;Radio frequency;Receivers;Benchmark testing;Feature extraction;Computational efficiency;Labeling,,
5076,"Title:Toxic Comment Classification Using S-BERT Vectorization and Random Forest Algorithm

 The growing popularity of social media platforms and microblogging websites has led to an increase in the expression of views and opinions. However, conversations and debates on these platforms often lead to the use of toxic comments, which consists of insulting and hateful remarks. To address this issue, it is important for social media systems to be able to recognize harmful comments. With the rising incidence of cyberbullying, it is crucial to study the classification of toxic comments using various algorithms. This study compares the effectiveness of different word and sentence embedding methods, including TF-IDF, InferSent, Bert, and T5 for toxic comments classification. A comparative study is also conducted on the impact of using SMOTE to balance the highly imbalanced dataset. The results of these models are compared and analysed. It is observed that T5 embedding with Random Forest Classifier works best at 0.91 F1-Score.",A. A. Kumar; P. B. Pati; K. Deepa; S. T. Sangeetha,,,Toxic Comment Classification Using S-BERT Vectorization and Random Forest Algorithm,1,,10.1109/InC457730.2023.10263218 ,IEEE Conferences ,,"The growing popularity of social media platforms and microblogging websites has led to an increase in the expression of views and opinions. However, conversations and debates on these platforms often lead to the use of toxic comments, which consists of insulting and hateful remarks. To address this issue, it is important for social media systems to be able to recognize harmful comments. With the rising incidence of cyberbullying, it is crucial to study the classification of toxic comments using various algorithms. This study compares the effectiveness of different word and sentence embedding methods, including TF-IDF, InferSent, Bert, and T5 for toxic comments classification. A comparative study is also conducted on the impact of using SMOTE to balance the highly imbalanced dataset. The results of these models are compared and analysed. It is observed that T5 embedding with Random Forest Classifier works best at 0.91 F1-Score.",,,979-8-3503-3577-4,1-6,IEEE , ,Measurement;Deep learning;Analytical models;Computational modeling;Blogs;Cyberbullying;Oral communication,,
5077,"Title:Systematic Literature Review: Toxic Comment Classification

 Over the last decade, deep learning models have surpassed machine learning models in text classification. However, with the continuity of the digital age, many are exposed to the dangers of the internet. One of the dangers would be cyberbullying. In an attempt to decrease cyberbullying, much toxic text detection and classification research has been done. In this paper, we aim to understand the effectiveness of deep learning models compared to machine learning models along with the most common models used by researchers in the last 5 years. We will also be providing insight on the most common data sets utilized by researchers to detect toxic comments. To achieve this, we have compiled the datasets of research papers and analyze the algorithm used. The findings indicate that Long Term Short Memory is the most routinely mentioned deep learning model with 8 out of26 research papers. LSTM has also repeatedly yielded high accuracy results with above 79% for around 9000 data which could be adjusted depending on the pre-processing method used. There have been attempts to combine more than one deep learning algorithms, however these hybrid models might not result in a better accuracy than an original model. Furthermore, the most frequent sources of datasets came from Kaggle and Wikipedia datasets and a total of 13 researchers that used Wikipedia's talk page edits as their dataset.",F. Museng; A. Jessica; N. Wijaya; A. Anderies; I. A. Iswanto,,,Systematic Literature Review: Toxic Comment Classification,,,10.1109/ICITDA55840.2022.9971338 ,IEEE Conferences ,,"Over the last decade, deep learning models have surpassed machine learning models in text classification. However, with the continuity of the digital age, many are exposed to the dangers of the internet. One of the dangers would be cyberbullying. In an attempt to decrease cyberbullying, much toxic text detection and classification research has been done. In this paper, we aim to understand the effectiveness of deep learning models compared to machine learning models along with the most common models used by researchers in the last 5 years. We will also be providing insight on the most common data sets utilized by researchers to detect toxic comments. To achieve this, we have compiled the datasets of research papers and analyze the algorithm used. The findings indicate that Long Term Short Memory is the most routinely mentioned deep learning model with 8 out of26 research papers. LSTM has also repeatedly yielded high accuracy results with above 79% for around 9000 data which could be adjusted depending on the pre-processing method used. There have been attempts to combine more than one deep learning algorithms, however these hybrid models might not result in a better accuracy than an original model. Furthermore, the most frequent sources of datasets came from Kaggle and Wikipedia datasets and a total of 13 researchers that used Wikipedia's talk page edits as their dataset.",,,978-1-6654-6136-8,1-7,IEEE , ,Deep learning;Systematics;Text categorization;Neural networks;Cyberbullying;Encyclopedias;Internet,,
5078,"Title:Tackling Toxic Online Communication with Recurrent Capsule Networks

 Internet has provided everyone a platform to productively exchange ideas, learn new things and have meaningful conversation. To make online interactions fruitful it is necessary the user feels comfortable with sharing information without the menace of online hate which includes insults, personal attacks, identity hate, threats and so on. The first step to combating this problem would be the identification of such online behaviour. Framing the problem as text classification, we present a novel and versatile model in this paper which employs Recurrent Neural Network and Capsule network as its backbone and captures contextual information to a larger extent when learning word representations in the text. A series of experiments are conducted on Wikipedia's talk page edits provided by Jigsaw in Kaggle's toxic comment classification challenge. The experimental results show that the proposed model outperforms other traditional state-of-the-art models on the dataset, thereby proving the effectiveness of capsule networks for multi-label text classification. The superior performance of architecture is also confirmed by results obtained on traditional benchmark datasets such as AG News, IMDB Large Movie Review and Yelp Reviews data.",S. Deshmukh; R. Rade,,,Tackling Toxic Online Communication with Recurrent Capsule Networks,,,10.1109/INFOCOMTECH.2018.8722433 ,IEEE Conferences ,,"Internet has provided everyone a platform to productively exchange ideas, learn new things and have meaningful conversation. To make online interactions fruitful it is necessary the user feels comfortable with sharing information without the menace of online hate which includes insults, personal attacks, identity hate, threats and so on. The first step to combating this problem would be the identification of such online behaviour. Framing the problem as text classification, we present a novel and versatile model in this paper which employs Recurrent Neural Network and Capsule network as its backbone and captures contextual information to a larger extent when learning word representations in the text. A series of experiments are conducted on Wikipedia's talk page edits provided by Jigsaw in Kaggle's toxic comment classification challenge. The experimental results show that the proposed model outperforms other traditional state-of-the-art models on the dataset, thereby proving the effectiveness of capsule networks for multi-label text classification. The superior performance of architecture is also confirmed by results obtained on traditional benchmark datasets such as AG News, IMDB Large Movie Review and Yelp Reviews data.",,,978-1-5386-8215-9,1-7,IEEE , ,Text categorization;Routing;Logic gates;Heuristic algorithms;Recurrent neural networks;Computer architecture;Convolutional neural networks,,
5079,"Title:Performance analysis of 2% Fe2O3 Doped Thick-film Gas Sensor in Toxic Liquid Detection Using Machine Learning Techniques

 The proposed research paper communicates the outcomes of sensitiveness retroaction time of a sensor constituted by a doped 2% Fe2O3 thick-film SnO2 gas sensor. First, the sensor's sensitivity has been investigated for Methanol and Acetone (for constant 2 ML) with consistent monitoring by comprehension of short retroaction of 2% Fe2O3 doped sensor as it possesses evanescent sensitivity for entirely the evaluation toxic liquid. Second, a thick-film SnO2 sensor has been fabricated on a 1” x 1” alumina substrate that constitutes gas-sensitive laminations SnO2 doped with 2% Fe2O3, a couple of electrodes on the underside of the gas recognition layer auxiliary as an area of contact for detecting device. Also, a heater constituent on the posterior of the parent substantial was printed. Finally, the sensor's sensitivity has been premeditated at 2% Fe2O3-doped engrossment at a constant temperature of 150°C and 200°C upon exposure to Methanol & Acetone. The minimum response time of 2.7s was established for methanol at 150°C and an extreme response time of 2.5s for acetone at 150°C. The minimum response time of 6.9s was found to be for methanol at 200°C, and the minimum response time was 8..9s for acetone at 200°C. The proposed paper emulates in anaconda platform through spider tool (spyder-3) exploitation in python. Furthermore, python code scripted in machine learning utilizes the cluster method to appreciate toxic liquids. The emulative results suit hand on results with simulated results at different operating temperatures.",A. Gupta; S. K. Dargar; M. Sabir,,,Performance analysis of 2% Fe2O3 Doped Thick-film Gas Sensor in Toxic Liquid Detection Using Machine Learning Techniques,,,10.1109/ICSSIT53264.2022.9716258 ,IEEE Conferences ,,"The proposed research paper communicates the outcomes of sensitiveness retroaction time of a sensor constituted by a doped 2% Fe2O3 thick-film SnO2 gas sensor. First, the sensor's sensitivity has been investigated for Methanol and Acetone (for constant 2 ML) with consistent monitoring by comprehension of short retroaction of 2% Fe2O3 doped sensor as it possesses evanescent sensitivity for entirely the evaluation toxic liquid. Second, a thick-film SnO2 sensor has been fabricated on a 1” x 1” alumina substrate that constitutes gas-sensitive laminations SnO2 doped with 2% Fe2O3, a couple of electrodes on the underside of the gas recognition layer auxiliary as an area of contact for detecting device. Also, a heater constituent on the posterior of the parent substantial was printed. Finally, the sensor's sensitivity has been premeditated at 2% Fe2O3-doped engrossment at a constant temperature of 150°C and 200°C upon exposure to Methanol & Acetone. The minimum response time of 2.7s was established for methanol at 150°C and an extreme response time of 2.5s for acetone at 150°C. The minimum response time of 6.9s was found to be for methanol at 200°C, and the minimum response time was 8..9s for acetone at 200°C. The proposed paper emulates in anaconda platform through spider tool (spyder-3) exploitation in python. Furthermore, python code scripted in machine learning utilizes the cluster method to appreciate toxic liquids. The emulative results suit hand on results with simulated results at different operating temperatures.",,,978-1-6654-0118-0,689-693,IEEE , ,Temperature sensors;Temperature measurement;Sensitivity;Liquids;Machine learning;Time measurement;Time factors,,
5080,"Title:Determination of Crisis on Climatic Fluctuations and Smog Deterioration by Categorizing the Condition Using Predictive Analytics

 In the recent years, the climatic conditions and the air pollution are drastically getting increased due to which the environment conditions are disturbed. Deterioration of the environment by the depletion of natural resources such as air, soil and water cause environmental degradation. When the temperature gets high, the climatic change leads an increase in the ozone layer, air pollutant. Due to these disruptions, the conditions of the living beings are getting changed. To maintain the proper temperature and climatic conditions, the usage of carbon, fuels, plastics and non biodegradable products has to be prohibited. Due to the emission of harmful air pollutants, the climatic change is getting changed accordingly. Contaminating the air can damage the air quality in the environment. Hence, the air quality and the climatic change play a vital role in the environment aspect. For detecting the various climatic condition states and the air quality, the variations over the dataset have to be predicted. By predicting those values, the use of non biodegradable products can be decreased. For the prediction and classifying the training dataset, machine learning approach is implemented. By using the supervised learning approach, the dataset can be classified by predicting the condition state. The use of this approach is to take initiative and precautionary step of reducing the non biodegradable products which are used. Climatic factors change according to the temperature humidity, wind speed, pressure, moisture content, wind direction.",G. Saritha; A. Subbarayudu; G. Premalatha; C. A. Christa; S. Arun; R. Krishnamoorthy,,,Determination of Crisis on Climatic Fluctuations and Smog Deterioration by Categorizing the Condition Using Predictive Analytics,,,10.1109/ICSSS54381.2022.9782287 ,IEEE Conferences ,,"In the recent years, the climatic conditions and the air pollution are drastically getting increased due to which the environment conditions are disturbed. Deterioration of the environment by the depletion of natural resources such as air, soil and water cause environmental degradation. When the temperature gets high, the climatic change leads an increase in the ozone layer, air pollutant. Due to these disruptions, the conditions of the living beings are getting changed. To maintain the proper temperature and climatic conditions, the usage of carbon, fuels, plastics and non biodegradable products has to be prohibited. Due to the emission of harmful air pollutants, the climatic change is getting changed accordingly. Contaminating the air can damage the air quality in the environment. Hence, the air quality and the climatic change play a vital role in the environment aspect. For detecting the various climatic condition states and the air quality, the variations over the dataset have to be predicted. By predicting those values, the use of non biodegradable products can be decreased. For the prediction and classifying the training dataset, machine learning approach is implemented. By using the supervised learning approach, the dataset can be classified by predicting the condition state. The use of this approach is to take initiative and precautionary step of reducing the non biodegradable products which are used. Climatic factors change according to the temperature humidity, wind speed, pressure, moisture content, wind direction.",,,978-1-6654-9761-9,1-7,IEEE , ,Training;Support vector machines;Fluctuations;Temperature;Wind speed;Weather forecasting;Air pollution,,
5081,"Title:Pathogen-Based Classification of Plant Diseases: A Deep Transfer Learning Approach for Intelligent Support Systems

 The national economy’s key pillar, agriculture has a significant influence on society. Plant health monitoring and disease detection are essential for sustainable agriculture. To protect plants against pathogen damage, farmers must be able to detect an infection prior to its obviousness. Effective plant disease detection technique can greatly lessen the use of toxic chemicals thereby aiding a better environment. For diseases to be managed effectively, plant pathogens must be accurately detected. The pathogens that cause plant diseases include bacteria, fungi, viruses, oomycetes, nematodes, phytoplasmas, protozoa, and parasitic plants. In this paper pathogen-based plant disease detection is done. An automated plant disease detection and its classification are done along with identifying the pathogen responsible for it using keras transfer learning models. This is done by considering Agri-ImageNet dataset as well as images of leaves, bulb, and flowers of sunflower and cauliflower captured in a natural realistic environment. This dataset overcomes the drawback of PlantVillage dataset in which images are captured in homogeneous backgrounds and controlled settings. These problems can be solved by reusing knowledge representations through deep transfer learning. Main objective of this paper is to explore and analyze all the deep transfer learning models, to identify which model is best suited for plant disease dataset. This work has been carried out by using 38 deep transfer learning models to obtain best classification accuracy. EfficientNetV2B2 and EfficientNetV2B3 models’ give highest accuracy in comparison with all other deep transfer learning models for sunflower, cauliflower and Agri-ImageNet datasets. Classification report is generated from the best deep transfer learning model.",K. P. Asha Rani; S. Gowrishankar,,,Pathogen-Based Classification of Plant Diseases: A Deep Transfer Learning Approach for Intelligent Support Systems,11,,10.1109/ACCESS.2023.3284680 ,IEEE Journals ,,"The national economy’s key pillar, agriculture has a significant influence on society. Plant health monitoring and disease detection are essential for sustainable agriculture. To protect plants against pathogen damage, farmers must be able to detect an infection prior to its obviousness. Effective plant disease detection technique can greatly lessen the use of toxic chemicals thereby aiding a better environment. For diseases to be managed effectively, plant pathogens must be accurately detected. The pathogens that cause plant diseases include bacteria, fungi, viruses, oomycetes, nematodes, phytoplasmas, protozoa, and parasitic plants. In this paper pathogen-based plant disease detection is done. An automated plant disease detection and its classification are done along with identifying the pathogen responsible for it using keras transfer learning models. This is done by considering Agri-ImageNet dataset as well as images of leaves, bulb, and flowers of sunflower and cauliflower captured in a natural realistic environment. This dataset overcomes the drawback of PlantVillage dataset in which images are captured in homogeneous backgrounds and controlled settings. These problems can be solved by reusing knowledge representations through deep transfer learning. Main objective of this paper is to explore and analyze all the deep transfer learning models, to identify which model is best suited for plant disease dataset. This work has been carried out by using 38 deep transfer learning models to obtain best classification accuracy. EfficientNetV2B2 and EfficientNetV2B3 models’ give highest accuracy in comparison with all other deep transfer learning models for sunflower, cauliflower and Agri-ImageNet datasets. Classification report is generated from the best deep transfer learning model.",2169-3536,,,64476-64493,IEEE , ,Plant diseases;Transfer learning;Pathogens;Deep learning;Feature extraction;Task analysis;Biological system modeling,,
5082,"Title:Overlapping Toxic Sentiment Classification Using Deep Neural Architectures

 We are living in an era where data is enjoying an unprecedented increase in its volume in each passing moment through online media platforms. Such a colossal amount of data is multifarious in its nature where textual data proves to be its vital pillar. Almost every sort of online media platform is producing textual data. Short posts (i.e. Twitter and Facebook) and comments constitute a significant part of this textual data. Unfortunately, this text data may contain overlapping toxic sentiments in terms of personal attacks, abuses, obscenity, insults, threats or identity hatred. In many cases, it becomes extremely important to track such toxic posts/data to trigger needed actions e.g. automated tagging of posts as inappropriate. State-of-the-art classification techniques do not handle the overlapping sentiment categories of text data. In this paper, we propose Deep Neural Network (DNN) architectures to classify the overlapping sentiments with high accuracy. Moreover, we show that our proposed classification framework does not require any laborious text pre-processing and is capable of handling text pre-processing (e.g. stop word removal, feature engineering, etc.) intrinsically. Our empirical validation on a real world dataset supports our claims by showing the superior performance of the proposed methods.",H. H. Saeed; K. Shahzad; F. Kamiran,,,Overlapping Toxic Sentiment Classification Using Deep Neural Architectures,,,10.1109/ICDMW.2018.00193 ,IEEE Conferences ,,"We are living in an era where data is enjoying an unprecedented increase in its volume in each passing moment through online media platforms. Such a colossal amount of data is multifarious in its nature where textual data proves to be its vital pillar. Almost every sort of online media platform is producing textual data. Short posts (i.e. Twitter and Facebook) and comments constitute a significant part of this textual data. Unfortunately, this text data may contain overlapping toxic sentiments in terms of personal attacks, abuses, obscenity, insults, threats or identity hatred. In many cases, it becomes extremely important to track such toxic posts/data to trigger needed actions e.g. automated tagging of posts as inappropriate. State-of-the-art classification techniques do not handle the overlapping sentiment categories of text data. In this paper, we propose Deep Neural Network (DNN) architectures to classify the overlapping sentiments with high accuracy. Moreover, we show that our proposed classification framework does not require any laborious text pre-processing and is capable of handling text pre-processing (e.g. stop word removal, feature engineering, etc.) intrinsically. Our empirical validation on a real world dataset supports our claims by showing the superior performance of the proposed methods.",2375-9259,,978-1-5386-9288-2,1361-1366,IEEE , ,Kernel;Computer architecture;Facebook;Convolution;Natural language processing;Encoding;Logic gates,,
5083,"Title:ScarNet: Development and Validation of a Novel Deep CNN Model for Acne Scar Classification With a New Dataset

 Acne scarring occurs in 95% of people with acne vulgaris due to collagen loss or gains when the body is healing the damages of the skin caused by acne inflammation. Accurate classification of acne scars is a vital factor in providing a timely, effective treatment protocol. Dermatologists mainly recognize the type of acne scars manually based on visual inspections, which are time- and energy-consuming and subject to intra- and inter-reader variability. In this paper, a novel automated acne scar classification system is proposed based on a deep Convolutional Neural Network (CNN) model. First, a dataset of 250 images from five different classes is collected and labeled by four well-experienced dermatologists. The pre-processed input images are fed into our proposed model, namely ScarNet, for deep feature map extraction. The optimizer, loss function, activation functions, filter and kernel sizes, regularization methods, and the batch size of the proposed architecture are tuned so that the classification performance is maximized while minimizing the computational cost. Experimental results demonstrate the feasibility of the proposed method with accuracy, specificity, and kappa score of 92.53%, 95.38%, and 76.7%, respectively.",M. S. Junayed; M. B. Islam; A. A. Jeny; A. Sadeghzadeh; T. Biswas; A. F. M. S. Shah,,,ScarNet: Development and Validation of a Novel Deep CNN Model for Acne Scar Classification With a New Dataset,10,,10.1109/ACCESS.2021.3138021 ,IEEE Journals ,,"Acne scarring occurs in 95% of people with acne vulgaris due to collagen loss or gains when the body is healing the damages of the skin caused by acne inflammation. Accurate classification of acne scars is a vital factor in providing a timely, effective treatment protocol. Dermatologists mainly recognize the type of acne scars manually based on visual inspections, which are time- and energy-consuming and subject to intra- and inter-reader variability. In this paper, a novel automated acne scar classification system is proposed based on a deep Convolutional Neural Network (CNN) model. First, a dataset of 250 images from five different classes is collected and labeled by four well-experienced dermatologists. The pre-processed input images are fed into our proposed model, namely ScarNet, for deep feature map extraction. The optimizer, loss function, activation functions, filter and kernel sizes, regularization methods, and the batch size of the proposed architecture are tuned so that the classification performance is maximized while minimizing the computational cost. Experimental results demonstrate the feasibility of the proposed method with accuracy, specificity, and kappa score of 92.53%, 95.38%, and 76.7%, respectively.",2169-3536,,,1245-1258,IEEE , ,Skin;Feature extraction;Convolutional neural networks;Support vector machines;Diseases;Computational modeling;Kernel,,
5084,"Title:Patten recognition for toxic gases based on electronic nose using artificial neural networks

 Electronic Nose gas sensor is a device used to detect various chemical gases/vapors present in Environment. Each sensor has its own kind of response from sensory arrays. The various pattern recognition methods are used to processes the signals derived from a sensor array employed in Electronic-nose. This paper proposed intelligent pattern recognition method to predict the toxic vapors present in environment. We have used Principal Component Analysis technique to reduce dataset and Artificial Neural Network approach has been used as Pattern Recognition method to predict the toxic gases through MATLAB tool.",M. Sreelatha; G. M. Nasira; P. Thangamani,,,Patten recognition for toxic gases based on electronic nose using artificial neural networks,,, ,IEEE Conferences ,,Electronic Nose gas sensor is a device used to detect various chemical gases/vapors present in Environment. Each sensor has its own kind of response from sensory arrays. The various pattern recognition methods are used to processes the signals derived from a sensor array employed in Electronic-nose. This paper proposed intelligent pattern recognition method to predict the toxic vapors present in environment. We have used Principal Component Analysis technique to reduce dataset and Artificial Neural Network approach has been used as Pattern Recognition method to predict the toxic gases through MATLAB tool.,,,978-9-3805-4421-2,3075-3079,IEEE , ,Handheld computers;Decision support systems;Conferences,,
5085,"Title:Two-Stage Unsupervised Classification of Cell Health

 Supervised learning for cell classification is one of the most used approaches on different studies. However, due to lack of labelling datasets provided by experts, and the small number of images per dataset, the usage of unsupervised learning would be a better approach. This work reports a study done on a two-stage unsupervised classification of cell health: i) phase one: divide the dataset into two main groups healthy and unhealthy, and ii) phase two: divide healthy group into two smaller clusters and unhealthy group into three different clusters. The groups are defined following the description of the cell health ISO STANDARD for invitro cytotoxicity evaluation. Unsupervised learning is done based on image features and the labelling of the clusters is done after it. K-means algorithm was used for clustering and two different datasets were tested. The second dataset had the best performance and the correct labelling of the clusters.",X. Polisi; A. N. Halili; A. Uka; C. Ciulla,,,Two-Stage Unsupervised Classification of Cell Health,,,10.1109/iCCECE59400.2023.10238637 ,IEEE Conferences ,,"Supervised learning for cell classification is one of the most used approaches on different studies. However, due to lack of labelling datasets provided by experts, and the small number of images per dataset, the usage of unsupervised learning would be a better approach. This work reports a study done on a two-stage unsupervised classification of cell health: i) phase one: divide the dataset into two main groups healthy and unhealthy, and ii) phase two: divide healthy group into two smaller clusters and unhealthy group into three different clusters. The groups are defined following the description of the cell health ISO STANDARD for invitro cytotoxicity evaluation. Unsupervised learning is done based on image features and the labelling of the clusters is done after it. K-means algorithm was used for clustering and two different datasets were tested. The second dataset had the best performance and the correct labelling of the clusters.",2836-8983,,979-8-3503-4092-1,145-149,IEEE , ,ISO Standards;Supervised learning;Clustering algorithms;Classification algorithms;Labeling;Unsupervised learning,,
5086,"Title:Measles Rash Identification Using Transfer Learning and Deep Convolutional Neural Networks

 Measles is a highly contagious disease, one of the largest vaccine-preventable illnesses and leading causes of death in developing countries, claiming more than 140,000 lives each year. Measles was declared eliminated in the United States in the year 2000 due to decades of successful vaccination but it resurged in 2019 with 1,282 confirmed cases. Due to rapid spread of this disease among people in contact, rapid and automated diagnostic systems are required for early prevention. In this work, we employed transfer learning to build deep convolutional neural networks (CNNs) to distinguish measles rash from other skin conditions. Experiments with ResNet-50 model, trained on our diverse and curated skin rash image dataset, produce classification accuracy of 95.2%, sensitivity of 81.7%, and specificity of 97.1%, respectively. This indicates that our technique is effective in facilitating an accurate detection of measles to help contain outbreaks. The performance of a small CNN model MobileNet-V2 on our image data set is also discussed. Our work will facilitate healthcare professionals to effectively diagnose measles and accelerate the development of automated diagnostic tools to prevent the measles spread at various public venues.",K. Glock; C. Napier; T. Gary; V. Gupta; J. Gigante; W. Schaffner; Q. Wang,,,Measles Rash Identification Using Transfer Learning and Deep Convolutional Neural Networks,,,10.1109/BigData52589.2021.9671333 ,IEEE Conferences ,,"Measles is a highly contagious disease, one of the largest vaccine-preventable illnesses and leading causes of death in developing countries, claiming more than 140,000 lives each year. Measles was declared eliminated in the United States in the year 2000 due to decades of successful vaccination but it resurged in 2019 with 1,282 confirmed cases. Due to rapid spread of this disease among people in contact, rapid and automated diagnostic systems are required for early prevention. In this work, we employed transfer learning to build deep convolutional neural networks (CNNs) to distinguish measles rash from other skin conditions. Experiments with ResNet-50 model, trained on our diverse and curated skin rash image dataset, produce classification accuracy of 95.2%, sensitivity of 81.7%, and specificity of 97.1%, respectively. This indicates that our technique is effective in facilitating an accurate detection of measles to help contain outbreaks. The performance of a small CNN model MobileNet-V2 on our image data set is also discussed. Our work will facilitate healthcare professionals to effectively diagnose measles and accelerate the development of automated diagnostic tools to prevent the measles spread at various public venues.",,,978-1-6654-3902-2,3905-3910,IEEE , ,Pediatrics;Sensitivity;Transfer learning;Neural networks;Big Data;Skin;Vaccines,,
5087,"Title:ML-Based Trojan Classification: Repercussions of Toxic Boundary Nets

 Machine learning (ML) algorithms were recently adapted for testing integrated circuits and detecting potential design backdoors. Such testing mechanisms mainly rely on the available training dataset and the extracted features of the Trojan circuit. In this paper, we demonstrate that this method is attackable by exploiting a structural problem of classifiers for hardware Trojan detection in gate-level netlists, called the Boundary Net Problem. There, an adversary modifies the labels of those boundary nets, connecting the original logic to the Trojan circuit. We show that the proposed adversarial label-flipping attacks are potentially highly toxic to the accuracy of supervised ML-based Trojan detection approaches. The experimental results indicate that an adversary needs to flip only 0.09% of all labels to achieve an accuracy drop of over 9%, demonstrating one of the most efficient adversarial label-flipping attacks in the hardware Trojan detection research domain.",S. Mulhem; F. Muuss; C. Ewert; R. Buchty; M. Berekovic,,,ML-Based Trojan Classification: Repercussions of Toxic Boundary Nets,PP,99,10.1109/LES.2023.3338543 ,IEEE Early Access Articles ,,"Machine learning (ML) algorithms were recently adapted for testing integrated circuits and detecting potential design backdoors. Such testing mechanisms mainly rely on the available training dataset and the extracted features of the Trojan circuit. In this paper, we demonstrate that this method is attackable by exploiting a structural problem of classifiers for hardware Trojan detection in gate-level netlists, called the Boundary Net Problem. There, an adversary modifies the labels of those boundary nets, connecting the original logic to the Trojan circuit. We show that the proposed adversarial label-flipping attacks are potentially highly toxic to the accuracy of supervised ML-based Trojan detection approaches. The experimental results indicate that an adversary needs to flip only 0.09% of all labels to achieve an accuracy drop of over 9%, demonstrating one of the most efficient adversarial label-flipping attacks in the hardware Trojan detection research domain.",1943-0671,,,1-1,IEEE , ,Trojan horses;Labeling;Feature extraction;Logic gates;Training;Testing;Support vector machines,,
5088,"Title:Toxic Voice Classification Implementing CNN-LSTM & Employing Supervised Machine Learning Algorithms Through Explainable AI-SHAP

 Data innovation has advanced rapidly in recent years, and the network media has undergone several problematic changes. Places where consumers can express their thoughts through messages, photos, and notes, such as Facebook, Twitter, and Instagram, are gaining popularity. Unfortunately, it has become a place of toxic, insults, cyberbullying, and mysterious dangers. There is a lot of research here, but none has found a sufficient level of accuracy. This paper proposes a Convolutional Neural Network with Long Short-Term Memory (CNN-LSTM) and Natural Language Processing (NLP) fusion strategy that characterizes malicious and non-malicious remarks with a word embedding technique at an initial stage. And this model can categorize any voice data into six levels of classification. Furthermore, the processed dataset is applied to two traditional Machine Learning Algorithms (Random Forest and Extra Tress Algorithm) with an estimator (Logistic Regression) and interprets these algorithms with an Explainable AI (XAI)-SHAP. In the final step, two classifiers and the estimator are ensembled with Stacking Classifier, which is better than any previous activity.",M. H. Shakil; M. G. Rabiul Alam,,,Toxic Voice Classification Implementing CNN-LSTM & Employing Supervised Machine Learning Algorithms Through Explainable AI-SHAP,,,10.1109/IICAIET55139.2022.9936775 ,IEEE Conferences ,,"Data innovation has advanced rapidly in recent years, and the network media has undergone several problematic changes. Places where consumers can express their thoughts through messages, photos, and notes, such as Facebook, Twitter, and Instagram, are gaining popularity. Unfortunately, it has become a place of toxic, insults, cyberbullying, and mysterious dangers. There is a lot of research here, but none has found a sufficient level of accuracy. This paper proposes a Convolutional Neural Network with Long Short-Term Memory (CNN-LSTM) and Natural Language Processing (NLP) fusion strategy that characterizes malicious and non-malicious remarks with a word embedding technique at an initial stage. And this model can categorize any voice data into six levels of classification. Furthermore, the processed dataset is applied to two traditional Machine Learning Algorithms (Random Forest and Extra Tress Algorithm) with an estimator (Logistic Regression) and interprets these algorithms with an Explainable AI (XAI)-SHAP. In the final step, two classifiers and the estimator are ensembled with Stacking Classifier, which is better than any previous activity.",,,978-1-6654-6837-4,1-6,IEEE , ,Technological innovation;Machine learning algorithms;Stacking;Media;Tokenization;Classification algorithms;Convolutional neural networks,,
5089,"Title:On Optimizing the Principal Component Analysis in the Hyperspectral Inversion of Chromium and Zinc Concentrations by the Deep Forest

 This letter examines how the principal component analysis (PCA) affects the performance of the deep forest 2021 (DF21) model for the hyperspectral inversion. To this end, the spectra contaminated by eight types of heavy metals are applied and processed by PCA. Subsequently, various retained principal components (PCs) are devoted to establish the inversion model in line with the DF21. Two typical heavy metal elements, i.e., zinc (Zn) and chromium (Cr), are used for instance; it explores the accuracies of the DF21 model for inverting their concentrations under different PCs. The findings reveal that the DF21 model’s performance fluctuates with varying retained PCs. Furthermore, the fluctuations are influenced by the heavy metal’s type and its concentration distribution. As a result, the optimal performances for inverting the Zn and Cr concentrations appear at the first nine PCs and first eight PCs, respectively. Hence, it might not be feasible to improve the accuracy by retaining more PCs in hyperspectral inversion, at least not for the DF21 model.",F. Guo; Y. Wang; D. Lin; Z. Xu,,,On Optimizing the Principal Component Analysis in the Hyperspectral Inversion of Chromium and Zinc Concentrations by the Deep Forest,20,,10.1109/LGRS.2023.3330854 ,IEEE Journals ,,"This letter examines how the principal component analysis (PCA) affects the performance of the deep forest 2021 (DF21) model for the hyperspectral inversion. To this end, the spectra contaminated by eight types of heavy metals are applied and processed by PCA. Subsequently, various retained principal components (PCs) are devoted to establish the inversion model in line with the DF21. Two typical heavy metal elements, i.e., zinc (Zn) and chromium (Cr), are used for instance; it explores the accuracies of the DF21 model for inverting their concentrations under different PCs. The findings reveal that the DF21 model’s performance fluctuates with varying retained PCs. Furthermore, the fluctuations are influenced by the heavy metal’s type and its concentration distribution. As a result, the optimal performances for inverting the Zn and Cr concentrations appear at the first nine PCs and first eight PCs, respectively. Hence, it might not be feasible to improve the accuracy by retaining more PCs in hyperspectral inversion, at least not for the DF21 model.",1558-0571,,,1-5,IEEE , ,Metals;Zinc;Soil;Principal component analysis;Hyperspectral imaging;Reflectivity;Biological system modeling,,
5090,"Title:Protection of Hazardous Places in Industries using Machine Learning

 Extreme precautions must be observed to handle toxic wastes, radioactive substances, chemical raw materials, chemical wastes, and bio-products in different industries. Any malfunction in a dangerous traffic network can lead to serious accidents, deaths and / or serious damage. Direct monitoring and analysis, and preventive measures to prevent the spread of failures, can significantly reduce the recurrence of adverse effects. Current research suggests that detailed publicity and information on the latest developments in pipeline monitoring and research may help modernize the oil industry in the future. We also propose a framework to detect timely leakage in pipelines, especially in oil and gas sector.",P. Sankarasubramanian,,,Protection of Hazardous Places in Industries using Machine Learning,,,10.1109/ESCI56872.2023.10100323 ,IEEE Conferences ,,"Extreme precautions must be observed to handle toxic wastes, radioactive substances, chemical raw materials, chemical wastes, and bio-products in different industries. Any malfunction in a dangerous traffic network can lead to serious accidents, deaths and / or serious damage. Direct monitoring and analysis, and preventive measures to prevent the spread of failures, can significantly reduce the recurrence of adverse effects. Current research suggests that detailed publicity and information on the latest developments in pipeline monitoring and research may help modernize the oil industry in the future. We also propose a framework to detect timely leakage in pipelines, especially in oil and gas sector.",,,978-1-6654-7524-2,1-5,IEEE , ,Oils;Current measurement;Pipelines;Machine learning;Raw materials;Petroleum industry;Informatics,,
5091,"Title:Data Ensemble Model for Prediction of Oxygen Content in Gas fired Boiler for Efficient Combustion

 Measurement of the oxygen concentration in a boiler is crucial for efficient combustion in a gas-fired boiler, which results in the reduction of the amount of release of toxic gases in the environment. This research work describes a method to improve the effectiveness and performance of the Boiler combustion efficiency by the prediction of oxygen content using a Data Ensemble model. More useful data about the flame's physical characteristics can be viewed using CCD flame pictures. Images of boilers at various temperatures, air pressures, and gas conditions have been acquired through on-site tests in a genuine combustion system and classification models have been used. By applying a deep learning prediction model to these images, and comparing the results with the test data set, the accurate value of oxygen content is determined. An accuracy of 98% and a loss of 0.02 have been obtained. The unsupervised and semi-supervised, multilevel based deep ensemble models are applied and oxygen content is predicted.",K. G. S. Sharma; S. Bhusnur,,,Data Ensemble Model for Prediction of Oxygen Content in Gas fired Boiler for Efficient Combustion,,,10.1109/SCEECS57921.2023.10062991 ,IEEE Conferences ,,"Measurement of the oxygen concentration in a boiler is crucial for efficient combustion in a gas-fired boiler, which results in the reduction of the amount of release of toxic gases in the environment. This research work describes a method to improve the effectiveness and performance of the Boiler combustion efficiency by the prediction of oxygen content using a Data Ensemble model. More useful data about the flame's physical characteristics can be viewed using CCD flame pictures. Images of boilers at various temperatures, air pressures, and gas conditions have been acquired through on-site tests in a genuine combustion system and classification models have been used. By applying a deep learning prediction model to these images, and comparing the results with the test data set, the accurate value of oxygen content is determined. An accuracy of 98% and a loss of 0.02 have been obtained. The unsupervised and semi-supervised, multilevel based deep ensemble models are applied and oxygen content is predicted.",2688-0288,,979-8-3503-9874-8,1-8,IEEE , ,Deep learning;Temperature sensors;Analytical models;Atmospheric modeling;Toxic chemicals;Predictive models;Boilers,,
5092,"Title:Leveraging Profanity for Insincere Content Detection - A Neural Network Approach

 Community driven social media sites are rich sources of knowledge and entertainment and at the same vulnerable to the flames or toxic content that can be dangerous to various users of these platforms as well as to the society. Therefore, it is crucial to identify and remove such content to have a better and safe online experience. Manually eliminating flames is tedious and hence many research works focus on machine learning or deep learning models for automated methods. In this paper, we primarily focus on detecting the insincere content using neural network-based learning methods. We also integrated the profanity features as profanity is correlated with honesty according to psychology research. We tested our model on the questions datasets from CQA platform to detect the insincere content. Our integrated neural network model enabled us to achieve a high performance of F1-score, 94.01%, compared to the standard machine learning algorithms.",S. Gottipati; A. Tan; D. Chow; J. Shan; J. Lim; W. Kiat,,,Leveraging Profanity for Insincere Content Detection - A Neural Network Approach,,,10.1109/IEMCON51383.2020.9284844 ,IEEE Conferences ,,"Community driven social media sites are rich sources of knowledge and entertainment and at the same vulnerable to the flames or toxic content that can be dangerous to various users of these platforms as well as to the society. Therefore, it is crucial to identify and remove such content to have a better and safe online experience. Manually eliminating flames is tedious and hence many research works focus on machine learning or deep learning models for automated methods. In this paper, we primarily focus on detecting the insincere content using neural network-based learning methods. We also integrated the profanity features as profanity is correlated with honesty according to psychology research. We tested our model on the questions datasets from CQA platform to detect the insincere content. Our integrated neural network model enabled us to achieve a high performance of F1-score, 94.01%, compared to the standard machine learning algorithms.",2644-3163,,978-1-7281-8416-6,41-0047,IEEE , ,Deep learning;Training;Machine learning algorithms;Social networking (online);Neural networks;Psychology;Fires,,
5093,"Title:Multi-Ion-Sensing Emulator and Multivariate Calibration Optimization by Machine Learning Models

 One paramount challenge in multi-ion-sensing arises from ion interference that degrades the accuracy of sensor calibration. Machine learning models are here proposed to optimize such multivariate calibration. However, the acquisition of big experimental data is time and resource consuming in practice, necessitating new paradigms and efficient models for these data-limited frameworks. Therefore, a novel approach is presented in this work, where a multi-ion-sensing emulator is designed to explain the response of an ion-sensing array in a mixed-ion environment. A case study is performed emulating the concurrent monitoring of sodium, potassium, lithium, and lead ions, in a medium representative of sweat samples. These analytes are relevant examples of sweat ion-sensing applications for physiology, therapeutic drug monitoring, and heavy metal contamination. It is demonstrated that calibration datasets output by the emulator explain accurately the experimental response of polymeric solid-contact ion-selective electrodes, where root-mean-squared error of 1.37, 1.44, 1.78, 2 mV are obtained, respectively, for Na+, K+, Li+, Pb2+ sensor calibration in artificial sweat. Besides, synthetic datasets of custom size are generated to train, validate, and evaluate different types of multivariate regressors. A Multi-Output Support Vector Regressor (M-SVR) is proposed as a compact, accurate, robust, and efficient multivariate calibration model. It features 13.22% normalized root mean squares, and 20.29% mean root squares improvement compared to a simple linear regression model. It is an unbiased estimator for medium to large datasets, and its average generalization error is of 3.22%. Besides, M-SVR models have a lower computational complexity than single-output SVR or neural network models, making them a suitable solution for memory and energy-constrained edge devices used for continuous and real-time multi-ion monitoring.",I. N. Hanitra; F. Criscuolo; S. Carrara; G. De Micheli,,,Multi-Ion-Sensing Emulator and Multivariate Calibration Optimization by Machine Learning Models,9,,10.1109/ACCESS.2021.3065754 ,IEEE Journals ,,"One paramount challenge in multi-ion-sensing arises from ion interference that degrades the accuracy of sensor calibration. Machine learning models are here proposed to optimize such multivariate calibration. However, the acquisition of big experimental data is time and resource consuming in practice, necessitating new paradigms and efficient models for these data-limited frameworks. Therefore, a novel approach is presented in this work, where a multi-ion-sensing emulator is designed to explain the response of an ion-sensing array in a mixed-ion environment. A case study is performed emulating the concurrent monitoring of sodium, potassium, lithium, and lead ions, in a medium representative of sweat samples. These analytes are relevant examples of sweat ion-sensing applications for physiology, therapeutic drug monitoring, and heavy metal contamination. It is demonstrated that calibration datasets output by the emulator explain accurately the experimental response of polymeric solid-contact ion-selective electrodes, where root-mean-squared error of 1.37, 1.44, 1.78, 2 mV are obtained, respectively, for Na+, K+, Li+, Pb2+ sensor calibration in artificial sweat. Besides, synthetic datasets of custom size are generated to train, validate, and evaluate different types of multivariate regressors. A Multi-Output Support Vector Regressor (M-SVR) is proposed as a compact, accurate, robust, and efficient multivariate calibration model. It features 13.22% normalized root mean squares, and 20.29% mean root squares improvement compared to a simple linear regression model. It is an unbiased estimator for medium to large datasets, and its average generalization error is of 3.22%. Besides, M-SVR models have a lower computational complexity than single-output SVR or neural network models, making them a suitable solution for memory and energy-constrained edge devices used for continuous and real-time multi-ion monitoring.",2169-3536,,,46821-46836,IEEE , ,Ions;Monitoring;Calibration;Interference;Mathematical model;Lead;Training,,
5094,"Title:Cyberbullying detection on Tweets

 Nowadays the young generation spends a median of 3 hours a day on social media sites such as Twitter, Facebook, Instagram, Snapchat or TikTok. As a consequence, these platforms have gradually become part of their daily life as well as an influence on their attitude and behaviour. Although the social media platforms were originally designed to share information/news or connect families and friends, they also spread fake news, conspiracy theories, hate speech and cyberbullying. Cyberbullying is bullying with the use of digital technologies which is repeated, aimed at scaring, angering or shaming those who are targeted. Feeling vulnerable, powerless, humiliated, isolated, depressed or suicidal are examples of the negative effects from cyberbullying. Unfortunately, study has shown that one-third of the students have experienced cyberbullying in their lifetime. To mitigate this problem, we propose 1) a novel dataset of 67K tweets collected from Twitter, 2) automatic annotation methods for a large-scale dataset and 3) a detection system that to identify these toxic behaviours. The experimental results demonstrate that our method outperforms the baseline by 4%.",A. Phanomtip; T. Sueb-in; S. Vittayakorn,,,Cyberbullying detection on Tweets,,,10.1109/ECTI-CON51831.2021.9454848 ,IEEE Conferences ,,"Nowadays the young generation spends a median of 3 hours a day on social media sites such as Twitter, Facebook, Instagram, Snapchat or TikTok. As a consequence, these platforms have gradually become part of their daily life as well as an influence on their attitude and behaviour. Although the social media platforms were originally designed to share information/news or connect families and friends, they also spread fake news, conspiracy theories, hate speech and cyberbullying. Cyberbullying is bullying with the use of digital technologies which is repeated, aimed at scaring, angering or shaming those who are targeted. Feeling vulnerable, powerless, humiliated, isolated, depressed or suicidal are examples of the negative effects from cyberbullying. Unfortunately, study has shown that one-third of the students have experienced cyberbullying in their lifetime. To mitigate this problem, we propose 1) a novel dataset of 67K tweets collected from Twitter, 2) automatic annotation methods for a large-scale dataset and 3) a detection system that to identify these toxic behaviours. The experimental results demonstrate that our method outperforms the baseline by 4%.",,,978-1-6654-0382-5,295-298,IEEE , ,Training;Social networking (online);Annotations;Multimedia Web sites;Blogs;Telecommunications;Labeling,,
5095,"Title:Automatic Vehicle Pollution Detection Using Feedback Based Iterative Deep Learning

 Air pollution is one of the major health hazards in modern times. Vehicle pollution is one of the major contributors to aerial contamination. Significant emphasis has been given by the researchers to identify the traffic pollutant sources. However, there is a need for a low-cost, automated solution for fast detection of polluting vehicles from the end of law enforcers. In this article, we have presented a novel deep learning based evaluation strategy that will identify the pollutant vehicle through on- road installed surveillance camera images. An enhanced image data set with notable variations has been prepared for training the models. Thereafter, a multi-model feedback process has been integrated. In contrast to the other deep learning approaches, the proposed framework has started with low labeled training data which is quite relevant in real-life scenarios. Subsequently, the size of the training samples has been increased using feedback. The evaluation of the framework has been performed with seven popular deep learning CNN models, i.e Inception-V3, MobileNet-V2, MobileNet-V3 (small), InceptionResNet-V2, VGG16, VGG19 and XceptionNet. Transfer learning has been exploited to distinguish the on- road pollutants and to provide proper surveillance in transport system. We have compared our method with recent state-of-the-art techniques. The results have demonstrated the superiority of the proposed framework in the road surveillance domain. To the best of our knowledge, this is the first attempt to apply a feedback based iterative deep learning model for vehicle pollution detection.",U. Maulik; S. Kundu,,,Automatic Vehicle Pollution Detection Using Feedback Based Iterative Deep Learning,24,5,10.1109/TITS.2023.3239190 ,IEEE Journals ,,"Air pollution is one of the major health hazards in modern times. Vehicle pollution is one of the major contributors to aerial contamination. Significant emphasis has been given by the researchers to identify the traffic pollutant sources. However, there is a need for a low-cost, automated solution for fast detection of polluting vehicles from the end of law enforcers. In this article, we have presented a novel deep learning based evaluation strategy that will identify the pollutant vehicle through on- road installed surveillance camera images. An enhanced image data set with notable variations has been prepared for training the models. Thereafter, a multi-model feedback process has been integrated. In contrast to the other deep learning approaches, the proposed framework has started with low labeled training data which is quite relevant in real-life scenarios. Subsequently, the size of the training samples has been increased using feedback. The evaluation of the framework has been performed with seven popular deep learning CNN models, i.e Inception-V3, MobileNet-V2, MobileNet-V3 (small), InceptionResNet-V2, VGG16, VGG19 and XceptionNet. Transfer learning has been exploited to distinguish the on- road pollutants and to provide proper surveillance in transport system. We have compared our method with recent state-of-the-art techniques. The results have demonstrated the superiority of the proposed framework in the road surveillance domain. To the best of our knowledge, this is the first attempt to apply a feedback based iterative deep learning model for vehicle pollution detection.",1558-0016,,,4804-4814,IEEE , ,Surveillance;Engines;Deep learning;Air pollution;Roads;Iterative methods;Image color analysis,,
5096,"Title:Scalable Machine learning for Mushroom Dataset Classification

 High mycotoxin in mushrooms determines whether mushrooms are edible or toxic. In general, the distinction between foodstuffs and poisonous mushrooms is largely unknown. Each mushroom is unique in its own way. These characteristics have been described as characteristics to categorise mushrooms into two classes: edible and poisonous. Machine Learning (ML) is a system to recognize patterns which could be used in various fields which include medicine, business management, military and engineering. However, a scalable ML platform supports large dataset processing with higher speed in distributed manner. This research focuses on analysing the performance of the scalable ML classification algorithms in mushroom poisonous detection using scalable platform (i.e. Spark). At end, comparative performance analysis of baseline ML algorithms with Spark ML algorithms was conducted on the basis of various parameters viz., Accuracy, Precision, Recall, F1-score, ZOL and Kappa-statistics.",A. K. Agarwal; V. Khullar; N. K. Agrawal,,,Scalable Machine learning for Mushroom Dataset Classification,,,10.1109/SASM51857.2021.9841201 ,IEEE Conferences ,,"High mycotoxin in mushrooms determines whether mushrooms are edible or toxic. In general, the distinction between foodstuffs and poisonous mushrooms is largely unknown. Each mushroom is unique in its own way. These characteristics have been described as characteristics to categorise mushrooms into two classes: edible and poisonous. Machine Learning (ML) is a system to recognize patterns which could be used in various fields which include medicine, business management, military and engineering. However, a scalable ML platform supports large dataset processing with higher speed in distributed manner. This research focuses on analysing the performance of the scalable ML classification algorithms in mushroom poisonous detection using scalable platform (i.e. Spark). At end, comparative performance analysis of baseline ML algorithms with Spark ML algorithms was conducted on the basis of various parameters viz., Accuracy, Precision, Recall, F1-score, ZOL and Kappa-statistics.",,,978-1-6654-0357-3,1-4,IEEE , ,Support vector machines;Radio frequency;Machine learning algorithms;Scalability;Machine learning;Classification algorithms;Performance analysis,,
5097,"Title:Classification and Prediction of Liver Disease Diagnosis Using Machine Learning Algorithms

 Liver diseases which is a chronic disease that lasts more than six months are one of the most dangerous and sounding alarms in the health care systems of the world due to the prediction of its enhancement due to several factors such as an increase in the consumption of alcohols, deteriorating polluting the situation in the whole world due to global warming and heavy industrialization and exhaust of toxic gases, contaminated water, and food, drug, primarily poor lifestyle choices lead to continuous increase in the diagnosis of anomalies in the liver of the Patients. The patient’s liver datasets are explored to build classification and prediction models for early diagnosis of liver disease. In an effort to reduce the workload on doctors, machine learning is used to predict disease. This paper explores many historical machine-learning models for liver diseases diagnosis and classification. The comparative evaluation of more than six models suggests the best method for the targeted dataset. Various ensemble techniques and tunning of hyperparameters suggest that these techniques may result in better accuracy but with the increased cost of computing, efficiency makes them irrelevant for real-world applications for offline problems these are the best bet for enhanced accuracy of the model.",H. S. Yadav; R. K. Singhal,,,Classification and Prediction of Liver Disease Diagnosis Using Machine Learning Algorithms,,,10.1109/INOCON57975.2023.10101221 ,IEEE Conferences ,,"Liver diseases which is a chronic disease that lasts more than six months are one of the most dangerous and sounding alarms in the health care systems of the world due to the prediction of its enhancement due to several factors such as an increase in the consumption of alcohols, deteriorating polluting the situation in the whole world due to global warming and heavy industrialization and exhaust of toxic gases, contaminated water, and food, drug, primarily poor lifestyle choices lead to continuous increase in the diagnosis of anomalies in the liver of the Patients. The patient’s liver datasets are explored to build classification and prediction models for early diagnosis of liver disease. In an effort to reduce the workload on doctors, machine learning is used to predict disease. This paper explores many historical machine-learning models for liver diseases diagnosis and classification. The comparative evaluation of more than six models suggests the best method for the targeted dataset. Various ensemble techniques and tunning of hyperparameters suggest that these techniques may result in better accuracy but with the increased cost of computing, efficiency makes them irrelevant for real-world applications for offline problems these are the best bet for enhanced accuracy of the model.",,,979-8-3503-2092-3,1-6,IEEE , ,Technological innovation;Machine learning algorithms;Liver diseases;Computational modeling;Medical services;Machine learning;Predictive models,,
5098,"Title:Determining the Effect of Correlation between Asthma/Gross Domestic Product and Air Pollution

 Air pollution, Asthma, and Gross Domestic Product (GDP) are very important indicators to human life and development and it has been found that air pollution has a big effect on the latter two. In this paper, we find the correlation factor and to what extent air pollution has an effect on those two. For this, we chose 20 American states, handpicked the ones having unique features with respect to pollution levels, asthma cases, GDP numbers, and the datasets for the past 20 years of each state were taken. We chose 6 toxic pollutants, namely PM2.5, Carbon Monoxide, Sulfur Dioxide, PM10, Ozone, and Nitrogen Dioxide with each dataset including daily readings of these pollutants for the past 20 years in each state. The idea behind our model is to use all these data and find the extent to which air pollution is related to the asthma cases and the GDP of a state. For this, we use 4 models, namely Neural Network (NN), Random Forest (RFC), Support Vector Machines (SVM) and K-Nearest Neighbors (KNN). We use metrics like Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and R-Squared to evaluate our results. We observed a positive correlation between rates of asthma and GDP and pollution data. NN gave the best prediction accuracy especially for GDP (Average: 76%) followed closely by SVM. SVM's also had the least MAE while RFC had the least RMSE.",A. N. S.; A. Y. Nair; V. S.,,,Determining the Effect of Correlation between Asthma/Gross Domestic Product and Air Pollution,,,10.1109/WiSPNET54241.2022.9767145 ,IEEE Conferences ,,"Air pollution, Asthma, and Gross Domestic Product (GDP) are very important indicators to human life and development and it has been found that air pollution has a big effect on the latter two. In this paper, we find the correlation factor and to what extent air pollution has an effect on those two. For this, we chose 20 American states, handpicked the ones having unique features with respect to pollution levels, asthma cases, GDP numbers, and the datasets for the past 20 years of each state were taken. We chose 6 toxic pollutants, namely PM2.5, Carbon Monoxide, Sulfur Dioxide, PM10, Ozone, and Nitrogen Dioxide with each dataset including daily readings of these pollutants for the past 20 years in each state. The idea behind our model is to use all these data and find the extent to which air pollution is related to the asthma cases and the GDP of a state. For this, we use 4 models, namely Neural Network (NN), Random Forest (RFC), Support Vector Machines (SVM) and K-Nearest Neighbors (KNN). We use metrics like Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and R-Squared to evaluate our results. We observed a positive correlation between rates of asthma and GDP and pollution data. NN gave the best prediction accuracy especially for GDP (Average: 76%) followed closely by SVM. SVM's also had the least MAE while RFC had the least RMSE.",,,978-1-6654-9648-3,44-48,IEEE , ,Support vector machines;Measurement;Wireless communication;Correlation;Economic indicators;Atmospheric modeling;Artificial neural networks,,
5099,"Title:Prediction Analysis of Idiopathic Pulmonary Fibrosis Progression from OSIC Dataset

 Pulmonary fibrosis is a progressive lungs disease which usually gets worse over time. Once this disease damages the lungs, it cannot be cured totally. But early detection and proper diagnosis can help to keep this disease in control. It causes scarring in the lungs over time. As an effect, people face breathing difficulty. It can cause shortness of breath, even at rest. The general causes of pulmonary fibrosis can be exposure to toxic element like coal dust, asbestos fibres, silica dust, hard metal dusts etc. But in majority of the cases, the doctor cannot figure out the exact cause of this disease. That's why this disease is termed as Idiopathic Pulmonary Fibrosis. The objective of this paper is to analyse and compare the performance of various machine leaning models by predicting the final forced volume capacity measurements for each patient and a confidence value. It can be deployed on any computer to predict a patient's severe condition regarding lungs function which is based on a CT scan of the lungs of the patients. Lung function is checked out based on a spirometer output that measures the forced vital capacity (FVC) of the lungs. In the future, early diagnosis of pulmonary fibrosis should be possible. Machine learning model is helping to use the human resources efficiently and it is also reducing the expanses spent on the social and healthcare aspects of this deadly disease.",S. Mandal; V. E. Balas; R. N. Shaw; A. Ghosh,,,Prediction Analysis of Idiopathic Pulmonary Fibrosis Progression from OSIC Dataset,,,10.1109/GUCON48875.2020.9231239 ,IEEE Conferences ,,"Pulmonary fibrosis is a progressive lungs disease which usually gets worse over time. Once this disease damages the lungs, it cannot be cured totally. But early detection and proper diagnosis can help to keep this disease in control. It causes scarring in the lungs over time. As an effect, people face breathing difficulty. It can cause shortness of breath, even at rest. The general causes of pulmonary fibrosis can be exposure to toxic element like coal dust, asbestos fibres, silica dust, hard metal dusts etc. But in majority of the cases, the doctor cannot figure out the exact cause of this disease. That's why this disease is termed as Idiopathic Pulmonary Fibrosis. The objective of this paper is to analyse and compare the performance of various machine leaning models by predicting the final forced volume capacity measurements for each patient and a confidence value. It can be deployed on any computer to predict a patient's severe condition regarding lungs function which is based on a CT scan of the lungs of the patients. Lung function is checked out based on a spirometer output that measures the forced vital capacity (FVC) of the lungs. In the future, early diagnosis of pulmonary fibrosis should be possible. Machine learning model is helping to use the human resources efficiently and it is also reducing the expanses spent on the social and healthcare aspects of this deadly disease.",,,978-1-7281-5070-3,861-865,IEEE , ,Analytical models;Force measurement;Pulmonary diseases;Computed tomography;Volume measurement;Lung;Medical services,,
5100,"Title:A signature-based liver cancer predictive system

 The predictive system presented in this paper employs both SOM and Hopfield nets to determine whether a given chemical agent causes cancer in the liver. The SOM net performs the clustering of the training set and delivers a signature for each cluster. Hopfield net treats each signature as an exemplar and learns the exemplars. Each record of the test set is considered a corrupted signature. The Hopfield net tries to un-corrupt the test record using learned exemplars and map it to one of the signatures and consequently to the prediction value associated with the signature. Four pairs of training and test sets are used to test the system. To establish the validity of the new predictive system, its performance is compared with the performance of the discriminant analysis and the rough sets methodology applied on the same datasets.",R. R. Hashemi; J. H. Early; M. Bahar; A. A. Tyler; J. F. Young,,,A signature-based liver cancer predictive system,1,,10.1109/ITCC.2005.37 ,IEEE Conferences ,,"The predictive system presented in this paper employs both SOM and Hopfield nets to determine whether a given chemical agent causes cancer in the liver. The SOM net performs the clustering of the training set and delivers a signature for each cluster. Hopfield net treats each signature as an exemplar and learns the exemplars. Each record of the test set is considered a corrupted signature. The Hopfield net tries to un-corrupt the test record using learned exemplars and map it to one of the signatures and consequently to the prediction value associated with the signature. Four pairs of training and test sets are used to test the system. To establish the validity of the new predictive system, its performance is compared with the performance of the discriminant analysis and the rough sets methodology applied on the same datasets.",,,0-7695-2315-3,195-199 Vol. 1,IEEE , ,Liver;Cancer;Computer science;System testing;Organizing;Neural networks;Physics;Educational institutions;Toxicology;Toxic chemicals,,
5101,"Title:Alignment of Chan's Supply Value chain Waste Management Using Artificial Intelligence

 Economy circulation can extend product cycle life, efficiency in using (extracting) natural resources, reduce waste generated from the production process and use recycled products as an increase in state revenue. The amount of waste does not show that the pattern of supply chain management in waste management is still not optimal, and the management of organic, inorganic waste (plastic, glass, wood, etc.) to hazardous and toxic waste (B3) which causes pollution, increases emissions impact on human health and the environment. Prevention to reduce excessive consumption patterns, waste management with the 3R pattern (reduce, reuse, and recycle), bio-physical-chemical processes for turning waste into new products, and waste incineration processes. Implementation of the Integrated Circular Economy System of waste in Indonesia with several stages of separating the waste into several waste groups, waste collection, waste transportation, waste treatment, and final waste treatment. Data collection in the form of data sets in the process of artificial intelligence or data mining for descriptive analysis, diagnostic analysis to find out the root of the problem and the background that occurs, predictive analysis to predict what will happen in the future, predictive analysis which is carried out at the latest and requires 4.0 technology supported by Artificial Intelligence (AI), Internet of Things (IoT) which is integrated with information systems in waste management to be able to improve people's welfare, reduce waste from upstream / households and provide government input to make policy technical, budgeting, operational efficiency, optimization of TPA and garbage transportation system.",A. Winarno; O. D. Nurhayati; R. Gernowo; Z. A. Hasibuan,,,Alignment of Chan's Supply Value chain Waste Management Using Artificial Intelligence,,,10.1109/iSemantic59612.2023.10295316 ,IEEE Conferences ,,"Economy circulation can extend product cycle life, efficiency in using (extracting) natural resources, reduce waste generated from the production process and use recycled products as an increase in state revenue. The amount of waste does not show that the pattern of supply chain management in waste management is still not optimal, and the management of organic, inorganic waste (plastic, glass, wood, etc.) to hazardous and toxic waste (B3) which causes pollution, increases emissions impact on human health and the environment. Prevention to reduce excessive consumption patterns, waste management with the 3R pattern (reduce, reuse, and recycle), bio-physical-chemical processes for turning waste into new products, and waste incineration processes. Implementation of the Integrated Circular Economy System of waste in Indonesia with several stages of separating the waste into several waste groups, waste collection, waste transportation, waste treatment, and final waste treatment. Data collection in the form of data sets in the process of artificial intelligence or data mining for descriptive analysis, diagnostic analysis to find out the root of the problem and the background that occurs, predictive analysis to predict what will happen in the future, predictive analysis which is carried out at the latest and requires 4.0 technology supported by Artificial Intelligence (AI), Internet of Things (IoT) which is integrated with information systems in waste management to be able to improve people's welfare, reduce waste from upstream / households and provide government input to make policy technical, budgeting, operational efficiency, optimization of TPA and garbage transportation system.",,,979-8-3503-3921-5,514-518,IEEE , ,Waste management;Transportation;System integration;Water conservation;Turning;Water pollution;Recycling,,
5102,"Title:Evaluation of Multi- and Hyper- Spectral Chl-A Algorithms in the RÍo De La Plata Turbid Waters During a Cyanobacteria Bloom

 The Río de la Plata estuary, located in the eastern coast of South America, has large social, ecological and economical importance for Argentina and Uruguay, in which margins their capital cities (Buenos Aires and Montevideo) and a number of harbours, resorts and industrial centres are located. Being the estuary the main source of drinking water for the millions of inhabitants in the region and a recreational area, the increasing occurrence of cyanobacteria blooms, consistently composed of Microcystis and Dolichospermum complex, is worrying and the need for a monitoring tool like remote sensing is highly desirable. In the present study we evaluated existing multi- and hyper-spectral red/NIR chlorophyll-a (chl-$a$) algorithms using radiometric and bio-optical field measurements. Empirically derived multi-spectral algorithms showed poor results, while hyper-spectral algorithms showed better and promising results. S3B/OLCI and CHRIS-PROBA chl-a maps were generated using fitted models derived using the existing in situ dataset.",A. I. Dogliotti; J. I. Gossn; C. Gonzalez; L. Yema; M. Sanchez; I. L. O'Farrell,,,Evaluation of Multi- and Hyper- Spectral Chl-A Algorithms in the RÍo De La Plata Turbid Waters During a Cyanobacteria Bloom,,,10.1109/IGARSS47720.2021.9553148 ,IEEE Conferences ,,"The Río de la Plata estuary, located in the eastern coast of South America, has large social, ecological and economical importance for Argentina and Uruguay, in which margins their capital cities (Buenos Aires and Montevideo) and a number of harbours, resorts and industrial centres are located. Being the estuary the main source of drinking water for the millions of inhabitants in the region and a recreational area, the increasing occurrence of cyanobacteria blooms, consistently composed of Microcystis and Dolichospermum complex, is worrying and the need for a monitoring tool like remote sensing is highly desirable. In the present study we evaluated existing multi- and hyper-spectral red/NIR chlorophyll-a (chl-$a$) algorithms using radiometric and bio-optical field measurements. Empirically derived multi-spectral algorithms showed poor results, while hyper-spectral algorithms showed better and promising results. S3B/OLCI and CHRIS-PROBA chl-a maps were generated using fitted models derived using the existing in situ dataset.",2153-7003,,978-1-6654-0369-6,7442-7445,IEEE , ,South America;Urban areas;Tools;Radiometry;Calibration;Optical sensors;Indexes,,
5103,"Title:An Artificial Intelligence and Cloud Based Collaborative Platform for Plant Disease Identification, Tracking and Forecasting for Farmers

 Plant diseases are a major threat to farmers, consumers, environment and the global economy. In India alone, 35% of field crops are lost to pathogens and pests causing losses to farmers. Indiscriminate use of pesticides is also a serious health concern as many are toxic and biomagnified. These adverse effects can be avoided by early disease detection, crop surveillance and targeted treatments. Most diseases are diagnosed by agricultural experts by examining external symptoms. However, farmers have limited access to experts. Our project is the first integrated and collaborative platform for automated disease diagnosis, tracking and forecasting. Farmers can instantly and accurately identify diseases and get solutions with a mobile app by photographing affected plant parts. Real-time diagnosis is enabled using the latest Artificial Intelligence (AI) algorithms for Cloud-based image processing. The AI model continuously learns from user uploaded images and expert suggestions to enhance its accuracy. Farmers can also interact with local experts through the platform. For preventive measures, disease density maps with spread forecasting are rendered from a Cloud based repository of geo-tagged images and micro-climactic factors. A web interface allows experts to perform disease analytics with geographical visualizations. In our experiments, the AI model (CNN) was trained with large disease datasets, created with plant images self-collected from many farms over 7 months. Test images were diagnosed using the automated CNN model and the results were validated by plant pathologists. Over 95% disease identification accuracy was achieved. Our solution is a novel, scalable and accessible tool for disease management of diverse agricultural crop plants and can be deployed as a Cloud based service for farmers and experts for ecologically sustainable crop production.",K. K. Singh,,,"An Artificial Intelligence and Cloud Based Collaborative Platform for Plant Disease Identification, Tracking and Forecasting for Farmers",,,10.1109/CCEM.2018.00016 ,IEEE Conferences ,,"Plant diseases are a major threat to farmers, consumers, environment and the global economy. In India alone, 35% of field crops are lost to pathogens and pests causing losses to farmers. Indiscriminate use of pesticides is also a serious health concern as many are toxic and biomagnified. These adverse effects can be avoided by early disease detection, crop surveillance and targeted treatments. Most diseases are diagnosed by agricultural experts by examining external symptoms. However, farmers have limited access to experts. Our project is the first integrated and collaborative platform for automated disease diagnosis, tracking and forecasting. Farmers can instantly and accurately identify diseases and get solutions with a mobile app by photographing affected plant parts. Real-time diagnosis is enabled using the latest Artificial Intelligence (AI) algorithms for Cloud-based image processing. The AI model continuously learns from user uploaded images and expert suggestions to enhance its accuracy. Farmers can also interact with local experts through the platform. For preventive measures, disease density maps with spread forecasting are rendered from a Cloud based repository of geo-tagged images and micro-climactic factors. A web interface allows experts to perform disease analytics with geographical visualizations. In our experiments, the AI model (CNN) was trained with large disease datasets, created with plant images self-collected from many farms over 7 months. Test images were diagnosed using the automated CNN model and the results were validated by plant pathologists. Over 95% disease identification accuracy was achieved. Our solution is a novel, scalable and accessible tool for disease management of diverse agricultural crop plants and can be deployed as a Cloud based service for farmers and experts for ecologically sustainable crop production.",,,978-1-5386-9441-1,49-56,IEEE , ,Diseases;Agriculture;Training;Artificial intelligence;Databases;Cloud computing;Medical diagnosis,,
5104,"Title:Oblivion: Poisoning Federated Learning by Inducing Catastrophic Forgetting

 Federated learning is exposed to model poisoning attacks as compromised clients may submit malicious model updates to pollute the global model. To defend against such attacks, robust aggregation rules are designed for the centralized server to winnow out outlier updates, and to significantly reduce the effectiveness of existing poisoning attacks. In this paper, we develop an advanced model poisoning attack against defensive aggregation rules. In particular, we exploit the catastrophic forgetting phenomenon during the process of continual learning to destroy the memory of the global model. Our proposed framework, called Oblivion, features two special components. The first component prioritizes the weights that have the most influence on the model accuracy for poisoning, which induces a more significant degradation on the global model than equally perturbing all weights. The second component smooths malicious model updates based on the number of selected compromised clients in the current round, adjusting the degree of poisoning to suit the dynamics of each training round. We implement a fully-functional prototype of Oblivion in PLATO, a real-world scalable federated learning framework. Our extensive experiments over three datasets demonstrate that Oblivion can boost the attack performance of model poisoning attacks against unknown defensive aggregation rules.",C. Zhang; B. Zhou; Z. He; Z. Liu; Y. Chen; W. Xu; B. Li,,,Oblivion: Poisoning Federated Learning by Inducing Catastrophic Forgetting,,,10.1109/INFOCOM53939.2023.10228981 ,IEEE Conferences ,,"Federated learning is exposed to model poisoning attacks as compromised clients may submit malicious model updates to pollute the global model. To defend against such attacks, robust aggregation rules are designed for the centralized server to winnow out outlier updates, and to significantly reduce the effectiveness of existing poisoning attacks. In this paper, we develop an advanced model poisoning attack against defensive aggregation rules. In particular, we exploit the catastrophic forgetting phenomenon during the process of continual learning to destroy the memory of the global model. Our proposed framework, called Oblivion, features two special components. The first component prioritizes the weights that have the most influence on the model accuracy for poisoning, which induces a more significant degradation on the global model than equally perturbing all weights. The second component smooths malicious model updates based on the number of selected compromised clients in the current round, adjusting the degree of poisoning to suit the dynamics of each training round. We implement a fully-functional prototype of Oblivion in PLATO, a real-world scalable federated learning framework. Our extensive experiments over three datasets demonstrate that Oblivion can boost the attack performance of model poisoning attacks against unknown defensive aggregation rules.",2641-9874,,979-8-3503-3414-2,1-10,IEEE , ,Training;Degradation;Federated learning;Computational modeling;Prototypes;Servers,,
5105,"Title:Chronic Kidney Disease Prediction Using Machine Learning Algorithms and the Important Attributes for the Detection

 In the modern world, chronic kidney disease has become one of the most hazardous diseases. CKD is a condition in which the kidney cannot perform the proper filtering of the blood or it stooped working completely which causes the left toxic into the blood, which leads the patient to death. It is likely impossible to detect CKD in the early stages, and it is very difficult to save patient’s lives in the last stage of CKD. A patient's life can be saved by renal transplant or the early detection the CKD. Machine Learning algorithm techniques have played a very important role in CKD prediction. Past medical test, reports can also be used as a tool for the early detection of renal disease. Machine Learning (ML) Techniques like KNN, Decision Tree, and ANN are used in this review. We have to find out that Decision Tree has shown the best result of 98.60% of accuracy. Generally, the majority of the algorithms are based on supervised learning and classification problem solving. We have explained some important attributes, which play a major role in early CKD Prediction and Detection. Every attribute has its specific effect on CKD. The previous researchers have done many experiments to get the best attribute and best ml technique for the prediction. in this paper, we have studied all related ML techniques, and important Attributes and discussed the measurement factor for CKD prediction.",G. Shukla; G. Dhuriya; S. K. Pillai; A. Saini,,,Chronic Kidney Disease Prediction Using Machine Learning Algorithms and the Important Attributes for the Detection,,,10.1109/GlobConET56651.2023.10149900 ,IEEE Conferences ,,"In the modern world, chronic kidney disease has become one of the most hazardous diseases. CKD is a condition in which the kidney cannot perform the proper filtering of the blood or it stooped working completely which causes the left toxic into the blood, which leads the patient to death. It is likely impossible to detect CKD in the early stages, and it is very difficult to save patient’s lives in the last stage of CKD. A patient's life can be saved by renal transplant or the early detection the CKD. Machine Learning algorithm techniques have played a very important role in CKD prediction. Past medical test, reports can also be used as a tool for the early detection of renal disease. Machine Learning (ML) Techniques like KNN, Decision Tree, and ANN are used in this review. We have to find out that Decision Tree has shown the best result of 98.60% of accuracy. Generally, the majority of the algorithms are based on supervised learning and classification problem solving. We have explained some important attributes, which play a major role in early CKD Prediction and Detection. Every attribute has its specific effect on CKD. The previous researchers have done many experiments to get the best attribute and best ml technique for the prediction. in this paper, we have studied all related ML techniques, and important Attributes and discussed the measurement factor for CKD prediction.",,,979-8-3503-3179-0,1-4,IEEE , ,Machine learning algorithms;Supervised learning;Surgery;Prediction algorithms;Chronic kidney disease;Organ transplantation;Decision trees,,
5106,"Title:Machine learning for the assessment and prediction of nitrite in the aquaculture water

 This paper presents an automatic system for the assessment and prediction of the nitrite level in the aquaculture water using machine learning (ML) techniques. The decision tree (DT) and artificial neural network (ANN) algorithms are used to create the desired prediction model. Then, these models are implemented on an embedded computer Raspberry Pi 3, which also plays both roles of image data collector and controller to peripheral devices. The system automatically takes a sample from the aquaculture water to a measuring chamber then mix it with the reagents to create a liquid solution whose color indicates the nitrite content in the water sample. From these colored liquid solutions, image processing methods are applied and combined with machine learning algorithms to assess and give out of the current state of nitrite levels in water sample such as good (0.0 mg/l), tolerable (0.5 mg/l), harmful (1.0 mg/l), dangerous (2.0 mg/l) or toxic (5.0 mg/l). The accuracy of the model based on the ANN algorithm is higher than the DT algorithm on both train dataset and test dataset. The system also allows users to set it up in two operation modes: auto and manual. The proposed system is connected to an Internet of Things (IoT) platform to transmit the prediction results to a mobile application and operating tested with water samples from a Ranchu aquarium in an aquaponics farm.",N. Nguyen; K. Nguyen; N. Dinh; N. Tran,,,Machine learning for the assessment and prediction of nitrite in the aquaculture water,,,10.1109/MAPR56351.2022.9924656 ,IEEE Conferences ,,"This paper presents an automatic system for the assessment and prediction of the nitrite level in the aquaculture water using machine learning (ML) techniques. The decision tree (DT) and artificial neural network (ANN) algorithms are used to create the desired prediction model. Then, these models are implemented on an embedded computer Raspberry Pi 3, which also plays both roles of image data collector and controller to peripheral devices. The system automatically takes a sample from the aquaculture water to a measuring chamber then mix it with the reagents to create a liquid solution whose color indicates the nitrite content in the water sample. From these colored liquid solutions, image processing methods are applied and combined with machine learning algorithms to assess and give out of the current state of nitrite levels in water sample such as good (0.0 mg/l), tolerable (0.5 mg/l), harmful (1.0 mg/l), dangerous (2.0 mg/l) or toxic (5.0 mg/l). The accuracy of the model based on the ANN algorithm is higher than the DT algorithm on both train dataset and test dataset. The system also allows users to set it up in two operation modes: auto and manual. The proposed system is connected to an Internet of Things (IoT) platform to transmit the prediction results to a mobile application and operating tested with water samples from a Ranchu aquarium in an aquaponics farm.",2770-6850,,978-1-6654-7410-8,1-5,IEEE , ,Machine learning algorithms;Liquids;Computational modeling;Machine learning;Artificial neural networks;Water quality;Predictive models,,
5107,"Title:Development of Spectroscopic Sensor System for an IoT Application of Adulteration Identification on Milk Using Machine Learning

 Adulteration in milk is a common scenario for gaining extra profit, which may cause severe harmful effects on humans. The qualitative spectroscopic technique provides a better solution for detecting the toxic contents of milk and foodstuffs. All the available spectroscopic methods for milk adulterant detection are based on laboratory-based with costly equipment. This laboratory-based detection takes a long time and is more expensive, which may not be afforded by a common man. To overcome this issue, this research work involves the design and development of a low-cost, portable, multispectral, AI-based, non-destructive spectroscopic sensor system that can be used to detect the milk adulterant in real-time. The designed sensor system uses the spectroscopic method with wavelength ranges from (410-940nm) which consists of three different bands Ultraviolet (UV), visible, and Infra-Red(IR) spectrum to improve the accuracy of detection. The sensor system is connected to the internet via the developed IoT application module, which displays the detected adulterant results in a dedicated web page designed for this purpose. This IoT application enables the adulterant detected results published on the internet immediately with location information for bringing transparency. Adulterant detection problem is formulated as a classification problem and solved by machine learning algorithms of a decision tree, Naive Bayes, linear discriminant analysis, support vector machine and neural network model. The average accuracy of linear discriminant analysis, support vector machine, Naive Bayes, decision tree and neural network model are obtained as 88.1%, 90%, 90%, 91.7% and 92.7% respectively. Genetic algorithm framework is formulated for hyperparameter tuning of neural network model which improved the accuracy from 92.7% to 100%. The model is trained for five different classes of four adulterants, namely Sodium Salicylate, Dextrose, Hydrogen Peroxide, Ammonium Sulphate, and one pure milk sample.",N. Sowmya; V. Ponnusamy,,,Development of Spectroscopic Sensor System for an IoT Application of Adulteration Identification on Milk Using Machine Learning,9,,10.1109/ACCESS.2021.3070558 ,IEEE Journals ,,"Adulteration in milk is a common scenario for gaining extra profit, which may cause severe harmful effects on humans. The qualitative spectroscopic technique provides a better solution for detecting the toxic contents of milk and foodstuffs. All the available spectroscopic methods for milk adulterant detection are based on laboratory-based with costly equipment. This laboratory-based detection takes a long time and is more expensive, which may not be afforded by a common man. To overcome this issue, this research work involves the design and development of a low-cost, portable, multispectral, AI-based, non-destructive spectroscopic sensor system that can be used to detect the milk adulterant in real-time. The designed sensor system uses the spectroscopic method with wavelength ranges from (410-940nm) which consists of three different bands Ultraviolet (UV), visible, and Infra-Red(IR) spectrum to improve the accuracy of detection. The sensor system is connected to the internet via the developed IoT application module, which displays the detected adulterant results in a dedicated web page designed for this purpose. This IoT application enables the adulterant detected results published on the internet immediately with location information for bringing transparency. Adulterant detection problem is formulated as a classification problem and solved by machine learning algorithms of a decision tree, Naive Bayes, linear discriminant analysis, support vector machine and neural network model. The average accuracy of linear discriminant analysis, support vector machine, Naive Bayes, decision tree and neural network model are obtained as 88.1%, 90%, 90%, 91.7% and 92.7% respectively. Genetic algorithm framework is formulated for hyperparameter tuning of neural network model which improved the accuracy from 92.7% to 100%. The model is trained for five different classes of four adulterants, namely Sodium Salicylate, Dextrose, Hydrogen Peroxide, Ammonium Sulphate, and one pure milk sample.",2169-3536,,,53979-53995,IEEE , ,Dairy products;Cows;Powders;Spectroscopy;Sensor systems;Internet of Things;Hydrogen,,
5108,"Title:Using Machine Learning and Regression Analysis to Classify and Predict Danger Levels in Burning Sites

 Firefighters go into burning structures to rescue trapped victims and put out the fire as soon as possible. Factors such as extreme temperatures, smoke, toxic gases, explosions, and falling objects inhibit their efficiency and risk their safety. These factors could change within a twinkle of an eye. Firefighters must be provided with accurate information and data about the burning site. They can make informed decisions about their duties and know when it is safe to enter and evacuate to reduce casualties. This research work presents Machine Learning (ML) and regression models for predicting the danger levels in burning sites and utilizes autonomous embedded system vehicles (AESV) to validate the models' performance to increase firefighters' safety. We investigated the classification performance of three ML methods: Support Vector Machines (SVM), Logistic Regression (LR), and k- Nearest Neighbors (k-NN) on the Cross Laminated Timber (CLT) data collected by the National Institute of Standards and Technology (NIST) and the National Research Council Canada while testing the impacts of laminated timber in a controlled fire temperature. We have reported promising results for danger levels classification with the three models, but the k-NN performed slightly better than the other two classifiers.",A. A. Ishola; D. Valles,,,Using Machine Learning and Regression Analysis to Classify and Predict Danger Levels in Burning Sites,,,10.1109/AIIoT54504.2022.9817232 ,IEEE Conferences ,,"Firefighters go into burning structures to rescue trapped victims and put out the fire as soon as possible. Factors such as extreme temperatures, smoke, toxic gases, explosions, and falling objects inhibit their efficiency and risk their safety. These factors could change within a twinkle of an eye. Firefighters must be provided with accurate information and data about the burning site. They can make informed decisions about their duties and know when it is safe to enter and evacuate to reduce casualties. This research work presents Machine Learning (ML) and regression models for predicting the danger levels in burning sites and utilizes autonomous embedded system vehicles (AESV) to validate the models' performance to increase firefighters' safety. We investigated the classification performance of three ML methods: Support Vector Machines (SVM), Logistic Regression (LR), and k- Nearest Neighbors (k-NN) on the Cross Laminated Timber (CLT) data collected by the National Institute of Standards and Technology (NIST) and the National Research Council Canada while testing the impacts of laminated timber in a controlled fire temperature. We have reported promising results for danger levels classification with the three models, but the k-NN performed slightly better than the other two classifiers.",,,978-1-6654-8453-4,453-459,IEEE , ,Support vector machines;Personal protective equipment;Temperature distribution;Machine learning;Predictive models;NIST;Safety,,
5109,"Title:Machine Learning for Classification of Inhibitors of Hepatic Drug Transporters

 Interactions between drugs may occur when drugs are administered together. These interactions can increase or decrease the efficacy of one of the drugs or can cause a new therapeutic effect which cannot be attributed to either drug alone. An important mechanism underlying drug-drug interactions is inhibition of proteins that mediate transport of drugs across cellular membranes. We developed five machine learning models, including deep learning, for predicting which drugs may inhibit transporter proteins in the liver, and assessed their performance in internal and external validation. Three out of five methods, k-nearest Neighbors, Support Vector Machines, and Recursive Neural Networks have not been previously applied in this domain. The area under the Receiver Operating Curve statistic for the five models ranged between 67% and 78%. Random forest and Support Vector Machines models showed the highest performance in external validation as assessed by the F1 metric. Our modeling approach and results demonstrate a practical application of machine learning techniques in an important application domain.",N. Khuri; S. Deshmukh,,,Machine Learning for Classification of Inhibitors of Hepatic Drug Transporters,,,10.1109/ICMLA.2018.00034 ,IEEE Conferences ,,"Interactions between drugs may occur when drugs are administered together. These interactions can increase or decrease the efficacy of one of the drugs or can cause a new therapeutic effect which cannot be attributed to either drug alone. An important mechanism underlying drug-drug interactions is inhibition of proteins that mediate transport of drugs across cellular membranes. We developed five machine learning models, including deep learning, for predicting which drugs may inhibit transporter proteins in the liver, and assessed their performance in internal and external validation. Three out of five methods, k-nearest Neighbors, Support Vector Machines, and Recursive Neural Networks have not been previously applied in this domain. The area under the Receiver Operating Curve statistic for the five models ranged between 67% and 78%. Random forest and Support Vector Machines models showed the highest performance in external validation as assessed by the F1 metric. Our modeling approach and results demonstrate a practical application of machine learning techniques in an important application domain.",,,978-1-5386-6805-4,181-186,IEEE , ,Drugs;Machine learning;Proteins;Computational modeling;Inhibitors;Data models;Liver,,
5110,"Title:Multi-label Comment Classification Using GloVe-RNN Framework

 Multi-label comment classification using GloVe embedding is addressed using deep neural networks in this paper. Online web media have opened a platform for users to express their thoughts on various contemporary issues and set no limit for their opinions. Unfortunately, the freedom of expression often leads to the usage of explicit language, which may hurt the readers. GloVe embedding vectors are computed in the front-end. Long short-term memory (LSTM), convolutional neural network (CNN), and gated recurrent neural network (GRU) models have been used for the classification phase. The performance is evaluated on the Kaggle comment classification dataset. The evaluation of results shows that recurrent neural network-based models outperform convolutional neural network-based models.",S. Nazar; R. Rajan,,,Multi-label Comment Classification Using GloVe-RNN Framework,,,10.1109/INDICON56171.2022.10040184 ,IEEE Conferences ,,"Multi-label comment classification using GloVe embedding is addressed using deep neural networks in this paper. Online web media have opened a platform for users to express their thoughts on various contemporary issues and set no limit for their opinions. Unfortunately, the freedom of expression often leads to the usage of explicit language, which may hurt the readers. GloVe embedding vectors are computed in the front-end. Long short-term memory (LSTM), convolutional neural network (CNN), and gated recurrent neural network (GRU) models have been used for the classification phase. The performance is evaluated on the Kaggle comment classification dataset. The evaluation of results shows that recurrent neural network-based models outperform convolutional neural network-based models.",2325-9418,,978-1-6654-7350-7,1-4,IEEE , ,Deep learning;Recurrent neural networks;Toxicology;Computational modeling;Media;Logic gates;Convolutional neural networks,,
5111,"Title:Domestic Trash Classification with Transfer Learning Using VGG16

 Environmental contamination is a major issue affecting all inhabitants living in any environment. The domestic environment is engulfed with many trash items such as solid and toxic trashes, leading to severe environmental contamination and causing life-threatening diseases if not appropriately managed. Trash classification is at the heart of these issues because the inability to classify the trash leads to difficulty in recycling. Humans categorize trash based on what they understand about the trash object rather than on the recyclability status of an object, which frequently leads to incorrect classification in manual classification. Additionally, coming into contact with toxic waste directly could be physically dangerous for those involved. Few machine learning and Deep Learning (DL) techniques were proposed using benchmarked trash classification datasets. However, most benchmarked datasets used to train DL models have a transparent or white background, which leads to a lack of model generalization, particularly in the real world. In this paper, we propose a Deep Learning model based on the VGG16 Architecture that can accurately classify various types of trash objects. On the TrashNet dataset plus the images collected in the wild, we achieved an accuracy of more than 96%.",H. Abdu; M. H. M. Noor,,,Domestic Trash Classification with Transfer Learning Using VGG16,,,10.1109/ICCSCE54767.2022.9935653 ,IEEE Conferences ,,"Environmental contamination is a major issue affecting all inhabitants living in any environment. The domestic environment is engulfed with many trash items such as solid and toxic trashes, leading to severe environmental contamination and causing life-threatening diseases if not appropriately managed. Trash classification is at the heart of these issues because the inability to classify the trash leads to difficulty in recycling. Humans categorize trash based on what they understand about the trash object rather than on the recyclability status of an object, which frequently leads to incorrect classification in manual classification. Additionally, coming into contact with toxic waste directly could be physically dangerous for those involved. Few machine learning and Deep Learning (DL) techniques were proposed using benchmarked trash classification datasets. However, most benchmarked datasets used to train DL models have a transparent or white background, which leads to a lack of model generalization, particularly in the real world. In this paper, we propose a Deep Learning model based on the VGG16 Architecture that can accurately classify various types of trash objects. On the TrashNet dataset plus the images collected in the wild, we achieved an accuracy of more than 96%.",,,978-1-6654-8339-1,137-141,IEEE , ,Deep learning;Heart;Transfer learning;Manuals;Benchmark testing;Solids;Control systems,,
5112,"Title:Automatically Detecting Cyberbullying Comments on Online Game Forums

 Online game forums are popular to most of game players. They use it to communicate and discuss the strategy of the game, or even to make friends. However, game forums also contain abusive and harassment speech, disturbing and threatening players. Therefore, it is necessary to automatically detect and remove cyberbullying comments to keep the game forum clean and friendly. We use the Cyberbullying dataset collected from World of Warcraft (WoW) and League of Legends (LoL) forums and train classification models to automatically detect whether a comment of a player is abusive or not. The result obtains 82.69% of macro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the Toxic-BERT model on the Cyberbullying dataset.",H. H. -P. Vo; H. Trung Tran; S. T. Luu,,,Automatically Detecting Cyberbullying Comments on Online Game Forums,,,10.1109/RIVF51545.2021.9642116 ,IEEE Conferences ,,"Online game forums are popular to most of game players. They use it to communicate and discuss the strategy of the game, or even to make friends. However, game forums also contain abusive and harassment speech, disturbing and threatening players. Therefore, it is necessary to automatically detect and remove cyberbullying comments to keep the game forum clean and friendly. We use the Cyberbullying dataset collected from World of Warcraft (WoW) and League of Legends (LoL) forums and train classification models to automatically detect whether a comment of a player is abusive or not. The result obtains 82.69% of macro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the Toxic-BERT model on the Cyberbullying dataset.",2162-786X,,978-1-6654-0435-8,1-5,IEEE , ,Dictionaries;Error analysis;Computational modeling;Text categorization;Cyberbullying;Games;Machine learning,,
5113,"Title:CO Emission Prediction of MSWI Processes Based on Nonlinear Feature Reduction Long Short-Term Memory Neural Network

 Carbon monoxide (CO), one of the by-products of the municipal solid waste incineration (MSWI) processes, is a toxic gas that is harm to human health. Moreover, its emission concentration relates to the dioxins (DXN) from the MSWI plant directly. Thus, the CO emission concentration should be predicted in terms of assisting the optimal control of pollutant emission in the MSWI process. In this article, a prediction method of CO emission concentration based on nonlinear feature reduction and long short-term memory neural network (LSTM) is proposed. Firstly, the nonlinear feature selection based on mutual information (MI) is carried out on the preprocessed data to remove the features with weak correlation. Then, the nonlinear features were extracted based on one-dimensional convolution (1DCNN), which is fed into LSTM to construct the prediction model. The convolutional layer and LSTM parameters are updated based on the loss function. Finally, the validity and rationality of the proposed method are verified based on the benchmark dataset and the actual industrial CO dataset.",R. Zhang; J. Tang; H. Xia; C. Cui; C. Xu; W. Xu,,,CO Emission Prediction of MSWI Processes Based on Nonlinear Feature Reduction Long Short-Term Memory Neural Network,,,10.1109/IAI59504.2023.10327537 ,IEEE Conferences ,,"Carbon monoxide (CO), one of the by-products of the municipal solid waste incineration (MSWI) processes, is a toxic gas that is harm to human health. Moreover, its emission concentration relates to the dioxins (DXN) from the MSWI plant directly. Thus, the CO emission concentration should be predicted in terms of assisting the optimal control of pollutant emission in the MSWI process. In this article, a prediction method of CO emission concentration based on nonlinear feature reduction and long short-term memory neural network (LSTM) is proposed. Firstly, the nonlinear feature selection based on mutual information (MI) is carried out on the preprocessed data to remove the features with weak correlation. Then, the nonlinear features were extracted based on one-dimensional convolution (1DCNN), which is fed into LSTM to construct the prediction model. The convolutional layer and LSTM parameters are updated based on the loss function. Finally, the validity and rationality of the proposed method are verified based on the benchmark dataset and the actual industrial CO dataset.",,,979-8-3503-2529-4,1-4,IEEE , ,Waste management;Waste materials;Solid modeling;Neural networks;Process control;Pollution control;Predictive models,,
5114,"Title:Few-Shot Learning for Small Impurities in Tobacco Stems With Improved YOLOv7

 With the increase of public concern about health and smoking, the authorities have gradually tightened the control of tar content in cigarettes, making reconstituted tobacco a growing concern for tobacco companies. Tobacco stems are used as the main raw material for reconstituted tobacco, but they contain a large number of small broken impurities mainly from cigarette butts, which are difficult to remove efficiently by air selection and manual methods. Detection schemes for cigarette butt impurities based on computer vision and deep learning are still difficult. The scarcity of images containing foreign impurities in cigarette butts and the small size of impurities limit the efficient application of deep learning algorithms. In view of the small impurities’ characteristics, this paper optimizes the model structure of the YOLOv7 algorithm, and only retains the two detection head structures with high feature resolution, which reduces the model parameters by 29.68%. Using online data augmentation and transfer learning, the difficulty of small sample datasets is overcome. After the CutMix, Mosaic, Affine transformation, Copy-paste data augmentation in this paper, the model precision is increased by 6.95%, and the recall rate is increased by 10.51%. Detection FPS has been increased from 99 FPS to 111 FPS. Precision and recall rate reached 97.21% and 92.11%. Compared with YOLOv4_csp, the precision is in-creased by 11.58%, and the recall rate is increased by 0.48%. It shows that the improved YOLOv7xs model has the potential for wide application in small target recognition. At the same time, it has shown the potential to avoid the harm of toxic substances produced by cigarette impurities in the combustion process and promotes the application of computer vision and deep learning in industrial production.",S. Xue; Z. Li; R. Wu; T. Zhu; Y. Yuan; C. Ni,,,Few-Shot Learning for Small Impurities in Tobacco Stems With Improved YOLOv7,11,,10.1109/ACCESS.2023.3275023 ,IEEE Journals ,,"With the increase of public concern about health and smoking, the authorities have gradually tightened the control of tar content in cigarettes, making reconstituted tobacco a growing concern for tobacco companies. Tobacco stems are used as the main raw material for reconstituted tobacco, but they contain a large number of small broken impurities mainly from cigarette butts, which are difficult to remove efficiently by air selection and manual methods. Detection schemes for cigarette butt impurities based on computer vision and deep learning are still difficult. The scarcity of images containing foreign impurities in cigarette butts and the small size of impurities limit the efficient application of deep learning algorithms. In view of the small impurities’ characteristics, this paper optimizes the model structure of the YOLOv7 algorithm, and only retains the two detection head structures with high feature resolution, which reduces the model parameters by 29.68%. Using online data augmentation and transfer learning, the difficulty of small sample datasets is overcome. After the CutMix, Mosaic, Affine transformation, Copy-paste data augmentation in this paper, the model precision is increased by 6.95%, and the recall rate is increased by 10.51%. Detection FPS has been increased from 99 FPS to 111 FPS. Precision and recall rate reached 97.21% and 92.11%. Compared with YOLOv4_csp, the precision is in-creased by 11.58%, and the recall rate is increased by 0.48%. It shows that the improved YOLOv7xs model has the potential for wide application in small target recognition. At the same time, it has shown the potential to avoid the harm of toxic substances produced by cigarette impurities in the combustion process and promotes the application of computer vision and deep learning in industrial production.",2169-3536,,,48136-48144,IEEE , ,Impurities;Raw materials;Production;Sorting;Deep learning;Cameras;Transfer learning;Computer vision;Crops,,
5115,"Title:Development of Interactive Dashboards and Intelligent Data Analytics for Visual Decision-Making in The Underground Mining Environment: The Sterkfontein Cave Case Study

 In the 21st century, the advancements of computing, Internet of Things and wireless communications are enabling mining companies to collect a vast amount of datasets during risk management. Multipurpose sensors installed at many locations in underground mining environment provide data about the safety, security and mine conditions in near realtime. However, it is more important to convert this data into strategic intelligence, which means the communication of the right information to the right people at the right time to enable them to make optimal and informed decisions on risk control and process optimization. The Sterkfontein caves is a world heritage site, and over the past few years, some deformation was recorded inside the caves. Possible reasons include urbanization in the surrounding area, illegal dolomite mining in the past, weathering, man-made archaeological activities and continuous pouring of polluted and acidic water into the caves system. Acid water has high potential to dissolve the sensitive dolomite, create new and enlarge existing rock cavities, which can destabilize rock formations. The Wits Mining Institute (WMI) has installed a geotechnical and geo-environmental wireless sensor network inside the caves for monitoring and to gain a better understanding of deformation in a cave system. In this research, data analytics and visualization concepts have been applied to the data collected from the sensors in order to identify the trends or patterns inside the caves. Several dashboards have been developed to analyze and visualize the ground movement, wind velocity, temperature, humidity and toxic gases (carbon monoxide) using Tableau code. The data from ground movement monitoring sensors placed at different locations can be analyzed and visualized in relation to each other and in different time steps (minutes to hours, daily, weekly, monthly and/or yearly basis). The analytics can also be applied to the aggregated data based on seasonal, time and/or location variation. The results of this study showed that interactive intelligent dashboards are key to interpret underground data insights and to provide the deep understanding required for smart, near real-time decision-making.",I. Atif; F. T. Cawood; M. A. Mahboob,,,Development of Interactive Dashboards and Intelligent Data Analytics for Visual Decision-Making in The Underground Mining Environment: The Sterkfontein Cave Case Study,,,10.1109/IBCAST51254.2021.9393017 ,IEEE Conferences ,,"In the 21st century, the advancements of computing, Internet of Things and wireless communications are enabling mining companies to collect a vast amount of datasets during risk management. Multipurpose sensors installed at many locations in underground mining environment provide data about the safety, security and mine conditions in near realtime. However, it is more important to convert this data into strategic intelligence, which means the communication of the right information to the right people at the right time to enable them to make optimal and informed decisions on risk control and process optimization. The Sterkfontein caves is a world heritage site, and over the past few years, some deformation was recorded inside the caves. Possible reasons include urbanization in the surrounding area, illegal dolomite mining in the past, weathering, man-made archaeological activities and continuous pouring of polluted and acidic water into the caves system. Acid water has high potential to dissolve the sensitive dolomite, create new and enlarge existing rock cavities, which can destabilize rock formations. The Wits Mining Institute (WMI) has installed a geotechnical and geo-environmental wireless sensor network inside the caves for monitoring and to gain a better understanding of deformation in a cave system. In this research, data analytics and visualization concepts have been applied to the data collected from the sensors in order to identify the trends or patterns inside the caves. Several dashboards have been developed to analyze and visualize the ground movement, wind velocity, temperature, humidity and toxic gases (carbon monoxide) using Tableau code. The data from ground movement monitoring sensors placed at different locations can be analyzed and visualized in relation to each other and in different time steps (minutes to hours, daily, weekly, monthly and/or yearly basis). The analytics can also be applied to the aggregated data based on seasonal, time and/or location variation. The results of this study showed that interactive intelligent dashboards are key to interpret underground data insights and to provide the deep understanding required for smart, near real-time decision-making.",2151-1411,,978-1-6654-0516-4,383-388,IEEE , ,Temperature sensors;Data analysis;Decision making;Data visualization;Real-time systems;Data mining;Monitoring,,
5116,"Title:Prediction method of dioxin emission concentration based on PCA and deep forest regression

 Municipal solid waste incineration (MSWI) is a widely used technology for reducing, harmless and recycling municipal solid waste. However, dioxin (DXN), a highly toxic pollutant in the exhaust gas of MSWI process, is the main factor that causes the ""NIMBY effect"" in building incineration power plants. The existing DXN detection method by combining long-period online sampling and off-line testing cannot meet the requirement of direct optimization control of DXN. To solve this problem, the prediction model of DXN emission concentration based on easy-to-measure process variables has become a research hotspot. However, due to the high dimension of process variables and the complex mechanism of DXN generation, adsorption and emission, it is difficult to effectively select input features of DXN model. Therefore, this paper proposes a modeling method based on principal component analysis (PCA) and deep forest regression (DFR). At first, the dioxin emission characteristics of MSWI process are described. Then, a modeling strategy and algorithm including PCA dimension reduction and DFR modeling are proposed. Finally, the effectiveness of the proposed method is verified by using the Benchmark data set and the actual DXN data.",W. Xu; J. Tang; H. Xia; Z. Sun,,,Prediction method of dioxin emission concentration based on PCA and deep forest regression,,,10.23919/CCC52363.2021.9550458 ,IEEE Conferences ,,"Municipal solid waste incineration (MSWI) is a widely used technology for reducing, harmless and recycling municipal solid waste. However, dioxin (DXN), a highly toxic pollutant in the exhaust gas of MSWI process, is the main factor that causes the ""NIMBY effect"" in building incineration power plants. The existing DXN detection method by combining long-period online sampling and off-line testing cannot meet the requirement of direct optimization control of DXN. To solve this problem, the prediction model of DXN emission concentration based on easy-to-measure process variables has become a research hotspot. However, due to the high dimension of process variables and the complex mechanism of DXN generation, adsorption and emission, it is difficult to effectively select input features of DXN model. Therefore, this paper proposes a modeling method based on principal component analysis (PCA) and deep forest regression (DFR). At first, the dioxin emission characteristics of MSWI process are described. Then, a modeling strategy and algorithm including PCA dimension reduction and DFR modeling are proposed. Finally, the effectiveness of the proposed method is verified by using the Benchmark data set and the actual DXN data.",1934-1768,,978-9-8815-6380-4,1212-1217,IEEE , ,Waste management;Waste materials;Incineration;Forestry;Predictive models;Benchmark testing;Prediction algorithms,,
5117,"Title:An Improved Method for Making CNN Immune to Backdoor Attack by Activating Clustering

 When a neural network is trained with a data set from an untrusted source, an attacker can insert poisoned data with a backdoor trigger into the data set to make the neural network make wrong decisions. By using Activation Clustering over convolutional neural networks, we propose an improved method for defensing backdoor attacks in the process of data collection and preparation. Experimental results show that this method can reliably protect neural networks from the interference of malicious data during training. The essence of this method is making a neural network to learn the feature of the trigger and classify the toxic data into a separate class. The structure of the existing model is also optimized to make the size of the model lightweight.",Y. Zhou; Y. Lei; L. Yu; X. Li; D. Chen; T. Zhang,,,An Improved Method for Making CNN Immune to Backdoor Attack by Activating Clustering,,,10.1109/ISCSIC57216.2022.00012 ,IEEE Conferences ,,"When a neural network is trained with a data set from an untrusted source, an attacker can insert poisoned data with a backdoor trigger into the data set to make the neural network make wrong decisions. By using Activation Clustering over convolutional neural networks, we propose an improved method for defensing backdoor attacks in the process of data collection and preparation. Experimental results show that this method can reliably protect neural networks from the interference of malicious data during training. The essence of this method is making a neural network to learn the feature of the trigger and classify the toxic data into a separate class. The structure of the existing model is also optimized to make the size of the model lightweight.",,,978-1-6654-5488-9,1-6,IEEE , ,Training;Computer science;Computational modeling;Computer network reliability;Neural networks;Interference;Data collection,,
5118,"Title:AI-Based Child Care Parental Control System

 Due to the prevalence of the COVID-19 epidemic around the globe, children were compelled to engage in remote learning through online platforms, hence mobile phone has become one of their predominant devices. Mobile device with Internet access offers a major outlet for education, entertainment, and social connection, but this combination can lead to several significant bad sequences such as online exploitation, harmful addictions, and other negative impacts of online social networking. To address harmful effects, parental controls are becoming more crucial, yet Sri Lankan parents are less aware of this. Consequently, this study proposes a parental control system to monitor their child’s activities. Android, Microsoft Azure, Java, Python, OpenCV, MySQL, and FastAPI are among the most prominent technologies utilized in the proposed application’s development. The suggested approach focuses primarily on the Sri Lankan context and aims to enhance parental digital literacy while safeguarding children from cyber threats. Yielded results showed the proposed mobile application for the identification of toxic words, drugs & alcohol content, game character images, and Instagram Sinhala comments severity as 94%, 95%, 97%, and 55% respectively in controlled experiments.",U. Jayasekara; H. Maniyangama; K. Vithana; T. Weerasinghe; J. Wijekoon; R. Panchendrarajan,,,AI-Based Child Care Parental Control System,,,10.1109/ICAC57685.2022.10025332 ,IEEE Conferences ,,"Due to the prevalence of the COVID-19 epidemic around the globe, children were compelled to engage in remote learning through online platforms, hence mobile phone has become one of their predominant devices. Mobile device with Internet access offers a major outlet for education, entertainment, and social connection, but this combination can lead to several significant bad sequences such as online exploitation, harmful addictions, and other negative impacts of online social networking. To address harmful effects, parental controls are becoming more crucial, yet Sri Lankan parents are less aware of this. Consequently, this study proposes a parental control system to monitor their child’s activities. Android, Microsoft Azure, Java, Python, OpenCV, MySQL, and FastAPI are among the most prominent technologies utilized in the proposed application’s development. The suggested approach focuses primarily on the Sri Lankan context and aims to enhance parental digital literacy while safeguarding children from cyber threats. Yielded results showed the proposed mobile application for the identification of toxic words, drugs & alcohol content, game character images, and Instagram Sinhala comments severity as 94%, 95%, 97%, and 55% respectively in controlled experiments.",,,979-8-3503-9809-0,120-125,IEEE , ,Pediatrics;Social networking (online);Multimedia Web sites;Process control;Control systems;Real-time systems;Mobile applications,,
5119,"Title:Identification of Cyanobacteria for Harmful Algal Blooms Research Using the YOLO Framework

 Cyanobacteria, an ancient type of photosynthetic microbe, inhabit most fresh and marine water on Earth. The rapid growth of cyanobacteria can lead to Harmful Algal Blooms (HABs), posing major threats to water quality and aquatic ecosystems. Rapid and accurate identification of cyanobacteria is essential for population monitoring and mitigation efforts, especially when cyanobacteria produce toxins, threatening the health of wildlife and humans. However, the diverse shapes and appearances of cyanobacteria render manual identification time-consuming and error-prone. In this study, we make multiple novel contributions to the field of microscopic cyanobacterial identification using computer vision algorithms. To begin, we utilize the YOLOv5 algorithm, known for its speed and accuracy, which has never been evaluated for its efficacy in this field. Additionally, we propose numerous methods of addressing limited dataset size and image heterogeneity. We use various image pre-processing techniques, including color-preserving CLAHE. We also construct a comprehensive dataset containing several genera of cyanobacteria by supplementing laboratory images with opensource database images for training and evaluation. To combat overfitting and avoid unrealistic model performance values, we evaluate detection performance on common microscope artifacts (detritus and water bubbles), incorporate “background images”, which contain unrelated microorganisms into the dataset, and utilize image augmentation conservatively. Finally, hyperparameter tuning was used with a genetic algorithm to optimize a specified fitness function. The final model outperformed the Faster R-CNN model used in previous literature, achieving average precision values ranging from 70% to 90% for five commonly found, toxin-producing cyanobacteria taxa in the USA, representing state-of the-art performance and great potential for usage by biologists investigating HABs.",B. Li; K. Serrano; M. Mazzaro; M. Wu; W. Wang; M. Zhu,,,Identification of Cyanobacteria for Harmful Algal Blooms Research Using the YOLO Framework,,,10.1109/UEMCON59035.2023.10316078 ,IEEE Conferences ,,"Cyanobacteria, an ancient type of photosynthetic microbe, inhabit most fresh and marine water on Earth. The rapid growth of cyanobacteria can lead to Harmful Algal Blooms (HABs), posing major threats to water quality and aquatic ecosystems. Rapid and accurate identification of cyanobacteria is essential for population monitoring and mitigation efforts, especially when cyanobacteria produce toxins, threatening the health of wildlife and humans. However, the diverse shapes and appearances of cyanobacteria render manual identification time-consuming and error-prone. In this study, we make multiple novel contributions to the field of microscopic cyanobacterial identification using computer vision algorithms. To begin, we utilize the YOLOv5 algorithm, known for its speed and accuracy, which has never been evaluated for its efficacy in this field. Additionally, we propose numerous methods of addressing limited dataset size and image heterogeneity. We use various image pre-processing techniques, including color-preserving CLAHE. We also construct a comprehensive dataset containing several genera of cyanobacteria by supplementing laboratory images with opensource database images for training and evaluation. To combat overfitting and avoid unrealistic model performance values, we evaluate detection performance on common microscope artifacts (detritus and water bubbles), incorporate “background images”, which contain unrelated microorganisms into the dataset, and utilize image augmentation conservatively. Finally, hyperparameter tuning was used with a genetic algorithm to optimize a specified fitness function. The final model outperformed the Faster R-CNN model used in previous literature, achieving average precision values ranging from 70% to 90% for five commonly found, toxin-producing cyanobacteria taxa in the USA, representing state-of the-art performance and great potential for usage by biologists investigating HABs.",,,979-8-3503-0413-8,407-0415,IEEE , ,Training;Microscopy;Biological system modeling;Wildlife;Sociology;Water quality;Water conservation,,
5120,"Title:Modelling Chlorophyll-a Concentration using Deep Neural Networks considering Extreme Data Imbalance and Skewness

 Algal bloom has been a serious problem, as some of algae such as cyanobacteria produce toxic wastes. Chlorophyll-a has been one of the primary indicator of algal bloom; however, it is difficult to model to forecast due to scarceness of the events. Since canonical machine learning algorithms assume balanced datasets, data imbalance of the Chlorophyll-a concentration must be visited for accurate prediction. In this paper, we present a convolutional neural network model to predict Chlorophyll-a concentration, handling its data imbalance and skewness. The experiment results show that proper data transformation and oversampling can improve prediction accuracy, especially in rare-event regions.",J. -H. Choi; J. Kim; J. Won; O. Min,,,Modelling Chlorophyll-a Concentration using Deep Neural Networks considering Extreme Data Imbalance and Skewness,,,10.23919/ICACT.2019.8702027 ,IEEE Conferences ,,"Algal bloom has been a serious problem, as some of algae such as cyanobacteria produce toxic wastes. Chlorophyll-a has been one of the primary indicator of algal bloom; however, it is difficult to model to forecast due to scarceness of the events. Since canonical machine learning algorithms assume balanced datasets, data imbalance of the Chlorophyll-a concentration must be visited for accurate prediction. In this paper, we present a convolutional neural network model to predict Chlorophyll-a concentration, handling its data imbalance and skewness. The experiment results show that proper data transformation and oversampling can improve prediction accuracy, especially in rare-event regions.",1738-9445,,979-11-88428-02-1,631-634,IEEE , ,Predictive models;Data models;Convolutional neural networks;Training;Machine learning;Algae,,
5121,"Title:Towards Chronic Liver Dysfunction Self-monitoring: a Proof-of-Concept Study

 The liver is our very own chemical processing plant as it plays a vital role in maintaining the body's metabolic balance. Liver's health is assessed by a group of clinical tests (such as blood tests, ultrasonographic imaging, liver biopsy) most of which are invasive and burdensome for the patients. In the setting of severely scarred liver, toxic substances, such as ammonia, have fewer opportunities to be detoxified. Accumulation of ammonia in the systemic circulation and in the brain may result in Hepatic Encephalopathy (HE), a spectrum of neuropsychiatric abnormalities which entails changes in consciousness, intellectual functions, behavior. Minimal HE has attracted increasing attention, as it does not cause detectable changes in personality or behaviour, but the complex and sustained attention is impaired. Hence, it can be detected only by specific but biased, time-consuming and burdensome examinations, such as blood ammonia levels assessment and neuro-psychological tests. The obstrusivity of the majority of the liver function clinical tests, and, in case of minimal HE, the lack of reliable examinations, are encouraging the scientific community to look for alternative diagnostic methods. For this purpose, the exploitation of a non-invasive technique such as breath analysis, to identify chronic liver disease, discriminate among its degree of severity and detect the onset of HE, could be a step forward for clinical diagnosis. In this paper, we report a proof-of-concept study that aimed at detecting ammonia in the breath of patients suffering from chronic liver disease by means of a low-cost, easy-to-use, gas-sensors based device. Not only, we also aimed at investigating the possibility of discriminating the several severity degree of liver impairment on the basis of the detected ammonia.",D. Germanese; S. Colantonio; M. D’Acunto; M. Brunetto; V. Romagnoli; A. Salvati,,,Towards Chronic Liver Dysfunction Self-monitoring: a Proof-of-Concept Study,,,10.1109/ISCC47284.2019.8969605 ,IEEE Conferences ,,"The liver is our very own chemical processing plant as it plays a vital role in maintaining the body's metabolic balance. Liver's health is assessed by a group of clinical tests (such as blood tests, ultrasonographic imaging, liver biopsy) most of which are invasive and burdensome for the patients. In the setting of severely scarred liver, toxic substances, such as ammonia, have fewer opportunities to be detoxified. Accumulation of ammonia in the systemic circulation and in the brain may result in Hepatic Encephalopathy (HE), a spectrum of neuropsychiatric abnormalities which entails changes in consciousness, intellectual functions, behavior. Minimal HE has attracted increasing attention, as it does not cause detectable changes in personality or behaviour, but the complex and sustained attention is impaired. Hence, it can be detected only by specific but biased, time-consuming and burdensome examinations, such as blood ammonia levels assessment and neuro-psychological tests. The obstrusivity of the majority of the liver function clinical tests, and, in case of minimal HE, the lack of reliable examinations, are encouraging the scientific community to look for alternative diagnostic methods. For this purpose, the exploitation of a non-invasive technique such as breath analysis, to identify chronic liver disease, discriminate among its degree of severity and detect the onset of HE, could be a step forward for clinical diagnosis. In this paper, we report a proof-of-concept study that aimed at detecting ammonia in the breath of patients suffering from chronic liver disease by means of a low-cost, easy-to-use, gas-sensors based device. Not only, we also aimed at investigating the possibility of discriminating the several severity degree of liver impairment on the basis of the detected ammonia.",2642-7389,,978-1-7281-2999-0,1107-1112,IEEE , ,Ammonia;Liver diseases;Gas detectors;Blood;Sensor arrays,,
5122,"Title:Targets and Shapes Tracking (Advanced Seminar)

 The topics of tracking moving objects and moving shapes have been extensively researched in multiple communities – from Moving Objects Databases (MOD) and spatio-temporal data management, through image/video processing and traffic management, to environmental and ecology studies. This paper gives a summary of the topics discussed in the advanced seminar on tracking objects and shapes, as well as an overview of its proposed structure. After a brief introduction and motivation-survey of different research fields and societal applications, the first part of the seminar will give a historic survey of the fundamental techniques for tracking mobile objects. The second part will give an overview of the approaches popular in MOD and spatiotemporal data management communities (tracking and querying, streaming data, map-matching, etc.). The third part is the central one – discussing the issues and solutions in distributed tracking of moving objects and shapes: from topological predicates and trends detection, through tracking deformable shapes, to specifics of indoor tracking. The fourth major part is intended to be a ""potpourri-style"" review of different application contexts and the popular approaches for tracking individual objects and shapes – spanning from collective motion analysis in social networks and animal herds, through toxic elements, pollutants, and geoprocesses (landslides), to different approaches for visual analytics in this context. The main objective of this advanced seminar is to provide a cohesive overview of the different perspectives on motion tracking; the corresponding approaches for its effective management; and possibilities for other research directions",G. Trajcevski; P. Scheuermann,,,Targets and Shapes Tracking (Advanced Seminar),,,10.1109/MDM.2018.00015 ,IEEE Conferences ,,"The topics of tracking moving objects and moving shapes have been extensively researched in multiple communities – from Moving Objects Databases (MOD) and spatio-temporal data management, through image/video processing and traffic management, to environmental and ecology studies. This paper gives a summary of the topics discussed in the advanced seminar on tracking objects and shapes, as well as an overview of its proposed structure. After a brief introduction and motivation-survey of different research fields and societal applications, the first part of the seminar will give a historic survey of the fundamental techniques for tracking mobile objects. The second part will give an overview of the approaches popular in MOD and spatiotemporal data management communities (tracking and querying, streaming data, map-matching, etc.). The third part is the central one – discussing the issues and solutions in distributed tracking of moving objects and shapes: from topological predicates and trends detection, through tracking deformable shapes, to specifics of indoor tracking. The fourth major part is intended to be a ""potpourri-style"" review of different application contexts and the popular approaches for tracking individual objects and shapes – spanning from collective motion analysis in social networks and animal herds, through toxic elements, pollutants, and geoprocesses (landslides), to different approaches for visual analytics in this context. The main objective of this advanced seminar is to provide a cohesive overview of the different perspectives on motion tracking; the corresponding approaches for its effective management; and possibilities for other research directions",2375-0324,,978-1-5386-4133-0,7-10,IEEE , ,Sensors;Shape;Radar tracking;Seminars;Wireless sensor networks;Target tracking,,
5123,"Title:Standoff and Miniature Chemical Vapor Detectors Based on Tunable Diode Laser Absorption Spectroscopy

 Trace gas sensing and analysis by tunable diode laser absorption spectroscopy (TDLAS) has become a robust and reliable technology accepted for industrial process monitoring and control, quality assurance, environmental sensing, plant safety, and infrastructure security. Sensors incorporating well-packaged wavelength-stabilized near-IR (1.2-2.0 ¿m) laser sources sense over a dozen toxic or industrially-important gases. Recently developed mid-IR lasers, particularly quantum cascade devices spanning wavelengths of 3-12 ¿m, can sense in real-time sub-parts per million concentrations of many hydrocarbons.A large emerging application for TDLAS is standoff sensing of chemical vapors, e.g., leaks from natural gas pipelines. Employing a 10-mW DFB laser, the eye-safe, battery-powered, 6-lb handheld remote methane leak detector illuminates a noncooperative topographic surface and analyzes returned scattered light to deduce the presence of excess methane. For aerial surveying, replacing the handheld transceiver with a large-aperture telescope and adding an erbium-doped fiber amplifier to the laser transmitter extends the standoff distance to 3000 m. By selecting a laser source having an appropriate wavelength, the standoff TDLAS tool detects trace concentrations of nonmethane hazardous gases, including several high-priority toxic industrial compounds and emissions from illicit chemical production laboratories. This paper also describes concepts for miniature integrated optic TDLAS sensors that combine a laser source, sampling section, and detector on a monolithic semiconductor materials system substrate. Such chip-scale low-power integrated optic gas-phase chemical sensors may enable low-cost mass production, so that many hundreds or thousands of such sensors can be distributed cost-effectively over a wide area of interest and communicate via wireless networks.",M. B. Frish; R. T. Wainner; M. C. Laderer; B. D. Green; M. G. Allen,,,Standoff and Miniature Chemical Vapor Detectors Based on Tunable Diode Laser Absorption Spectroscopy,10,3,10.1109/JSEN.2009.2038536 ,IEEE Journals ,,"Trace gas sensing and analysis by tunable diode laser absorption spectroscopy (TDLAS) has become a robust and reliable technology accepted for industrial process monitoring and control, quality assurance, environmental sensing, plant safety, and infrastructure security. Sensors incorporating well-packaged wavelength-stabilized near-IR (1.2-2.0 ¿m) laser sources sense over a dozen toxic or industrially-important gases. Recently developed mid-IR lasers, particularly quantum cascade devices spanning wavelengths of 3-12 ¿m, can sense in real-time sub-parts per million concentrations of many hydrocarbons.A large emerging application for TDLAS is standoff sensing of chemical vapors, e.g., leaks from natural gas pipelines. Employing a 10-mW DFB laser, the eye-safe, battery-powered, 6-lb handheld remote methane leak detector illuminates a noncooperative topographic surface and analyzes returned scattered light to deduce the presence of excess methane. For aerial surveying, replacing the handheld transceiver with a large-aperture telescope and adding an erbium-doped fiber amplifier to the laser transmitter extends the standoff distance to 3000 m. By selecting a laser source having an appropriate wavelength, the standoff TDLAS tool detects trace concentrations of nonmethane hazardous gases, including several high-priority toxic industrial compounds and emissions from illicit chemical production laboratories. This paper also describes concepts for miniature integrated optic TDLAS sensors that combine a laser source, sampling section, and detector on a monolithic semiconductor materials system substrate. Such chip-scale low-power integrated optic gas-phase chemical sensors may enable low-cost mass production, so that many hundreds or thousands of such sensors can be distributed cost-effectively over a wide area of interest and communicate via wireless networks.",1558-1748,,,639-646,IEEE , ,Chemical lasers;Tunable circuits and devices;Diode lasers;Absorption;Spectroscopy;Gas lasers;Chemical sensors;Quantum cascade lasers;Gas industry;Erbium-doped fiber lasers,,
5124,"Title:Occurrence and Spatial Extent of HABs on the West Florida Shelf 2002–Present

 Harmful algal blooms (HABs) can lead to severe economic and ecological impacts in coastal areas and can threaten marine life and human health. About three quarters of these toxic blooms are caused by dinoflagellate species. One dinoflagellate species, i.e., Karenia brevis, blooms nearly every year in the Gulf of Mexico, particularly on the West Florida Shelf (WFS), where these blooms cause millions of dollars in socioeconomic damage. In this letter, we use the red band difference (RBD) bloom detection technique for detection of low backscattering phytoplankton blooms, such as K. brevis, and conduct time-series analyses of the spatial extent of these blooms using Moderate Resolution Imaging Spectroradiometer (MODIS) monthly mean data spanning July 2002 (sensor inception) to September 2014. The time-series results show that the RBD successfully detects the documented HABs in the region, illustrating the seasonal and interannual variability, including the extensive blooms of 2005 and 2014.",R. Amin; B. Penta; S. deRada,,,Occurrence and Spatial Extent of HABs on the West Florida Shelf 2002–Present,12,10,10.1109/LGRS.2015.2448453 ,IEEE Journals ,,"Harmful algal blooms (HABs) can lead to severe economic and ecological impacts in coastal areas and can threaten marine life and human health. About three quarters of these toxic blooms are caused by dinoflagellate species. One dinoflagellate species, i.e., Karenia brevis, blooms nearly every year in the Gulf of Mexico, particularly on the West Florida Shelf (WFS), where these blooms cause millions of dollars in socioeconomic damage. In this letter, we use the red band difference (RBD) bloom detection technique for detection of low backscattering phytoplankton blooms, such as K. brevis, and conduct time-series analyses of the spatial extent of these blooms using Moderate Resolution Imaging Spectroradiometer (MODIS) monthly mean data spanning July 2002 (sensor inception) to September 2014. The time-series results show that the RBD successfully detects the documented HABs in the region, illustrating the seasonal and interannual variability, including the extensive blooms of 2005 and 2014.",1558-0571,,,2080-2084,IEEE , ,Sea measurements;Oceans;MODIS;Remote sensing;Satellites;Noise;Clouds,,
